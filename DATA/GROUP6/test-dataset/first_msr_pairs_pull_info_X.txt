[{"A_title": "Fraction percentageValue rare overflowThe percentageValue() method of the Fraction class works by first multiplying the Fraction by 100 then converting the Fraction to a double. This causes overflows when the numerator is greater than Integer.MAX_VALUE/100 even when the value of the fraction is far below this value. The patch changes the method to first convert to a double value and then multiply this value by 100 - the result should be the same but with less overflows. An addition to the test for the method that covers this bug is also included.", "A_clean_title": ["fraction", "percentagevalu", "percentag", "valu", "rare", "overflowth", "overflow", "percentagevalu", "percentag", "valu", "method", "fraction", "class", "work", "by", "first", "multipli", "fraction", "by", "100", "then", "convert", "fraction", "doubl", "thi", "caus", "overflow", "when", "numer", "greater", "than", "integ", "max", "valu", "100", "even", "when", "valu", "fraction", "far", "below", "thi", "valu", "patch", "chang", "method", "first", "convert", "doubl", "valu", "then", "multipli", "thi", "valu", "by", "100", "result", "same", "but", "less", "overflow", "addit", "test", "method", "that", "cover", "thi", "bug", "also", "includ"], "B_title": "Added Fraction copy of Fraction . percentageValue ( ). ", "B_clean_title": ["ad", "fraction", "copi", "fraction", "percentagevalu", "percentag", "valu"]},
{"A_title": "NumberUtils.createNumber throws NumberFormatException for one digit longNumberUtils.createNumber throws a NumberFormatException when parsing 1l 2l .. etc... It works fine if you try to parse 01l or 02l.  The condition isDigits(numeric.substring(1)) line 455 return false as numeric.substring(1) is an empty string for 1l", "A_clean_title": ["numberutil", "createnumb", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "one", "digit", "longnumberutil", "createnumb", "long", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "when", "pars", "1l", "2l", "etc", "it", "work", "fine", "you", "tri", "pars", "01l", "or", "02l", "condit", "isdigit", "digit", "numer", "substr", "line", "455", "return", "fals", "as", "numer", "substr", "empti", "string", "1l"], "B_title": "Fix NumberFormatException. ", "B_clean_title": ["fix", "numberformatexcept", "number", "format", "except"]},
{"A_title": "NumberUtils.createNumber throws NumberFormatException for one digit longNumberUtils.createNumber throws a NumberFormatException when parsing 1l 2l .. etc... It works fine if you try to parse 01l or 02l.  The condition isDigits(numeric.substring(1)) line 455 return false as numeric.substring(1) is an empty string for 1l", "A_clean_title": ["numberutil", "createnumb", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "one", "digit", "longnumberutil", "createnumb", "long", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "when", "pars", "1l", "2l", "etc", "it", "work", "fine", "you", "tri", "pars", "01l", "or", "02l", "condit", "isdigit", "digit", "numer", "substr", "line", "455", "return", "fals", "as", "numer", "substr", "empti", "string", "1l"], "B_title": "Fix parse error ( l - > long ). ", "B_clean_title": ["fix", "pars", "error", "long"]},
{"A_title": "weight versus sigma in AbstractLeastSquaresIn AbstractLeastSquares residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS() these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation it should multiply the square of the residual even in the computation of the chi2.  Once corrected getRMS() can even reduce  public double getRMS()  return Math.sqrt(getChiSquare()/rows);", "A_clean_title": ["weight", "versu", "sigma", "abstractleastsquaresin", "abstract", "least", "squar", "abstractleastsquar", "abstract", "least", "squar", "residualsweight", "residu", "weight", "contain", "weight", "assign", "each", "observ", "method", "getrm", "get", "rm", "these", "weight", "are", "multipl", "as", "they", "unlik", "getchisquar", "get", "chi", "squar", "where", "it", "appear", "at", "denomin", "weight", "realli", "weight", "observ", "it", "multipli", "squar", "residu", "even", "comput", "chi2", "onc", "correct", "getrm", "get", "rm", "even", "reduc", "public", "doubl", "getrm", "get", "rm", "return", "math", "sqrt", "getchisquar", "get", "chi", "squar", "row"], "B_title": "Fix residualsWeights .. ", "B_clean_title": ["fix", "residualsweight", "residu", "weight"]},
{"A_title": "weight versus sigma in AbstractLeastSquaresIn AbstractLeastSquares residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS() these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation it should multiply the square of the residual even in the computation of the chi2.  Once corrected getRMS() can even reduce  public double getRMS()  return Math.sqrt(getChiSquare()/rows);", "A_clean_title": ["weight", "versu", "sigma", "abstractleastsquaresin", "abstract", "least", "squar", "abstractleastsquar", "abstract", "least", "squar", "residualsweight", "residu", "weight", "contain", "weight", "assign", "each", "observ", "method", "getrm", "get", "rm", "these", "weight", "are", "multipl", "as", "they", "unlik", "getchisquar", "get", "chi", "squar", "where", "it", "appear", "at", "denomin", "weight", "realli", "weight", "observ", "it", "multipli", "squar", "residu", "even", "comput", "chi2", "onc", "correct", "getrm", "get", "rm", "even", "reduc", "public", "doubl", "getrm", "get", "rm", "return", "math", "sqrt", "getchisquar", "get", "chi", "squar", "row"], "B_title": "Fix ColorConvertor .. ", "B_clean_title": ["fix", "colorconvertor", "color", "convertor"]},
{"A_title": "In stat.Frequency getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable)Drop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change Frequency.java    /**  Returns the percentage of values that are equal to v @deprecated replaced by  @link #getPct(Comparable)  as of 2.0      */     @Deprecated     public double getPct(Object v)           return getCumPct((Comparable<?>) v);     ", "A_clean_title": ["stat", "frequenc", "getpct", "get", "pct", "object", "use", "getcumpct", "get", "cum", "pct", "compar", "instead", "getpct", "get", "pct", "compar", "drop", "replac", "not", "possibl", "becaus", "all", "getpct", "get", "pct", "call", "will", "cummul", "without", "code", "chang", "frequenc", "java", "return", "percentag", "valu", "that", "are", "equal", "deprec", "replac", "by", "link", "getpct", "get", "pct", "compar", "as", "deprec", "public", "doubl", "getpct", "get", "pct", "object", "return", "getcumpct", "get", "cum", "pct", "compar"], "B_title": "Fix an issue with getPct that was being too verbose .. ", "B_clean_title": ["fix", "issu", "getpct", "get", "pct", "that", "wa", "be", "too", "verbos"]},
{"A_title": "In stat.Frequency getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable)Drop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change Frequency.java    /**  Returns the percentage of values that are equal to v @deprecated replaced by  @link #getPct(Comparable)  as of 2.0      */     @Deprecated     public double getPct(Object v)           return getCumPct((Comparable<?>) v);     ", "A_clean_title": ["stat", "frequenc", "getpct", "get", "pct", "object", "use", "getcumpct", "get", "cum", "pct", "compar", "instead", "getpct", "get", "pct", "compar", "drop", "replac", "not", "possibl", "becaus", "all", "getpct", "get", "pct", "call", "will", "cummul", "without", "code", "chang", "frequenc", "java", "return", "percentag", "valu", "that", "are", "equal", "deprec", "replac", "by", "link", "getpct", "get", "pct", "compar", "as", "deprec", "public", "doubl", "getpct", "get", "pct", "object", "return", "getcumpct", "get", "cum", "pct", "compar"], "B_title": "Fix getOwnPct return type. ", "B_clean_title": ["fix", "getownpct", "get", "own", "pct", "return", "type"]},
{"A_title": "In stat.Frequency getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable)Drop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change Frequency.java    /**  Returns the percentage of values that are equal to v @deprecated replaced by  @link #getPct(Comparable)  as of 2.0      */     @Deprecated     public double getPct(Object v)           return getCumPct((Comparable<?>) v);     ", "A_clean_title": ["stat", "frequenc", "getpct", "get", "pct", "object", "use", "getcumpct", "get", "cum", "pct", "compar", "instead", "getpct", "get", "pct", "compar", "drop", "replac", "not", "possibl", "becaus", "all", "getpct", "get", "pct", "call", "will", "cummul", "without", "code", "chang", "frequenc", "java", "return", "percentag", "valu", "that", "are", "equal", "deprec", "replac", "by", "link", "getpct", "get", "pct", "compar", "as", "deprec", "public", "doubl", "getpct", "get", "pct", "object", "return", "getcumpct", "get", "cum", "pct", "compar"], "B_title": "Fix getFrequency ( Object ) to return precise value instead of getCumPct ( Object ). ", "B_clean_title": ["fix", "getfrequ", "get", "frequenc", "object", "return", "precis", "valu", "instead", "getcumpct", "get", "cum", "pct", "object"]},
{"A_title": "In stat.Frequency getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable)Drop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change Frequency.java    /**  Returns the percentage of values that are equal to v @deprecated replaced by  @link #getPct(Comparable)  as of 2.0      */     @Deprecated     public double getPct(Object v)           return getCumPct((Comparable<?>) v);     ", "A_clean_title": ["stat", "frequenc", "getpct", "get", "pct", "object", "use", "getcumpct", "get", "cum", "pct", "compar", "instead", "getpct", "get", "pct", "compar", "drop", "replac", "not", "possibl", "becaus", "all", "getpct", "get", "pct", "call", "will", "cummul", "without", "code", "chang", "frequenc", "java", "return", "percentag", "valu", "that", "are", "equal", "deprec", "replac", "by", "link", "getpct", "get", "pct", "compar", "as", "deprec", "public", "doubl", "getpct", "get", "pct", "object", "return", "getcumpct", "get", "cum", "pct", "compar"], "B_title": "Add missing import .. Fix getFrequency ( Object ) to return 1  not 2. ", "B_clean_title": ["add", "miss", "import", "fix", "getfrequ", "get", "frequenc", "object", "return", "not"]},
{"A_title": "org.apache.commons.lang3.math.Fraction does not reduce (Integer.MIN_VALUE 2^k)The greatestCommonDivisor method in class Fraction does not find the gcd of Integer.MIN_VALUE and 2^k and this case can be triggered by taking Integer.MIN_VALUE as the numerator. Note that the case of taking Integer.MIN_VALUE as the denominator is handled explicitly in the getReducedFraction factory method. FractionTest.java // additional test cases public void testReducedFactory_int_int()  // ... f = Fraction.getReducedFraction(Integer.MIN_VALUE 2); assertEquals(Integer.MIN_VALUE / 2 f.getNumerator()); assertEquals(1 f.getDenominator());  public void testReduce()  // ... f = Fraction.getFraction(Integer.MIN_VALUE 2); result = f.reduce(); assertEquals(Integer.MIN_VALUE / 2 result.getNumerator()); assertEquals(1 result.getDenominator());", "A_clean_title": ["org", "apach", "common", "lang3", "math", "fraction", "not", "reduc", "integ", "min", "valu", "2^k", "greatestcommondivisor", "greatest", "common", "divisor", "method", "class", "fraction", "not", "find", "gcd", "integ", "min", "valu", "2^k", "thi", "case", "trigger", "by", "take", "integ", "min", "valu", "as", "numer", "note", "that", "case", "take", "integ", "min", "valu", "as", "denomin", "handl", "explicitli", "getreducedfract", "get", "reduc", "fraction", "factori", "method", "fractiontest", "java", "fraction", "test", "addit", "test", "case", "public", "void", "testreducedfactori", "int", "int", "test", "reduc", "factori", "fraction", "getreducedfract", "get", "reduc", "fraction", "integ", "min", "valu", "assertequ", "assert", "equal", "integ", "min", "valu", "getnumer", "get", "numer", "assertequ", "assert", "equal", "getdenomin", "get", "denomin", "public", "void", "testreduc", "test", "reduc", "fraction", "getfract", "get", "fraction", "integ", "min", "valu", "result", "reduc", "assertequ", "assert", "equal", "integ", "min", "valu", "result", "getnumer", "get", "numer", "assertequ", "assert", "equal", "result", "getdenomin", "get", "denomin"], "B_title": "Fix Fraction . greatestCommonDivisor ( ). ", "B_clean_title": ["fix", "fraction", "greatestcommondivisor", "greatest", "common", "divisor"]},
{"A_title": "org.apache.commons.lang3.math.Fraction does not reduce (Integer.MIN_VALUE 2^k)The greatestCommonDivisor method in class Fraction does not find the gcd of Integer.MIN_VALUE and 2^k and this case can be triggered by taking Integer.MIN_VALUE as the numerator. Note that the case of taking Integer.MIN_VALUE as the denominator is handled explicitly in the getReducedFraction factory method. FractionTest.java // additional test cases public void testReducedFactory_int_int()  // ... f = Fraction.getReducedFraction(Integer.MIN_VALUE 2); assertEquals(Integer.MIN_VALUE / 2 f.getNumerator()); assertEquals(1 f.getDenominator());  public void testReduce()  // ... f = Fraction.getFraction(Integer.MIN_VALUE 2); result = f.reduce(); assertEquals(Integer.MIN_VALUE / 2 result.getNumerator()); assertEquals(1 result.getDenominator());", "A_clean_title": ["org", "apach", "common", "lang3", "math", "fraction", "not", "reduc", "integ", "min", "valu", "2^k", "greatestcommondivisor", "greatest", "common", "divisor", "method", "class", "fraction", "not", "find", "gcd", "integ", "min", "valu", "2^k", "thi", "case", "trigger", "by", "take", "integ", "min", "valu", "as", "numer", "note", "that", "case", "take", "integ", "min", "valu", "as", "denomin", "handl", "explicitli", "getreducedfract", "get", "reduc", "fraction", "factori", "method", "fractiontest", "java", "fraction", "test", "addit", "test", "case", "public", "void", "testreducedfactori", "int", "int", "test", "reduc", "factori", "fraction", "getreducedfract", "get", "reduc", "fraction", "integ", "min", "valu", "assertequ", "assert", "equal", "integ", "min", "valu", "getnumer", "get", "numer", "assertequ", "assert", "equal", "getdenomin", "get", "denomin", "public", "void", "testreduc", "test", "reduc", "fraction", "getfract", "get", "fraction", "integ", "min", "valu", "result", "reduc", "assertequ", "assert", "equal", "integ", "min", "valu", "result", "getnumer", "get", "numer", "assertequ", "assert", "equal", "result", "getdenomin", "get", "denomin"], "B_title": "Fix greatestCommonDivisor in Fraction copy. ", "B_clean_title": ["fix", "greatestcommondivisor", "greatest", "common", "divisor", "fraction", "copi"]},
{"A_title": "HarmonicFitter.ParameterGuesser sometimes fails to return sensible valuesThe inner class ParameterGuesser in HarmonicFitter (package o.a.c.m.optimization.fitting) fails to compute a usable guess for the amplitude parameter.", "A_clean_title": ["harmonicfitt", "parameterguess", "harmon", "fitter", "paramet", "guesser", "sometim", "fail", "return", "sensibl", "valuesth", "valu", "inner", "class", "parameterguess", "paramet", "guesser", "harmonicfitt", "harmon", "fitter", "packag", "optim", "fit", "fail", "comput", "usabl", "guess", "amplitud", "paramet"], "B_title": "Added throw if c2 == 0 . 0 to HarmonicFitter . java. ", "B_clean_title": ["ad", "throw", "c2", "harmonicfitt", "harmon", "fitter", "java"]},
{"A_title": "HarmonicFitter.ParameterGuesser sometimes fails to return sensible valuesThe inner class ParameterGuesser in HarmonicFitter (package o.a.c.m.optimization.fitting) fails to compute a usable guess for the amplitude parameter.", "A_clean_title": ["harmonicfitt", "parameterguess", "harmon", "fitter", "paramet", "guesser", "sometim", "fail", "return", "sensibl", "valuesth", "valu", "inner", "class", "parameterguess", "paramet", "guesser", "harmonicfitt", "harmon", "fitter", "packag", "optim", "fit", "fail", "comput", "usabl", "guess", "amplitud", "paramet"], "B_title": "Add a throw if the pair of arguments are not compatible with 1 . 0 .. ", "B_clean_title": ["add", "throw", "pair", "argument", "are", "not", "compat"]},
{"A_title": "Constructor types that return all or unknown fail to parseNone", "A_clean_title": ["constructor", "type", "that", "return", "all", "or", "unknown", "fail", "parsenon", "pars", "none"], "B_title": "updated hercules patch. ", "B_clean_title": ["updat", "hercul", "patch"]},
{"A_title": "Bug in method appendFixedWidthPadRight of class StrBuilder causes an ArrayIndexOutOfBoundsExceptionTheres a bug in method appendFixedWidthPadRight of class StrBuilder: public StrBuilder appendFixedWidthPadRight(Object obj int width char padChar)          if (width > 0)              ensureCapacity(size + width);             String str = (obj == null ? getNullText() : obj.toString());             int strLen = str.length();             if (strLen >= width)    ==>            str.getChars(0 strLen buffer size);   <==== BUG: it should be str.getChars(0 width buffer size);               else                  int padLen = width - strLen;                 str.getChars(0 strLen buffer size);                 for (int i = 0; i < padLen; i++)                       buffersize + strLen + i = padChar;                                           size += width;                  return this;      This is causing an ArrayIndexOutOfBoundsException so this method is unusable when strLen > width. Its counterpart method appendFixedWidthPadLeft seems to be ok.", "A_clean_title": ["bug", "method", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "class", "strbuilder", "str", "builder", "caus", "arrayindexoutofboundsexceptionther", "array", "index", "out", "bound", "except", "there", "bug", "method", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "class", "strbuilder", "str", "builder", "public", "strbuilder", "str", "builder", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "object", "obj", "int", "width", "char", "padchar", "pad", "char", "width", "ensurecapac", "ensur", "capac", "size", "width", "string", "str", "obj", "null", "getnulltext", "get", "null", "text", "obj", "tostr", "string", "int", "strlen", "str", "len", "str", "length", "strlen", "str", "len", "width", "str", "getchar", "get", "char", "strlen", "str", "len", "buffer", "size", "bug", "it", "str", "getchar", "get", "char", "width", "buffer", "size", "int", "padlen", "pad", "len", "width", "strlen", "str", "len", "str", "getchar", "get", "char", "strlen", "str", "len", "buffer", "size", "int", "padlen", "pad", "len", "i++", "buffers", "strlen", "str", "len", "padchar", "pad", "char", "size", "width", "return", "thi", "thi", "caus", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "so", "thi", "method", "unus", "when", "strlen", "str", "len", "width", "it", "counterpart", "method", "appendfixedwidthpadleft", "append", "fix", "width", "pad", "left", "seem", "ok"], "B_title": "Removed reverseEach method from XmlConverterTest. ", "B_clean_title": ["remov", "reverseeach", "revers", "each", "method", "xmlconvertertest", "xml", "convert", "test"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "reduce error in SimplexTableau. ", "B_clean_title": ["reduc", "error", "simplextableau", "simplex", "tableau"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "Removing epsilon from tableau test .. ", "B_clean_title": ["remov", "epsilon", "tableau", "test"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "Using the copy of SimplexTableau  it is better for testing. ", "B_clean_title": ["copi", "simplextableau", "simplex", "tableau", "it", "better", "test"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "Updated patch1 - Math - 33 - Hercules . fixed. ", "B_clean_title": ["updat", "patch1", "math", "33", "hercul", "fix"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "Fix missing import. reduce maxUlps to epsilon. ", "B_clean_title": ["fix", "miss", "import", "reduc", "maxulp", "max", "ulp", "epsilon"]},
{"A_title": "BrentOptimizer not always reporting the best pointBrentOptimizer (package o.a.c.m.optimization.univariate) does not check that the point it is going to return is indeed the best one it has encountered. Indeed the last evaluated point might be slightly worse than the one before last.", "A_clean_title": ["brentoptim", "brent", "optim", "not", "alway", "report", "best", "pointbrentoptim", "point", "brent", "optim", "packag", "optim", "univari", "not", "check", "that", "point", "it", "go", "return", "inde", "best", "one", "it", "ha", "encount", "inde", "last", "evalu", "point", "might", "slightli", "wors", "than", "one", "befor", "last"], "B_title": "Using the best function to reduce the total number of tests for a fixed situation .. Fix the patch. ", "B_clean_title": ["best", "function", "reduc", "total", "number", "test", "fix", "situat", "fix", "patch"]},
{"A_title": "Negative value with restrictNonNegativeProblem: commons-math-2.2 SimplexSolver.  A variable with 0 coefficient may be assigned a negative value nevertheless restrictToNonnegative flag in call: SimplexSolver.optimize(function constraints GoalType.MINIMIZE true);  Function 1 * x + 1 * y + 0  Constraints: 1 * x + 0 * y = 1  Result: x = 1; y = -1;  Probably variables with 0 coefficients are omitted at some point of computation and because of that the restrictions do not affect their values.", "A_clean_title": ["neg", "valu", "restrictnonnegativeproblem", "restrict", "non", "neg", "problem", "common", "math", "simplexsolv", "simplex", "solver", "variabl", "coeffici", "may", "assign", "neg", "valu", "nevertheless", "restricttononneg", "restrict", "nonneg", "flag", "call", "simplexsolv", "optim", "simplex", "solver", "function", "constraint", "goaltyp", "minim", "goal", "type", "true", "function", "constraint", "result", "probabl", "variabl", "coeffici", "are", "omit", "at", "some", "point", "comput", "becaus", "that", "restrict", "not", "affect", "their", "valu"], "B_title": "Fixed case of unconstrained variables that still occur in the objective function in simplex solver.", "B_clean_title": ["fix", "case", "unconstrain", "variabl", "that", "still", "occur", "object", "function", "simplex", "solver"]},
{"A_title": "WicketTester does not follow absolute redirectsWicket tester does not follow absolute redirects:  This is a problem when using HttpsMapper. For example when requesting a page over http:// with an forced redirect to https:// for secure access will make wicket tester return null for the last renderer page instead of the rendered page instance. In general all kinds of absolute redirects to another page will not be tracked by wicket tester. So this potentially a problem for all kinds of tests that rely on absolute redirects.", "A_clean_title": ["wickettest", "wicket", "tester", "not", "follow", "absolut", "redirectswicket", "redirect", "wicket", "tester", "not", "follow", "absolut", "redirect", "thi", "problem", "when", "httpsmapper", "http", "mapper", "exampl", "when", "request", "page", "over", "http", "forc", "redirect", "http", "secur", "access", "will", "make", "wicket", "tester", "return", "null", "last", "render", "page", "instead", "render", "page", "instanc", "gener", "all", "kind", "absolut", "redirect", "anoth", "page", "will", "not", "track", "by", "wicket", "tester", "so", "thi", "potenti", "problem", "all", "kind", "test", "that", "reli", "absolut", "redirect"], "B_title": "WicketTester does not follow absolute redirects", "B_clean_title": ["wickettest", "wicket", "tester", "not", "follow", "absolut", "redirect"]},
{"A_title": "IllegalStateException at com.google.javascript.rhino.jstype.FunctionType.getInstanceTypeNone", "A_clean_title": ["illegalstateexcept", "illeg", "state", "except", "at", "com", "googl", "javascript", "rhino", "jstype", "functiontyp", "getinstancetypenon", "function", "type", "get", "instanc", "type", "none"], "B_title": "Skip checks if constructor has no instance type.", "B_clean_title": ["skip", "check", "constructor", "ha", "no", "instanc", "type"]},
{"A_title": "Query: for joins sometimes no or the wrong index is usedCurrently no index is used for the join condition. For example the query:  code select * from nodeTypeA as a  inner join nodeTypeB as b on isdescendantnode(b a)  where lower(a.x) = y and b.property is not null code  currently doesnt take into account that the path of the selector a is known at the time selector b is accessed (given that selector a is executed first). So in this case the query would use an index on the property b.property even if this index has a very bad selectivity (many nodes with this problem) or the query would use the node type index on nodeTypeB even if there are many nodes of this type.  Instead most likely the query should do a traversal using the isdescendantnode(b a) join condition.", "A_clean_title": ["queri", "join", "sometim", "no", "or", "wrong", "index", "usedcurr", "use", "current", "no", "index", "use", "join", "condit", "exampl", "queri", "code", "select", "nodetypea", "node", "type", "as", "inner", "join", "nodetypeb", "node", "type", "as", "isdescendantnod", "where", "lower", "properti", "not", "null", "code", "current", "doesnt", "take", "into", "account", "that", "path", "selector", "known", "at", "time", "selector", "access", "given", "that", "selector", "execut", "first", "so", "thi", "case", "queri", "would", "use", "index", "properti", "properti", "even", "thi", "index", "ha", "veri", "bad", "select", "mani", "node", "thi", "problem", "or", "queri", "would", "use", "node", "type", "index", "nodetypeb", "node", "type", "even", "there", "are", "mani", "node", "thi", "type", "instead", "most", "like", "queri", "travers", "isdescendantnod", "join", "condit"], "B_title": "Query: for joins sometimes no or the wrong index is used", "B_clean_title": ["queri", "join", "sometim", "no", "or", "wrong", "index", "use"]},
{"A_title": "Malformed solr delete queryFollowing OAK-734 the solr query tests are failing because of a parsing error on the wildcard delete query.  The exact query is path_exact:/test* which apparently upsets the lucene parser somehow.  Full trace:  code SEVERE: org.apache.solr.common.SolrException: org.apache.lucene.queryparser.classic.ParseException: Cannot parse path_exact:/test*: Lexical error at line 1 column 18.  Encountered: <EOF> after : /test* at org.apache.solr.update.DirectUpdateHandler2.getQuery(DirectUpdateHandler2.java:328) at org.apache.solr.update.DirectUpdateHandler2.deleteByQuery(DirectUpdateHandler2.java:340) at org.apache.solr.update.processor.RunUpdateProcessor.processDelete(RunUpdateProcessorFactory.java:72) at org.apache.solr.update.processor.UpdateRequestProcessor.processDelete(UpdateRequestProcessor.java:55) at org.apache.solr.update.processor.DistributedUpdateProcessor.doLocalDelete(DistributedUpdateProcessor.java:437) at org.apache.solr.update.processor.DistributedUpdateProcessor.doDeleteByQuery(DistributedUpdateProcessor.java:835) at org.apache.solr.update.processor.DistributedUpdateProcessor.processDelete(DistributedUpdateProcessor.java:657) at org.apache.solr.update.processor.LogUpdateProcessor.processDelete(LogUpdateProcessorFactory.java:121) at org.apache.solr.handler.loader.XMLLoader.processDelete(XMLLoader.java:330) at org.apache.solr.handler.loader.XMLLoader.processUpdate(XMLLoader.java:261) at org.apache.solr.handler.loader.XMLLoader.load(XMLLoader.java:157) at org.apache.solr.handler.UpdateRequestHandler 1.load(UpdateRequestHandler.java:92) at org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody(ContentStreamHandlerBase.java:74) at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:129) at org.apache.solr.core.SolrCore.execute(SolrCore.java:1699) at org.apache.solr.client.solrj.embedded.EmbeddedSolrServer.request(EmbeddedSolrServer.java:150) at org.apache.solr.client.solrj.request.AbstractUpdateRequest.process(AbstractUpdateRequest.java:117) at org.apache.solr.client.solrj.SolrServer.deleteByQuery(SolrServer.java:285) at org.apache.solr.client.solrj.SolrServer.deleteByQuery(SolrServer.java:271) at org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexUpdate.deleteSubtreeWriter(SolrIndexUpdate.java:161) at org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexUpdate.apply(SolrIndexUpdate.java:98) at org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexDiff.leave(SolrIndexDiff.java:202) at org.apache.jackrabbit.oak.spi.commit.CompositeEditor.leave(CompositeEditor.java:74) at org.apache.jackrabbit.oak.plugins.index.IndexHookManagerDiff.leave(IndexHookManagerDiff.java:117) at org.apache.jackrabbit.oak.spi.commit.EditorHook EditorDiff.process(EditorHook.java:115) at org.apache.jackrabbit.oak.spi.commit.EditorHook.process(EditorHook.java:80) at org.apache.jackrabbit.oak.spi.commit.EditorHook.processCommit(EditorHook.java:54) at org.apache.jackrabbit.oak.kernel.KernelNodeStoreBranch.merge(KernelNodeStoreBranch.java:144) at org.apache.jackrabbit.oak.core.RootImpl 2.run(RootImpl.java:266) at org.apache.jackrabbit.oak.core.RootImpl 2.run(RootImpl.java:1) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:337) at org.apache.jackrabbit.oak.core.RootImpl.commit(RootImpl.java:261) at org.apache.jackrabbit.oak.query.AbstractQueryTest.test(AbstractQueryTest.java:236) at org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTest.sql2(SolrIndexQueryTest.java:79) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.junit.runners.model.FrameworkMethod 1.runReflectiveCall(FrameworkMethod.java:44) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:76) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) at org.junit.runners.ParentRunner 3.run(ParentRunner.java:193) at org.junit.runners.ParentRunner 1.schedule(ParentRunner.java:52) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191) at org.junit.runners.ParentRunner.access 000(ParentRunner.java:42) at org.junit.runners.ParentRunner 2.evaluate(ParentRunner.java:184) at org.junit.runners.ParentRunner.run(ParentRunner.java:236) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197) Caused by: org.apache.lucene.queryparser.classic.ParseException: Cannot parse path_exact:/test*: Lexical error at line 1 column 18.  Encountered: <EOF> after : /test* at org.apache.lucene.queryparser.classic.QueryParserBase.parse(QueryParserBase.java:130) at org.apache.solr.search.LuceneQParser.parse(LuceneQParserPlugin.java:72) at org.apache.solr.search.QParser.getQuery(QParser.java:143) at org.apache.solr.update.DirectUpdateHandler2.getQuery(DirectUpdateHandler2.java:310) ... 58 more Caused by: org.apache.lucene.queryparser.classic.TokenMgrError: Lexical error at line 1 column 18.  Encountered: <EOF> after : /test* at org.apache.lucene.queryparser.classic.QueryParserTokenManager.getNextToken(QueryParserTokenManager.java:1048) at org.apache.lucene.queryparser.classic.QueryParser.jj_ntk(QueryParser.java:638) at org.apache.lucene.queryparser.classic.QueryParser.Clause(QueryParser.java:246) at org.apache.lucene.queryparser.classic.QueryParser.Query(QueryParser.java:181) at org.apache.lucene.queryparser.classic.QueryParser.TopLevelQuery(QueryParser.java:170) at org.apache.lucene.queryparser.classic.QueryParserBase.parse(QueryParserBase.java:120) ... 61 more code", "A_clean_title": ["malform", "solr", "delet", "queryfollow", "queri", "follow", "oak", "734", "solr", "queri", "test", "are", "fail", "becaus", "pars", "error", "wildcard", "delet", "queri", "exact", "queri", "path", "exact", "test", "which", "appar", "upset", "lucen", "parser", "somehow", "full", "trace", "code", "sever", "org", "apach", "solr", "common", "solrexcept", "solr", "except", "org", "apach", "lucen", "querypars", "classic", "parseexcept", "pars", "except", "not", "pars", "path", "exact", "test", "lexic", "error", "at", "line", "column", "18", "encount", "eof", "after", "test", "at", "org", "apach", "solr", "updat", "directupdatehandler2", "getqueri", "direct", "updat", "handler2", "get", "queri", "directupdatehandler2", "java:328", "direct", "updat", "handler2", "at", "org", "apach", "solr", "updat", "directupdatehandler2", "deletebyqueri", "direct", "updat", "handler2", "delet", "by", "queri", "directupdatehandler2", "java:340", "direct", "updat", "handler2", "at", "org", "apach", "solr", "updat", "processor", "runupdateprocessor", "processdelet", "run", "updat", "processor", "process", "delet", "runupdateprocessorfactori", "java:72", "run", "updat", "processor", "factori", "at", "org", "apach", "solr", "updat", "processor", "updaterequestprocessor", "processdelet", "updat", "request", "processor", "process", "delet", "updaterequestprocessor", "java:55", "updat", "request", "processor", "at", "org", "apach", "solr", "updat", "processor", "distributedupdateprocessor", "dolocaldelet", "distribut", "updat", "processor", "local", "delet", "distributedupdateprocessor", "java:437", "distribut", "updat", "processor", "at", "org", "apach", "solr", "updat", "processor", "distributedupdateprocessor", "dodeletebyqueri", "distribut", "updat", "processor", "delet", "by", "queri", "distributedupdateprocessor", "java:835", "distribut", "updat", "processor", "at", "org", "apach", "solr", "updat", "processor", "distributedupdateprocessor", "processdelet", "distribut", "updat", "processor", "process", "delet", "distributedupdateprocessor", "java:657", "distribut", "updat", "processor", "at", "org", "apach", "solr", "updat", "processor", "logupdateprocessor", "processdelet", "log", "updat", "processor", "process", "delet", "logupdateprocessorfactori", "java:121", "log", "updat", "processor", "factori", "at", "org", "apach", "solr", "handler", "loader", "xmlloader", "processdelet", "xml", "loader", "process", "delet", "xmlloader", "java:330", "xml", "loader", "at", "org", "apach", "solr", "handler", "loader", "xmlloader", "processupd", "xml", "loader", "process", "updat", "xmlloader", "java:261", "xml", "loader", "at", "org", "apach", "solr", "handler", "loader", "xmlloader", "load", "xml", "loader", "xmlloader", "java:157", "xml", "loader", "at", "org", "apach", "solr", "handler", "updaterequesthandl", "updat", "request", "handler", "load", "updaterequesthandl", "java:92", "updat", "request", "handler", "at", "org", "apach", "solr", "handler", "contentstreamhandlerbas", "handlerequestbodi", "content", "stream", "handler", "base", "handl", "request", "bodi", "contentstreamhandlerbas", "java:74", "content", "stream", "handler", "base", "at", "org", "apach", "solr", "handler", "requesthandlerbas", "handlerequest", "request", "handler", "base", "handl", "request", "requesthandlerbas", "java:129", "request", "handler", "base", "at", "org", "apach", "solr", "core", "solrcor", "execut", "solr", "core", "solrcor", "java:1699", "solr", "core", "at", "org", "apach", "solr", "client", "solrj", "embed", "embeddedsolrserv", "request", "embed", "solr", "server", "embeddedsolrserv", "java:150", "embed", "solr", "server", "at", "org", "apach", "solr", "client", "solrj", "request", "abstractupdaterequest", "process", "abstract", "updat", "request", "abstractupdaterequest", "java:117", "abstract", "updat", "request", "at", "org", "apach", "solr", "client", "solrj", "solrserv", "deletebyqueri", "solr", "server", "delet", "by", "queri", "solrserv", "java:285", "solr", "server", "at", "org", "apach", "solr", "client", "solrj", "solrserv", "deletebyqueri", "solr", "server", "delet", "by", "queri", "solrserv", "java:271", "solr", "server", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "solr", "index", "solrindexupd", "deletesubtreewrit", "solr", "index", "updat", "delet", "subtre", "writer", "solrindexupd", "java:161", "solr", "index", "updat", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "solr", "index", "solrindexupd", "appli", "solr", "index", "updat", "solrindexupd", "java:98", "solr", "index", "updat", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "solr", "index", "solrindexdiff", "leav", "solr", "index", "diff", "solrindexdiff", "java:202", "solr", "index", "diff", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositeeditor", "leav", "composit", "editor", "compositeeditor", "java:74", "composit", "editor", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "indexhookmanagerdiff", "leav", "index", "hook", "manag", "diff", "indexhookmanagerdiff", "java:117", "index", "hook", "manag", "diff", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "editorhook", "editor", "hook", "editordiff", "process", "editor", "diff", "editorhook", "java:115", "editor", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "editorhook", "process", "editor", "hook", "editorhook", "java:80", "editor", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "editorhook", "processcommit", "editor", "hook", "process", "commit", "editorhook", "java:54", "editor", "hook", "at", "org", "apach", "jackrabbit", "oak", "kernel", "kernelnodestorebranch", "merg", "kernel", "node", "store", "branch", "kernelnodestorebranch", "java:144", "kernel", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "root", "impl", "run", "rootimpl", "java:266", "root", "impl", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "root", "impl", "run", "rootimpl", "java:1", "root", "impl", "at", "java", "secur", "accesscontrol", "doprivileg", "access", "control", "privileg", "nativ", "method", "at", "javax", "secur", "auth", "subject", "doa", "as", "subject", "java:337", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "commit", "root", "impl", "rootimpl", "java:261", "root", "impl", "at", "org", "apach", "jackrabbit", "oak", "queri", "abstractquerytest", "test", "abstract", "queri", "test", "abstractquerytest", "java:236", "abstract", "queri", "test", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "solr", "queri", "solrindexquerytest", "sql2", "solr", "index", "queri", "test", "solrindexquerytest", "java:79", "solr", "index", "queri", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "org", "junit", "runner", "model", "frameworkmethod", "framework", "method", "runreflectivecal", "run", "reflect", "call", "frameworkmethod", "java:44", "framework", "method", "at", "org", "junit", "intern", "runner", "model", "reflectivecal", "run", "reflect", "callabl", "reflectivecal", "java:15", "reflect", "callabl", "at", "org", "junit", "runner", "model", "frameworkmethod", "invokeexplos", "framework", "method", "invok", "explos", "frameworkmethod", "java:41", "framework", "method", "at", "org", "junit", "intern", "runner", "statement", "invokemethod", "evalu", "invok", "method", "invokemethod", "java:20", "invok", "method", "at", "org", "junit", "intern", "runner", "statement", "runbefor", "evalu", "run", "befor", "runbefor", "java:28", "run", "befor", "at", "org", "junit", "intern", "runner", "statement", "runaft", "evalu", "run", "after", "runaft", "java:31", "run", "after", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:76", "block", "unit4class", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:50", "block", "unit4class", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "run", "parentrunn", "java:193", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "schedul", "parentrunn", "java:52", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "runchildren", "parent", "runner", "run", "children", "parentrunn", "java:191", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "access", "parent", "runner", "000", "parentrunn", "java:42", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "evalu", "parentrunn", "java:184", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "run", "parent", "runner", "parentrunn", "java:236", "parent", "runner", "at", "org", "eclips", "jdt", "intern", "junit4", "runner", "junit4testrefer", "run", "unit4test", "refer", "junit4testrefer", "java:50", "unit4test", "refer", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "testexecut", "run", "test", "execut", "testexecut", "java:38", "test", "execut", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:467", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:683", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "run", "remot", "test", "runner", "remotetestrunn", "java:390", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "main", "remot", "test", "runner", "remotetestrunn", "java:197", "remot", "test", "runner", "caus", "by", "org", "apach", "lucen", "querypars", "classic", "parseexcept", "pars", "except", "not", "pars", "path", "exact", "test", "lexic", "error", "at", "line", "column", "18", "encount", "eof", "after", "test", "at", "org", "apach", "lucen", "querypars", "classic", "queryparserbas", "pars", "queri", "parser", "base", "queryparserbas", "java:130", "queri", "parser", "base", "at", "org", "apach", "solr", "search", "luceneqpars", "pars", "lucen", "parser", "luceneqparserplugin", "java:72", "lucen", "parser", "plugin", "at", "org", "apach", "solr", "search", "qparser", "getqueri", "parser", "get", "queri", "qparser", "java:143", "parser", "at", "org", "apach", "solr", "updat", "directupdatehandler2", "getqueri", "direct", "updat", "handler2", "get", "queri", "directupdatehandler2", "java:310", "direct", "updat", "handler2", "58", "more", "caus", "by", "org", "apach", "lucen", "querypars", "classic", "tokenmgrerror", "token", "mgr", "error", "lexic", "error", "at", "line", "column", "18", "encount", "eof", "after", "test", "at", "org", "apach", "lucen", "querypars", "classic", "queryparsertokenmanag", "getnexttoken", "queri", "parser", "token", "manag", "get", "next", "token", "queryparsertokenmanag", "java:1048", "queri", "parser", "token", "manag", "at", "org", "apach", "lucen", "querypars", "classic", "querypars", "queri", "parser", "jj", "ntk", "querypars", "java:638", "queri", "parser", "at", "org", "apach", "lucen", "querypars", "classic", "querypars", "claus", "queri", "parser", "querypars", "java:246", "queri", "parser", "at", "org", "apach", "lucen", "querypars", "classic", "querypars", "queri", "queri", "parser", "querypars", "java:181", "queri", "parser", "at", "org", "apach", "lucen", "querypars", "classic", "querypars", "toplevelqueri", "queri", "parser", "top", "level", "queri", "querypars", "java:170", "queri", "parser", "at", "org", "apach", "lucen", "querypars", "classic", "queryparserbas", "pars", "queri", "parser", "base", "queryparserbas", "java:120", "queri", "parser", "base", "61", "more", "code"], "B_title": "Malformed solr delete query", "B_clean_title": ["malform", "solr", "delet", "queri"]},
{"A_title": "ArgumentCaptor no longer working for varargsWhen upgrading 1.10.8 the verify passes but the getValue() fails with this error. One other piece of info came to light as a result of creating the MCVE - the test works fine if the Date is the only element passed for bindVariables. That is remove var1 from target and test code then the test runs fine under 1.9.5 and 1.10.8. Also it doesnt matter that the captor is for a Date. The same issue occurs if the parameter is of another type such as Integer.", "A_clean_title": ["argumentcaptor", "argument", "captor", "no", "longer", "work", "varargswhen", "vararg", "when", "upgrad", "10", "verifi", "pass", "but", "getvalu", "get", "valu", "fail", "thi", "error", "one", "other", "piec", "info", "came", "light", "as", "result", "creat", "mcve", "test", "work", "fine", "date", "onli", "element", "pass", "bindvari", "bind", "variabl", "that", "remov", "var1", "target", "test", "code", "then", "test", "run", "fine", "under", "10", "also", "it", "doesnt", "matter", "that", "captor", "date", "same", "issu", "occur", "paramet", "anoth", "type", "such", "as", "integ"], "B_title": "Fixed issue 188 @Captor annotation should work OK with nested parametrized type", "B_clean_title": ["fix", "issu", "188", "captor", "annot", "work", "ok", "nest", "parametr", "type"]},
{"A_title": "URL IPv6 parsingThere is an issue with native IPv6 address parsing. https://::1/myapp URL parsing fails:  org.apache.wicket.request.Url.parse(https://::1/myapp) generates an exception: java.lang.NumberFormatException: For input string: 1 at java.lang.NumberFormatException.forInputString( NumberFormatException.java:65) at java.lang.Integer.parseInt(Integer.java:492)  However https://::1:80/myapp works as expected.", "A_clean_title": ["url", "ipv6", "pv6", "parsingther", "pars", "there", "issu", "nativ", "ipv6", "pv6", "address", "pars", "http", ":1", "myapp", "url", "pars", "fail", "org", "apach", "wicket", "request", "url", "pars", "http", ":1", "myapp", "gener", "except", "java", "lang", "numberformatexcept", "number", "format", "except", "input", "string", "at", "java", "lang", "numberformatexcept", "forinputstr", "number", "format", "except", "input", "string", "numberformatexcept", "java:65", "number", "format", "except", "at", "java", "lang", "integ", "parseint", "pars", "int", "integ", "java:492", "howev", "http", ":1:80", "myapp", "work", "as", "expect"], "B_title": "URL IPv6 parsing", "B_clean_title": ["url", "ipv6", "pv6", "pars"]},
{"A_title": "Fraction percentageValue rare overflowThe percentageValue() method of the Fraction class works by first multiplying the Fraction by 100 then converting the Fraction to a double. This causes overflows when the numerator is greater than Integer.MAX_VALUE/100 even when the value of the fraction is far below this value. The patch changes the method to first convert to a double value and then multiply this value by 100 - the result should be the same but with less overflows. An addition to the test for the method that covers this bug is also included.", "A_clean_title": ["fraction", "percentagevalu", "percentag", "valu", "rare", "overflowth", "overflow", "percentagevalu", "percentag", "valu", "method", "fraction", "class", "work", "by", "first", "multipli", "fraction", "by", "100", "then", "convert", "fraction", "doubl", "thi", "caus", "overflow", "when", "numer", "greater", "than", "integ", "max", "valu", "100", "even", "when", "valu", "fraction", "far", "below", "thi", "valu", "patch", "chang", "method", "first", "convert", "doubl", "valu", "then", "multipli", "thi", "valu", "by", "100", "result", "same", "but", "less", "overflow", "addit", "test", "method", "that", "cover", "thi", "bug", "also", "includ"], "B_title": "Avoid overflow.", "B_clean_title": ["avoid", "overflow"]},
{"A_title": "Component#setDefaultModel() should call #modelChanging()Component#setDefaultModel() should call #modelChanging() as #setDefaultModelObject() does. It worked by chance so far because addStateChange() is called.  http://markmail.org/thread/uxl6uufusggqbb6s", "A_clean_title": ["compon", "setdefaultmodel", "set", "default", "model", "call", "modelchang", "model", "chang", "compon", "setdefaultmodel", "set", "default", "model", "call", "modelchang", "model", "chang", "as", "setdefaultmodelobject", "set", "default", "model", "object", "it", "work", "by", "chanc", "so", "far", "becaus", "addstatechang", "add", "state", "chang", "call", "http", "markmail", "org", "thread", "uxl6uufusggqbb6"], "B_title": "Component#setDefaultModel() should call #modelChanging()", "B_clean_title": ["compon", "setdefaultmodel", "set", "default", "model", "call", "modelchang", "model", "chang"]},
{"A_title": "Validity checks missing for readFields and Thrift deserializationClasses in o.a.a.core.data (and potentially elsewhere) that support construction from a Thrift object and/or population from a DataInput (via a readFields() method) often lack data validity checks that the classes constructors enforce. The missing checks make it possible for an attacker to create invalid objects by manipulating the bytes being read. The situation is analogous to the need to check objects deserialized from their Java serialized form within the readObject() method.", "A_clean_title": ["valid", "check", "miss", "readfield", "read", "field", "thrift", "deserializationclass", "deseri", "class", "core", "data", "potenti", "elsewher", "that", "support", "construct", "thrift", "object", "or", "popul", "datainput", "data", "input", "via", "readfield", "read", "field", "method", "often", "lack", "data", "valid", "check", "that", "class", "constructor", "enforc", "miss", "check", "make", "it", "possibl", "attack", "creat", "invalid", "object", "by", "manipul", "byte", "be", "read", "situat", "analog", "need", "check", "object", "deseri", "their", "java", "serial", "form", "within", "readobject", "read", "object", "method"], "B_title": "merge to 1.5.1-SNAPSHOT", "B_clean_title": ["merg", "snapshot"]},
{"A_title": "RDB Updated blob still deleted even if deletion interval lowerIf an existing blob is uploaded again the timestamp of the existing entry is updated in the meta table. Subsequently if a call to delete (RDBBlobStore#countDeleteChunks) is made with maxLastModifiedTime parameter of less than the updated time above the entry in the meta table is not touched but the data table entry is wiped out.   Refer https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/rdb/RDBBlobStore.java#L510", "A_clean_title": ["rdb", "updat", "blob", "still", "delet", "even", "delet", "interv", "lowerif", "lower", "exist", "blob", "upload", "again", "timestamp", "exist", "entri", "updat", "meta", "tabl", "subsequ", "call", "delet", "rdbblobstor", "rdb", "blob", "store", "countdeletechunk", "count", "delet", "chunk", "made", "maxlastmodifiedtim", "max", "last", "modifi", "time", "paramet", "less", "than", "updat", "time", "abov", "entri", "meta", "tabl", "not", "touch", "but", "data", "tabl", "entri", "wipe", "out", "refer", "http", "oak", "blob", "trunk", "oak", "java", "github", "com", "apach", "jackrabbit", "core", "src", "main", "java", "org", "apach", "jackrabbit", "oak", "plugin", "document", "rdb", "rdbblobstor", "rdb", "blob", "store", "l510"], "B_title": "RDBBlobStore - fix problem when cleaning up data rows", "B_clean_title": ["rdbblobstor", "rdb", "blob", "store", "fix", "problem", "when", "clean", "up", "data", "row"]},
{"A_title": "StringEscapeUtils.escapeJava(String) escapes / charactersCommons Lang 2.4 StringEscapeUtils.escapeJava(String) now escapes / characters which is not a valid escapable character in Java strings.  I havent tried the other Java escape/unescape methods to see if they have a similar problem or that only Java escapable characters are escaped by escapeJava(String). This bug may have appeared as an unintended side-effect of the fix for LANG-363. Also the javadoc for escapeJava is now a little off in that / should now be included in the sentence describing the differences between Java and Javascript strings with respect to escaping rules. The following is a JUnit3 test demonstrating the bug. import junit.framework.TestCase; import org.apache.commons.lang.StringEscapeUtils; public class StringEscapeUtilsTest extends TestCase      public void testEscapeJavaWithSlash()           final String input = String with a slash (/) in it;                  final String expected = input;         final String actual   = StringEscapeUtils.escapeJava( input );          /**          * In 2.4 StringEscapeUtils.escapeJava(String) escapes / characters          * which are not a valid character to escape in a Java string.            */         assertEquals( expected actual );", "A_clean_title": ["stringescapeutil", "escapejava", "string", "escap", "util", "escap", "java", "string", "escap", "characterscommon", "charact", "common", "lang", "stringescapeutil", "escapejava", "string", "escap", "util", "escap", "java", "string", "now", "escap", "charact", "which", "not", "valid", "escap", "charact", "java", "string", "havent", "tri", "other", "java", "escap", "unescap", "method", "see", "they", "have", "similar", "problem", "or", "that", "onli", "java", "escap", "charact", "are", "escap", "by", "escapejava", "escap", "java", "string", "thi", "bug", "may", "have", "appear", "as", "unintend", "side", "effect", "fix", "lang", "363", "also", "javadoc", "escapejava", "escap", "java", "now", "littl", "off", "that", "now", "includ", "sentenc", "describ", "differ", "between", "java", "javascript", "string", "respect", "escap", "rule", "follow", "junit3", "unit3", "test", "demonstr", "bug", "import", "junit", "framework", "testcas", "test", "case", "import", "org", "apach", "common", "lang", "stringescapeutil", "string", "escap", "util", "public", "class", "stringescapeutilstest", "string", "escap", "util", "test", "extend", "testcas", "test", "case", "public", "void", "testescapejavawithslash", "test", "escap", "java", "slash", "final", "string", "input", "string", "slash", "it", "final", "string", "expect", "input", "final", "string", "actual", "stringescapeutil", "escapejava", "string", "escap", "util", "escap", "java", "input", "stringescapeutil", "escapejava", "string", "escap", "util", "escap", "java", "string", "escap", "charact", "which", "are", "not", "valid", "charact", "escap", "java", "string", "assertequ", "assert", "equal", "expect", "actual"], "B_title": "StringEscapeUtils.escapeJava(String) escapes / characters", "B_clean_title": ["stringescapeutil", "escapejava", "string", "escap", "util", "escap", "java", "string", "escap", "charact"]},
{"A_title": "NumberUtils.createNumber throws NumberFormatException for one digit longNumberUtils.createNumber throws a NumberFormatException when parsing 1l 2l .. etc... It works fine if you try to parse 01l or 02l.  The condition isDigits(numeric.substring(1)) line 455 return false as numeric.substring(1) is an empty string for 1l", "A_clean_title": ["numberutil", "createnumb", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "one", "digit", "longnumberutil", "createnumb", "long", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "when", "pars", "1l", "2l", "etc", "it", "work", "fine", "you", "tri", "pars", "01l", "or", "02l", "condit", "isdigit", "digit", "numer", "substr", "line", "455", "return", "fals", "as", "numer", "substr", "empti", "string", "1l"], "B_title": "Fixing LANG-300 (reported by Jeremy Lemaire) - 1L to 9L incorrectly throw exceptions when passed into NumberUtils.createNumber. Fixed in both the math.NumbersUtils and the deprecated NumberUtils classes.", "B_clean_title": ["fix", "lang", "300", "report", "by", "jeremi", "lemair", "1l", "9l", "incorrectli", "throw", "except", "when", "pass", "into", "numberutil", "createnumb", "number", "util", "creat", "number", "fix", "both", "math", "numbersutil", "number", "util", "deprec", "numberutil", "number", "util", "class"]},
{"A_title": "weight versus sigma in AbstractLeastSquaresIn AbstractLeastSquares residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS() these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation it should multiply the square of the residual even in the computation of the chi2.  Once corrected getRMS() can even reduce  public double getRMS()  return Math.sqrt(getChiSquare()/rows);", "A_clean_title": ["weight", "versu", "sigma", "abstractleastsquaresin", "abstract", "least", "squar", "abstractleastsquar", "abstract", "least", "squar", "residualsweight", "residu", "weight", "contain", "weight", "assign", "each", "observ", "method", "getrm", "get", "rm", "these", "weight", "are", "multipl", "as", "they", "unlik", "getchisquar", "get", "chi", "squar", "where", "it", "appear", "at", "denomin", "weight", "realli", "weight", "observ", "it", "multipli", "squar", "residu", "even", "comput", "chi2", "onc", "correct", "getrm", "get", "rm", "even", "reduc", "public", "doubl", "getrm", "get", "rm", "return", "math", "sqrt", "getchisquar", "get", "chi", "squar", "row"], "B_title": "fixed", "B_clean_title": ["fix"]},
{"A_title": "OnChangeAjaxBehavior attached to DropDownChoice produces two Ajax requests in Chrome v35I have a DropDownChoice with attached OnChangeAjaxBehavior like this: code:borderStyle=solid new DropDownChoice<>(dd new Model<>() Arrays.asList( First Second))     .add( new OnChangeAjaxBehavior()          @Override         protected void onUpdate(AjaxRequestTarget target)              System.out.println( update );          ); code  When selecting any of drop down options two Ajax requests being generated. It behaves OK in IE FF and Chrome v34 only Chrome v35 is affected", "A_clean_title": ["onchangeajaxbehavior", "chang", "ajax", "behavior", "attach", "dropdownchoic", "drop", "down", "choic", "produc", "two", "ajax", "request", "chrome", "v35i", "have", "dropdownchoic", "drop", "down", "choic", "attach", "onchangeajaxbehavior", "chang", "ajax", "behavior", "like", "thi", "code", "borderstyle=solid", "border", "style=solid", "new", "dropdownchoic", "drop", "down", "choic", "dd", "new", "model", "array", "aslist", "as", "list", "first", "second", "add", "new", "onchangeajaxbehavior", "chang", "ajax", "behavior", "overrid", "protect", "void", "onupd", "updat", "ajaxrequesttarget", "ajax", "request", "target", "target", "system", "out", "println", "updat", "code", "when", "select", "ani", "drop", "down", "option", "two", "ajax", "request", "be", "gener", "it", "behav", "ok", "ie", "ff", "chrome", "v34", "onli", "chrome", "v35", "affect"], "B_title": "OnChangeAjaxBehavior attached to DropDownChoice produces two Ajax requests in the last versions of Chrome Opera and IE", "B_clean_title": ["onchangeajaxbehavior", "chang", "ajax", "behavior", "attach", "dropdownchoic", "drop", "down", "choic", "produc", "two", "ajax", "request", "last", "version", "chrome", "opera", "ie"]},
{"A_title": "MathUtils.binomialCoefficient(nk) fails for large resultsProbably due to rounding errors MathUtils.binomialCoefficient(nk) fails for results near Long.MAX_VALUE. The existence of failures can be demonstrated by testing the recursive property:           assertEquals(MathUtils.binomialCoefficient(6532) + MathUtils.binomialCoefficient(6533)                  MathUtils.binomialCoefficient(6633));   Or by directly using the (externally calculated and hopefully correct) expected value:           assertEquals(7219428434016265740L MathUtils.binomialCoefficient(6633));   I suggest a nonrecursive test implementation along the lines of MathUtilsTest.java     /**      * Exact implementation using BigInteger and the explicit formula      * (n k) == ((k-1)*...*n) / (1*...*(n-k))      */ public static long binomialCoefficient(int n int k)  if (k == 0 || k == n) return 1; BigInteger result = BigInteger.ONE; for (int i = k + 1; i <= n; i++)  result = result.multiply(BigInteger.valueOf(i));  for (int i = 1; i <= n - k; i++)  result = result.divide(BigInteger.valueOf(i));  if (result.compareTo(BigInteger.valueOf(Long.MAX_VALUE)) > 0)  throw new ArithmeticException(                                 Binomial coefficient overflow:  + n +   + k);  return result.longValue();    Which would allow you to test the expected values directly:           assertEquals(binomialCoefficient(6633) MathUtils.binomialCoefficient(6633));", "A_clean_title": ["mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "nk", "fail", "larg", "resultsprob", "result", "probabl", "due", "round", "error", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "nk", "fail", "result", "near", "long", "max", "valu", "exist", "failur", "demonstr", "by", "test", "recurs", "properti", "assertequ", "assert", "equal", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "6532", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "6533", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "6633", "or", "by", "directli", "extern", "calcul", "hope", "correct", "expect", "valu", "assertequ", "assert", "equal", "7219428434016265740l", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "6633", "suggest", "nonrecurs", "test", "implement", "along", "line", "mathutilstest", "java", "math", "util", "test", "exact", "implement", "biginteg", "big", "integ", "explicit", "formula", "public", "static", "long", "binomialcoeffici", "binomi", "coeffici", "int", "int", "return", "biginteg", "big", "integ", "result", "biginteg", "one", "big", "integ", "int", "i++", "result", "result", "multipli", "biginteg", "valueof", "big", "integ", "valu", "int", "i++", "result", "result", "divid", "biginteg", "valueof", "big", "integ", "valu", "result", "compareto", "compar", "biginteg", "valueof", "big", "integ", "valu", "long", "max", "valu", "throw", "new", "arithmeticexcept", "arithmet", "except", "binomi", "coeffici", "overflow", "return", "result", "longvalu", "long", "valu", "which", "would", "allow", "you", "test", "expect", "valu", "directli", "assertequ", "assert", "equal", "binomialcoeffici", "binomi", "coeffici", "6633", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "6633"], "B_title": "Fixed error in binomial coefficient computation JIRA: MATH-241 Reported and patched by Christian Semrau", "B_clean_title": ["fix", "error", "binomi", "coeffici", "comput", "jira", "math", "241", "report", "patch", "by", "christian", "semrau"]},
{"A_title": "StringEscapeUtils.escapeHtml incorrectly converts unicode characters above U+00FFFF into 2 charactersCharacters that are represented as a 2 characters internaly by java are incorrectly converted by the function. The following test displays the problem quite nicely: import org.apache.commons.lang.*; public class J2      public static void main(String args) throws Exception          // this is the utf8 representation of the character:         // COUNTING ROD UNIT DIGIT THREE         // in unicode         // codepoint: U+1D362         byte data = new byte   (byte)0xF0 (byte)0x9D (byte)0x8D (byte)0xA2  ;         //output is: &#55348;&#57186;         // should be: &#119650;         System.out.println( + StringEscapeUtils.escapeHtml(new String(data UTF8)) + );       Should be very quick to fix feel free to drop me an email if you want a patch.", "A_clean_title": ["stringescapeutil", "escapehtml", "string", "escap", "util", "escap", "html", "incorrectli", "convert", "unicod", "charact", "abov", "u+00ffff", "into", "characterscharact", "charact", "charact", "that", "are", "repres", "as", "charact", "internali", "by", "java", "are", "incorrectli", "convert", "by", "function", "follow", "test", "display", "problem", "quit", "nice", "import", "org", "apach", "common", "lang", "public", "class", "j2", "public", "static", "void", "main", "string", "arg", "throw", "except", "thi", "utf8", "represent", "charact", "count", "rod", "unit", "digit", "three", "unicod", "codepoint", "u+1d362", "byte", "data", "new", "byte", "byte", "0xf0", "0x", "f0", "byte", "0x9d", "byte", "0x8d", "byte", "0xa2", "0x", "a2", "output", "55348", "57186", "119650", "system", "out", "println", "stringescapeutil", "escapehtml", "string", "escap", "util", "escap", "html", "new", "string", "data", "utf8", "veri", "quick", "fix", "feel", "free", "drop", "me", "email", "you", "want", "patch"], "B_title": "Applying Alexander Kjalls patch from LANG-480; along with a unit test made from his example. Fixes unicode conversion above U+00FFFF being done into 2 characters", "B_clean_title": ["appli", "alexand", "kjall", "patch", "lang", "480", "along", "unit", "test", "made", "hi", "exampl", "fix", "unicod", "convers", "abov", "u+00ffff", "be", "done", "into", "charact"]},
{"A_title": "multiple <style> tags in header are rendered incorrectlyI created a small quickstart.  The BasePage has some multiple <style> tags. Only he first one is rendered correctly all following render the tag body only the surrounding <style></style> is missing.", "A_clean_title": ["multipl", "style", "tag", "header", "are", "render", "incorrectlyi", "incorrectli", "creat", "small", "quickstart", "basepag", "base", "page", "ha", "some", "multipl", "style", "tag", "onli", "he", "first", "one", "render", "correctli", "all", "follow", "render", "tag", "bodi", "onli", "surround", "style", "style", "miss"], "B_title": "render PageHeaderItems all at once", "B_clean_title": ["render", "pageheaderitem", "page", "header", "item", "all", "at", "onc"]},
{"A_title": "FLAG_INHERITABLE_MODEL and default model changeThe issue is about correctness of Component#setDefaultModel (Component#setModelImpl) method behavior. I expect that the flag FLAG_INHERITABLE_MODEL should be checked there and turned off in case if new model is not a IComponentInheritedModel.   Let check the next code: public MyPanel(String id)   super(id);   ...   form.setModel(new CompoundPropertyModel(this));   DropDownChoice ddc = new DropDownChoice(variant Arrays.ofList(...))     // p1     @Override     protected void onInitialize()         super.onInitialize();        setModel(new DefaultingWrapModel(getModel() Model.of(default value));            // p2        ;   ddc.setNullValid(false);   ddc.setRequired(true);   form.add(ddc);   ...   In the (p1) the DDC will initialize with CompoundPropertyModel and the FLAG_INHERITABLE_MODEL will be turned on soon by the first invocation of FormComponent#getModel().   In the (p2) we wrap the DDC model with the model which provide the default value (DefaultingWrapModel implements IWrapModel). So we change the model but the FLAG_INHERITABLE_MODEL is still turned on. On the Component#detach() event the method Component#setModelImpl(null) will be invoked for the ddc and the DefaultingWrapModel instance will be lost:  // reset the model to null when the current model is a IWrapModel and // the model that created it/wrapped in it is a IComponentInheritedModel // The model will be created next time. if (getFlag(FLAG_INHERITABLE_MODEL))  setModelImpl(null); setFlag(FLAG_INHERITABLE_MODEL false);   I think that such behavior is unexpected.  http://apache-wicket.1842946.n4.nabble.com/1-4-15-FLAG-INHERITABLE-MODEL-and-default-model-change-td3252093.html", "A_clean_title": ["flag", "inherit", "model", "default", "model", "changeth", "chang", "issu", "about", "correct", "compon", "setdefaultmodel", "set", "default", "model", "compon", "setmodelimpl", "set", "model", "impl", "method", "behavior", "expect", "that", "flag", "flag", "inherit", "model", "check", "there", "turn", "off", "case", "new", "model", "not", "icomponentinheritedmodel", "compon", "inherit", "model", "let", "check", "next", "code", "public", "mypanel", "my", "panel", "string", "id", "super", "id", "form", "setmodel", "set", "model", "new", "compoundpropertymodel", "compound", "properti", "model", "thi", "dropdownchoic", "drop", "down", "choic", "ddc", "new", "dropdownchoic", "drop", "down", "choic", "variant", "array", "oflist", "list", "p1", "overrid", "protect", "void", "oniniti", "initi", "super", "oniniti", "initi", "setmodel", "set", "model", "new", "defaultingwrapmodel", "default", "wrap", "model", "getmodel", "get", "model", "model", "default", "valu", "p2", "ddc", "setnullvalid", "set", "null", "valid", "fals", "ddc", "setrequir", "set", "requir", "true", "form", "add", "ddc", "p1", "ddc", "will", "initi", "compoundpropertymodel", "compound", "properti", "model", "flag", "inherit", "model", "will", "turn", "soon", "by", "first", "invoc", "formcompon", "form", "compon", "getmodel", "get", "model", "p2", "we", "wrap", "ddc", "model", "model", "which", "provid", "default", "valu", "defaultingwrapmodel", "default", "wrap", "model", "implement", "iwrapmodel", "wrap", "model", "so", "we", "chang", "model", "but", "flag", "inherit", "model", "still", "turn", "compon", "detach", "event", "method", "compon", "setmodelimpl", "set", "model", "impl", "null", "will", "invok", "ddc", "defaultingwrapmodel", "default", "wrap", "model", "instanc", "will", "lost", "reset", "model", "null", "when", "current", "model", "iwrapmodel", "wrap", "model", "model", "that", "creat", "it", "wrap", "it", "icomponentinheritedmodel", "compon", "inherit", "model", "model", "will", "creat", "next", "time", "getflag", "get", "flag", "flag", "inherit", "model", "setmodelimpl", "set", "model", "impl", "null", "setflag", "set", "flag", "flag", "inherit", "model", "fals", "think", "that", "such", "behavior", "unexpect", "http", "15", "flag", "inherit", "model", "default", "model", "chang", "apach", "wicket", "1842946", "n4", "nabbl", "td3252093", "html", "com"], "B_title": "FLAG_INHERITABLE_MODEL and default model change", "B_clean_title": ["flag", "inherit", "model", "default", "model", "chang"]},
{"A_title": "Partial.with fails with NPEFails with yearOfCentury year and yearOfEra. Probably because weekyear has a null range duration type.", "A_clean_title": ["partial", "fail", "npefail", "npe", "fail", "yearofcenturi", "year", "centuri", "year", "yearofera", "year", "era", "probabl", "becaus", "weekyear", "ha", "null", "rang", "durat", "type"], "B_title": "Fix NPE in Partial.with()", "B_clean_title": ["fix", "npe", "partial"]},
{"A_title": "GJChronology rejects valid Julian datesThe 2nd statement fails with org.joda.time.IllegalFieldValueException: Value 29 for dayOfMonth must be in the range 128.  Given that I left the cutover date at the default (October 15 1582) isnt 1500/02/29 a valid date in the GJChronology?", "A_clean_title": ["gjchronolog", "gj", "chronolog", "reject", "valid", "julian", "datesth", "date", "2nd", "statement", "fail", "org", "joda", "time", "illegalfieldvalueexcept", "illeg", "field", "valu", "except", "valu", "29", "dayofmonth", "day", "month", "must", "rang", "128", "given", "that", "left", "cutov", "date", "at", "default", "octob", "15", "1582", "isnt", "1500", "02", "29", "valid", "date", "gjchronolog", "gj", "chronolog"], "B_title": "Fix GJChronology to allow some leap year dates in JulianChronology to be created 3446915", "B_clean_title": ["fix", "gjchronolog", "gj", "chronolog", "allow", "some", "leap", "year", "date", "julianchronolog", "julian", "chronolog", "creat", "3446915"]},
{"A_title": "Allow KeySelectors to implement ResultTypeQueryableSee https://github.com/apache/flink/pull/354", "A_clean_title": ["allow", "keyselector", "key", "selector", "implement", "resulttypequeryablese", "result", "type", "queryabl", "see", "http", "github", "com", "apach", "flink", "pull", "354"], "B_title": "Fixes wrong input validation if function has no generics", "B_clean_title": ["fix", "wrong", "input", "valid", "function", "ha", "no", "gener"]},
{"A_title": "Node becomes invalid after Session#move()moving or renaming an existing (saved) node renders that node instance invalid and any access on that node instance will throw IllegalStateException.", "A_clean_title": ["node", "becom", "invalid", "after", "session", "move", "move", "or", "renam", "exist", "save", "node", "render", "that", "node", "instanc", "invalid", "ani", "access", "that", "node", "instanc", "will", "throw", "illegalstateexcept", "illeg", "state", "except"], "B_title": "Node becomes invalid after Session#move() throw invalid item state exception on disconnected nodes", "B_clean_title": ["node", "becom", "invalid", "after", "session", "move", "throw", "invalid", "item", "state", "except", "disconnect", "node"]},
{"A_title": "void function () (); wrongly identified as having no side effectsNone", "A_clean_title": ["void", "function", "wrongli", "identifi", "as", "have", "no", "side", "effectsnon", "effect", "none"], "B_title": "fix a mishandling of the void keyword also fix a bunch of apis fixes issue 504", "B_clean_title": ["fix", "mishandl", "void", "keyword", "also", "fix", "bunch", "api", "fix", "issu", "504"]},
{"A_title": "assignment to object in conditional causes type error on function w/ record type return typeNone", "A_clean_title": ["assign", "object", "condit", "caus", "type", "error", "function", "record", "type", "return", "typenon", "type", "none"], "B_title": "push reverse-inference into the type system fixes issue 669", "B_clean_title": ["push", "revers", "infer", "into", "type", "system", "fix", "issu", "669"]},
{"A_title": "Handling of semicolons in form action URLsWhat I expect to happen when there is no semicolon support in Wicket is that a URL in a form like below stays intact and will not be cut off at the position of the first semicolon:  <form action=http://localhost:8080/dor/abc_1234:56;023:456_def_78;90.html method=post><input type=submit value=Submit /></form>  In my application the part abc_1234:56;023:456_def_78;90.html is named1 in the mapping below:  mount(new MountedMapper(dor/#named1 TestPage.class new MyPageParametersEncoder()));  and parsed in MyPageParametersEncoder.  The officially intended use of semicolons in URLs seems to be specified in RFC 1808 - Relative Uniform Resource Locators 2.4.5. (http://www.faqs.org/rfcs/rfc1808.html). But that´s not what I´m looking for.  If I had not some pages running on this syntax I could easily swap the semicolon with another symbol. Nevertheless and if I´m correctly informed I think those URLs should not be cut off.  (Quotation from the mailing list)  The quickstart can be tested with the following URLs:  http://localhost:8080/dor/abc_1234:56;023:456_def_78;90.html http://localhost:8080/dor/abc_1234:56%3B023:456_def_78%3B90.html http://localhost:8080/dor/?abc=1234:56%3B023:456&def=78%3B90  The crucial part is the action attribute in the form in the page´s source code which contains i.e. ./abc_1234:56?-1.IFormSubmitListener-form.", "A_clean_title": ["handl", "semicolon", "form", "action", "urlswhat", "ur", "ls", "what", "expect", "happen", "when", "there", "no", "semicolon", "support", "wicket", "that", "url", "form", "like", "below", "stay", "intact", "will", "not", "cut", "off", "at", "posit", "first", "semicolon", "form", "action=http", "1234:56", "localhost:8080", "dor", "abc", "023:456", "def", "78", "90", "html", "method=post", "input", "type=submit", "value=submit", "form", "my", "applic", "part", "abc", "1234:56", "023:456", "def", "78", "90", "html", "named1", "map", "below", "mount", "new", "mountedmapp", "mount", "mapper", "dor", "named1", "testpag", "class", "test", "page", "new", "mypageparametersencod", "my", "page", "paramet", "encod", "pars", "mypageparametersencod", "my", "page", "paramet", "encod", "offici", "intend", "use", "semicolon", "url", "ur", "ls", "seem", "specifi", "rfc", "1808", "rel", "uniform", "resourc", "locat", "http", "faq", "html", "www", "org", "rfc", "rfc1808", "but", "that´", "not", "what", "i´m", "look", "had", "not", "some", "page", "run", "thi", "syntax", "could", "easili", "swap", "semicolon", "anoth", "symbol", "nevertheless", "i´m", "correctli", "inform", "think", "those", "url", "ur", "ls", "not", "cut", "off", "quotat", "mail", "list", "quickstart", "test", "follow", "url", "ur", "ls", "http", "1234:56", "localhost:8080", "dor", "abc", "023:456", "def", "78", "90", "html", "http", "1234:56", "localhost:8080", "dor", "abc", "3b023:456", "def", "78", "3b90", "html", "http", "localhost:8080", "dor", "abc=1234:56", "3b023:456", "def=78", "3b90", "crucial", "part", "action", "attribut", "form", "page´", "sourc", "code", "which", "contain", "1234:56", "abc", "form", "iformsubmitlisten", "form", "submit", "listen"], "B_title": "Handling of semicolons in form action URLs", "B_clean_title": ["handl", "semicolon", "form", "action", "url", "ur", "ls"]},
{"A_title": "Dequeueing problem when there is TransparentWebMarkupContainer around <wicket:child/>While testing 7.0.0-M1 release Ive found an issue with wicket-bootstraps sample application.  Here is a minified version of it that reproduces the problem. The two important things are: - a TransparentWebMarkupContainer (TWMC) is attached to <html> tag in the base page - the sub page is requested  It appears that dequeueing logic cannot find the closing tag of the TWMC and thinks that </wicket:child> is the closing tag.", "A_clean_title": ["dequeu", "problem", "when", "there", "transparentwebmarkupcontain", "transpar", "web", "markup", "contain", "around", "wicket", "child", "while", "test", "m1", "releas", "ive", "found", "issu", "wicket", "bootstrap", "sampl", "applic", "here", "minifi", "version", "it", "that", "reproduc", "problem", "two", "import", "thing", "are", "transparentwebmarkupcontain", "transpar", "web", "markup", "contain", "twmc", "attach", "html", "tag", "base", "page", "sub", "page", "request", "it", "appear", "that", "dequeu", "logic", "not", "find", "close", "tag", "twmc", "think", "that", "wicket", "child", "close", "tag"], "B_title": "Dequeueing problem when there is TransparentWebMarkupContainer around <wicket:child/>", "B_clean_title": ["dequeu", "problem", "when", "there", "transparentwebmarkupcontain", "transpar", "web", "markup", "contain", "around", "wicket", "child"]},
{"A_title": "FileInputFormat.addFilesInDir miscalculates total sizeIn FileInputFormat.addFilesInDir the length variable should start from 0 because the return value is always used by adding it to the length (instead of just assigning). So with the current version the length before the call will be seen twice in the result.  mvn verify caught this for me now. The reason why this hasnt been seen yet is because testGetStatisticsMultipleNestedFiles catches this only if it gets the listings of the outer directory in a certain order. Concretely if the inner directory is seen before the other file in the outer directory then length is 0 at that point so the bug doesnt show. But if the other file is seen first then its size is added twice to the total result.", "A_clean_title": ["fileinputformat", "addfilesindir", "file", "input", "format", "add", "file", "dir", "miscalcul", "total", "sizein", "size", "fileinputformat", "addfilesindir", "file", "input", "format", "add", "file", "dir", "length", "variabl", "start", "becaus", "return", "valu", "alway", "use", "by", "ad", "it", "length", "instead", "just", "assign", "so", "current", "version", "length", "befor", "call", "will", "seen", "twice", "result", "mvn", "verifi", "caught", "thi", "me", "now", "reason", "whi", "thi", "hasnt", "been", "seen", "yet", "becaus", "testgetstatisticsmultiplenestedfil", "test", "get", "statist", "multipl", "nest", "file", "catch", "thi", "onli", "it", "get", "list", "outer", "directori", "certain", "order", "concret", "inner", "directori", "seen", "befor", "other", "file", "outer", "directori", "then", "length", "at", "that", "point", "so", "bug", "doesnt", "show", "but", "other", "file", "seen", "first", "then", "it", "size", "ad", "twice", "total", "result"], "B_title": "Fix the recursive summation in FileInputFormat.addFilesInDir", "B_clean_title": ["fix", "recurs", "summat", "fileinputformat", "addfilesindir", "file", "input", "format", "add", "file", "dir"]},
{"A_title": "In stat.Frequency getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable)Drop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change Frequency.java    /**  Returns the percentage of values that are equal to v @deprecated replaced by  @link #getPct(Comparable)  as of 2.0      */     @Deprecated     public double getPct(Object v)           return getCumPct((Comparable<?>) v);", "A_clean_title": ["stat", "frequenc", "getpct", "get", "pct", "object", "use", "getcumpct", "get", "cum", "pct", "compar", "instead", "getpct", "get", "pct", "compar", "drop", "replac", "not", "possibl", "becaus", "all", "getpct", "get", "pct", "call", "will", "cummul", "without", "code", "chang", "frequenc", "java", "return", "percentag", "valu", "that", "are", "equal", "deprec", "replac", "by", "link", "getpct", "get", "pct", "compar", "as", "deprec", "public", "doubl", "getpct", "get", "pct", "object", "return", "getcumpct", "get", "cum", "pct", "compar"], "B_title": "Fixed regression in Frequency.getPct(Object) introduced in 2.0. Cumulative percent was being returned for Object arguments in place of percent.", "B_clean_title": ["fix", "regress", "frequenc", "getpct", "get", "pct", "object", "introduc", "cumul", "percent", "wa", "be", "return", "object", "argument", "place", "percent"]},
{"A_title": "Infinite recursion when deserializing a class extending a Map with a recursive value type.Hello I am using jackson-databind 2.8.8 and have a class with an unusual definition (extending a Map where the values are of the type of the same class). It seems like I am facing an infinite recursion issue.  To reproduce you can re-use or inspire from the class defined  here . Then when executing the following code:    When calling  readValue() the mapper throws a StackOverflowException  heres the stacktrace:  Looking briefly into the code it seems like because of the recursive definition of the class the  equals call in MapLikeType may never get out of this loop. Any idea? Thanks.", "A_clean_title": ["infinit", "recurs", "when", "deseri", "class", "extend", "map", "recurs", "valu", "type", "hello", "am", "jackson", "databind", "have", "class", "unusu", "definit", "extend", "map", "where", "valu", "are", "type", "same", "class", "it", "seem", "like", "am", "face", "infinit", "recurs", "issu", "reproduc", "you", "re", "use", "or", "inspir", "class", "defin", "here", "then", "when", "execut", "follow", "code", "when", "call", "readvalu", "read", "valu", "mapper", "throw", "stackoverflowexcept", "stack", "overflow", "except", "here", "stacktrac", "look", "briefli", "into", "code", "it", "seem", "like", "becaus", "recurs", "definit", "class", "equal", "call", "mapliketyp", "map", "like", "type", "may", "never", "get", "out", "thi", "loop", "ani", "idea", "thank"], "B_title": "Fix #1658", "B_clean_title": ["fix", "1658"]},
{"A_title": "EmptyNodeState.equals() brokenEmptyNodeState.equals() returns incorrect results when the other node state is not of type EmptyNodeState and the two states have differing exists() flags.", "A_clean_title": ["emptynodest", "equal", "empti", "node", "state", "brokenemptynodest", "equal", "broken", "empti", "node", "state", "return", "incorrect", "result", "when", "other", "node", "state", "not", "type", "emptynodest", "empti", "node", "state", "two", "state", "have", "differ", "exist", "flag"], "B_title": "EmptyNodeState.equals() broken", "B_clean_title": ["emptynodest", "equal", "empti", "node", "state", "broken"]},
{"A_title": "WicketTester does not follow absolute redirectsWicket tester does not follow absolute redirects:  This is a problem when using HttpsMapper. For example when requesting a page over http:// with an forced redirect to https:// for secure access will make wicket tester return null for the last renderer page instead of the rendered page instance. In general all kinds of absolute redirects to another page will not be tracked by wicket tester. So this potentially a problem for all kinds of tests that rely on absolute redirects.", "A_clean_title": ["wickettest", "wicket", "tester", "not", "follow", "absolut", "redirectswicket", "redirect", "wicket", "tester", "not", "follow", "absolut", "redirect", "thi", "problem", "when", "httpsmapper", "http", "mapper", "exampl", "when", "request", "page", "over", "http", "forc", "redirect", "http", "secur", "access", "will", "make", "wicket", "tester", "return", "null", "last", "render", "page", "instead", "render", "page", "instanc", "gener", "all", "kind", "absolut", "redirect", "anoth", "page", "will", "not", "track", "by", "wicket", "tester", "so", "thi", "potenti", "problem", "all", "kind", "test", "that", "reli", "absolut", "redirect"], "B_title": "WicketTester does not follow absolute redirects: make Url.parse(..) capable of parsing absolute urls", "B_clean_title": ["wickettest", "wicket", "tester", "not", "follow", "absolut", "redirect", "make", "url", "pars", "capabl", "pars", "absolut", "url"]},
{"A_title": "Questionable behaviour of GJChronology when dates pass 1BCI expect the following test to pass:  However I never provided 0 for the year myself. I thought it was the job of the framework to skip over non-existent year 0 for me to return 1 BC?", "A_clean_title": ["question", "behaviour", "gjchronolog", "gj", "chronolog", "when", "date", "pass", "1bci", "expect", "follow", "test", "pass", "howev", "never", "provid", "year", "myself", "thought", "it", "wa", "job", "framework", "skip", "over", "non", "exist", "year", "me", "return", "bc"], "B_title": "Fix GJChronology.plus/minus across cutover and year zero", "B_clean_title": ["fix", "gjchronolog", "gj", "chronolog", "plu", "minu", "across", "cutov", "year", "zero"]},
{"A_title": "FastDateFormat formats year differently than SimpleDateFormat in Java 7Starting with Java 7 does SimpleDateFormat format a year pattern of Y or YYY as 2003 instead of 03 as in former Java releases. According Javadoc this pattern should have been always been formatted as number therefore the new behavior seems to be a bug fix in the JDK. FastDateFormat is adjusted to behave the same.", "A_clean_title": ["fastdateformat", "fast", "date", "format", "format", "year", "differ", "than", "simpledateformat", "simpl", "date", "format", "java", "7start", "java", "simpledateformat", "simpl", "date", "format", "format", "year", "pattern", "or", "yyy", "as", "2003", "instead", "03", "as", "former", "java", "releas", "accord", "javadoc", "thi", "pattern", "have", "been", "alway", "been", "format", "as", "number", "therefor", "new", "behavior", "seem", "bug", "fix", "jdk", "fastdateformat", "fast", "date", "format", "adjust", "behav", "same"], "B_title": "Adjust FastDateFormat for Java 7 behavior regarding format of the year pattern (LANG-719).", "B_clean_title": ["adjust", "fastdateformat", "fast", "date", "format", "java", "behavior", "regard", "format", "year", "pattern", "lang", "719"]},
{"A_title": "ClassCastException when requesting for non-page classorg.apache.wicket.request.mapper.BookmarkableMapper tries to instantiate Page even for classes which are not Page. Requesting http://localhost:8080/wicket/bookmarkable/com.mycompany.Pojo fails with:  ERROR - DefaultExceptionMapper     - Unexpected error occurred java.lang.ClassCastException: com.mycompany.Pojo at org.apache.wicket.session.DefaultPageFactory.newPage(DefaultPageFactory.java:155) at org.apache.wicket.session.DefaultPageFactory.newPage(DefaultPageFactory.java:59) at org.apache.wicket.session.DefaultPageFactory.newPage(DefaultPageFactory.java:43) at org.apache.wicket.Application 2.newPageInstance(Application.java:1425) at org.apache.wicket.request.handler.PageProvider.getPageInstance(PageProvider.java:259) at org.apache.wicket.request.handler.PageProvider.getPageInstance(PageProvider.java:160) at org.apache.wicket.request.handler.render.WebPageRenderer.getPage(WebPageRenderer.java:59) at org.apache.wicket.request.handler.render.WebPageRenderer.renderPage(WebPageRenderer.java:131) at org.apache.wicket.request.handler.render.WebPageRenderer.respond(WebPageRenderer.java:232) at org.apache.wicket.request.handler.RenderPageRequestHandler.respond(RenderPageRequestHandler.java:147) at org.apache.wicket.request.RequestHandlerStack.executeRequestHandler(RequestHandlerStack.java:84) at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:217) at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:253) at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:135) at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:188) at org.mortbay.jetty.servlet.ServletHandler CachedChain.doFilter(ServletHandler.java:1157)          .....", "A_clean_title": ["classcastexcept", "class", "cast", "except", "when", "request", "non", "page", "classorg", "apach", "wicket", "request", "mapper", "bookmarkablemapp", "bookmark", "mapper", "tri", "instanti", "page", "even", "class", "which", "are", "not", "page", "request", "http", "mycompani", "pojo", "localhost:8080", "wicket", "bookmark", "com", "fail", "error", "defaultexceptionmapp", "default", "except", "mapper", "unexpect", "error", "occur", "java", "lang", "classcastexcept", "class", "cast", "except", "com", "mycompani", "pojo", "at", "org", "apach", "wicket", "session", "defaultpagefactori", "newpag", "default", "page", "factori", "new", "page", "defaultpagefactori", "java:155", "default", "page", "factori", "at", "org", "apach", "wicket", "session", "defaultpagefactori", "newpag", "default", "page", "factori", "new", "page", "defaultpagefactori", "java:59", "default", "page", "factori", "at", "org", "apach", "wicket", "session", "defaultpagefactori", "newpag", "default", "page", "factori", "new", "page", "defaultpagefactori", "java:43", "default", "page", "factori", "at", "org", "apach", "wicket", "applic", "newpageinst", "new", "page", "instanc", "applic", "java:1425", "at", "org", "apach", "wicket", "request", "handler", "pageprovid", "getpageinst", "page", "provid", "get", "page", "instanc", "pageprovid", "java:259", "page", "provid", "at", "org", "apach", "wicket", "request", "handler", "pageprovid", "getpageinst", "page", "provid", "get", "page", "instanc", "pageprovid", "java:160", "page", "provid", "at", "org", "apach", "wicket", "request", "handler", "render", "webpagerender", "getpag", "web", "page", "render", "get", "page", "webpagerender", "java:59", "web", "page", "render", "at", "org", "apach", "wicket", "request", "handler", "render", "webpagerender", "renderpag", "web", "page", "render", "render", "page", "webpagerender", "java:131", "web", "page", "render", "at", "org", "apach", "wicket", "request", "handler", "render", "webpagerender", "respond", "web", "page", "render", "webpagerender", "java:232", "web", "page", "render", "at", "org", "apach", "wicket", "request", "handler", "renderpagerequesthandl", "respond", "render", "page", "request", "handler", "renderpagerequesthandl", "java:147", "render", "page", "request", "handler", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "executerequesthandl", "request", "handler", "stack", "execut", "request", "handler", "requesthandlerstack", "java:84", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:217", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:253", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:135", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:188", "wicket", "filter", "at", "org", "mortbay", "jetti", "servlet", "servlethandl", "servlet", "handler", "cachedchain", "dofilt", "cach", "chain", "filter", "servlethandl", "java:1157", "servlet", "handler"], "B_title": "ClassCastException when requesting for non-page class", "B_clean_title": ["classcastexcept", "class", "cast", "except", "when", "request", "non", "page", "class"]},
{"A_title": "Make sure iterators handle deletion entries properlyIn minor compaction scope and in non-full major compaction scopes the iterator may see deletion entries. These entries should be preserved by all iterators except ones that are strictly scan-time iterators that will never be configured for the minc or majc scopes. Deletion entries are only removed during full major compactions.", "A_clean_title": ["make", "sure", "iter", "handl", "delet", "entri", "properlyin", "properli", "minor", "compact", "scope", "non", "full", "major", "compact", "scope", "iter", "may", "see", "delet", "entri", "these", "entri", "preserv", "by", "all", "iter", "except", "one", "that", "are", "strictli", "scan", "time", "iter", "that", "will", "never", "configur", "minc", "or", "majc", "scope", "delet", "entri", "are", "onli", "remov", "dure", "full", "major", "compact"], "B_title": "expanded javadocs and added deletion handling to Filter", "B_clean_title": ["expand", "javadoc", "ad", "delet", "handl", "filter"]},
{"A_title": "StatUtils.sum returns NaN for zero-length arraysStatUtils.sum returns NaN for zero-length arrays which is:  1. inconsistent with the mathematical notion of sum: in maths sum_i=0^N-1 a_i will be 0 for N=0. In particular the identity  sum_i=0^k-1 a_i + sum_i=k^N-1 = sum_i=0^N-1  is broken for k = 0 since NaN + x = NaN not x.  2. introduces hard to debug erros (returning a NaN is one of the worst forms of reporting an exceptional condition as NaNs propagate silently and require manual tracing during the debugging)  3. enforces special case handling when the user expects that the summed array can have a zero length.  The correct behaviour is in my opinion to return 0.0 not NaN in the above case.", "A_clean_title": ["statutil", "sum", "stat", "util", "return", "nan", "na", "zero", "length", "arraysstatutil", "sum", "array", "stat", "util", "return", "nan", "na", "zero", "length", "array", "which", "inconsist", "mathemat", "notion", "sum", "math", "sum", "i=0^n", "will", "n=0", "particular", "ident", "sum", "i=0^k", "sum", "i=k^n", "sum", "i=0^n", "broken", "sinc", "nan", "na", "nan", "na", "not", "introduc", "hard", "debug", "erro", "return", "nan", "na", "one", "worst", "form", "report", "except", "condit", "as", "nan", "na", "ns", "propag", "silent", "requir", "manual", "trace", "dure", "debug", "enforc", "special", "case", "handl", "when", "user", "expect", "that", "sum", "array", "have", "zero", "length", "correct", "behaviour", "my", "opinion", "return", "not", "nan", "na", "abov", "case"], "B_title": "Change the default value for those UnivariateStatistics that have a conventional value on the empty set. JIRA: MATH-373", "B_clean_title": ["chang", "default", "valu", "those", "univariatestatist", "univari", "statist", "that", "have", "convent", "valu", "empti", "set", "jira", "math", "373"]},
{"A_title": "Inconsistency in Node#setProperty in case of null valueSetting a null value to a single valued property will result in null being returned while executing the same on a multivalued property will return the removed property.  jr2 returned the removed property in both cases as far as i  remember and i would suggest that we dont change that behavior. in particular since the specification IMO doesnt allow to return null-values for these methods.", "A_clean_title": ["inconsist", "node", "setproperti", "set", "properti", "case", "null", "valueset", "valu", "set", "null", "valu", "singl", "valu", "properti", "will", "result", "null", "be", "return", "while", "execut", "same", "multivalu", "properti", "will", "return", "remov", "properti", "jr2", "return", "remov", "properti", "both", "case", "as", "far", "as", "rememb", "would", "suggest", "that", "we", "dont", "chang", "that", "behavior", "particular", "sinc", "specif", "imo", "doesnt", "allow", "return", "null", "valu", "these", "method"], "B_title": "Inconsistency in Node#setProperty in case of null value - return a Property instance at the location where the property was removed - updated tests in CRUDTest accordingly", "B_clean_title": ["inconsist", "node", "setproperti", "set", "properti", "case", "null", "valu", "return", "properti", "instanc", "at", "locat", "where", "properti", "wa", "remov", "updat", "test", "crudtest", "crud", "test", "accordingli"]},
{"A_title": "Constructor of PolyhedronsSet throws NullPointerExceptionThe following statement throws a NullPointerException: new org.apache.commons.math3.geometry.euclidean.threed.PolyhedronsSet(0.0d 0.0d 0.0d 0.0d 0.0d 0.0d);  I found that other numbers also produce that effect. The stack trace: java.lang.NullPointerException         at org.apache.commons.math3.geometry.partitioning.BSPTree.fitToCell(BSPTree.java:297)         at org.apache.commons.math3.geometry.partitioning.BSPTree.insertCut(BSPTree.java:155)         at org.apache.commons.math3.geometry.partitioning.RegionFactory.buildConvex(RegionFactory.java:55)         at org.apache.commons.math3.geometry.euclidean.threed.PolyhedronsSet.buildBoundary(PolyhedronsSet.java:119)         at org.apache.commons.math3.geometry.euclidean.threed.PolyhedronsSet.<init>(PolyhedronsSet.java:97)", "A_clean_title": ["constructor", "polyhedronsset", "polyhedron", "set", "throw", "nullpointerexceptionth", "null", "pointer", "except", "follow", "statement", "throw", "nullpointerexcept", "null", "pointer", "except", "new", "org", "apach", "common", "math3", "geometri", "euclidean", "threed", "polyhedronsset", "polyhedron", "set", "0d", "0d", "0d", "0d", "0d", "0d", "found", "that", "other", "number", "also", "produc", "that", "effect", "stack", "trace", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "common", "math3", "geometri", "partit", "bsptree", "fittocel", "bsp", "tree", "fit", "cell", "bsptree", "java:297", "bsp", "tree", "at", "org", "apach", "common", "math3", "geometri", "partit", "bsptree", "insertcut", "bsp", "tree", "insert", "cut", "bsptree", "java:155", "bsp", "tree", "at", "org", "apach", "common", "math3", "geometri", "partit", "regionfactori", "buildconvex", "region", "factori", "build", "convex", "regionfactori", "java:55", "region", "factori", "at", "org", "apach", "common", "math3", "geometri", "euclidean", "threed", "polyhedronsset", "buildboundari", "polyhedron", "set", "build", "boundari", "polyhedronsset", "java:119", "polyhedron", "set", "at", "org", "apach", "common", "math3", "geometri", "euclidean", "threed", "polyhedronsset", "polyhedron", "set", "init", "polyhedronsset", "java:97", "polyhedron", "set"], "B_title": "Build empty polyhedrons set when given equal min/max boundaries.", "B_clean_title": ["build", "empti", "polyhedron", "set", "when", "given", "equal", "min", "max", "boundari"]},
{"A_title": "IResponseFilter doesnt work in 1.5In current 1.5-SNAPSHOT there are no callers of org.apache.wicket.settings.IRequestCycleSettings.getResponseFilters() and thus filters are never executed.", "A_clean_title": ["iresponsefilt", "respons", "filter", "doesnt", "work", "5in", "current", "snapshot", "there", "are", "no", "caller", "org", "apach", "wicket", "set", "irequestcycleset", "getresponsefilt", "request", "cycl", "set", "get", "respons", "filter", "thu", "filter", "are", "never", "execut"], "B_title": "IResponseFilter doesnt work in 1.5", "B_clean_title": ["iresponsefilt", "respons", "filter", "doesnt", "work"]},
{"A_title": "NPE in MarkSweepGarbageCollector.saveBatchToFile during Datastore GC with FileDataStoreDuring running a datastore garbage collection on a Jackrabbit 2 FileDataStore (org.apache.jackrabbit.oak.plugins.blob.datastore.FileDataStore see http://jackrabbit.apache.org/oak/docs/osgi_config.html) an NPE is thrown code 13.05.2014 17:50:16.944 *ERROR* qtp1416657193-147 org.apache.jackrabbit.oak.management.ManagementOperation Blob garbage collection failed java.lang.RuntimeException: Error in retrieving references at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector 1.addReference(MarkSweepGarbageCollector.java:395) at org.apache.jackrabbit.oak.plugins.segment.Segment.collectBlobReferences(Segment.java:248) at org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.collectBlobReferences(SegmentTracker.java:178) at org.apache.jackrabbit.oak.plugins.segment.SegmentBlobReferenceRetriever.collectReferences(SegmentBlobReferenceRetriever.java:38) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector.iterateNodeTree(MarkSweepGarbageCollector.java:361) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector.mark(MarkSweepGarbageCollector.java:201) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector.markAndSweep(MarkSweepGarbageCollector.java:173) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector.collectGarbage(MarkSweepGarbageCollector.java:149) at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService 2.collectGarbage(SegmentNodeStoreService.java:185) at org.apache.jackrabbit.oak.plugins.blob.BlobGC 1.call(BlobGC.java:68) at org.apache.jackrabbit.oak.plugins.blob.BlobGC 1.call(BlobGC.java:64) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.NullPointerException: null at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:192) at com.google.common.base.Joiner.toString(Joiner.java:436) at com.google.common.base.Joiner.appendTo(Joiner.java:108) at com.google.common.base.Joiner.appendTo(Joiner.java:152) at com.google.common.base.Joiner.join(Joiner.java:193) at com.google.common.base.Joiner.join(Joiner.java:183) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector.saveBatchToFile(MarkSweepGarbageCollector.java:317) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector 1.addReference(MarkSweepGarbageCollector.java:391) ... 14 common frames omitted code  Attached you find the OSGi config for both the nodestore and the datastore.", "A_clean_title": ["npe", "marksweepgarbagecollector", "savebatchtofil", "mark", "sweep", "garbag", "collector", "save", "batch", "file", "dure", "datastor", "gc", "filedatastoredur", "file", "data", "store", "dure", "run", "datastor", "garbag", "collect", "jackrabbit", "filedatastor", "file", "data", "store", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "datastor", "filedatastor", "file", "data", "store", "see", "http", "apach", "html", "jackrabbit", "config", "org", "oak", "doc", "osgi", "npe", "thrown", "code", "13", "05", "2014", "17:50:16", "944", "error", "qtp1416657193", "147", "org", "apach", "jackrabbit", "oak", "manag", "managementoper", "manag", "oper", "blob", "garbag", "collect", "fail", "java", "lang", "runtimeexcept", "runtim", "except", "error", "retriev", "refer", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "mark", "sweep", "garbag", "collector", "addrefer", "add", "refer", "marksweepgarbagecollector", "java:395", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segment", "collectblobrefer", "collect", "blob", "refer", "segment", "java:248", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmenttrack", "collectblobrefer", "segment", "tracker", "collect", "blob", "refer", "segmenttrack", "java:178", "segment", "tracker", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentblobreferenceretriev", "collectrefer", "segment", "blob", "refer", "retriev", "collect", "refer", "segmentblobreferenceretriev", "java:38", "segment", "blob", "refer", "retriev", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "iteratenodetre", "mark", "sweep", "garbag", "collector", "iter", "node", "tree", "marksweepgarbagecollector", "java:361", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "mark", "mark", "sweep", "garbag", "collector", "marksweepgarbagecollector", "java:201", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "markandsweep", "mark", "sweep", "garbag", "collector", "mark", "sweep", "marksweepgarbagecollector", "java:173", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "collectgarbag", "mark", "sweep", "garbag", "collector", "collect", "garbag", "marksweepgarbagecollector", "java:149", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodestoreservic", "segment", "node", "store", "servic", "collectgarbag", "collect", "garbag", "segmentnodestoreservic", "java:185", "segment", "node", "store", "servic", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "blobgc", "blob", "gc", "call", "blobgc", "java:68", "blob", "gc", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "blobgc", "blob", "gc", "call", "blobgc", "java:64", "blob", "gc", "at", "java", "util", "concurr", "futuretask", "run", "futur", "task", "futuretask", "java:262", "futur", "task", "at", "java", "util", "concurr", "threadpoolexecutor", "runwork", "thread", "pool", "executor", "run", "worker", "threadpoolexecutor", "java:1145", "thread", "pool", "executor", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:615", "thread", "pool", "executor", "at", "java", "lang", "thread", "run", "thread", "java:745", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "null", "at", "com", "googl", "common", "base", "precondit", "checknotnul", "check", "not", "null", "precondit", "java:192", "at", "com", "googl", "common", "base", "joiner", "tostr", "string", "joiner", "java:436", "at", "com", "googl", "common", "base", "joiner", "appendto", "append", "joiner", "java:108", "at", "com", "googl", "common", "base", "joiner", "appendto", "append", "joiner", "java:152", "at", "com", "googl", "common", "base", "joiner", "join", "joiner", "java:193", "at", "com", "googl", "common", "base", "joiner", "join", "joiner", "java:183", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "savebatchtofil", "mark", "sweep", "garbag", "collector", "save", "batch", "file", "marksweepgarbagecollector", "java:317", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "mark", "sweep", "garbag", "collector", "addrefer", "add", "refer", "marksweepgarbagecollector", "java:391", "mark", "sweep", "garbag", "collector", "14", "common", "frame", "omit", "code", "attach", "you", "find", "osgi", "os", "gi", "config", "both", "nodestor", "datastor"], "B_title": "NPE in MarkSweepGarbageCollector.saveBatchToFile during Datastore GC with FileDataStore", "B_clean_title": ["npe", "marksweepgarbagecollector", "savebatchtofil", "mark", "sweep", "garbag", "collector", "save", "batch", "file", "dure", "datastor", "gc", "filedatastor", "file", "data", "store"]},
{"A_title": "Reproduceable crash with switch statementNone", "A_clean_title": ["reproduc", "crash", "switch", "statementnon", "statement", "none"], "B_title": "Dont remove nodes out of traversal order. Fixes issue 311.", "B_clean_title": ["dont", "remov", "node", "out", "travers", "order", "fix", "issu", "311"]},
{"A_title": "numerical problems in rotation creationbuilding a rotation from the following vector pairs leads to NaN: u1 = -4921140.837095533 -2.1512094250440013E7 -890093.279426377 u2 = -2.7238580938724895E9 -2.169664921341876E9 6.749688708885301E10 v1 = 1 0 0 v2 = 0 0 1 The constructor first changes the (v1 v2) pair into (v1 v2) ensuring the following scalar products hold:  <v1|v1> == <u1|u1>  <v2|v2> == <u2|u2>  <u1 |u2>  == <v1|v2> Once the (v1 v2) pair has been computed we compute the cross product:   k = (v1 - u1)^(v2 - u2) and the scalar product:   c = <k | (u1^u2)> By construction c is positive or null and the quaternion axis we want to build is q = k/2*sqrt(c). c should be null only if some of the vectors are aligned and this is dealt with later in the algorithm. However there are numerical problems with the vector above with the way these computations are done as shown by the following comparisons showing the result we get from our Java code and the result we get from manual computation with the same formulas but with enhanced precision: commons math:   k = 38514476.5            -84.                           -1168590144 high precision: k = 38514410.36093388...  -0.374075245201180409222711... -1168590152.10599715208... and it becomes worse when computing c because the vectors are almost orthogonal to each other hence inducing additional cancellations. We get: commons math    c = -1.2397173627587605E20 high precision: c =  558382746168463196.7079627... We have lost ALL significant digits in cancellations and even the sign is wrong!", "A_clean_title": ["numer", "problem", "rotat", "creationbuild", "rotat", "follow", "vector", "pair", "lead", "nan", "na", "u1", "4921140", "837095533", "1512094250440013e7", "890093", "279426377", "u2", "7238580938724895e9", "169664921341876e9", "749688708885301e10", "v1", "v2", "constructor", "first", "chang", "v1", "v2", "pair", "into", "v1", "v2", "ensur", "follow", "scalar", "product", "hold", "v1|v1", "u1|u1", "v2|v2", "u2|u2", "u1", "|u2", "v1|v2", "onc", "v1", "v2", "pair", "ha", "been", "comput", "we", "comput", "cross", "product", "v1", "u1", "v2", "u2", "scalar", "product", "u1^u2", "by", "construct", "posit", "or", "null", "quaternion", "axi", "we", "want", "build", "sqrt", "null", "onli", "some", "vector", "are", "align", "thi", "dealt", "later", "algorithm", "howev", "there", "are", "numer", "problem", "vector", "abov", "way", "these", "comput", "are", "done", "as", "shown", "by", "follow", "comparison", "show", "result", "we", "get", "our", "java", "code", "result", "we", "get", "manual", "comput", "same", "formula", "but", "enhanc", "precis", "common", "math", "38514476", "84", "1168590144", "high", "precis", "38514410", "36093388", "374075245201180409222711", "1168590152", "10599715208", "it", "becom", "wors", "when", "comput", "becaus", "vector", "are", "almost", "orthogon", "each", "other", "henc", "induc", "addit", "cancel", "we", "get", "common", "math", "2397173627587605e20", "high", "precis", "558382746168463196", "7079627", "we", "have", "lost", "all", "signific", "digit", "cancel", "even", "sign", "wrong"], "B_title": "Fixed a wrong detection of rotation axis versus vectors plane in Rotation constructor using two vectors pairs.", "B_clean_title": ["fix", "wrong", "detect", "rotat", "axi", "versu", "vector", "plane", "rotat", "constructor", "two", "vector", "pair"]},
{"A_title": "Cross foreign cluster revision comparison may be wrongRunning one of the access control related benchmarks concurrently on a MongoDB may result in strange conflicts even when DocumentNodeStore retries the commit. The root cause may be a wrong revision comparison when both revision to compare are from a foreign cluster node and one of them is not withing the known seen-at revision ranges.", "A_clean_title": ["cross", "foreign", "cluster", "revis", "comparison", "may", "wrongrun", "wrong", "run", "one", "access", "control", "relat", "benchmark", "concurr", "mongodb", "mongo", "db", "may", "result", "strang", "conflict", "even", "when", "documentnodestor", "document", "node", "store", "retri", "commit", "root", "caus", "may", "wrong", "revis", "comparison", "when", "both", "revis", "compar", "are", "foreign", "cluster", "node", "one", "them", "not", "with", "known", "seen", "at", "revis", "rang"], "B_title": "Cross foreign cluster revision comparison may be wrong", "B_clean_title": ["cross", "foreign", "cluster", "revis", "comparison", "may", "wrong"]},
{"A_title": "Background update may create journal entry with incorrect idThe conflict check does not consider changes that are made visible between the rebase and the background read.", "A_clean_title": ["background", "updat", "may", "creat", "journal", "entri", "incorrect", "idth", "id", "conflict", "check", "not", "consid", "chang", "that", "are", "made", "visibl", "between", "rebas", "background", "read"], "B_title": "Commit does not detect conflict when background read happens after rebase", "B_clean_title": ["commit", "not", "detect", "conflict", "when", "background", "read", "happen", "after", "rebas"]},
{"A_title": "ListenerInterfaceRequestHandler#respond throws ComponentNotFoundException as a side-effectThe following exception occurs instead of a generic WicketRuntimeException:  16:27:56.181 WARN  (RequestCycle.java:343) Handling the following exception qtp9826071-207 org.apache.wicket.core.request.handler.ComponentNotFoundException: Could not find component xyz on page class MyPage’        at org.apache.wicket.core.request.handler.PageAndComponentProvider.getComponent(PageAndComponentProvider.java:182) ~org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.core.request.handler.ListenerInterfaceRequestHandler.getComponent(ListenerInterfaceRequestHandler.java:90) ~org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.core.request.handler.ListenerInterfaceRequestHandler.respond(ListenerInterfaceRequestHandler.java:231) ~org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.request.cycle.RequestCycle HandlerExecutor.respond(RequestCycle.java:861) ~org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:64) ~org.apache.wicket.request_6.12.0.jar:6.12.0        at org.apache.wicket.request.cycle.RequestCycle.execute(RequestCycle.java:261) org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:218) org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:289) org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.protocol.http.WicketFilter.processRequestCycle(WicketFilter.java:259) org.apache.wicket.core_6.12.0.jar:6.12.0  in fact this is a side effect if you look at the code:         @Override        public void respond(final IRequestCycle requestCycle)                      final IRequestablePage page = getPage();              final boolean freshPage = pageComponentProvider.isPageInstanceFresh();              final boolean isAjax = ((WebRequest)requestCycle.getRequest()).isAjax();              IRequestableComponent component = null;              try                                   component = getComponent();                            catch (ComponentNotFoundException e)                                   // either the page is stateless and the component we are looking for is not added in the                     // constructor                     // or the page is stateful+stale and a new instances was created by pageprovider                     // we denote this by setting component to null                     component = null;                            if ((component == null && freshPage) ||                      (component != null && getComponent().getPage() == page))                             ....                             else                                     throw new WicketRuntimeException(Component  + getComponent() +                             has been removed from page.);                          You see that getComponent() is called twice.  1) Once guarded by a catch   - and - 2) once unguarded  So if the component cant be found AND freshPage is false as a sideeffect instead of the WicketRuntimeException with the removed message a componentnotfound exception is raised as a side effect.  I see two possible solutions for this  a) either it is intentional that a ComponentNotFoundException is thrown then it should be thrown from the catch block like               catch (ComponentNotFoundException e)                                   if (!freshPage)                         throw e;                                     b) if it is unintentionall in the else case ther should be a simple check like this   if (component == null)                          throw new WicketRuntimeException(Component for path  + getPath() +                            and page +page.getClass().getName()+ has been removed from page.);                      else                         throw new WicketRuntimeException(Component  + component +                            has been removed from page.);                        Beside this: it would be a good idea to mention at least the page class in either case.", "A_clean_title": ["listenerinterfacerequesthandl", "listen", "interfac", "request", "handler", "respond", "throw", "componentnotfoundexcept", "compon", "not", "found", "except", "as", "side", "effectth", "effect", "follow", "except", "occur", "instead", "gener", "wicketruntimeexcept", "wicket", "runtim", "except", "16:27:56", "181", "warn", "requestcycl", "java:343", "request", "cycl", "handl", "follow", "except", "qtp9826071", "207", "org", "apach", "wicket", "core", "request", "handler", "componentnotfoundexcept", "compon", "not", "found", "except", "could", "not", "find", "compon", "xyz", "page", "class", "mypag", "my", "page", "at", "org", "apach", "wicket", "core", "request", "handler", "pageandcomponentprovid", "getcompon", "page", "compon", "provid", "get", "compon", "pageandcomponentprovid", "java:182", "page", "compon", "provid", "~org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "core", "request", "handler", "listenerinterfacerequesthandl", "getcompon", "listen", "interfac", "request", "handler", "get", "compon", "listenerinterfacerequesthandl", "java:90", "listen", "interfac", "request", "handler", "~org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "core", "request", "handler", "listenerinterfacerequesthandl", "respond", "listen", "interfac", "request", "handler", "listenerinterfacerequesthandl", "java:231", "listen", "interfac", "request", "handler", "~org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "request", "cycl", "handlerexecutor", "respond", "handler", "executor", "requestcycl", "java:861", "request", "cycl", "~org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:64", "request", "handler", "stack", "~org", "apach", "wicket", "12", "jar:6", "12", "request", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "execut", "request", "cycl", "requestcycl", "java:261", "request", "cycl", "org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:218", "request", "cycl", "org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:289", "request", "cycl", "org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequestcycl", "wicket", "filter", "process", "request", "cycl", "wicketfilt", "java:259", "wicket", "filter", "org", "apach", "wicket", "12", "jar:6", "12", "core", "fact", "thi", "side", "effect", "you", "look", "at", "code", "overrid", "public", "void", "respond", "final", "irequestcycl", "request", "cycl", "requestcycl", "request", "cycl", "final", "irequestablepag", "request", "page", "page", "getpag", "get", "page", "final", "boolean", "freshpag", "fresh", "page", "pagecomponentprovid", "ispageinstancefresh", "page", "compon", "provid", "page", "instanc", "fresh", "final", "boolean", "isajax", "ajax", "webrequest", "web", "request", "requestcycl", "getrequest", "request", "cycl", "get", "request", "isajax", "ajax", "irequestablecompon", "request", "compon", "compon", "null", "tri", "compon", "getcompon", "get", "compon", "catch", "componentnotfoundexcept", "compon", "not", "found", "except", "either", "page", "stateless", "compon", "we", "are", "look", "not", "ad", "constructor", "or", "page", "stateful+stal", "new", "instanc", "wa", "creat", "by", "pageprovid", "we", "denot", "thi", "by", "set", "compon", "null", "compon", "null", "compon", "null", "freshpag", "fresh", "page", "compon", "null", "getcompon", "get", "compon", "getpag", "get", "page", "page", "throw", "new", "wicketruntimeexcept", "wicket", "runtim", "except", "compon", "getcompon", "get", "compon", "ha", "been", "remov", "page", "you", "see", "that", "getcompon", "get", "compon", "call", "twice", "onc", "guard", "by", "catch", "onc", "unguard", "so", "compon", "cant", "found", "freshpag", "fresh", "page", "fals", "as", "sideeffect", "instead", "wicketruntimeexcept", "wicket", "runtim", "except", "remov", "messag", "componentnotfound", "except", "rais", "as", "side", "effect", "see", "two", "possibl", "solut", "thi", "either", "it", "intent", "that", "componentnotfoundexcept", "compon", "not", "found", "except", "thrown", "then", "it", "thrown", "catch", "block", "like", "catch", "componentnotfoundexcept", "compon", "not", "found", "except", "freshpag", "fresh", "page", "throw", "it", "unintentional", "case", "ther", "simpl", "check", "like", "thi", "compon", "null", "throw", "new", "wicketruntimeexcept", "wicket", "runtim", "except", "compon", "path", "getpath", "get", "path", "page", "+page", "getclass", "get", "class", "getnam", "get", "name", "ha", "been", "remov", "page", "throw", "new", "wicketruntimeexcept", "wicket", "runtim", "except", "compon", "compon", "ha", "been", "remov", "page", "besid", "thi", "it", "would", "good", "idea", "mention", "at", "least", "page", "class", "either", "case"], "B_title": "watch out for null component; break early from method", "B_clean_title": ["watch", "out", "null", "compon", "break", "earli", "method"]},
{"A_title": "NullPointerException in vertex-centric iterationHello to my Squirrels  I came across this exception when having a vertex-centric iteration output followed by a group by.  Im not sure if what is causing it since I saw this error in a rather large pipeline but I managed to reproduce it with this code example | https://github.com/vasia/flink/commit/1b7bbca1a6130fbcfe98b4b9b43967eb4c61f309 and a sufficiently large dataset e.g. this one | http://snap.stanford.edu/data/com-DBLP.html (Im running this locally). It seems like a null Buffer in RecordWriter.  The exception message is the following:  Exception in thread main org.apache.flink.runtime.client.JobExecutionException: Job execution failed. at org.apache.flink.runtime.jobmanager.JobManager anonfun receiveWithLogMessages 1.applyOrElse(JobManager.scala:319) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.ActorLogMessages anon 1.apply(ActorLogMessages.scala:37) at org.apache.flink.runtime.ActorLogMessages anon 1.apply(ActorLogMessages.scala:30) at scala.PartialFunction class.applyOrElse(PartialFunction.scala:118) at org.apache.flink.runtime.ActorLogMessages anon 1.applyOrElse(ActorLogMessages.scala:30) at akka.actor.Actor class.aroundReceive(Actor.scala:465) at org.apache.flink.runtime.jobmanager.JobManager.aroundReceive(JobManager.scala:94) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) at akka.actor.ActorCell.invoke(ActorCell.scala:487) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:254) at akka.dispatch.Mailbox.run(Mailbox.scala:221) at akka.dispatch.Mailbox.exec(Mailbox.scala:231) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) Caused by: java.lang.NullPointerException at org.apache.flink.runtime.io.network.api.serialization.SpanningRecordSerializer.setNextBuffer(SpanningRecordSerializer.java:93) at org.apache.flink.runtime.io.network.api.writer.RecordWriter.emit(RecordWriter.java:92) at org.apache.flink.runtime.operators.shipping.OutputCollector.collect(OutputCollector.java:65) at org.apache.flink.runtime.iterative.task.IterationHeadPactTask.streamSolutionSetToFinalOutput(IterationHeadPactTask.java:405) at org.apache.flink.runtime.iterative.task.IterationHeadPactTask.run(IterationHeadPactTask.java:365) at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:360) at org.apache.flink.runtime.execution.RuntimeEnvironment.run(RuntimeEnvironment.java:221) at java.lang.Thread.run(Thread.java:745)", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "vertex", "centric", "iterationhello", "iter", "hello", "my", "squirrel", "came", "across", "thi", "except", "when", "have", "vertex", "centric", "iter", "output", "follow", "by", "group", "by", "im", "not", "sure", "what", "caus", "it", "sinc", "saw", "thi", "error", "rather", "larg", "pipelin", "but", "manag", "reproduc", "it", "thi", "code", "exampl", "http", "github", "com", "vasia", "flink", "commit", "1b7bbca1a6130fbcfe98b4b9b43967eb4c61f309", "suffici", "larg", "dataset", "thi", "one", "http", "stanford", "dblp", "html", "snap", "edu", "data", "com", "im", "run", "thi", "local", "it", "seem", "like", "null", "buffer", "recordwrit", "record", "writer", "except", "messag", "follow", "except", "thread", "main", "org", "apach", "flink", "runtim", "client", "jobexecutionexcept", "job", "execut", "except", "job", "execut", "fail", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "anonfun", "receivewithlogmessag", "receiv", "log", "messag", "applyorels", "appli", "or", "jobmanag", "scala:319", "job", "manag", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "actorlogmessag", "actor", "log", "messag", "anon", "appli", "actorlogmessag", "scala:37", "actor", "log", "messag", "at", "org", "apach", "flink", "runtim", "actorlogmessag", "actor", "log", "messag", "anon", "appli", "actorlogmessag", "scala:30", "actor", "log", "messag", "at", "scala", "partialfunct", "partial", "function", "class", "applyorels", "appli", "or", "partialfunct", "scala:118", "partial", "function", "at", "org", "apach", "flink", "runtim", "actorlogmessag", "actor", "log", "messag", "anon", "applyorels", "appli", "or", "actorlogmessag", "scala:30", "actor", "log", "messag", "at", "akka", "actor", "actor", "class", "aroundrec", "around", "receiv", "actor", "scala:465", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "aroundrec", "job", "manag", "around", "receiv", "jobmanag", "scala:94", "job", "manag", "at", "akka", "actor", "actorcel", "receivemessag", "actor", "cell", "receiv", "messag", "actorcel", "scala:516", "actor", "cell", "at", "akka", "actor", "actorcel", "invok", "actor", "cell", "actorcel", "scala:487", "actor", "cell", "at", "akka", "dispatch", "mailbox", "processmailbox", "process", "mailbox", "mailbox", "scala:254", "at", "akka", "dispatch", "mailbox", "run", "mailbox", "scala:221", "at", "akka", "dispatch", "mailbox", "exec", "mailbox", "scala:231", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "flink", "runtim", "io", "network", "api", "serial", "spanningrecordseri", "setnextbuff", "span", "record", "serial", "set", "next", "buffer", "spanningrecordseri", "java:93", "span", "record", "serial", "at", "org", "apach", "flink", "runtim", "io", "network", "api", "writer", "recordwrit", "emit", "record", "writer", "recordwrit", "java:92", "record", "writer", "at", "org", "apach", "flink", "runtim", "oper", "ship", "outputcollector", "collect", "output", "collector", "outputcollector", "java:65", "output", "collector", "at", "org", "apach", "flink", "runtim", "iter", "task", "iterationheadpacttask", "streamsolutionsettofinaloutput", "iter", "head", "pact", "task", "stream", "solut", "set", "final", "output", "iterationheadpacttask", "java:405", "iter", "head", "pact", "task", "at", "org", "apach", "flink", "runtim", "iter", "task", "iterationheadpacttask", "run", "iter", "head", "pact", "task", "iterationheadpacttask", "java:365", "iter", "head", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "invok", "regular", "pact", "task", "regularpacttask", "java:360", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "run", "runtim", "environ", "runtimeenviron", "java:221", "runtim", "environ", "at", "java", "lang", "thread", "run", "thread", "java:745"], "B_title": "runtime Improve exception when bufferpools have been shut down.", "B_clean_title": ["runtim", "improv", "except", "when", "bufferpool", "have", "been", "shut", "down"]},
{"A_title": "org.apache.commons.lang3.math.Fraction does not reduce (Integer.MIN_VALUE 2^k)The greatestCommonDivisor method in class Fraction does not find the gcd of Integer.MIN_VALUE and 2^k and this case can be triggered by taking Integer.MIN_VALUE as the numerator. Note that the case of taking Integer.MIN_VALUE as the denominator is handled explicitly in the getReducedFraction factory method. FractionTest.java // additional test cases public void testReducedFactory_int_int()  // ... f = Fraction.getReducedFraction(Integer.MIN_VALUE 2); assertEquals(Integer.MIN_VALUE / 2 f.getNumerator()); assertEquals(1 f.getDenominator());  public void testReduce()  // ... f = Fraction.getFraction(Integer.MIN_VALUE 2); result = f.reduce(); assertEquals(Integer.MIN_VALUE / 2 result.getNumerator()); assertEquals(1 result.getDenominator());", "A_clean_title": ["org", "apach", "common", "lang3", "math", "fraction", "not", "reduc", "integ", "min", "valu", "2^k", "greatestcommondivisor", "greatest", "common", "divisor", "method", "class", "fraction", "not", "find", "gcd", "integ", "min", "valu", "2^k", "thi", "case", "trigger", "by", "take", "integ", "min", "valu", "as", "numer", "note", "that", "case", "take", "integ", "min", "valu", "as", "denomin", "handl", "explicitli", "getreducedfract", "get", "reduc", "fraction", "factori", "method", "fractiontest", "java", "fraction", "test", "addit", "test", "case", "public", "void", "testreducedfactori", "int", "int", "test", "reduc", "factori", "fraction", "getreducedfract", "get", "reduc", "fraction", "integ", "min", "valu", "assertequ", "assert", "equal", "integ", "min", "valu", "getnumer", "get", "numer", "assertequ", "assert", "equal", "getdenomin", "get", "denomin", "public", "void", "testreduc", "test", "reduc", "fraction", "getfract", "get", "fraction", "integ", "min", "valu", "result", "reduc", "assertequ", "assert", "equal", "integ", "min", "valu", "result", "getnumer", "get", "numer", "assertequ", "assert", "equal", "result", "getdenomin", "get", "denomin"], "B_title": "Adding first method check from Maths MathUtils.gcd method; and unit tests showing that this was needed. Bug reported and solved by Christian Semrau LANG-662", "B_clean_title": ["ad", "first", "method", "check", "math", "mathutil", "gcd", "math", "util", "method", "unit", "test", "show", "that", "thi", "wa", "need", "bug", "report", "solv", "by", "christian", "semrau", "lang", "662"]},
{"A_title": "Digamma calculation produces SOE on NaN argumentDigamma doesnt work particularly well with NaNs.  How to reproduce: call Gamma.digamma(Double.NaN)  Expected outcome: returns NaN or throws a meaningful exception  Real outcome: crashes with StackOverflowException as digamma enters infinite recursion.", "A_clean_title": ["digamma", "calcul", "produc", "soe", "nan", "na", "argumentdigamma", "argument", "digamma", "doesnt", "work", "particularli", "well", "nan", "na", "ns", "how", "reproduc", "call", "gamma", "digamma", "doubl", "nan", "na", "expect", "outcom", "return", "nan", "na", "or", "throw", "meaning", "except", "real", "outcom", "crash", "stackoverflowexcept", "stack", "overflow", "except", "as", "digamma", "enter", "infinit", "recurs"], "B_title": "Propagate input value to Gamma#digamma and Gamma#trigamma if the input is not a real value to avoid infinite recursion. Thanks to Aleksei Dievskii.", "B_clean_title": ["propag", "input", "valu", "gamma", "digamma", "gamma", "trigamma", "input", "not", "real", "valu", "avoid", "infinit", "recurs", "thank", "aleksei", "dievskii"]},
{"A_title": "issues with JsopBuilder.encode and .escape1) escape() escapes many characters that do not need to be escaped (>127)  2) encode() does not encode many control characters that would need to be escaped when read through a JSON parser.", "A_clean_title": ["issu", "jsopbuild", "encod", "jsop", "builder", "escape1", "escap", "escap", "mani", "charact", "that", "not", "need", "escap", "127", "encod", "not", "encod", "mani", "control", "charact", "that", "would", "need", "escap", "when", "read", "through", "json", "parser"], "B_title": "issues with JsopBuilder.encode and .escape", "B_clean_title": ["issu", "jsopbuild", "encod", "jsop", "builder", "escap"]},
{"A_title": "Using render strategy ONE_PASS_RENDER fails for Ajax requestsI have an application which has two pages. Page A has an AjaxLink which makes some checks and either sets some error feedback and stays on the same page (e.g. login page with Invalid user error) or if everything is OK then redirects to page B (via setResponsePage(B.class)). The problem comes when the current render strategy is ONE_PASS_RENDER. In this case no matter that fromUrl and toUrl are different and the request is Ajax the current code directly writes the page markup to the response. I think it should trigger a redirect instead. I am not sure whether it should be redirect to render or to buffer ...", "A_clean_title": ["render", "strategi", "one", "pass", "render", "fail", "ajax", "requestsi", "request", "have", "applic", "which", "ha", "two", "page", "page", "ha", "ajaxlink", "ajax", "link", "which", "make", "some", "check", "either", "set", "some", "error", "feedback", "stay", "same", "page", "login", "page", "invalid", "user", "error", "or", "everyth", "ok", "then", "redirect", "page", "via", "setresponsepag", "set", "respons", "page", "class", "problem", "come", "when", "current", "render", "strategi", "one", "pass", "render", "thi", "case", "no", "matter", "that", "fromurl", "url", "tourl", "url", "are", "differ", "request", "ajax", "current", "code", "directli", "write", "page", "markup", "respons", "think", "it", "trigger", "redirect", "instead", "am", "not", "sure", "whether", "it", "redirect", "render", "or", "buffer"], "B_title": "Using render strategy ONE_PASS_RENDER fails for Ajax requests", "B_clean_title": ["render", "strategi", "one", "pass", "render", "fail", "ajax", "request"]},
{"A_title": "Mixin based rules not working for relative propertiesIf an indexing rule is defined for mixin then it does not work as expected for relative properties.  Issue here being that most of logic in Aggregate class (which is used for relative property handling also) relies on nodes primaryType and does not account for mixin type", "A_clean_title": ["mixin", "base", "rule", "not", "work", "rel", "propertiesif", "properti", "index", "rule", "defin", "mixin", "then", "it", "not", "work", "as", "expect", "rel", "properti", "issu", "here", "be", "that", "most", "logic", "aggreg", "class", "which", "use", "rel", "properti", "handl", "also", "reli", "node", "primarytyp", "primari", "type", "not", "account", "mixin", "type"], "B_title": "- Mixin based rules not working for relative properties", "B_clean_title": ["mixin", "base", "rule", "not", "work", "rel", "properti"]},
{"A_title": "HarmonicFitter.ParameterGuesser sometimes fails to return sensible valuesThe inner class ParameterGuesser in HarmonicFitter (package o.a.c.m.optimization.fitting) fails to compute a usable guess for the amplitude parameter.", "A_clean_title": ["harmonicfitt", "parameterguess", "harmon", "fitter", "paramet", "guesser", "sometim", "fail", "return", "sensibl", "valuesth", "valu", "inner", "class", "parameterguess", "paramet", "guesser", "harmonicfitt", "harmon", "fitter", "packag", "optim", "fit", "fail", "comput", "usabl", "guess", "amplitud", "paramet"], "B_title": "Generate an exception when the parameter guessing procedure cannot perform correctly (in rare ill-conditioned cases).", "B_clean_title": ["gener", "except", "when", "paramet", "guess", "procedur", "not", "perform", "correctli", "rare", "ill", "condit", "case"]},
{"A_title": "MutableTree#isNew: replace implementation by NodeBuilder#isNewSimilar to the issue described in OAK-1177 we may consider replacing the implementation of MutableTree#isNew by the corresponding call on the NodeBuilder.  See also OAK-947.", "A_clean_title": ["mutabletre", "mutabl", "tree", "isnew", "new", "replac", "implement", "by", "nodebuild", "node", "builder", "isnewsimilar", "new", "similar", "issu", "describ", "oak", "1177", "we", "may", "consid", "replac", "implement", "mutabletre", "mutabl", "tree", "isnew", "new", "by", "correspond", "call", "nodebuild", "node", "builder", "see", "also", "oak", "947"], "B_title": "MutableTree#isNew: replace implementation by NodeBuilder#isNew", "B_clean_title": ["mutabletre", "mutabl", "tree", "isnew", "new", "replac", "implement", "by", "nodebuild", "node", "builder", "isnew", "new"]},
{"A_title": "Last-modified header of external markup is ignoredWhen using external base markup(in my case a drupal page with a wicket:child element in it) this markup is supposed to be cached after first fetch. For subsequent requests the last-modified header is checked to see if the markup has changed and when it has the markup is fetched again.  This does not work Connections.getLastModified(URL url) always returns 0 when the URL is a http url(in fact when url.openConnection returns a sun.net.www.protocol.http.HttpURLConnection.  Solution could be to not setDoInput to false on this URLConnection(tested that)", "A_clean_title": ["last", "modifi", "header", "extern", "markup", "ignoredwhen", "ignor", "when", "extern", "base", "markup", "my", "case", "drupal", "page", "wicket", "child", "element", "it", "thi", "markup", "suppos", "cach", "after", "first", "fetch", "subsequ", "request", "last", "modifi", "header", "check", "see", "markup", "ha", "chang", "when", "it", "ha", "markup", "fetch", "again", "thi", "not", "work", "connect", "getlastmodifi", "get", "last", "modifi", "url", "url", "alway", "return", "when", "url", "http", "url", "fact", "when", "url", "openconnect", "open", "connect", "return", "sun", "net", "www", "protocol", "http", "httpurlconnect", "http", "url", "connect", "solut", "could", "not", "setdoinput", "set", "input", "fals", "thi", "urlconnect", "url", "connect", "test", "that"], "B_title": "Last-modified header of external markup is ignored", "B_clean_title": ["last", "modifi", "header", "extern", "markup", "ignor"]},
{"A_title": "Bug in DoubleParser and FloatParser - empty String is not casted to 0Hi  I found the bug when I wanted to read a csv file which had a line like: ||n  If I treat it as a Tuple2<LongLong> I get as expected a tuple (0L0L).  But if I want to read it into a Double-Tuple or a Float-Tuple I get the following error:  java.lang.AssertionError: Test failed due to a org.apache.flink.api.common.io.ParseException: Line could not be parsed: || ParserError NUMERIC_VALUE_FORMAT_ERROR   This error can be solved by adding an additional condition for empty strings in the FloatParser / DoubleParser.  We definitely need the CSVReader to be able to read empty values.  I can fix it like described if there are no better ideas :)", "A_clean_title": ["bug", "doublepars", "doubl", "parser", "floatpars", "float", "parser", "empti", "string", "not", "cast", "0hi", "found", "bug", "when", "want", "read", "csv", "file", "which", "had", "line", "like", "||n", "treat", "it", "as", "tuple2", "longlong", "long", "long", "get", "as", "expect", "tupl", "0l0l", "but", "want", "read", "it", "into", "doubl", "tupl", "or", "float", "tupl", "get", "follow", "error", "java", "lang", "assertionerror", "assert", "error", "test", "fail", "due", "org", "apach", "flink", "api", "common", "io", "parseexcept", "pars", "except", "line", "could", "not", "pars", "parsererror", "parser", "error", "numer", "valu", "format", "error", "thi", "error", "solv", "by", "ad", "addit", "condit", "empti", "string", "floatpars", "float", "parser", "doublepars", "doubl", "parser", "we", "definit", "need", "csvreader", "csv", "reader", "abl", "read", "empti", "valu", "fix", "it", "like", "describ", "there", "are", "no", "better", "idea"], "B_title": "Consistent behavior of numeric value parsers.", "B_clean_title": ["consist", "behavior", "numer", "valu", "parser"]},
{"A_title": "Mock Accumulo Inverts order of mutations w/ same timestampMock accumulo has different behavior than real accumulo when the same key is updated in the same millisecond.  The hidden in memory map counter in mock accumulo needs to sort descending.", "A_clean_title": ["mock", "accumulo", "invert", "order", "mutat", "same", "timestampmock", "timestamp", "mock", "accumulo", "ha", "differ", "behavior", "than", "real", "accumulo", "when", "same", "key", "updat", "same", "millisecond", "hidden", "memori", "map", "counter", "mock", "accumulo", "need", "sort", "descend"], "B_title": "made mock accumulo sort incoming mutations the same as accumulo", "B_clean_title": ["made", "mock", "accumulo", "sort", "incom", "mutat", "same", "as", "accumulo"]},
{"A_title": "BitStreamGenerators (MersenneTwister Well generators) do not clear normal deviate cache on setSeedThe BitStream generators generate normal deviates (for nextGaussian) in pairs caching the last value generated. When reseeded the cache should be cleared; otherwise seeding two generators with the same value is not guaranteed to generate the same sequence.", "A_clean_title": ["bitstreamgener", "bit", "stream", "gener", "mersennetwist", "mersenn", "twister", "well", "gener", "not", "clear", "normal", "deviat", "cach", "setseedth", "set", "seed", "bitstream", "bit", "stream", "gener", "gener", "normal", "deviat", "nextgaussian", "next", "gaussian", "pair", "cach", "last", "valu", "gener", "when", "reseed", "cach", "clear", "otherwis", "seed", "two", "gener", "same", "valu", "not", "guarante", "gener", "same", "sequenc"], "B_title": "Made ISAACRandom clear its normal deviate cache on reseed. JIRA: MATH-723.", "B_clean_title": ["made", "isaacrandom", "isaac", "random", "clear", "it", "normal", "deviat", "cach", "rese", "jira", "math", "723"]},
{"A_title": "Constructor types that return all or unknown fail to parseNone", "A_clean_title": ["constructor", "type", "that", "return", "all", "or", "unknown", "fail", "parsenon", "pars", "none"], "B_title": "Tweak the grammar for this/new types. Fixes issue 1105 R=johnlenz", "B_clean_title": ["tweak", "grammar", "thi", "new", "type", "fix", "issu", "1105", "r=johnlenz"]},
{"A_title": "Bug in method appendFixedWidthPadRight of class StrBuilder causes an ArrayIndexOutOfBoundsExceptionTheres a bug in method appendFixedWidthPadRight of class StrBuilder: public StrBuilder appendFixedWidthPadRight(Object obj int width char padChar)          if (width > 0)              ensureCapacity(size + width);             String str = (obj == null ? getNullText() : obj.toString());             int strLen = str.length();             if (strLen >= width)    ==>            str.getChars(0 strLen buffer size);   <==== BUG: it should be str.getChars(0 width buffer size);               else                  int padLen = width - strLen;                 str.getChars(0 strLen buffer size);                 for (int i = 0; i < padLen; i++)                       buffersize + strLen + i = padChar;                                           size += width;                  return this;      This is causing an ArrayIndexOutOfBoundsException so this method is unusable when strLen > width. Its counterpart method appendFixedWidthPadLeft seems to be ok.", "A_clean_title": ["bug", "method", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "class", "strbuilder", "str", "builder", "caus", "arrayindexoutofboundsexceptionther", "array", "index", "out", "bound", "except", "there", "bug", "method", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "class", "strbuilder", "str", "builder", "public", "strbuilder", "str", "builder", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "object", "obj", "int", "width", "char", "padchar", "pad", "char", "width", "ensurecapac", "ensur", "capac", "size", "width", "string", "str", "obj", "null", "getnulltext", "get", "null", "text", "obj", "tostr", "string", "int", "strlen", "str", "len", "str", "length", "strlen", "str", "len", "width", "str", "getchar", "get", "char", "strlen", "str", "len", "buffer", "size", "bug", "it", "str", "getchar", "get", "char", "width", "buffer", "size", "int", "padlen", "pad", "len", "width", "strlen", "str", "len", "str", "getchar", "get", "char", "strlen", "str", "len", "buffer", "size", "int", "padlen", "pad", "len", "i++", "buffers", "strlen", "str", "len", "padchar", "pad", "char", "size", "width", "return", "thi", "thi", "caus", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "so", "thi", "method", "unus", "when", "strlen", "str", "len", "width", "it", "counterpart", "method", "appendfixedwidthpadleft", "append", "fix", "width", "pad", "left", "seem", "ok"], "B_title": "Applying a unit test for LANG-299 and the fix that Francisco Benavent suggests.", "B_clean_title": ["appli", "unit", "test", "lang", "299", "fix", "that", "francisco", "benav", "suggest"]},
{"A_title": "Minified name resolves incorrectly if default resource reference is usedIn PackageResourceReference.  When a default reference to a minified resource is used (i.e. the resource wasnt mounted) the resource reference name includes .min.   When trying to resolve the minified name another .min is appended resulting in the minified name resolving to html5.min.min.js.   As a result the PackageResourceReference concludes that the resource was not minified and adds compression.", "A_clean_title": ["minifi", "name", "resolv", "incorrectli", "default", "resourc", "refer", "usedin", "use", "packageresourcerefer", "packag", "resourc", "refer", "when", "default", "refer", "minifi", "resourc", "use", "resourc", "wasnt", "mount", "resourc", "refer", "name", "includ", "min", "when", "tri", "resolv", "minifi", "name", "anoth", "min", "append", "result", "minifi", "name", "resolv", "html5", "min", "min", "js", "as", "result", "packageresourcerefer", "packag", "resourc", "refer", "conclud", "that", "resourc", "wa", "not", "minifi", "add", "compress"], "B_title": "", "B_clean_title": []},
{"A_title": "NoSuchElementException thrown by NodeDocumentFollowing error is seen with latest 1.0.9-SNAPSHOT builds on some system  noformat Caused by: java.util.NoSuchElementException: null         at java.util.TreeMap.key(TreeMap.java:1221)         at java.util.TreeMap.firstKey(TreeMap.java:285)         at java.util.Collections UnmodifiableSortedMap.firstKey(Collections.java:1549)         at com.google.common.collect.ForwardingSortedMap.firstKey(ForwardingSortedMap.java:73)         at org.apache.jackrabbit.oak.plugins.document.NodeDocument.getNodeAtRevision(NodeDocument.java:819)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readNode(DocumentNodeStore.java:930) noformat  Most likely the above occurs because a TreeMap associated with some key in NodeDocument is empty.  noformat 23.01.2015 01:57:23.308 *WARN* pool-11-thread-5org.apache.jackrabbit.oak.plugins.observation.NodeObserver Error whiledispatching observation eventscom.google.common.util.concurrent.UncheckedExecutionException:com.google.common.util.concurrent.UncheckedExecutionException:java.util.NoSuchElementException         at com.google.common.cache.LocalCache Segment.get(LocalCache.java:2199)         at com.google.common.cache.LocalCache.get(LocalCache.java:3932)         at com.google.common.cache.LocalCache LocalManualCache.get(LocalCache.java:4721)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.getChildren(DocumentNodeStore.java:731)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.diffImpl(DocumentNodeStore.java:1666)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.access 200(DocumentNodeStore.java:105)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore 7.call(DocumentNodeStore.java:1260)         at org.apache.jackrabbit.oak.plugins.document.MongoDiffCache.getChanges(MongoDiffCache.java:88)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.diffChildren(DocumentNodeStore.java:1255)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeState.compareAgainstBaseState(DocumentNodeState.java:260)         at org.apache.jackrabbit.oak.plugins.observation.EventGenerator Continuation.run(EventGenerator.java:172)         at org.apache.jackrabbit.oak.plugins.observation.EventGenerator.generate(EventGenerator.java:118)         at org.apache.jackrabbit.oak.plugins.observation.NodeObserver.contentChanged(NodeObserver.java:156)         at org.apache.jackrabbit.oak.spi.commit.BackgroundObserver 1 1.call(BackgroundObserver.java:117)         at org.apache.jackrabbit.oak.spi.commit.BackgroundObserver 1 1.call(BackgroundObserver.java:111)         at java.util.concurrent.FutureTask.run(FutureTask.java:262)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)         at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:615)         at java.lang.Thread.run(Thread.java:744) Caused by: com.google.common.util.concurrent.UncheckedExecutionException:java.util.NoSuchElementException         at com.google.common.cache.LocalCache Segment.get(LocalCache.java:2199)         at com.google.common.cache.LocalCache.get(LocalCache.java:3932)         at com.google.common.cache.LocalCache LocalManualCache.get(LocalCache.java:4721)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.getNode(DocumentNodeStore.java:704)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readChildren(DocumentNodeStore.java:786)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore 4.call(DocumentNodeStore.java:734)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore 4.call(DocumentNodeStore.java:731)         at com.google.common.cache.LocalCache LocalManualCache 1.load(LocalCache.java:4724)         at com.google.common.cache.LocalCache LoadingValueReference.loadFuture(LocalCache.java:3522)         at com.google.common.cache.LocalCache Segment.loadSync(LocalCache.java:2315)         at com.google.common.cache.LocalCache Segment.lockedGetOrLoad(LocalCache.java:2278)         at com.google.common.cache.LocalCache Segment.get(LocalCache.java:2193)        ... 18 common frames omitted Caused by: java.util.NoSuchElementException: null         at java.util.TreeMap.key(TreeMap.java:1221)         at java.util.TreeMap.firstKey(TreeMap.java:285)         at java.util.Collections UnmodifiableSortedMap.firstKey(Collections.java:1549)         at com.google.common.collect.ForwardingSortedMap.firstKey(ForwardingSortedMap.java:73)         at org.apache.jackrabbit.oak.plugins.document.NodeDocument.getNodeAtRevision(NodeDocument.java:819)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readNode(DocumentNodeStore.java:930)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore 3.call(DocumentNodeStore.java:707)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore 3.call(DocumentNodeStore.java:704)         at com.google.common.cache.LocalCache LocalManualCache 1.load(LocalCache.java:4724)         at com.google.common.cache.LocalCache LoadingValueReference.loadFuture(LocalCache.java:3522)         at com.google.common.cache.LocalCache Segment.loadSync(LocalCache.java:2315)         at com.google.common.cache.LocalCache Segment.lockedGetOrLoad(LocalCache.java:2278)         at com.google.common.cache.LocalCache Segment.get(LocalCache.java:2193) noformat", "A_clean_title": ["nosuchelementexcept", "no", "such", "element", "except", "thrown", "by", "nodedocumentfollow", "node", "document", "follow", "error", "seen", "latest", "snapshot", "build", "some", "system", "noformat", "caus", "by", "java", "util", "nosuchelementexcept", "no", "such", "element", "except", "null", "at", "java", "util", "treemap", "key", "tree", "map", "treemap", "java:1221", "tree", "map", "at", "java", "util", "treemap", "firstkey", "tree", "map", "first", "key", "treemap", "java:285", "tree", "map", "at", "java", "util", "collect", "unmodifiablesortedmap", "firstkey", "unmodifi", "sort", "map", "first", "key", "collect", "java:1549", "at", "com", "googl", "common", "collect", "forwardingsortedmap", "firstkey", "forward", "sort", "map", "first", "key", "forwardingsortedmap", "java:73", "forward", "sort", "map", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "nodedocu", "getnodeatrevis", "node", "document", "get", "node", "at", "revis", "nodedocu", "java:819", "node", "document", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "readnod", "document", "node", "store", "read", "node", "documentnodestor", "java:930", "document", "node", "store", "noformat", "most", "like", "abov", "occur", "becaus", "treemap", "tree", "map", "associ", "some", "key", "nodedocu", "node", "document", "empti", "noformat", "23", "01", "2015", "01:57:23", "308", "warn", "pool", "11", "thread", "5org", "apach", "jackrabbit", "oak", "plugin", "observ", "nodeobserv", "node", "observ", "error", "whiledispatch", "observ", "eventscom", "googl", "common", "util", "concurr", "uncheckedexecutionexcept", "uncheck", "execut", "except", "com", "googl", "common", "util", "concurr", "uncheckedexecutionexcept", "uncheck", "execut", "except", "java", "util", "nosuchelementexcept", "no", "such", "element", "except", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "get", "localcach", "java:2199", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "get", "local", "cach", "localcach", "java:3932", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "localmanualcach", "get", "local", "manual", "cach", "localcach", "java:4721", "local", "cach", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "getchildren", "document", "node", "store", "get", "children", "documentnodestor", "java:731", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "diffimpl", "document", "node", "store", "diff", "impl", "documentnodestor", "java:1666", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "access", "document", "node", "store", "200", "documentnodestor", "java:105", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "document", "node", "store", "call", "documentnodestor", "java:1260", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "mongodiffcach", "getchang", "mongo", "diff", "cach", "get", "chang", "mongodiffcach", "java:88", "mongo", "diff", "cach", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "diffchildren", "document", "node", "store", "diff", "children", "documentnodestor", "java:1255", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodest", "compareagainstbasest", "document", "node", "state", "compar", "against", "base", "state", "documentnodest", "java:260", "document", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "observ", "eventgener", "event", "gener", "continu", "run", "eventgener", "java:172", "event", "gener", "at", "org", "apach", "jackrabbit", "oak", "plugin", "observ", "eventgener", "gener", "event", "gener", "eventgener", "java:118", "event", "gener", "at", "org", "apach", "jackrabbit", "oak", "plugin", "observ", "nodeobserv", "contentchang", "node", "observ", "content", "chang", "nodeobserv", "java:156", "node", "observ", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "backgroundobserv", "background", "observ", "call", "backgroundobserv", "java:117", "background", "observ", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "backgroundobserv", "background", "observ", "call", "backgroundobserv", "java:111", "background", "observ", "at", "java", "util", "concurr", "futuretask", "run", "futur", "task", "futuretask", "java:262", "futur", "task", "at", "java", "util", "concurr", "threadpoolexecutor", "runwork", "thread", "pool", "executor", "run", "worker", "threadpoolexecutor", "java:1145", "thread", "pool", "executor", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:615", "thread", "pool", "executor", "at", "java", "lang", "thread", "run", "thread", "java:744", "caus", "by", "com", "googl", "common", "util", "concurr", "uncheckedexecutionexcept", "uncheck", "execut", "except", "java", "util", "nosuchelementexcept", "no", "such", "element", "except", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "get", "localcach", "java:2199", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "get", "local", "cach", "localcach", "java:3932", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "localmanualcach", "get", "local", "manual", "cach", "localcach", "java:4721", "local", "cach", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "getnod", "document", "node", "store", "get", "node", "documentnodestor", "java:704", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "readchildren", "document", "node", "store", "read", "children", "documentnodestor", "java:786", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "document", "node", "store", "call", "documentnodestor", "java:734", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "document", "node", "store", "call", "documentnodestor", "java:731", "document", "node", "store", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "localmanualcach", "local", "manual", "cach", "load", "localcach", "java:4724", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "loadingvaluerefer", "loadfutur", "load", "valu", "refer", "load", "futur", "localcach", "java:3522", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "loadsync", "load", "sync", "localcach", "java:2315", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "lockedgetorload", "lock", "get", "or", "load", "localcach", "java:2278", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "get", "localcach", "java:2193", "local", "cach", "18", "common", "frame", "omit", "caus", "by", "java", "util", "nosuchelementexcept", "no", "such", "element", "except", "null", "at", "java", "util", "treemap", "key", "tree", "map", "treemap", "java:1221", "tree", "map", "at", "java", "util", "treemap", "firstkey", "tree", "map", "first", "key", "treemap", "java:285", "tree", "map", "at", "java", "util", "collect", "unmodifiablesortedmap", "firstkey", "unmodifi", "sort", "map", "first", "key", "collect", "java:1549", "at", "com", "googl", "common", "collect", "forwardingsortedmap", "firstkey", "forward", "sort", "map", "first", "key", "forwardingsortedmap", "java:73", "forward", "sort", "map", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "nodedocu", "getnodeatrevis", "node", "document", "get", "node", "at", "revis", "nodedocu", "java:819", "node", "document", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "readnod", "document", "node", "store", "read", "node", "documentnodestor", "java:930", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "document", "node", "store", "call", "documentnodestor", "java:707", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "document", "node", "store", "call", "documentnodestor", "java:704", "document", "node", "store", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "localmanualcach", "local", "manual", "cach", "load", "localcach", "java:4724", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "loadingvaluerefer", "loadfutur", "load", "valu", "refer", "load", "futur", "localcach", "java:3522", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "loadsync", "load", "sync", "localcach", "java:2315", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "lockedgetorload", "lock", "get", "or", "load", "localcach", "java:2278", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "get", "localcach", "java:2193", "local", "cach", "noformat"], "B_title": "NoSuchElementException thrown by NodeDocument", "B_clean_title": ["nosuchelementexcept", "no", "such", "element", "except", "thrown", "by", "nodedocu", "node", "document"]},
{"A_title": "Incorrect mapping of the MET time zoneThis timezone is mapped to Asia/Tehran in DateTimeZone. It should be middle europena time.", "A_clean_title": ["incorrect", "map", "met", "time", "zonethi", "zone", "thi", "timezon", "map", "asia", "tehran", "datetimezon", "date", "time", "zone", "it", "middl", "europena", "time"], "B_title": "3216471 Time-zone ID MET from java.util.TimeZone is now mapped correctly. Other time-zone conversions have been updated appropriately", "B_clean_title": ["3216471", "time", "zone", "id", "met", "java", "util", "timezon", "time", "zone", "now", "map", "correctli", "other", "time", "zone", "convers", "have", "been", "updat", "appropri"]},
{"A_title": "getKernel fails for buckets with only multiple instances of the same value in random.EmpiricalDistributionAfter loading a set of values into an EmpericalDistribution assume that theres a case where a single bin ONLY contains multiple instances of the same value.  In this case the standard deviation will equal zero.  This will fail when getKernel attempts to create a NormalDistribution.  The other case where stddev=0 is when there is only a single value in the bin and this is handled by returning a ConstantRealDistribution rather than a NormalDistrbution.  See: https://issues.apache.org/jira/browse/MATH-984", "A_clean_title": ["getkernel", "get", "kernel", "fail", "bucket", "onli", "multipl", "instanc", "same", "valu", "random", "empiricaldistributionaft", "empir", "distribut", "after", "load", "set", "valu", "into", "empericaldistribut", "emper", "distribut", "assum", "that", "there", "case", "where", "singl", "bin", "onli", "contain", "multipl", "instanc", "same", "valu", "thi", "case", "standard", "deviat", "will", "equal", "zero", "thi", "will", "fail", "when", "getkernel", "get", "kernel", "attempt", "creat", "normaldistribut", "normal", "distribut", "other", "case", "where", "stddev=0", "when", "there", "onli", "singl", "valu", "bin", "thi", "handl", "by", "return", "constantrealdistribut", "constant", "real", "distribut", "rather", "than", "normaldistrbut", "normal", "distrbut", "see", "http", "984", "apach", "issu", "org", "jira", "brows", "math"], "B_title": "Made getKernel return a constant distribution for zero variance bins.  JIRA: MATH-1203.", "B_clean_title": ["made", "getkernel", "get", "kernel", "return", "constant", "distribut", "zero", "varianc", "bin", "jira", "math", "1203"]},
{"A_title": "Parallel execution of ConcurrentReadAccessControlledTreeTest fails with MongoMKThe is caused by concurrent creation of test content and the conflict it creates in the index. Every Oak test instance tries to create /oak:index/nodetype/:index/nt%3Afile but only one will succeed. AFAICS there are two options how to handle this:  - Implement conflict annotation (OAK-1185) though Im not sure this will really work. On commit the rebase happens first when changes from the other Oak instance may not be visible yet. Then the commit hook runs and perform another branch commit with the changes which works fine. Only the last step fails when MongoMK tries to merge the branch. This is the point when the conflict may be detected.  - Implement a retry logic in MongoMK/NS", "A_clean_title": ["parallel", "execut", "concurrentreadaccesscontrolledtreetest", "concurr", "read", "access", "control", "tree", "test", "fail", "mongomkth", "mongo", "mk", "caus", "by", "concurr", "creation", "test", "content", "conflict", "it", "creat", "index", "everi", "oak", "test", "instanc", "tri", "creat", "oak", "index", "nodetyp", "index", "nt", "3afil", "but", "onli", "one", "will", "succeed", "afaic", "there", "are", "two", "option", "how", "handl", "thi", "implement", "conflict", "annot", "oak", "1185", "though", "im", "not", "sure", "thi", "will", "realli", "work", "commit", "rebas", "happen", "first", "when", "chang", "other", "oak", "instanc", "may", "not", "visibl", "yet", "then", "commit", "hook", "run", "perform", "anoth", "branch", "commit", "chang", "which", "work", "fine", "onli", "last", "step", "fail", "when", "mongomk", "mongo", "mk", "tri", "merg", "branch", "thi", "point", "when", "conflict", "may", "detect", "implement", "retri", "logic", "mongomk", "ns", "mongo", "mk"], "B_title": "Parallel execution of ConcurrentReadAccessControlledTreeTest fails with MongoMK - change MongoMK.reset() to actually undo the commits applying the reverse diff is not sufficient - additional tests", "B_clean_title": ["parallel", "execut", "concurrentreadaccesscontrolledtreetest", "concurr", "read", "access", "control", "tree", "test", "fail", "mongomk", "mongo", "mk", "chang", "mongomk", "reset", "mongo", "mk", "actual", "undo", "commit", "appli", "revers", "diff", "not", "suffici", "addit", "test"]},
{"A_title": "JSCompiler does not recursively resolve typedefsNone", "A_clean_title": ["jscompil", "js", "compil", "not", "recurs", "resolv", "typedefsnon", "typedef", "none"], "B_title": "When expanding goog.scope aliases in type expressions do not expand the alias until previous aliases have been expanded. fixes issue 772", "B_clean_title": ["when", "expand", "goog", "scope", "alias", "type", "express", "not", "expand", "alia", "until", "previou", "alias", "have", "been", "expand", "fix", "issu", "772"]},
{"A_title": "PackageMapper - Could not resolve classIt seems that the PackageMapper try to resolve much more than it is supposed to do for instance if Ive 2 pages test1/TestPage1 and test2/TestPage2 then it tries to resolve test2/TestPage1 when I reach the page1...   WARN  - WicketObjects              - Could not resolve class com.mycompany.test2.TestPage1 java.lang.ClassNotFoundException: com.mycompany.test2.TestPage1     at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1714)     at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1559)     at java.lang.Class.forName0(Native Method)     at java.lang.Class.forName(Class.java:270)     at org.apache.wicket.application.AbstractClassResolver.resolveClass(AbstractClassResolver.java:108)     at org.apache.wicket.core.util.lang.WicketObjects.resolveClass(WicketObjects.java:71)     at org.apache.wicket.core.request.mapper.AbstractComponentMapper.getPageClass(AbstractComponentMapper.java:134)     at org.apache.wicket.core.request.mapper.PackageMapper.parseRequest(PackageMapper.java:152)     at org.apache.wicket.core.request.mapper.AbstractBookmarkableMapper.mapRequest(AbstractBookmarkableMapper.java:322)     at org.apache.wicket.request.mapper.CompoundRequestMapper.mapRequest(CompoundRequestMapper.java:152)     at org.apache.wicket.request.cycle.RequestCycle.resolveRequestHandler(RequestCycle.java:189)     at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:219)     at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:293)     at org.apache.wicket.protocol.http.WicketFilter.processRequestCycle(WicketFilter.java:261)     at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:203)     at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:284)", "A_clean_title": ["packagemapp", "packag", "mapper", "could", "not", "resolv", "classit", "class", "it", "seem", "that", "packagemapp", "packag", "mapper", "tri", "resolv", "much", "more", "than", "it", "suppos", "instanc", "ive", "page", "test1", "testpage1", "test", "page1", "test2", "testpage2", "test", "page2", "then", "it", "tri", "resolv", "test2", "testpage1", "test", "page1", "when", "reach", "page1", "warn", "wicketobject", "wicket", "object", "could", "not", "resolv", "class", "com", "mycompani", "test2", "testpage1", "test", "page1", "java", "lang", "classnotfoundexcept", "class", "not", "found", "except", "com", "mycompani", "test2", "testpage1", "test", "page1", "at", "org", "apach", "catalina", "loader", "webappclassload", "loadclass", "webapp", "class", "loader", "load", "class", "webappclassload", "java:1714", "webapp", "class", "loader", "at", "org", "apach", "catalina", "loader", "webappclassload", "loadclass", "webapp", "class", "loader", "load", "class", "webappclassload", "java:1559", "webapp", "class", "loader", "at", "java", "lang", "class", "forname0", "name0", "nativ", "method", "at", "java", "lang", "class", "fornam", "name", "class", "java:270", "at", "org", "apach", "wicket", "applic", "abstractclassresolv", "resolveclass", "abstract", "class", "resolv", "resolv", "class", "abstractclassresolv", "java:108", "abstract", "class", "resolv", "at", "org", "apach", "wicket", "core", "util", "lang", "wicketobject", "resolveclass", "wicket", "object", "resolv", "class", "wicketobject", "java:71", "wicket", "object", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractcomponentmapp", "getpageclass", "abstract", "compon", "mapper", "get", "page", "class", "abstractcomponentmapp", "java:134", "abstract", "compon", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "packagemapp", "parserequest", "packag", "mapper", "pars", "request", "packagemapp", "java:152", "packag", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractbookmarkablemapp", "maprequest", "abstract", "bookmark", "mapper", "map", "request", "abstractbookmarkablemapp", "java:322", "abstract", "bookmark", "mapper", "at", "org", "apach", "wicket", "request", "mapper", "compoundrequestmapp", "maprequest", "compound", "request", "mapper", "map", "request", "compoundrequestmapp", "java:152", "compound", "request", "mapper", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "resolverequesthandl", "request", "cycl", "resolv", "request", "handler", "requestcycl", "java:189", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:219", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:293", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequestcycl", "wicket", "filter", "process", "request", "cycl", "wicketfilt", "java:261", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:203", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:284", "wicket", "filter"], "B_title": "PackageMapper issue WICKET-5565. The compatibility score is not correct.", "B_clean_title": ["packagemapp", "packag", "mapper", "issu", "wicket", "5565", "compat", "score", "not", "correct"]},
{"A_title": "ConvergenceException in NormalDistributionImpl.cumulativeProbability()I get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity -Infinity. For instance in the following code: @Test public void testCumulative()  final NormalDistribution nd = new NormalDistributionImpl(); for (int i = 0; i < 500; i++)  final double val = Math.exp; try   System.out.println(val =  + val +  cumulative =  + nd.cumulativeProbability(val));   catch (MathException e)   e.printStackTrace(); fail();    In version 2.0 I get no exception.  My suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values) not just MaxIterationsExceededException.", "A_clean_title": ["convergenceexcept", "converg", "except", "normaldistributionimpl", "cumulativeprob", "normal", "distribut", "impl", "cumul", "probabl", "get", "convergenceexcept", "converg", "except", "normaldistributionimpl", "cumulativeprob", "normal", "distribut", "impl", "cumul", "probabl", "veri", "larg", "small", "paramet", "includ", "infin", "infin", "instanc", "follow", "code", "test", "public", "void", "testcumul", "test", "cumul", "final", "normaldistribut", "normal", "distribut", "nd", "new", "normaldistributionimpl", "normal", "distribut", "impl", "int", "500", "i++", "final", "doubl", "val", "math", "exp", "tri", "system", "out", "println", "val", "val", "cumul", "nd", "cumulativeprob", "cumul", "probabl", "val", "catch", "mathexcept", "math", "except", "printstacktrac", "print", "stack", "trace", "fail", "version", "get", "no", "except", "my", "suggest", "chang", "implement", "cumulativeprob", "cumul", "probabl", "doubl", "catch", "all", "convergenceexcept", "converg", "except", "return", "veri", "larg", "veri", "small", "valu", "not", "just", "maxiterationsexceededexcept", "max", "iter", "exceed", "except"], "B_title": "Modified NormalDistributionImpl.cumulativeProbability to return 0 or 1 respectively for values more than 40 standard deviations from the mean. For these values the actual probability is indistinguishable from 0 or 1 as a double.  Top coding improves performance for extreme values and prevents convergence exceptions.", "B_clean_title": ["modifi", "normaldistributionimpl", "cumulativeprob", "normal", "distribut", "impl", "cumul", "probabl", "return", "or", "respect", "valu", "more", "than", "40", "standard", "deviat", "mean", "these", "valu", "actual", "probabl", "indistinguish", "or", "as", "doubl", "top", "code", "improv", "perform", "extrem", "valu", "prevent", "converg", "except"]},
{"A_title": "Node not accessible after document splitIn a cluster setup it may happen that a node becomes inaccessible when all remaining local revision entries after a split are not yet visible to a cluster node.", "A_clean_title": ["node", "not", "access", "after", "document", "splitin", "split", "cluster", "setup", "it", "may", "happen", "that", "node", "becom", "inaccess", "when", "all", "remain", "local", "revis", "entri", "after", "split", "are", "not", "yet", "visibl", "cluster", "node"], "B_title": "Node not accessible after document split", "B_clean_title": ["node", "not", "access", "after", "document", "split"]},
{"A_title": "Locking issues seen with CopyOnWrite mode enabledWhen CopyOnWrite mode is enabled and incremental mode is enabled i.e. indexPath property set then failure in any indexing cycle would prevent further indexing from progressing. For e.g. if any indexing cycle fails then subsequent indexing cycle would fail with Lucene locking related exception  noformat Caused by: org.apache.lucene.store.LockObtainFailedException: Lock obtain timed out: NativeFSLock@/tmp/junit8067118705344013640/2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7ae/1/write.lock at org.apache.lucene.store.Lock.obtain(Lock.java:89) at org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:707) at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorContext.getWriter(LuceneIndexEditorContext.java:169) at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.addOrUpdate(LuceneIndexEditor.java:293) ... 37 more noformat  Any further indexing would continue to fail with this exception", "A_clean_title": ["lock", "issu", "seen", "copyonwrit", "copi", "write", "mode", "enabledwhen", "enabl", "when", "copyonwrit", "copi", "write", "mode", "enabl", "increment", "mode", "enabl", "indexpath", "index", "path", "properti", "set", "then", "failur", "ani", "index", "cycl", "would", "prevent", "further", "index", "progress", "ani", "index", "cycl", "fail", "then", "subsequ", "index", "cycl", "would", "fail", "lucen", "lock", "relat", "except", "noformat", "caus", "by", "org", "apach", "lucen", "store", "lockobtainfailedexcept", "lock", "obtain", "fail", "except", "lock", "obtain", "time", "out", "nativefslock", "nativ", "fs", "lock", "lock", "tmp", "junit8067118705344013640", "2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7a", "write", "at", "org", "apach", "lucen", "store", "lock", "obtain", "lock", "java:89", "at", "org", "apach", "lucen", "index", "indexwrit", "index", "writer", "init", "indexwrit", "java:707", "index", "writer", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexeditorcontext", "getwrit", "lucen", "index", "editor", "context", "get", "writer", "luceneindexeditorcontext", "java:169", "lucen", "index", "editor", "context", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexeditor", "addorupd", "lucen", "index", "editor", "add", "or", "updat", "luceneindexeditor", "java:293", "lucen", "index", "editor", "37", "more", "noformat", "ani", "further", "index", "would", "continu", "fail", "thi", "except"], "B_title": "- Locking issues seen with CopyOnWrite mode enabled", "B_clean_title": ["lock", "issu", "seen", "copyonwrit", "copi", "write", "mode", "enabl"]},
{"A_title": "Make Mockito JUnit rule easier to useMockito JUnit rule easier to use by avoiding the need to pass test instance. Make it compatible with JUnit 4.7+ instead of 4.9+.", "A_clean_title": ["make", "mockito", "junit", "unit", "rule", "easier", "usemockito", "use", "mockito", "junit", "unit", "rule", "easier", "use", "by", "avoid", "need", "pass", "test", "instanc", "make", "it", "compat", "junit", "unit", "7+", "instead", "9+"], "B_title": "Inform the user with a good message when she tries to callRealMethod() on a mock of a interface. Fixed issue 140", "B_clean_title": ["inform", "user", "good", "messag", "when", "she", "tri", "callrealmethod", "call", "real", "method", "mock", "interfac", "fix", "issu", "140"]},
{"A_title": "key.followingKey(PartialKey.ROW_COLFAM_COLQUAL_COLVIS) can produce a key with an invalid COLVISNeed a new algorithm for calculating the next biggest column visibility because tagging 0 to the end creates an invalid column visibility. We might be able to minimize the timestamp for this (i.e. set timestamp to Long.MIN_VALUE but keep column and row elements the same).", "A_clean_title": ["key", "followingkey", "follow", "key", "partialkey", "partial", "key", "row", "colfam", "colqual", "colvi", "produc", "key", "invalid", "colvisne", "colvi", "need", "new", "algorithm", "calcul", "next", "biggest", "column", "visibl", "becaus", "tag", "end", "creat", "invalid", "column", "visibl", "we", "might", "abl", "minim", "timestamp", "thi", "set", "timestamp", "long", "min", "valu", "but", "keep", "column", "row", "element", "same"], "B_title": "merged to trunk", "B_clean_title": ["merg", "trunk"]},
{"A_title": "Calling addNode on a node that has orderable child nodes violates specificationit seems to me that the current behavior of Node.addNode for a node that  has orderable child nodes violates the specification (section 23.3):  quote 23.3 Adding a New Child Node When a child node is added to a node that has orderable child nodes it is added to the end of the list. quote  however the following test will fail:  code @Test     public void testAddNode() throws Exception          new TestContentLoader().loadTestContent(getAdminSession());          Session session = getAdminSession();         Node test = session.getRootNode().addNode(test test:orderableFolder);         assertTrue(test.getPrimaryNodeType().hasOrderableChildNodes());          Node n1 = test.addNode(a);         Node n2 = test.addNode(b);         session.save();          NodeIterator it = test.getNodes();         assertEquals(a it.nextNode().getName());         assertEquals(b it.nextNode().getName());      code", "A_clean_title": ["call", "addnod", "add", "node", "node", "that", "ha", "order", "child", "node", "violat", "specificationit", "seem", "me", "that", "current", "behavior", "node", "addnod", "add", "node", "node", "that", "ha", "order", "child", "node", "violat", "specif", "section", "23", "quot", "23", "ad", "new", "child", "node", "when", "child", "node", "ad", "node", "that", "ha", "order", "child", "node", "it", "ad", "end", "list", "quot", "howev", "follow", "test", "will", "fail", "code", "test", "public", "void", "testaddnod", "test", "add", "node", "throw", "except", "new", "testcontentload", "test", "content", "loader", "loadtestcont", "load", "test", "content", "getadminsess", "get", "admin", "session", "session", "session", "getadminsess", "get", "admin", "session", "node", "test", "session", "getrootnod", "get", "root", "node", "addnod", "add", "node", "test", "test", "orderablefold", "order", "folder", "asserttru", "assert", "true", "test", "getprimarynodetyp", "get", "primari", "node", "type", "hasorderablechildnod", "ha", "order", "child", "node", "node", "n1", "test", "addnod", "add", "node", "node", "n2", "test", "addnod", "add", "node", "session", "save", "nodeiter", "node", "iter", "it", "test", "getnod", "get", "node", "assertequ", "assert", "equal", "it", "nextnod", "next", "node", "getnam", "get", "name", "assertequ", "assert", "equal", "it", "nextnod", "next", "node", "getnam", "get", "name", "code"], "B_title": "Calling addNode on a node that has orderable child nodes violates specification", "B_clean_title": ["call", "addnod", "add", "node", "node", "that", "ha", "order", "child", "node", "violat", "specif"]},
{"A_title": "StatelessForm submitted to the wrong pageI made a small application to reproduce the problem. You can download it from http://aditsu.net/wickettest.zip  Ill try to attach it too. Dependencies: jetty 6 wicket 1.4-m3 slf4j log4j Steps to reproduce: 1. Run the test.Start class 2. Open http://localhost:8080 in a browser 3. Open http://localhost:8080/page2 in a new tab 4. Go to the first tab and click submit  Result:  WicketRuntimeException: unable to find component with path form on stateless page Page class = test.Page2 id = 0 version = 0  It looks like the 2 pages are created with the same id in 2 different pagemaps but when I submit the form it goes to the second pagemap and finds the second page (with no form on it).", "A_clean_title": ["statelessform", "stateless", "form", "submit", "wrong", "pagei", "page", "made", "small", "applic", "reproduc", "problem", "you", "download", "it", "http", "zip", "aditsu", "net", "wickettest", "ill", "tri", "attach", "it", "too", "depend", "jetti", "wicket", "m3", "slf4j", "log4j", "step", "reproduc", "run", "test", "start", "class", "open", "http", "localhost:8080", "browser", "open", "http", "localhost:8080", "page2", "new", "tab", "go", "first", "tab", "click", "submit", "result", "wicketruntimeexcept", "wicket", "runtim", "except", "unabl", "find", "compon", "path", "form", "stateless", "page", "page", "class", "test", "page2", "id", "version", "it", "look", "like", "page", "are", "creat", "same", "id", "differ", "pagemap", "but", "when", "submit", "form", "it", "goe", "second", "pagemap", "find", "second", "page", "no", "form", "it"], "B_title": "StatelessForm submitted to the wrong page Issue: WICKET-1897", "B_clean_title": ["statelessform", "stateless", "form", "submit", "wrong", "page", "issu", "wicket", "1897"]},
{"A_title": "BaseWicketTester#startComponentInPage fails for pages with <wicket:header-items></wicket:header> placeholderI am using the BaseWicketTester.html#startComponentInPage(C)|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#startComponentInPage(C) to validate individual components/panels.  I am overriding the BaseWicketTester.html#createPage()|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#createPage() and BaseWicketTester.html#createPageMarkup(java.lang.String)|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#createPageMarkup(java.lang.String) methods to return a dummy page that contains a placeholder for components-to-be-tested. The dummy page extends my base page class.  My base page class makes use of the <wicket:header-items/>|https://cwiki.apache.org/confluence/display/WICKET/Wickets+XHTML+tags#WicketsXHTMLtags-Elementwicket:header-items placeholder tag.  When attempting to use BaseWicketTester.html#createPage()|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#createPage() method the method fails with the following error message: |Error while parsing the markup for the autogenerated page: More than one <wicket:header-items/> detected in the <head> element. Only one is allowed.  If I remove the <wicket:header-items/>|https://cwiki.apache.org/confluence/display/WICKET/Wickets+XHTML+tags#WicketsXHTMLtags-Elementwicket:header-items placeholder tag from my base page class the test runs successfully.  The test only fails when using the BaseWicketTester.html#startComponentInPage(C)|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#startComponentInPage(C) which only accepts one argument. If I use the BaseWicketTester.html#startComponentInPage(C org.apache.wicket.markup.IMarkupFragment)|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#startComponentInPage(C org.apache.wicket.markup.IMarkupFragment) and pass in the MarkupFragment of the test class as the second argument then the test runs successfully e.g.  code tester.startComponentInPage(new MyPanel(DummyPanelPage.TEST_PANEL_ID)  new MyDummyPanelPage(new PageParameters()).getMarkup()); code  It would seem that the <wicket:header-items/>|https://cwiki.apache.org/confluence/display/WICKET/Wickets+XHTML+tags#WicketsXHTMLtags-Elementwicket:header-items placeholder tag clashes with the ContainerInfo|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/markup/ContainerInfo.html class used by the testing framework but this is by no means my area of expertise.  I am attaching a quick-start app with a TestHomePage test class that reproduces the issue.  Thank you in advance!", "A_clean_title": ["basewickettest", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "fail", "page", "wicket", "header", "item", "wicket", "header", "placeholderi", "placehold", "am", "basewickettest", "html", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "valid", "individu", "compon", "panel", "am", "overrid", "basewickettest", "html", "base", "wicket", "tester", "createpag", "creat", "page", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "createpag", "creat", "page", "basewickettest", "html", "base", "wicket", "tester", "createpagemarkup", "creat", "page", "markup", "java", "lang", "string", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "createpagemarkup", "creat", "page", "markup", "java", "lang", "string", "method", "return", "dummi", "page", "that", "contain", "placehold", "compon", "test", "dummi", "page", "extend", "my", "base", "page", "class", "my", "base", "page", "class", "make", "use", "wicket", "header", "item", "|http", "apach", "cwiki", "org", "confluenc", "display", "wicket", "wickets+xhtml+tag", "wicketsxhtmltag", "elementwicket", "wicket", "xhtm", "ltag", "header", "item", "placehold", "tag", "when", "attempt", "use", "basewickettest", "html", "base", "wicket", "tester", "createpag", "creat", "page", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "createpag", "creat", "page", "method", "method", "fail", "follow", "error", "messag", "|error", "while", "pars", "markup", "autogener", "page", "more", "than", "one", "wicket", "header", "item", "detect", "head", "element", "onli", "one", "allow", "remov", "wicket", "header", "item", "|http", "apach", "cwiki", "org", "confluenc", "display", "wicket", "wickets+xhtml+tag", "wicketsxhtmltag", "elementwicket", "wicket", "xhtm", "ltag", "header", "item", "placehold", "tag", "my", "base", "page", "class", "test", "run", "success", "test", "onli", "fail", "when", "basewickettest", "html", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "which", "onli", "accept", "one", "argument", "use", "basewickettest", "html", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "org", "apach", "wicket", "markup", "imarkupfrag", "markup", "fragment", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "org", "apach", "wicket", "markup", "imarkupfrag", "markup", "fragment", "pass", "markupfrag", "markup", "fragment", "test", "class", "as", "second", "argument", "then", "test", "run", "success", "code", "tester", "startcomponentinpag", "start", "compon", "page", "new", "mypanel", "my", "panel", "dummypanelpag", "dummi", "panel", "page", "test", "panel", "id", "new", "mydummypanelpag", "my", "dummi", "panel", "page", "new", "pageparamet", "page", "paramet", "getmarkup", "get", "markup", "code", "it", "would", "seem", "that", "wicket", "header", "item", "|http", "apach", "cwiki", "org", "confluenc", "display", "wicket", "wickets+xhtml+tag", "wicketsxhtmltag", "elementwicket", "wicket", "xhtm", "ltag", "header", "item", "placehold", "tag", "clash", "containerinfo|http", "contain", "info|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "markup", "containerinfo", "contain", "info", "class", "use", "by", "test", "framework", "but", "thi", "by", "no", "mean", "my", "area", "expertis", "am", "attach", "quick", "start", "app", "testhomepag", "test", "home", "page", "test", "class", "that", "reproduc", "issu", "thank", "you", "advanc"], "B_title": "BaseWicketTester#startComponentInPage fails for pages with <wicket:header-items></wicket:header> placeholder", "B_clean_title": ["basewickettest", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "fail", "page", "wicket", "header", "item", "wicket", "header", "placehold"]},
{"A_title": "Obvious optimizations dont works in inline ifNone", "A_clean_title": ["obviou", "optim", "dont", "work", "inlin", "ifnon", "none"], "B_title": "Fix more regressions caused by TRUE/FALSE denormalization. Fixes issue 413", "B_clean_title": ["fix", "more", "regress", "caus", "by", "true", "fals", "denorm", "fix", "issu", "413"]},
{"A_title": "Error while configuring analyzer by compositionError while creating analyzer by composition from osgi due to an illegal argument jcr:primaryType passed to TokenizerFactory.forName(clazz args) in NodeStateAnalyzerFactory.loadTokenizer()  noformat Caused by: java.lang.IllegalArgumentException: Unknown parameters: jcr:primaryType=nt:unstructured at org.apache.lucene.analysis.core.LowerCaseFilterFactory.<init>(LowerCaseFilterFactory.java:45) noformat", "A_clean_title": ["error", "while", "configur", "analyz", "by", "compositionerror", "composit", "error", "while", "creat", "analyz", "by", "composit", "osgi", "due", "illeg", "argument", "jcr", "primarytyp", "primari", "type", "pass", "tokenizerfactori", "fornam", "token", "factori", "name", "clazz", "arg", "nodestateanalyzerfactori", "loadtoken", "node", "state", "analyz", "factori", "load", "token", "noformat", "caus", "by", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "unknown", "paramet", "jcr", "primarytype=nt", "primari", "type=nt", "unstructur", "at", "org", "apach", "lucen", "analysi", "core", "lowercasefilterfactori", "lower", "case", "filter", "factori", "init", "lowercasefilterfactori", "java:45", "lower", "case", "filter", "factori", "noformat"], "B_title": "- Error while configuring analyzer by composition", "B_clean_title": ["error", "while", "configur", "analyz", "by", "composit"]},
{"A_title": "Beta LogNormalDistribution WeibullDistribution give slightly wrong answer for extremely small args due to log/exp inaccuracyBackground for those who arent familiar: math libs like Math and FastMath have two mysterious methods log1p and expm1. log1p(x) = log(1+x) and expm1(x) = exp(x)-1 mathetmatically but can return a correct answer even when x was small where floating-point error due to the addition/subtraction introduces a relatively large error.  There are three instances in the code that can employ these specialized methods and gain a measurable improvement in accuracy. See patch and tests for an example -- try the tests without the code change to see the error.", "A_clean_title": ["beta", "lognormaldistribut", "log", "normal", "distribut", "weibulldistribut", "weibul", "distribut", "give", "slightli", "wrong", "answer", "extrem", "small", "arg", "due", "log", "exp", "inaccuracybackground", "inaccuraci", "background", "those", "who", "arent", "familiar", "math", "lib", "like", "math", "fastmath", "fast", "math", "have", "two", "mysteri", "method", "log1p", "expm1", "log1p", "log", "1+x", "expm1", "exp", "mathetmat", "but", "return", "correct", "answer", "even", "when", "wa", "small", "where", "float", "point", "error", "due", "addit", "subtract", "introduc", "rel", "larg", "error", "there", "are", "three", "instanc", "code", "that", "employ", "these", "special", "method", "gain", "measur", "improv", "accuraci", "see", "patch", "test", "exampl", "tri", "test", "without", "code", "chang", "see", "error"], "B_title": "Precision improvements by using expm1 and log1p. Thanks to Sean Owen.", "B_clean_title": ["precis", "improv", "by", "expm1", "log1p", "thank", "sean", "owen"]},
{"A_title": "onBeforeRender called too early on stateless pageIm having a problem with a ListView that displays an outdated list. In my test the ListView uses a Model that returns a static variable just to make sure the model is independent from any page instance. As far as I can tell this problem has nothing to do with the model but with the way Wicket prepares for a request listener invocation.  The exact setup is this: - the page contains a ListView and (outside of the list) a Link that adds an item to the list in its onClick(). The list itself is stored in a static variable. - the page is stateless - the pages components are created in onInitialize()  Result: The list doesnt show the most recently added item. Reloading the original page shows the correct list. Note that by reloading I mean entering the pages original URL since the browsers address bar now contains the request listener URL due to the page being stateless.  This is how I think is happens: - Initially rendering the page works fine. The page is then discarded since its stateless. - Clicking on the link creates a new page instance to invoke the links request listener. - IPageAndComponentProvider.getComponent() cannot find the link yet since it is not created until onInitialize() has been called. - as a consequence it calls page.internalInitialize() and internalPrepareForRender(false) - this creates the link but it also creates the ListView and prepares it for rendering. This in turn polls the ListViews model and creates list items. It also marks the ListView as prepared for render which is the crucial point. - The links request listener runs and adds an item to the list. - After the request listener handler the page render handler runs - That handler renders the page including the ListView - ... but it doesnt call onBeforeRender() on the ListView anymore because its already marked as prepared for render! So it doesnt pick up the new up-to-date list from its model.  Im not sure if Im doing it wrong but then it doesnt seem quite right that onBeforeRender() gets called before invoking the listener but not actually before rendering. Theres probably some kind of logic behind the decision to run onBeforeRender() only when this hasnt yet happened right? Is there a general way to unprepare the component in onClick()?  --- Re: #internalPrepareForRender(false) should not mark the page as rendered (thus the false parameter).  The problem is I think not that the component is being marked as *rendered* but as *prepared for render*. From class Component:  protected void onBeforeRender()    setFlag(FLAG_PREPARED_FOR_RENDER true);   onBeforeRenderChildren();   setRequestFlag(RFLAG_BEFORE_RENDER_SUPER_CALL_VERIFIED true);   Note the first line. This causes subsequent invocations of internalBeforeRender() to skip the relevant part.", "A_clean_title": ["onbeforerend", "befor", "render", "call", "too", "earli", "stateless", "pageim", "page", "im", "have", "problem", "listview", "list", "view", "that", "display", "outdat", "list", "my", "test", "listview", "list", "view", "use", "model", "that", "return", "static", "variabl", "just", "make", "sure", "model", "independ", "ani", "page", "instanc", "as", "far", "as", "tell", "thi", "problem", "ha", "noth", "model", "but", "way", "wicket", "prepar", "request", "listen", "invoc", "exact", "setup", "thi", "page", "contain", "listview", "list", "view", "outsid", "list", "link", "that", "add", "item", "list", "it", "onclick", "click", "list", "itself", "store", "static", "variabl", "page", "stateless", "page", "compon", "are", "creat", "oniniti", "initi", "result", "list", "doesnt", "show", "most", "recent", "ad", "item", "reload", "origin", "page", "show", "correct", "list", "note", "that", "by", "reload", "mean", "enter", "page", "origin", "url", "sinc", "browser", "address", "bar", "now", "contain", "request", "listen", "url", "due", "page", "be", "stateless", "thi", "how", "think", "happen", "initi", "render", "page", "work", "fine", "page", "then", "discard", "sinc", "it", "stateless", "click", "link", "creat", "new", "page", "instanc", "invok", "link", "request", "listen", "ipageandcomponentprovid", "getcompon", "page", "compon", "provid", "get", "compon", "not", "find", "link", "yet", "sinc", "it", "not", "creat", "until", "oniniti", "initi", "ha", "been", "call", "as", "consequ", "it", "call", "page", "internaliniti", "intern", "initi", "internalprepareforrend", "intern", "prepar", "render", "fals", "thi", "creat", "link", "but", "it", "also", "creat", "listview", "list", "view", "prepar", "it", "render", "thi", "turn", "poll", "listview", "list", "view", "model", "creat", "list", "item", "it", "also", "mark", "listview", "list", "view", "as", "prepar", "render", "which", "crucial", "point", "link", "request", "listen", "run", "add", "item", "list", "after", "request", "listen", "handler", "page", "render", "handler", "run", "that", "handler", "render", "page", "includ", "listview", "list", "view", "but", "it", "doesnt", "call", "onbeforerend", "befor", "render", "listview", "list", "view", "anymor", "becaus", "it", "alreadi", "mark", "as", "prepar", "render", "so", "it", "doesnt", "pick", "up", "new", "up", "date", "list", "it", "model", "im", "not", "sure", "im", "do", "it", "wrong", "but", "then", "it", "doesnt", "seem", "quit", "right", "that", "onbeforerend", "befor", "render", "get", "call", "befor", "invok", "listen", "but", "not", "actual", "befor", "render", "there", "probabl", "some", "kind", "logic", "behind", "decis", "run", "onbeforerend", "befor", "render", "onli", "when", "thi", "hasnt", "yet", "happen", "right", "there", "gener", "way", "unprepar", "compon", "onclick", "click", "re", "internalprepareforrend", "intern", "prepar", "render", "fals", "not", "mark", "page", "as", "render", "thu", "fals", "paramet", "problem", "think", "not", "that", "compon", "be", "mark", "as", "render", "but", "as", "prepar", "render", "class", "compon", "protect", "void", "onbeforerend", "befor", "render", "setflag", "set", "flag", "flag", "prepar", "render", "true", "onbeforerenderchildren", "befor", "render", "children", "setrequestflag", "set", "request", "flag", "rflag", "befor", "render", "super", "call", "verifi", "true", "note", "first", "line", "thi", "caus", "subsequ", "invoc", "internalbeforerend", "intern", "befor", "render", "skip", "relev", "part"], "B_title": "always reset FLAG_PREPARED_FOR_RENDER so stateless page is re-prepared before next render", "B_clean_title": ["alway", "reset", "flag", "prepar", "render", "so", "stateless", "page", "re", "prepar", "befor", "next", "render"]},
{"A_title": "404 Error on Nested ModalWindows in IE7 and IE8When opening a ModalWindow inside a ModalWindow the inner ModalWindow generates a 404 error.  Both windows use a PageCreator for content.  To replicate you must use an actual IE 7 or IE 8 browser as this does not replicate using developer tools and setting the document and brower to IE 7.  The problem can be seen at http://www.wicket-library.com/wicket-examples/ajax/modal-window.  I will attach a Quickstart as well.", "A_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8when", "open", "modalwindow", "modal", "window", "insid", "modalwindow", "modal", "window", "inner", "modalwindow", "modal", "window", "gener", "404", "error", "both", "window", "use", "pagecr", "page", "creator", "content", "replic", "you", "must", "use", "actual", "ie", "or", "ie", "browser", "as", "thi", "not", "replic", "develop", "tool", "set", "document", "brower", "ie", "problem", "seen", "at", "http", "window", "wicket", "librari", "exampl", "ajax", "modal", "www", "com", "wicket", "will", "attach", "quickstart", "as", "well"], "B_title": "404 Error on Nested ModalWindows in IE7 and IE8", "B_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8"]},
{"A_title": "chiSquare(double expected long observed) is returning incorrect test statisticChiSquareTestImpl is returning incorrect chi-squared value. An implicit assumption of public double chiSquare(double expected long observed) is that the sum of expected and observed are equal. That is in the code: for (int i = 0; i < observed.length; i++)               dev = ((double) observedi - expectedi);             sumSq += dev * dev / expectedi;          this calculation is only correct if sum(observed)==sum(expected). When they are not equal then one must rescale the expected value by sum(observed) / sum(expected) so that they are. Ironically it is an example in the unit test ChiSquareTestTest that highlights the error: long observed1 =   500 623 72 70 31  ;         double expected1 =   485 541 82 61 37  ;         assertEquals( chi-square test statistic 16.4131070362 testStatistic.chiSquare(expected1 observed1) 1E-10);         assertEquals(chi-square p-value 0.002512096 testStatistic.chiSquareTest(expected1 observed1) 1E-9); 16.413 is not correct because the expected values do not make sense they should be: 521.19403 581.37313  88.11940  65.55224  39.76119 so that the sum of expected equals 1296 which is the sum of observed. Here is some R code (r-project.org) which proves it: > o1 1 500 623  72  70  31 > e1 1 485 541  82  61  37 > chisq.test(o1p=e1rescale.p=TRUE)         Chi-squared test for given probabilities data:  o1  X-squared = 9.0233 df = 4 p-value = 0.06052 > chisq.test(o1p=e1rescale.p=TRUE) observed 1 500 623  72  70  31 > chisq.test(o1p=e1rescale.p=TRUE) expected 1 521.19403 581.37313  88.11940  65.55224  39.76119", "A_clean_title": ["chisquar", "chi", "squar", "doubl", "expect", "long", "observ", "return", "incorrect", "test", "statisticchisquaretestimpl", "statist", "chi", "squar", "test", "impl", "return", "incorrect", "chi", "squar", "valu", "implicit", "assumpt", "public", "doubl", "chisquar", "chi", "squar", "doubl", "expect", "long", "observ", "that", "sum", "expect", "observ", "are", "equal", "that", "code", "int", "observ", "length", "i++", "dev", "doubl", "observedi", "expectedi", "sumsq", "sum", "sq", "dev", "dev", "expectedi", "thi", "calcul", "onli", "correct", "sum", "observ", "==sum", "expect", "when", "they", "are", "not", "equal", "then", "one", "must", "rescal", "expect", "valu", "by", "sum", "observ", "sum", "expect", "so", "that", "they", "are", "iron", "it", "exampl", "unit", "test", "chisquaretesttest", "chi", "squar", "test", "test", "that", "highlight", "error", "long", "observed1", "500", "623", "72", "70", "31", "doubl", "expected1", "485", "541", "82", "61", "37", "assertequ", "assert", "equal", "chi", "squar", "test", "statist", "16", "4131070362", "teststatist", "chisquar", "test", "statist", "chi", "squar", "expected1", "observed1", "1e", "10", "assertequ", "assert", "equal", "chi", "squar", "valu", "002512096", "teststatist", "chisquaretest", "test", "statist", "chi", "squar", "test", "expected1", "observed1", "1e", "16", "413", "not", "correct", "becaus", "expect", "valu", "not", "make", "sens", "they", "521", "19403", "581", "37313", "88", "11940", "65", "55224", "39", "76119", "so", "that", "sum", "expect", "equal", "1296", "which", "sum", "observ", "here", "some", "code", "project", "org", "which", "prove", "it", "o1", "500", "623", "72", "70", "31", "e1", "485", "541", "82", "61", "37", "chisq", "test", "o1p=e1rescal", "p=true", "chi", "squar", "test", "given", "probabl", "data", "o1", "squar", "0233", "df", "valu", "06052", "chisq", "test", "o1p=e1rescal", "p=true", "observ", "500", "623", "72", "70", "31", "chisq", "test", "o1p=e1rescal", "p=true", "expect", "521", "19403", "581", "37313", "88", "11940", "65", "55224", "39", "76119"], "B_title": "Added check and rescaling of expected counts to sum to sum of expected counts if necessary in ChiSquare test. JIRA: MATH-175 Reported and patched by Carl Anderson.", "B_clean_title": ["ad", "check", "rescal", "expect", "count", "sum", "sum", "expect", "count", "necessari", "chisquar", "chi", "squar", "test", "jira", "math", "175", "report", "patch", "by", "carl", "anderson"]},
{"A_title": "Integer overflow in OpenMapRealMatrixcomputeKey() has an integer overflow. Since it is a sparse matrix this is quite easily encountered long before heap space is exhausted. The attached code demonstrates the problem which could potentially be a security vulnerability (for example if one was to use this matrix to store access control information). Workaround: never create an OpenMapRealMatrix with more cells than are addressable with an int.", "A_clean_title": ["integ", "overflow", "openmaprealmatrixcomputekey", "open", "map", "real", "matrixcomput", "key", "ha", "integ", "overflow", "sinc", "it", "spars", "matrix", "thi", "quit", "easili", "encount", "long", "befor", "heap", "space", "exhaust", "attach", "code", "demonstr", "problem", "which", "could", "potenti", "secur", "vulner", "exampl", "one", "wa", "use", "thi", "matrix", "store", "access", "control", "inform", "workaround", "never", "creat", "openmaprealmatrix", "open", "map", "real", "matrix", "more", "cell", "than", "are", "address", "int"], "B_title": "Fixed an integer overflow in OpenMapRealMatrix.", "B_clean_title": ["fix", "integ", "overflow", "openmaprealmatrix", "open", "map", "real", "matrix"]},
{"A_title": "Inconsistent handling of invalid names/pathsPassing an invalid name to a JCR method might or might not throw a RepositoryException depending on whether name re-mappings exist or not:  code session.itemExists(/jcr:content); code  returns false if no name re-mappings exist but throws a RepositoryException otherwise.", "A_clean_title": ["inconsist", "handl", "invalid", "name", "pathspass", "path", "pass", "invalid", "name", "jcr", "method", "might", "or", "might", "not", "throw", "repositoryexcept", "repositori", "except", "depend", "whether", "name", "re", "map", "exist", "or", "not", "code", "session", "itemexist", "item", "exist", "jcr", "content", "code", "return", "fals", "no", "name", "re", "map", "exist", "but", "throw", "repositoryexcept", "repositori", "except", "otherwis"], "B_title": "Inconsistent handling of invalid names/paths", "B_clean_title": ["inconsist", "handl", "invalid", "name", "path"]},
{"A_title": "NPE in FormComponent#updateCollectionModel in case of no converted input and unmodifiable collectionThere are 2 issues with FormComponent#updateCollectionModel. 1) converted input is not checked for null before wrapping it to ArrayList 2) converted input is not checked for null then model returns unmodifiable collection. The both issues causes NPE.", "A_clean_title": ["npe", "formcompon", "form", "compon", "updatecollectionmodel", "updat", "collect", "model", "case", "no", "convert", "input", "unmodifi", "collectionther", "collect", "there", "are", "issu", "formcompon", "form", "compon", "updatecollectionmodel", "updat", "collect", "model", "convert", "input", "not", "check", "null", "befor", "wrap", "it", "arraylist", "array", "list", "convert", "input", "not", "check", "null", "then", "model", "return", "unmodifi", "collect", "both", "issu", "caus", "npe"], "B_title": "FormComponent#updateCollectionModel must check convertedInput for null before wrapping into ArrayListFormComponent#updateCollectionModel must check convertedInput for null before wrapping into ArrayList", "B_clean_title": ["formcompon", "form", "compon", "updatecollectionmodel", "updat", "collect", "model", "must", "check", "convertedinput", "convert", "input", "null", "befor", "wrap", "into", "arraylistformcompon", "array", "list", "form", "compon", "updatecollectionmodel", "updat", "collect", "model", "must", "check", "convertedinput", "convert", "input", "null", "befor", "wrap", "into", "arraylist", "array", "list"]},
{"A_title": "CreditCardValidator accepts invalid inputs(1) The onValidate() method of the CreditCardValidator class returns true for invalid inputs with null or unicode character such as 400000000000000.  (2) Also there is no length check on the input therefore even invalid length inputs such as 9845 are accepted.  (3) There is no check for invalid issuer identifier i.e.  840898920205250 is accepted where 84XXXX is not a valid issuer identifier", "A_clean_title": ["creditcardvalid", "credit", "card", "valid", "accept", "invalid", "input", "onvalid", "valid", "method", "creditcardvalid", "credit", "card", "valid", "class", "return", "true", "invalid", "input", "null", "or", "unicod", "charact", "such", "as", "400000000000000", "also", "there", "no", "length", "check", "input", "therefor", "even", "invalid", "length", "input", "such", "as", "9845", "are", "accept", "there", "no", "check", "invalid", "issuer", "identifi", "840898920205250", "accept", "where", "84xxxx", "not", "valid", "issuer", "identifi"], "B_title": "fixed CreditCardValidator accepts invalid inputs Issue: WICKET-2552", "B_clean_title": ["fix", "creditcardvalid", "credit", "card", "valid", "accept", "invalid", "input", "issu", "wicket", "2552"]},
{"A_title": "Upgrade should not overwrite new oak specific builtin nodetypesNone", "A_clean_title": ["upgrad", "not", "overwrit", "new", "oak", "specif", "builtin", "nodetypesnon", "nodetyp", "none"], "B_title": "Upgrade should not overwrite new oak specific builtin nodetypes", "B_clean_title": ["upgrad", "not", "overwrit", "new", "oak", "specif", "builtin", "nodetyp"]},
{"A_title": ".indexOf fails to produce missing property warningNone", "A_clean_title": ["indexof", "index", "fail", "produc", "miss", "properti", "warningnon", "warn", "none"], "B_title": "Treat the bottom function type as empty. Fixes issue 301.", "B_clean_title": ["treat", "bottom", "function", "type", "as", "empti", "fix", "issu", "301"]},
{"A_title": "Prototype methods cant be used from the constructor in case prototype is explicitly defined.None", "A_clean_title": ["prototyp", "method", "cant", "use", "constructor", "case", "prototyp", "explicitli", "defin", "none"], "B_title": "Support chrome-teams style of defining prototypes. Fixes issue 537", "B_clean_title": ["support", "chrome", "team", "style", "defin", "prototyp", "fix", "issu", "537"]},
{"A_title": "Commit.rollback() may remove changes from other commitCommit.rollback() removes documents it previously created. With concurrent commits it may happen that this method removes documents some other commit modified in the meantime.", "A_clean_title": ["commit", "rollback", "may", "remov", "chang", "other", "commitcommit", "rollback", "commit", "commit", "remov", "document", "it", "previous", "creat", "concurr", "commit", "it", "may", "happen", "that", "thi", "method", "remov", "document", "some", "other", "commit", "modifi", "meantim"], "B_title": "Commit.rollback() may remove changes from other commit", "B_clean_title": ["commit", "rollback", "may", "remov", "chang", "other", "commit"]},
{"A_title": "BrentOptimizer not always reporting the best pointBrentOptimizer (package o.a.c.m.optimization.univariate) does not check that the point it is going to return is indeed the best one it has encountered. Indeed the last evaluated point might be slightly worse than the one before last.", "A_clean_title": ["brentoptim", "brent", "optim", "not", "alway", "report", "best", "pointbrentoptim", "point", "brent", "optim", "packag", "optim", "univari", "not", "check", "that", "point", "it", "go", "return", "inde", "best", "one", "it", "ha", "encount", "inde", "last", "evalu", "point", "might", "slightli", "wors", "than", "one", "befor", "last"], "B_title": "(second take). Best point must be returned.", "B_clean_title": ["second", "take", "best", "point", "must", "return"]},
{"A_title": "DebugBar throws an java.lang.ExceptionInInitializerError when Tomcat is restartedI have just added the DebugBar to our base page and since then when Tomcat is restarted and session would be reloaded by this it throws this exception:  1    ERROR org.apache.catalina.session.ManagerBase  - Exception loading sessions from persistent storage java.lang.ExceptionInInitializerError at sun.misc.Unsafe.ensureClassInitialized(Native Method) at sun.reflect.UnsafeFieldAccessorFactory.newFieldAccessor(UnsafeFieldAccessorFactory.java:25) at sun.reflect.ReflectionFactory.newFieldAccessor(ReflectionFactory.java:122) at java.lang.reflect.Field.acquireFieldAccessor(Field.java:918) at java.lang.reflect.Field.getFieldAccessor(Field.java:899) at java.lang.reflect.Field.getLong(Field.java:528) at java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1614) at java.io.ObjectStreamClass.access 700(ObjectStreamClass.java:52) at java.io.ObjectStreamClass 2.run(ObjectStreamClass.java:425) at java.security.AccessController.doPrivileged(Native Method) at java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:413) at java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:310) at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:547) at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1583) at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1496) at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1583) at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1496) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1732) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1667) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1323) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.defaultReadObject(ObjectInputStream.java:480) at org.apache.wicket.Component.readObject(Component.java:4469) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:974) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1849) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1667) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1323) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:351) at java.util.concurrent.CopyOnWriteArrayList.readObject(CopyOnWriteArrayList.java:845) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:974) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1849) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1667) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1323) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.defaultReadObject(ObjectInputStream.java:480) at org.apache.wicket.Page.readPageObject(Page.java:1349) at org.apache.wicket.Component.readObject(Component.java:4465) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:974) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1849) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:351) at org.apache.wicket.protocol.http.SecondLevelCacheSessionStore SecondLevelCachePageMap.readObject(SecondLevelCacheSessionStore.java:412) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:974) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1849) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:351) at org.apache.catalina.session.StandardSession.readObject(StandardSession.java:1407) at org.apache.catalina.session.StandardSession.readObjectData(StandardSession.java:931) at org.apache.catalina.session.StandardManager.doLoad(StandardManager.java:394) at org.apache.catalina.session.StandardManager.load(StandardManager.java:321) at org.apache.catalina.session.StandardManager.start(StandardManager.java:637) at org.apache.catalina.core.ContainerBase.setManager(ContainerBase.java:432) at org.apache.catalina.core.StandardContext.start(StandardContext.java:4160) at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1014) at org.apache.catalina.core.StandardHost.start(StandardHost.java:736) at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1014) at org.apache.catalina.core.StandardEngine.start(StandardEngine.java:443) at org.apache.catalina.core.StandardService.start(StandardService.java:448) at org.apache.catalina.core.StandardServer.start(StandardServer.java:700) at org.apache.catalina.startup.Catalina.start(Catalina.java:552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:295) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:433) Caused by: org.apache.wicket.WicketRuntimeException: There is no application attached to current thread main at org.apache.wicket.Application.get(Application.java:178) at org.apache.wicket.devutils.debugbar.DebugBar.getContributors(DebugBar.java:146) at org.apache.wicket.devutils.debugbar.DebugBar.registerContributor(DebugBar.java:140) at org.apache.wicket.devutils.debugbar.DebugBar.registerStandardContributors(DebugBar.java:152) at org.apache.wicket.devutils.debugbar.DebugBar.<clinit>(DebugBar.java:65) ... 109 more", "A_clean_title": ["debugbar", "debug", "bar", "throw", "java", "lang", "exceptionininitializererror", "except", "initi", "error", "when", "tomcat", "restartedi", "restart", "have", "just", "ad", "debugbar", "debug", "bar", "our", "base", "page", "sinc", "then", "when", "tomcat", "restart", "session", "would", "reload", "by", "thi", "it", "throw", "thi", "except", "error", "org", "apach", "catalina", "session", "managerbas", "manag", "base", "except", "load", "session", "persist", "storag", "java", "lang", "exceptionininitializererror", "except", "initi", "error", "at", "sun", "misc", "unsaf", "ensureclassiniti", "ensur", "class", "initi", "nativ", "method", "at", "sun", "reflect", "unsafefieldaccessorfactori", "newfieldaccessor", "unsaf", "field", "accessor", "factori", "new", "field", "accessor", "unsafefieldaccessorfactori", "java:25", "unsaf", "field", "accessor", "factori", "at", "sun", "reflect", "reflectionfactori", "newfieldaccessor", "reflect", "factori", "new", "field", "accessor", "reflectionfactori", "java:122", "reflect", "factori", "at", "java", "lang", "reflect", "field", "acquirefieldaccessor", "acquir", "field", "accessor", "field", "java:918", "at", "java", "lang", "reflect", "field", "getfieldaccessor", "get", "field", "accessor", "field", "java:899", "at", "java", "lang", "reflect", "field", "getlong", "get", "long", "field", "java:528", "at", "java", "io", "objectstreamclass", "getdeclaredsuid", "object", "stream", "class", "get", "declar", "suid", "objectstreamclass", "java:1614", "object", "stream", "class", "at", "java", "io", "objectstreamclass", "access", "object", "stream", "class", "700", "objectstreamclass", "java:52", "object", "stream", "class", "at", "java", "io", "objectstreamclass", "object", "stream", "class", "run", "objectstreamclass", "java:425", "object", "stream", "class", "at", "java", "secur", "accesscontrol", "doprivileg", "access", "control", "privileg", "nativ", "method", "at", "java", "io", "objectstreamclass", "object", "stream", "class", "init", "objectstreamclass", "java:413", "object", "stream", "class", "at", "java", "io", "objectstreamclass", "lookup", "object", "stream", "class", "objectstreamclass", "java:310", "object", "stream", "class", "at", "java", "io", "objectstreamclass", "initnonproxi", "object", "stream", "class", "init", "non", "proxi", "objectstreamclass", "java:547", "object", "stream", "class", "at", "java", "io", "objectinputstream", "readnonproxydesc", "object", "input", "stream", "read", "non", "proxi", "desc", "objectinputstream", "java:1583", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readclassdesc", "object", "input", "stream", "read", "class", "desc", "objectinputstream", "java:1496", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readnonproxydesc", "object", "input", "stream", "read", "non", "proxi", "desc", "objectinputstream", "java:1583", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readclassdesc", "object", "input", "stream", "read", "class", "desc", "objectinputstream", "java:1496", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1732", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readarray", "object", "input", "stream", "read", "array", "objectinputstream", "java:1667", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1323", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1871", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadobject", "object", "input", "stream", "default", "read", "object", "objectinputstream", "java:480", "object", "input", "stream", "at", "org", "apach", "wicket", "compon", "readobject", "read", "object", "compon", "java:4469", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "java", "io", "objectstreamclass", "invokereadobject", "object", "stream", "class", "invok", "read", "object", "objectstreamclass", "java:974", "object", "stream", "class", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1849", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readarray", "object", "input", "stream", "read", "array", "objectinputstream", "java:1667", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1323", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1871", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject", "object", "input", "stream", "read", "object", "objectinputstream", "java:351", "object", "input", "stream", "at", "java", "util", "concurr", "copyonwritearraylist", "readobject", "copi", "write", "array", "list", "read", "object", "copyonwritearraylist", "java:845", "copi", "write", "array", "list", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "java", "io", "objectstreamclass", "invokereadobject", "object", "stream", "class", "invok", "read", "object", "objectstreamclass", "java:974", "object", "stream", "class", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1849", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1871", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1871", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1871", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readarray", "object", "input", "stream", "read", "array", "objectinputstream", "java:1667", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1323", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadobject", "object", "input", "stream", "default", "read", "object", "objectinputstream", "java:480", "object", "input", "stream", "at", "org", "apach", "wicket", "page", "readpageobject", "read", "page", "object", "page", "java:1349", "at", "org", "apach", "wicket", "compon", "readobject", "read", "object", "compon", "java:4465", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "java", "io", "objectstreamclass", "invokereadobject", "object", "stream", "class", "invok", "read", "object", "objectstreamclass", "java:974", "object", "stream", "class", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1849", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject", "object", "input", "stream", "read", "object", "objectinputstream", "java:351", "object", "input", "stream", "at", "org", "apach", "wicket", "protocol", "http", "secondlevelcachesessionstor", "second", "level", "cach", "session", "store", "secondlevelcachepagemap", "readobject", "second", "level", "cach", "page", "map", "read", "object", "secondlevelcachesessionstor", "java:412", "second", "level", "cach", "session", "store", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "java", "io", "objectstreamclass", "invokereadobject", "object", "stream", "class", "invok", "read", "object", "objectstreamclass", "java:974", "object", "stream", "class", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1849", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject", "object", "input", "stream", "read", "object", "objectinputstream", "java:351", "object", "input", "stream", "at", "org", "apach", "catalina", "session", "standardsess", "readobject", "standard", "session", "read", "object", "standardsess", "java:1407", "standard", "session", "at", "org", "apach", "catalina", "session", "standardsess", "readobjectdata", "standard", "session", "read", "object", "data", "standardsess", "java:931", "standard", "session", "at", "org", "apach", "catalina", "session", "standardmanag", "doload", "standard", "manag", "load", "standardmanag", "java:394", "standard", "manag", "at", "org", "apach", "catalina", "session", "standardmanag", "load", "standard", "manag", "standardmanag", "java:321", "standard", "manag", "at", "org", "apach", "catalina", "session", "standardmanag", "start", "standard", "manag", "standardmanag", "java:637", "standard", "manag", "at", "org", "apach", "catalina", "core", "containerbas", "setmanag", "contain", "base", "set", "manag", "containerbas", "java:432", "contain", "base", "at", "org", "apach", "catalina", "core", "standardcontext", "start", "standard", "context", "standardcontext", "java:4160", "standard", "context", "at", "org", "apach", "catalina", "core", "containerbas", "start", "contain", "base", "containerbas", "java:1014", "contain", "base", "at", "org", "apach", "catalina", "core", "standardhost", "start", "standard", "host", "standardhost", "java:736", "standard", "host", "at", "org", "apach", "catalina", "core", "containerbas", "start", "contain", "base", "containerbas", "java:1014", "contain", "base", "at", "org", "apach", "catalina", "core", "standardengin", "start", "standard", "engin", "standardengin", "java:443", "standard", "engin", "at", "org", "apach", "catalina", "core", "standardservic", "start", "standard", "servic", "standardservic", "java:448", "standard", "servic", "at", "org", "apach", "catalina", "core", "standardserv", "start", "standard", "server", "standardserv", "java:700", "standard", "server", "at", "org", "apach", "catalina", "startup", "catalina", "start", "catalina", "java:552", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "org", "apach", "catalina", "startup", "bootstrap", "start", "bootstrap", "java:295", "at", "org", "apach", "catalina", "startup", "bootstrap", "main", "bootstrap", "java:433", "caus", "by", "org", "apach", "wicket", "wicketruntimeexcept", "wicket", "runtim", "except", "there", "no", "applic", "attach", "current", "thread", "main", "at", "org", "apach", "wicket", "applic", "get", "applic", "java:178", "at", "org", "apach", "wicket", "devutil", "debugbar", "debugbar", "getcontributor", "debug", "bar", "get", "contributor", "debugbar", "java:146", "debug", "bar", "at", "org", "apach", "wicket", "devutil", "debugbar", "debugbar", "registercontributor", "debug", "bar", "regist", "contributor", "debugbar", "java:140", "debug", "bar", "at", "org", "apach", "wicket", "devutil", "debugbar", "debugbar", "registerstandardcontributor", "debug", "bar", "regist", "standard", "contributor", "debugbar", "java:152", "debug", "bar", "at", "org", "apach", "wicket", "devutil", "debugbar", "debugbar", "debug", "bar", "clinit", "debugbar", "java:65", "debug", "bar", "109", "more"], "B_title": "", "B_clean_title": []},
{"A_title": "DateLexicoder fails to correctly order dates prior to 1970DateLexicoder incorrectly orders dates before 1970 at the end of all other dates.  Therefore the order was correct for all dates if the user only wrote dates before 1970 or only dates after 1970 but not if they did both.  The DateLexicoder should be fixed to store using a signed LongLexicoder internally instead of the ULongLexicoder that it used before.", "A_clean_title": ["datelexicod", "date", "lexicod", "fail", "correctli", "order", "date", "prior", "1970datelexicod", "1970date", "lexicod", "incorrectli", "order", "date", "befor", "1970", "at", "end", "all", "other", "date", "therefor", "order", "wa", "correct", "all", "date", "user", "onli", "wrote", "date", "befor", "1970", "or", "onli", "date", "after", "1970", "but", "not", "they", "did", "both", "datelexicod", "date", "lexicod", "fix", "store", "sign", "longlexicod", "long", "lexicod", "intern", "instead", "ulonglexicod", "long", "lexicod", "that", "it", "use", "befor"], "B_title": "Fix broken DateLexicoder ordering", "B_clean_title": ["fix", "broken", "datelexicod", "date", "lexicod", "order"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "use epsilon criteria when deciding to drop columns after phase 1.", "B_clean_title": ["use", "epsilon", "criteria", "when", "decid", "drop", "column", "after", "phase"]},
{"A_title": "DeserializationFeature.UNWRAP_SINGLE_VALUE_ARRAYS only works for POJOs MapsDocumentation of  DeserializationFeature.UNWRAP_SINGLE_VALUE_ARRAYS only mentiones exceptional behavior for more than one value in the array (If more than one value is found in the array a JsonMappingException is thrown.). But trying to parse  value :   with value as String produces the following Stacktrace: (Parsing as null might be expected instead)   This shouldnt be problematic when using  DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT  but it does not take precedence over DeserializationFeature.UNWRAP_SINGLE_VALUE_ARRAYS (bug?) and still gives me the error from above! Are there any workarounds? I still need to map single element arrays that sometimes appear to be empty. (I am using version 2.5.1 tested also 2.6.0: same behavior)", "A_clean_title": ["deserializationfeatur", "deseri", "featur", "unwrap", "singl", "valu", "array", "onli", "work", "pojo", "poj", "os", "mapsdocument", "map", "document", "deserializationfeatur", "deseri", "featur", "unwrap", "singl", "valu", "array", "onli", "mention", "except", "behavior", "more", "than", "one", "valu", "array", "more", "than", "one", "valu", "found", "array", "jsonmappingexcept", "json", "map", "except", "thrown", "but", "tri", "pars", "valu", "valu", "as", "string", "produc", "follow", "stacktrac", "pars", "as", "null", "might", "expect", "instead", "thi", "shouldnt", "problemat", "when", "deserializationfeatur", "deseri", "featur", "accept", "empti", "array", "as", "null", "object", "but", "it", "not", "take", "preced", "over", "deserializationfeatur", "deseri", "featur", "unwrap", "singl", "valu", "array", "bug", "still", "give", "me", "error", "abov", "are", "there", "ani", "workaround", "still", "need", "map", "singl", "element", "array", "that", "sometim", "appear", "empti", "am", "version", "test", "also", "same", "behavior"], "B_title": "Add enum handling wrt #994", "B_clean_title": ["add", "enum", "handl", "wrt", "994"]},
{"A_title": "Node.getNodes throwing exception if user does not have access to any child nodeWhen trying to obtain child iterator via Node.getNodes InvalidItemStateException is thrown if user does not have access to its content  code:java     @Test     public void testGetChildren() throws Exception          deny(path privilegesFromName(PrivilegeConstants.JCR_ADD_CHILD_NODES));         NodeIterator it1 = testSession.getNode(path).getNodes();         while(it1.hasNext())             Node n = it1.nextNode();             NodeIterator it2 = n.getNodes();               code  Executing above code leads to following exception  noformat javax.jcr.InvalidItemStateException: Item is stale at org.apache.jackrabbit.oak.jcr.delegate.NodeDelegate.getTree(NodeDelegate.java:827) at org.apache.jackrabbit.oak.jcr.delegate.NodeDelegate.getChildren(NodeDelegate.java:336) at org.apache.jackrabbit.oak.jcr.session.NodeImpl 8.perform(NodeImpl.java:546) at org.apache.jackrabbit.oak.jcr.session.NodeImpl 8.perform(NodeImpl.java:543) at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:125) at org.apache.jackrabbit.oak.jcr.session.ItemImpl.perform(ItemImpl.java:113) at org.apache.jackrabbit.oak.jcr.session.NodeImpl.getNodes(NodeImpl.java:543) at org.apache.jackrabbit.oak.jcr.security.authorization.ReadPropertyTest.testGetChildren(ReadPropertyTest.java:135) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at org.apache.jackrabbit.test.AbstractJCRTest.run(AbstractJCRTest.java:464) at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83) at org.junit.runner.JUnitCore.run(JUnitCore.java:157) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:77) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:195) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:63) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:120) noformat  The exception is thrown for path /testroot/node1/rep:policy.   The issue occurs because the NodeIterator it1 includes rep:policy and later when its child are accessed security check leads to exception. Probably the it1 should not include rep:policy as part of child list and filter it out", "A_clean_title": ["node", "getnod", "get", "node", "throw", "except", "user", "not", "have", "access", "ani", "child", "nodewhen", "node", "when", "tri", "obtain", "child", "iter", "via", "node", "getnod", "get", "node", "invaliditemstateexcept", "invalid", "item", "state", "except", "thrown", "user", "not", "have", "access", "it", "content", "code", "java", "test", "public", "void", "testgetchildren", "test", "get", "children", "throw", "except", "deni", "path", "privilegesfromnam", "privileg", "name", "privilegeconst", "privileg", "constant", "jcr", "add", "child", "node", "nodeiter", "node", "iter", "it1", "testsess", "getnod", "test", "session", "get", "node", "path", "getnod", "get", "node", "while", "it1", "hasnext", "ha", "next", "node", "it1", "nextnod", "next", "node", "nodeiter", "node", "iter", "it2", "getnod", "get", "node", "code", "execut", "abov", "code", "lead", "follow", "except", "noformat", "javax", "jcr", "invaliditemstateexcept", "invalid", "item", "state", "except", "item", "stale", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "nodedeleg", "gettre", "node", "deleg", "get", "tree", "nodedeleg", "java:827", "node", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "nodedeleg", "getchildren", "node", "deleg", "get", "children", "nodedeleg", "java:336", "node", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "nodeimpl", "node", "impl", "perform", "nodeimpl", "java:546", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "nodeimpl", "node", "impl", "perform", "nodeimpl", "java:543", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "perform", "session", "deleg", "sessiondeleg", "java:125", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "itemimpl", "perform", "item", "impl", "itemimpl", "java:113", "item", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "nodeimpl", "getnod", "node", "impl", "get", "node", "nodeimpl", "java:543", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "secur", "author", "readpropertytest", "testgetchildren", "read", "properti", "test", "test", "get", "children", "readpropertytest", "java:135", "read", "properti", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "org", "apach", "jackrabbit", "test", "abstractjcrtest", "run", "abstract", "jcr", "test", "abstractjcrtest", "java:464", "abstract", "jcr", "test", "at", "org", "junit", "intern", "runner", "junit38classrunn", "run", "unit38class", "runner", "junit38classrunn", "java:83", "unit38class", "runner", "at", "org", "junit", "runner", "junitcor", "run", "unit", "core", "junitcor", "java:157", "unit", "core", "at", "com", "intellij", "junit4", "junit4ideatestrunn", "startrunnerwitharg", "unit4idea", "test", "runner", "start", "runner", "arg", "junit4ideatestrunn", "java:77", "unit4idea", "test", "runner", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "preparestreamsandstart", "unit", "starter", "prepar", "stream", "start", "junitstart", "java:195", "unit", "starter", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "main", "unit", "starter", "junitstart", "java:63", "unit", "starter", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "com", "intellij", "rt", "execut", "applic", "appmain", "main", "app", "main", "appmain", "java:120", "app", "main", "noformat", "except", "thrown", "path", "testroot", "node1", "rep", "polici", "issu", "occur", "becaus", "nodeiter", "node", "iter", "it1", "includ", "rep", "polici", "later", "when", "it", "child", "are", "access", "secur", "check", "lead", "except", "probabl", "it1", "not", "includ", "rep", "polici", "as", "part", "child", "list", "filter", "it", "out"], "B_title": "- Node.getNodes throwing exception if user does not have access to any child node", "B_clean_title": ["node", "getnod", "get", "node", "throw", "except", "user", "not", "have", "access", "ani", "child", "node"]},
{"A_title": "Form gets submitted using AjaxSubmitBehavior when sub-form has errorsfrom http://www.nabble.com/Should-a-form-submit-when-sub-form-has-error%27s--tt22803314.html  I have a main-form where I add a panel that contains another form. This sub-form contains a formvalidator that gives the error. However the main-form is submitted but the feedbackpanel does show the error message set in the sub-forms validator.  Ill attach 2 patches with testcases displaying the behavior in wicket 1.3 vs 1.4  (As a side note I had to rename the org.apache.wicket.markup.html.form.validation.TestHomePage to org.apache.wicket.markup.html.form.validation.HomePageTest to get the test to run when building wicket)", "A_clean_title": ["form", "get", "submit", "ajaxsubmitbehavior", "ajax", "submit", "behavior", "when", "sub", "form", "ha", "errorsfrom", "http", "form", "submit", "when", "sub", "form", "ha", "error", "nabbl", "www", "com", "27", "tt22803314", "html", "have", "main", "form", "where", "add", "panel", "that", "contain", "anoth", "form", "thi", "sub", "form", "contain", "formvalid", "that", "give", "error", "howev", "main", "form", "submit", "but", "feedbackpanel", "show", "error", "messag", "set", "sub", "form", "valid", "ill", "attach", "patch", "testcas", "display", "behavior", "wicket", "vs", "as", "side", "note", "had", "renam", "org", "apach", "wicket", "markup", "html", "form", "valid", "testhomepag", "test", "home", "page", "org", "apach", "wicket", "markup", "html", "form", "valid", "homepagetest", "home", "page", "test", "get", "test", "run", "when", "build", "wicket"], "B_title": "fixed: Form gets submitted using AjaxSubmitBehavior when sub-form has errors Issue: WICKET-2202", "B_clean_title": ["fix", "form", "get", "submit", "ajaxsubmitbehavior", "ajax", "submit", "behavior", "when", "sub", "form", "ha", "error", "issu", "wicket", "2202"]},
{"A_title": "Resolve table name to table id once in Accumulo input formatAccumuloInputFormat (and I suspect AccumuloOutputFormat) sends the table name to each mapper.  The mapper uses this table name to create a scanner.  In the case of the following events a map reduce job could read from two different table ids.      # start M/R job reading table A  # rename table A (tableId=1) to table C  # rename table B (tableId=2) to table A  If the input format passed table id 1 to the mappers then the renames would not cause a problem.", "A_clean_title": ["resolv", "tabl", "name", "tabl", "id", "onc", "accumulo", "input", "formataccumuloinputformat", "format", "accumulo", "input", "format", "suspect", "accumulooutputformat", "accumulo", "output", "format", "send", "tabl", "name", "each", "mapper", "mapper", "use", "thi", "tabl", "name", "creat", "scanner", "case", "follow", "event", "map", "reduc", "job", "could", "read", "two", "differ", "tabl", "id", "start", "job", "read", "tabl", "renam", "tabl", "tableid=1", "tabl", "id=1", "tabl", "renam", "tabl", "tableid=2", "tabl", "id=2", "tabl", "input", "format", "pass", "tabl", "id", "mapper", "then", "renam", "would", "not", "caus", "problem"], "B_title": "fixed input format w/ mock", "B_clean_title": ["fix", "input", "format", "mock"]},
{"A_title": "NumberUtils.isNumber() Should Return True for Valid Number with a Trailing Decimal PlaceNumberUtils.isNumber() should return true for a valid number ending in a trailing decimal place; e.g. 2. should be considered a number because new BigDecimal(2.) works fine.  This could be done by adding the code below after line 1444 which is the if (charsi == e || charsi == E) block. if (charsi == .)      if (hasDecPoint || hasExp)           // two decimal points or dec in exponent            return false;          return foundDigit; // single trailing decimal point after non-exponent is ok", "A_clean_title": ["numberutil", "isnumb", "number", "util", "number", "return", "true", "valid", "number", "trail", "decim", "placenumberutil", "isnumb", "place", "number", "util", "number", "return", "true", "valid", "number", "end", "trail", "decim", "place", "consid", "number", "becaus", "new", "bigdecim", "big", "decim", "work", "fine", "thi", "could", "done", "by", "ad", "code", "below", "after", "line", "1444", "which", "charsi", "charsi", "block", "charsi", "hasdecpoint", "ha", "dec", "point", "hasexp", "ha", "exp", "two", "decim", "point", "or", "dec", "expon", "return", "fals", "return", "founddigit", "found", "digit", "singl", "trail", "decim", "point", "after", "non", "expon", "ok"], "B_title": "isNumber(String) and createNumber(String) both modified to support 2.. LANG-521", "B_clean_title": ["isnumb", "number", "string", "createnumb", "creat", "number", "string", "both", "modifi", "support", "lang", "521"]},
{"A_title": "ClassUtils.getShortClassName() will not work with an array;  it seems to add a semicolon to the end.A semicolon is introduced into the class name at the end for all arrays... String sArray = new String2; sArray0 = mark; sArray1 = is cool; String simpleString = chris; assertEquals(String ClassUtils.getShortClassName(simpleString null)); assertEquals(String; ClassUtils.getShortClassName(sArray null));", "A_clean_title": ["classutil", "getshortclassnam", "class", "util", "get", "short", "class", "name", "will", "not", "work", "array", "it", "seem", "add", "semicolon", "end", "semicolon", "introduc", "into", "class", "name", "at", "end", "all", "array", "string", "sarray", "array", "new", "string2", "sarray0", "array0", "mark", "sarray1", "array1", "cool", "string", "simplestr", "simpl", "string", "chri", "assertequ", "assert", "equal", "string", "classutil", "getshortclassnam", "class", "util", "get", "short", "class", "name", "simplestr", "simpl", "string", "null", "assertequ", "assert", "equal", "string", "classutil", "getshortclassnam", "class", "util", "get", "short", "class", "name", "sarray", "array", "null"], "B_title": "Applying my patch from LANG-535 - adding support to getShortClassName and getPackageName for arrays including primitive arrays and multi-dimensional arrays. Also stopped getPackageName relying on the underlying class.getPackage as its sometimes null", "B_clean_title": ["appli", "my", "patch", "lang", "535", "ad", "support", "getshortclassnam", "get", "short", "class", "name", "getpackagenam", "get", "packag", "name", "array", "includ", "primit", "array", "multi", "dimension", "array", "also", "stop", "getpackagenam", "get", "packag", "name", "reli", "underli", "class", "getpackag", "get", "packag", "as", "it", "sometim", "null"]},
{"A_title": "AbstractEstimator: getCovariances() and guessParametersErrors() crash when having bound parametersthe two methods getCovariances() and guessParametersErrors() from org.apache.commons.math.estimation.AbstractEstimator crash with ArrayOutOfBounds exception when some of the parameters are bound. The reason is that the Jacobian is calculated only for the unbound parameters. in the code you loop through all parameters. line #166: final int cols = problem.getAllParameters().length; should be replaced by:  final int cols = problem.getUnboundParameters().length; (similar changes could be done in guessParametersErrors()) the dissadvantage of the above bug fix is that what is returned to the user is an array with smaller size than the number of all parameters. Alternatively you can have some logic in the code which writes zeros for the elements of the covariance matrix corresponding to the bound parameters", "A_clean_title": ["abstractestim", "abstract", "estim", "getcovari", "get", "covari", "guessparameterserror", "guess", "paramet", "error", "crash", "when", "have", "bound", "parametersth", "two", "method", "getcovari", "get", "covari", "guessparameterserror", "guess", "paramet", "error", "org", "apach", "common", "math", "estim", "abstractestim", "abstract", "estim", "crash", "arrayoutofbound", "array", "out", "bound", "except", "when", "some", "paramet", "are", "bound", "reason", "that", "jacobian", "calcul", "onli", "unbound", "paramet", "code", "you", "loop", "through", "all", "paramet", "line", "166", "final", "int", "col", "problem", "getallparamet", "get", "all", "paramet", "length", "replac", "by", "final", "int", "col", "problem", "getunboundparamet", "get", "unbound", "paramet", "length", "similar", "chang", "could", "done", "guessparameterserror", "guess", "paramet", "error", "dissadvantag", "abov", "bug", "fix", "that", "what", "return", "user", "array", "smaller", "size", "than", "number", "all", "paramet", "altern", "you", "have", "some", "logic", "code", "which", "write", "zero", "element", "covari", "matrix", "correspond", "bound", "paramet"], "B_title": "fixed crashes in AbstractEstimator when some parameters are bound. getCovariances() and guessParametersErrors() now only give result about unbound parameters JIRA: MATH-200", "B_clean_title": ["fix", "crash", "abstractestim", "abstract", "estim", "when", "some", "paramet", "are", "bound", "getcovari", "get", "covari", "guessparameterserror", "guess", "paramet", "error", "now", "onli", "give", "result", "about", "unbound", "paramet", "jira", "math", "200"]},
{"A_title": "Race leading to IndexOutOfBoundsException when querying for buffer while releasing SpillablePartitionWhen running a code as simple as:   noformat ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();  DataSet<Edge<String NullValue>> edges = getEdgesDataSet(env); Graph<String NullValue NullValue> graph = Graph.fromDataSet(edges env);  DataSet<Tuple2<String Long>> degrees = graph.getDegrees(); degrees.writeAsCsv(outputPath n  ); env.execute();  on the Freindster data set: https://snap.stanford.edu/data/com-Friendster.html; on 30 Wally nodes   I get the following exception: java.lang.Exception: The data preparation for task CoGroup (CoGroup at inDegrees(Graph.java:701))  caused an error: Error obtaining the sorted input: Thread SortMerger Reading Thread terminated due to an exception: Fatal error at remote task manager wally028.cit.tu-berlin.de/130.149.249.38:53730. at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:471) at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:362) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:559) at java.lang.Thread.run(Thread.java:722) Caused by: java.lang.RuntimeException: Error obtaining the sorted input: Thread SortMerger Reading Thread terminated due to an exception: Fatal error at remote task manager wally028.cit.tu-berlin.de/130.149.249.38:53730. at org.apache.flink.runtime.operators.sort.UnilateralSortMerger.getIterator(UnilateralSortMerger.java:607) at org.apache.flink.runtime.operators.RegularPactTask.getInput(RegularPactTask.java:1145) at org.apache.flink.runtime.operators.CoGroupDriver.prepare(CoGroupDriver.java:98) at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:466) ... 3 more Caused by: java.io.IOException: Thread SortMerger Reading Thread terminated due to an exception: Fatal error at remote task manager wally028.cit.tu-berlin.de/130.149.249.38:53730. at org.apache.flink.runtime.operators.sort.UnilateralSortMerger ThreadBase.run(UnilateralSortMerger.java:784) Caused by: org.apache.flink.runtime.io.network.netty.exception.RemoteTransportException: Fatal error at remote task manager wally028.cit.tu-berlin.de/130.149.249.38:53730. at org.apache.flink.runtime.io.network.netty.PartitionRequestClientHandler.decodeMsg(PartitionRequestClientHandler.java:227) at org.apache.flink.runtime.io.network.netty.PartitionRequestClientHandler.channelRead(PartitionRequestClientHandler.java:162) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:339) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:324) at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:339) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:324) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:242) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:339) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:324) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:847) at io.netty.channel.nio.AbstractNioByteChannel NioByteUnsafe.read(AbstractNioByteChannel.java:131) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354) at io.netty.util.concurrent.SingleThreadEventExecutor 2.run(SingleThreadEventExecutor.java:111) at java.lang.Thread.run(Thread.java:722) Caused by: java.io.IOException: Index: 133 Size: 0  noformat  Code works fine for the twitter data set for instance which is bigger in size but contains less vertices.", "A_clean_title": ["race", "lead", "indexoutofboundsexcept", "index", "out", "bound", "except", "when", "queri", "buffer", "while", "releas", "spillablepartitionwhen", "spillabl", "partit", "when", "run", "code", "as", "simpl", "as", "noformat", "executionenviron", "execut", "environ", "env", "executionenviron", "getexecutionenviron", "execut", "environ", "get", "execut", "environ", "dataset", "data", "set", "edg", "string", "nullvalu", "null", "valu", "edg", "getedgesdataset", "get", "edg", "data", "set", "env", "graph", "string", "nullvalu", "null", "valu", "nullvalu", "null", "valu", "graph", "graph", "fromdataset", "data", "set", "edg", "env", "dataset", "data", "set", "tuple2", "string", "long", "degre", "graph", "getdegre", "get", "degre", "degre", "writeascsv", "write", "as", "csv", "outputpath", "output", "path", "env", "execut", "freindster", "data", "set", "http", "stanford", "friendster", "html", "snap", "edu", "data", "com", "30", "walli", "node", "get", "follow", "except", "java", "lang", "except", "data", "prepar", "task", "cogroup", "co", "group", "cogroup", "co", "group", "at", "indegre", "degre", "graph", "java:701", "caus", "error", "error", "obtain", "sort", "input", "thread", "sortmerg", "sort", "merger", "read", "thread", "termin", "due", "except", "fatal", "error", "at", "remot", "task", "manag", "wally028", "cit", "tu", "berlin", "149", "249", "38:53730", "de", "130", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "run", "regular", "pact", "task", "regularpacttask", "java:471", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "invok", "regular", "pact", "task", "regularpacttask", "java:362", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "taskmanag", "task", "run", "task", "java:559", "at", "java", "lang", "thread", "run", "thread", "java:722", "caus", "by", "java", "lang", "runtimeexcept", "runtim", "except", "error", "obtain", "sort", "input", "thread", "sortmerg", "sort", "merger", "read", "thread", "termin", "due", "except", "fatal", "error", "at", "remot", "task", "manag", "wally028", "cit", "tu", "berlin", "149", "249", "38:53730", "de", "130", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "getiter", "unilater", "sort", "merger", "get", "iter", "unilateralsortmerg", "java:607", "unilater", "sort", "merger", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "getinput", "regular", "pact", "task", "get", "input", "regularpacttask", "java:1145", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "cogroupdriv", "prepar", "co", "group", "driver", "cogroupdriv", "java:98", "co", "group", "driver", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "run", "regular", "pact", "task", "regularpacttask", "java:466", "regular", "pact", "task", "more", "caus", "by", "java", "io", "ioexcept", "io", "except", "thread", "sortmerg", "sort", "merger", "read", "thread", "termin", "due", "except", "fatal", "error", "at", "remot", "task", "manag", "wally028", "cit", "tu", "berlin", "149", "249", "38:53730", "de", "130", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "unilater", "sort", "merger", "threadbas", "run", "thread", "base", "unilateralsortmerg", "java:784", "unilater", "sort", "merger", "caus", "by", "org", "apach", "flink", "runtim", "io", "network", "netti", "except", "remotetransportexcept", "remot", "transport", "except", "fatal", "error", "at", "remot", "task", "manag", "wally028", "cit", "tu", "berlin", "149", "249", "38:53730", "de", "130", "at", "org", "apach", "flink", "runtim", "io", "network", "netti", "partitionrequestclienthandl", "decodemsg", "partit", "request", "client", "handler", "decod", "msg", "partitionrequestclienthandl", "java:227", "partit", "request", "client", "handler", "at", "org", "apach", "flink", "runtim", "io", "network", "netti", "partitionrequestclienthandl", "channelread", "partit", "request", "client", "handler", "channel", "read", "partitionrequestclienthandl", "java:162", "partit", "request", "client", "handler", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "invokechannelread", "abstract", "channel", "handler", "context", "invok", "channel", "read", "abstractchannelhandlercontext", "java:339", "abstract", "channel", "handler", "context", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "firechannelread", "abstract", "channel", "handler", "context", "fire", "channel", "read", "abstractchannelhandlercontext", "java:324", "abstract", "channel", "handler", "context", "at", "io", "netti", "handler", "codec", "messagetomessagedecod", "channelread", "messag", "messag", "decod", "channel", "read", "messagetomessagedecod", "java:103", "messag", "messag", "decod", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "invokechannelread", "abstract", "channel", "handler", "context", "invok", "channel", "read", "abstractchannelhandlercontext", "java:339", "abstract", "channel", "handler", "context", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "firechannelread", "abstract", "channel", "handler", "context", "fire", "channel", "read", "abstractchannelhandlercontext", "java:324", "abstract", "channel", "handler", "context", "at", "io", "netti", "handler", "codec", "bytetomessagedecod", "channelread", "byte", "messag", "decod", "channel", "read", "bytetomessagedecod", "java:242", "byte", "messag", "decod", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "invokechannelread", "abstract", "channel", "handler", "context", "invok", "channel", "read", "abstractchannelhandlercontext", "java:339", "abstract", "channel", "handler", "context", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "firechannelread", "abstract", "channel", "handler", "context", "fire", "channel", "read", "abstractchannelhandlercontext", "java:324", "abstract", "channel", "handler", "context", "at", "io", "netti", "channel", "defaultchannelpipelin", "firechannelread", "default", "channel", "pipelin", "fire", "channel", "read", "defaultchannelpipelin", "java:847", "default", "channel", "pipelin", "at", "io", "netti", "channel", "nio", "abstractniobytechannel", "abstract", "nio", "byte", "channel", "niobyteunsaf", "read", "nio", "byte", "unsaf", "abstractniobytechannel", "java:131", "abstract", "nio", "byte", "channel", "at", "io", "netti", "channel", "nio", "nioeventloop", "processselectedkey", "nio", "event", "loop", "process", "select", "key", "nioeventloop", "java:511", "nio", "event", "loop", "at", "io", "netti", "channel", "nio", "nioeventloop", "processselectedkeysoptim", "nio", "event", "loop", "process", "select", "key", "optim", "nioeventloop", "java:468", "nio", "event", "loop", "at", "io", "netti", "channel", "nio", "nioeventloop", "processselectedkey", "nio", "event", "loop", "process", "select", "key", "nioeventloop", "java:382", "nio", "event", "loop", "at", "io", "netti", "channel", "nio", "nioeventloop", "run", "nio", "event", "loop", "nioeventloop", "java:354", "nio", "event", "loop", "at", "io", "netti", "util", "concurr", "singlethreadeventexecutor", "singl", "thread", "event", "executor", "run", "singlethreadeventexecutor", "java:111", "singl", "thread", "event", "executor", "at", "java", "lang", "thread", "run", "thread", "java:722", "caus", "by", "java", "io", "ioexcept", "io", "except", "index", "133", "size", "noformat", "code", "work", "fine", "twitter", "data", "set", "instanc", "which", "bigger", "size", "but", "contain", "less", "vertic"], "B_title": "runtime Check if parent released before querying in-memory buffer in SpillableSubpartitionView", "B_clean_title": ["runtim", "check", "parent", "releas", "befor", "queri", "memori", "buffer", "spillablesubpartitionview", "spillabl", "subpartit", "view"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Work around infinite loop.", "B_clean_title": ["work", "around", "infinit", "loop"]},
{"A_title": "ArrayIndexOutOfBoundsException in Segment.getRefId()It looks like there is some SegmentMK bug that causes the Segment.getRefId() to throw an ArrayIndexOutOfBoundsException in some fairly rare corner cases. The data was originally migrated into oak via the crx2oak tool mentioned here: http://docs.adobe.com/docs/en/aem/6-0/deploy/upgrade.html That tool uses *oak-core-1.0.0* creating an oak instance.  Similar to OAK-1566 this system was using FileDataStore with SegmentNodeStore.  In this case the error is seen when running offline compaction using oak-run-1.1-SNAPSHOT.jar (latest).  code:none > java -Xmx4096m -jar oak-run-1.1-SNAPSHOT.jar compact /oak/crx-quickstart/repository/segmentstore Apache Jackrabbit Oak 1.1-SNAPSHOT Compacting /wcm/cq-author/crx-quickstart/repository/segmentstore before data00055a.tar data00064a.tar data00045b.tar data00005a.tar data00018a.tar data00022a.tar data00047a.tar data00037a.tar data00049a.tar data00014a.tar data00066a.tar data00020a.tar data00058a.tar data00065a.tar data00069a.tar data00012a.tar data00009a.tar data00060a.tar data00041a.tar data00016a.tar data00072a.tar data00048a.tar data00061a.tar data00053a.tar data00038a.tar data00001a.tar data00034a.tar data00003a.tar data00052a.tar data00006a.tar data00027a.tar data00031a.tar data00056a.tar data00035a.tar data00063a.tar data00068a.tar data00008v.tar data00010a.tar data00043b.tar data00021a.tar data00017a.tar data00024a.tar data00054a.tar data00051a.tar data00057a.tar data00059a.tar data00036a.tar data00033a.tar data00019a.tar data00046a.tar data00067a.tar data00004a.tar data00044a.tar data00013a.tar data00070a.tar data00026a.tar data00002a.tar data00011a.tar journal.log data00030a.tar data00042a.tar data00025a.tar data00062a.tar data00023a.tar data00071a.tar data00032b.tar data00040a.tar data00015a.tar data00029a.tar data00050a.tar data00000a.tar data00007a.tar data00028a.tar data00039a.tar -> compacting Exception in thread main java.lang.ArrayIndexOutOfBoundsException: 206 at org.apache.jackrabbit.oak.plugins.segment.Segment.getRefId(Segment.java:191) at org.apache.jackrabbit.oak.plugins.segment.Segment.internalReadRecordId(Segment.java:299) at org.apache.jackrabbit.oak.plugins.segment.Segment.readRecordId(Segment.java:295) at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplateId(SegmentNodeState.java:69) at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplate(SegmentNodeState.java:78) at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getProperties(SegmentNodeState.java:150) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:154) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:395) at org.apache.jackrabbit.oak.plugins.segment.Compactor.process(Compactor.java:80) at org.apache.jackrabbit.oak.plugins.segment.Compactor.compact(Compactor.java:85) at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.compact(FileStore.java:438) at org.apache.jackrabbit.oak.run.Main.compact(Main.java:311) at org.apache.jackrabbit.oak.run.Main.main(Main.java:133) code", "A_clean_title": ["arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "segment", "getrefid", "get", "ref", "id", "it", "look", "like", "there", "some", "segmentmk", "segment", "mk", "bug", "that", "caus", "segment", "getrefid", "get", "ref", "id", "throw", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "some", "fairli", "rare", "corner", "case", "data", "wa", "origin", "migrat", "into", "oak", "via", "crx2oak", "tool", "mention", "here", "http", "adob", "html", "doc", "com", "doc", "en", "aem", "deploy", "upgrad", "that", "tool", "use", "oak", "core", "creat", "oak", "instanc", "similar", "oak", "1566", "thi", "system", "wa", "filedatastor", "file", "data", "store", "segmentnodestor", "segment", "node", "store", "thi", "case", "error", "seen", "when", "run", "offlin", "compact", "oak", "run", "snapshot", "jar", "latest", "code", "none", "java", "xmx4096m", "jar", "oak", "run", "snapshot", "jar", "compact", "oak", "crx", "quickstart", "repositori", "segmentstor", "apach", "jackrabbit", "oak", "snapshot", "compact", "wcm", "cq", "author", "crx", "quickstart", "repositori", "segmentstor", "befor", "data00055a", "tar", "data00064a", "tar", "data00045b", "tar", "data00005a", "tar", "data00018a", "tar", "data00022a", "tar", "data00047a", "tar", "data00037a", "tar", "data00049a", "tar", "data00014a", "tar", "data00066a", "tar", "data00020a", "tar", "data00058a", "tar", "data00065a", "tar", "data00069a", "tar", "data00012a", "tar", "data00009a", "tar", "data00060a", "tar", "data00041a", "tar", "data00016a", "tar", "data00072a", "tar", "data00048a", "tar", "data00061a", "tar", "data00053a", "tar", "data00038a", "tar", "data00001a", "tar", "data00034a", "tar", "data00003a", "tar", "data00052a", "tar", "data00006a", "tar", "data00027a", "tar", "data00031a", "tar", "data00056a", "tar", "data00035a", "tar", "data00063a", "tar", "data00068a", "tar", "data00008v", "tar", "data00010a", "tar", "data00043b", "tar", "data00021a", "tar", "data00017a", "tar", "data00024a", "tar", "data00054a", "tar", "data00051a", "tar", "data00057a", "tar", "data00059a", "tar", "data00036a", "tar", "data00033a", "tar", "data00019a", "tar", "data00046a", "tar", "data00067a", "tar", "data00004a", "tar", "data00044a", "tar", "data00013a", "tar", "data00070a", "tar", "data00026a", "tar", "data00002a", "tar", "data00011a", "tar", "journal", "log", "data00030a", "tar", "data00042a", "tar", "data00025a", "tar", "data00062a", "tar", "data00023a", "tar", "data00071a", "tar", "data00032b", "tar", "data00040a", "tar", "data00015a", "tar", "data00029a", "tar", "data00050a", "tar", "data00000a", "tar", "data00007a", "tar", "data00028a", "tar", "data00039a", "tar", "compact", "except", "thread", "main", "java", "lang", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "206", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segment", "getrefid", "get", "ref", "id", "segment", "java:191", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segment", "internalreadrecordid", "intern", "read", "record", "id", "segment", "java:299", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segment", "readrecordid", "read", "record", "id", "segment", "java:295", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "gettemplateid", "segment", "node", "state", "get", "templat", "id", "segmentnodest", "java:69", "segment", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "gettempl", "segment", "node", "state", "get", "templat", "segmentnodest", "java:78", "segment", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "getproperti", "segment", "node", "state", "get", "properti", "segmentnodest", "java:150", "segment", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:154", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "compareagainstbasest", "segment", "node", "state", "compar", "against", "base", "state", "segmentnodest", "java:395", "segment", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "process", "compactor", "java:80", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compact", "compactor", "java:85", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "file", "filestor", "compact", "file", "store", "filestor", "java:438", "file", "store", "at", "org", "apach", "jackrabbit", "oak", "run", "main", "compact", "main", "java:311", "at", "org", "apach", "jackrabbit", "oak", "run", "main", "main", "main", "java:133", "code"], "B_title": "ArrayIndexOutOfBoundsException in Segment.getRefId() - Applying Toms fix - Asserting length <= buffer.length - More aggressive tests case", "B_clean_title": ["arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "segment", "getrefid", "get", "ref", "id", "appli", "tom", "fix", "assert", "length", "buffer", "length", "more", "aggress", "test", "case"]},
{"A_title": "Remove username from initializationThis is an artifact from a brief transition area during the 1.5 development. We have a flag for the user to set what the root username is except its never used. We should remove both the variable and the flag for it.", "A_clean_title": ["remov", "usernam", "initializationthi", "initi", "thi", "artifact", "brief", "transit", "area", "dure", "develop", "we", "have", "flag", "user", "set", "what", "root", "usernam", "except", "it", "never", "use", "we", "remov", "both", "variabl", "flag", "it"], "B_title": "Thought this flag was gone in MAC fixed now", "B_clean_title": ["thought", "thi", "flag", "wa", "gone", "mac", "fix", "now"]},
{"A_title": "segments compareAgainstBaseState wont call childNodeDeleted when deleting last and adding n nodesSegmentNodeState.compareAgainstBaseState fails to call NodeStateDiff.childNodeDeleted when for the same parent the only child is deleted and at the same time multiple new different children are added.  Reason is that the current code|https://github.com/apache/jackrabbit-oak/blob/a9ce70b61567ffe27529dad8eb5d38ced77cf8ad/oak-segment/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentNodeState.java#L558 for afterChildName == MANY_CHILD_NODES *and* beforeChildName == ONE_CHILD_NODE does not handle all cases: it assumes that after contains the before child and doesnt handle the situation where the before child has gone.", "A_clean_title": ["segment", "compareagainstbasest", "compar", "against", "base", "state", "wont", "call", "childnodedelet", "child", "node", "delet", "when", "delet", "last", "ad", "nodessegmentnodest", "compareagainstbasest", "node", "segment", "node", "state", "compar", "against", "base", "state", "fail", "call", "nodestatediff", "childnodedelet", "node", "state", "diff", "child", "node", "delet", "when", "same", "parent", "onli", "child", "delet", "at", "same", "time", "multipl", "new", "differ", "children", "are", "ad", "reason", "that", "current", "code|http", "oak", "blob", "a9ce70b61567ffe27529dad8eb5d38ced77cf8ad", "oak", "java", "github", "com", "apach", "jackrabbit", "segment", "src", "main", "java", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "segment", "node", "state", "l558", "afterchildnam", "after", "child", "name", "mani", "child", "node", "beforechildnam", "befor", "child", "name", "one", "child", "node", "not", "handl", "all", "case", "it", "assum", "that", "after", "contain", "befor", "child", "doesnt", "handl", "situat", "where", "befor", "child", "ha", "gone"], "B_title": ": fix for compareAgainstBaseState which properly handles deletion of last child and adding multiple new children in same go", "B_clean_title": ["fix", "compareagainstbasest", "compar", "against", "base", "state", "which", "properli", "handl", "delet", "last", "child", "ad", "multipl", "new", "children", "same", "go"]},
{"A_title": "@lends does not work unless class is defined beforehandNone", "A_clean_title": ["lend", "not", "work", "unless", "class", "defin", "beforehandnon", "beforehand", "none"], "B_title": "defer evaluation of the @lends annotation fixes issue 314", "B_clean_title": ["defer", "evalu", "lend", "annot", "fix", "issu", "314"]},
{"A_title": "StackOverflowError when calling getObject() from load() in LDMThe fix for WICKET-5772 caused an infinite loop when calling getObject() from inside load() in LoadableDetachableModel. While of course unwise to do so and nobody in their right mind would do so directly such a cycle can be triggered through a series of unrelated calls emanating from load().", "A_clean_title": ["stackoverflowerror", "stack", "overflow", "error", "when", "call", "getobject", "get", "object", "load", "ldmthe", "ldm", "fix", "wicket", "5772", "caus", "infinit", "loop", "when", "call", "getobject", "get", "object", "insid", "load", "loadabledetachablemodel", "loadabl", "detach", "model", "while", "cours", "unwis", "so", "nobodi", "their", "right", "mind", "would", "so", "directli", "such", "cycl", "trigger", "through", "seri", "unrel", "call", "eman", "load"], "B_title": "StackOverflowError in LoadableDetachableModel", "B_clean_title": ["stackoverflowerror", "stack", "overflow", "error", "loadabledetachablemodel", "loadabl", "detach", "model"]},
{"A_title": "math Complex Tanh for big numbersHi  In Complex.java the tanh is computed with the following formula:  tanh(a + bi) = sinh(2a)/(cosh(2a)+cos(2b)) + sin(2b)/(cosh(2a)+cos(2b))i  The problem that Im finding is that as soon as a is a big number both sinh(2a) and cosh(2a) are infinity and then the method tanh returns in the real part NaN (infinity/infinity) when it should return 1.0.  Wouldnt it be appropiate to add something as in the FastMath library??:  if (real>20.0)       return createComplex(1.0 0.0);  if (real<-20.0)       return createComplex(-1.0 0.0);    Best regards  JBB", "A_clean_title": ["math", "complex", "tanh", "big", "numbershi", "number", "hi", "complex", "java", "tanh", "comput", "follow", "formula", "tanh", "bi", "sinh", "2a", "cosh", "2a", "+co", "2b", "sin", "2b", "cosh", "2a", "+co", "2b", "problem", "that", "im", "find", "that", "as", "soon", "as", "big", "number", "both", "sinh", "2a", "cosh", "2a", "are", "infin", "then", "method", "tanh", "return", "real", "part", "nan", "na", "infin", "infin", "when", "it", "return", "wouldnt", "it", "appropi", "add", "someth", "as", "fastmath", "fast", "math", "librari", "real", "20", "return", "createcomplex", "creat", "complex", "real", "20", "return", "createcomplex", "creat", "complex", "best", "regard", "jbb"], "B_title": "Introduced tests to guard against overflow (MATH-722). Corrected Javadoc and updated unit tests accordingly.", "B_clean_title": ["introduc", "test", "guard", "against", "overflow", "math", "722", "correct", "javadoc", "updat", "unit", "test", "accordingli"]},
{"A_title": "Incomplete beta function I(x a b) is inaccurate for large values of a and/or bThis was first reported in MATH-718. The result of the current implementation of the incomplete beta function I(x a b) is inaccurate when a and/or b are large-ish.     Ive skimmed through slatec|http://www.netlib.org/slatec/fnlib/betai.f GSL Boost|http://www.boost.org/doc/libs/1_38_0/libs/math/doc/sf_and_dist/html/math_toolkit/special/sf_beta/ibeta_function.html as well as NR. At first sight neither uses the same method to compute this function. I think TOMS-708|http://www.netlib.org/toms/708 is probably the best option.    _Issue moved from MATH project on January 27 2018 (concerned implementation was moved to module commons-numbers-gamma of Commons Numbers)._", "A_clean_title": ["incomplet", "beta", "function", "inaccur", "larg", "valu", "or", "bthi", "thi", "wa", "first", "report", "math", "718", "result", "current", "implement", "incomplet", "beta", "function", "inaccur", "when", "or", "are", "larg", "ish", "ive", "skim", "through", "slatec|http", "netlib", "www", "org", "slatec", "fnlib", "betai", "gsl", "boost|http", "boost", "html", "www", "38", "function", "org", "doc", "lib", "lib", "math", "doc", "sf", "dist", "html", "math", "toolkit", "special", "sf", "beta", "ibeta", "as", "well", "as", "nr", "at", "first", "sight", "neither", "use", "same", "method", "comput", "thi", "function", "think", "tom", "708|http", "netlib", "www", "org", "tom", "708", "probabl", "best", "option", "issu", "move", "math", "project", "januari", "27", "2018", "concern", "implement", "wa", "move", "modul", "common", "number", "gamma", "common", "number"], "B_title": "New implementation of Beta.logBeta(double double) based on the NSWC library of mathematical functions.   - increased accuracy   - deprecation of Beta.logBeta(double double double int) as the new     implementation is no longer iterative.   - some private methods are tested through reflection.", "B_clean_title": ["new", "implement", "beta", "logbeta", "log", "beta", "doubl", "doubl", "base", "nswc", "librari", "mathemat", "function", "increas", "accuraci", "deprec", "beta", "logbeta", "log", "beta", "doubl", "doubl", "doubl", "int", "as", "new", "implement", "no", "longer", "iter", "some", "privat", "method", "are", "test", "through", "reflect"]},
{"A_title": "Use of ThreadLocals in ToStringStyle and HashCodeBuilder trigger memory leaks in container environmentsThe thread local in org.apache.commons.lang3.builder.ToStringStyle is created but never removed and no API is provided to remove it. If a webapps use of LANG triggers the loading of this class a reference chain will be created that will cause a memory leak on web application reload. See http://markmail.org/thread/uetw2fdrsqgbh2cv for more info.", "A_clean_title": ["use", "threadloc", "thread", "local", "tostringstyl", "string", "style", "hashcodebuild", "hash", "code", "builder", "trigger", "memori", "leak", "contain", "environmentsth", "environ", "thread", "local", "org", "apach", "common", "lang3", "builder", "tostringstyl", "string", "style", "creat", "but", "never", "remov", "no", "api", "provid", "remov", "it", "webapp", "use", "lang", "trigger", "load", "thi", "class", "refer", "chain", "will", "creat", "that", "will", "caus", "memori", "leak", "web", "applic", "reload", "see", "http", "markmail", "org", "thread", "uetw2fdrsqgbh2cv", "more", "info"], "B_title": "part 2: refactor ToStringStyle and ToStringBuilderTest to verify that we are unsetting the registry when no longer needed", "B_clean_title": ["part", "refactor", "tostringstyl", "string", "style", "tostringbuildertest", "string", "builder", "test", "verifi", "that", "we", "are", "unset", "registri", "when", "no", "longer", "need"]},
{"A_title": "AccumuloVFSClassloader incorrectly treats folders as folders of jar filesSpecifying a directory of classes is incorrectly interpreted as a directory of jars in the general.dynamic.classpaths configuration property.  Example: adding a path such as *_ ACCUMULO_HOME/core/target/classes_* gets incorrectly interpreted as *_ ACCUMULO_HOME/core/target/classes/*_* and evaluates to *_ ACCUMULO_HOME/core/target/classes/org_* and *_ ACCUMULO_HOME/core/target/classes/META-INF_* but *NOT* to *_ ACCUMULO_HOME/core/target/classes_* as expected.", "A_clean_title": ["accumulovfsclassload", "accumulo", "vf", "classload", "incorrectli", "treat", "folder", "as", "folder", "jar", "filesspecifi", "file", "specifi", "directori", "class", "incorrectli", "interpret", "as", "directori", "jar", "gener", "dynam", "classpath", "configur", "properti", "exampl", "ad", "path", "such", "as", "accumulo", "home", "core", "target", "class", "get", "incorrectli", "interpret", "as", "accumulo", "home", "core", "target", "class", "evalu", "accumulo", "home", "core", "target", "class", "org", "accumulo", "inf", "home", "core", "target", "class", "meta", "but", "not", "accumulo", "home", "core", "target", "class", "as", "expect"], "B_title": "I jumped the gun", "B_clean_title": ["jump", "gun"]},
{"A_title": "Void is not added to TypeInfoParserList l = Arrays.asList(new Tuple2<VoidLong>(null 1L)); TypeInformation t = TypeInfoParser.parse(Tuple2<VoidLong>); DataSet<Tuple2<VoidLong>> data = env.fromCollection(l t); data.print(); Throws: Exception in thread main java.lang.IllegalArgumentException: String could not be parsed: Class Void could not be found for use as custom object. Please note that inner classes must be declared static. at org.apache.flink.api.java.typeutils.TypeInfoParser.parse(TypeInfoParser.java:90) at org.apache.flink.hadoopcompatibility.mapreduce.example.ParquetOutput.main(ParquetOutput.java:92) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134) Caused by: java.lang.IllegalArgumentException: Class Void could not be found for use as custom object. Please note that inner classes must be declared static. at org.apache.flink.api.java.typeutils.TypeInfoParser.parse(TypeInfoParser.java:290) at org.apache.flink.api.java.typeutils.TypeInfoParser.parse(TypeInfoParser.java:133) at org.apache.flink.api.java.typeutils.TypeInfoParser.parse(TypeInfoParser.java:88) ... 6 more", "A_clean_title": ["void", "not", "ad", "typeinfoparserlist", "type", "info", "parser", "list", "array", "aslist", "as", "list", "new", "tuple2", "voidlong", "void", "long", "null", "1l", "typeinform", "type", "inform", "typeinfopars", "pars", "type", "info", "parser", "tuple2", "voidlong", "void", "long", "dataset", "data", "set", "tuple2", "voidlong", "void", "long", "data", "env", "fromcollect", "collect", "data", "print", "throw", "except", "thread", "main", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "string", "could", "not", "pars", "class", "void", "could", "not", "found", "use", "as", "custom", "object", "pleas", "note", "that", "inner", "class", "must", "declar", "static", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeinfopars", "pars", "type", "info", "parser", "typeinfopars", "java:90", "type", "info", "parser", "at", "org", "apach", "flink", "hadoopcompat", "mapreduc", "exampl", "parquetoutput", "main", "parquet", "output", "parquetoutput", "java:92", "parquet", "output", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:57", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:43", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:606", "at", "com", "intellij", "rt", "execut", "applic", "appmain", "main", "app", "main", "appmain", "java:134", "app", "main", "caus", "by", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "class", "void", "could", "not", "found", "use", "as", "custom", "object", "pleas", "note", "that", "inner", "class", "must", "declar", "static", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeinfopars", "pars", "type", "info", "parser", "typeinfopars", "java:290", "type", "info", "parser", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeinfopars", "pars", "type", "info", "parser", "typeinfopars", "java:133", "type", "info", "parser", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeinfopars", "pars", "type", "info", "parser", "typeinfopars", "java:88", "type", "info", "parser", "more"], "B_title": "Adds the new basic types Void and Date to the TypeInfoParser", "B_clean_title": ["add", "new", "basic", "type", "void", "date", "typeinfopars", "type", "info", "parser"]},
{"A_title": "Entries in _commitRoot not purgedEntries in _commitRoot are not purged or moved to previous documents if there are no changes with those revisions. Usually there is always a change associated with a _commitRoot but in some cases it may happen that the only update on the document is for non-revisioned data like the _children flag.", "A_clean_title": ["entri", "commitroot", "commit", "root", "not", "purgedentri", "purg", "entri", "commitroot", "commit", "root", "are", "not", "purg", "or", "move", "previou", "document", "there", "are", "no", "chang", "those", "revis", "usual", "there", "alway", "chang", "associ", "commitroot", "commit", "root", "but", "some", "case", "it", "may", "happen", "that", "onli", "updat", "document", "non", "revis", "data", "like", "children", "flag"], "B_title": "Entries in _commitRoot not purged", "B_clean_title": ["entri", "commitroot", "commit", "root", "not", "purg"]},
{"A_title": "Boosting fields not working as expectedWhen the boost support was added the intention was to support a usecase like   quote For the fulltext search on a node where the fulltext content is derived from multiple field it should be possible to boost specific text contributed by individual field. Meaning that if a title field is boosted more than description the title (part) in the fulltext field will mean more than the description (part) in the fulltext field. quote  This would enable a user to perform a search like _/jcr:root/content/geometrixx-outdoors/en//element(* cq:Page)jcr:contains(. Keyword)_ and get a result where pages having Keyword in title come above in search result compared to those where Keyword is found in description.  Current implementation just sets the boost while add the field value to fulltext field with the intention that Lucene would use the boost as explained above. However it does not work like that and boost value gets multiplies with other field and hence boosting does not work as expected", "A_clean_title": ["boost", "field", "not", "work", "as", "expectedwhen", "expect", "when", "boost", "support", "wa", "ad", "intent", "wa", "support", "usecas", "like", "quot", "fulltext", "search", "node", "where", "fulltext", "content", "deriv", "multipl", "field", "it", "possibl", "boost", "specif", "text", "contribut", "by", "individu", "field", "mean", "that", "titl", "field", "boost", "more", "than", "descript", "titl", "part", "fulltext", "field", "will", "mean", "more", "than", "descript", "part", "fulltext", "field", "quot", "thi", "would", "enabl", "user", "perform", "search", "like", "jcr", "root", "content", "geometrixx", "outdoor", "en", "element", "cq", "page", "jcr", "contain", "keyword", "get", "result", "where", "page", "have", "keyword", "titl", "come", "abov", "search", "result", "compar", "those", "where", "keyword", "found", "descript", "current", "implement", "just", "set", "boost", "while", "add", "field", "valu", "fulltext", "field", "intent", "that", "lucen", "would", "use", "boost", "as", "explain", "abov", "howev", "it", "not", "work", "like", "that", "boost", "valu", "get", "multipli", "other", "field", "henc", "boost", "not", "work", "as", "expect"], "B_title": "- Boosting fields not working as expected", "B_clean_title": ["boost", "field", "not", "work", "as", "expect"]},
{"A_title": "implementation of smallest enclosing ball algorithm sometime failsThe algorithm for finding the smallest ball is designed in such a way the radius should be strictly increasing at each iteration.  In some cases it is not true and one iteration has a smaller ball. In most cases there is no consequence there is just one or two more iterations. However in rare cases discovered while testing 3D this generates an infinite loop.  Some very short offending cases have already been identified and added to the test suite. These cases are currently deactivated in the main repository while I am already working on them. The test cases are  * WelzlEncloser2DTest.testReducingBall * WelzlEncloser2DTest.testLargeSamples * WelzlEncloser3DTest.testInfiniteLoop * WelzlEncloser3DTest.testLargeSamples", "A_clean_title": ["implement", "smallest", "enclos", "ball", "algorithm", "sometim", "failsth", "fail", "algorithm", "find", "smallest", "ball", "design", "such", "way", "radiu", "strictli", "increas", "at", "each", "iter", "some", "case", "it", "not", "true", "one", "iter", "ha", "smaller", "ball", "most", "case", "there", "no", "consequ", "there", "just", "one", "or", "two", "more", "iter", "howev", "rare", "case", "discov", "while", "test", "3d", "thi", "gener", "infinit", "loop", "some", "veri", "short", "offend", "case", "have", "alreadi", "been", "identifi", "ad", "test", "suit", "these", "case", "are", "current", "deactiv", "main", "repositori", "while", "am", "alreadi", "work", "them", "test", "case", "are", "welzlencloser2dtest", "testreducingbal", "welzl", "encloser2d", "test", "test", "reduc", "ball", "welzlencloser2dtest", "testlargesampl", "welzl", "encloser2d", "test", "test", "larg", "sampl", "welzlencloser3dtest", "testinfiniteloop", "welzl", "encloser3d", "test", "test", "infinit", "loop", "welzlencloser3dtest", "testlargesampl", "welzl", "encloser3d", "test", "test", "larg", "sampl"], "B_title": "Partly fixed MATH-1096.", "B_clean_title": ["partli", "fix", "math", "1096"]},
{"A_title": "Property Index: cost calculation is wrong (zero) when searching for many valuesCurrently for queries of the form   code select * from nt:unstructured where type = xyz code  the node type index is used in some cases even if there is an index on the property type. The reason is that the cost for the node type index is 0 due to a bug. The node type index internally uses the property index on the property jcr:primaryType and asks for the cost using all possible children node types of nt:unstructured. The returned cost is 0 because of this bug. The cost estimation is an extrapolation of the number of entries for the first 3 values. It is currently coded as:  code count = count / size / i; code  when in fact it should be written as:  code count = count * size / i; code", "A_clean_title": ["properti", "index", "cost", "calcul", "wrong", "zero", "when", "search", "mani", "valuescurr", "valu", "current", "queri", "form", "code", "select", "nt", "unstructur", "where", "type", "xyz", "code", "node", "type", "index", "use", "some", "case", "even", "there", "index", "properti", "type", "reason", "that", "cost", "node", "type", "index", "due", "bug", "node", "type", "index", "intern", "use", "properti", "index", "properti", "jcr", "primarytyp", "primari", "type", "ask", "cost", "all", "possibl", "children", "node", "type", "nt", "unstructur", "return", "cost", "becaus", "thi", "bug", "cost", "estim", "extrapol", "number", "entri", "first", "valu", "it", "current", "code", "as", "code", "count", "count", "size", "code", "when", "fact", "it", "written", "as", "code", "count", "count", "size", "code"], "B_title": "Property Index: cost calculation is wrong (zero) when searching for many values", "B_clean_title": ["properti", "index", "cost", "calcul", "wrong", "zero", "when", "search", "mani", "valu"]},
{"A_title": "Dont allow viewfs in instance.volumesI think one of our folks put viewfs into instance.volumes on accident. File references in accumulo.root and accumulo.metadata were then written with viewfs in the path. The garbage collector then throws errors as compactions occur and it tries delete and move the files to the hdfs users trash directory.  viewfs should never be allowed in instance.volumes property. It should fail.", "A_clean_title": ["dont", "allow", "viewf", "instanc", "volumesi", "volum", "think", "one", "our", "folk", "put", "viewf", "into", "instanc", "volum", "accid", "file", "refer", "accumulo", "root", "accumulo", "metadata", "were", "then", "written", "viewf", "path", "garbag", "collector", "then", "throw", "error", "as", "compact", "occur", "it", "tri", "delet", "move", "file", "hdf", "user", "trash", "directori", "viewf", "never", "allow", "instanc", "volum", "properti", "it", "fail"], "B_title": "check for viewfs", "B_clean_title": ["check", "viewf"]},
{"A_title": "MultiDirectional optimzation loops forver if started at the correct solutionMultiDirectional.iterateSimplex loops forever if the starting point is the correct solution. see the attached test case (testMultiDirectionalCorrectStart) as an example.", "A_clean_title": ["multidirect", "multi", "direct", "optimz", "loop", "forver", "start", "at", "correct", "solutionmultidirect", "iteratesimplex", "solut", "multi", "direct", "iter", "simplex", "loop", "forev", "start", "point", "correct", "solut", "see", "attach", "test", "case", "testmultidirectionalcorrectstart", "test", "multi", "direct", "correct", "start", "as", "exampl"], "B_title": "Prevent infinite loops in multi-directional direct optimization method when the start point is exactly at the optimal point JIRA: MATH-283", "B_clean_title": ["prevent", "infinit", "loop", "multi", "direct", "direct", "optim", "method", "when", "start", "point", "exactli", "at", "optim", "point", "jira", "math", "283"]},
{"A_title": "Node.hasNode(foo2) must not throw PathNotFoundExceptionsimilar to OAK-1225 Node.hasNode(foo2) should return false", "A_clean_title": ["node", "hasnod", "ha", "node", "foo2", "must", "not", "throw", "pathnotfoundexceptionsimilar", "path", "not", "found", "exceptionsimilar", "oak", "1225", "node", "hasnod", "ha", "node", "foo2", "return", "fals"], "B_title": "Node.hasNode(foo2) must not throw PathNotFoundException", "B_clean_title": ["node", "hasnod", "ha", "node", "foo2", "must", "not", "throw", "pathnotfoundexcept", "path", "not", "found", "except"]},
{"A_title": "Percentile Computation errsIn the following test the 75th percentile is _smaller_ than the 25th percentile leaving me with a negative interquartile range.  code:title=Bar.java|borderStyle=solid @Test public void negativePercentiles()          double data = new double                 -0.012086732064244697                  -0.24975668704012527                  0.5706168483164684                  -0.322111769955327                  0.24166759508327315                  Double.NaN                  0.16698443218942854                  -0.10427763937565114                  -0.15595963093172435                  -0.028075857595882995                  -0.24137994506058857                  0.47543170476574426                  -0.07495595384947631                  0.37445697625436497                  -0.09944199541668033         ;         DescriptiveStatistics descriptiveStatistics = new DescriptiveStatistics(data);          double threeQuarters = descriptiveStatistics.getPercentile(75);         double oneQuarter = descriptiveStatistics.getPercentile(25);          double IQR = threeQuarters - oneQuarter;                  System.out.println(String.format(25th percentile %s 75th percentile %s oneQuarter threeQuarters ));                  assert IQR >= 0;               code", "A_clean_title": ["percentil", "comput", "errsin", "err", "follow", "test", "75th", "percentil", "smaller", "than", "25th", "percentil", "leav", "me", "neg", "interquartil", "rang", "code", "title=bar", "java|borderstyle=solid", "java|bord", "style=solid", "test", "public", "void", "negativepercentil", "neg", "percentil", "doubl", "data", "new", "doubl", "012086732064244697", "24975668704012527", "5706168483164684", "322111769955327", "24166759508327315", "doubl", "nan", "na", "16698443218942854", "10427763937565114", "15595963093172435", "028075857595882995", "24137994506058857", "47543170476574426", "07495595384947631", "37445697625436497", "09944199541668033", "descriptivestatist", "descript", "statist", "descriptivestatist", "descript", "statist", "new", "descriptivestatist", "descript", "statist", "data", "doubl", "threequart", "three", "quarter", "descriptivestatist", "getpercentil", "descript", "statist", "get", "percentil", "75", "doubl", "onequart", "one", "quarter", "descriptivestatist", "getpercentil", "descript", "statist", "get", "percentil", "25", "doubl", "iqr", "threequart", "three", "quarter", "onequart", "one", "quarter", "system", "out", "println", "string", "format", "25th", "percentil", "75th", "percentil", "onequart", "one", "quarter", "threequart", "three", "quarter", "assert", "iqr", "code"], "B_title": "Fix wrong sorting in the presence of NaN.", "B_clean_title": ["fix", "wrong", "sort", "presenc", "nan", "na"]},
{"A_title": "Lucene AND query with a complex OR phrase returns incorrect resultQueries like this noformat/jcr:root/content//element(* test:Asset)(jcr:contains(. cube)) and (jcr:contains(jcr:content/@foo a OR b)) noformat returns wrong results.  This get converted to noformat+:fulltext:cube full:jcr:content/foo:a full:jcr:content/foo:b noformat", "A_clean_title": ["lucen", "queri", "complex", "or", "phrase", "return", "incorrect", "resultqueri", "result", "queri", "like", "thi", "noformat", "jcr", "root", "content", "element", "test", "asset", "jcr", "contain", "cube", "jcr", "contain", "jcr", "content", "foo", "or", "noformat", "return", "wrong", "result", "thi", "get", "convert", "noformat+", "fulltext", "cube", "full", "jcr", "content", "foo", "full", "jcr", "content", "foo", "noformat"], "B_title": "Lucene AND query with a complex OR phrase returns incorrect result Fixed by not flattening the boolean query", "B_clean_title": ["lucen", "queri", "complex", "or", "phrase", "return", "incorrect", "result", "fix", "by", "not", "flatten", "boolean", "queri"]},
{"A_title": "Page header isnt rendered for pages where URL has changed during renderDue to the changes in WICKET-5309 a page is re-rendered when any of the URL segments is modified during the request:  From WebPageRenderer.java:  code // the url might have changed after page has been rendered (e.g. the // stateless flag might have changed because stateful components // were added) final Url afterRenderUrl = requestCycle .mapUrlFor(getRenderPageRequestHandler());  if (beforeRenderUrl.getSegments().equals(afterRenderUrl.getSegments()) == false)  // the amount of segments is different - generated relative URLs // will not work we need to rerender the page. This can happen // with IRequestHandlers that produce different URLs with // different amount of segments for stateless and stateful pages response = renderPage(afterRenderUrl requestCycle);   if (currentUrl.equals(afterRenderUrl)) code  The re-render causes the <head> section to be empty because it was already rendered in the first try.", "A_clean_title": ["page", "header", "isnt", "render", "page", "where", "url", "ha", "chang", "dure", "renderdu", "render", "due", "chang", "wicket", "5309", "page", "re", "render", "when", "ani", "url", "segment", "modifi", "dure", "request", "webpagerender", "java", "web", "page", "render", "code", "url", "might", "have", "chang", "after", "page", "ha", "been", "render", "stateless", "flag", "might", "have", "chang", "becaus", "state", "compon", "were", "ad", "final", "url", "afterrenderurl", "after", "render", "url", "requestcycl", "request", "cycl", "mapurlfor", "map", "url", "getrenderpagerequesthandl", "get", "render", "page", "request", "handler", "beforerenderurl", "getseg", "befor", "render", "url", "get", "segment", "equal", "afterrenderurl", "getseg", "after", "render", "url", "get", "segment", "fals", "amount", "segment", "differ", "gener", "rel", "url", "ur", "ls", "will", "not", "work", "we", "need", "rerend", "page", "thi", "happen", "irequesthandl", "request", "handler", "that", "produc", "differ", "url", "ur", "ls", "differ", "amount", "segment", "stateless", "state", "page", "respons", "renderpag", "render", "page", "afterrenderurl", "after", "render", "url", "requestcycl", "request", "cycl", "currenturl", "equal", "current", "url", "afterrenderurl", "after", "render", "url", "code", "re", "render", "caus", "head", "section", "empti", "becaus", "it", "wa", "alreadi", "render", "first", "tri"], "B_title": "drop headerResponse and renderedComponentsPerScope in #onAfterRender() so a second rendering re-renders the header", "B_clean_title": ["drop", "headerrespons", "header", "respons", "renderedcomponentsperscop", "render", "compon", "per", "scope", "onafterrend", "after", "render", "so", "second", "render", "re", "render", "header"]},
{"A_title": "new multivariate vector optimizers cannot be used with large number of weightsWhen using the Weigth class to pass a large number of weights to multivariate vector optimizers an nxn full matrix is created (and copied) when a n elements vector is used. This exhausts memory when n is large. This happens for example when using curve fitters (even simple curve fitters like polynomial ones for low degree) with large number of points. I encountered this with curve fitting on 41200 points which created a matrix with 1.7 billion elements.", "A_clean_title": ["new", "multivari", "vector", "optim", "not", "use", "larg", "number", "weightswhen", "weight", "when", "weigth", "class", "pass", "larg", "number", "weight", "multivari", "vector", "optim", "nxn", "full", "matrix", "creat", "copi", "when", "element", "vector", "use", "thi", "exhaust", "memori", "when", "larg", "thi", "happen", "exampl", "when", "curv", "fitter", "even", "simpl", "curv", "fitter", "like", "polynomi", "one", "low", "degre", "larg", "number", "point", "encount", "thi", "curv", "fit", "41200", "point", "which", "creat", "matrix", "billion", "element"], "B_title": "Avoid memory exhaustion for large number of unclorrelated observations.", "B_clean_title": ["avoid", "memori", "exhaust", "larg", "number", "unclorrel", "observ"]},
{"A_title": "BrentOptimizer not always reporting the best pointBrentOptimizer (package o.a.c.m.optimization.univariate) does not check that the point it is going to return is indeed the best one it has encountered. Indeed the last evaluated point might be slightly worse than the one before last.", "A_clean_title": ["brentoptim", "brent", "optim", "not", "alway", "report", "best", "pointbrentoptim", "point", "brent", "optim", "packag", "optim", "univari", "not", "check", "that", "point", "it", "go", "return", "inde", "best", "one", "it", "ha", "encount", "inde", "last", "evalu", "point", "might", "slightli", "wors", "than", "one", "befor", "last"], "B_title": "The best point is sometimes not the last one evaluated.", "B_clean_title": ["best", "point", "sometim", "not", "last", "one", "evalu"]},
{"A_title": "CEP operator does not forward watermarks properlyThe CEP stream operator dont emit a proper watermark when using event time.", "A_clean_title": ["cep", "oper", "not", "forward", "watermark", "properlyth", "properli", "cep", "stream", "oper", "dont", "emit", "proper", "watermark", "when", "event", "time"], "B_title": "cep Add proper watermark emission to CEP operators", "B_clean_title": ["cep", "add", "proper", "watermark", "emiss", "cep", "oper"]},
{"A_title": "ClientConfiguration.getAllPropertiesWithPrefix doesnt workI think I introduced this method for trace.span.receiver.* and didnt write a test for it.  My mistake.", "A_clean_title": ["clientconfigur", "getallpropertieswithprefix", "client", "configur", "get", "all", "properti", "prefix", "doesnt", "worki", "work", "think", "introduc", "thi", "method", "trace", "span", "receiv", "didnt", "write", "test", "it", "my", "mistak"], "B_title": "fix ClientConfiguration.getAllPropertiesWithPrefix and add test", "B_clean_title": ["fix", "clientconfigur", "getallpropertieswithprefix", "client", "configur", "get", "all", "properti", "prefix", "add", "test"]},
{"A_title": "Validity checks missing for readFields and Thrift deserializationClasses in o.a.a.core.data (and potentially elsewhere) that support construction from a Thrift object and/or population from a DataInput (via a readFields() method) often lack data validity checks that the classes constructors enforce. The missing checks make it possible for an attacker to create invalid objects by manipulating the bytes being read. The situation is analogous to the need to check objects deserialized from their Java serialized form within the readObject() method.", "A_clean_title": ["valid", "check", "miss", "readfield", "read", "field", "thrift", "deserializationclass", "deseri", "class", "core", "data", "potenti", "elsewher", "that", "support", "construct", "thrift", "object", "or", "popul", "datainput", "data", "input", "via", "readfield", "read", "field", "method", "often", "lack", "data", "valid", "check", "that", "class", "constructor", "enforc", "miss", "check", "make", "it", "possibl", "attack", "creat", "invalid", "object", "by", "manipul", "byte", "be", "read", "situat", "analog", "need", "check", "object", "deseri", "their", "java", "serial", "form", "within", "readobject", "read", "object", "method"], "B_title": "Add data integrity checks to Key and Mutation", "B_clean_title": ["add", "data", "integr", "check", "key", "mutat"]},
{"A_title": "RepositoryBeanNameGenerator fails to resolve bean names for custom implementations detected via Springs component index DATACMNS-1115opened and commented After upgrading to Spring Boot 2.0.0.M2 and Spring Data Kay.M4 I cannot start my microservices any more which are accessing MongoDB. A testcase is appended to produce the stacktrace below.  First I thought it is a Spring Boot issue spring-projects/spring-boot#9780 Stacktrace:    Affects: 2.0 M4 (Kay)  Attachments:     Backported to:  1.13.5 (Ingalls SR5)  1.12.12 (Hopper SR12)", "A_clean_title": ["repositorybeannamegener", "repositori", "bean", "name", "gener", "fail", "resolv", "bean", "name", "custom", "implement", "detect", "via", "spring", "compon", "index", "datacmn", "1115open", "comment", "after", "upgrad", "spring", "boot", "m2", "spring", "data", "kay", "m4", "not", "start", "my", "microservic", "ani", "more", "which", "are", "access", "mongodb", "mongo", "db", "testcas", "append", "produc", "stacktrac", "below", "first", "thought", "it", "spring", "boot", "issu", "spring", "boot", "project", "spring", "9780", "stacktrac", "affect", "m4", "kay", "attach", "backport", "13", "ingal", "sr5", "12", "12", "hopper", "sr12"], "B_title": "DATACMNS-1115 - Improve RepositoryBeanNameGenerator to properly resolve bean names for indexed BeanDefinitions.  Previously RepositoryBeanNameGenerator applied the custom bean name lookup if the BeanDefinition given was not a ScannedGenericBeanDefinition. That in turn had been the case for custom implementation classes that were obtained through classpath scanning. With Spring 5 an index file can be used by the scanner which in turn will cause AnnotatedGenericBeanDefinition instances being returned. That caused the code path to lookup the first constructor argument to kick in (usually used to obtain the repository interface from repository factory beans) and cause a NullPointerException.  We now forward AnnotatedBeanDefinitions as is and only apply the custom lookup for everything else i.e. the bean definitions used for the factories.", "B_clean_title": ["datacmn", "1115", "improv", "repositorybeannamegener", "repositori", "bean", "name", "gener", "properli", "resolv", "bean", "name", "index", "beandefinit", "bean", "definit", "previous", "repositorybeannamegener", "repositori", "bean", "name", "gener", "appli", "custom", "bean", "name", "lookup", "beandefinit", "bean", "definit", "given", "wa", "not", "scannedgenericbeandefinit", "scan", "gener", "bean", "definit", "that", "turn", "had", "been", "case", "custom", "implement", "class", "that", "were", "obtain", "through", "classpath", "scan", "spring", "index", "file", "use", "by", "scanner", "which", "turn", "will", "caus", "annotatedgenericbeandefinit", "annot", "gener", "bean", "definit", "instanc", "be", "return", "that", "caus", "code", "path", "lookup", "first", "constructor", "argument", "kick", "usual", "use", "obtain", "repositori", "interfac", "repositori", "factori", "bean", "caus", "nullpointerexcept", "null", "pointer", "except", "we", "now", "forward", "annotatedbeandefinit", "annot", "bean", "definit", "as", "onli", "appli", "custom", "lookup", "everyth", "bean", "definit", "use", "factori"]},
{"A_title": "Shell displays authTimeout poorlyThe authTimeout in the shell is displayed badly when executing about -v. Even though it is configured in integer minutes it is converted to seconds for display as a floating point number with 2 decimals. This makes no sense since the decimals will always be .00.  We can keep the units in seconds I guess but this needs to be displayed with %ds not %.2fs. This was broken in ACCUMULO-3224 by using TimeUnit to convert the number instead of dividing by 1000.0 as we were doing manually before.", "A_clean_title": ["shell", "display", "authtimeout", "auth", "timeout", "poorlyth", "poorli", "authtimeout", "auth", "timeout", "shell", "display", "badli", "when", "execut", "about", "even", "though", "it", "configur", "integ", "minut", "it", "convert", "second", "display", "as", "float", "point", "number", "decim", "thi", "make", "no", "sens", "sinc", "decim", "will", "alway", "00", "we", "keep", "unit", "second", "guess", "but", "thi", "need", "display", "ds", "not", "2f", "thi", "wa", "broken", "accumulo", "3224", "by", "timeunit", "time", "unit", "convert", "number", "instead", "divid", "by", "1000", "as", "we", "were", "do", "manual", "befor"], "B_title": "Format long as decimal integer not floating-point", "B_clean_title": ["format", "long", "as", "decim", "integ", "not", "float", "point"]},
{"A_title": "Lucene Index should ignore property existence checksSome optimizations on the query engine transform certain clauses in property existence checks. ie (p = somevalue turns into p is not null).  This doesnt play well with lucene as it can not  effectively build a not null query even worse the query doesnt return any results.  As a fix Ill just skip the existence constraints from the generated lucene query.", "A_clean_title": ["lucen", "index", "ignor", "properti", "exist", "checkssom", "check", "some", "optim", "queri", "engin", "transform", "certain", "claus", "properti", "exist", "check", "ie", "somevalu", "turn", "into", "not", "null", "thi", "doesnt", "play", "well", "lucen", "as", "it", "not", "effect", "build", "not", "null", "queri", "even", "wors", "queri", "doesnt", "return", "ani", "result", "as", "fix", "ill", "just", "skip", "exist", "constraint", "gener", "lucen", "queri"], "B_title": "Lucene Index should ignore property existence checks", "B_clean_title": ["lucen", "index", "ignor", "properti", "exist", "check"]}]