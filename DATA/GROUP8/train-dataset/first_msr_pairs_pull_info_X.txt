[{"A_title": "StopWatch: suspend() acts as split() if followed by stop()In my opinion it is a bug that suspend() acts as split() if followed by stop(); see below:         StopWatch sw = new StopWatch();         sw.start();         Thread.sleep(1000);         sw.suspend();         // Time 1 (ok)         System.out.println(sw.getTime());         Thread.sleep(2000);         // Time 1 (again ok)         System.out.println(sw.getTime());         sw.resume();         Thread.sleep(3000);         sw.suspend();         // Time 2 (ok)         System.out.println(sw.getTime());         Thread.sleep(4000);         // Time 2 (again ok)         System.out.println(sw.getTime());         Thread.sleep(5000);         sw.stop();         // Time 2 (should be but is Time 3 => NOT ok)         System.out.println(sw.getTime()); suspend/resume is like a pause where time counter doesnt continue. So a following stop()-call shouldnt increase the time counter should it?", "A_clean_title": ["stopwatch", "stop", "watch", "suspend", "act", "as", "split", "follow", "by", "stop", "my", "opinion", "it", "bug", "that", "suspend", "act", "as", "split", "follow", "by", "stop", "see", "below", "stopwatch", "stop", "watch", "sw", "new", "stopwatch", "stop", "watch", "sw", "start", "thread", "sleep", "1000", "sw", "suspend", "time", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "thread", "sleep", "2000", "time", "again", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "sw", "resum", "thread", "sleep", "3000", "sw", "suspend", "time", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "thread", "sleep", "4000", "time", "again", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "thread", "sleep", "5000", "sw", "stop", "time", "but", "time", "not", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "suspend", "resum", "like", "paus", "where", "time", "counter", "doesnt", "continu", "so", "follow", "stop", "call", "shouldnt", "increas", "time", "counter", "it"], "B_title": "Add a test to make sure that no one keeps being left in StopWatch after a running state ==. ", "B_clean_title": ["add", "test", "make", "sure", "that", "no", "one", "keep", "be", "left", "stopwatch", "stop", "watch", "after", "run", "state"]},
{"A_title": "StopWatch: suspend() acts as split() if followed by stop()In my opinion it is a bug that suspend() acts as split() if followed by stop(); see below:         StopWatch sw = new StopWatch();         sw.start();         Thread.sleep(1000);         sw.suspend();         // Time 1 (ok)         System.out.println(sw.getTime());         Thread.sleep(2000);         // Time 1 (again ok)         System.out.println(sw.getTime());         sw.resume();         Thread.sleep(3000);         sw.suspend();         // Time 2 (ok)         System.out.println(sw.getTime());         Thread.sleep(4000);         // Time 2 (again ok)         System.out.println(sw.getTime());         Thread.sleep(5000);         sw.stop();         // Time 2 (should be but is Time 3 => NOT ok)         System.out.println(sw.getTime()); suspend/resume is like a pause where time counter doesnt continue. So a following stop()-call shouldnt increase the time counter should it?", "A_clean_title": ["stopwatch", "stop", "watch", "suspend", "act", "as", "split", "follow", "by", "stop", "my", "opinion", "it", "bug", "that", "suspend", "act", "as", "split", "follow", "by", "stop", "see", "below", "stopwatch", "stop", "watch", "sw", "new", "stopwatch", "stop", "watch", "sw", "start", "thread", "sleep", "1000", "sw", "suspend", "time", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "thread", "sleep", "2000", "time", "again", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "sw", "resum", "thread", "sleep", "3000", "sw", "suspend", "time", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "thread", "sleep", "4000", "time", "again", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "thread", "sleep", "5000", "sw", "stop", "time", "but", "time", "not", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "suspend", "resum", "like", "paus", "where", "time", "counter", "doesnt", "continu", "so", "follow", "stop", "call", "shouldnt", "increas", "time", "counter", "it"], "B_title": "Fixed bug in StopWatch . stopTime. ", "B_clean_title": ["fix", "bug", "stopwatch", "stop", "watch", "stoptim", "stop", "time"]},
{"A_title": "Record type invalid property not reported on function with @this annotationNone", "A_clean_title": ["record", "type", "invalid", "properti", "not", "report", "function", "thi", "annotationnon", "annot", "none"], "B_title": "Fix wrong closing curly brace in object literals. ", "B_clean_title": ["fix", "wrong", "close", "curli", "brace", "object", "liter"]},
{"A_title": "HypergeometricDistribution.sample suffers from integer overflowHi I have an application which broke when ported from commons math 2.2 to 3.2. It looks like the HypergeometricDistribution.sample() method doesnt work as well as it used to with large integer values – the example code below should return a sample between 0 and 50 but usually returns -50.  import org.apache.commons.math3.distribution.HypergeometricDistribution;  public class Foo    public static void main(String args)      HypergeometricDistribution a = new HypergeometricDistribution(         43130568 42976365 50);     System.out.printf(%d %d%n a.getSupportLowerBound() a.getSupportUpperBound()); // Prints 0 50     System.out.printf(%d%na.sample());                                             // Prints -50       In the debugger I traced it as far as an integer overflow in HypergeometricDistribution.getNumericalMean() – instead of doing  return (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();   it could do:  return getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());   This seemed to fix it based on a quick test.", "A_clean_title": ["hypergeometricdistribut", "sampl", "hypergeometr", "distribut", "suffer", "integ", "overflowhi", "overflow", "hi", "have", "applic", "which", "broke", "when", "port", "common", "math", "it", "look", "like", "hypergeometricdistribut", "sampl", "hypergeometr", "distribut", "method", "doesnt", "work", "as", "well", "as", "it", "use", "larg", "integ", "valu", "exampl", "code", "below", "return", "sampl", "between", "50", "but", "usual", "return", "50", "import", "org", "apach", "common", "math3", "distribut", "hypergeometricdistribut", "hypergeometr", "distribut", "public", "class", "foo", "public", "static", "void", "main", "string", "arg", "hypergeometricdistribut", "hypergeometr", "distribut", "new", "hypergeometricdistribut", "hypergeometr", "distribut", "43130568", "42976365", "50", "system", "out", "printf", "getsupportlowerbound", "get", "support", "lower", "bound", "getsupportupperbound", "get", "support", "upper", "bound", "print", "50", "system", "out", "printf", "na", "sampl", "print", "50", "debugg", "trace", "it", "as", "far", "as", "integ", "overflow", "hypergeometricdistribut", "getnumericalmean", "hypergeometr", "distribut", "get", "numer", "mean", "instead", "do", "return", "doubl", "getsamples", "get", "sampl", "size", "getnumberofsuccess", "get", "number", "success", "doubl", "getpopulations", "get", "popul", "size", "it", "could", "return", "getsamples", "get", "sampl", "size", "doubl", "getnumberofsuccess", "get", "number", "success", "doubl", "getpopulations", "get", "popul", "size", "thi", "seem", "fix", "it", "base", "quick", "test"], "B_title": "Fix numeric mean .. ", "B_clean_title": ["fix", "numer", "mean"]},
{"A_title": "HypergeometricDistribution.sample suffers from integer overflowHi I have an application which broke when ported from commons math 2.2 to 3.2. It looks like the HypergeometricDistribution.sample() method doesnt work as well as it used to with large integer values – the example code below should return a sample between 0 and 50 but usually returns -50.  import org.apache.commons.math3.distribution.HypergeometricDistribution;  public class Foo    public static void main(String args)      HypergeometricDistribution a = new HypergeometricDistribution(         43130568 42976365 50);     System.out.printf(%d %d%n a.getSupportLowerBound() a.getSupportUpperBound()); // Prints 0 50     System.out.printf(%d%na.sample());                                             // Prints -50       In the debugger I traced it as far as an integer overflow in HypergeometricDistribution.getNumericalMean() – instead of doing  return (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();   it could do:  return getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());   This seemed to fix it based on a quick test.", "A_clean_title": ["hypergeometricdistribut", "sampl", "hypergeometr", "distribut", "suffer", "integ", "overflowhi", "overflow", "hi", "have", "applic", "which", "broke", "when", "port", "common", "math", "it", "look", "like", "hypergeometricdistribut", "sampl", "hypergeometr", "distribut", "method", "doesnt", "work", "as", "well", "as", "it", "use", "larg", "integ", "valu", "exampl", "code", "below", "return", "sampl", "between", "50", "but", "usual", "return", "50", "import", "org", "apach", "common", "math3", "distribut", "hypergeometricdistribut", "hypergeometr", "distribut", "public", "class", "foo", "public", "static", "void", "main", "string", "arg", "hypergeometricdistribut", "hypergeometr", "distribut", "new", "hypergeometricdistribut", "hypergeometr", "distribut", "43130568", "42976365", "50", "system", "out", "printf", "getsupportlowerbound", "get", "support", "lower", "bound", "getsupportupperbound", "get", "support", "upper", "bound", "print", "50", "system", "out", "printf", "na", "sampl", "print", "50", "debugg", "trace", "it", "as", "far", "as", "integ", "overflow", "hypergeometricdistribut", "getnumericalmean", "hypergeometr", "distribut", "get", "numer", "mean", "instead", "do", "return", "doubl", "getsamples", "get", "sampl", "size", "getnumberofsuccess", "get", "number", "success", "doubl", "getpopulations", "get", "popul", "size", "it", "could", "return", "getsamples", "get", "sampl", "size", "doubl", "getnumberofsuccess", "get", "number", "success", "doubl", "getpopulations", "get", "popul", "size", "thi", "seem", "fix", "it", "base", "quick", "test"], "B_title": "Remove extraneous whitespace. ", "B_clean_title": ["remov", "extran", "whitespac"]},
{"A_title": "too large first step with embedded Runge-Kutta integrators (Dormand-Prince 8(53) ...)Adaptive step size integrators compute the first step size by themselves if it is not provided. For embedded Runge-Kutta type this step size is not checked against the integration range so if the integration range is extremely short this step size may evaluate the function out of the range (and in fact it tries afterward to go back and fails to stop). Gragg-Bulirsch-Stoer integrators do not have this problem the step size is checked and truncated if needed.", "A_clean_title": ["too", "larg", "first", "step", "embed", "rung", "kutta", "integr", "dormand", "princ", "53", "adapt", "step", "size", "integr", "comput", "first", "step", "size", "by", "themselv", "it", "not", "provid", "embed", "rung", "kutta", "type", "thi", "step", "size", "not", "check", "against", "integr", "rang", "so", "integr", "rang", "extrem", "short", "thi", "step", "size", "may", "evalu", "function", "out", "rang", "fact", "it", "tri", "afterward", "go", "back", "fail", "stop", "gragg", "bulirsch", "stoer", "integr", "not", "have", "thi", "problem", "step", "size", "check", "truncat", "need"], "B_title": "Fix step size = t - stepStart ;. ", "B_clean_title": ["fix", "step", "size", "stepstart", "step", "start"]},
{"A_title": "Add support for --manage_closure_dependencies and --only_closure_dependencies with compilation level WHITESPACE_ONLYNone", "A_clean_title": ["add", "support", "manag", "closur", "depend", "onli", "closur", "depend", "compil", "level", "whitespac", "onlynon", "onli", "none"], "B_title": "improve comment. ", "B_clean_title": ["improv", "comment"]},
{"A_title": "Add support for --manage_closure_dependencies and --only_closure_dependencies with compilation level WHITESPACE_ONLYNone", "A_clean_title": ["add", "support", "manag", "closur", "depend", "onli", "closur", "depend", "compil", "level", "whitespac", "onlynon", "onli", "none"], "B_title": "don  t skip building all passes when building. ", "B_clean_title": ["don", "skip", "build", "all", "pass", "when", "build"]},
{"A_title": "Add support for --manage_closure_dependencies and --only_closure_dependencies with compilation level WHITESPACE_ONLYNone", "A_clean_title": ["add", "support", "manag", "closur", "depend", "onli", "closur", "depend", "compil", "level", "whitespac", "onlynon", "onli", "none"], "B_title": "Allow closure pass through. ", "B_clean_title": ["allow", "closur", "pass", "through"]},
{"A_title": "FastMath.max(50.0f -50.0f) => -50.0f; should be +50.0fFastMath.max(50.0f -50.0f) => -50.0f; should be +50.0f. This is because the wrong variable is returned. The bug was not detected by the test case testMinMaxFloat() because that has a bug too - it tests doubles not floats.", "A_clean_title": ["fastmath", "max", "fast", "math", "50", "0f", "50", "0f", "50", "0f", "+50", "0ffastmath", "max", "0f", "fast", "math", "50", "0f", "50", "0f", "50", "0f", "+50", "0f", "thi", "becaus", "wrong", "variabl", "return", "bug", "wa", "not", "detect", "by", "test", "case", "testminmaxfloat", "test", "min", "max", "float", "becaus", "that", "ha", "bug", "too", "it", "test", "doubl", "not", "float"], "B_title": "Fix 3481 test. ", "B_clean_title": ["fix", "3481", "test"]},
{"A_title": "FastMath.max(50.0f -50.0f) => -50.0f; should be +50.0fFastMath.max(50.0f -50.0f) => -50.0f; should be +50.0f. This is because the wrong variable is returned. The bug was not detected by the test case testMinMaxFloat() because that has a bug too - it tests doubles not floats.", "A_clean_title": ["fastmath", "max", "fast", "math", "50", "0f", "50", "0f", "50", "0f", "+50", "0ffastmath", "max", "0f", "fast", "math", "50", "0f", "50", "0f", "50", "0f", "+50", "0f", "thi", "becaus", "wrong", "variabl", "return", "bug", "wa", "not", "detect", "by", "test", "case", "testminmaxfloat", "test", "min", "max", "float", "becaus", "that", "ha", "bug", "too", "it", "test", "doubl", "not", "float"], "B_title": "Fix float . max ( a  b ). ", "B_clean_title": ["fix", "float", "max"]},
{"A_title": "FastMath.max(50.0f -50.0f) => -50.0f; should be +50.0fFastMath.max(50.0f -50.0f) => -50.0f; should be +50.0f. This is because the wrong variable is returned. The bug was not detected by the test case testMinMaxFloat() because that has a bug too - it tests doubles not floats.", "A_clean_title": ["fastmath", "max", "fast", "math", "50", "0f", "50", "0f", "50", "0f", "+50", "0ffastmath", "max", "0f", "fast", "math", "50", "0f", "50", "0f", "50", "0f", "+50", "0f", "thi", "becaus", "wrong", "variabl", "return", "bug", "wa", "not", "detect", "by", "test", "case", "testminmaxfloat", "test", "min", "max", "float", "becaus", "that", "ha", "bug", "too", "it", "test", "doubl", "not", "float"], "B_title": "Fix typo in FastMath . exp ( x ). Fix NaN in FastMath . max ( a  b ). ", "B_clean_title": ["fix", "typo", "fastmath", "fast", "math", "exp", "fix", "nan", "na", "fastmath", "fast", "math", "max"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "FastMath . abs ( x ) doesn  t allow false positives in baseSecantSolver. ", "B_clean_title": ["fastmath", "fast", "math", "ab", "doesn", "allow", "fals", "posit", "basesecantsolv", "base", "secant", "solver"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Fix renegation of baseSecantSolver. ", "B_clean_title": ["fix", "reneg", "basesecantsolv", "base", "secant", "solver"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Remove false positives in 186 e . g .  186e3232 .. ", "B_clean_title": ["remov", "fals", "posit", "186", "186e3232"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Fix renegation of base secant solver .. ", "B_clean_title": ["fix", "reneg", "base", "secant", "solver"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Fix renegation of baseSecantSolver. ", "B_clean_title": ["fix", "reneg", "basesecantsolv", "base", "secant", "solver"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Fix renegation of boolean methods. ", "B_clean_title": ["fix", "reneg", "boolean", "method"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Fix the case for renegation in BaseSecantSolver. ", "B_clean_title": ["fix", "case", "reneg", "basesecantsolv", "base", "secant", "solver"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Fix a bug in the patch .. ", "B_clean_title": ["fix", "bug", "patch"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Fix renegation of baseSecantSolver. ", "B_clean_title": ["fix", "reneg", "basesecantsolv", "base", "secant", "solver"]},
{"A_title": "StrBuilder appendFixedWidth does not handle nullsAppending a null value with fixed width causes a null pointer exception if getNullText() has not been set.", "A_clean_title": ["strbuilder", "str", "builder", "appendfixedwidth", "append", "fix", "width", "not", "handl", "nullsappend", "null", "append", "null", "valu", "fix", "width", "caus", "null", "pointer", "except", "getnulltext", "get", "null", "text", "ha", "not", "been", "set"], "B_title": "Don  t set the length of a string to 0 if the object is null .. Don  t use the constructor of StrBuilder in some cases .. ", "B_clean_title": ["don", "set", "length", "string", "object", "null", "don", "use", "constructor", "strbuilder", "str", "builder", "some", "case"]},
{"A_title": "StrBuilder appendFixedWidth does not handle nullsAppending a null value with fixed width causes a null pointer exception if getNullText() has not been set.", "A_clean_title": ["strbuilder", "str", "builder", "appendfixedwidth", "append", "fix", "width", "not", "handl", "nullsappend", "null", "append", "null", "valu", "fix", "width", "caus", "null", "pointer", "except", "getnulltext", "get", "null", "text", "ha", "not", "been", "set"], "B_title": "Fix the bug in Hercules . fixed. Fix the bug in Hercules .. ", "B_clean_title": ["fix", "bug", "hercul", "fix", "fix", "bug", "hercul"]},
{"A_title": "StrBuilder appendFixedWidth does not handle nullsAppending a null value with fixed width causes a null pointer exception if getNullText() has not been set.", "A_clean_title": ["strbuilder", "str", "builder", "appendfixedwidth", "append", "fix", "width", "not", "handl", "nullsappend", "null", "append", "null", "valu", "fix", "width", "caus", "null", "pointer", "except", "getnulltext", "get", "null", "text", "ha", "not", "been", "set"], "B_title": "Fix an NPE in StrBuilder . toString ( ). ", "B_clean_title": ["fix", "npe", "strbuilder", "str", "builder", "tostr", "string"]},
{"A_title": "StrBuilder appendFixedWidth does not handle nullsAppending a null value with fixed width causes a null pointer exception if getNullText() has not been set.", "A_clean_title": ["strbuilder", "str", "builder", "appendfixedwidth", "append", "fix", "width", "not", "handl", "nullsappend", "null", "append", "null", "valu", "fix", "width", "caus", "null", "pointer", "except", "getnulltext", "get", "null", "text", "ha", "not", "been", "set"], "B_title": "Fix bug. ", "B_clean_title": ["fix", "bug"]},
{"A_title": "StrBuilder appendFixedWidth does not handle nullsAppending a null value with fixed width causes a null pointer exception if getNullText() has not been set.", "A_clean_title": ["strbuilder", "str", "builder", "appendfixedwidth", "append", "fix", "width", "not", "handl", "nullsappend", "null", "append", "null", "valu", "fix", "width", "caus", "null", "pointer", "except", "getnulltext", "get", "null", "text", "ha", "not", "been", "set"], "B_title": "Fix bug. ", "B_clean_title": ["fix", "bug"]},
{"A_title": "SimplexSolver not working as expected 2SimplexSolver didnt find the optimal solution. Program for Lpsolve: ===================== /* Objective function */ max: 7 a 3 b; /* Constraints */ R1: +3 a -5 c <= 0; R2: +2 a -5 d <= 0; R3: +2 b -5 c <= 0; R4: +3 b -5 d <= 0; R5: +3 a +2 b <= 5; R6: +2 a +3 b <= 5; /* Variable bounds */ a <= 1; b <= 1; ===================== Results(correct): a = 1 b = 1 value = 10 Program for SimplexSolve: ===================== LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double 7 3 0 0  0); Collection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>(); podmienky.add(new LinearConstraint(new double 1 0 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 0 1 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 3 0 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 2 0 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 2 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 3 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 3 2 0 0  Relationship.LEQ 5)); podmienky.add(new LinearConstraint(new double 2 3 0 0  Relationship.LEQ 5)); SimplexSolver solver = new SimplexSolver(); RealPointValuePair result = solver.optimize(kritFcia podmienky GoalType.MAXIMIZE true); ===================== Results(incorrect): a = 1 b = 0.5 value = 8.5 P.S. I used the latest software from the repository (including MATH-286 fix).", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "2simplexsolv", "2simplex", "solver", "didnt", "find", "optim", "solut", "program", "lpsolv", "object", "function", "max", "constraint", "r1", "+3", "r2", "+2", "r3", "+2", "r4", "+3", "r5", "+3", "+2", "r6", "+2", "+3", "variabl", "bound", "result", "correct", "valu", "10", "program", "simplexsolv", "simplex", "solv", "linearobjectivefunct", "linear", "object", "function", "kritfcia", "krit", "fcia", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "podmienki", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "simplexsolv", "simplex", "solver", "solver", "new", "simplexsolv", "simplex", "solver", "realpointvaluepair", "real", "point", "valu", "pair", "result", "solver", "optim", "kritfcia", "krit", "fcia", "podmienki", "goaltyp", "maxim", "goal", "type", "true", "result", "incorrect", "valu", "use", "latest", "softwar", "repositori", "includ", "math", "286", "fix"], "B_title": "removed test. ", "B_clean_title": ["remov", "test"]},
{"A_title": "SimplexSolver not working as expected 2SimplexSolver didnt find the optimal solution. Program for Lpsolve: ===================== /* Objective function */ max: 7 a 3 b; /* Constraints */ R1: +3 a -5 c <= 0; R2: +2 a -5 d <= 0; R3: +2 b -5 c <= 0; R4: +3 b -5 d <= 0; R5: +3 a +2 b <= 5; R6: +2 a +3 b <= 5; /* Variable bounds */ a <= 1; b <= 1; ===================== Results(correct): a = 1 b = 1 value = 10 Program for SimplexSolve: ===================== LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double 7 3 0 0  0); Collection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>(); podmienky.add(new LinearConstraint(new double 1 0 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 0 1 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 3 0 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 2 0 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 2 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 3 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 3 2 0 0  Relationship.LEQ 5)); podmienky.add(new LinearConstraint(new double 2 3 0 0  Relationship.LEQ 5)); SimplexSolver solver = new SimplexSolver(); RealPointValuePair result = solver.optimize(kritFcia podmienky GoalType.MAXIMIZE true); ===================== Results(incorrect): a = 1 b = 0.5 value = 8.5 P.S. I used the latest software from the repository (including MATH-286 fix).", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "2simplexsolv", "2simplex", "solver", "didnt", "find", "optim", "solut", "program", "lpsolv", "object", "function", "max", "constraint", "r1", "+3", "r2", "+2", "r3", "+2", "r4", "+3", "r5", "+3", "+2", "r6", "+2", "+3", "variabl", "bound", "result", "correct", "valu", "10", "program", "simplexsolv", "simplex", "solv", "linearobjectivefunct", "linear", "object", "function", "kritfcia", "krit", "fcia", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "podmienki", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "simplexsolv", "simplex", "solver", "solver", "new", "simplexsolv", "simplex", "solver", "realpointvaluepair", "real", "point", "valu", "pair", "result", "solver", "optim", "kritfcia", "krit", "fcia", "podmienki", "goaltyp", "maxim", "goal", "type", "true", "result", "incorrect", "valu", "use", "latest", "softwar", "repositori", "includ", "math", "286", "fix"], "B_title": "Fixed epsilon regression in tableau objective function. ", "B_clean_title": ["fix", "epsilon", "regress", "tableau", "object", "function"]},
{"A_title": "SimplexSolver not working as expected 2SimplexSolver didnt find the optimal solution. Program for Lpsolve: ===================== /* Objective function */ max: 7 a 3 b; /* Constraints */ R1: +3 a -5 c <= 0; R2: +2 a -5 d <= 0; R3: +2 b -5 c <= 0; R4: +3 b -5 d <= 0; R5: +3 a +2 b <= 5; R6: +2 a +3 b <= 5; /* Variable bounds */ a <= 1; b <= 1; ===================== Results(correct): a = 1 b = 1 value = 10 Program for SimplexSolve: ===================== LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double 7 3 0 0  0); Collection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>(); podmienky.add(new LinearConstraint(new double 1 0 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 0 1 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 3 0 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 2 0 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 2 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 3 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 3 2 0 0  Relationship.LEQ 5)); podmienky.add(new LinearConstraint(new double 2 3 0 0  Relationship.LEQ 5)); SimplexSolver solver = new SimplexSolver(); RealPointValuePair result = solver.optimize(kritFcia podmienky GoalType.MAXIMIZE true); ===================== Results(incorrect): a = 1 b = 0.5 value = 8.5 P.S. I used the latest software from the repository (including MATH-286 fix).", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "2simplexsolv", "2simplex", "solver", "didnt", "find", "optim", "solut", "program", "lpsolv", "object", "function", "max", "constraint", "r1", "+3", "r2", "+2", "r3", "+2", "r4", "+3", "r5", "+3", "+2", "r6", "+2", "+3", "variabl", "bound", "result", "correct", "valu", "10", "program", "simplexsolv", "simplex", "solv", "linearobjectivefunct", "linear", "object", "function", "kritfcia", "krit", "fcia", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "podmienki", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "simplexsolv", "simplex", "solver", "solver", "new", "simplexsolv", "simplex", "solver", "realpointvaluepair", "real", "point", "valu", "pair", "result", "solver", "optim", "kritfcia", "krit", "fcia", "podmienki", "goaltyp", "maxim", "goal", "type", "true", "result", "incorrect", "valu", "use", "latest", "softwar", "repositori", "includ", "math", "286", "fix"], "B_title": "Improved the garbage collection profile of TwoDimTableau .. ", "B_clean_title": ["improv", "garbag", "collect", "profil", "twodimtableau", "two", "dim", "tableau"]},
{"A_title": "SimplexSolver not working as expected 2SimplexSolver didnt find the optimal solution. Program for Lpsolve: ===================== /* Objective function */ max: 7 a 3 b; /* Constraints */ R1: +3 a -5 c <= 0; R2: +2 a -5 d <= 0; R3: +2 b -5 c <= 0; R4: +3 b -5 d <= 0; R5: +3 a +2 b <= 5; R6: +2 a +3 b <= 5; /* Variable bounds */ a <= 1; b <= 1; ===================== Results(correct): a = 1 b = 1 value = 10 Program for SimplexSolve: ===================== LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double 7 3 0 0  0); Collection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>(); podmienky.add(new LinearConstraint(new double 1 0 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 0 1 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 3 0 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 2 0 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 2 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 3 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 3 2 0 0  Relationship.LEQ 5)); podmienky.add(new LinearConstraint(new double 2 3 0 0  Relationship.LEQ 5)); SimplexSolver solver = new SimplexSolver(); RealPointValuePair result = solver.optimize(kritFcia podmienky GoalType.MAXIMIZE true); ===================== Results(incorrect): a = 1 b = 0.5 value = 8.5 P.S. I used the latest software from the repository (including MATH-286 fix).", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "2simplexsolv", "2simplex", "solver", "didnt", "find", "optim", "solut", "program", "lpsolv", "object", "function", "max", "constraint", "r1", "+3", "r2", "+2", "r3", "+2", "r4", "+3", "r5", "+3", "+2", "r6", "+2", "+3", "variabl", "bound", "result", "correct", "valu", "10", "program", "simplexsolv", "simplex", "solv", "linearobjectivefunct", "linear", "object", "function", "kritfcia", "krit", "fcia", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "podmienki", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "simplexsolv", "simplex", "solver", "solver", "new", "simplexsolv", "simplex", "solver", "realpointvaluepair", "real", "point", "valu", "pair", "result", "solver", "optim", "kritfcia", "krit", "fcia", "podmienki", "goaltyp", "maxim", "goal", "type", "true", "result", "incorrect", "valu", "use", "latest", "softwar", "repositori", "includ", "math", "286", "fix"], "B_title": "removed epsilon label from tableau objective function. ", "B_clean_title": ["remov", "epsilon", "label", "tableau", "object", "function"]},
{"A_title": "SimplexSolver not working as expected 2SimplexSolver didnt find the optimal solution. Program for Lpsolve: ===================== /* Objective function */ max: 7 a 3 b; /* Constraints */ R1: +3 a -5 c <= 0; R2: +2 a -5 d <= 0; R3: +2 b -5 c <= 0; R4: +3 b -5 d <= 0; R5: +3 a +2 b <= 5; R6: +2 a +3 b <= 5; /* Variable bounds */ a <= 1; b <= 1; ===================== Results(correct): a = 1 b = 1 value = 10 Program for SimplexSolve: ===================== LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double 7 3 0 0  0); Collection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>(); podmienky.add(new LinearConstraint(new double 1 0 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 0 1 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 3 0 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 2 0 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 2 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 3 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 3 2 0 0  Relationship.LEQ 5)); podmienky.add(new LinearConstraint(new double 2 3 0 0  Relationship.LEQ 5)); SimplexSolver solver = new SimplexSolver(); RealPointValuePair result = solver.optimize(kritFcia podmienky GoalType.MAXIMIZE true); ===================== Results(incorrect): a = 1 b = 0.5 value = 8.5 P.S. I used the latest software from the repository (including MATH-286 fix).", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "2simplexsolv", "2simplex", "solver", "didnt", "find", "optim", "solut", "program", "lpsolv", "object", "function", "max", "constraint", "r1", "+3", "r2", "+2", "r3", "+2", "r4", "+3", "r5", "+3", "+2", "r6", "+2", "+3", "variabl", "bound", "result", "correct", "valu", "10", "program", "simplexsolv", "simplex", "solv", "linearobjectivefunct", "linear", "object", "function", "kritfcia", "krit", "fcia", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "podmienki", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "simplexsolv", "simplex", "solver", "solver", "new", "simplexsolv", "simplex", "solver", "realpointvaluepair", "real", "point", "valu", "pair", "result", "solver", "optim", "kritfcia", "krit", "fcia", "podmienki", "goaltyp", "maxim", "goal", "type", "true", "result", "incorrect", "valu", "use", "latest", "softwar", "repositori", "includ", "math", "286", "fix"], "B_title": "Fixed an example of the regression in LinearSolver . . .. ", "B_clean_title": ["fix", "exampl", "regress", "linearsolv", "linear", "solver"]},
{"A_title": "SimplexSolver not working as expected 2SimplexSolver didnt find the optimal solution. Program for Lpsolve: ===================== /* Objective function */ max: 7 a 3 b; /* Constraints */ R1: +3 a -5 c <= 0; R2: +2 a -5 d <= 0; R3: +2 b -5 c <= 0; R4: +3 b -5 d <= 0; R5: +3 a +2 b <= 5; R6: +2 a +3 b <= 5; /* Variable bounds */ a <= 1; b <= 1; ===================== Results(correct): a = 1 b = 1 value = 10 Program for SimplexSolve: ===================== LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double 7 3 0 0  0); Collection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>(); podmienky.add(new LinearConstraint(new double 1 0 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 0 1 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 3 0 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 2 0 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 2 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 3 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 3 2 0 0  Relationship.LEQ 5)); podmienky.add(new LinearConstraint(new double 2 3 0 0  Relationship.LEQ 5)); SimplexSolver solver = new SimplexSolver(); RealPointValuePair result = solver.optimize(kritFcia podmienky GoalType.MAXIMIZE true); ===================== Results(incorrect): a = 1 b = 0.5 value = 8.5 P.S. I used the latest software from the repository (including MATH-286 fix).", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "2simplexsolv", "2simplex", "solver", "didnt", "find", "optim", "solut", "program", "lpsolv", "object", "function", "max", "constraint", "r1", "+3", "r2", "+2", "r3", "+2", "r4", "+3", "r5", "+3", "+2", "r6", "+2", "+3", "variabl", "bound", "result", "correct", "valu", "10", "program", "simplexsolv", "simplex", "solv", "linearobjectivefunct", "linear", "object", "function", "kritfcia", "krit", "fcia", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "podmienki", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "simplexsolv", "simplex", "solver", "solver", "new", "simplexsolv", "simplex", "solver", "realpointvaluepair", "real", "point", "valu", "pair", "result", "solver", "optim", "kritfcia", "krit", "fcia", "podmienki", "goaltyp", "maxim", "goal", "type", "true", "result", "incorrect", "valu", "use", "latest", "softwar", "repositori", "includ", "math", "286", "fix"], "B_title": "Using less restrictive conditionals .. ", "B_clean_title": ["less", "restrict", "condit"]},
{"A_title": "SimplexSolver not working as expected 2SimplexSolver didnt find the optimal solution. Program for Lpsolve: ===================== /* Objective function */ max: 7 a 3 b; /* Constraints */ R1: +3 a -5 c <= 0; R2: +2 a -5 d <= 0; R3: +2 b -5 c <= 0; R4: +3 b -5 d <= 0; R5: +3 a +2 b <= 5; R6: +2 a +3 b <= 5; /* Variable bounds */ a <= 1; b <= 1; ===================== Results(correct): a = 1 b = 1 value = 10 Program for SimplexSolve: ===================== LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double 7 3 0 0  0); Collection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>(); podmienky.add(new LinearConstraint(new double 1 0 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 0 1 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 3 0 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 2 0 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 2 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 3 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 3 2 0 0  Relationship.LEQ 5)); podmienky.add(new LinearConstraint(new double 2 3 0 0  Relationship.LEQ 5)); SimplexSolver solver = new SimplexSolver(); RealPointValuePair result = solver.optimize(kritFcia podmienky GoalType.MAXIMIZE true); ===================== Results(incorrect): a = 1 b = 0.5 value = 8.5 P.S. I used the latest software from the repository (including MATH-286 fix).", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "2simplexsolv", "2simplex", "solver", "didnt", "find", "optim", "solut", "program", "lpsolv", "object", "function", "max", "constraint", "r1", "+3", "r2", "+2", "r3", "+2", "r4", "+3", "r5", "+3", "+2", "r6", "+2", "+3", "variabl", "bound", "result", "correct", "valu", "10", "program", "simplexsolv", "simplex", "solv", "linearobjectivefunct", "linear", "object", "function", "kritfcia", "krit", "fcia", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "podmienki", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "simplexsolv", "simplex", "solver", "solver", "new", "simplexsolv", "simplex", "solver", "realpointvaluepair", "real", "point", "valu", "pair", "result", "solver", "optim", "kritfcia", "krit", "fcia", "podmienki", "goaltyp", "maxim", "goal", "type", "true", "result", "incorrect", "valu", "use", "latest", "softwar", "repositori", "includ", "math", "286", "fix"], "B_title": "Fixed epsilon. ", "B_clean_title": ["fix", "epsilon"]},
{"A_title": "MathUtils.gcd(Integer.MIN_VALUE 0) should throw an Exception instead of returning Integer.MIN_VALUEThe gcd method should throw an Exception for gcd(Integer.MIN_VALUE 0) like for gcd(Integer.MIN_VALUE Integer.MIN_VALUE). The method should only return nonnegative results.", "A_clean_title": ["mathutil", "gcd", "math", "util", "integ", "min", "valu", "throw", "except", "instead", "return", "integ", "min", "valueth", "valu", "gcd", "method", "throw", "except", "gcd", "integ", "min", "valu", "like", "gcd", "integ", "min", "valu", "integ", "min", "valu", "method", "onli", "return", "nonneg", "result"], "B_title": "Fix divide by zero error in MathUtils. Add a throw if it wasn  t possible to do this .. ", "B_clean_title": ["fix", "divid", "by", "zero", "error", "mathutil", "math", "util", "add", "throw", "it", "wasn", "possibl", "thi"]},
{"A_title": "WordUtils.abbreviate bug when lower is greater than str.lengthIn WordUtils.abbreviate upper is adjusted to the length of the string then to lower. But lower is never adjusted to the length of the string so if lower is greater than str.lengt() upper will be too... Then str.substring(0 upper) throw a StringIndexOutOfBoundsException The fix is to adjust lower to the length of the string", "A_clean_title": ["wordutil", "abbrevi", "word", "util", "bug", "when", "lower", "greater", "than", "str", "lengthin", "length", "wordutil", "abbrevi", "word", "util", "upper", "adjust", "length", "string", "then", "lower", "but", "lower", "never", "adjust", "length", "string", "so", "lower", "greater", "than", "str", "lengt", "upper", "will", "too", "then", "str", "substr", "upper", "throw", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "fix", "adjust", "lower", "length", "string"], "B_title": "Fixed misc problems caused by the use of substringBefore and substringAfter methods in WordUtils. ", "B_clean_title": ["fix", "misc", "problem", "caus", "by", "use", "substringbefor", "substr", "befor", "substringaft", "substr", "after", "method", "wordutil", "word", "util"]},
{"A_title": "WordUtils.abbreviate bug when lower is greater than str.lengthIn WordUtils.abbreviate upper is adjusted to the length of the string then to lower. But lower is never adjusted to the length of the string so if lower is greater than str.lengt() upper will be too... Then str.substring(0 upper) throw a StringIndexOutOfBoundsException The fix is to adjust lower to the length of the string", "A_clean_title": ["wordutil", "abbrevi", "word", "util", "bug", "when", "lower", "greater", "than", "str", "lengthin", "length", "wordutil", "abbrevi", "word", "util", "upper", "adjust", "length", "string", "then", "lower", "but", "lower", "never", "adjust", "length", "string", "so", "lower", "greater", "than", "str", "lengt", "upper", "will", "too", "then", "str", "substr", "upper", "throw", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "fix", "adjust", "lower", "length", "string"], "B_title": "Extend word utils upper bounds. ", "B_clean_title": ["extend", "word", "util", "upper", "bound"]},
{"A_title": "ArrayIndexOutOfBoundsException in MathArrays.linearCombinationWhen MathArrays.linearCombination is passed arguments with length 1 it throws an ArrayOutOfBoundsException. This is caused by this line: double prodHighNext = prodHigh1; linearCombination should check the length of the arguments and fall back to simple multiplication if length == 1.", "A_clean_title": ["arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "matharray", "linearcombinationwhen", "math", "array", "linear", "combin", "when", "matharray", "linearcombin", "math", "array", "linear", "combin", "pass", "argument", "length", "it", "throw", "arrayoutofboundsexcept", "array", "out", "bound", "except", "thi", "caus", "by", "thi", "line", "doubl", "prodhighnext", "prod", "high", "next", "prodhigh1", "prod", "high1", "linearcombin", "linear", "combin", "check", "length", "argument", "fall", "back", "simpl", "multipl", "length"], "B_title": "Added missing if (. ", "B_clean_title": ["ad", "miss"]},
{"A_title": "Column-indicating caret is sometimes not in error outputNone", "A_clean_title": ["column", "indic", "caret", "sometim", "not", "error", "outputnon", "output", "none"], "B_title": "Remove whitespaces from sourceExcerpt. ", "B_clean_title": ["remov", "whitespac", "sourceexcerpt", "sourc", "excerpt"]},
{"A_title": "Generate change list separated by types using labelsAs discussed on the mailing list instead of one big list of Improvements the change list for the release is divided into change types based on labels. It is required to specify which labels should be considered separately. Some other labels can be excluded (like question or refactoring). There is also headerForOtherChanges method to override default Other header.", "A_clean_title": ["gener", "chang", "list", "separ", "by", "type", "labelsa", "label", "as", "discuss", "mail", "list", "instead", "one", "big", "list", "improv", "chang", "list", "releas", "divid", "into", "chang", "type", "base", "label", "it", "requir", "specifi", "which", "label", "consid", "separ", "some", "other", "label", "exclud", "like", "question", "or", "refactor", "there", "also", "headerforotherchang", "header", "other", "chang", "method", "overrid", "default", "other", "header"], "B_title": "Fix toStringEquals with null arg. ", "B_clean_title": ["fix", "tostringequ", "string", "equal", "null", "arg"]},
{"A_title": "Generate change list separated by types using labelsAs discussed on the mailing list instead of one big list of Improvements the change list for the release is divided into change types based on labels. It is required to specify which labels should be considered separately. Some other labels can be excluded (like question or refactoring). There is also headerForOtherChanges method to override default Other header.", "A_clean_title": ["gener", "chang", "list", "separ", "by", "type", "labelsa", "label", "as", "discuss", "mail", "list", "instead", "one", "big", "list", "improv", "chang", "list", "releas", "divid", "into", "chang", "type", "base", "label", "it", "requir", "specifi", "which", "label", "consid", "separ", "some", "other", "label", "exclud", "like", "question", "or", "refactor", "there", "also", "headerforotherchang", "header", "other", "chang", "method", "overrid", "default", "other", "header"], "B_title": "Fix toStringEquals in ArgumentMatchingTool. ", "B_clean_title": ["fix", "tostringequ", "string", "equal", "argumentmatchingtool", "argument", "match", "tool"]},
{"A_title": "BisectionSolver.solve(final UnivariateRealFunction f double min double max double initial) throws NullPointerExceptionMethod      BisectionSolver.solve(final UnivariateRealFunction f double min double max double initial)   invokes      BisectionSolver.solve(double min double max)  which throws NullPointerException as member variable     UnivariateRealSolverImpl.f  is null. Instead the method:     BisectionSolver.solve(final UnivariateRealFunction f double min double max) should be called. Steps to reproduce: invoke:      new BisectionSolver().solve(someUnivariateFunctionImpl 0.0 1.0 0.5); NullPointerException will be thrown.", "A_clean_title": ["bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "doubl", "initi", "throw", "nullpointerexceptionmethod", "null", "pointer", "except", "method", "bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "doubl", "initi", "invok", "bisectionsolv", "solv", "bisect", "solver", "doubl", "min", "doubl", "max", "which", "throw", "nullpointerexcept", "null", "pointer", "except", "as", "member", "variabl", "univariaterealsolverimpl", "univari", "real", "solver", "impl", "null", "instead", "method", "bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "call", "step", "reproduc", "invok", "new", "bisectionsolv", "bisect", "solver", "solv", "someunivariatefunctionimpl", "some", "univari", "function", "impl", "nullpointerexcept", "null", "pointer", "except", "will", "thrown"], "B_title": "fixed erroneous loop. ", "B_clean_title": ["fix", "erron", "loop"]},
{"A_title": "BisectionSolver.solve(final UnivariateRealFunction f double min double max double initial) throws NullPointerExceptionMethod      BisectionSolver.solve(final UnivariateRealFunction f double min double max double initial)   invokes      BisectionSolver.solve(double min double max)  which throws NullPointerException as member variable     UnivariateRealSolverImpl.f  is null. Instead the method:     BisectionSolver.solve(final UnivariateRealFunction f double min double max) should be called. Steps to reproduce: invoke:      new BisectionSolver().solve(someUnivariateFunctionImpl 0.0 1.0 0.5); NullPointerException will be thrown.", "A_clean_title": ["bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "doubl", "initi", "throw", "nullpointerexceptionmethod", "null", "pointer", "except", "method", "bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "doubl", "initi", "invok", "bisectionsolv", "solv", "bisect", "solver", "doubl", "min", "doubl", "max", "which", "throw", "nullpointerexcept", "null", "pointer", "except", "as", "member", "variabl", "univariaterealsolverimpl", "univari", "real", "solver", "impl", "null", "instead", "method", "bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "call", "step", "reproduc", "invok", "new", "bisectionsolv", "bisect", "solver", "solv", "someunivariatefunctionimpl", "some", "univari", "function", "impl", "nullpointerexcept", "null", "pointer", "except", "will", "thrown"], "B_title": "fixed a typo in solve ( ). ", "B_clean_title": ["fix", "typo", "solv"]},
{"A_title": "BisectionSolver.solve(final UnivariateRealFunction f double min double max double initial) throws NullPointerExceptionMethod      BisectionSolver.solve(final UnivariateRealFunction f double min double max double initial)   invokes      BisectionSolver.solve(double min double max)  which throws NullPointerException as member variable     UnivariateRealSolverImpl.f  is null. Instead the method:     BisectionSolver.solve(final UnivariateRealFunction f double min double max) should be called. Steps to reproduce: invoke:      new BisectionSolver().solve(someUnivariateFunctionImpl 0.0 1.0 0.5); NullPointerException will be thrown.", "A_clean_title": ["bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "doubl", "initi", "throw", "nullpointerexceptionmethod", "null", "pointer", "except", "method", "bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "doubl", "initi", "invok", "bisectionsolv", "solv", "bisect", "solver", "doubl", "min", "doubl", "max", "which", "throw", "nullpointerexcept", "null", "pointer", "except", "as", "member", "variabl", "univariaterealsolverimpl", "univari", "real", "solver", "impl", "null", "instead", "method", "bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "call", "step", "reproduc", "invok", "new", "bisectionsolv", "bisect", "solver", "solv", "someunivariatefunctionimpl", "some", "univari", "function", "impl", "nullpointerexcept", "null", "pointer", "except", "will", "thrown"], "B_title": "Added missing throws. ", "B_clean_title": ["ad", "miss", "throw"]},
{"A_title": "BisectionSolver.solve(final UnivariateRealFunction f double min double max double initial) throws NullPointerExceptionMethod      BisectionSolver.solve(final UnivariateRealFunction f double min double max double initial)   invokes      BisectionSolver.solve(double min double max)  which throws NullPointerException as member variable     UnivariateRealSolverImpl.f  is null. Instead the method:     BisectionSolver.solve(final UnivariateRealFunction f double min double max) should be called. Steps to reproduce: invoke:      new BisectionSolver().solve(someUnivariateFunctionImpl 0.0 1.0 0.5); NullPointerException will be thrown.", "A_clean_title": ["bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "doubl", "initi", "throw", "nullpointerexceptionmethod", "null", "pointer", "except", "method", "bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "doubl", "initi", "invok", "bisectionsolv", "solv", "bisect", "solver", "doubl", "min", "doubl", "max", "which", "throw", "nullpointerexcept", "null", "pointer", "except", "as", "member", "variabl", "univariaterealsolverimpl", "univari", "real", "solver", "impl", "null", "instead", "method", "bisectionsolv", "solv", "bisect", "solver", "final", "univariaterealfunct", "univari", "real", "function", "doubl", "min", "doubl", "max", "call", "step", "reproduc", "invok", "new", "bisectionsolv", "bisect", "solver", "solv", "someunivariatefunctionimpl", "some", "univari", "function", "impl", "nullpointerexcept", "null", "pointer", "except", "will", "thrown"], "B_title": "updated imports. Added missing closing parenthesis .. ", "B_clean_title": ["updat", "import", "ad", "miss", "close", "parenthesi"]},
{"A_title": "NumberUtils#createNumber - bad behaviour for leading --NumberUtils#createNumber checks for a leading -- in the string and returns null if found. This is documented as a work round for a bug in BigDecimal. Returning nulll is contrary to the Javadoc and the behaviour for other methods which would throw NumberFormatException. Its not clear whether the BigDecimal problem still exists with recent versions of Java. However if it does exist then the check needs to be done for all invocations of BigDecimal i.e. needs to be moved to createBigDecimal.", "A_clean_title": ["numberutil", "number", "util", "createnumb", "creat", "number", "bad", "behaviour", "lead", "numberutil", "number", "util", "createnumb", "creat", "number", "check", "lead", "string", "return", "null", "found", "thi", "document", "as", "work", "round", "bug", "bigdecim", "big", "decim", "return", "nulll", "contrari", "javadoc", "behaviour", "other", "method", "which", "would", "throw", "numberformatexcept", "number", "format", "except", "it", "not", "clear", "whether", "bigdecim", "big", "decim", "problem", "still", "exist", "recent", "version", "java", "howev", "it", "exist", "then", "check", "need", "done", "all", "invoc", "bigdecim", "big", "decim", "need", "move", "createbigdecim", "creat", "big", "decim"], "B_title": "formatting of numbers with spaces does not make much sense for number utils. ", "B_clean_title": ["format", "number", "space", "not", "make", "much", "sens", "number", "util"]},
{"A_title": "NumberUtils#createNumber - bad behaviour for leading --NumberUtils#createNumber checks for a leading -- in the string and returns null if found. This is documented as a work round for a bug in BigDecimal. Returning nulll is contrary to the Javadoc and the behaviour for other methods which would throw NumberFormatException. Its not clear whether the BigDecimal problem still exists with recent versions of Java. However if it does exist then the check needs to be done for all invocations of BigDecimal i.e. needs to be moved to createBigDecimal.", "A_clean_title": ["numberutil", "number", "util", "createnumb", "creat", "number", "bad", "behaviour", "lead", "numberutil", "number", "util", "createnumb", "creat", "number", "check", "lead", "string", "return", "null", "found", "thi", "document", "as", "work", "round", "bug", "bigdecim", "big", "decim", "return", "nulll", "contrari", "javadoc", "behaviour", "other", "method", "which", "would", "throw", "numberformatexcept", "number", "format", "except", "it", "not", "clear", "whether", "bigdecim", "big", "decim", "problem", "still", "exist", "recent", "version", "java", "howev", "it", "exist", "then", "check", "need", "done", "all", "invoc", "bigdecim", "big", "decim", "need", "move", "createbigdecim", "creat", "big", "decim"], "B_title": "Fix BigDecimal from string startsWith ( # 77 ). ", "B_clean_title": ["fix", "bigdecim", "big", "decim", "string", "startswith", "start", "77"]},
{"A_title": "NumberUtils#createNumber - bad behaviour for leading --NumberUtils#createNumber checks for a leading -- in the string and returns null if found. This is documented as a work round for a bug in BigDecimal. Returning nulll is contrary to the Javadoc and the behaviour for other methods which would throw NumberFormatException. Its not clear whether the BigDecimal problem still exists with recent versions of Java. However if it does exist then the check needs to be done for all invocations of BigDecimal i.e. needs to be moved to createBigDecimal.", "A_clean_title": ["numberutil", "number", "util", "createnumb", "creat", "number", "bad", "behaviour", "lead", "numberutil", "number", "util", "createnumb", "creat", "number", "check", "lead", "string", "return", "null", "found", "thi", "document", "as", "work", "round", "bug", "bigdecim", "big", "decim", "return", "nulll", "contrari", "javadoc", "behaviour", "other", "method", "which", "would", "throw", "numberformatexcept", "number", "format", "except", "it", "not", "clear", "whether", "bigdecim", "big", "decim", "problem", "still", "exist", "recent", "version", "java", "howev", "it", "exist", "then", "check", "need", "done", "all", "invoc", "bigdecim", "big", "decim", "need", "move", "createbigdecim", "creat", "big", "decim"], "B_title": "Handle early NPE when NumberUtils . startsWith ( ) is true. ", "B_clean_title": ["handl", "earli", "npe", "when", "numberutil", "number", "util", "startswith", "start", "true"]},
{"A_title": "NumberUtils#createNumber - bad behaviour for leading --NumberUtils#createNumber checks for a leading -- in the string and returns null if found. This is documented as a work round for a bug in BigDecimal. Returning nulll is contrary to the Javadoc and the behaviour for other methods which would throw NumberFormatException. Its not clear whether the BigDecimal problem still exists with recent versions of Java. However if it does exist then the check needs to be done for all invocations of BigDecimal i.e. needs to be moved to createBigDecimal.", "A_clean_title": ["numberutil", "number", "util", "createnumb", "creat", "number", "bad", "behaviour", "lead", "numberutil", "number", "util", "createnumb", "creat", "number", "check", "lead", "string", "return", "null", "found", "thi", "document", "as", "work", "round", "bug", "bigdecim", "big", "decim", "return", "nulll", "contrari", "javadoc", "behaviour", "other", "method", "which", "would", "throw", "numberformatexcept", "number", "format", "except", "it", "not", "clear", "whether", "bigdecim", "big", "decim", "problem", "still", "exist", "recent", "version", "java", "howev", "it", "exist", "then", "check", "need", "done", "all", "invoc", "bigdecim", "big", "decim", "need", "move", "createbigdecim", "creat", "big", "decim"], "B_title": "removed the unnecessary  --  from NumberUtils . startsWith ( )  it was restricting our. ", "B_clean_title": ["remov", "unnecessari", "numberutil", "number", "util", "startswith", "start", "it", "wa", "restrict", "our"]},
{"A_title": "NumberUtils#createNumber - bad behaviour for leading --NumberUtils#createNumber checks for a leading -- in the string and returns null if found. This is documented as a work round for a bug in BigDecimal. Returning nulll is contrary to the Javadoc and the behaviour for other methods which would throw NumberFormatException. Its not clear whether the BigDecimal problem still exists with recent versions of Java. However if it does exist then the check needs to be done for all invocations of BigDecimal i.e. needs to be moved to createBigDecimal.", "A_clean_title": ["numberutil", "number", "util", "createnumb", "creat", "number", "bad", "behaviour", "lead", "numberutil", "number", "util", "createnumb", "creat", "number", "check", "lead", "string", "return", "null", "found", "thi", "document", "as", "work", "round", "bug", "bigdecim", "big", "decim", "return", "nulll", "contrari", "javadoc", "behaviour", "other", "method", "which", "would", "throw", "numberformatexcept", "number", "format", "except", "it", "not", "clear", "whether", "bigdecim", "big", "decim", "problem", "still", "exist", "recent", "version", "java", "howev", "it", "exist", "then", "check", "need", "done", "all", "invoc", "bigdecim", "big", "decim", "need", "move", "createbigdecim", "creat", "big", "decim"], "B_title": "Fix 0x mistake in patch. ", "B_clean_title": ["fix", "0x", "mistak", "patch"]},
{"A_title": "Bugs in Frequency APII think the existing Frequency API has some bugs in it. The addValue(Object v) method allows one to add a plain Object but one cannot add anything further to the instance as the second add fails with IllegalArgumentException. In fact the problem is with the first call to addValue(Object) which should not allow a plain Object to be added - it should only allow Comparable objects. This could be fixed by checking that the object is Comparable. Similar considerations apply to the getCumFreq(Object) and getCumPct(Object) methods - they will only work with objects that implement Comparable. The getCount(Object) and getPct(Object) methods dont fail when given a non-Comparable object (because the class cast exception is caught) however they just return 0 as if the object was not present:          final Object OBJ = new Object();         f.addValue(OBJ); // This ought to fail but doesnt causing the unexpected behaviour below         System.out.println(f.getCount(OBJ)); // 0         System.out.println(f.getPct(OBJ)); // 0.0   Rather than adding extra checks for Comparable it seems to me that the API would be much improved by using Comparable instead of Object. Also it should make it easier to implement generics. However this would cause compilation failures for some programs that pass Object rather than Comparable to the class. These would need recoding but I think they would continue to run OK against the new API. It would also affect the run-time behaviour slightly as the first attempt to add a non-Comparable object would fail rather than the second add of a possibly valid object. But is that a viable program? It can only add one object and any attempt to get statistics will either return 0 or an Exception and applying the instanceof fix would also cause it to fail.", "A_clean_title": ["bug", "frequenc", "apii", "think", "exist", "frequenc", "api", "ha", "some", "bug", "it", "addvalu", "add", "valu", "object", "method", "allow", "one", "add", "plain", "object", "but", "one", "not", "add", "anyth", "further", "instanc", "as", "second", "add", "fail", "illegalargumentexcept", "illeg", "argument", "except", "fact", "problem", "first", "call", "addvalu", "add", "valu", "object", "which", "not", "allow", "plain", "object", "ad", "it", "onli", "allow", "compar", "object", "thi", "could", "fix", "by", "check", "that", "object", "compar", "similar", "consider", "appli", "getcumfreq", "get", "cum", "freq", "object", "getcumpct", "get", "cum", "pct", "object", "method", "they", "will", "onli", "work", "object", "that", "implement", "compar", "getcount", "get", "count", "object", "getpct", "get", "pct", "object", "method", "dont", "fail", "when", "given", "non", "compar", "object", "becaus", "class", "cast", "except", "caught", "howev", "they", "just", "return", "as", "object", "wa", "not", "present", "final", "object", "obj", "new", "object", "addvalu", "add", "valu", "obj", "thi", "ought", "fail", "but", "doesnt", "caus", "unexpect", "behaviour", "below", "system", "out", "println", "getcount", "get", "count", "obj", "system", "out", "println", "getpct", "get", "pct", "obj", "rather", "than", "ad", "extra", "check", "compar", "it", "seem", "me", "that", "api", "would", "much", "improv", "by", "compar", "instead", "object", "also", "it", "make", "it", "easier", "implement", "gener", "howev", "thi", "would", "caus", "compil", "failur", "some", "program", "that", "pass", "object", "rather", "than", "compar", "class", "these", "would", "need", "recod", "but", "think", "they", "would", "continu", "run", "ok", "against", "new", "api", "it", "would", "also", "affect", "run", "time", "behaviour", "slightli", "as", "first", "attempt", "add", "non", "compar", "object", "would", "fail", "rather", "than", "second", "add", "possibl", "valid", "object", "but", "that", "viabl", "program", "it", "onli", "add", "one", "object", "ani", "attempt", "get", "statist", "will", "either", "return", "or", "except", "appli", "instanceof", "fix", "would", "also", "caus", "it", "fail"], "B_title": "Fix a bug in Frequency . put ( Object  Long ). ", "B_clean_title": ["fix", "bug", "frequenc", "put", "object", "long"]},
{"A_title": "Bugs in Frequency APII think the existing Frequency API has some bugs in it. The addValue(Object v) method allows one to add a plain Object but one cannot add anything further to the instance as the second add fails with IllegalArgumentException. In fact the problem is with the first call to addValue(Object) which should not allow a plain Object to be added - it should only allow Comparable objects. This could be fixed by checking that the object is Comparable. Similar considerations apply to the getCumFreq(Object) and getCumPct(Object) methods - they will only work with objects that implement Comparable. The getCount(Object) and getPct(Object) methods dont fail when given a non-Comparable object (because the class cast exception is caught) however they just return 0 as if the object was not present:          final Object OBJ = new Object();         f.addValue(OBJ); // This ought to fail but doesnt causing the unexpected behaviour below         System.out.println(f.getCount(OBJ)); // 0         System.out.println(f.getPct(OBJ)); // 0.0   Rather than adding extra checks for Comparable it seems to me that the API would be much improved by using Comparable instead of Object. Also it should make it easier to implement generics. However this would cause compilation failures for some programs that pass Object rather than Comparable to the class. These would need recoding but I think they would continue to run OK against the new API. It would also affect the run-time behaviour slightly as the first attempt to add a non-Comparable object would fail rather than the second add of a possibly valid object. But is that a viable program? It can only add one object and any attempt to get statistics will either return 0 or an Exception and applying the instanceof fix would also cause it to fail.", "A_clean_title": ["bug", "frequenc", "apii", "think", "exist", "frequenc", "api", "ha", "some", "bug", "it", "addvalu", "add", "valu", "object", "method", "allow", "one", "add", "plain", "object", "but", "one", "not", "add", "anyth", "further", "instanc", "as", "second", "add", "fail", "illegalargumentexcept", "illeg", "argument", "except", "fact", "problem", "first", "call", "addvalu", "add", "valu", "object", "which", "not", "allow", "plain", "object", "ad", "it", "onli", "allow", "compar", "object", "thi", "could", "fix", "by", "check", "that", "object", "compar", "similar", "consider", "appli", "getcumfreq", "get", "cum", "freq", "object", "getcumpct", "get", "cum", "pct", "object", "method", "they", "will", "onli", "work", "object", "that", "implement", "compar", "getcount", "get", "count", "object", "getpct", "get", "pct", "object", "method", "dont", "fail", "when", "given", "non", "compar", "object", "becaus", "class", "cast", "except", "caught", "howev", "they", "just", "return", "as", "object", "wa", "not", "present", "final", "object", "obj", "new", "object", "addvalu", "add", "valu", "obj", "thi", "ought", "fail", "but", "doesnt", "caus", "unexpect", "behaviour", "below", "system", "out", "println", "getcount", "get", "count", "obj", "system", "out", "println", "getpct", "get", "pct", "obj", "rather", "than", "ad", "extra", "check", "compar", "it", "seem", "me", "that", "api", "would", "much", "improv", "by", "compar", "instead", "object", "also", "it", "make", "it", "easier", "implement", "gener", "howev", "thi", "would", "caus", "compil", "failur", "some", "program", "that", "pass", "object", "rather", "than", "compar", "class", "these", "would", "need", "recod", "but", "think", "they", "would", "continu", "run", "ok", "against", "new", "api", "it", "would", "also", "affect", "run", "time", "behaviour", "slightli", "as", "first", "attempt", "add", "non", "compar", "object", "would", "fail", "rather", "than", "second", "add", "possibl", "valid", "object", "but", "that", "viabl", "program", "it", "onli", "add", "one", "object", "ani", "attempt", "get", "statist", "will", "either", "return", "or", "except", "appli", "instanceof", "fix", "would", "also", "caus", "it", "fail"], "B_title": "Fixing rat phase. ", "B_clean_title": ["fix", "rat", "phase"]},
{"A_title": "NullPointerException in isAvailableLocale(Locale)FindBugs pointed out:    UwF: Field not initialized in constructor: org.apache.commons.lang.LocaleUtils.cAvailableLocaleSet cAvailableSet is used directly once in the source - and if availableLocaleSet() hasnt been called it will cause a NullPointerException.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "isavailablelocal", "avail", "local", "local", "findbug", "find", "bug", "point", "out", "uwf", "uw", "field", "not", "initi", "constructor", "org", "apach", "common", "lang", "localeutil", "cavailablelocaleset", "local", "util", "avail", "local", "set", "cavailableset", "avail", "set", "use", "directli", "onc", "sourc", "availablelocaleset", "avail", "local", "set", "hasnt", "been", "call", "it", "will", "caus", "nullpointerexcept", "null", "pointer", "except"], "B_title": "Use availableLocaleList ( ) instead of cAvailableLocaleSet. ", "B_clean_title": ["use", "availablelocalelist", "avail", "local", "list", "instead", "cavailablelocaleset", "avail", "local", "set"]},
{"A_title": "NullPointerException in isAvailableLocale(Locale)FindBugs pointed out:    UwF: Field not initialized in constructor: org.apache.commons.lang.LocaleUtils.cAvailableLocaleSet cAvailableSet is used directly once in the source - and if availableLocaleSet() hasnt been called it will cause a NullPointerException.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "isavailablelocal", "avail", "local", "local", "findbug", "find", "bug", "point", "out", "uwf", "uw", "field", "not", "initi", "constructor", "org", "apach", "common", "lang", "localeutil", "cavailablelocaleset", "local", "util", "avail", "local", "set", "cavailableset", "avail", "set", "use", "directli", "onc", "sourc", "availablelocaleset", "avail", "local", "set", "hasnt", "been", "call", "it", "will", "caus", "nullpointerexcept", "null", "pointer", "except"], "B_title": "Fixed LocaleUtils # isAvailableLocale ( ). ", "B_clean_title": ["fix", "localeutil", "local", "util", "isavailablelocal", "avail", "local"]},
{"A_title": "NullPointerException in isAvailableLocale(Locale)FindBugs pointed out:    UwF: Field not initialized in constructor: org.apache.commons.lang.LocaleUtils.cAvailableLocaleSet cAvailableSet is used directly once in the source - and if availableLocaleSet() hasnt been called it will cause a NullPointerException.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "isavailablelocal", "avail", "local", "local", "findbug", "find", "bug", "point", "out", "uwf", "uw", "field", "not", "initi", "constructor", "org", "apach", "common", "lang", "localeutil", "cavailablelocaleset", "local", "util", "avail", "local", "set", "cavailableset", "avail", "set", "use", "directli", "onc", "sourc", "availablelocaleset", "avail", "local", "set", "hasnt", "been", "call", "it", "will", "caus", "nullpointerexcept", "null", "pointer", "except"], "B_title": "@@ isAvailableLocale ( )  removed 222 from the comment. ", "B_clean_title": ["isavailablelocal", "avail", "local", "remov", "222", "comment"]},
{"A_title": "NullPointerException in isAvailableLocale(Locale)FindBugs pointed out:    UwF: Field not initialized in constructor: org.apache.commons.lang.LocaleUtils.cAvailableLocaleSet cAvailableSet is used directly once in the source - and if availableLocaleSet() hasnt been called it will cause a NullPointerException.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "isavailablelocal", "avail", "local", "local", "findbug", "find", "bug", "point", "out", "uwf", "uw", "field", "not", "initi", "constructor", "org", "apach", "common", "lang", "localeutil", "cavailablelocaleset", "local", "util", "avail", "local", "set", "cavailableset", "avail", "set", "use", "directli", "onc", "sourc", "availablelocaleset", "avail", "local", "set", "hasnt", "been", "call", "it", "will", "caus", "nullpointerexcept", "null", "pointer", "except"], "B_title": "Use the available locale list. ", "B_clean_title": ["use", "avail", "local", "list"]},
{"A_title": "NullPointerException in isAvailableLocale(Locale)FindBugs pointed out:    UwF: Field not initialized in constructor: org.apache.commons.lang.LocaleUtils.cAvailableLocaleSet cAvailableSet is used directly once in the source - and if availableLocaleSet() hasnt been called it will cause a NullPointerException.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "isavailablelocal", "avail", "local", "local", "findbug", "find", "bug", "point", "out", "uwf", "uw", "field", "not", "initi", "constructor", "org", "apach", "common", "lang", "localeutil", "cavailablelocaleset", "local", "util", "avail", "local", "set", "cavailableset", "avail", "set", "use", "directli", "onc", "sourc", "availablelocaleset", "avail", "local", "set", "hasnt", "been", "call", "it", "will", "caus", "nullpointerexcept", "null", "pointer", "except"], "B_title": "Use new java . util . HashSet ( ) instead of cAvailableLocaleSet. ", "B_clean_title": ["use", "new", "java", "util", "hashset", "hash", "set", "instead", "cavailablelocaleset", "avail", "local", "set"]},
{"A_title": "NullPointerException in isAvailableLocale(Locale)FindBugs pointed out:    UwF: Field not initialized in constructor: org.apache.commons.lang.LocaleUtils.cAvailableLocaleSet cAvailableSet is used directly once in the source - and if availableLocaleSet() hasnt been called it will cause a NullPointerException.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "isavailablelocal", "avail", "local", "local", "findbug", "find", "bug", "point", "out", "uwf", "uw", "field", "not", "initi", "constructor", "org", "apach", "common", "lang", "localeutil", "cavailablelocaleset", "local", "util", "avail", "local", "set", "cavailableset", "avail", "set", "use", "directli", "onc", "sourc", "availablelocaleset", "avail", "local", "set", "hasnt", "been", "call", "it", "will", "caus", "nullpointerexcept", "null", "pointer", "except"], "B_title": "Fixed bug in LocaleUtils. ", "B_clean_title": ["fix", "bug", "localeutil", "local", "util"]},
{"A_title": "NullPointerException in isAvailableLocale(Locale)FindBugs pointed out:    UwF: Field not initialized in constructor: org.apache.commons.lang.LocaleUtils.cAvailableLocaleSet cAvailableSet is used directly once in the source - and if availableLocaleSet() hasnt been called it will cause a NullPointerException.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "isavailablelocal", "avail", "local", "local", "findbug", "find", "bug", "point", "out", "uwf", "uw", "field", "not", "initi", "constructor", "org", "apach", "common", "lang", "localeutil", "cavailablelocaleset", "local", "util", "avail", "local", "set", "cavailableset", "avail", "set", "use", "directli", "onc", "sourc", "availablelocaleset", "avail", "local", "set", "hasnt", "been", "call", "it", "will", "caus", "nullpointerexcept", "null", "pointer", "except"], "B_title": "Improved javadoc in LocaleUtils. ", "B_clean_title": ["improv", "javadoc", "localeutil", "local", "util"]},
{"A_title": "NullPointerException in isAvailableLocale(Locale)FindBugs pointed out:    UwF: Field not initialized in constructor: org.apache.commons.lang.LocaleUtils.cAvailableLocaleSet cAvailableSet is used directly once in the source - and if availableLocaleSet() hasnt been called it will cause a NullPointerException.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "isavailablelocal", "avail", "local", "local", "findbug", "find", "bug", "point", "out", "uwf", "uw", "field", "not", "initi", "constructor", "org", "apach", "common", "lang", "localeutil", "cavailablelocaleset", "local", "util", "avail", "local", "set", "cavailableset", "avail", "set", "use", "directli", "onc", "sourc", "availablelocaleset", "avail", "local", "set", "hasnt", "been", "call", "it", "will", "caus", "nullpointerexcept", "null", "pointer", "except"], "B_title": "Add null check. ", "B_clean_title": ["add", "null", "check"]},
{"A_title": "StringIndexOutOfBoundsException in CharSequenceTranslatorI found that there is bad surrogate pair handling in the CharSequenceTranslator This is a simple test case for this problem. uD83DuDE30 is a surrogate pair.  @Test public void testEscapeSurrogatePairs() throws Exception      assertEquals(uD83DuDE30 StringEscapeUtils.escapeCsv(uD83DuDE30));    Youll get the exception as shown below.  java.lang.StringIndexOutOfBoundsException: String index out of range: 2 at java.lang.String.charAt(String.java:658) at java.lang.Character.codePointAt(Character.java:4668) at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:95) at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:59) at org.apache.commons.lang3.StringEscapeUtils.escapeCsv(StringEscapeUtils.java:556)   Patch attached the method affected:  public final void translate(CharSequence input Writer out) throws IOException", "A_clean_title": ["stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "charsequencetranslatori", "char", "sequenc", "translat", "found", "that", "there", "bad", "surrog", "pair", "handl", "charsequencetransl", "char", "sequenc", "translat", "thi", "simpl", "test", "case", "thi", "problem", "ud83dude30", "d83du", "de30", "surrog", "pair", "test", "public", "void", "testescapesurrogatepair", "test", "escap", "surrog", "pair", "throw", "except", "assertequ", "assert", "equal", "ud83dude30", "d83du", "de30", "stringescapeutil", "escapecsv", "string", "escap", "util", "escap", "csv", "ud83dude30", "d83du", "de30", "youll", "get", "except", "as", "shown", "below", "java", "lang", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "string", "index", "out", "rang", "at", "java", "lang", "string", "charat", "char", "at", "string", "java:658", "at", "java", "lang", "charact", "codepointat", "code", "point", "at", "charact", "java:4668", "at", "org", "apach", "common", "lang3", "text", "translat", "charsequencetransl", "translat", "char", "sequenc", "translat", "charsequencetransl", "java:95", "char", "sequenc", "translat", "at", "org", "apach", "common", "lang3", "text", "translat", "charsequencetransl", "translat", "char", "sequenc", "translat", "charsequencetransl", "java:59", "char", "sequenc", "translat", "at", "org", "apach", "common", "lang3", "stringescapeutil", "escapecsv", "string", "escap", "util", "escap", "csv", "stringescapeutil", "java:556", "string", "escap", "util", "patch", "attach", "method", "affect", "public", "final", "void", "translat", "charsequ", "char", "sequenc", "input", "writer", "out", "throw", "ioexcept", "io", "except"], "B_title": "Remove excess code point in source string. ", "B_clean_title": ["remov", "excess", "code", "point", "sourc", "string"]},
{"A_title": "StringIndexOutOfBoundsException in CharSequenceTranslatorI found that there is bad surrogate pair handling in the CharSequenceTranslator This is a simple test case for this problem. uD83DuDE30 is a surrogate pair.  @Test public void testEscapeSurrogatePairs() throws Exception      assertEquals(uD83DuDE30 StringEscapeUtils.escapeCsv(uD83DuDE30));    Youll get the exception as shown below.  java.lang.StringIndexOutOfBoundsException: String index out of range: 2 at java.lang.String.charAt(String.java:658) at java.lang.Character.codePointAt(Character.java:4668) at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:95) at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:59) at org.apache.commons.lang3.StringEscapeUtils.escapeCsv(StringEscapeUtils.java:556)   Patch attached the method affected:  public final void translate(CharSequence input Writer out) throws IOException", "A_clean_title": ["stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "charsequencetranslatori", "char", "sequenc", "translat", "found", "that", "there", "bad", "surrog", "pair", "handl", "charsequencetransl", "char", "sequenc", "translat", "thi", "simpl", "test", "case", "thi", "problem", "ud83dude30", "d83du", "de30", "surrog", "pair", "test", "public", "void", "testescapesurrogatepair", "test", "escap", "surrog", "pair", "throw", "except", "assertequ", "assert", "equal", "ud83dude30", "d83du", "de30", "stringescapeutil", "escapecsv", "string", "escap", "util", "escap", "csv", "ud83dude30", "d83du", "de30", "youll", "get", "except", "as", "shown", "below", "java", "lang", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "string", "index", "out", "rang", "at", "java", "lang", "string", "charat", "char", "at", "string", "java:658", "at", "java", "lang", "charact", "codepointat", "code", "point", "at", "charact", "java:4668", "at", "org", "apach", "common", "lang3", "text", "translat", "charsequencetransl", "translat", "char", "sequenc", "translat", "charsequencetransl", "java:95", "char", "sequenc", "translat", "at", "org", "apach", "common", "lang3", "text", "translat", "charsequencetransl", "translat", "char", "sequenc", "translat", "charsequencetransl", "java:59", "char", "sequenc", "translat", "at", "org", "apach", "common", "lang3", "stringescapeutil", "escapecsv", "string", "escap", "util", "escap", "csv", "stringescapeutil", "java:556", "string", "escap", "util", "patch", "attach", "method", "affect", "public", "final", "void", "translat", "charsequ", "char", "sequenc", "input", "writer", "out", "throw", "ioexcept", "io", "except"], "B_title": "Fix bug in CharSequenceTranslator. ", "B_clean_title": ["fix", "bug", "charsequencetransl", "char", "sequenc", "translat"]},
{"A_title": "StringIndexOutOfBoundsException in CharSequenceTranslatorI found that there is bad surrogate pair handling in the CharSequenceTranslator This is a simple test case for this problem. uD83DuDE30 is a surrogate pair.  @Test public void testEscapeSurrogatePairs() throws Exception      assertEquals(uD83DuDE30 StringEscapeUtils.escapeCsv(uD83DuDE30));    Youll get the exception as shown below.  java.lang.StringIndexOutOfBoundsException: String index out of range: 2 at java.lang.String.charAt(String.java:658) at java.lang.Character.codePointAt(Character.java:4668) at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:95) at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:59) at org.apache.commons.lang3.StringEscapeUtils.escapeCsv(StringEscapeUtils.java:556)   Patch attached the method affected:  public final void translate(CharSequence input Writer out) throws IOException", "A_clean_title": ["stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "charsequencetranslatori", "char", "sequenc", "translat", "found", "that", "there", "bad", "surrog", "pair", "handl", "charsequencetransl", "char", "sequenc", "translat", "thi", "simpl", "test", "case", "thi", "problem", "ud83dude30", "d83du", "de30", "surrog", "pair", "test", "public", "void", "testescapesurrogatepair", "test", "escap", "surrog", "pair", "throw", "except", "assertequ", "assert", "equal", "ud83dude30", "d83du", "de30", "stringescapeutil", "escapecsv", "string", "escap", "util", "escap", "csv", "ud83dude30", "d83du", "de30", "youll", "get", "except", "as", "shown", "below", "java", "lang", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "string", "index", "out", "rang", "at", "java", "lang", "string", "charat", "char", "at", "string", "java:658", "at", "java", "lang", "charact", "codepointat", "code", "point", "at", "charact", "java:4668", "at", "org", "apach", "common", "lang3", "text", "translat", "charsequencetransl", "translat", "char", "sequenc", "translat", "charsequencetransl", "java:95", "char", "sequenc", "translat", "at", "org", "apach", "common", "lang3", "text", "translat", "charsequencetransl", "translat", "char", "sequenc", "translat", "charsequencetransl", "java:59", "char", "sequenc", "translat", "at", "org", "apach", "common", "lang3", "stringescapeutil", "escapecsv", "string", "escap", "util", "escap", "csv", "stringescapeutil", "java:556", "string", "escap", "util", "patch", "attach", "method", "affect", "public", "final", "void", "translat", "charsequ", "char", "sequenc", "input", "writer", "out", "throw", "ioexcept", "io", "except"], "B_title": "Missing import. Fix bug in CharSequenceTranslator. ", "B_clean_title": ["miss", "import", "fix", "bug", "charsequencetransl", "char", "sequenc", "translat"]},
{"A_title": "bug with implicit namespaces across modulesNone", "A_clean_title": ["bug", "implicit", "namespac", "across", "modulesnon", "modul", "none"], "B_title": "remove lastIndexOf. ", "B_clean_title": ["remov", "lastindexof", "last", "index"]},
{"A_title": "1.10 regression (StackOverflowError) with interface where generic type has itself as upper bound.None", "A_clean_title": ["10", "regress", "stackoverflowerror", "stack", "overflow", "error", "interfac", "where", "gener", "type", "ha", "itself", "as", "upper", "bound", "none"], "B_title": "Fix contextualActualTypeParameters . put ( typeParameter  actualTypeArgument ). ", "B_clean_title": ["fix", "contextualactualtypeparamet", "contextu", "actual", "type", "paramet", "put", "typeparamet", "type", "paramet", "actualtypeargu", "actual", "type", "argument"]},
{"A_title": "possibly a bug in org.joda.time.field.FieldUtils.safeMultiplyIt seems to me that as currently written in joda-time-2.1.jar org.joda.time.field.FieldUtils.safeMultiply(long val1 int scalar) doesnt detect the overflow if the long val1 == Long.MIN_VALUE and the int scalar == -1.  The attached file demonstrates what I think is the bug and suggests a patch.  I looked at the Joda Time bugs list in SourceForge but couldnt see anything that looked relevant.", "A_clean_title": ["possibl", "bug", "org", "joda", "time", "field", "fieldutil", "safemultiplyit", "field", "util", "safe", "multipli", "it", "seem", "me", "that", "as", "current", "written", "joda", "time", "jar", "org", "joda", "time", "field", "fieldutil", "safemultipli", "field", "util", "safe", "multipli", "long", "val1", "int", "scalar", "doesnt", "detect", "overflow", "long", "val1", "long", "min", "valu", "int", "scalar", "attach", "file", "demonstr", "what", "think", "bug", "suggest", "patch", "look", "at", "joda", "time", "bug", "list", "sourceforg", "sourc", "forg", "but", "couldnt", "see", "anyth", "that", "look", "relev"], "B_title": "Fix fieldUtils. ", "B_clean_title": ["fix", "fieldutil", "field", "util"]},
{"A_title": "possibly a bug in org.joda.time.field.FieldUtils.safeMultiplyIt seems to me that as currently written in joda-time-2.1.jar org.joda.time.field.FieldUtils.safeMultiply(long val1 int scalar) doesnt detect the overflow if the long val1 == Long.MIN_VALUE and the int scalar == -1.  The attached file demonstrates what I think is the bug and suggests a patch.  I looked at the Joda Time bugs list in SourceForge but couldnt see anything that looked relevant.", "A_clean_title": ["possibl", "bug", "org", "joda", "time", "field", "fieldutil", "safemultiplyit", "field", "util", "safe", "multipli", "it", "seem", "me", "that", "as", "current", "written", "joda", "time", "jar", "org", "joda", "time", "field", "fieldutil", "safemultipli", "field", "util", "safe", "multipli", "long", "val1", "int", "scalar", "doesnt", "detect", "overflow", "long", "val1", "long", "min", "valu", "int", "scalar", "attach", "file", "demonstr", "what", "think", "bug", "suggest", "patch", "look", "at", "joda", "time", "bug", "list", "sourceforg", "sourc", "forg", "but", "couldnt", "see", "anyth", "that", "look", "relev"], "B_title": "Allow negative numbers in FieldUtils. ", "B_clean_title": ["allow", "neg", "number", "fieldutil", "field", "util"]},
{"A_title": "possibly a bug in org.joda.time.field.FieldUtils.safeMultiplyIt seems to me that as currently written in joda-time-2.1.jar org.joda.time.field.FieldUtils.safeMultiply(long val1 int scalar) doesnt detect the overflow if the long val1 == Long.MIN_VALUE and the int scalar == -1.  The attached file demonstrates what I think is the bug and suggests a patch.  I looked at the Joda Time bugs list in SourceForge but couldnt see anything that looked relevant.", "A_clean_title": ["possibl", "bug", "org", "joda", "time", "field", "fieldutil", "safemultiplyit", "field", "util", "safe", "multipli", "it", "seem", "me", "that", "as", "current", "written", "joda", "time", "jar", "org", "joda", "time", "field", "fieldutil", "safemultipli", "field", "util", "safe", "multipli", "long", "val1", "int", "scalar", "doesnt", "detect", "overflow", "long", "val1", "long", "min", "valu", "int", "scalar", "attach", "file", "demonstr", "what", "think", "bug", "suggest", "patch", "look", "at", "joda", "time", "bug", "list", "sourceforg", "sourc", "forg", "but", "couldnt", "see", "anyth", "that", "look", "relev"], "B_title": "Fix a bug in FieldUtils. ", "B_clean_title": ["fix", "bug", "fieldutil", "field", "util"]},
{"A_title": "BooleanUtils.toBoolean() - invalid drop-thru in case statement causes StringIndexOutOfBoundsExceptionThe method BooleanUtils.toBoolean() has a case statement; case 3 drops through to case 4; this can cause StringIndexOutOfBoundsException for example with the test: assertEquals(false BooleanUtils.toBoolean(tru)); The end of case 3 should return false. Patch to follow for source and unit test.", "A_clean_title": ["booleanutil", "toboolean", "boolean", "util", "boolean", "invalid", "drop", "thru", "case", "statement", "caus", "stringindexoutofboundsexceptionth", "string", "index", "out", "bound", "except", "method", "booleanutil", "toboolean", "boolean", "util", "boolean", "ha", "case", "statement", "case", "drop", "through", "case", "thi", "caus", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "exampl", "test", "assertequ", "assert", "equal", "fals", "booleanutil", "toboolean", "boolean", "util", "boolean", "tru", "end", "case", "return", "fals", "patch", "follow", "sourc", "unit", "test"], "B_title": "Optimize toBoolean ( ). ", "B_clean_title": ["optim", "toboolean", "boolean"]},
{"A_title": "BooleanUtils.toBoolean() - invalid drop-thru in case statement causes StringIndexOutOfBoundsExceptionThe method BooleanUtils.toBoolean() has a case statement; case 3 drops through to case 4; this can cause StringIndexOutOfBoundsException for example with the test: assertEquals(false BooleanUtils.toBoolean(tru)); The end of case 3 should return false. Patch to follow for source and unit test.", "A_clean_title": ["booleanutil", "toboolean", "boolean", "util", "boolean", "invalid", "drop", "thru", "case", "statement", "caus", "stringindexoutofboundsexceptionth", "string", "index", "out", "bound", "except", "method", "booleanutil", "toboolean", "boolean", "util", "boolean", "ha", "case", "statement", "case", "drop", "through", "case", "thi", "caus", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "exampl", "test", "assertequ", "assert", "equal", "fals", "booleanutil", "toboolean", "boolean", "util", "boolean", "tru", "end", "case", "return", "fals", "patch", "follow", "sourc", "unit", "test"], "B_title": "Added missing return statement. ", "B_clean_title": ["ad", "miss", "return", "statement"]},
{"A_title": "BooleanUtils.toBoolean() - invalid drop-thru in case statement causes StringIndexOutOfBoundsExceptionThe method BooleanUtils.toBoolean() has a case statement; case 3 drops through to case 4; this can cause StringIndexOutOfBoundsException for example with the test: assertEquals(false BooleanUtils.toBoolean(tru)); The end of case 3 should return false. Patch to follow for source and unit test.", "A_clean_title": ["booleanutil", "toboolean", "boolean", "util", "boolean", "invalid", "drop", "thru", "case", "statement", "caus", "stringindexoutofboundsexceptionth", "string", "index", "out", "bound", "except", "method", "booleanutil", "toboolean", "boolean", "util", "boolean", "ha", "case", "statement", "case", "drop", "through", "case", "thi", "caus", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "exampl", "test", "assertequ", "assert", "equal", "fals", "booleanutil", "toboolean", "boolean", "util", "boolean", "tru", "end", "case", "return", "fals", "patch", "follow", "sourc", "unit", "test"], "B_title": "missing break. ", "B_clean_title": ["miss", "break"]},
{"A_title": "BooleanUtils.toBoolean() - invalid drop-thru in case statement causes StringIndexOutOfBoundsExceptionThe method BooleanUtils.toBoolean() has a case statement; case 3 drops through to case 4; this can cause StringIndexOutOfBoundsException for example with the test: assertEquals(false BooleanUtils.toBoolean(tru)); The end of case 3 should return false. Patch to follow for source and unit test.", "A_clean_title": ["booleanutil", "toboolean", "boolean", "util", "boolean", "invalid", "drop", "thru", "case", "statement", "caus", "stringindexoutofboundsexceptionth", "string", "index", "out", "bound", "except", "method", "booleanutil", "toboolean", "boolean", "util", "boolean", "ha", "case", "statement", "case", "drop", "through", "case", "thi", "caus", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "exampl", "test", "assertequ", "assert", "equal", "fals", "booleanutil", "toboolean", "boolean", "util", "boolean", "tru", "end", "case", "return", "fals", "patch", "follow", "sourc", "unit", "test"], "B_title": "missing bracket. ", "B_clean_title": ["miss", "bracket"]},
{"A_title": "BooleanUtils.toBoolean() - invalid drop-thru in case statement causes StringIndexOutOfBoundsExceptionThe method BooleanUtils.toBoolean() has a case statement; case 3 drops through to case 4; this can cause StringIndexOutOfBoundsException for example with the test: assertEquals(false BooleanUtils.toBoolean(tru)); The end of case 3 should return false. Patch to follow for source and unit test.", "A_clean_title": ["booleanutil", "toboolean", "boolean", "util", "boolean", "invalid", "drop", "thru", "case", "statement", "caus", "stringindexoutofboundsexceptionth", "string", "index", "out", "bound", "except", "method", "booleanutil", "toboolean", "boolean", "util", "boolean", "ha", "case", "statement", "case", "drop", "through", "case", "thi", "caus", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "exampl", "test", "assertequ", "assert", "equal", "fals", "booleanutil", "toboolean", "boolean", "util", "boolean", "tru", "end", "case", "return", "fals", "patch", "follow", "sourc", "unit", "test"], "B_title": "Added missing case in BooleanUtils. ", "B_clean_title": ["ad", "miss", "case", "booleanutil", "boolean", "util"]},
{"A_title": "BooleanUtils.toBoolean() - invalid drop-thru in case statement causes StringIndexOutOfBoundsExceptionThe method BooleanUtils.toBoolean() has a case statement; case 3 drops through to case 4; this can cause StringIndexOutOfBoundsException for example with the test: assertEquals(false BooleanUtils.toBoolean(tru)); The end of case 3 should return false. Patch to follow for source and unit test.", "A_clean_title": ["booleanutil", "toboolean", "boolean", "util", "boolean", "invalid", "drop", "thru", "case", "statement", "caus", "stringindexoutofboundsexceptionth", "string", "index", "out", "bound", "except", "method", "booleanutil", "toboolean", "boolean", "util", "boolean", "ha", "case", "statement", "case", "drop", "through", "case", "thi", "caus", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "exampl", "test", "assertequ", "assert", "equal", "fals", "booleanutil", "toboolean", "boolean", "util", "boolean", "tru", "end", "case", "return", "fals", "patch", "follow", "sourc", "unit", "test"], "B_title": "missing break. ", "B_clean_title": ["miss", "break"]},
{"A_title": "BooleanUtils.toBoolean() - invalid drop-thru in case statement causes StringIndexOutOfBoundsExceptionThe method BooleanUtils.toBoolean() has a case statement; case 3 drops through to case 4; this can cause StringIndexOutOfBoundsException for example with the test: assertEquals(false BooleanUtils.toBoolean(tru)); The end of case 3 should return false. Patch to follow for source and unit test.", "A_clean_title": ["booleanutil", "toboolean", "boolean", "util", "boolean", "invalid", "drop", "thru", "case", "statement", "caus", "stringindexoutofboundsexceptionth", "string", "index", "out", "bound", "except", "method", "booleanutil", "toboolean", "boolean", "util", "boolean", "ha", "case", "statement", "case", "drop", "through", "case", "thi", "caus", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "exampl", "test", "assertequ", "assert", "equal", "fals", "booleanutil", "toboolean", "boolean", "util", "boolean", "tru", "end", "case", "return", "fals", "patch", "follow", "sourc", "unit", "test"], "B_title": "missing test for Y. ", "B_clean_title": ["miss", "test"]},
{"A_title": "BooleanUtils.toBoolean() - invalid drop-thru in case statement causes StringIndexOutOfBoundsExceptionThe method BooleanUtils.toBoolean() has a case statement; case 3 drops through to case 4; this can cause StringIndexOutOfBoundsException for example with the test: assertEquals(false BooleanUtils.toBoolean(tru)); The end of case 3 should return false. Patch to follow for source and unit test.", "A_clean_title": ["booleanutil", "toboolean", "boolean", "util", "boolean", "invalid", "drop", "thru", "case", "statement", "caus", "stringindexoutofboundsexceptionth", "string", "index", "out", "bound", "except", "method", "booleanutil", "toboolean", "boolean", "util", "boolean", "ha", "case", "statement", "case", "drop", "through", "case", "thi", "caus", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "exampl", "test", "assertequ", "assert", "equal", "fals", "booleanutil", "toboolean", "boolean", "util", "boolean", "tru", "end", "case", "return", "fals", "patch", "follow", "sourc", "unit", "test"], "B_title": "missing break. ", "B_clean_title": ["miss", "break"]},
{"A_title": "combining @interface and multiple @extends can crash compilerNone", "A_clean_title": ["combin", "interfac", "multipl", "extend", "crash", "compilernon", "compil", "none"], "B_title": "Add null check in TypeCheck . java. Added missing for loop. ", "B_clean_title": ["add", "null", "check", "typecheck", "type", "check", "java", "ad", "miss", "loop"]},
{"A_title": "combining @interface and multiple @extends can crash compilerNone", "A_clean_title": ["combin", "interfac", "multipl", "extend", "crash", "compilernon", "compil", "none"], "B_title": "Added TypeCheck copy check. Added TypeCheck copy .. ", "B_clean_title": ["ad", "typecheck", "type", "check", "copi", "check", "ad", "typecheck", "type", "check", "copi"]},
{"A_title": "Dangerous code in PoissonDistributionImplIn the following excerpt from class PoissonDistributionImpl: PoissonDistributionImpl.java     public PoissonDistributionImpl(double p NormalDistribution z)          super();         setNormal(z);         setMean(p);        (1) Overridable methods are called within the constructor. (2) The reference z is stored and modified within the class. Ive encountered problem (1) in several classes while working on issue 348. In those cases in order to remove potential problems I copied/pasted the body of the setter methods inside the constructor but I think that a more elegant solution would be to remove the setters altogether (i.e. make the classes immutable). Problem (2) can also create unexpected behaviour. Is it really necessary to pass the NormalDistribution object; cant it be always created within the class?", "A_clean_title": ["danger", "code", "poissondistributionimplin", "poisson", "distribut", "impl", "follow", "excerpt", "class", "poissondistributionimpl", "poisson", "distribut", "impl", "poissondistributionimpl", "java", "poisson", "distribut", "impl", "public", "poissondistributionimpl", "poisson", "distribut", "impl", "doubl", "normaldistribut", "normal", "distribut", "super", "setnorm", "set", "normal", "setmean", "set", "mean", "overrid", "method", "are", "call", "within", "constructor", "refer", "store", "modifi", "within", "class", "ive", "encount", "problem", "sever", "class", "while", "work", "issu", "348", "those", "case", "order", "remov", "potenti", "problem", "copi", "past", "bodi", "setter", "method", "insid", "constructor", "but", "think", "that", "more", "eleg", "solut", "would", "remov", "setter", "altogeth", "make", "class", "immut", "problem", "also", "creat", "unexpect", "behaviour", "it", "realli", "necessari", "pass", "normaldistribut", "normal", "distribut", "object", "cant", "it", "alway", "creat", "within", "class"], "B_title": "Add missing import. Add a check for strictly positive p = 0 .. ", "B_clean_title": ["add", "miss", "import", "add", "check", "strictli", "posit"]},
{"A_title": "weird object literal invalid property error on unrelated object prototypeNone", "A_clean_title": ["weird", "object", "liter", "invalid", "properti", "error", "unrel", "object", "prototypenon", "prototyp", "none"], "B_title": "Avoid matching against an unneeded property .. ", "B_clean_title": ["avoid", "match", "against", "unneed", "properti"]},
{"A_title": "Classify non-rightmost expressions as problematicNone", "A_clean_title": ["classifi", "non", "rightmost", "express", "as", "problematicnon", "problemat", "none"], "B_title": "Remove one more for - loop. ", "B_clean_title": ["remov", "one", "more", "loop"]},
{"A_title": "Classify non-rightmost expressions as problematicNone", "A_clean_title": ["classifi", "non", "rightmost", "express", "as", "problematicnon", "problemat", "none"], "B_title": "Updated patch. ", "B_clean_title": ["updat", "patch"]},
{"A_title": "getLInfNorm() uses wrong formula in both ArrayRealVector and OpenMapRealVector (in different ways)the L_infinity norm of a finite dimensional vector is just the max of the absolute value of its entries. The current implementation in ArrayRealVector has a typo:      public double getLInfNorm()          double max = 0;         for (double a : data)              max += Math.max(max Math.abs(a));                  return max;        the += should just be an =. There is sadly a unit test assuring us that this is the correct behavior (effectively a regression-only test not a test for correctness). Worse the implementation in OpenMapRealVector is not even positive semi-definite:          public double getLInfNorm()          double max = 0;         Iterator iter = entries.iterator();         while (iter.hasNext())              iter.advance();             max += iter.value();                  return max;        I would suggest that this method be moved up to the AbstractRealVector superclass and implemented using the sparseIterator():    public double getLInfNorm()      double norm = 0;     Iterator<Entry> it = sparseIterator();     Entry e;     while(it.hasNext() && (e = it.next()) != null)        norm = Math.max(norm Math.abs(e.getValue()));          return norm;      Unit tests with negative valued vectors would be helpful to check for this kind of thing in the future.", "A_clean_title": ["getlinfnorm", "get", "inf", "norm", "use", "wrong", "formula", "both", "arrayrealvector", "array", "real", "vector", "openmaprealvector", "open", "map", "real", "vector", "differ", "way", "infin", "norm", "finit", "dimension", "vector", "just", "max", "absolut", "valu", "it", "entri", "current", "implement", "arrayrealvector", "array", "real", "vector", "ha", "typo", "public", "doubl", "getlinfnorm", "get", "inf", "norm", "doubl", "max", "doubl", "data", "max", "math", "max", "max", "math", "ab", "return", "max", "just", "there", "sadli", "unit", "test", "assur", "us", "that", "thi", "correct", "behavior", "effect", "regress", "onli", "test", "not", "test", "correct", "wors", "implement", "openmaprealvector", "open", "map", "real", "vector", "not", "even", "posit", "semi", "definit", "public", "doubl", "getlinfnorm", "get", "inf", "norm", "doubl", "max", "iter", "iter", "entri", "iter", "while", "iter", "hasnext", "ha", "next", "iter", "advanc", "max", "iter", "valu", "return", "max", "would", "suggest", "that", "thi", "method", "move", "up", "abstractrealvector", "abstract", "real", "vector", "superclass", "implement", "sparseiter", "spars", "iter", "public", "doubl", "getlinfnorm", "get", "inf", "norm", "doubl", "norm", "iter", "entri", "it", "sparseiter", "spars", "iter", "entri", "while", "it", "hasnext", "ha", "next", "it", "next", "null", "norm", "math", "max", "norm", "math", "ab", "getvalu", "get", "valu", "return", "norm", "unit", "test", "neg", "valu", "vector", "would", "help", "check", "thi", "kind", "thing", "futur"], "B_title": "Fix ArrayRealVector . getLInfNorm ( ). Added get ( ) method to OpenMapRealVector. ", "B_clean_title": ["fix", "arrayrealvector", "array", "real", "vector", "getlinfnorm", "get", "inf", "norm", "ad", "get", "method", "openmaprealvector", "open", "map", "real", "vector"]},
{"A_title": "Constructing invalid PartialsPartials can be constructed by invoking a constructor Partial(DateTimeFieldType int) or by merging together a set of partials using with each constructed by calling Partial(DateTimeFieldType int). However the above doesnt work in all cases: I suppose the Partials should not allow to be constructed in either case. Is that right?  Theres also a related issue (probably stems from the fact that the Partial is invalid):", "A_clean_title": ["construct", "invalid", "partialsparti", "partial", "partial", "construct", "by", "invok", "constructor", "partial", "datetimefieldtyp", "date", "time", "field", "type", "int", "or", "by", "merg", "togeth", "set", "partial", "each", "construct", "by", "call", "partial", "datetimefieldtyp", "date", "time", "field", "type", "int", "howev", "abov", "doesnt", "work", "all", "case", "suppos", "partial", "not", "allow", "construct", "either", "case", "that", "right", "there", "also", "relat", "issu", "probabl", "stem", "fact", "that", "partial", "invalid"], "B_title": "Fix partial constructor to not use iChronology directly in the partial constructor. ", "B_clean_title": ["fix", "partial", "constructor", "not", "use", "ichronolog", "chronolog", "directli", "partial", "constructor"]},
{"A_title": "Constructing invalid PartialsPartials can be constructed by invoking a constructor Partial(DateTimeFieldType int) or by merging together a set of partials using with each constructed by calling Partial(DateTimeFieldType int). However the above doesnt work in all cases: I suppose the Partials should not allow to be constructed in either case. Is that right?  Theres also a related issue (probably stems from the fact that the Partial is invalid):", "A_clean_title": ["construct", "invalid", "partialsparti", "partial", "partial", "construct", "by", "invok", "constructor", "partial", "datetimefieldtyp", "date", "time", "field", "type", "int", "or", "by", "merg", "togeth", "set", "partial", "each", "construct", "by", "call", "partial", "datetimefieldtyp", "date", "time", "field", "type", "int", "howev", "abov", "doesnt", "work", "all", "case", "suppos", "partial", "not", "allow", "construct", "either", "case", "that", "right", "there", "also", "relat", "issu", "probabl", "stem", "fact", "that", "partial", "invalid"], "B_title": "Fix partial constructor to work with joda - time. ", "B_clean_title": ["fix", "partial", "constructor", "work", "joda", "time"]},
{"A_title": "ClassCastException during TypeCheck passNone", "A_clean_title": ["classcastexcept", "class", "cast", "except", "dure", "typecheck", "type", "check", "passnon", "pass", "none"], "B_title": "Improved performance for record types .. ", "B_clean_title": ["improv", "perform", "record", "type"]},
{"A_title": "ClassCastException during TypeCheck passNone", "A_clean_title": ["classcastexcept", "class", "cast", "except", "dure", "typecheck", "type", "check", "passnon", "pass", "none"], "B_title": "Improved method return type for JSType . getLeastSupertype ( JSType ). ", "B_clean_title": ["improv", "method", "return", "type", "jstype", "js", "type", "getleastsupertyp", "get", "least", "supertyp", "jstype", "js", "type"]},
{"A_title": "ClassCastException during TypeCheck passNone", "A_clean_title": ["classcastexcept", "class", "cast", "except", "dure", "typecheck", "type", "check", "passnon", "pass", "none"], "B_title": "Remove recording type properties where they are not equivalent. ", "B_clean_title": ["remov", "record", "type", "properti", "where", "they", "are", "not", "equival"]},
{"A_title": "LocaleUtils.toLocale() rejects strings with only language+variantLocaleUtils.toLocale() throws an exception on strings containing a language and a variant but no country code. For example : fr__POSIX This string can be produced with the JDK by instanciating a Locale with an empty string for the country : new Locale(fr  POSIX).toString(). According to the javadoc for the Locale class a variant is allowed with just a language code or just a country code. Commons Configuration handles this case in its PropertyConverter.toLocale() method. Id like to replace our implementation by the one provided by LocaleUtils but our tests fail due to this case.", "A_clean_title": ["localeutil", "tolocal", "local", "util", "local", "reject", "string", "onli", "language+variantlocaleutil", "tolocal", "language+vari", "local", "util", "local", "throw", "except", "string", "contain", "languag", "variant", "but", "no", "countri", "code", "exampl", "fr", "posix", "thi", "string", "produc", "jdk", "by", "instanci", "local", "empti", "string", "countri", "new", "local", "fr", "posix", "tostr", "string", "accord", "javadoc", "local", "class", "variant", "allow", "just", "languag", "code", "or", "just", "countri", "code", "common", "configur", "handl", "thi", "case", "it", "propertyconvert", "tolocal", "properti", "convert", "local", "method", "id", "like", "replac", "our", "implement", "by", "one", "provid", "by", "localeutil", "local", "util", "but", "our", "test", "fail", "due", "thi", "case"], "B_title": "Remove spaces. Missing _ sign in LocaleUtils. Added missing copy of LocaleUtils. ", "B_clean_title": ["remov", "space", "miss", "sign", "localeutil", "local", "util", "ad", "miss", "copi", "localeutil", "local", "util"]},
{"A_title": "Bugs in Frequency APII think the existing Frequency API has some bugs in it. The addValue(Object v) method allows one to add a plain Object but one cannot add anything further to the instance as the second add fails with IllegalArgumentException. In fact the problem is with the first call to addValue(Object) which should not allow a plain Object to be added - it should only allow Comparable objects. This could be fixed by checking that the object is Comparable. Similar considerations apply to the getCumFreq(Object) and getCumPct(Object) methods - they will only work with objects that implement Comparable. The getCount(Object) and getPct(Object) methods dont fail when given a non-Comparable object (because the class cast exception is caught) however they just return 0 as if the object was not present:          final Object OBJ = new Object();         f.addValue(OBJ); // This ought to fail but doesnt causing the unexpected behaviour below         System.out.println(f.getCount(OBJ)); // 0         System.out.println(f.getPct(OBJ)); // 0.0   Rather than adding extra checks for Comparable it seems to me that the API would be much improved by using Comparable instead of Object. Also it should make it easier to implement generics. However this would cause compilation failures for some programs that pass Object rather than Comparable to the class. These would need recoding but I think they would continue to run OK against the new API. It would also affect the run-time behaviour slightly as the first attempt to add a non-Comparable object would fail rather than the second add of a possibly valid object. But is that a viable program? It can only add one object and any attempt to get statistics will either return 0 or an Exception and applying the instanceof fix would also cause it to fail.", "A_clean_title": ["bug", "frequenc", "apii", "think", "exist", "frequenc", "api", "ha", "some", "bug", "it", "addvalu", "add", "valu", "object", "method", "allow", "one", "add", "plain", "object", "but", "one", "not", "add", "anyth", "further", "instanc", "as", "second", "add", "fail", "illegalargumentexcept", "illeg", "argument", "except", "fact", "problem", "first", "call", "addvalu", "add", "valu", "object", "which", "not", "allow", "plain", "object", "ad", "it", "onli", "allow", "compar", "object", "thi", "could", "fix", "by", "check", "that", "object", "compar", "similar", "consider", "appli", "getcumfreq", "get", "cum", "freq", "object", "getcumpct", "get", "cum", "pct", "object", "method", "they", "will", "onli", "work", "object", "that", "implement", "compar", "getcount", "get", "count", "object", "getpct", "get", "pct", "object", "method", "dont", "fail", "when", "given", "non", "compar", "object", "becaus", "class", "cast", "except", "caught", "howev", "they", "just", "return", "as", "object", "wa", "not", "present", "final", "object", "obj", "new", "object", "addvalu", "add", "valu", "obj", "thi", "ought", "fail", "but", "doesnt", "caus", "unexpect", "behaviour", "below", "system", "out", "println", "getcount", "get", "count", "obj", "system", "out", "println", "getpct", "get", "pct", "obj", "rather", "than", "ad", "extra", "check", "compar", "it", "seem", "me", "that", "api", "would", "much", "improv", "by", "compar", "instead", "object", "also", "it", "make", "it", "easier", "implement", "gener", "howev", "thi", "would", "caus", "compil", "failur", "some", "program", "that", "pass", "object", "rather", "than", "compar", "class", "these", "would", "need", "recod", "but", "think", "they", "would", "continu", "run", "ok", "against", "new", "api", "it", "would", "also", "affect", "run", "time", "behaviour", "slightli", "as", "first", "attempt", "add", "non", "compar", "object", "would", "fail", "rather", "than", "second", "add", "possibl", "valid", "object", "but", "that", "viabl", "program", "it", "onli", "add", "one", "object", "ani", "attempt", "get", "statist", "will", "either", "return", "or", "except", "appli", "instanceof", "fix", "would", "also", "caus", "it", "fail"], "B_title": "AddValue ( Object ) to Frequency  throw exception if it is not a Comparable. ", "B_clean_title": ["addvalu", "add", "valu", "object", "frequenc", "throw", "except", "it", "not", "compar"]},
{"A_title": "Bugs in Frequency APII think the existing Frequency API has some bugs in it. The addValue(Object v) method allows one to add a plain Object but one cannot add anything further to the instance as the second add fails with IllegalArgumentException. In fact the problem is with the first call to addValue(Object) which should not allow a plain Object to be added - it should only allow Comparable objects. This could be fixed by checking that the object is Comparable. Similar considerations apply to the getCumFreq(Object) and getCumPct(Object) methods - they will only work with objects that implement Comparable. The getCount(Object) and getPct(Object) methods dont fail when given a non-Comparable object (because the class cast exception is caught) however they just return 0 as if the object was not present:          final Object OBJ = new Object();         f.addValue(OBJ); // This ought to fail but doesnt causing the unexpected behaviour below         System.out.println(f.getCount(OBJ)); // 0         System.out.println(f.getPct(OBJ)); // 0.0   Rather than adding extra checks for Comparable it seems to me that the API would be much improved by using Comparable instead of Object. Also it should make it easier to implement generics. However this would cause compilation failures for some programs that pass Object rather than Comparable to the class. These would need recoding but I think they would continue to run OK against the new API. It would also affect the run-time behaviour slightly as the first attempt to add a non-Comparable object would fail rather than the second add of a possibly valid object. But is that a viable program? It can only add one object and any attempt to get statistics will either return 0 or an Exception and applying the instanceof fix would also cause it to fail.", "A_clean_title": ["bug", "frequenc", "apii", "think", "exist", "frequenc", "api", "ha", "some", "bug", "it", "addvalu", "add", "valu", "object", "method", "allow", "one", "add", "plain", "object", "but", "one", "not", "add", "anyth", "further", "instanc", "as", "second", "add", "fail", "illegalargumentexcept", "illeg", "argument", "except", "fact", "problem", "first", "call", "addvalu", "add", "valu", "object", "which", "not", "allow", "plain", "object", "ad", "it", "onli", "allow", "compar", "object", "thi", "could", "fix", "by", "check", "that", "object", "compar", "similar", "consider", "appli", "getcumfreq", "get", "cum", "freq", "object", "getcumpct", "get", "cum", "pct", "object", "method", "they", "will", "onli", "work", "object", "that", "implement", "compar", "getcount", "get", "count", "object", "getpct", "get", "pct", "object", "method", "dont", "fail", "when", "given", "non", "compar", "object", "becaus", "class", "cast", "except", "caught", "howev", "they", "just", "return", "as", "object", "wa", "not", "present", "final", "object", "obj", "new", "object", "addvalu", "add", "valu", "obj", "thi", "ought", "fail", "but", "doesnt", "caus", "unexpect", "behaviour", "below", "system", "out", "println", "getcount", "get", "count", "obj", "system", "out", "println", "getpct", "get", "pct", "obj", "rather", "than", "ad", "extra", "check", "compar", "it", "seem", "me", "that", "api", "would", "much", "improv", "by", "compar", "instead", "object", "also", "it", "make", "it", "easier", "implement", "gener", "howev", "thi", "would", "caus", "compil", "failur", "some", "program", "that", "pass", "object", "rather", "than", "compar", "class", "these", "would", "need", "recod", "but", "think", "they", "would", "continu", "run", "ok", "against", "new", "api", "it", "would", "also", "affect", "run", "time", "behaviour", "slightli", "as", "first", "attempt", "add", "non", "compar", "object", "would", "fail", "rather", "than", "second", "add", "possibl", "valid", "object", "but", "that", "viabl", "program", "it", "onli", "add", "one", "object", "ani", "attempt", "get", "statist", "will", "either", "return", "or", "except", "appli", "instanceof", "fix", "would", "also", "caus", "it", "fail"], "B_title": "Adding missing throw in Frequency . addValue ( ). ", "B_clean_title": ["ad", "miss", "throw", "frequenc", "addvalu", "add", "valu"]},
{"A_title": "bogus missing return warningNone", "A_clean_title": ["bogu", "miss", "return", "warningnon", "warn", "none"], "B_title": "Fixing finally map .. ", "B_clean_title": ["fix", "final", "map"]},
{"A_title": "XYSeries.addOrUpdate() should add if duplicates are allowedIve found a bug in jfreechart-1.0.9 code for org.jfree.data.xy.XYSeries. There was a change some time ago which introduced the notion of allowing duplicate X values in XYSeries data. The method addOrUpdate(Number x Number y) was never modified to support this and therefore duplicate data were overwriting existing data.", "A_clean_title": ["xyseri", "addorupd", "xy", "seri", "add", "or", "updat", "add", "duplic", "are", "allowed", "allow", "ive", "found", "bug", "jfreechart", "code", "org", "jfree", "data", "xy", "xyseri", "xy", "seri", "there", "wa", "chang", "some", "time", "ago", "which", "introduc", "notion", "allow", "duplic", "valu", "xyseri", "xy", "seri", "data", "method", "addorupd", "add", "or", "updat", "number", "number", "wa", "never", "modifi", "support", "thi", "therefor", "duplic", "data", "were", "overwrit", "exist", "data"], "B_title": "Use the method provided for sorting XYSeries. ", "B_clean_title": ["use", "method", "provid", "sort", "xyseri", "xy", "seri"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Fix NaN - > org . apache . commons . math3 . complex . Complex. ", "B_clean_title": ["fix", "nan", "na", "org", "apach", "common", "math3", "complex", "complex"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Extend the definition of INF .. ", "B_clean_title": ["extend", "definit", "inf"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Add 0 . 0 equals to Complex. ", "B_clean_title": ["add", "equal", "complex"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Add the inverse of Complex . INF to check for 0 . 0 precision .. ", "B_clean_title": ["add", "invers", "complex", "inf", "check", "precis"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Add the inverse of Complex . INF as well .. ", "B_clean_title": ["add", "invers", "complex", "inf", "as", "well"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Fixed a minor typo in Complex . reciprocal ( ). ", "B_clean_title": ["fix", "minor", "typo", "complex", "reciproc"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "NaN - > Complex . INF. ", "B_clean_title": ["nan", "na", "complex", "inf"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "disable side effects check for functions with side effects. ", "B_clean_title": ["disabl", "side", "effect", "check", "function", "side", "effect"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "@@ start = 0 ; for the better coding experience. ", "B_clean_title": ["start", "better", "code", "experi"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Updated function injector copy. ", "B_clean_title": ["updat", "function", "injector", "copi"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Allow side effects in function arguments .. ", "B_clean_title": ["allow", "side", "effect", "function", "argument"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Fixing the function infusion of side effects in JS stylesheet. ", "B_clean_title": ["fix", "function", "infus", "side", "effect", "js", "stylesheet"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Allow null arguments for static closures .. ", "B_clean_title": ["allow", "null", "argument", "static", "closur"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Allow side effects for closure arguments. ", "B_clean_title": ["allow", "side", "effect", "closur", "argument"]},
{"A_title": "Statistics.setVarianceImpl makes getStandardDeviation produce NaNInvoking SummaryStatistics.setVarianceImpl(new Variance(true/false) makes getStandardDeviation produce NaN. The code to reproduce it:  int scores = 1 2 3 4; SummaryStatistics stats = new SummaryStatistics(); stats.setVarianceImpl(new Variance(false)); //use population variance for(int i : scores)    stats.addValue(i);  double sd = stats.getStandardDeviation(); System.out.println(sd);   A workaround suggested by Mikkel is:    double sd = FastMath.sqrt(stats.getSecondMoment() / stats.getN());", "A_clean_title": ["statist", "setvarianceimpl", "set", "varianc", "impl", "make", "getstandarddevi", "get", "standard", "deviat", "produc", "naninvok", "na", "invok", "summarystatist", "setvarianceimpl", "summari", "statist", "set", "varianc", "impl", "new", "varianc", "true", "fals", "make", "getstandarddevi", "get", "standard", "deviat", "produc", "nan", "na", "code", "reproduc", "it", "int", "score", "summarystatist", "summari", "statist", "stat", "new", "summarystatist", "summari", "statist", "stat", "setvarianceimpl", "set", "varianc", "impl", "new", "varianc", "fals", "use", "popul", "varianc", "int", "score", "stat", "addvalu", "add", "valu", "doubl", "sd", "stat", "getstandarddevi", "get", "standard", "deviat", "system", "out", "println", "sd", "workaround", "suggest", "by", "mikkel", "doubl", "sd", "fastmath", "sqrt", "fast", "math", "stat", "getsecondmo", "get", "second", "moment", "stat", "getn", "get"], "B_title": "updated hercules patch. Fix bug in secondMoment of mean implementation. fixed case. ", "B_clean_title": ["updat", "hercul", "patch", "fix", "bug", "secondmo", "second", "moment", "mean", "implement", "fix", "case"]},
{"A_title": "StrBuilder contains usages of thisBuf.length when they should use sizeWhile fixing LANG-294 I noticed that there are two other places in StrBuilder that reference thisBuf.length and unless Im mistaken they shouldnt.", "A_clean_title": ["strbuilder", "str", "builder", "contain", "usag", "thisbuf", "length", "thi", "buf", "when", "they", "use", "sizewhil", "size", "while", "fix", "lang", "294", "notic", "that", "there", "are", "two", "other", "place", "strbuilder", "str", "builder", "that", "refer", "thisbuf", "length", "thi", "buf", "unless", "im", "mistaken", "they", "shouldnt"], "B_title": "added missing patch. updated hercules bugfix. ", "B_clean_title": ["ad", "miss", "patch", "updat", "hercul", "bugfix"]},
{"A_title": "StrBuilder contains usages of thisBuf.length when they should use sizeWhile fixing LANG-294 I noticed that there are two other places in StrBuilder that reference thisBuf.length and unless Im mistaken they shouldnt.", "A_clean_title": ["strbuilder", "str", "builder", "contain", "usag", "thisbuf", "length", "thi", "buf", "when", "they", "use", "sizewhil", "size", "while", "fix", "lang", "294", "notic", "that", "there", "are", "two", "other", "place", "strbuilder", "str", "builder", "that", "refer", "thisbuf", "length", "thi", "buf", "unless", "im", "mistaken", "they", "shouldnt"], "B_title": "StrBuilder . contains ( ) now uses the same level of storage as ArrayList .. ", "B_clean_title": ["strbuilder", "str", "builder", "contain", "now", "use", "same", "level", "storag", "as", "arraylist", "array", "list"]},
{"A_title": "unexpected typed coverage of less than 100%None", "A_clean_title": ["unexpect", "type", "coverag", "less", "than", "100", "none"], "B_title": "Fix jsDoc parameter definition for function parameters .. ", "B_clean_title": ["fix", "jsdoc", "js", "doc", "paramet", "definit", "function", "paramet"]},
{"A_title": "unexpected typed coverage of less than 100%None", "A_clean_title": ["unexpect", "type", "coverag", "less", "than", "100", "none"], "B_title": "Fix typed scope creator for parameter types .. ", "B_clean_title": ["fix", "type", "scope", "creator", "paramet", "type"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "Fix empty range in TimeSeries. ", "B_clean_title": ["fix", "empti", "rang", "timeseri", "time", "seri"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "Fix an issue with time series end index < startIndex. ", "B_clean_title": ["fix", "issu", "time", "seri", "end", "index", "startindex", "start", "index"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "Fix an issue with TimeSeries . isEmpty ( ) .. ", "B_clean_title": ["fix", "issu", "timeseri", "time", "seri", "isempti", "empti"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "Fix an issue with TimeSeries . isEmptyRange ( ). ", "B_clean_title": ["fix", "issu", "timeseri", "time", "seri", "isemptyrang", "empti", "rang"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "Fix an issue with time series end index < startIndex. ", "B_clean_title": ["fix", "issu", "time", "seri", "end", "index", "startindex", "start", "index"]},
{"A_title": "One of Variance.evaluate() methods does not work correctlyThe method org.apache.commons.math.stat.descriptive.moment.Variance.evaluate(double values double weights double mean int begin int length) does not work properly. Looks loke it ignores the length parameter and grabs the whole dataset. Similar method in Mean class seems to work. I did not check other methods taking the part of the array; they may have the same problem. Workaround: I had to shrink my arrays and use the method without the length.", "A_clean_title": ["one", "varianc", "evalu", "method", "not", "work", "correctlyth", "correctli", "method", "org", "apach", "common", "math", "stat", "descript", "moment", "varianc", "evalu", "doubl", "valu", "doubl", "weight", "doubl", "mean", "int", "begin", "int", "length", "not", "work", "properli", "look", "loke", "it", "ignor", "length", "paramet", "grab", "whole", "dataset", "similar", "method", "mean", "class", "seem", "work", "did", "not", "check", "other", "method", "take", "part", "array", "they", "may", "have", "same", "problem", "workaround", "had", "shrink", "my", "array", "use", "method", "without", "length"], "B_title": "Added missing range in Variance copy constructor. ", "B_clean_title": ["ad", "miss", "rang", "varianc", "copi", "constructor"]},
{"A_title": "One of Variance.evaluate() methods does not work correctlyThe method org.apache.commons.math.stat.descriptive.moment.Variance.evaluate(double values double weights double mean int begin int length) does not work properly. Looks loke it ignores the length parameter and grabs the whole dataset. Similar method in Mean class seems to work. I did not check other methods taking the part of the array; they may have the same problem. Workaround: I had to shrink my arrays and use the method without the length.", "A_clean_title": ["one", "varianc", "evalu", "method", "not", "work", "correctlyth", "correctli", "method", "org", "apach", "common", "math", "stat", "descript", "moment", "varianc", "evalu", "doubl", "valu", "doubl", "weight", "doubl", "mean", "int", "begin", "int", "length", "not", "work", "properli", "look", "loke", "it", "ignor", "length", "paramet", "grab", "whole", "dataset", "similar", "method", "mean", "class", "seem", "work", "did", "not", "check", "other", "method", "take", "part", "array", "they", "may", "have", "same", "problem", "workaround", "had", "shrink", "my", "array", "use", "method", "without", "length"], "B_title": "Fix the for loop. ", "B_clean_title": ["fix", "loop"]},
{"A_title": "StringUtils replaceEach - Bug or Missing DocumentationThe following Test Case for replaceEach fails with a null pointer exception. I have expected that all StringUtils methods are null-friendly The use case is that i will stuff Values into the replacementList of which I do not want to check whether they are null. I admit the use case is not perfect because it is unclear what happens on the replace. I outlined three expectations in the test case of course only one should be met. If it is decided that none of them should be possible I propose to update the documentation with what happens when null is passed as replacement string  import static org.junit.Assert.assertEquals;  import org.apache.commons.lang.StringUtils; import org.junit.Test;   public class StringUtilsTest   @Test public void replaceEach() String original = Hello World!; String searchList = Hello World; String replacementList = Greetings null; String result = StringUtils.replaceEach(original searchList replacementList); assertEquals(Greetings ! result); //perhaps this is ok as well                 //assertEquals(Greetings World! result);                 //or even //assertEquals(Greetings null! result);    ", "A_clean_title": ["stringutil", "string", "util", "replaceeach", "replac", "each", "bug", "or", "miss", "documentationth", "document", "follow", "test", "case", "replaceeach", "replac", "each", "fail", "null", "pointer", "except", "have", "expect", "that", "all", "stringutil", "string", "util", "method", "are", "null", "friendli", "use", "case", "that", "will", "stuff", "valu", "into", "replacementlist", "replac", "list", "which", "not", "want", "check", "whether", "they", "are", "null", "admit", "use", "case", "not", "perfect", "becaus", "it", "unclear", "what", "happen", "replac", "outlin", "three", "expect", "test", "case", "cours", "onli", "one", "met", "it", "decid", "that", "none", "them", "possibl", "propos", "updat", "document", "what", "happen", "when", "null", "pass", "as", "replac", "string", "import", "static", "org", "junit", "assert", "assertequ", "assert", "equal", "import", "org", "apach", "common", "lang", "stringutil", "string", "util", "import", "org", "junit", "test", "public", "class", "stringutilstest", "string", "util", "test", "test", "public", "void", "replaceeach", "replac", "each", "string", "origin", "hello", "world", "string", "searchlist", "search", "list", "hello", "world", "string", "replacementlist", "replac", "list", "greet", "null", "string", "result", "stringutil", "replaceeach", "string", "util", "replac", "each", "origin", "searchlist", "search", "list", "replacementlist", "replac", "list", "assertequ", "assert", "equal", "greet", "result", "perhap", "thi", "ok", "as", "well", "assertequ", "assert", "equal", "greet", "world", "result", "or", "even", "assertequ", "assert", "equal", "greet", "null", "result"], "B_title": "still need more matches in StringUtils. ", "B_clean_title": ["still", "need", "more", "match", "stringutil", "string", "util"]},
{"A_title": "StringUtils replaceEach - Bug or Missing DocumentationThe following Test Case for replaceEach fails with a null pointer exception. I have expected that all StringUtils methods are null-friendly The use case is that i will stuff Values into the replacementList of which I do not want to check whether they are null. I admit the use case is not perfect because it is unclear what happens on the replace. I outlined three expectations in the test case of course only one should be met. If it is decided that none of them should be possible I propose to update the documentation with what happens when null is passed as replacement string  import static org.junit.Assert.assertEquals;  import org.apache.commons.lang.StringUtils; import org.junit.Test;   public class StringUtilsTest   @Test public void replaceEach() String original = Hello World!; String searchList = Hello World; String replacementList = Greetings null; String result = StringUtils.replaceEach(original searchList replacementList); assertEquals(Greetings ! result); //perhaps this is ok as well                 //assertEquals(Greetings World! result);                 //or even //assertEquals(Greetings null! result);    ", "A_clean_title": ["stringutil", "string", "util", "replaceeach", "replac", "each", "bug", "or", "miss", "documentationth", "document", "follow", "test", "case", "replaceeach", "replac", "each", "fail", "null", "pointer", "except", "have", "expect", "that", "all", "stringutil", "string", "util", "method", "are", "null", "friendli", "use", "case", "that", "will", "stuff", "valu", "into", "replacementlist", "replac", "list", "which", "not", "want", "check", "whether", "they", "are", "null", "admit", "use", "case", "not", "perfect", "becaus", "it", "unclear", "what", "happen", "replac", "outlin", "three", "expect", "test", "case", "cours", "onli", "one", "met", "it", "decid", "that", "none", "them", "possibl", "propos", "updat", "document", "what", "happen", "when", "null", "pass", "as", "replac", "string", "import", "static", "org", "junit", "assert", "assertequ", "assert", "equal", "import", "org", "apach", "common", "lang", "stringutil", "string", "util", "import", "org", "junit", "test", "public", "class", "stringutilstest", "string", "util", "test", "test", "public", "void", "replaceeach", "replac", "each", "string", "origin", "hello", "world", "string", "searchlist", "search", "list", "hello", "world", "string", "replacementlist", "replac", "list", "greet", "null", "string", "result", "stringutil", "replaceeach", "string", "util", "replac", "each", "origin", "searchlist", "search", "list", "replacementlist", "replac", "list", "assertequ", "assert", "equal", "greet", "result", "perhap", "thi", "ok", "as", "well", "assertequ", "assert", "equal", "greet", "world", "result", "or", "even", "assertequ", "assert", "equal", "greet", "null", "result"], "B_title": "fix bug. ", "B_clean_title": ["fix", "bug"]},
{"A_title": "GaussianFitter Unexpectedly Throws NotStrictlyPositiveExceptionRunning the following:     double observations =         1.1143831578403364E-29       4.95281403484594E-28       1.1171347211930288E-26       1.7044813962636277E-25       1.9784716574832164E-24       1.8630236407866774E-23       1.4820532905097742E-22       1.0241963854632831E-21       6.275077366673128E-21       3.461808994532493E-20       1.7407124684715706E-19       8.056687953553974E-19       3.460193945992071E-18       1.3883326374011525E-17       5.233894983671116E-17       1.8630791465263745E-16       6.288759227922111E-16       2.0204433920597856E-15       6.198768938576155E-15       1.821419346860626E-14       5.139176445538471E-14       1.3956427429045787E-13       3.655705706448139E-13       9.253753324779779E-13       2.267636001476696E-12       5.3880460095836855E-12       1.2431632654852931E-11       ;     GaussianFitter g =      new GaussianFitter(new LevenbergMarquardtOptimizer());     for (int index = 0; index < 27; index++)          g.addObservedPoint(index observationsindex);             g.fit(); Results in: org.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than or equal to the minimum (0) at org.apache.commons.math.analysis.function.Gaussian Parametric.validateParameters(Gaussian.java:184) at org.apache.commons.math.analysis.function.Gaussian Parametric.value(Gaussian.java:129) Im guessing the initial guess for sigma is off.", "A_clean_title": ["gaussianfitt", "gaussian", "fitter", "unexpectedli", "throw", "notstrictlypositiveexceptionrun", "not", "strictli", "posit", "except", "run", "follow", "doubl", "observ", "29", "1143831578403364e", "28", "95281403484594e", "26", "1171347211930288e", "25", "7044813962636277e", "24", "9784716574832164e", "23", "8630236407866774e", "22", "4820532905097742e", "21", "0241963854632831e", "21", "275077366673128e", "20", "461808994532493e", "19", "7407124684715706e", "19", "056687953553974e", "18", "460193945992071e", "17", "3883326374011525e", "17", "233894983671116e", "16", "8630791465263745e", "16", "288759227922111e", "15", "0204433920597856e", "15", "198768938576155e", "14", "821419346860626e", "14", "139176445538471e", "13", "3956427429045787e", "13", "655705706448139e", "13", "253753324779779e", "12", "267636001476696e", "12", "3880460095836855e", "11", "2431632654852931e", "gaussianfitt", "gaussian", "fitter", "new", "gaussianfitt", "gaussian", "fitter", "new", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "int", "index", "index", "27", "index++", "addobservedpoint", "add", "observ", "point", "index", "observationsindex", "fit", "result", "org", "apach", "common", "math", "except", "notstrictlypositiveexcept", "not", "strictli", "posit", "except", "277", "smaller", "than", "or", "equal", "minimum", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "validateparamet", "valid", "paramet", "gaussian", "java:184", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "valu", "gaussian", "java:129", "im", "guess", "initi", "guess", "sigma", "off"], "B_title": "fit ( ) now uses Gaussian . Parametric ( ). ", "B_clean_title": ["fit", "now", "use", "gaussian", "parametr"]},
{"A_title": "GaussianFitter Unexpectedly Throws NotStrictlyPositiveExceptionRunning the following:     double observations =         1.1143831578403364E-29       4.95281403484594E-28       1.1171347211930288E-26       1.7044813962636277E-25       1.9784716574832164E-24       1.8630236407866774E-23       1.4820532905097742E-22       1.0241963854632831E-21       6.275077366673128E-21       3.461808994532493E-20       1.7407124684715706E-19       8.056687953553974E-19       3.460193945992071E-18       1.3883326374011525E-17       5.233894983671116E-17       1.8630791465263745E-16       6.288759227922111E-16       2.0204433920597856E-15       6.198768938576155E-15       1.821419346860626E-14       5.139176445538471E-14       1.3956427429045787E-13       3.655705706448139E-13       9.253753324779779E-13       2.267636001476696E-12       5.3880460095836855E-12       1.2431632654852931E-11       ;     GaussianFitter g =      new GaussianFitter(new LevenbergMarquardtOptimizer());     for (int index = 0; index < 27; index++)          g.addObservedPoint(index observationsindex);             g.fit(); Results in: org.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than or equal to the minimum (0) at org.apache.commons.math.analysis.function.Gaussian Parametric.validateParameters(Gaussian.java:184) at org.apache.commons.math.analysis.function.Gaussian Parametric.value(Gaussian.java:129) Im guessing the initial guess for sigma is off.", "A_clean_title": ["gaussianfitt", "gaussian", "fitter", "unexpectedli", "throw", "notstrictlypositiveexceptionrun", "not", "strictli", "posit", "except", "run", "follow", "doubl", "observ", "29", "1143831578403364e", "28", "95281403484594e", "26", "1171347211930288e", "25", "7044813962636277e", "24", "9784716574832164e", "23", "8630236407866774e", "22", "4820532905097742e", "21", "0241963854632831e", "21", "275077366673128e", "20", "461808994532493e", "19", "7407124684715706e", "19", "056687953553974e", "18", "460193945992071e", "17", "3883326374011525e", "17", "233894983671116e", "16", "8630791465263745e", "16", "288759227922111e", "15", "0204433920597856e", "15", "198768938576155e", "14", "821419346860626e", "14", "139176445538471e", "13", "3956427429045787e", "13", "655705706448139e", "13", "253753324779779e", "12", "267636001476696e", "12", "3880460095836855e", "11", "2431632654852931e", "gaussianfitt", "gaussian", "fitter", "new", "gaussianfitt", "gaussian", "fitter", "new", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "int", "index", "index", "27", "index++", "addobservedpoint", "add", "observ", "point", "index", "observationsindex", "fit", "result", "org", "apach", "common", "math", "except", "notstrictlypositiveexcept", "not", "strictli", "posit", "except", "277", "smaller", "than", "or", "equal", "minimum", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "validateparamet", "valid", "paramet", "gaussian", "java:184", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "valu", "gaussian", "java:129", "im", "guess", "initi", "guess", "sigma", "off"], "B_title": "GaussianFitter . fit ( ) now uses parameter guesser. ", "B_clean_title": ["gaussianfitt", "gaussian", "fitter", "fit", "now", "use", "paramet", "guesser"]},
{"A_title": "Need range checks for elitismRate in ElitisticListPopulation constructors.There is a range check for setting the elitismRate via ElitisticListPopulations setElitismRate method but not via the constructors.", "A_clean_title": ["need", "rang", "check", "elitismr", "elit", "rate", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "there", "rang", "check", "set", "elitismr", "elit", "rate", "via", "elitisticlistpopul", "elitist", "list", "popul", "setelitismr", "set", "elit", "rate", "method", "but", "not", "via", "constructor"], "B_title": "ElitisticListPopulation can throw exception if elitism rate is too high. ElitisticListPopulation ( ) throws outOfRangeException if elitismRate is not 1 .. ", "B_clean_title": ["elitisticlistpopul", "elitist", "list", "popul", "throw", "except", "elit", "rate", "too", "high", "elitisticlistpopul", "elitist", "list", "popul", "throw", "outofrangeexcept", "out", "rang", "except", "elitismr", "elit", "rate", "not"]},
{"A_title": "Need range checks for elitismRate in ElitisticListPopulation constructors.There is a range check for setting the elitismRate via ElitisticListPopulations setElitismRate method but not via the constructors.", "A_clean_title": ["need", "rang", "check", "elitismr", "elit", "rate", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "there", "rang", "check", "set", "elitismr", "elit", "rate", "via", "elitisticlistpopul", "elitist", "list", "popul", "setelitismr", "set", "elit", "rate", "method", "but", "not", "via", "constructor"], "B_title": "added fix .. ElitisticListPopulation constructor should set the elitism rate before setting the population .. ", "B_clean_title": ["ad", "fix", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "set", "elit", "rate", "befor", "set", "popul"]},
{"A_title": "Need range checks for elitismRate in ElitisticListPopulation constructors.There is a range check for setting the elitismRate via ElitisticListPopulations setElitismRate method but not via the constructors.", "A_clean_title": ["need", "rang", "check", "elitismr", "elit", "rate", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "there", "rang", "check", "set", "elitismr", "elit", "rate", "via", "elitisticlistpopul", "elitist", "list", "popul", "setelitismr", "set", "elit", "rate", "method", "but", "not", "via", "constructor"], "B_title": "Missing license header. ElitisticListPopulation can throw exception if elitismRate is not 1 . 0. ElitisticListPopulation constructor should throw exception if elitismRate is not 1 . 0. ", "B_clean_title": ["miss", "licens", "header", "elitisticlistpopul", "elitist", "list", "popul", "throw", "except", "elitismr", "elit", "rate", "not", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "throw", "except", "elitismr", "elit", "rate", "not"]},
{"A_title": "Need range checks for elitismRate in ElitisticListPopulation constructors.There is a range check for setting the elitismRate via ElitisticListPopulations setElitismRate method but not via the constructors.", "A_clean_title": ["need", "rang", "check", "elitismr", "elit", "rate", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "there", "rang", "check", "set", "elitismr", "elit", "rate", "via", "elitisticlistpopul", "elitist", "list", "popul", "setelitismr", "set", "elit", "rate", "method", "but", "not", "via", "constructor"], "B_title": "Add a exception check. Add a exception check. ", "B_clean_title": ["add", "except", "check", "add", "except", "check"]},
{"A_title": "MathUtils.factorial(n) fails for n >= 17The result of MathUtils.factorial( n ) for n = 17 18 19 is wrong probably because of rounding errors in the double calculations. Replace the first line of MathUtilsTest.testFactorial() by         for (int i = 1; i <= 20; i++)  to check all valid arguments for the long result and see the failure. I suggest implementing a simple loop to multiply the long result - or even using a precomputed long - instead of adding logarithms.", "A_clean_title": ["mathutil", "factori", "math", "util", "fail", "17the", "result", "mathutil", "factori", "math", "util", "17", "18", "19", "wrong", "probabl", "becaus", "round", "error", "doubl", "calcul", "replac", "first", "line", "mathutilstest", "testfactori", "math", "util", "test", "test", "factori", "by", "int", "20", "i++", "check", "all", "valid", "argument", "long", "result", "see", "failur", "suggest", "implement", "simpl", "loop", "multipli", "long", "result", "or", "even", "precomput", "long", "instead", "ad", "logarithm"], "B_title": "Added patch method for MathUtils .. Added patch_method ( ) for n = 20 . 0 .. ", "B_clean_title": ["ad", "patch", "method", "mathutil", "math", "util", "ad", "patch", "method", "20"]},
{"A_title": "ODE integrator goes past specified end of integration rangeEnd of integration range in ODE solving is handled as an event. In some cases numerical accuracy in events detection leads to error in events location. The following test case shows the end event is not handled properly and an integration that should cover a 60s range in fact covers a 160s range more than twice the specified range.    public void testMissedEvent() throws IntegratorException DerivativeException            final double t0 = 1878250320.0000029;           final double t =  1878250379.9999986;           FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations()                           public int getDimension()                  return 1;                                       public void computeDerivatives(double t double y double yDot)                 throws DerivativeException                  yDot0 = y0 * 1.0e-6;                      ;          DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0 100.0                                                                                1.0e-10 1.0e-10);          double y =  1.0 ;         integrator.setInitialStepSize(60.0);         double finalT = integrator.integrate(ode t0 y t y);         Assert.assertEquals(t finalT 1.0e-6);     ", "A_clean_title": ["ode", "integr", "goe", "past", "specifi", "end", "integr", "rangeend", "rang", "end", "integr", "rang", "ode", "solv", "handl", "as", "event", "some", "case", "numer", "accuraci", "event", "detect", "lead", "error", "event", "locat", "follow", "test", "case", "show", "end", "event", "not", "handl", "properli", "integr", "that", "cover", "60", "rang", "fact", "cover", "160", "rang", "more", "than", "twice", "specifi", "rang", "public", "void", "testmissedev", "test", "miss", "event", "throw", "integratorexcept", "integr", "except", "derivativeexcept", "deriv", "except", "final", "doubl", "t0", "1878250320", "0000029", "final", "doubl", "1878250379", "9999986", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "ode", "new", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "public", "int", "getdimens", "get", "dimens", "return", "public", "void", "computederiv", "comput", "deriv", "doubl", "doubl", "doubl", "ydot", "dot", "throw", "derivativeexcept", "deriv", "except", "ydot0", "dot0", "y0", "0e", "dormandprince853integr", "dormand", "prince853integr", "integr", "new", "dormandprince853integr", "dormand", "prince853integr", "100", "10", "0e", "10", "0e", "doubl", "integr", "setinitialsteps", "set", "initi", "step", "size", "60", "doubl", "finalt", "final", "integr", "integr", "ode", "t0", "assert", "assertequ", "assert", "equal", "finalt", "final", "0e"], "B_title": "Fix the artificial 0 size step for EmbeddedRungeKuttaIntegator .. Fix the nonstiff test .. ", "B_clean_title": ["fix", "artifici", "size", "step", "embeddedrungekuttainteg", "embed", "rung", "kutta", "integ", "fix", "nonstiff", "test"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));   ", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Reset timeZone on parse ( ) .. ", "B_clean_title": ["reset", "timezon", "time", "zone", "pars"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));   ", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Fixed formatting of date with timeZone. ", "B_clean_title": ["fix", "format", "date", "timezon", "time", "zone"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));   ", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Reset the calendar time to GMT on Sunday .. ", "B_clean_title": ["reset", "calendar", "time", "gmt", "sunday"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));   ", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Fix null pointer check in FastDateFormat. ", "B_clean_title": ["fix", "null", "pointer", "check", "fastdateformat", "fast", "date", "format"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));   ", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Fix null pointer check in FastDateFormat. ", "B_clean_title": ["fix", "null", "pointer", "check", "fastdateformat", "fast", "date", "format"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "Fix NPE triggered by nullability exception. ", "B_clean_title": ["fix", "npe", "trigger", "by", "nullabl", "except"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed null check. ", "B_clean_title": ["remov", "null", "check"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed null check. ", "B_clean_title": ["remov", "null", "check"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "added null check in Hercules . fixed. null check in Hercules for fixed. fix null pointer check. ", "B_clean_title": ["ad", "null", "check", "hercul", "fix", "null", "check", "hercul", "fix", "fix", "null", "pointer", "check"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed null check. ", "B_clean_title": ["remov", "null", "check"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed unnecessary loop. ", "B_clean_title": ["remov", "unnecessari", "loop"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed unnecessary copy of ClassUtils. ", "B_clean_title": ["remov", "unnecessari", "copi", "classutil", "class", "util"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed null check. ", "B_clean_title": ["remov", "null", "check"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed null check. ", "B_clean_title": ["remov", "null", "check"]},
{"A_title": "side-effects analysis incorrectly removing function calls with side effectsNone", "A_clean_title": ["side", "effect", "analysi", "incorrectli", "remov", "function", "call", "side", "effectsnon", "effect", "none"], "B_title": "Updated lookahead for the NEW value keyword. ", "B_clean_title": ["updat", "lookahead", "new", "valu", "keyword"]},
{"A_title": "side-effects analysis incorrectly removing function calls with side effectsNone", "A_clean_title": ["side", "effect", "analysi", "incorrectli", "remov", "function", "call", "side", "effectsnon", "effect", "none"], "B_title": "fix broken patch. ", "B_clean_title": ["fix", "broken", "patch"]},
{"A_title": "MultivariateNormalDistribution.density(double) returns wrong value when the dimension is oddTo reproduce:  Assert.assertEquals(0.398942280401433 new MultivariateNormalDistribution(new double0 new double1).density(new double0) 1e-15);", "A_clean_title": ["multivariatenormaldistribut", "densiti", "multivari", "normal", "distribut", "doubl", "return", "wrong", "valu", "when", "dimens", "oddto", "odd", "reproduc", "assert", "assertequ", "assert", "equal", "398942280401433", "new", "multivariatenormaldistribut", "multivari", "normal", "distribut", "new", "double0", "new", "double1", "densiti", "new", "double0", "1e", "15"], "B_title": "Fix MultivariateNormalDistribution precision thingie in 1 . 6 . 2. ", "B_clean_title": ["fix", "multivariatenormaldistribut", "multivari", "normal", "distribut", "precis", "thingi"]},
{"A_title": "ListPopulation Iterator allows you to remove chromosomes from the population.Calling the iterator method of ListPopulation returns an iterator of the protected modifiable list. Before returning the iterator we should wrap it in an unmodifiable list.", "A_clean_title": ["listpopul", "list", "popul", "iter", "allow", "you", "remov", "chromosom", "popul", "call", "iter", "method", "listpopul", "list", "popul", "return", "iter", "protect", "modifi", "list", "befor", "return", "iter", "we", "wrap", "it", "unmodifi", "list"], "B_title": "Fix ListPopulation . iterator ( ). ", "B_clean_title": ["fix", "listpopul", "list", "popul", "iter"]},
{"A_title": "ListPopulation Iterator allows you to remove chromosomes from the population.Calling the iterator method of ListPopulation returns an iterator of the protected modifiable list. Before returning the iterator we should wrap it in an unmodifiable list.", "A_clean_title": ["listpopul", "list", "popul", "iter", "allow", "you", "remov", "chromosom", "popul", "call", "iter", "method", "listpopul", "list", "popul", "return", "iter", "protect", "modifi", "list", "befor", "return", "iter", "we", "wrap", "it", "unmodifi", "list"], "B_title": "Fix # 12. ", "B_clean_title": ["fix", "12"]},
{"A_title": "ListPopulation Iterator allows you to remove chromosomes from the population.Calling the iterator method of ListPopulation returns an iterator of the protected modifiable list. Before returning the iterator we should wrap it in an unmodifiable list.", "A_clean_title": ["listpopul", "list", "popul", "iter", "allow", "you", "remov", "chromosom", "popul", "call", "iter", "method", "listpopul", "list", "popul", "return", "iter", "protect", "modifi", "list", "befor", "return", "iter", "we", "wrap", "it", "unmodifi", "list"], "B_title": "added iterator on non - empty chromosomes list. ", "B_clean_title": ["ad", "iter", "non", "empti", "chromosom", "list"]},
{"A_title": "ExtendedMessageFormat: OutOfMemory with custom format registry and a pattern containing single quotesWhen using ExtendedMessageFormat with a custom format registry and a pattern conatining single quotes an OutOfMemoryError will occur. Example that will cause error: ExtendedMessageFormatTest.java  private static Map<String Object> formatRegistry = new HashMap<String Object>();         static          formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT new DummyFormatFactory());               public static void main(String args)          ExtendedMessageFormat mf = new ExtendedMessageFormat(its a dummy test! formatRegistry);         String formattedPattern = mf.format(new String great);         System.out.println(formattedPattern);          The following change starting at line 421 on the 2.4 release seems to fix the problem: ExtendedMessageFormat.java CURRENT (Broken): if (escapingOn && cstart == QUOTE)          return appendTo == null ? null : appendTo.append(QUOTE);   WORKING: if (escapingOn && cstart == QUOTE)          next(pos);         return appendTo == null ? null : appendTo.append(QUOTE); ", "A_clean_title": ["extendedmessageformat", "extend", "messag", "format", "outofmemori", "out", "memori", "custom", "format", "registri", "pattern", "contain", "singl", "quoteswhen", "quot", "when", "extendedmessageformat", "extend", "messag", "format", "custom", "format", "registri", "pattern", "conatin", "singl", "quot", "outofmemoryerror", "out", "memori", "error", "will", "occur", "exampl", "that", "will", "caus", "error", "extendedmessageformattest", "java", "extend", "messag", "format", "test", "privat", "static", "map", "string", "object", "formatregistri", "format", "registri", "new", "hashmap", "hash", "map", "string", "object", "static", "formatregistri", "put", "format", "registri", "dummyformatfactori", "dummi", "format", "factori", "dummi", "format", "new", "dummyformatfactori", "dummi", "format", "factori", "public", "static", "void", "main", "string", "arg", "extendedmessageformat", "extend", "messag", "format", "mf", "new", "extendedmessageformat", "extend", "messag", "format", "it", "dummi", "test", "formatregistri", "format", "registri", "string", "formattedpattern", "format", "pattern", "mf", "format", "new", "string", "great", "system", "out", "println", "formattedpattern", "format", "pattern", "follow", "chang", "start", "at", "line", "421", "releas", "seem", "fix", "problem", "extendedmessageformat", "java", "extend", "messag", "format", "current", "broken", "escapingon", "escap", "cstart", "quot", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot", "work", "escapingon", "escap", "cstart", "quot", "next", "po", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot"], "B_title": "don  t append QUOTE if escaping is on. ", "B_clean_title": ["don", "append", "quot", "escap"]},
{"A_title": "ExtendedMessageFormat: OutOfMemory with custom format registry and a pattern containing single quotesWhen using ExtendedMessageFormat with a custom format registry and a pattern conatining single quotes an OutOfMemoryError will occur. Example that will cause error: ExtendedMessageFormatTest.java  private static Map<String Object> formatRegistry = new HashMap<String Object>();         static          formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT new DummyFormatFactory());               public static void main(String args)          ExtendedMessageFormat mf = new ExtendedMessageFormat(its a dummy test! formatRegistry);         String formattedPattern = mf.format(new String great);         System.out.println(formattedPattern);          The following change starting at line 421 on the 2.4 release seems to fix the problem: ExtendedMessageFormat.java CURRENT (Broken): if (escapingOn && cstart == QUOTE)          return appendTo == null ? null : appendTo.append(QUOTE);   WORKING: if (escapingOn && cstart == QUOTE)          next(pos);         return appendTo == null ? null : appendTo.append(QUOTE); ", "A_clean_title": ["extendedmessageformat", "extend", "messag", "format", "outofmemori", "out", "memori", "custom", "format", "registri", "pattern", "contain", "singl", "quoteswhen", "quot", "when", "extendedmessageformat", "extend", "messag", "format", "custom", "format", "registri", "pattern", "conatin", "singl", "quot", "outofmemoryerror", "out", "memori", "error", "will", "occur", "exampl", "that", "will", "caus", "error", "extendedmessageformattest", "java", "extend", "messag", "format", "test", "privat", "static", "map", "string", "object", "formatregistri", "format", "registri", "new", "hashmap", "hash", "map", "string", "object", "static", "formatregistri", "put", "format", "registri", "dummyformatfactori", "dummi", "format", "factori", "dummi", "format", "new", "dummyformatfactori", "dummi", "format", "factori", "public", "static", "void", "main", "string", "arg", "extendedmessageformat", "extend", "messag", "format", "mf", "new", "extendedmessageformat", "extend", "messag", "format", "it", "dummi", "test", "formatregistri", "format", "registri", "string", "formattedpattern", "format", "pattern", "mf", "format", "new", "string", "great", "system", "out", "println", "formattedpattern", "format", "pattern", "follow", "chang", "start", "at", "line", "421", "releas", "seem", "fix", "problem", "extendedmessageformat", "java", "extend", "messag", "format", "current", "broken", "escapingon", "escap", "cstart", "quot", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot", "work", "escapingon", "escap", "cstart", "quot", "next", "po", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot"], "B_title": "Fix format. ", "B_clean_title": ["fix", "format"]},
{"A_title": "bug with implicit namespaces across modulesNone", "A_clean_title": ["bug", "implicit", "namespac", "across", "modulesnon", "modul", "none"], "B_title": "Fix up whitespace. ", "B_clean_title": ["fix", "up", "whitespac"]},
{"A_title": "NumberUtils does not handle upper-case hex: 0X and -0XNumberUtils.createNumber() should work equally for 0x1234 and 0X1234; currently 0X1234 generates a NumberFormatException Integer.decode() handles both upper and lower case hex.", "A_clean_title": ["numberutil", "number", "util", "not", "handl", "upper", "case", "hex", "0x", "0xnumberutil", "createnumb", "0x", "number", "util", "creat", "number", "work", "equal", "0x1234", "0x1234", "current", "0x1234", "gener", "numberformatexcept", "number", "format", "except", "integ", "decod", "handl", "both", "upper", "lower", "case", "hex"], "B_title": "convert string to lower case since it  s a number. ", "B_clean_title": ["convert", "string", "lower", "case", "sinc", "it", "number"]},
{"A_title": "Fraction percentageValue rare overflowThe percentageValue() method of the Fraction class works by first multiplying the Fraction by 100 then converting the Fraction to a double. This causes overflows when the numerator is greater than Integer.MAX_VALUE/100 even when the value of the fraction is far below this value. The patch changes the method to first convert to a double value and then multiply this value by 100 - the result should be the same but with less overflows. An addition to the test for the method that covers this bug is also included.", "A_clean_title": ["fraction", "percentagevalu", "percentag", "valu", "rare", "overflowth", "overflow", "percentagevalu", "percentag", "valu", "method", "fraction", "class", "work", "by", "first", "multipli", "fraction", "by", "100", "then", "convert", "fraction", "doubl", "thi", "caus", "overflow", "when", "numer", "greater", "than", "integ", "max", "valu", "100", "even", "when", "valu", "fraction", "far", "below", "thi", "valu", "patch", "chang", "method", "first", "convert", "doubl", "valu", "then", "multipli", "thi", "valu", "by", "100", "result", "same", "but", "less", "overflow", "addit", "test", "method", "that", "cover", "thi", "bug", "also", "includ"], "B_title": "Added Fraction copy of Fraction . percentageValue ( ). ", "B_clean_title": ["ad", "fraction", "copi", "fraction", "percentagevalu", "percentag", "valu"]},
{"A_title": "NumberUtils.createNumber throws NumberFormatException for one digit longNumberUtils.createNumber throws a NumberFormatException when parsing 1l 2l .. etc... It works fine if you try to parse 01l or 02l.  The condition isDigits(numeric.substring(1)) line 455 return false as numeric.substring(1) is an empty string for 1l", "A_clean_title": ["numberutil", "createnumb", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "one", "digit", "longnumberutil", "createnumb", "long", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "when", "pars", "1l", "2l", "etc", "it", "work", "fine", "you", "tri", "pars", "01l", "or", "02l", "condit", "isdigit", "digit", "numer", "substr", "line", "455", "return", "fals", "as", "numer", "substr", "empti", "string", "1l"], "B_title": "Fix NumberFormatException. ", "B_clean_title": ["fix", "numberformatexcept", "number", "format", "except"]},
{"A_title": "NumberUtils.createNumber throws NumberFormatException for one digit longNumberUtils.createNumber throws a NumberFormatException when parsing 1l 2l .. etc... It works fine if you try to parse 01l or 02l.  The condition isDigits(numeric.substring(1)) line 455 return false as numeric.substring(1) is an empty string for 1l", "A_clean_title": ["numberutil", "createnumb", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "one", "digit", "longnumberutil", "createnumb", "long", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "when", "pars", "1l", "2l", "etc", "it", "work", "fine", "you", "tri", "pars", "01l", "or", "02l", "condit", "isdigit", "digit", "numer", "substr", "line", "455", "return", "fals", "as", "numer", "substr", "empti", "string", "1l"], "B_title": "Fix parse error ( l - > long ). ", "B_clean_title": ["fix", "pars", "error", "long"]},
{"A_title": "weight versus sigma in AbstractLeastSquaresIn AbstractLeastSquares residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS() these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation it should multiply the square of the residual even in the computation of the chi2.  Once corrected getRMS() can even reduce  public double getRMS()  return Math.sqrt(getChiSquare()/rows);", "A_clean_title": ["weight", "versu", "sigma", "abstractleastsquaresin", "abstract", "least", "squar", "abstractleastsquar", "abstract", "least", "squar", "residualsweight", "residu", "weight", "contain", "weight", "assign", "each", "observ", "method", "getrm", "get", "rm", "these", "weight", "are", "multipl", "as", "they", "unlik", "getchisquar", "get", "chi", "squar", "where", "it", "appear", "at", "denomin", "weight", "realli", "weight", "observ", "it", "multipli", "squar", "residu", "even", "comput", "chi2", "onc", "correct", "getrm", "get", "rm", "even", "reduc", "public", "doubl", "getrm", "get", "rm", "return", "math", "sqrt", "getchisquar", "get", "chi", "squar", "row"], "B_title": "Fix residualsWeights .. ", "B_clean_title": ["fix", "residualsweight", "residu", "weight"]},
{"A_title": "weight versus sigma in AbstractLeastSquaresIn AbstractLeastSquares residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS() these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation it should multiply the square of the residual even in the computation of the chi2.  Once corrected getRMS() can even reduce  public double getRMS()  return Math.sqrt(getChiSquare()/rows);", "A_clean_title": ["weight", "versu", "sigma", "abstractleastsquaresin", "abstract", "least", "squar", "abstractleastsquar", "abstract", "least", "squar", "residualsweight", "residu", "weight", "contain", "weight", "assign", "each", "observ", "method", "getrm", "get", "rm", "these", "weight", "are", "multipl", "as", "they", "unlik", "getchisquar", "get", "chi", "squar", "where", "it", "appear", "at", "denomin", "weight", "realli", "weight", "observ", "it", "multipli", "squar", "residu", "even", "comput", "chi2", "onc", "correct", "getrm", "get", "rm", "even", "reduc", "public", "doubl", "getrm", "get", "rm", "return", "math", "sqrt", "getchisquar", "get", "chi", "squar", "row"], "B_title": "Fix ColorConvertor .. ", "B_clean_title": ["fix", "colorconvertor", "color", "convertor"]},
{"A_title": "In stat.Frequency getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable)Drop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change Frequency.java    /**  Returns the percentage of values that are equal to v @deprecated replaced by  @link #getPct(Comparable)  as of 2.0      */     @Deprecated     public double getPct(Object v)           return getCumPct((Comparable<?>) v);     ", "A_clean_title": ["stat", "frequenc", "getpct", "get", "pct", "object", "use", "getcumpct", "get", "cum", "pct", "compar", "instead", "getpct", "get", "pct", "compar", "drop", "replac", "not", "possibl", "becaus", "all", "getpct", "get", "pct", "call", "will", "cummul", "without", "code", "chang", "frequenc", "java", "return", "percentag", "valu", "that", "are", "equal", "deprec", "replac", "by", "link", "getpct", "get", "pct", "compar", "as", "deprec", "public", "doubl", "getpct", "get", "pct", "object", "return", "getcumpct", "get", "cum", "pct", "compar"], "B_title": "Fix an issue with getPct that was being too verbose .. ", "B_clean_title": ["fix", "issu", "getpct", "get", "pct", "that", "wa", "be", "too", "verbos"]},
{"A_title": "In stat.Frequency getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable)Drop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change Frequency.java    /**  Returns the percentage of values that are equal to v @deprecated replaced by  @link #getPct(Comparable)  as of 2.0      */     @Deprecated     public double getPct(Object v)           return getCumPct((Comparable<?>) v);     ", "A_clean_title": ["stat", "frequenc", "getpct", "get", "pct", "object", "use", "getcumpct", "get", "cum", "pct", "compar", "instead", "getpct", "get", "pct", "compar", "drop", "replac", "not", "possibl", "becaus", "all", "getpct", "get", "pct", "call", "will", "cummul", "without", "code", "chang", "frequenc", "java", "return", "percentag", "valu", "that", "are", "equal", "deprec", "replac", "by", "link", "getpct", "get", "pct", "compar", "as", "deprec", "public", "doubl", "getpct", "get", "pct", "object", "return", "getcumpct", "get", "cum", "pct", "compar"], "B_title": "Fix getOwnPct return type. ", "B_clean_title": ["fix", "getownpct", "get", "own", "pct", "return", "type"]},
{"A_title": "In stat.Frequency getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable)Drop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change Frequency.java    /**  Returns the percentage of values that are equal to v @deprecated replaced by  @link #getPct(Comparable)  as of 2.0      */     @Deprecated     public double getPct(Object v)           return getCumPct((Comparable<?>) v);     ", "A_clean_title": ["stat", "frequenc", "getpct", "get", "pct", "object", "use", "getcumpct", "get", "cum", "pct", "compar", "instead", "getpct", "get", "pct", "compar", "drop", "replac", "not", "possibl", "becaus", "all", "getpct", "get", "pct", "call", "will", "cummul", "without", "code", "chang", "frequenc", "java", "return", "percentag", "valu", "that", "are", "equal", "deprec", "replac", "by", "link", "getpct", "get", "pct", "compar", "as", "deprec", "public", "doubl", "getpct", "get", "pct", "object", "return", "getcumpct", "get", "cum", "pct", "compar"], "B_title": "Fix getFrequency ( Object ) to return precise value instead of getCumPct ( Object ). ", "B_clean_title": ["fix", "getfrequ", "get", "frequenc", "object", "return", "precis", "valu", "instead", "getcumpct", "get", "cum", "pct", "object"]},
{"A_title": "In stat.Frequency getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable)Drop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change Frequency.java    /**  Returns the percentage of values that are equal to v @deprecated replaced by  @link #getPct(Comparable)  as of 2.0      */     @Deprecated     public double getPct(Object v)           return getCumPct((Comparable<?>) v);     ", "A_clean_title": ["stat", "frequenc", "getpct", "get", "pct", "object", "use", "getcumpct", "get", "cum", "pct", "compar", "instead", "getpct", "get", "pct", "compar", "drop", "replac", "not", "possibl", "becaus", "all", "getpct", "get", "pct", "call", "will", "cummul", "without", "code", "chang", "frequenc", "java", "return", "percentag", "valu", "that", "are", "equal", "deprec", "replac", "by", "link", "getpct", "get", "pct", "compar", "as", "deprec", "public", "doubl", "getpct", "get", "pct", "object", "return", "getcumpct", "get", "cum", "pct", "compar"], "B_title": "Add missing import .. Fix getFrequency ( Object ) to return 1  not 2. ", "B_clean_title": ["add", "miss", "import", "fix", "getfrequ", "get", "frequenc", "object", "return", "not"]},
{"A_title": "org.apache.commons.lang3.math.Fraction does not reduce (Integer.MIN_VALUE 2^k)The greatestCommonDivisor method in class Fraction does not find the gcd of Integer.MIN_VALUE and 2^k and this case can be triggered by taking Integer.MIN_VALUE as the numerator. Note that the case of taking Integer.MIN_VALUE as the denominator is handled explicitly in the getReducedFraction factory method. FractionTest.java // additional test cases public void testReducedFactory_int_int()  // ... f = Fraction.getReducedFraction(Integer.MIN_VALUE 2); assertEquals(Integer.MIN_VALUE / 2 f.getNumerator()); assertEquals(1 f.getDenominator());  public void testReduce()  // ... f = Fraction.getFraction(Integer.MIN_VALUE 2); result = f.reduce(); assertEquals(Integer.MIN_VALUE / 2 result.getNumerator()); assertEquals(1 result.getDenominator());", "A_clean_title": ["org", "apach", "common", "lang3", "math", "fraction", "not", "reduc", "integ", "min", "valu", "2^k", "greatestcommondivisor", "greatest", "common", "divisor", "method", "class", "fraction", "not", "find", "gcd", "integ", "min", "valu", "2^k", "thi", "case", "trigger", "by", "take", "integ", "min", "valu", "as", "numer", "note", "that", "case", "take", "integ", "min", "valu", "as", "denomin", "handl", "explicitli", "getreducedfract", "get", "reduc", "fraction", "factori", "method", "fractiontest", "java", "fraction", "test", "addit", "test", "case", "public", "void", "testreducedfactori", "int", "int", "test", "reduc", "factori", "fraction", "getreducedfract", "get", "reduc", "fraction", "integ", "min", "valu", "assertequ", "assert", "equal", "integ", "min", "valu", "getnumer", "get", "numer", "assertequ", "assert", "equal", "getdenomin", "get", "denomin", "public", "void", "testreduc", "test", "reduc", "fraction", "getfract", "get", "fraction", "integ", "min", "valu", "result", "reduc", "assertequ", "assert", "equal", "integ", "min", "valu", "result", "getnumer", "get", "numer", "assertequ", "assert", "equal", "result", "getdenomin", "get", "denomin"], "B_title": "Fix Fraction . greatestCommonDivisor ( ). ", "B_clean_title": ["fix", "fraction", "greatestcommondivisor", "greatest", "common", "divisor"]},
{"A_title": "org.apache.commons.lang3.math.Fraction does not reduce (Integer.MIN_VALUE 2^k)The greatestCommonDivisor method in class Fraction does not find the gcd of Integer.MIN_VALUE and 2^k and this case can be triggered by taking Integer.MIN_VALUE as the numerator. Note that the case of taking Integer.MIN_VALUE as the denominator is handled explicitly in the getReducedFraction factory method. FractionTest.java // additional test cases public void testReducedFactory_int_int()  // ... f = Fraction.getReducedFraction(Integer.MIN_VALUE 2); assertEquals(Integer.MIN_VALUE / 2 f.getNumerator()); assertEquals(1 f.getDenominator());  public void testReduce()  // ... f = Fraction.getFraction(Integer.MIN_VALUE 2); result = f.reduce(); assertEquals(Integer.MIN_VALUE / 2 result.getNumerator()); assertEquals(1 result.getDenominator());", "A_clean_title": ["org", "apach", "common", "lang3", "math", "fraction", "not", "reduc", "integ", "min", "valu", "2^k", "greatestcommondivisor", "greatest", "common", "divisor", "method", "class", "fraction", "not", "find", "gcd", "integ", "min", "valu", "2^k", "thi", "case", "trigger", "by", "take", "integ", "min", "valu", "as", "numer", "note", "that", "case", "take", "integ", "min", "valu", "as", "denomin", "handl", "explicitli", "getreducedfract", "get", "reduc", "fraction", "factori", "method", "fractiontest", "java", "fraction", "test", "addit", "test", "case", "public", "void", "testreducedfactori", "int", "int", "test", "reduc", "factori", "fraction", "getreducedfract", "get", "reduc", "fraction", "integ", "min", "valu", "assertequ", "assert", "equal", "integ", "min", "valu", "getnumer", "get", "numer", "assertequ", "assert", "equal", "getdenomin", "get", "denomin", "public", "void", "testreduc", "test", "reduc", "fraction", "getfract", "get", "fraction", "integ", "min", "valu", "result", "reduc", "assertequ", "assert", "equal", "integ", "min", "valu", "result", "getnumer", "get", "numer", "assertequ", "assert", "equal", "result", "getdenomin", "get", "denomin"], "B_title": "Fix greatestCommonDivisor in Fraction copy. ", "B_clean_title": ["fix", "greatestcommondivisor", "greatest", "common", "divisor", "fraction", "copi"]},
{"A_title": "HarmonicFitter.ParameterGuesser sometimes fails to return sensible valuesThe inner class ParameterGuesser in HarmonicFitter (package o.a.c.m.optimization.fitting) fails to compute a usable guess for the amplitude parameter.", "A_clean_title": ["harmonicfitt", "parameterguess", "harmon", "fitter", "paramet", "guesser", "sometim", "fail", "return", "sensibl", "valuesth", "valu", "inner", "class", "parameterguess", "paramet", "guesser", "harmonicfitt", "harmon", "fitter", "packag", "optim", "fit", "fail", "comput", "usabl", "guess", "amplitud", "paramet"], "B_title": "Added throw if c2 == 0 . 0 to HarmonicFitter . java. ", "B_clean_title": ["ad", "throw", "c2", "harmonicfitt", "harmon", "fitter", "java"]},
{"A_title": "HarmonicFitter.ParameterGuesser sometimes fails to return sensible valuesThe inner class ParameterGuesser in HarmonicFitter (package o.a.c.m.optimization.fitting) fails to compute a usable guess for the amplitude parameter.", "A_clean_title": ["harmonicfitt", "parameterguess", "harmon", "fitter", "paramet", "guesser", "sometim", "fail", "return", "sensibl", "valuesth", "valu", "inner", "class", "parameterguess", "paramet", "guesser", "harmonicfitt", "harmon", "fitter", "packag", "optim", "fit", "fail", "comput", "usabl", "guess", "amplitud", "paramet"], "B_title": "Add a throw if the pair of arguments are not compatible with 1 . 0 .. ", "B_clean_title": ["add", "throw", "pair", "argument", "are", "not", "compat"]},
{"A_title": "Constructor types that return all or unknown fail to parseNone", "A_clean_title": ["constructor", "type", "that", "return", "all", "or", "unknown", "fail", "parsenon", "pars", "none"], "B_title": "updated hercules patch. ", "B_clean_title": ["updat", "hercul", "patch"]},
{"A_title": "Bug in method appendFixedWidthPadRight of class StrBuilder causes an ArrayIndexOutOfBoundsExceptionTheres a bug in method appendFixedWidthPadRight of class StrBuilder: public StrBuilder appendFixedWidthPadRight(Object obj int width char padChar)          if (width > 0)              ensureCapacity(size + width);             String str = (obj == null ? getNullText() : obj.toString());             int strLen = str.length();             if (strLen >= width)    ==>            str.getChars(0 strLen buffer size);   <==== BUG: it should be str.getChars(0 width buffer size);               else                  int padLen = width - strLen;                 str.getChars(0 strLen buffer size);                 for (int i = 0; i < padLen; i++)                       buffersize + strLen + i = padChar;                                           size += width;                  return this;      This is causing an ArrayIndexOutOfBoundsException so this method is unusable when strLen > width. Its counterpart method appendFixedWidthPadLeft seems to be ok.", "A_clean_title": ["bug", "method", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "class", "strbuilder", "str", "builder", "caus", "arrayindexoutofboundsexceptionther", "array", "index", "out", "bound", "except", "there", "bug", "method", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "class", "strbuilder", "str", "builder", "public", "strbuilder", "str", "builder", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "object", "obj", "int", "width", "char", "padchar", "pad", "char", "width", "ensurecapac", "ensur", "capac", "size", "width", "string", "str", "obj", "null", "getnulltext", "get", "null", "text", "obj", "tostr", "string", "int", "strlen", "str", "len", "str", "length", "strlen", "str", "len", "width", "str", "getchar", "get", "char", "strlen", "str", "len", "buffer", "size", "bug", "it", "str", "getchar", "get", "char", "width", "buffer", "size", "int", "padlen", "pad", "len", "width", "strlen", "str", "len", "str", "getchar", "get", "char", "strlen", "str", "len", "buffer", "size", "int", "padlen", "pad", "len", "i++", "buffers", "strlen", "str", "len", "padchar", "pad", "char", "size", "width", "return", "thi", "thi", "caus", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "so", "thi", "method", "unus", "when", "strlen", "str", "len", "width", "it", "counterpart", "method", "appendfixedwidthpadleft", "append", "fix", "width", "pad", "left", "seem", "ok"], "B_title": "Removed reverseEach method from XmlConverterTest. ", "B_clean_title": ["remov", "reverseeach", "revers", "each", "method", "xmlconvertertest", "xml", "convert", "test"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "reduce error in SimplexTableau. ", "B_clean_title": ["reduc", "error", "simplextableau", "simplex", "tableau"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "Removing epsilon from tableau test .. ", "B_clean_title": ["remov", "epsilon", "tableau", "test"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "Using the copy of SimplexTableau  it is better for testing. ", "B_clean_title": ["copi", "simplextableau", "simplex", "tableau", "it", "better", "test"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "Updated patch1 - Math - 33 - Hercules . fixed. ", "B_clean_title": ["updat", "patch1", "math", "33", "hercul", "fix"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "Fix missing import. reduce maxUlps to epsilon. ", "B_clean_title": ["fix", "miss", "import", "reduc", "maxulp", "max", "ulp", "epsilon"]},
{"A_title": "BrentOptimizer not always reporting the best pointBrentOptimizer (package o.a.c.m.optimization.univariate) does not check that the point it is going to return is indeed the best one it has encountered. Indeed the last evaluated point might be slightly worse than the one before last.", "A_clean_title": ["brentoptim", "brent", "optim", "not", "alway", "report", "best", "pointbrentoptim", "point", "brent", "optim", "packag", "optim", "univari", "not", "check", "that", "point", "it", "go", "return", "inde", "best", "one", "it", "ha", "encount", "inde", "last", "evalu", "point", "might", "slightli", "wors", "than", "one", "befor", "last"], "B_title": "Using the best function to reduce the total number of tests for a fixed situation .. Fix the patch. ", "B_clean_title": ["best", "function", "reduc", "total", "number", "test", "fix", "situat", "fix", "patch"]},
{"A_title": "Brent solver doesnt throw IllegalArgumentException when initial guess has the wrong signJavadoc for public double solve(final UnivariateRealFunction f final double min final double max final double initial) claims that if the values of the function at the three points have the same sign an IllegalArgumentException is thrown. This case isnt even checked.", "A_clean_title": ["brent", "solver", "doesnt", "throw", "illegalargumentexcept", "illeg", "argument", "except", "when", "initi", "guess", "ha", "wrong", "signjavadoc", "sign", "javadoc", "public", "doubl", "solv", "final", "univariaterealfunct", "univari", "real", "function", "final", "doubl", "min", "final", "doubl", "max", "final", "doubl", "initi", "claim", "that", "valu", "function", "at", "three", "point", "have", "same", "sign", "illegalargumentexcept", "illeg", "argument", "except", "thrown", "thi", "case", "isnt", "even", "check"], "B_title": "Added verifyBracketing to BrentSolver. ", "B_clean_title": ["ad", "verifybracket", "verifi", "bracket", "brentsolv", "brent", "solver"]},
{"A_title": "Brent solver doesnt throw IllegalArgumentException when initial guess has the wrong signJavadoc for public double solve(final UnivariateRealFunction f final double min final double max final double initial) claims that if the values of the function at the three points have the same sign an IllegalArgumentException is thrown. This case isnt even checked.", "A_clean_title": ["brent", "solver", "doesnt", "throw", "illegalargumentexcept", "illeg", "argument", "except", "when", "initi", "guess", "ha", "wrong", "signjavadoc", "sign", "javadoc", "public", "doubl", "solv", "final", "univariaterealfunct", "univari", "real", "function", "final", "doubl", "min", "final", "doubl", "max", "final", "doubl", "initi", "claim", "that", "valu", "function", "at", "three", "point", "have", "same", "sign", "illegalargumentexcept", "illeg", "argument", "except", "thrown", "thi", "case", "isnt", "even", "check"], "B_title": "Added back missing betas. ", "B_clean_title": ["ad", "back", "miss", "beta"]},
{"A_title": "bug in inverseCumulativeProbability() for Normal Distribution@version  Revision: 617953    Date: 2008-02-02 22:54:00 -0700 (Sat 02 Feb 2008)    */ public class NormalDistributionImpl extends AbstractContinuousDistribution    @version  Revision: 506600    Date: 2007-02-12 12:35:59 -0700 (Mon 12 Feb 2007)    */ public abstract class AbstractContinuousDistribution  This code:         DistributionFactory factory = app.getDistributionFactory();         NormalDistribution normal = factory.createNormalDistribution(01);         double result = normal.inverseCumulativeProbability(0.9772498680518209); gives the exception below. It should return (approx) 2.0000... normal.inverseCumulativeProbability(0.977249868051820); works fine These also give errors: 0.9986501019683698 (should return 3.0000...) 0.9999683287581673 (should return 4.0000...) org.apache.commons.math.MathException: Number of iterations=1 maximum iterations=2147483647 initial=1 lower bound=0 upper bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 final a value=0 final b value=2 f(a)=-0.477 f(b)=0 at org.apache.commons.math.distribution.AbstractContinuousDistribution.inverseCumulativeProbability(AbstractContinuousDistribution.java:103) at org.apache.commons.math.distribution.NormalDistributionImpl.inverseCumulativeProbability(NormalDistributionImpl.java:145)", "A_clean_title": ["bug", "inversecumulativeprob", "invers", "cumul", "probabl", "normal", "distribut", "version", "revis", "617953", "date", "2008", "02", "02", "22:54:00", "0700", "sat", "02", "feb", "2008", "public", "class", "normaldistributionimpl", "normal", "distribut", "impl", "extend", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "version", "revis", "506600", "date", "2007", "02", "12", "12:35:59", "0700", "mon", "12", "feb", "2007", "public", "abstract", "class", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "thi", "code", "distributionfactori", "distribut", "factori", "factori", "app", "getdistributionfactori", "get", "distribut", "factori", "normaldistribut", "normal", "distribut", "normal", "factori", "createnormaldistribut", "creat", "normal", "distribut", "01", "doubl", "result", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "9772498680518209", "give", "except", "below", "it", "return", "approx", "0000", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "977249868051820", "work", "fine", "these", "also", "give", "error", "9986501019683698", "return", "0000", "9999683287581673", "return", "0000", "org", "apach", "common", "math", "mathexcept", "math", "except", "number", "iterations=1", "maximum", "iterations=2147483647", "initial=1", "lower", "bound=0", "upper", "bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "final", "value=0", "final", "value=2", "477", "=0", "at", "org", "apach", "common", "math", "distribut", "abstractcontinuousdistribut", "inversecumulativeprob", "abstract", "continu", "distribut", "invers", "cumul", "probabl", "abstractcontinuousdistribut", "java:103", "abstract", "continu", "distribut", "at", "org", "apach", "common", "math", "distribut", "normaldistributionimpl", "inversecumulativeprob", "normal", "distribut", "impl", "invers", "cumul", "probabl", "normaldistributionimpl", "java:145", "normal", "distribut", "impl"], "B_title": "Remove unused if (. ", "B_clean_title": ["remov", "unus"]},
{"A_title": "bug in inverseCumulativeProbability() for Normal Distribution@version  Revision: 617953    Date: 2008-02-02 22:54:00 -0700 (Sat 02 Feb 2008)    */ public class NormalDistributionImpl extends AbstractContinuousDistribution    @version  Revision: 506600    Date: 2007-02-12 12:35:59 -0700 (Mon 12 Feb 2007)    */ public abstract class AbstractContinuousDistribution  This code:         DistributionFactory factory = app.getDistributionFactory();         NormalDistribution normal = factory.createNormalDistribution(01);         double result = normal.inverseCumulativeProbability(0.9772498680518209); gives the exception below. It should return (approx) 2.0000... normal.inverseCumulativeProbability(0.977249868051820); works fine These also give errors: 0.9986501019683698 (should return 3.0000...) 0.9999683287581673 (should return 4.0000...) org.apache.commons.math.MathException: Number of iterations=1 maximum iterations=2147483647 initial=1 lower bound=0 upper bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 final a value=0 final b value=2 f(a)=-0.477 f(b)=0 at org.apache.commons.math.distribution.AbstractContinuousDistribution.inverseCumulativeProbability(AbstractContinuousDistribution.java:103) at org.apache.commons.math.distribution.NormalDistributionImpl.inverseCumulativeProbability(NormalDistributionImpl.java:145)", "A_clean_title": ["bug", "inversecumulativeprob", "invers", "cumul", "probabl", "normal", "distribut", "version", "revis", "617953", "date", "2008", "02", "02", "22:54:00", "0700", "sat", "02", "feb", "2008", "public", "class", "normaldistributionimpl", "normal", "distribut", "impl", "extend", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "version", "revis", "506600", "date", "2007", "02", "12", "12:35:59", "0700", "mon", "12", "feb", "2007", "public", "abstract", "class", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "thi", "code", "distributionfactori", "distribut", "factori", "factori", "app", "getdistributionfactori", "get", "distribut", "factori", "normaldistribut", "normal", "distribut", "normal", "factori", "createnormaldistribut", "creat", "normal", "distribut", "01", "doubl", "result", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "9772498680518209", "give", "except", "below", "it", "return", "approx", "0000", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "977249868051820", "work", "fine", "these", "also", "give", "error", "9986501019683698", "return", "0000", "9999683287581673", "return", "0000", "org", "apach", "common", "math", "mathexcept", "math", "except", "number", "iterations=1", "maximum", "iterations=2147483647", "initial=1", "lower", "bound=0", "upper", "bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "final", "value=0", "final", "value=2", "477", "=0", "at", "org", "apach", "common", "math", "distribut", "abstractcontinuousdistribut", "inversecumulativeprob", "abstract", "continu", "distribut", "invers", "cumul", "probabl", "abstractcontinuousdistribut", "java:103", "abstract", "continu", "distribut", "at", "org", "apach", "common", "math", "distribut", "normaldistributionimpl", "inversecumulativeprob", "normal", "distribut", "impl", "invers", "cumul", "probabl", "normaldistributionimpl", "java:145", "normal", "distribut", "impl"], "B_title": "Fix a false reporting of convergence. ", "B_clean_title": ["fix", "fals", "report", "converg"]},
{"A_title": "bug in inverseCumulativeProbability() for Normal Distribution@version  Revision: 617953    Date: 2008-02-02 22:54:00 -0700 (Sat 02 Feb 2008)    */ public class NormalDistributionImpl extends AbstractContinuousDistribution    @version  Revision: 506600    Date: 2007-02-12 12:35:59 -0700 (Mon 12 Feb 2007)    */ public abstract class AbstractContinuousDistribution  This code:         DistributionFactory factory = app.getDistributionFactory();         NormalDistribution normal = factory.createNormalDistribution(01);         double result = normal.inverseCumulativeProbability(0.9772498680518209); gives the exception below. It should return (approx) 2.0000... normal.inverseCumulativeProbability(0.977249868051820); works fine These also give errors: 0.9986501019683698 (should return 3.0000...) 0.9999683287581673 (should return 4.0000...) org.apache.commons.math.MathException: Number of iterations=1 maximum iterations=2147483647 initial=1 lower bound=0 upper bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 final a value=0 final b value=2 f(a)=-0.477 f(b)=0 at org.apache.commons.math.distribution.AbstractContinuousDistribution.inverseCumulativeProbability(AbstractContinuousDistribution.java:103) at org.apache.commons.math.distribution.NormalDistributionImpl.inverseCumulativeProbability(NormalDistributionImpl.java:145)", "A_clean_title": ["bug", "inversecumulativeprob", "invers", "cumul", "probabl", "normal", "distribut", "version", "revis", "617953", "date", "2008", "02", "02", "22:54:00", "0700", "sat", "02", "feb", "2008", "public", "class", "normaldistributionimpl", "normal", "distribut", "impl", "extend", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "version", "revis", "506600", "date", "2007", "02", "12", "12:35:59", "0700", "mon", "12", "feb", "2007", "public", "abstract", "class", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "thi", "code", "distributionfactori", "distribut", "factori", "factori", "app", "getdistributionfactori", "get", "distribut", "factori", "normaldistribut", "normal", "distribut", "normal", "factori", "createnormaldistribut", "creat", "normal", "distribut", "01", "doubl", "result", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "9772498680518209", "give", "except", "below", "it", "return", "approx", "0000", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "977249868051820", "work", "fine", "these", "also", "give", "error", "9986501019683698", "return", "0000", "9999683287581673", "return", "0000", "org", "apach", "common", "math", "mathexcept", "math", "except", "number", "iterations=1", "maximum", "iterations=2147483647", "initial=1", "lower", "bound=0", "upper", "bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "final", "value=0", "final", "value=2", "477", "=0", "at", "org", "apach", "common", "math", "distribut", "abstractcontinuousdistribut", "inversecumulativeprob", "abstract", "continu", "distribut", "invers", "cumul", "probabl", "abstractcontinuousdistribut", "java:103", "abstract", "continu", "distribut", "at", "org", "apach", "common", "math", "distribut", "normaldistributionimpl", "inversecumulativeprob", "normal", "distribut", "impl", "invers", "cumul", "probabl", "normaldistributionimpl", "java:145", "normal", "distribut", "impl"], "B_title": "Fix a false reporting of convergence. ", "B_clean_title": ["fix", "fals", "report", "converg"]},
{"A_title": "bug in inverseCumulativeProbability() for Normal Distribution@version  Revision: 617953    Date: 2008-02-02 22:54:00 -0700 (Sat 02 Feb 2008)    */ public class NormalDistributionImpl extends AbstractContinuousDistribution    @version  Revision: 506600    Date: 2007-02-12 12:35:59 -0700 (Mon 12 Feb 2007)    */ public abstract class AbstractContinuousDistribution  This code:         DistributionFactory factory = app.getDistributionFactory();         NormalDistribution normal = factory.createNormalDistribution(01);         double result = normal.inverseCumulativeProbability(0.9772498680518209); gives the exception below. It should return (approx) 2.0000... normal.inverseCumulativeProbability(0.977249868051820); works fine These also give errors: 0.9986501019683698 (should return 3.0000...) 0.9999683287581673 (should return 4.0000...) org.apache.commons.math.MathException: Number of iterations=1 maximum iterations=2147483647 initial=1 lower bound=0 upper bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 final a value=0 final b value=2 f(a)=-0.477 f(b)=0 at org.apache.commons.math.distribution.AbstractContinuousDistribution.inverseCumulativeProbability(AbstractContinuousDistribution.java:103) at org.apache.commons.math.distribution.NormalDistributionImpl.inverseCumulativeProbability(NormalDistributionImpl.java:145)", "A_clean_title": ["bug", "inversecumulativeprob", "invers", "cumul", "probabl", "normal", "distribut", "version", "revis", "617953", "date", "2008", "02", "02", "22:54:00", "0700", "sat", "02", "feb", "2008", "public", "class", "normaldistributionimpl", "normal", "distribut", "impl", "extend", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "version", "revis", "506600", "date", "2007", "02", "12", "12:35:59", "0700", "mon", "12", "feb", "2007", "public", "abstract", "class", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "thi", "code", "distributionfactori", "distribut", "factori", "factori", "app", "getdistributionfactori", "get", "distribut", "factori", "normaldistribut", "normal", "distribut", "normal", "factori", "createnormaldistribut", "creat", "normal", "distribut", "01", "doubl", "result", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "9772498680518209", "give", "except", "below", "it", "return", "approx", "0000", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "977249868051820", "work", "fine", "these", "also", "give", "error", "9986501019683698", "return", "0000", "9999683287581673", "return", "0000", "org", "apach", "common", "math", "mathexcept", "math", "except", "number", "iterations=1", "maximum", "iterations=2147483647", "initial=1", "lower", "bound=0", "upper", "bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "final", "value=0", "final", "value=2", "477", "=0", "at", "org", "apach", "common", "math", "distribut", "abstractcontinuousdistribut", "inversecumulativeprob", "abstract", "continu", "distribut", "invers", "cumul", "probabl", "abstractcontinuousdistribut", "java:103", "abstract", "continu", "distribut", "at", "org", "apach", "common", "math", "distribut", "normaldistributionimpl", "inversecumulativeprob", "normal", "distribut", "impl", "invers", "cumul", "probabl", "normaldistributionimpl", "java:145", "normal", "distribut", "impl"], "B_title": "Remove a redundant check. ", "B_clean_title": ["remov", "redund", "check"]},
{"A_title": "bug in inverseCumulativeProbability() for Normal Distribution@version  Revision: 617953    Date: 2008-02-02 22:54:00 -0700 (Sat 02 Feb 2008)    */ public class NormalDistributionImpl extends AbstractContinuousDistribution    @version  Revision: 506600    Date: 2007-02-12 12:35:59 -0700 (Mon 12 Feb 2007)    */ public abstract class AbstractContinuousDistribution  This code:         DistributionFactory factory = app.getDistributionFactory();         NormalDistribution normal = factory.createNormalDistribution(01);         double result = normal.inverseCumulativeProbability(0.9772498680518209); gives the exception below. It should return (approx) 2.0000... normal.inverseCumulativeProbability(0.977249868051820); works fine These also give errors: 0.9986501019683698 (should return 3.0000...) 0.9999683287581673 (should return 4.0000...) org.apache.commons.math.MathException: Number of iterations=1 maximum iterations=2147483647 initial=1 lower bound=0 upper bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 final a value=0 final b value=2 f(a)=-0.477 f(b)=0 at org.apache.commons.math.distribution.AbstractContinuousDistribution.inverseCumulativeProbability(AbstractContinuousDistribution.java:103) at org.apache.commons.math.distribution.NormalDistributionImpl.inverseCumulativeProbability(NormalDistributionImpl.java:145)", "A_clean_title": ["bug", "inversecumulativeprob", "invers", "cumul", "probabl", "normal", "distribut", "version", "revis", "617953", "date", "2008", "02", "02", "22:54:00", "0700", "sat", "02", "feb", "2008", "public", "class", "normaldistributionimpl", "normal", "distribut", "impl", "extend", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "version", "revis", "506600", "date", "2007", "02", "12", "12:35:59", "0700", "mon", "12", "feb", "2007", "public", "abstract", "class", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "thi", "code", "distributionfactori", "distribut", "factori", "factori", "app", "getdistributionfactori", "get", "distribut", "factori", "normaldistribut", "normal", "distribut", "normal", "factori", "createnormaldistribut", "creat", "normal", "distribut", "01", "doubl", "result", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "9772498680518209", "give", "except", "below", "it", "return", "approx", "0000", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "977249868051820", "work", "fine", "these", "also", "give", "error", "9986501019683698", "return", "0000", "9999683287581673", "return", "0000", "org", "apach", "common", "math", "mathexcept", "math", "except", "number", "iterations=1", "maximum", "iterations=2147483647", "initial=1", "lower", "bound=0", "upper", "bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "final", "value=0", "final", "value=2", "477", "=0", "at", "org", "apach", "common", "math", "distribut", "abstractcontinuousdistribut", "inversecumulativeprob", "abstract", "continu", "distribut", "invers", "cumul", "probabl", "abstractcontinuousdistribut", "java:103", "abstract", "continu", "distribut", "at", "org", "apach", "common", "math", "distribut", "normaldistributionimpl", "inversecumulativeprob", "normal", "distribut", "impl", "invers", "cumul", "probabl", "normaldistributionimpl", "java:145", "normal", "distribut", "impl"], "B_title": "Fix a bug in the patch collection. ", "B_clean_title": ["fix", "bug", "patch", "collect"]},
{"A_title": "MathRuntimeException with simple ebeMultiply on OpenMapRealVectorThe following piece of code  import org.apache.commons.math.linear.OpenMapRealVector; import org.apache.commons.math.linear.RealVector;  public class DemoBugOpenMapRealVector      public static void main(String args)          final RealVector u = new OpenMapRealVector(3 1E-6);         u.setEntry(0 1.);         u.setEntry(1 0.);         u.setEntry(2 2.);         final RealVector v = new OpenMapRealVector(3 1E-6);         v.setEntry(0 0.);         v.setEntry(1 3.);         v.setEntry(2 0.);         System.out.println(u);         System.out.println(v);         System.out.println(u.ebeMultiply(v));         raises an exception  org.apache.commons.math.linear.OpenMapRealVector@7170a9b6 Exception in thread main org.apache.commons.math.MathRuntimeException 6: map has been modified while iterating at org.apache.commons.math.MathRuntimeException.createConcurrentModificationException(MathRuntimeException.java:373) at org.apache.commons.math.util.OpenIntToDoubleHashMap Iterator.advance(OpenIntToDoubleHashMap.java:564) at org.apache.commons.math.linear.OpenMapRealVector.ebeMultiply(OpenMapRealVector.java:372) at org.apache.commons.math.linear.OpenMapRealVector.ebeMultiply(OpenMapRealVector.java:1) at DemoBugOpenMapRealVector.main(DemoBugOpenMapRealVector.java:17)", "A_clean_title": ["mathruntimeexcept", "math", "runtim", "except", "simpl", "ebemultipli", "ebe", "multipli", "openmaprealvectorth", "open", "map", "real", "vector", "follow", "piec", "code", "import", "org", "apach", "common", "math", "linear", "openmaprealvector", "open", "map", "real", "vector", "import", "org", "apach", "common", "math", "linear", "realvector", "real", "vector", "public", "class", "demobugopenmaprealvector", "demo", "bug", "open", "map", "real", "vector", "public", "static", "void", "main", "string", "arg", "final", "realvector", "real", "vector", "new", "openmaprealvector", "open", "map", "real", "vector", "1e", "setentri", "set", "entri", "setentri", "set", "entri", "setentri", "set", "entri", "final", "realvector", "real", "vector", "new", "openmaprealvector", "open", "map", "real", "vector", "1e", "setentri", "set", "entri", "setentri", "set", "entri", "setentri", "set", "entri", "system", "out", "println", "system", "out", "println", "system", "out", "println", "ebemultipli", "ebe", "multipli", "rais", "except", "org", "apach", "common", "math", "linear", "openmaprealvector", "open", "map", "real", "vector", "7170a9b6", "except", "thread", "main", "org", "apach", "common", "math", "mathruntimeexcept", "math", "runtim", "except", "map", "ha", "been", "modifi", "while", "iter", "at", "org", "apach", "common", "math", "mathruntimeexcept", "createconcurrentmodificationexcept", "math", "runtim", "except", "creat", "concurr", "modif", "except", "mathruntimeexcept", "java:373", "math", "runtim", "except", "at", "org", "apach", "common", "math", "util", "openinttodoublehashmap", "open", "int", "doubl", "hash", "map", "iter", "advanc", "openinttodoublehashmap", "java:564", "open", "int", "doubl", "hash", "map", "at", "org", "apach", "common", "math", "linear", "openmaprealvector", "ebemultipli", "open", "map", "real", "vector", "ebe", "multipli", "openmaprealvector", "java:372", "open", "map", "real", "vector", "at", "org", "apach", "common", "math", "linear", "openmaprealvector", "ebemultipli", "open", "map", "real", "vector", "ebe", "multipli", "openmaprealvector", "java:1", "open", "map", "real", "vector", "at", "demobugopenmaprealvector", "main", "demo", "bug", "open", "map", "real", "vector", "demobugopenmaprealvector", "java:17", "demo", "bug", "open", "map", "real", "vector"], "B_title": "Fix bug in ebeDivide ( RealVector ). Fix bug in ebeDivide ( ). Updated patch. Fix bug in ebeMultiply ( ). ", "B_clean_title": ["fix", "bug", "ebedivid", "ebe", "divid", "realvector", "real", "vector", "fix", "bug", "ebedivid", "ebe", "divid", "updat", "patch", "fix", "bug", "ebemultipli", "ebe", "multipli"]},
{"A_title": "StringUtils.join throws NPE when toString returns null for one of objects in collectionTry    StringUtils.join(new Object         new Object()            @Override           public String toString()              return null;                          );   ToString should probably never return null but it does in javax.mail.internet.InternetAddress", "A_clean_title": ["stringutil", "join", "string", "util", "throw", "npe", "when", "tostr", "string", "return", "null", "one", "object", "collectiontri", "collect", "tri", "stringutil", "join", "string", "util", "new", "object", "new", "object", "overrid", "public", "string", "tostr", "string", "return", "null", "tostr", "string", "probabl", "never", "return", "null", "but", "it", "javax", "mail", "internet", "internetaddress", "internet", "address"], "B_title": "Bump the buffer size for the empty string builder .. Removed unnecessary copy of StringUtils. ", "B_clean_title": ["bump", "buffer", "size", "empti", "string", "builder", "remov", "unnecessari", "copi", "stringutil", "string", "util"]},
{"A_title": "StringUtils.join throws NPE when toString returns null for one of objects in collectionTry    StringUtils.join(new Object         new Object()            @Override           public String toString()              return null;                          );   ToString should probably never return null but it does in javax.mail.internet.InternetAddress", "A_clean_title": ["stringutil", "join", "string", "util", "throw", "npe", "when", "tostr", "string", "return", "null", "one", "object", "collectiontri", "collect", "tri", "stringutil", "join", "string", "util", "new", "object", "new", "object", "overrid", "public", "string", "tostr", "string", "return", "null", "tostr", "string", "probabl", "never", "return", "null", "but", "it", "javax", "mail", "internet", "internetaddress", "internet", "address"], "B_title": "fixed bug. ", "B_clean_title": ["fix", "bug"]},
{"A_title": "StringUtils.join throws NPE when toString returns null for one of objects in collectionTry    StringUtils.join(new Object         new Object()            @Override           public String toString()              return null;                          );   ToString should probably never return null but it does in javax.mail.internet.InternetAddress", "A_clean_title": ["stringutil", "join", "string", "util", "throw", "npe", "when", "tostr", "string", "return", "null", "one", "object", "collectiontri", "collect", "tri", "stringutil", "join", "string", "util", "new", "object", "new", "object", "overrid", "public", "string", "tostr", "string", "return", "null", "tostr", "string", "probabl", "never", "return", "null", "but", "it", "javax", "mail", "internet", "internetaddress", "internet", "address"], "B_title": "fixed bug. ", "B_clean_title": ["fix", "bug"]},
{"A_title": "JCommon 1.0.12 ShapeUtilities.equal(path1path2)The comparison of two GeneralPath objects uses the same PathIterator for both objects. equal(GeneralPath path1 GeneralPath path2) will thus return true for any pair of non-null GeneralPath instances having the same windingRule.", "A_clean_title": ["jcommon", "common", "12", "shapeutil", "equal", "shape", "util", "path1path2", "comparison", "two", "generalpath", "gener", "path", "object", "use", "same", "pathiter", "path", "iter", "both", "object", "equal", "generalpath", "gener", "path", "path1", "generalpath", "gener", "path", "path2", "will", "thu", "return", "true", "ani", "pair", "non", "null", "generalpath", "gener", "path", "instanc", "have", "same", "windingrul", "wind", "rule"], "B_title": "Remove redundant code. ", "B_clean_title": ["remov", "redund", "code"]},
{"A_title": "JCommon 1.0.12 ShapeUtilities.equal(path1path2)The comparison of two GeneralPath objects uses the same PathIterator for both objects. equal(GeneralPath path1 GeneralPath path2) will thus return true for any pair of non-null GeneralPath instances having the same windingRule.", "A_clean_title": ["jcommon", "common", "12", "shapeutil", "equal", "shape", "util", "path1path2", "comparison", "two", "generalpath", "gener", "path", "object", "use", "same", "pathiter", "path", "iter", "both", "object", "equal", "generalpath", "gener", "path", "path1", "generalpath", "gener", "path", "path2", "will", "thu", "return", "true", "ani", "pair", "non", "null", "generalpath", "gener", "path", "instanc", "have", "same", "windingrul", "wind", "rule"], "B_title": "fix merge issue. ", "B_clean_title": ["fix", "merg", "issu"]},
{"A_title": "JCommon 1.0.12 ShapeUtilities.equal(path1path2)The comparison of two GeneralPath objects uses the same PathIterator for both objects. equal(GeneralPath path1 GeneralPath path2) will thus return true for any pair of non-null GeneralPath instances having the same windingRule.", "A_clean_title": ["jcommon", "common", "12", "shapeutil", "equal", "shape", "util", "path1path2", "comparison", "two", "generalpath", "gener", "path", "object", "use", "same", "pathiter", "path", "iter", "both", "object", "equal", "generalpath", "gener", "path", "path1", "generalpath", "gener", "path", "path2", "will", "thu", "return", "true", "ani", "pair", "non", "null", "generalpath", "gener", "path", "instanc", "have", "same", "windingrul", "wind", "rule"], "B_title": "Fix swapped diffs in patch. ", "B_clean_title": ["fix", "swap", "diff", "patch"]},
{"A_title": "JCommon 1.0.12 ShapeUtilities.equal(path1path2)The comparison of two GeneralPath objects uses the same PathIterator for both objects. equal(GeneralPath path1 GeneralPath path2) will thus return true for any pair of non-null GeneralPath instances having the same windingRule.", "A_clean_title": ["jcommon", "common", "12", "shapeutil", "equal", "shape", "util", "path1path2", "comparison", "two", "generalpath", "gener", "path", "object", "use", "same", "pathiter", "path", "iter", "both", "object", "equal", "generalpath", "gener", "path", "path1", "generalpath", "gener", "path", "path2", "will", "thu", "return", "true", "ani", "pair", "non", "null", "generalpath", "gener", "path", "instanc", "have", "same", "windingrul", "wind", "rule"], "B_title": "added missing copy. ", "B_clean_title": ["ad", "miss", "copi"]},
{"A_title": "JCommon 1.0.12 ShapeUtilities.equal(path1path2)The comparison of two GeneralPath objects uses the same PathIterator for both objects. equal(GeneralPath path1 GeneralPath path2) will thus return true for any pair of non-null GeneralPath instances having the same windingRule.", "A_clean_title": ["jcommon", "common", "12", "shapeutil", "equal", "shape", "util", "path1path2", "comparison", "two", "generalpath", "gener", "path", "object", "use", "same", "pathiter", "path", "iter", "both", "object", "equal", "generalpath", "gener", "path", "path1", "generalpath", "gener", "path", "path2", "will", "thu", "return", "true", "ani", "pair", "non", "null", "generalpath", "gener", "path", "instanc", "have", "same", "windingrul", "wind", "rule"], "B_title": "Add missing import. Fix test. ", "B_clean_title": ["add", "miss", "import", "fix", "test"]},
{"A_title": "Classify non-rightmost expressions as problematicNone", "A_clean_title": ["classifi", "non", "rightmost", "express", "as", "problematicnon", "problemat", "none"], "B_title": "Remove unused local variable .. ", "B_clean_title": ["remov", "unus", "local", "variabl"]},
{"A_title": "Classify non-rightmost expressions as problematicNone", "A_clean_title": ["classifi", "non", "rightmost", "express", "as", "problematicnon", "problemat", "none"], "B_title": "Fix bug in closure patch. ", "B_clean_title": ["fix", "bug", "closur", "patch"]},
{"A_title": "compiler crashes when  goog.provide used with non stringNone", "A_clean_title": ["compil", "crash", "when", "goog", "provid", "use", "non", "stringnon", "string", "none"], "B_title": "Fixing closure code conventions. ", "B_clean_title": ["fix", "closur", "code", "convent"]},
{"A_title": ".withHourOfDay() sets hour inconsistantly on DST transition.When the hour of day is set to the ambiguous hour on the daylight to standard time transition in a given time zone the result is inconsistent for different time zones. Shoul the hour be set to the daylight hour or the standard hour for all time zones? I cant find anything that documents this behavior.  My test code below returns different results for different time zones. The very last assertion fails on the Australia time zone cutover.", "A_clean_title": ["withhourofday", "hour", "day", "set", "hour", "inconsistantli", "dst", "transit", "when", "hour", "day", "set", "ambigu", "hour", "daylight", "standard", "time", "transit", "given", "time", "zone", "result", "inconsist", "differ", "time", "zone", "shoul", "hour", "set", "daylight", "hour", "or", "standard", "hour", "all", "time", "zone", "cant", "find", "anyth", "that", "document", "thi", "behavior", "my", "test", "code", "below", "return", "differ", "result", "differ", "time", "zone", "veri", "last", "assert", "fail", "australia", "time", "zone", "cutov"], "B_title": "Fixed typo in Time - 26 - Hercules .. Fixed bug in Time - 26 - Hercules .. Fixed formatting mistake .. Fixed bug in Time - 26 - Hercules .. Fixed typo in patch1. Fixed formatting mistake in convertLocalToUTC ( long  boolean  boolean  boolean  boolean ). Fixed formatting mistake in convertLocalToUTC ( long  boolean  boolean  boolean ). ", "B_clean_title": ["fix", "typo", "time", "26", "hercul", "fix", "bug", "time", "26", "hercul", "fix", "format", "mistak", "fix", "bug", "time", "26", "hercul", "fix", "typo", "patch1", "fix", "format", "mistak", "convertlocaltoutc", "convert", "local", "utc", "long", "boolean", "boolean", "boolean", "boolean", "fix", "format", "mistak", "convertlocaltoutc", "convert", "local", "utc", "long", "boolean", "boolean", "boolean"]},
{"A_title": "RealMatrixImpl#operate gets result vector dimensions wrongorg.apache.commons.math.linear.RealMatrixImpl#operate tries to create a result vector that always has the same length as the input vector. This can result in runtime exceptions if the matrix is non-square and it always yields incorrect results if the matrix is non-square. The correct behaviour would of course be to create a vector with the same length as the row dimension of the matrix. Thus line 640 in RealMatrixImpl.java should read double out = new doublenRows; instead of double out = new doublev.length;", "A_clean_title": ["realmatriximpl", "real", "matrix", "impl", "oper", "get", "result", "vector", "dimens", "wrongorg", "apach", "common", "math", "linear", "realmatriximpl", "real", "matrix", "impl", "oper", "tri", "creat", "result", "vector", "that", "alway", "ha", "same", "length", "as", "input", "vector", "thi", "result", "runtim", "except", "matrix", "non", "squar", "it", "alway", "yield", "incorrect", "result", "matrix", "non", "squar", "correct", "behaviour", "would", "cours", "creat", "vector", "same", "length", "as", "row", "dimens", "matrix", "thu", "line", "640", "realmatriximpl", "java", "real", "matrix", "impl", "read", "doubl", "out", "new", "doublenrow", "doublen", "row", "instead", "doubl", "out", "new", "doublev", "length"], "B_title": "Fix array length. ", "B_clean_title": ["fix", "array", "length"]},
{"A_title": "RealMatrixImpl#operate gets result vector dimensions wrongorg.apache.commons.math.linear.RealMatrixImpl#operate tries to create a result vector that always has the same length as the input vector. This can result in runtime exceptions if the matrix is non-square and it always yields incorrect results if the matrix is non-square. The correct behaviour would of course be to create a vector with the same length as the row dimension of the matrix. Thus line 640 in RealMatrixImpl.java should read double out = new doublenRows; instead of double out = new doublev.length;", "A_clean_title": ["realmatriximpl", "real", "matrix", "impl", "oper", "get", "result", "vector", "dimens", "wrongorg", "apach", "common", "math", "linear", "realmatriximpl", "real", "matrix", "impl", "oper", "tri", "creat", "result", "vector", "that", "alway", "ha", "same", "length", "as", "input", "vector", "thi", "result", "runtim", "except", "matrix", "non", "squar", "it", "alway", "yield", "incorrect", "result", "matrix", "non", "squar", "correct", "behaviour", "would", "cours", "creat", "vector", "same", "length", "as", "row", "dimens", "matrix", "thu", "line", "640", "realmatriximpl", "java", "real", "matrix", "impl", "read", "doubl", "out", "new", "doublenrow", "doublen", "row", "instead", "doubl", "out", "new", "doublev", "length"], "B_title": "Fix the array to work properly. fix the bug. ", "B_clean_title": ["fix", "array", "work", "properli", "fix", "bug"]},
{"A_title": "RealMatrixImpl#operate gets result vector dimensions wrongorg.apache.commons.math.linear.RealMatrixImpl#operate tries to create a result vector that always has the same length as the input vector. This can result in runtime exceptions if the matrix is non-square and it always yields incorrect results if the matrix is non-square. The correct behaviour would of course be to create a vector with the same length as the row dimension of the matrix. Thus line 640 in RealMatrixImpl.java should read double out = new doublenRows; instead of double out = new doublev.length;", "A_clean_title": ["realmatriximpl", "real", "matrix", "impl", "oper", "get", "result", "vector", "dimens", "wrongorg", "apach", "common", "math", "linear", "realmatriximpl", "real", "matrix", "impl", "oper", "tri", "creat", "result", "vector", "that", "alway", "ha", "same", "length", "as", "input", "vector", "thi", "result", "runtim", "except", "matrix", "non", "squar", "it", "alway", "yield", "incorrect", "result", "matrix", "non", "squar", "correct", "behaviour", "would", "cours", "creat", "vector", "same", "length", "as", "row", "dimens", "matrix", "thu", "line", "640", "realmatriximpl", "java", "real", "matrix", "impl", "read", "doubl", "out", "new", "doublenrow", "doublen", "row", "instead", "doubl", "out", "new", "doublev", "length"], "B_title": "BigMatrixImpl copy constructor. Fix error in RealMatrixImpl .. ", "B_clean_title": ["bigmatriximpl", "big", "matrix", "impl", "copi", "constructor", "fix", "error", "realmatriximpl", "real", "matrix", "impl"]},
{"A_title": "RealMatrixImpl#operate gets result vector dimensions wrongorg.apache.commons.math.linear.RealMatrixImpl#operate tries to create a result vector that always has the same length as the input vector. This can result in runtime exceptions if the matrix is non-square and it always yields incorrect results if the matrix is non-square. The correct behaviour would of course be to create a vector with the same length as the row dimension of the matrix. Thus line 640 in RealMatrixImpl.java should read double out = new doublenRows; instead of double out = new doublev.length;", "A_clean_title": ["realmatriximpl", "real", "matrix", "impl", "oper", "get", "result", "vector", "dimens", "wrongorg", "apach", "common", "math", "linear", "realmatriximpl", "real", "matrix", "impl", "oper", "tri", "creat", "result", "vector", "that", "alway", "ha", "same", "length", "as", "input", "vector", "thi", "result", "runtim", "except", "matrix", "non", "squar", "it", "alway", "yield", "incorrect", "result", "matrix", "non", "squar", "correct", "behaviour", "would", "cours", "creat", "vector", "same", "length", "as", "row", "dimens", "matrix", "thu", "line", "640", "realmatriximpl", "java", "real", "matrix", "impl", "read", "doubl", "out", "new", "doublenrow", "doublen", "row", "instead", "doubl", "out", "new", "doublev", "length"], "B_title": "Fixed erroneous conversion to BigDecimal. Fix initial matrix lengths .. ", "B_clean_title": ["fix", "erron", "convers", "bigdecim", "big", "decim", "fix", "initi", "matrix", "length"]},
{"A_title": "RealMatrixImpl#operate gets result vector dimensions wrongorg.apache.commons.math.linear.RealMatrixImpl#operate tries to create a result vector that always has the same length as the input vector. This can result in runtime exceptions if the matrix is non-square and it always yields incorrect results if the matrix is non-square. The correct behaviour would of course be to create a vector with the same length as the row dimension of the matrix. Thus line 640 in RealMatrixImpl.java should read double out = new doublenRows; instead of double out = new doublev.length;", "A_clean_title": ["realmatriximpl", "real", "matrix", "impl", "oper", "get", "result", "vector", "dimens", "wrongorg", "apach", "common", "math", "linear", "realmatriximpl", "real", "matrix", "impl", "oper", "tri", "creat", "result", "vector", "that", "alway", "ha", "same", "length", "as", "input", "vector", "thi", "result", "runtim", "except", "matrix", "non", "squar", "it", "alway", "yield", "incorrect", "result", "matrix", "non", "squar", "correct", "behaviour", "would", "cours", "creat", "vector", "same", "length", "as", "row", "dimens", "matrix", "thu", "line", "640", "realmatriximpl", "java", "real", "matrix", "impl", "read", "doubl", "out", "new", "doublenrow", "doublen", "row", "instead", "doubl", "out", "new", "doublev", "length"], "B_title": "Fixed erroneous conversion to BigDecimal. Fix initial matrix length. ", "B_clean_title": ["fix", "erron", "convers", "bigdecim", "big", "decim", "fix", "initi", "matrix", "length"]},
{"A_title": "Fix for MultiplePiePlotWhen dataset is passed into constructor for MultiplePiePlot the dataset is not wired to a listener as it would be if setDataset is called.", "A_clean_title": ["fix", "multiplepieplotwhen", "multipl", "pie", "plot", "when", "dataset", "pass", "into", "constructor", "multiplepieplot", "multipl", "pie", "plot", "dataset", "not", "wire", "listen", "as", "it", "would", "setdataset", "set", "dataset", "call"], "B_title": "Fix 144 bug. ", "B_clean_title": ["fix", "144", "bug"]},
{"A_title": "Fix for MultiplePiePlotWhen dataset is passed into constructor for MultiplePiePlot the dataset is not wired to a listener as it would be if setDataset is called.", "A_clean_title": ["fix", "multiplepieplotwhen", "multipl", "pie", "plot", "when", "dataset", "pass", "into", "constructor", "multiplepieplot", "multipl", "pie", "plot", "dataset", "not", "wire", "listen", "as", "it", "would", "setdataset", "set", "dataset", "call"], "B_title": "Fixed a bug in MultiplePiePlot .. ", "B_clean_title": ["fix", "bug", "multiplepieplot", "multipl", "pie", "plot"]},
{"A_title": "Fix for MultiplePiePlotWhen dataset is passed into constructor for MultiplePiePlot the dataset is not wired to a listener as it would be if setDataset is called.", "A_clean_title": ["fix", "multiplepieplotwhen", "multipl", "pie", "plot", "when", "dataset", "pass", "into", "constructor", "multiplepieplot", "multipl", "pie", "plot", "dataset", "not", "wire", "listen", "as", "it", "would", "setdataset", "set", "dataset", "call"], "B_title": "Missing warning. ", "B_clean_title": ["miss", "warn"]},
{"A_title": "Fix for MultiplePiePlotWhen dataset is passed into constructor for MultiplePiePlot the dataset is not wired to a listener as it would be if setDataset is called.", "A_clean_title": ["fix", "multiplepieplotwhen", "multipl", "pie", "plot", "when", "dataset", "pass", "into", "constructor", "multiplepieplot", "multipl", "pie", "plot", "dataset", "not", "wire", "listen", "as", "it", "would", "setdataset", "set", "dataset", "call"], "B_title": "Set the dataset on the pie chart .. ", "B_clean_title": ["set", "dataset", "pie", "chart"]},
{"A_title": "Complex Add and Subtract handle NaN arguments differently but javadoc contracts are the sameFor both Complex add and subtract the javadoc states that       * If either this or <code>rhs</code> has a NaN value in either part      * @link #NaN is returned; otherwise Inifinite and NaN values are      * returned in the parts of the result according to the rules for      * @link java.lang.Double arithmetic   Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored since this looks like a code merge problem going back to 1.1).", "A_clean_title": ["complex", "add", "subtract", "handl", "nan", "na", "argument", "differ", "but", "javadoc", "contract", "are", "samefor", "same", "both", "complex", "add", "subtract", "javadoc", "state", "that", "either", "thi", "or", "code", "rh", "code", "ha", "nan", "na", "valu", "either", "part", "link", "nan", "na", "return", "otherwis", "inifinit", "nan", "na", "valu", "are", "return", "part", "result", "accord", "rule", "link", "java", "lang", "doubl", "arithmet", "subtract", "includ", "isnan", "na", "test", "return", "complex", "nan", "na", "either", "complex", "argument", "isnan", "na", "but", "add", "omit", "thi", "test", "test", "ad", "add", "implement", "actual", "restor", "sinc", "thi", "look", "like", "code", "merg", "problem", "go", "back"], "B_title": "Add the isNaN check to Complex . add ( ). ", "B_clean_title": ["add", "isnan", "na", "check", "complex", "add"]},
{"A_title": "Complex Add and Subtract handle NaN arguments differently but javadoc contracts are the sameFor both Complex add and subtract the javadoc states that       * If either this or <code>rhs</code> has a NaN value in either part      * @link #NaN is returned; otherwise Inifinite and NaN values are      * returned in the parts of the result according to the rules for      * @link java.lang.Double arithmetic   Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored since this looks like a code merge problem going back to 1.1).", "A_clean_title": ["complex", "add", "subtract", "handl", "nan", "na", "argument", "differ", "but", "javadoc", "contract", "are", "samefor", "same", "both", "complex", "add", "subtract", "javadoc", "state", "that", "either", "thi", "or", "code", "rh", "code", "ha", "nan", "na", "valu", "either", "part", "link", "nan", "na", "return", "otherwis", "inifinit", "nan", "na", "valu", "are", "return", "part", "result", "accord", "rule", "link", "java", "lang", "doubl", "arithmet", "subtract", "includ", "isnan", "na", "test", "return", "complex", "nan", "na", "either", "complex", "argument", "isnan", "na", "but", "add", "omit", "thi", "test", "test", "ad", "add", "implement", "actual", "restor", "sinc", "thi", "look", "like", "code", "merg", "problem", "go", "back"], "B_title": "Add the isNaN check to Complex . add ( ). ", "B_clean_title": ["add", "isnan", "na", "check", "complex", "add"]},
{"A_title": "Complex Add and Subtract handle NaN arguments differently but javadoc contracts are the sameFor both Complex add and subtract the javadoc states that       * If either this or <code>rhs</code> has a NaN value in either part      * @link #NaN is returned; otherwise Inifinite and NaN values are      * returned in the parts of the result according to the rules for      * @link java.lang.Double arithmetic   Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored since this looks like a code merge problem going back to 1.1).", "A_clean_title": ["complex", "add", "subtract", "handl", "nan", "na", "argument", "differ", "but", "javadoc", "contract", "are", "samefor", "same", "both", "complex", "add", "subtract", "javadoc", "state", "that", "either", "thi", "or", "code", "rh", "code", "ha", "nan", "na", "valu", "either", "part", "link", "nan", "na", "return", "otherwis", "inifinit", "nan", "na", "valu", "are", "return", "part", "result", "accord", "rule", "link", "java", "lang", "doubl", "arithmet", "subtract", "includ", "isnan", "na", "test", "return", "complex", "nan", "na", "either", "complex", "argument", "isnan", "na", "but", "add", "omit", "thi", "test", "test", "ad", "add", "implement", "actual", "restor", "sinc", "thi", "look", "like", "code", "merg", "problem", "go", "back"], "B_title": "Add NaN to Complex . add ( ). ", "B_clean_title": ["add", "nan", "na", "complex", "add"]},
{"A_title": "Complex Add and Subtract handle NaN arguments differently but javadoc contracts are the sameFor both Complex add and subtract the javadoc states that       * If either this or <code>rhs</code> has a NaN value in either part      * @link #NaN is returned; otherwise Inifinite and NaN values are      * returned in the parts of the result according to the rules for      * @link java.lang.Double arithmetic   Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored since this looks like a code merge problem going back to 1.1).", "A_clean_title": ["complex", "add", "subtract", "handl", "nan", "na", "argument", "differ", "but", "javadoc", "contract", "are", "samefor", "same", "both", "complex", "add", "subtract", "javadoc", "state", "that", "either", "thi", "or", "code", "rh", "code", "ha", "nan", "na", "valu", "either", "part", "link", "nan", "na", "return", "otherwis", "inifinit", "nan", "na", "valu", "are", "return", "part", "result", "accord", "rule", "link", "java", "lang", "doubl", "arithmet", "subtract", "includ", "isnan", "na", "test", "return", "complex", "nan", "na", "either", "complex", "argument", "isnan", "na", "but", "add", "omit", "thi", "test", "test", "ad", "add", "implement", "actual", "restor", "sinc", "thi", "look", "like", "code", "merg", "problem", "go", "back"], "B_title": "Add the isNaN check. ", "B_clean_title": ["add", "isnan", "na", "check"]},
{"A_title": "Complex Add and Subtract handle NaN arguments differently but javadoc contracts are the sameFor both Complex add and subtract the javadoc states that       * If either this or <code>rhs</code> has a NaN value in either part      * @link #NaN is returned; otherwise Inifinite and NaN values are      * returned in the parts of the result according to the rules for      * @link java.lang.Double arithmetic   Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored since this looks like a code merge problem going back to 1.1).", "A_clean_title": ["complex", "add", "subtract", "handl", "nan", "na", "argument", "differ", "but", "javadoc", "contract", "are", "samefor", "same", "both", "complex", "add", "subtract", "javadoc", "state", "that", "either", "thi", "or", "code", "rh", "code", "ha", "nan", "na", "valu", "either", "part", "link", "nan", "na", "return", "otherwis", "inifinit", "nan", "na", "valu", "are", "return", "part", "result", "accord", "rule", "link", "java", "lang", "doubl", "arithmet", "subtract", "includ", "isnan", "na", "test", "return", "complex", "nan", "na", "either", "complex", "argument", "isnan", "na", "but", "add", "omit", "thi", "test", "test", "ad", "add", "implement", "actual", "restor", "sinc", "thi", "look", "like", "code", "merg", "problem", "go", "back"], "B_title": "Add one - line ifs. ", "B_clean_title": ["add", "one", "line", "if"]},
{"A_title": "Complex Add and Subtract handle NaN arguments differently but javadoc contracts are the sameFor both Complex add and subtract the javadoc states that       * If either this or <code>rhs</code> has a NaN value in either part      * @link #NaN is returned; otherwise Inifinite and NaN values are      * returned in the parts of the result according to the rules for      * @link java.lang.Double arithmetic   Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored since this looks like a code merge problem going back to 1.1).", "A_clean_title": ["complex", "add", "subtract", "handl", "nan", "na", "argument", "differ", "but", "javadoc", "contract", "are", "samefor", "same", "both", "complex", "add", "subtract", "javadoc", "state", "that", "either", "thi", "or", "code", "rh", "code", "ha", "nan", "na", "valu", "either", "part", "link", "nan", "na", "return", "otherwis", "inifinit", "nan", "na", "valu", "are", "return", "part", "result", "accord", "rule", "link", "java", "lang", "doubl", "arithmet", "subtract", "includ", "isnan", "na", "test", "return", "complex", "nan", "na", "either", "complex", "argument", "isnan", "na", "but", "add", "omit", "thi", "test", "test", "ad", "add", "implement", "actual", "restor", "sinc", "thi", "look", "like", "code", "merg", "problem", "go", "back"], "B_title": "Add the isNaN check in Complex . add ( ). ", "B_clean_title": ["add", "isnan", "na", "check", "complex", "add"]},
{"A_title": "wrong result in eigen decompositionSome results computed by EigenDecompositionImpl are wrong. The following case computed by Fortran Lapack fails with version 2.0      public void testMathpbx02()           double mainTridiagonal =            7484.860960227216 18405.28129035345 13855.225609560746          10016.708722343366 559.8117399576674 6750.190788301587              71.21428769782159         ;         double secondaryTridiagonal =           -4175.0885704763661975.79558582419945193.178422374075            1995.28665916917975.34535882933804-234.0808002076056         ;          // the reference values have been computed using routine DSTEMR         // from the fortran library LAPACK version 3.2.1         double refEigenValues =          20654.74489030697441216828.208208485466457         6893.1559126349948206757.083016675340332         5887.79988568855878864.309089923240379         57.992628792736340         ;         RealVector refEigenVectors =          new ArrayRealVector(new double -0.270356342026904 0.852811091326997 0.399639490702077 0.198794657813990 0.019739323307666 0.000106983022327 -0.000001216636321)         new ArrayRealVector(new double 0.179995273578326-0.4028078481530420.7018709935257340.5550582110148880.0680791488982360.000509139115227-0.000007112235617)         new ArrayRealVector(new double -0.399582721284727-0.056629954519333-0.5144064885228270.7111681645185800.2255480812763670.125943999652923-0.004321507456014)         new ArrayRealVector(new double 0.0585157215728210.0102001300577390.063516274916536-0.090696087449378-0.0171484204325970.991318870265707-0.034707338554096)         new ArrayRealVector(new double 0.8552059955375640.327134656629775-0.2653823970605480.2826907290267060.105736068025572-0.0091381266220390.000367751821196)         new ArrayRealVector(new double -0.002913069901144-0.0051775157771010.041906334478672-0.1093159184162580.4361923054567410.0263073156395350.891797507436344)         new ArrayRealVector(new double -0.005738311176435-0.0102076116703780.082662420517928-0.2157338860943680.861606487840411-0.025478530652759-0.451080697503958)         ;          // the following line triggers the exception         EigenDecomposition decomposition =             new EigenDecompositionImpl(mainTridiagonal secondaryTridiagonal MathUtils.SAFE_MIN);          double eigenValues = decomposition.getRealEigenvalues();         for (int i = 0; i < refEigenValues.length; ++i)              assertEquals(refEigenValuesi eigenValuesi 1.0e-3);             if (refEigenVectorsi.dotProduct(decomposition.getEigenvector(i)) < 0)                  assertEquals(0 refEigenVectorsi.add(decomposition.getEigenvector(i)).getNorm() 1.0e-5);              else                  assertEquals(0 refEigenVectorsi.subtract(decomposition.getEigenvector(i)).getNorm() 1.0e-5);                            ", "A_clean_title": ["wrong", "result", "eigen", "decompositionsom", "decomposit", "some", "result", "comput", "by", "eigendecompositionimpl", "eigen", "decomposit", "impl", "are", "wrong", "follow", "case", "comput", "by", "fortran", "lapack", "fail", "version", "public", "void", "testmathpbx02", "test", "mathpbx02", "doubl", "maintridiagon", "main", "tridiagon", "7484", "860960227216", "18405", "28129035345", "13855", "225609560746", "10016", "708722343366", "559", "8117399576674", "6750", "190788301587", "71", "21428769782159", "doubl", "secondarytridiagon", "secondari", "tridiagon", "4175", "0885704763661975", "79558582419945193", "178422374075", "1995", "28665916917975", "34535882933804", "234", "0808002076056", "refer", "valu", "have", "been", "comput", "routin", "dstemr", "fortran", "librari", "lapack", "version", "doubl", "refeigenvalu", "ref", "eigen", "valu", "20654", "74489030697441216828", "208208485466457", "6893", "1559126349948206757", "083016675340332", "5887", "79988568855878864", "309089923240379", "57", "992628792736340", "realvector", "real", "vector", "refeigenvector", "ref", "eigen", "vector", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "270356342026904", "852811091326997", "399639490702077", "198794657813990", "019739323307666", "000106983022327", "000001216636321", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "179995273578326", "4028078481530420", "7018709935257340", "5550582110148880", "0680791488982360", "000509139115227", "000007112235617", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "399582721284727", "056629954519333", "5144064885228270", "7111681645185800", "2255480812763670", "125943999652923", "004321507456014", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "0585157215728210", "0102001300577390", "063516274916536", "090696087449378", "0171484204325970", "991318870265707", "034707338554096", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "8552059955375640", "327134656629775", "2653823970605480", "2826907290267060", "105736068025572", "0091381266220390", "000367751821196", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "002913069901144", "0051775157771010", "041906334478672", "1093159184162580", "4361923054567410", "0263073156395350", "891797507436344", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "005738311176435", "0102076116703780", "082662420517928", "2157338860943680", "861606487840411", "025478530652759", "451080697503958", "follow", "line", "trigger", "except", "eigendecomposit", "eigen", "decomposit", "decomposit", "new", "eigendecompositionimpl", "eigen", "decomposit", "impl", "maintridiagon", "main", "tridiagon", "secondarytridiagon", "secondari", "tridiagon", "mathutil", "math", "util", "safe", "min", "doubl", "eigenvalu", "eigen", "valu", "decomposit", "getrealeigenvalu", "get", "real", "eigenvalu", "int", "refeigenvalu", "length", "ref", "eigen", "valu", "++i", "assertequ", "assert", "equal", "refeigenvaluesi", "ref", "eigen", "valuesi", "eigenvaluesi", "eigen", "valuesi", "0e", "refeigenvectorsi", "dotproduct", "ref", "eigen", "vectorsi", "dot", "product", "decomposit", "geteigenvector", "get", "eigenvector", "assertequ", "assert", "equal", "refeigenvectorsi", "add", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e", "assertequ", "assert", "equal", "refeigenvectorsi", "subtract", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e"], "B_title": "Fixed a bug in EigenDecompositionImpl . flipIfWarranted ( ) .. ", "B_clean_title": ["fix", "bug", "eigendecompositionimpl", "eigen", "decomposit", "impl", "flipifwarr", "flip", "warrant"]},
{"A_title": "wrong result in eigen decompositionSome results computed by EigenDecompositionImpl are wrong. The following case computed by Fortran Lapack fails with version 2.0      public void testMathpbx02()           double mainTridiagonal =            7484.860960227216 18405.28129035345 13855.225609560746          10016.708722343366 559.8117399576674 6750.190788301587              71.21428769782159         ;         double secondaryTridiagonal =           -4175.0885704763661975.79558582419945193.178422374075            1995.28665916917975.34535882933804-234.0808002076056         ;          // the reference values have been computed using routine DSTEMR         // from the fortran library LAPACK version 3.2.1         double refEigenValues =          20654.74489030697441216828.208208485466457         6893.1559126349948206757.083016675340332         5887.79988568855878864.309089923240379         57.992628792736340         ;         RealVector refEigenVectors =          new ArrayRealVector(new double -0.270356342026904 0.852811091326997 0.399639490702077 0.198794657813990 0.019739323307666 0.000106983022327 -0.000001216636321)         new ArrayRealVector(new double 0.179995273578326-0.4028078481530420.7018709935257340.5550582110148880.0680791488982360.000509139115227-0.000007112235617)         new ArrayRealVector(new double -0.399582721284727-0.056629954519333-0.5144064885228270.7111681645185800.2255480812763670.125943999652923-0.004321507456014)         new ArrayRealVector(new double 0.0585157215728210.0102001300577390.063516274916536-0.090696087449378-0.0171484204325970.991318870265707-0.034707338554096)         new ArrayRealVector(new double 0.8552059955375640.327134656629775-0.2653823970605480.2826907290267060.105736068025572-0.0091381266220390.000367751821196)         new ArrayRealVector(new double -0.002913069901144-0.0051775157771010.041906334478672-0.1093159184162580.4361923054567410.0263073156395350.891797507436344)         new ArrayRealVector(new double -0.005738311176435-0.0102076116703780.082662420517928-0.2157338860943680.861606487840411-0.025478530652759-0.451080697503958)         ;          // the following line triggers the exception         EigenDecomposition decomposition =             new EigenDecompositionImpl(mainTridiagonal secondaryTridiagonal MathUtils.SAFE_MIN);          double eigenValues = decomposition.getRealEigenvalues();         for (int i = 0; i < refEigenValues.length; ++i)              assertEquals(refEigenValuesi eigenValuesi 1.0e-3);             if (refEigenVectorsi.dotProduct(decomposition.getEigenvector(i)) < 0)                  assertEquals(0 refEigenVectorsi.add(decomposition.getEigenvector(i)).getNorm() 1.0e-5);              else                  assertEquals(0 refEigenVectorsi.subtract(decomposition.getEigenvector(i)).getNorm() 1.0e-5);                            ", "A_clean_title": ["wrong", "result", "eigen", "decompositionsom", "decomposit", "some", "result", "comput", "by", "eigendecompositionimpl", "eigen", "decomposit", "impl", "are", "wrong", "follow", "case", "comput", "by", "fortran", "lapack", "fail", "version", "public", "void", "testmathpbx02", "test", "mathpbx02", "doubl", "maintridiagon", "main", "tridiagon", "7484", "860960227216", "18405", "28129035345", "13855", "225609560746", "10016", "708722343366", "559", "8117399576674", "6750", "190788301587", "71", "21428769782159", "doubl", "secondarytridiagon", "secondari", "tridiagon", "4175", "0885704763661975", "79558582419945193", "178422374075", "1995", "28665916917975", "34535882933804", "234", "0808002076056", "refer", "valu", "have", "been", "comput", "routin", "dstemr", "fortran", "librari", "lapack", "version", "doubl", "refeigenvalu", "ref", "eigen", "valu", "20654", "74489030697441216828", "208208485466457", "6893", "1559126349948206757", "083016675340332", "5887", "79988568855878864", "309089923240379", "57", "992628792736340", "realvector", "real", "vector", "refeigenvector", "ref", "eigen", "vector", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "270356342026904", "852811091326997", "399639490702077", "198794657813990", "019739323307666", "000106983022327", "000001216636321", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "179995273578326", "4028078481530420", "7018709935257340", "5550582110148880", "0680791488982360", "000509139115227", "000007112235617", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "399582721284727", "056629954519333", "5144064885228270", "7111681645185800", "2255480812763670", "125943999652923", "004321507456014", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "0585157215728210", "0102001300577390", "063516274916536", "090696087449378", "0171484204325970", "991318870265707", "034707338554096", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "8552059955375640", "327134656629775", "2653823970605480", "2826907290267060", "105736068025572", "0091381266220390", "000367751821196", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "002913069901144", "0051775157771010", "041906334478672", "1093159184162580", "4361923054567410", "0263073156395350", "891797507436344", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "005738311176435", "0102076116703780", "082662420517928", "2157338860943680", "861606487840411", "025478530652759", "451080697503958", "follow", "line", "trigger", "except", "eigendecomposit", "eigen", "decomposit", "decomposit", "new", "eigendecompositionimpl", "eigen", "decomposit", "impl", "maintridiagon", "main", "tridiagon", "secondarytridiagon", "secondari", "tridiagon", "mathutil", "math", "util", "safe", "min", "doubl", "eigenvalu", "eigen", "valu", "decomposit", "getrealeigenvalu", "get", "real", "eigenvalu", "int", "refeigenvalu", "length", "ref", "eigen", "valu", "++i", "assertequ", "assert", "equal", "refeigenvaluesi", "ref", "eigen", "valuesi", "eigenvaluesi", "eigen", "valuesi", "0e", "refeigenvectorsi", "dotproduct", "ref", "eigen", "vectorsi", "dot", "product", "decomposit", "geteigenvector", "get", "eigenvector", "assertequ", "assert", "equal", "refeigenvectorsi", "add", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e", "assertequ", "assert", "equal", "refeigenvectorsi", "subtract", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e"], "B_title": "Fixed a bug in EigenDecompositionImpl . flipIfWarranted ( ) .. ", "B_clean_title": ["fix", "bug", "eigendecompositionimpl", "eigen", "decomposit", "impl", "flipifwarr", "flip", "warrant"]},
{"A_title": "wrong result in eigen decompositionSome results computed by EigenDecompositionImpl are wrong. The following case computed by Fortran Lapack fails with version 2.0      public void testMathpbx02()           double mainTridiagonal =            7484.860960227216 18405.28129035345 13855.225609560746          10016.708722343366 559.8117399576674 6750.190788301587              71.21428769782159         ;         double secondaryTridiagonal =           -4175.0885704763661975.79558582419945193.178422374075            1995.28665916917975.34535882933804-234.0808002076056         ;          // the reference values have been computed using routine DSTEMR         // from the fortran library LAPACK version 3.2.1         double refEigenValues =          20654.74489030697441216828.208208485466457         6893.1559126349948206757.083016675340332         5887.79988568855878864.309089923240379         57.992628792736340         ;         RealVector refEigenVectors =          new ArrayRealVector(new double -0.270356342026904 0.852811091326997 0.399639490702077 0.198794657813990 0.019739323307666 0.000106983022327 -0.000001216636321)         new ArrayRealVector(new double 0.179995273578326-0.4028078481530420.7018709935257340.5550582110148880.0680791488982360.000509139115227-0.000007112235617)         new ArrayRealVector(new double -0.399582721284727-0.056629954519333-0.5144064885228270.7111681645185800.2255480812763670.125943999652923-0.004321507456014)         new ArrayRealVector(new double 0.0585157215728210.0102001300577390.063516274916536-0.090696087449378-0.0171484204325970.991318870265707-0.034707338554096)         new ArrayRealVector(new double 0.8552059955375640.327134656629775-0.2653823970605480.2826907290267060.105736068025572-0.0091381266220390.000367751821196)         new ArrayRealVector(new double -0.002913069901144-0.0051775157771010.041906334478672-0.1093159184162580.4361923054567410.0263073156395350.891797507436344)         new ArrayRealVector(new double -0.005738311176435-0.0102076116703780.082662420517928-0.2157338860943680.861606487840411-0.025478530652759-0.451080697503958)         ;          // the following line triggers the exception         EigenDecomposition decomposition =             new EigenDecompositionImpl(mainTridiagonal secondaryTridiagonal MathUtils.SAFE_MIN);          double eigenValues = decomposition.getRealEigenvalues();         for (int i = 0; i < refEigenValues.length; ++i)              assertEquals(refEigenValuesi eigenValuesi 1.0e-3);             if (refEigenVectorsi.dotProduct(decomposition.getEigenvector(i)) < 0)                  assertEquals(0 refEigenVectorsi.add(decomposition.getEigenvector(i)).getNorm() 1.0e-5);              else                  assertEquals(0 refEigenVectorsi.subtract(decomposition.getEigenvector(i)).getNorm() 1.0e-5);                            ", "A_clean_title": ["wrong", "result", "eigen", "decompositionsom", "decomposit", "some", "result", "comput", "by", "eigendecompositionimpl", "eigen", "decomposit", "impl", "are", "wrong", "follow", "case", "comput", "by", "fortran", "lapack", "fail", "version", "public", "void", "testmathpbx02", "test", "mathpbx02", "doubl", "maintridiagon", "main", "tridiagon", "7484", "860960227216", "18405", "28129035345", "13855", "225609560746", "10016", "708722343366", "559", "8117399576674", "6750", "190788301587", "71", "21428769782159", "doubl", "secondarytridiagon", "secondari", "tridiagon", "4175", "0885704763661975", "79558582419945193", "178422374075", "1995", "28665916917975", "34535882933804", "234", "0808002076056", "refer", "valu", "have", "been", "comput", "routin", "dstemr", "fortran", "librari", "lapack", "version", "doubl", "refeigenvalu", "ref", "eigen", "valu", "20654", "74489030697441216828", "208208485466457", "6893", "1559126349948206757", "083016675340332", "5887", "79988568855878864", "309089923240379", "57", "992628792736340", "realvector", "real", "vector", "refeigenvector", "ref", "eigen", "vector", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "270356342026904", "852811091326997", "399639490702077", "198794657813990", "019739323307666", "000106983022327", "000001216636321", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "179995273578326", "4028078481530420", "7018709935257340", "5550582110148880", "0680791488982360", "000509139115227", "000007112235617", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "399582721284727", "056629954519333", "5144064885228270", "7111681645185800", "2255480812763670", "125943999652923", "004321507456014", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "0585157215728210", "0102001300577390", "063516274916536", "090696087449378", "0171484204325970", "991318870265707", "034707338554096", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "8552059955375640", "327134656629775", "2653823970605480", "2826907290267060", "105736068025572", "0091381266220390", "000367751821196", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "002913069901144", "0051775157771010", "041906334478672", "1093159184162580", "4361923054567410", "0263073156395350", "891797507436344", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "005738311176435", "0102076116703780", "082662420517928", "2157338860943680", "861606487840411", "025478530652759", "451080697503958", "follow", "line", "trigger", "except", "eigendecomposit", "eigen", "decomposit", "decomposit", "new", "eigendecompositionimpl", "eigen", "decomposit", "impl", "maintridiagon", "main", "tridiagon", "secondarytridiagon", "secondari", "tridiagon", "mathutil", "math", "util", "safe", "min", "doubl", "eigenvalu", "eigen", "valu", "decomposit", "getrealeigenvalu", "get", "real", "eigenvalu", "int", "refeigenvalu", "length", "ref", "eigen", "valu", "++i", "assertequ", "assert", "equal", "refeigenvaluesi", "ref", "eigen", "valuesi", "eigenvaluesi", "eigen", "valuesi", "0e", "refeigenvectorsi", "dotproduct", "ref", "eigen", "vectorsi", "dot", "product", "decomposit", "geteigenvector", "get", "eigenvector", "assertequ", "assert", "equal", "refeigenvectorsi", "add", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e", "assertequ", "assert", "equal", "refeigenvectorsi", "subtract", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e"], "B_title": "Fixed a bug in EigenDecompositionImpl . java. ", "B_clean_title": ["fix", "bug", "eigendecompositionimpl", "eigen", "decomposit", "impl", "java"]},
{"A_title": "wrong result in eigen decompositionSome results computed by EigenDecompositionImpl are wrong. The following case computed by Fortran Lapack fails with version 2.0      public void testMathpbx02()           double mainTridiagonal =            7484.860960227216 18405.28129035345 13855.225609560746          10016.708722343366 559.8117399576674 6750.190788301587              71.21428769782159         ;         double secondaryTridiagonal =           -4175.0885704763661975.79558582419945193.178422374075            1995.28665916917975.34535882933804-234.0808002076056         ;          // the reference values have been computed using routine DSTEMR         // from the fortran library LAPACK version 3.2.1         double refEigenValues =          20654.74489030697441216828.208208485466457         6893.1559126349948206757.083016675340332         5887.79988568855878864.309089923240379         57.992628792736340         ;         RealVector refEigenVectors =          new ArrayRealVector(new double -0.270356342026904 0.852811091326997 0.399639490702077 0.198794657813990 0.019739323307666 0.000106983022327 -0.000001216636321)         new ArrayRealVector(new double 0.179995273578326-0.4028078481530420.7018709935257340.5550582110148880.0680791488982360.000509139115227-0.000007112235617)         new ArrayRealVector(new double -0.399582721284727-0.056629954519333-0.5144064885228270.7111681645185800.2255480812763670.125943999652923-0.004321507456014)         new ArrayRealVector(new double 0.0585157215728210.0102001300577390.063516274916536-0.090696087449378-0.0171484204325970.991318870265707-0.034707338554096)         new ArrayRealVector(new double 0.8552059955375640.327134656629775-0.2653823970605480.2826907290267060.105736068025572-0.0091381266220390.000367751821196)         new ArrayRealVector(new double -0.002913069901144-0.0051775157771010.041906334478672-0.1093159184162580.4361923054567410.0263073156395350.891797507436344)         new ArrayRealVector(new double -0.005738311176435-0.0102076116703780.082662420517928-0.2157338860943680.861606487840411-0.025478530652759-0.451080697503958)         ;          // the following line triggers the exception         EigenDecomposition decomposition =             new EigenDecompositionImpl(mainTridiagonal secondaryTridiagonal MathUtils.SAFE_MIN);          double eigenValues = decomposition.getRealEigenvalues();         for (int i = 0; i < refEigenValues.length; ++i)              assertEquals(refEigenValuesi eigenValuesi 1.0e-3);             if (refEigenVectorsi.dotProduct(decomposition.getEigenvector(i)) < 0)                  assertEquals(0 refEigenVectorsi.add(decomposition.getEigenvector(i)).getNorm() 1.0e-5);              else                  assertEquals(0 refEigenVectorsi.subtract(decomposition.getEigenvector(i)).getNorm() 1.0e-5);                            ", "A_clean_title": ["wrong", "result", "eigen", "decompositionsom", "decomposit", "some", "result", "comput", "by", "eigendecompositionimpl", "eigen", "decomposit", "impl", "are", "wrong", "follow", "case", "comput", "by", "fortran", "lapack", "fail", "version", "public", "void", "testmathpbx02", "test", "mathpbx02", "doubl", "maintridiagon", "main", "tridiagon", "7484", "860960227216", "18405", "28129035345", "13855", "225609560746", "10016", "708722343366", "559", "8117399576674", "6750", "190788301587", "71", "21428769782159", "doubl", "secondarytridiagon", "secondari", "tridiagon", "4175", "0885704763661975", "79558582419945193", "178422374075", "1995", "28665916917975", "34535882933804", "234", "0808002076056", "refer", "valu", "have", "been", "comput", "routin", "dstemr", "fortran", "librari", "lapack", "version", "doubl", "refeigenvalu", "ref", "eigen", "valu", "20654", "74489030697441216828", "208208485466457", "6893", "1559126349948206757", "083016675340332", "5887", "79988568855878864", "309089923240379", "57", "992628792736340", "realvector", "real", "vector", "refeigenvector", "ref", "eigen", "vector", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "270356342026904", "852811091326997", "399639490702077", "198794657813990", "019739323307666", "000106983022327", "000001216636321", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "179995273578326", "4028078481530420", "7018709935257340", "5550582110148880", "0680791488982360", "000509139115227", "000007112235617", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "399582721284727", "056629954519333", "5144064885228270", "7111681645185800", "2255480812763670", "125943999652923", "004321507456014", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "0585157215728210", "0102001300577390", "063516274916536", "090696087449378", "0171484204325970", "991318870265707", "034707338554096", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "8552059955375640", "327134656629775", "2653823970605480", "2826907290267060", "105736068025572", "0091381266220390", "000367751821196", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "002913069901144", "0051775157771010", "041906334478672", "1093159184162580", "4361923054567410", "0263073156395350", "891797507436344", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "005738311176435", "0102076116703780", "082662420517928", "2157338860943680", "861606487840411", "025478530652759", "451080697503958", "follow", "line", "trigger", "except", "eigendecomposit", "eigen", "decomposit", "decomposit", "new", "eigendecompositionimpl", "eigen", "decomposit", "impl", "maintridiagon", "main", "tridiagon", "secondarytridiagon", "secondari", "tridiagon", "mathutil", "math", "util", "safe", "min", "doubl", "eigenvalu", "eigen", "valu", "decomposit", "getrealeigenvalu", "get", "real", "eigenvalu", "int", "refeigenvalu", "length", "ref", "eigen", "valu", "++i", "assertequ", "assert", "equal", "refeigenvaluesi", "ref", "eigen", "valuesi", "eigenvaluesi", "eigen", "valuesi", "0e", "refeigenvectorsi", "dotproduct", "ref", "eigen", "vectorsi", "dot", "product", "decomposit", "geteigenvector", "get", "eigenvector", "assertequ", "assert", "equal", "refeigenvectorsi", "add", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e", "assertequ", "assert", "equal", "refeigenvectorsi", "subtract", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e"], "B_title": "Fixed a bug in EigenDecompositionImpl . java. ", "B_clean_title": ["fix", "bug", "eigendecompositionimpl", "eigen", "decomposit", "impl", "java"]},
{"A_title": "BSPTree class and recovery of a Euclidean 3D BRepNew to the work here. Thanks for your efforts on this code. I create a BSPTree from a BoundaryRep (Brep) my test Brep is a cube as represented by a float array containing 8 3D points in(xyz) order and an array of indices (12 triplets for the 12 faces of the cube). I construct a BSPMesh() as shown in the code below. I can construct the PolyhedronsSet() but have problems extracting the faces from the BSPTree to reconstruct the BRep. The attached code (BSPMesh2.java) shows that a small change to 1 of the vertex positions causes/corrects the problem. Any ideas?", "A_clean_title": ["bsptree", "bsp", "tree", "class", "recoveri", "euclidean", "3d", "brepnew", "rep", "new", "work", "here", "thank", "your", "effort", "thi", "code", "creat", "bsptree", "bsp", "tree", "boundaryrep", "boundari", "rep", "brep", "my", "test", "brep", "cube", "as", "repres", "by", "float", "array", "contain", "3d", "point", "xyz", "order", "array", "indic", "12", "triplet", "12", "face", "cube", "construct", "bspmesh", "bsp", "mesh", "as", "shown", "code", "below", "construct", "polyhedronsset", "polyhedron", "set", "but", "have", "problem", "extract", "face", "bsptree", "bsp", "tree", "reconstruct", "brep", "rep", "attach", "code", "bspmesh2", "java", "bsp", "mesh2", "show", "that", "small", "chang", "vertex", "posit", "caus", "correct", "problem", "ani", "idea"], "B_title": "removed debug code. ", "B_clean_title": ["remov", "debug", "code"]},
{"A_title": "FastDateParser does not handle white-space properlyThe SimpleDateFormat Javadoc does not treat white-space specially however FastDateParser treats a single white-space as being any number of white-space characters. This means that FDP will parse dates that fail when parsed by SDP.", "A_clean_title": ["fastdatepars", "fast", "date", "parser", "not", "handl", "white", "space", "properlyth", "properli", "simpledateformat", "simpl", "date", "format", "javadoc", "not", "treat", "white", "space", "special", "howev", "fastdatepars", "fast", "date", "parser", "treat", "singl", "white", "space", "as", "be", "ani", "number", "white", "space", "charact", "thi", "mean", "that", "fdp", "will", "pars", "date", "that", "fail", "when", "pars", "by", "sdp"], "B_title": "I don  t really see a justification for doing a whitespace in a string ( changed by the. ", "B_clean_title": ["don", "realli", "see", "justif", "do", "whitespac", "string", "chang", "by"]},
{"A_title": "FastDateParser does not handle white-space properlyThe SimpleDateFormat Javadoc does not treat white-space specially however FastDateParser treats a single white-space as being any number of white-space characters. This means that FDP will parse dates that fail when parsed by SDP.", "A_clean_title": ["fastdatepars", "fast", "date", "parser", "not", "handl", "white", "space", "properlyth", "properli", "simpledateformat", "simpl", "date", "format", "javadoc", "not", "treat", "white", "space", "special", "howev", "fastdatepars", "fast", "date", "parser", "treat", "singl", "white", "space", "as", "be", "ani", "number", "white", "space", "charact", "thi", "mean", "that", "fdp", "will", "pars", "date", "that", "fail", "when", "pars", "by", "sdp"], "B_title": "Remove redundant check. ", "B_clean_title": ["remov", "redund", "check"]},
{"A_title": "FastDateParser does not handle white-space properlyThe SimpleDateFormat Javadoc does not treat white-space specially however FastDateParser treats a single white-space as being any number of white-space characters. This means that FDP will parse dates that fail when parsed by SDP.", "A_clean_title": ["fastdatepars", "fast", "date", "parser", "not", "handl", "white", "space", "properlyth", "properli", "simpledateformat", "simpl", "date", "format", "javadoc", "not", "treat", "white", "space", "special", "howev", "fastdatepars", "fast", "date", "parser", "treat", "singl", "white", "space", "as", "be", "ani", "number", "white", "space", "charact", "thi", "mean", "that", "fdp", "will", "pars", "date", "that", "fail", "when", "pars", "by", "sdp"], "B_title": "FastDateParser ignores white space. ", "B_clean_title": ["fastdatepars", "fast", "date", "parser", "ignor", "white", "space"]},
{"A_title": "FastDateParser does not handle white-space properlyThe SimpleDateFormat Javadoc does not treat white-space specially however FastDateParser treats a single white-space as being any number of white-space characters. This means that FDP will parse dates that fail when parsed by SDP.", "A_clean_title": ["fastdatepars", "fast", "date", "parser", "not", "handl", "white", "space", "properlyth", "properli", "simpledateformat", "simpl", "date", "format", "javadoc", "not", "treat", "white", "space", "special", "howev", "fastdatepars", "fast", "date", "parser", "treat", "singl", "white", "space", "as", "be", "ani", "number", "white", "space", "charact", "thi", "mean", "that", "fdp", "will", "pars", "date", "that", "fail", "when", "pars", "by", "sdp"], "B_title": "FastDateParser copy ( ) didn  t ignore whitespace in date parsing. ", "B_clean_title": ["fastdatepars", "fast", "date", "parser", "copi", "didn", "ignor", "whitespac", "date", "pars"]},
{"A_title": "FastDateParser does not handle white-space properlyThe SimpleDateFormat Javadoc does not treat white-space specially however FastDateParser treats a single white-space as being any number of white-space characters. This means that FDP will parse dates that fail when parsed by SDP.", "A_clean_title": ["fastdatepars", "fast", "date", "parser", "not", "handl", "white", "space", "properlyth", "properli", "simpledateformat", "simpl", "date", "format", "javadoc", "not", "treat", "white", "space", "special", "howev", "fastdatepars", "fast", "date", "parser", "treat", "singl", "white", "space", "as", "be", "ani", "number", "white", "space", "charact", "thi", "mean", "that", "fdp", "will", "pars", "date", "that", "fail", "when", "pars", "by", "sdp"], "B_title": "don  t backslash backslash in regex so it won  t be backslashed. ", "B_clean_title": ["don", "backslash", "backslash", "regex", "so", "it", "won", "backslash"]},
{"A_title": "FastDateFormat getDateInstance() and getDateTimeInstance() assume Locale.getDefault() wont changeThe FastDateFormat getDateInstance() and getDateTimeInstance()  methods create the HashMap key from various items including the locale. If the locale is null then it is not made part of the key but the stored object is created using the current default locale. If the Locale is changed subsequently then the wrong locale is applied. Patch for test case to follow.", "A_clean_title": ["fastdateformat", "fast", "date", "format", "getdateinst", "get", "date", "instanc", "getdatetimeinst", "get", "date", "time", "instanc", "assum", "local", "getdefault", "get", "default", "wont", "changeth", "chang", "fastdateformat", "fast", "date", "format", "getdateinst", "get", "date", "instanc", "getdatetimeinst", "get", "date", "time", "instanc", "method", "creat", "hashmap", "hash", "map", "key", "variou", "item", "includ", "local", "local", "null", "then", "it", "not", "made", "part", "key", "but", "store", "object", "creat", "current", "default", "local", "local", "chang", "subsequ", "then", "wrong", "local", "appli", "patch", "test", "case", "follow"], "B_title": "Fix FastDateFormat  s key value if locale is not null. Fix getLocaleKey exception in FastDateFormat. ", "B_clean_title": ["fix", "fastdateformat", "fast", "date", "format", "key", "valu", "local", "not", "null", "fix", "getlocalekey", "get", "local", "key", "except", "fastdateformat", "fast", "date", "format"]},
{"A_title": "NPE in  KMeansPlusPlusClusterer unittestWhen running this unittest I am facing this NPE: java.lang.NullPointerException at org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer.assignPointsToClusters(KMeansPlusPlusClusterer.java:91) This is the unittest: package org.fao.fisheries.chronicles.calcuation.cluster; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertTrue; import java.util.Arrays; import java.util.List; import java.util.Random; import org.apache.commons.math.stat.clustering.Cluster; import org.apache.commons.math.stat.clustering.EuclideanIntegerPoint; import org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer; import org.fao.fisheries.chronicles.input.CsvImportProcess; import org.fao.fisheries.chronicles.input.Top200Csv; import org.junit.Test; public class ClusterAnalysisTest  @Test public void testPerformClusterAnalysis2()  KMeansPlusPlusClusterer<EuclideanIntegerPoint> transformer = new KMeansPlusPlusClusterer<EuclideanIntegerPoint>( new Random(1746432956321l)); EuclideanIntegerPoint points = new EuclideanIntegerPoint  new EuclideanIntegerPoint(new int   1959 325100  ) new EuclideanIntegerPoint(new int   1960 373200  ) ; List<Cluster<EuclideanIntegerPoint>> clusters = transformer.cluster(Arrays.asList(points) 1 1); assertEquals(1 clusters.size());  ", "A_clean_title": ["npe", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "unittestwhen", "unittest", "when", "run", "thi", "unittest", "am", "face", "thi", "npe", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "common", "math", "stat", "cluster", "kmeanspluspluscluster", "assignpointstoclust", "mean", "plu", "plu", "cluster", "assign", "point", "cluster", "kmeanspluspluscluster", "java:91", "mean", "plu", "plu", "cluster", "thi", "unittest", "packag", "org", "fao", "fisheri", "chronicl", "calcuat", "cluster", "import", "static", "org", "junit", "assert", "assertequ", "assert", "equal", "import", "static", "org", "junit", "assert", "asserttru", "assert", "true", "import", "java", "util", "array", "import", "java", "util", "list", "import", "java", "util", "random", "import", "org", "apach", "common", "math", "stat", "cluster", "cluster", "import", "org", "apach", "common", "math", "stat", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "import", "org", "apach", "common", "math", "stat", "cluster", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "import", "org", "fao", "fisheri", "chronicl", "input", "csvimportprocess", "csv", "import", "process", "import", "org", "fao", "fisheri", "chronicl", "input", "top200csv", "import", "org", "junit", "test", "public", "class", "clusteranalysistest", "cluster", "analysi", "test", "test", "public", "void", "testperformclusteranalysis2", "test", "perform", "cluster", "analysis2", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "transform", "new", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "random", "1746432956321l", "euclideanintegerpoint", "euclidean", "integ", "point", "point", "new", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "int", "1959", "325100", "new", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "int", "1960", "373200", "list", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "cluster", "transform", "cluster", "array", "aslist", "as", "list", "point", "assertequ", "assert", "equal", "cluster", "size"], "B_title": "Fix MathUtils . distance ( )  reported by Marin Dzhigarov .. ", "B_clean_title": ["fix", "mathutil", "math", "util", "distanc", "report", "by", "marin", "dzhigarov"]},
{"A_title": "NPE in  KMeansPlusPlusClusterer unittestWhen running this unittest I am facing this NPE: java.lang.NullPointerException at org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer.assignPointsToClusters(KMeansPlusPlusClusterer.java:91) This is the unittest: package org.fao.fisheries.chronicles.calcuation.cluster; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertTrue; import java.util.Arrays; import java.util.List; import java.util.Random; import org.apache.commons.math.stat.clustering.Cluster; import org.apache.commons.math.stat.clustering.EuclideanIntegerPoint; import org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer; import org.fao.fisheries.chronicles.input.CsvImportProcess; import org.fao.fisheries.chronicles.input.Top200Csv; import org.junit.Test; public class ClusterAnalysisTest  @Test public void testPerformClusterAnalysis2()  KMeansPlusPlusClusterer<EuclideanIntegerPoint> transformer = new KMeansPlusPlusClusterer<EuclideanIntegerPoint>( new Random(1746432956321l)); EuclideanIntegerPoint points = new EuclideanIntegerPoint  new EuclideanIntegerPoint(new int   1959 325100  ) new EuclideanIntegerPoint(new int   1960 373200  ) ; List<Cluster<EuclideanIntegerPoint>> clusters = transformer.cluster(Arrays.asList(points) 1 1); assertEquals(1 clusters.size());  ", "A_clean_title": ["npe", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "unittestwhen", "unittest", "when", "run", "thi", "unittest", "am", "face", "thi", "npe", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "common", "math", "stat", "cluster", "kmeanspluspluscluster", "assignpointstoclust", "mean", "plu", "plu", "cluster", "assign", "point", "cluster", "kmeanspluspluscluster", "java:91", "mean", "plu", "plu", "cluster", "thi", "unittest", "packag", "org", "fao", "fisheri", "chronicl", "calcuat", "cluster", "import", "static", "org", "junit", "assert", "assertequ", "assert", "equal", "import", "static", "org", "junit", "assert", "asserttru", "assert", "true", "import", "java", "util", "array", "import", "java", "util", "list", "import", "java", "util", "random", "import", "org", "apach", "common", "math", "stat", "cluster", "cluster", "import", "org", "apach", "common", "math", "stat", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "import", "org", "apach", "common", "math", "stat", "cluster", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "import", "org", "fao", "fisheri", "chronicl", "input", "csvimportprocess", "csv", "import", "process", "import", "org", "fao", "fisheri", "chronicl", "input", "top200csv", "import", "org", "junit", "test", "public", "class", "clusteranalysistest", "cluster", "analysi", "test", "test", "public", "void", "testperformclusteranalysis2", "test", "perform", "cluster", "analysis2", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "transform", "new", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "random", "1746432956321l", "euclideanintegerpoint", "euclidean", "integ", "point", "point", "new", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "int", "1959", "325100", "new", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "int", "1960", "373200", "list", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "cluster", "transform", "cluster", "array", "aslist", "as", "list", "point", "assertequ", "assert", "equal", "cluster", "size"], "B_title": "removed int because it wasn  t working as expected. ", "B_clean_title": ["remov", "int", "becaus", "it", "wasn", "work", "as", "expect"]},
{"A_title": "NPE in DateTimeZoneBuilderWhen a DateTimeZone is build with duplicate-named recurring saving time in a first thread all goes Ok: a warning message is generated and an identifier is automatically generated in PrecalculatedZone.create(). When a second thread does the same an NPE is generated in ZoneInfoCompiler.verbose().  The cause is that the cVerbose ThreadLocal is incorrectly initialized in ZoneInfoCompiler ...will initialize cVerbose only for the first thread and not for the subsequent ones. The NPE is caused by the autoboxing in: . A better approach could be to remove the initialization and test for null:", "A_clean_title": ["npe", "datetimezonebuilderwhen", "date", "time", "zone", "builder", "when", "datetimezon", "date", "time", "zone", "build", "duplic", "name", "recur", "save", "time", "first", "thread", "all", "goe", "ok", "warn", "messag", "gener", "identifi", "automat", "gener", "precalculatedzon", "creat", "precalcul", "zone", "when", "second", "thread", "same", "npe", "gener", "zoneinfocompil", "verbos", "zone", "info", "compil", "caus", "that", "cverbos", "verbos", "threadloc", "thread", "local", "incorrectli", "initi", "zoneinfocompil", "zone", "info", "compil", "will", "initi", "cverbos", "verbos", "onli", "first", "thread", "not", "subsequ", "one", "npe", "caus", "by", "autobox", "better", "approach", "could", "remov", "initi", "test", "null"], "B_title": "Stops verbose output. ", "B_clean_title": ["stop", "verbos", "output"]},
{"A_title": "division by zero wrongly throws JSC_DIVIDE_BY_0_ERRORNone", "A_clean_title": ["divis", "by", "zero", "wrongli", "throw", "jsc", "divid", "by", "errornon", "error", "none"], "B_title": "disable division by zero check. disable division by zero check. ", "B_clean_title": ["disabl", "divis", "by", "zero", "check", "disabl", "divis", "by", "zero", "check"]},
{"A_title": "ArrayUtils.add(T array T element) can create unexpected ClassCastExceptionArrayUtils.add(T array T element) can create an unexpected ClassCastException. For example the following code compiles without a warning:  String sa = ArrayUtils.add(stringArray aString);   and works fine provided at least one of the parameters is non-null. However if both parameters are null the add() method returns an Object array hence the Exception. If both parameters are null its not possible to determine the correct array type to return so it seems to me this should be disallowed. I think the method ought to be changed to throw IllegalParameterException when both parameters are null.", "A_clean_title": ["arrayutil", "add", "array", "util", "array", "element", "creat", "unexpect", "classcastexceptionarrayutil", "add", "class", "cast", "except", "array", "util", "array", "element", "creat", "unexpect", "classcastexcept", "class", "cast", "except", "exampl", "follow", "code", "compil", "without", "warn", "string", "sa", "arrayutil", "add", "array", "util", "stringarray", "string", "array", "astr", "string", "work", "fine", "provid", "at", "least", "one", "paramet", "non", "null", "howev", "both", "paramet", "are", "null", "add", "method", "return", "object", "array", "henc", "except", "both", "paramet", "are", "null", "it", "not", "possibl", "determin", "correct", "array", "type", "return", "so", "it", "seem", "me", "thi", "disallow", "think", "method", "ought", "chang", "throw", "illegalparameterexcept", "illeg", "paramet", "except", "when", "both", "paramet", "are", "null"], "B_title": "Allow null to be stored in Java ArrayUtils. Allow null to be added to the array .. ", "B_clean_title": ["allow", "null", "store", "java", "arrayutil", "array", "util", "allow", "null", "ad", "array"]},
{"A_title": "NumberUtils.isNumber(String)  is not right when the String is 1.1L1.1L  is not a Java Number . but NumberUtils.isNumber(String) return true. perhaps change:              if (charsi == l                 || charsi == L)                  // not allowing L with an exponent                 return foundDigit && !hasExp;                to:              if (charsi == l                 || charsi == L)                  // not allowing L with an exponent                 return foundDigit && !hasExp && !hasDecPoint;             ", "A_clean_title": ["numberutil", "isnumb", "number", "util", "number", "string", "not", "right", "when", "string", "1l1", "1l", "not", "java", "number", "but", "numberutil", "isnumb", "number", "util", "number", "string", "return", "true", "perhap", "chang", "charsi", "charsi", "not", "allow", "expon", "return", "founddigit", "found", "digit", "hasexp", "ha", "exp", "charsi", "charsi", "not", "allow", "expon", "return", "founddigit", "found", "digit", "hasexp", "ha", "exp", "hasdecpoint", "ha", "dec", "point"], "B_title": "allow L with a decimal point. ", "B_clean_title": ["allow", "decim", "point"]},
{"A_title": "NumberUtils.isNumber(String)  is not right when the String is 1.1L1.1L  is not a Java Number . but NumberUtils.isNumber(String) return true. perhaps change:              if (charsi == l                 || charsi == L)                  // not allowing L with an exponent                 return foundDigit && !hasExp;                to:              if (charsi == l                 || charsi == L)                  // not allowing L with an exponent                 return foundDigit && !hasExp && !hasDecPoint;             ", "A_clean_title": ["numberutil", "isnumb", "number", "util", "number", "string", "not", "right", "when", "string", "1l1", "1l", "not", "java", "number", "but", "numberutil", "isnumb", "number", "util", "number", "string", "return", "true", "perhap", "chang", "charsi", "charsi", "not", "allow", "expon", "return", "founddigit", "found", "digit", "hasexp", "ha", "exp", "charsi", "charsi", "not", "allow", "expon", "return", "founddigit", "found", "digit", "hasexp", "ha", "exp", "hasdecpoint", "ha", "dec", "point"], "B_title": "Allow trailing commas in NumberUtils. ", "B_clean_title": ["allow", "trail", "comma", "numberutil", "number", "util"]},
{"A_title": "NumberUtils.isNumber(String)  is not right when the String is 1.1L1.1L  is not a Java Number . but NumberUtils.isNumber(String) return true. perhaps change:              if (charsi == l                 || charsi == L)                  // not allowing L with an exponent                 return foundDigit && !hasExp;                to:              if (charsi == l                 || charsi == L)                  // not allowing L with an exponent                 return foundDigit && !hasExp && !hasDecPoint;             ", "A_clean_title": ["numberutil", "isnumb", "number", "util", "number", "string", "not", "right", "when", "string", "1l1", "1l", "not", "java", "number", "but", "numberutil", "isnumb", "number", "util", "number", "string", "return", "true", "perhap", "chang", "charsi", "charsi", "not", "allow", "expon", "return", "founddigit", "found", "digit", "hasexp", "ha", "exp", "charsi", "charsi", "not", "allow", "expon", "return", "founddigit", "found", "digit", "hasexp", "ha", "exp", "hasdecpoint", "ha", "dec", "point"], "B_title": "Allow L with an exponent or decimal point. remove wrong java char. ", "B_clean_title": ["allow", "expon", "or", "decim", "point", "remov", "wrong", "java", "char"]},
{"A_title": "NumberUtils.isNumber(String)  is not right when the String is 1.1L1.1L  is not a Java Number . but NumberUtils.isNumber(String) return true. perhaps change:              if (charsi == l                 || charsi == L)                  // not allowing L with an exponent                 return foundDigit && !hasExp;                to:              if (charsi == l                 || charsi == L)                  // not allowing L with an exponent                 return foundDigit && !hasExp && !hasDecPoint;             ", "A_clean_title": ["numberutil", "isnumb", "number", "util", "number", "string", "not", "right", "when", "string", "1l1", "1l", "not", "java", "number", "but", "numberutil", "isnumb", "number", "util", "number", "string", "return", "true", "perhap", "chang", "charsi", "charsi", "not", "allow", "expon", "return", "founddigit", "found", "digit", "hasexp", "ha", "exp", "charsi", "charsi", "not", "allow", "expon", "return", "founddigit", "found", "digit", "hasexp", "ha", "exp", "hasdecpoint", "ha", "dec", "point"], "B_title": "Allow L with an exponent or decimal point. ", "B_clean_title": ["allow", "expon", "or", "decim", "point"]},
{"A_title": "Dependency sorting with closurePass set to false no longer works.None", "A_clean_title": ["depend", "sort", "closurepass", "closur", "pass", "set", "fals", "no", "longer", "work", "none"], "B_title": "remove 1287 from the closure pass condition. ", "B_clean_title": ["remov", "1287", "closur", "pass", "condit"]},
{"A_title": "Dependency sorting with closurePass set to false no longer works.None", "A_clean_title": ["depend", "sort", "closurepass", "closur", "pass", "set", "fals", "no", "longer", "work", "none"], "B_title": "Fix the  closure pass  flag in Compiler . java. ", "B_clean_title": ["fix", "closur", "pass", "flag", "compil", "java"]},
{"A_title": "Identifier minus a negative number needs a space between the -sNone", "A_clean_title": ["identifi", "minu", "neg", "number", "need", "space", "between", "snone", "none"], "B_title": "Improved javadoc comment .. ", "B_clean_title": ["improv", "javadoc", "comment"]},
{"A_title": "Identifier minus a negative number needs a space between the -sNone", "A_clean_title": ["identifi", "minu", "neg", "number", "need", "space", "between", "snone", "none"], "B_title": "Fix negative zero log in case of a - sign in JSON. ", "B_clean_title": ["fix", "neg", "zero", "log", "case", "sign", "json"]},
{"A_title": "Identifier minus a negative number needs a space between the -sNone", "A_clean_title": ["identifi", "minu", "neg", "number", "need", "space", "between", "snone", "none"], "B_title": "Fix whitespace in code consumer. ", "B_clean_title": ["fix", "whitespac", "code", "consum"]},
{"A_title": "Truncation issue in KMeansPlusPlusClustererThe for loop inside KMeansPlusPlusClusterer.chooseInitialClusters defines a variable   int sum = 0; This variable should have type double rather than int.  Using an int causes the method to truncate the distances between points to (square roots of) integers.  Its especially bad when the distances between points are typically less than 1. As an aside in version 2.2 this bug manifested itself by making the clusterer return empty clusters.  I wonder if the EmptyClusterStrategy would still be necessary if this bug were fixed.", "A_clean_title": ["truncat", "issu", "kmeansplusplusclustererth", "mean", "plu", "plu", "cluster", "loop", "insid", "kmeanspluspluscluster", "chooseinitialclust", "mean", "plu", "plu", "cluster", "choos", "initi", "cluster", "defin", "variabl", "int", "sum", "thi", "variabl", "have", "type", "doubl", "rather", "than", "int", "int", "caus", "method", "truncat", "distanc", "between", "point", "squar", "root", "integ", "it", "especi", "bad", "when", "distanc", "between", "point", "are", "typic", "less", "than", "as", "asid", "version", "thi", "bug", "manifest", "itself", "by", "make", "cluster", "return", "empti", "cluster", "wonder", "emptyclusterstrategi", "empti", "cluster", "strategi", "would", "still", "necessari", "thi", "bug", "were", "fix"], "B_title": "KMeansPlusPlusClusterer copy constructor. ", "B_clean_title": ["kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "copi", "constructor"]},
{"A_title": "FastDateFormat.format() outputs incorrect week of year because locale isnt respectedFastDateFormat apparently doesnt respect the locale it was sent on creation when outputting week in year (e.g. ww) in format(). It seems to use the settings of the system locale for firstDayOfWeek and minimalDaysInFirstWeek which (depending on the year) may result in the incorrect week number being output. Here is a simple test program to demonstrate the problem by comparing with SimpleDateFormat which gets the week number right:  import java.util.Calendar; import java.util.Date; import java.util.Locale; import java.text.SimpleDateFormat;  import org.apache.commons.lang.time.FastDateFormat;  public class FastDateFormatWeekBugDemo      public static void main(String args)          Locale.setDefault(new Locale(en US));         Locale locale = new Locale(sv SE);          Calendar cal = Calendar.getInstance(); // setting locale here doesnt change outcome         cal.set(2010 0 1 12 0 0);         Date d = cal.getTime();         System.out.println(Target date:  + d);          FastDateFormat fdf = FastDateFormat.getInstance(EEEE week ww locale);         SimpleDateFormat sdf = new SimpleDateFormat(EEEE week ww locale);         System.out.println(FastDateFormat:    + fdf.format(d)); // will output FastDateFormat:   fredag week 01         System.out.println(SimpleDateFormat:  + sdf.format(d)); // will output SimpleDateFormat: fredag week 53         If sv/SE is passed to Locale.setDefault() instead of en/US both FastDateFormat and SimpleDateFormat output the correct week number.", "A_clean_title": ["fastdateformat", "format", "fast", "date", "format", "output", "incorrect", "week", "year", "becaus", "local", "isnt", "respectedfastdateformat", "respect", "fast", "date", "format", "appar", "doesnt", "respect", "local", "it", "wa", "sent", "creation", "when", "output", "week", "year", "ww", "format", "it", "seem", "use", "set", "system", "local", "firstdayofweek", "first", "day", "week", "minimaldaysinfirstweek", "minim", "day", "first", "week", "which", "depend", "year", "may", "result", "incorrect", "week", "number", "be", "output", "here", "simpl", "test", "program", "demonstr", "problem", "by", "compar", "simpledateformat", "simpl", "date", "format", "which", "get", "week", "number", "right", "import", "java", "util", "calendar", "import", "java", "util", "date", "import", "java", "util", "local", "import", "java", "text", "simpledateformat", "simpl", "date", "format", "import", "org", "apach", "common", "lang", "time", "fastdateformat", "fast", "date", "format", "public", "class", "fastdateformatweekbugdemo", "fast", "date", "format", "week", "bug", "demo", "public", "static", "void", "main", "string", "arg", "local", "setdefault", "set", "default", "new", "local", "en", "us", "local", "local", "new", "local", "sv", "se", "calendar", "cal", "calendar", "getinst", "get", "instanc", "set", "local", "here", "doesnt", "chang", "outcom", "cal", "set", "2010", "12", "date", "cal", "gettim", "get", "time", "system", "out", "println", "target", "date", "fastdateformat", "fast", "date", "format", "fdf", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "eeee", "week", "ww", "local", "simpledateformat", "simpl", "date", "format", "sdf", "new", "simpledateformat", "simpl", "date", "format", "eeee", "week", "ww", "local", "system", "out", "println", "fastdateformat", "fast", "date", "format", "fdf", "format", "will", "output", "fastdateformat", "fast", "date", "format", "fredag", "week", "01", "system", "out", "println", "simpledateformat", "simpl", "date", "format", "sdf", "format", "will", "output", "simpledateformat", "simpl", "date", "format", "fredag", "week", "53", "sv", "se", "pass", "local", "setdefault", "set", "default", "instead", "en", "us", "both", "fastdateformat", "fast", "date", "format", "simpledateformat", "simpl", "date", "format", "output", "correct", "week", "number"], "B_title": "Missing locale argument. ", "B_clean_title": ["miss", "local", "argument"]},
{"A_title": "FastDateFormat.format() outputs incorrect week of year because locale isnt respectedFastDateFormat apparently doesnt respect the locale it was sent on creation when outputting week in year (e.g. ww) in format(). It seems to use the settings of the system locale for firstDayOfWeek and minimalDaysInFirstWeek which (depending on the year) may result in the incorrect week number being output. Here is a simple test program to demonstrate the problem by comparing with SimpleDateFormat which gets the week number right:  import java.util.Calendar; import java.util.Date; import java.util.Locale; import java.text.SimpleDateFormat;  import org.apache.commons.lang.time.FastDateFormat;  public class FastDateFormatWeekBugDemo      public static void main(String args)          Locale.setDefault(new Locale(en US));         Locale locale = new Locale(sv SE);          Calendar cal = Calendar.getInstance(); // setting locale here doesnt change outcome         cal.set(2010 0 1 12 0 0);         Date d = cal.getTime();         System.out.println(Target date:  + d);          FastDateFormat fdf = FastDateFormat.getInstance(EEEE week ww locale);         SimpleDateFormat sdf = new SimpleDateFormat(EEEE week ww locale);         System.out.println(FastDateFormat:    + fdf.format(d)); // will output FastDateFormat:   fredag week 01         System.out.println(SimpleDateFormat:  + sdf.format(d)); // will output SimpleDateFormat: fredag week 53         If sv/SE is passed to Locale.setDefault() instead of en/US both FastDateFormat and SimpleDateFormat output the correct week number.", "A_clean_title": ["fastdateformat", "format", "fast", "date", "format", "output", "incorrect", "week", "year", "becaus", "local", "isnt", "respectedfastdateformat", "respect", "fast", "date", "format", "appar", "doesnt", "respect", "local", "it", "wa", "sent", "creation", "when", "output", "week", "year", "ww", "format", "it", "seem", "use", "set", "system", "local", "firstdayofweek", "first", "day", "week", "minimaldaysinfirstweek", "minim", "day", "first", "week", "which", "depend", "year", "may", "result", "incorrect", "week", "number", "be", "output", "here", "simpl", "test", "program", "demonstr", "problem", "by", "compar", "simpledateformat", "simpl", "date", "format", "which", "get", "week", "number", "right", "import", "java", "util", "calendar", "import", "java", "util", "date", "import", "java", "util", "local", "import", "java", "text", "simpledateformat", "simpl", "date", "format", "import", "org", "apach", "common", "lang", "time", "fastdateformat", "fast", "date", "format", "public", "class", "fastdateformatweekbugdemo", "fast", "date", "format", "week", "bug", "demo", "public", "static", "void", "main", "string", "arg", "local", "setdefault", "set", "default", "new", "local", "en", "us", "local", "local", "new", "local", "sv", "se", "calendar", "cal", "calendar", "getinst", "get", "instanc", "set", "local", "here", "doesnt", "chang", "outcom", "cal", "set", "2010", "12", "date", "cal", "gettim", "get", "time", "system", "out", "println", "target", "date", "fastdateformat", "fast", "date", "format", "fdf", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "eeee", "week", "ww", "local", "simpledateformat", "simpl", "date", "format", "sdf", "new", "simpledateformat", "simpl", "date", "format", "eeee", "week", "ww", "local", "system", "out", "println", "fastdateformat", "fast", "date", "format", "fdf", "format", "will", "output", "fastdateformat", "fast", "date", "format", "fredag", "week", "01", "system", "out", "println", "simpledateformat", "simpl", "date", "format", "sdf", "format", "will", "output", "simpledateformat", "simpl", "date", "format", "fredag", "week", "53", "sv", "se", "pass", "local", "setdefault", "set", "default", "instead", "en", "us", "both", "fastdateformat", "fast", "date", "format", "simpledateformat", "simpl", "date", "format", "output", "correct", "week", "number"], "B_title": "Missing locale string for format ( Date ). ", "B_clean_title": ["miss", "local", "string", "format", "date"]},
{"A_title": "Codepoint U+007f appears raw in outputNone", "A_clean_title": ["codepoint", "u+007f", "appear", "raw", "outputnon", "output", "none"], "B_title": "Remove spurious check for UTF - 8 .. ", "B_clean_title": ["remov", "spuriou", "check", "utf"]},
{"A_title": "Codepoint U+007f appears raw in outputNone", "A_clean_title": ["codepoint", "u+007f", "appear", "raw", "outputnon", "output", "none"], "B_title": "Fix typo in codeGenerator where  c  was passed through  but was accidentally ignored .. ", "B_clean_title": ["fix", "typo", "codegener", "code", "gener", "where", "wa", "pass", "through", "but", "wa", "accident", "ignor"]},
{"A_title": "Codepoint U+007f appears raw in outputNone", "A_clean_title": ["codepoint", "u+007f", "appear", "raw", "outputnon", "output", "none"], "B_title": "Fix typo in codeGenerator . java. ", "B_clean_title": ["fix", "typo", "codegener", "code", "gener", "java"]},
{"A_title": "Codepoint U+007f appears raw in outputNone", "A_clean_title": ["codepoint", "u+007f", "appear", "raw", "outputnon", "output", "none"], "B_title": "Fix typo in codeGenerator . java. ", "B_clean_title": ["fix", "typo", "codegener", "code", "gener", "java"]},
{"A_title": "Codepoint U+007f appears raw in outputNone", "A_clean_title": ["codepoint", "u+007f", "appear", "raw", "outputnon", "output", "none"], "B_title": "Fix typo in codeGenerator . java. ", "B_clean_title": ["fix", "typo", "codegener", "code", "gener", "java"]},
{"A_title": "NPE when calling SubLine.intersection() with non-intersecting linesWhen calling SubLine.intersection() with two lines that not intersect then a NullPointerException is thrown in Line.toSubSpace(). This bug is in the twod and threed implementations. The attached patch fixes both implementations and adds the required test cases.", "A_clean_title": ["npe", "when", "call", "sublin", "intersect", "sub", "line", "non", "intersect", "lineswhen", "line", "when", "call", "sublin", "intersect", "sub", "line", "two", "line", "that", "not", "intersect", "then", "nullpointerexcept", "null", "pointer", "except", "thrown", "line", "tosubspac", "sub", "space", "thi", "bug", "twod", "threed", "implement", "attach", "patch", "fix", "both", "implement", "add", "requir", "test", "case"], "B_title": "Added missing if (. Added missing if (. ", "B_clean_title": ["ad", "miss", "ad", "miss"]},
{"A_title": "NPE when calling SubLine.intersection() with non-intersecting linesWhen calling SubLine.intersection() with two lines that not intersect then a NullPointerException is thrown in Line.toSubSpace(). This bug is in the twod and threed implementations. The attached patch fixes both implementations and adds the required test cases.", "A_clean_title": ["npe", "when", "call", "sublin", "intersect", "sub", "line", "non", "intersect", "lineswhen", "line", "when", "call", "sublin", "intersect", "sub", "line", "two", "line", "that", "not", "intersect", "then", "nullpointerexcept", "null", "pointer", "except", "thrown", "line", "tosubspac", "sub", "space", "thi", "bug", "twod", "threed", "implement", "attach", "patch", "fix", "both", "implement", "add", "requir", "test", "case"], "B_title": "added fix. added fix. ", "B_clean_title": ["ad", "fix", "ad", "fix"]},
{"A_title": "NPE when calling SubLine.intersection() with non-intersecting linesWhen calling SubLine.intersection() with two lines that not intersect then a NullPointerException is thrown in Line.toSubSpace(). This bug is in the twod and threed implementations. The attached patch fixes both implementations and adds the required test cases.", "A_clean_title": ["npe", "when", "call", "sublin", "intersect", "sub", "line", "non", "intersect", "lineswhen", "line", "when", "call", "sublin", "intersect", "sub", "line", "two", "line", "that", "not", "intersect", "then", "nullpointerexcept", "null", "pointer", "except", "thrown", "line", "tosubspac", "sub", "space", "thi", "bug", "twod", "threed", "implement", "attach", "patch", "fix", "both", "implement", "add", "requir", "test", "case"], "B_title": "Add null check in SubLine. Add null check in SubLine  closes # 77. ", "B_clean_title": ["add", "null", "check", "sublin", "sub", "line", "add", "null", "check", "sublin", "sub", "line", "close", "77"]},
{"A_title": "NPE when calling SubLine.intersection() with non-intersecting linesWhen calling SubLine.intersection() with two lines that not intersect then a NullPointerException is thrown in Line.toSubSpace(). This bug is in the twod and threed implementations. The attached patch fixes both implementations and adds the required test cases.", "A_clean_title": ["npe", "when", "call", "sublin", "intersect", "sub", "line", "non", "intersect", "lineswhen", "line", "when", "call", "sublin", "intersect", "sub", "line", "two", "line", "that", "not", "intersect", "then", "nullpointerexcept", "null", "pointer", "except", "thrown", "line", "tosubspac", "sub", "space", "thi", "bug", "twod", "threed", "implement", "attach", "patch", "fix", "both", "implement", "add", "requir", "test", "case"], "B_title": "added null check in subLine copy. ", "B_clean_title": ["ad", "null", "check", "sublin", "sub", "line", "copi"]},
{"A_title": "NPE when calling SubLine.intersection() with non-intersecting linesWhen calling SubLine.intersection() with two lines that not intersect then a NullPointerException is thrown in Line.toSubSpace(). This bug is in the twod and threed implementations. The attached patch fixes both implementations and adds the required test cases.", "A_clean_title": ["npe", "when", "call", "sublin", "intersect", "sub", "line", "non", "intersect", "lineswhen", "line", "when", "call", "sublin", "intersect", "sub", "line", "two", "line", "that", "not", "intersect", "then", "nullpointerexcept", "null", "pointer", "except", "thrown", "line", "tosubspac", "sub", "space", "thi", "bug", "twod", "threed", "implement", "attach", "patch", "fix", "both", "implement", "add", "requir", "test", "case"], "B_title": "added missing if (. ", "B_clean_title": ["ad", "miss"]},
{"A_title": "NPE when calling SubLine.intersection() with non-intersecting linesWhen calling SubLine.intersection() with two lines that not intersect then a NullPointerException is thrown in Line.toSubSpace(). This bug is in the twod and threed implementations. The attached patch fixes both implementations and adds the required test cases.", "A_clean_title": ["npe", "when", "call", "sublin", "intersect", "sub", "line", "non", "intersect", "lineswhen", "line", "when", "call", "sublin", "intersect", "sub", "line", "two", "line", "that", "not", "intersect", "then", "nullpointerexcept", "null", "pointer", "except", "thrown", "line", "tosubspac", "sub", "space", "thi", "bug", "twod", "threed", "implement", "attach", "patch", "fix", "both", "implement", "add", "requir", "test", "case"], "B_title": "Add null check in patch2. ", "B_clean_title": ["add", "null", "check", "patch2"]},
{"A_title": "fixed a verify() call example in @Captor javadoc.None", "A_clean_title": ["fix", "verifi", "call", "exampl", "captor", "javadoc", "none"], "B_title": "Fix appendQuoting ( ). ", "B_clean_title": ["fix", "appendquot", "append", "quot"]},
{"A_title": "fixed a verify() call example in @Captor javadoc.None", "A_clean_title": ["fix", "verifi", "call", "exampl", "captor", "javadoc", "none"], "B_title": "Fix appendText ( ) with null values .. ", "B_clean_title": ["fix", "appendtext", "append", "text", "null", "valu"]},
{"A_title": "Bug propgated from v1.0.5 on to presentThe method getRowCount() in class org.jfree.data.category.DefaultIntervalCategoryDataset says that it Returns the number of series in the dataset (possibly zero).  The implementation from v1.0.5 on no longer checks for a null condition (which would then return a zero) on the seriesKeys as it did in v1.0.4 and previous. This now throws a Null Pointer if seriesKeys never got initialized and the getRowCount() method is called.", "A_clean_title": ["bug", "propgat", "v1", "presentth", "present", "method", "getrowcount", "get", "row", "count", "class", "org", "jfree", "data", "categori", "defaultintervalcategorydataset", "default", "interv", "categori", "dataset", "say", "that", "it", "return", "number", "seri", "dataset", "possibl", "zero", "implement", "v1", "no", "longer", "check", "null", "condit", "which", "would", "then", "return", "zero", "serieskey", "seri", "key", "as", "it", "did", "v1", "previou", "thi", "now", "throw", "null", "pointer", "serieskey", "seri", "key", "never", "got", "initi", "getrowcount", "get", "row", "count", "method", "call"], "B_title": "Fix bug in chart 16. ", "B_clean_title": ["fix", "bug", "chart", "16"]},
{"A_title": "Bug propgated from v1.0.5 on to presentThe method getRowCount() in class org.jfree.data.category.DefaultIntervalCategoryDataset says that it Returns the number of series in the dataset (possibly zero).  The implementation from v1.0.5 on no longer checks for a null condition (which would then return a zero) on the seriesKeys as it did in v1.0.4 and previous. This now throws a Null Pointer if seriesKeys never got initialized and the getRowCount() method is called.", "A_clean_title": ["bug", "propgat", "v1", "presentth", "present", "method", "getrowcount", "get", "row", "count", "class", "org", "jfree", "data", "categori", "defaultintervalcategorydataset", "default", "interv", "categori", "dataset", "say", "that", "it", "return", "number", "seri", "dataset", "possibl", "zero", "implement", "v1", "no", "longer", "check", "null", "condit", "which", "would", "then", "return", "zero", "serieskey", "seri", "key", "as", "it", "did", "v1", "previou", "thi", "now", "throw", "null", "pointer", "serieskey", "seri", "key", "never", "got", "initi", "getrowcount", "get", "row", "count", "method", "call"], "B_title": "Fix bug in chart - 16. ", "B_clean_title": ["fix", "bug", "chart", "16"]},
{"A_title": "Division by zeroIn class Complex division by zero always returns NaN. I think that it should return NaN only when the numerator is also ZERO otherwise the result should be INF. See here.", "A_clean_title": ["divis", "by", "zeroin", "zero", "class", "complex", "divis", "by", "zero", "alway", "return", "nan", "na", "think", "that", "it", "return", "nan", "na", "onli", "when", "numer", "also", "zero", "otherwis", "result", "inf", "see", "here"], "B_title": "Add fix from MATH - 657. Fix typo in MATH - 657. ", "B_clean_title": ["add", "fix", "math", "657", "fix", "typo", "math", "657"]},
{"A_title": "Potential NPE in AbstractCategoryItemRender.getLegendItems()Setting up a working copy of the current JFreeChart trunk in Eclipse I got a warning about a null pointer access in this bit of code from AbstractCategoryItemRender.java. The warning is in the last code line where seriesCount is assigned. The variable dataset is guaranteed to be null in this location I suppose that the check before that should actually read if (dataset == null) not if (dataset != null).", "A_clean_title": ["potenti", "npe", "abstractcategoryitemrend", "getlegenditem", "abstract", "categori", "item", "render", "get", "legend", "item", "set", "up", "work", "copi", "current", "jfreechart", "free", "chart", "trunk", "eclips", "got", "warn", "about", "null", "pointer", "access", "thi", "bit", "code", "abstractcategoryitemrend", "java", "abstract", "categori", "item", "render", "warn", "last", "code", "line", "where", "seriescount", "seri", "count", "assign", "variabl", "dataset", "guarante", "null", "thi", "locat", "suppos", "that", "check", "befor", "that", "actual", "read", "dataset", "null", "not", "dataset", "null"], "B_title": "Fix nullability assertion .. ", "B_clean_title": ["fix", "nullabl", "assert"]},
{"A_title": "Potential NPE in AbstractCategoryItemRender.getLegendItems()Setting up a working copy of the current JFreeChart trunk in Eclipse I got a warning about a null pointer access in this bit of code from AbstractCategoryItemRender.java. The warning is in the last code line where seriesCount is assigned. The variable dataset is guaranteed to be null in this location I suppose that the check before that should actually read if (dataset == null) not if (dataset != null).", "A_clean_title": ["potenti", "npe", "abstractcategoryitemrend", "getlegenditem", "abstract", "categori", "item", "render", "get", "legend", "item", "set", "up", "work", "copi", "current", "jfreechart", "free", "chart", "trunk", "eclips", "got", "warn", "about", "null", "pointer", "access", "thi", "bit", "code", "abstractcategoryitemrend", "java", "abstract", "categori", "item", "render", "warn", "last", "code", "line", "where", "seriescount", "seri", "count", "assign", "variabl", "dataset", "guarante", "null", "thi", "locat", "suppos", "that", "check", "befor", "that", "actual", "read", "dataset", "null", "not", "dataset", "null"], "B_title": "Fixed nullability assertion that was accidentally made too strong. ", "B_clean_title": ["fix", "nullabl", "assert", "that", "wa", "accident", "made", "too", "strong"]},
{"A_title": "Potential NPE in AbstractCategoryItemRender.getLegendItems()Setting up a working copy of the current JFreeChart trunk in Eclipse I got a warning about a null pointer access in this bit of code from AbstractCategoryItemRender.java. The warning is in the last code line where seriesCount is assigned. The variable dataset is guaranteed to be null in this location I suppose that the check before that should actually read if (dataset == null) not if (dataset != null).", "A_clean_title": ["potenti", "npe", "abstractcategoryitemrend", "getlegenditem", "abstract", "categori", "item", "render", "get", "legend", "item", "set", "up", "work", "copi", "current", "jfreechart", "free", "chart", "trunk", "eclips", "got", "warn", "about", "null", "pointer", "access", "thi", "bit", "code", "abstractcategoryitemrend", "java", "abstract", "categori", "item", "render", "warn", "last", "code", "line", "where", "seriescount", "seri", "count", "assign", "variabl", "dataset", "guarante", "null", "thi", "locat", "suppos", "that", "check", "befor", "that", "actual", "read", "dataset", "null", "not", "dataset", "null"], "B_title": "Fix nullability note in AbstractCategoryItemRenderer. ", "B_clean_title": ["fix", "nullabl", "note", "abstractcategoryitemrender", "abstract", "categori", "item", "render"]},
{"A_title": "Potential NPE in AbstractCategoryItemRender.getLegendItems()Setting up a working copy of the current JFreeChart trunk in Eclipse I got a warning about a null pointer access in this bit of code from AbstractCategoryItemRender.java. The warning is in the last code line where seriesCount is assigned. The variable dataset is guaranteed to be null in this location I suppose that the check before that should actually read if (dataset == null) not if (dataset != null).", "A_clean_title": ["potenti", "npe", "abstractcategoryitemrend", "getlegenditem", "abstract", "categori", "item", "render", "get", "legend", "item", "set", "up", "work", "copi", "current", "jfreechart", "free", "chart", "trunk", "eclips", "got", "warn", "about", "null", "pointer", "access", "thi", "bit", "code", "abstractcategoryitemrend", "java", "abstract", "categori", "item", "render", "warn", "last", "code", "line", "where", "seriescount", "seri", "count", "assign", "variabl", "dataset", "guarante", "null", "thi", "locat", "suppos", "that", "check", "befor", "that", "actual", "read", "dataset", "null", "not", "dataset", "null"], "B_title": "Fix null pointer check in AbstractCategoryItemRenderer. ", "B_clean_title": ["fix", "null", "pointer", "check", "abstractcategoryitemrender", "abstract", "categori", "item", "render"]},
{"A_title": "Potential NPE in AbstractCategoryItemRender.getLegendItems()Setting up a working copy of the current JFreeChart trunk in Eclipse I got a warning about a null pointer access in this bit of code from AbstractCategoryItemRender.java. The warning is in the last code line where seriesCount is assigned. The variable dataset is guaranteed to be null in this location I suppose that the check before that should actually read if (dataset == null) not if (dataset != null).", "A_clean_title": ["potenti", "npe", "abstractcategoryitemrend", "getlegenditem", "abstract", "categori", "item", "render", "get", "legend", "item", "set", "up", "work", "copi", "current", "jfreechart", "free", "chart", "trunk", "eclips", "got", "warn", "about", "null", "pointer", "access", "thi", "bit", "code", "abstractcategoryitemrend", "java", "abstract", "categori", "item", "render", "warn", "last", "code", "line", "where", "seriescount", "seri", "count", "assign", "variabl", "dataset", "guarante", "null", "thi", "locat", "suppos", "that", "check", "befor", "that", "actual", "read", "dataset", "null", "not", "dataset", "null"], "B_title": "Fix nullability assertion .. ", "B_clean_title": ["fix", "nullabl", "assert"]},
{"A_title": "Can not Return deep stubs from generic method that returns generic type.if I try to mock a generic method which a generic returntype where the returntype is derived from the generic type of the method using deep stubs I get a ClassCastException when calling when on it. When you dont use deep stubs and a raw Supplier mock to pass around it works:", "A_clean_title": ["not", "return", "deep", "stub", "gener", "method", "that", "return", "gener", "type", "tri", "mock", "gener", "method", "which", "gener", "returntyp", "where", "returntyp", "deriv", "gener", "type", "method", "deep", "stub", "get", "classcastexcept", "class", "cast", "except", "when", "call", "when", "it", "when", "you", "dont", "use", "deep", "stub", "raw", "supplier", "mock", "pass", "around", "it", "work"], "B_title": "added a bit more tidying of the areEqual method. ", "B_clean_title": ["ad", "bit", "more", "tidi", "areequ", "are", "equal", "method"]},
{"A_title": "Fix and then deprecate isSupportXxxInclusive in RealDistribution interfaceThe conclusion from 1 was never implemented. We should deprecate these properties from the RealDistribution interface but since removal will have to wait until 4.0 we should agree on a precise definition and fix the code to match it in the mean time. The definition that I propose is that isSupportXxxInclusive means that when the density function is applied to the upper or lower bound of support returned by getSupportXxxBound a finite (i.e. not infinite) not NaN value is returned. 1 http://markmail.org/message/dxuxh7eybl7xejde", "A_clean_title": ["fix", "then", "deprec", "issupportxxxinclus", "support", "xxx", "inclus", "realdistribut", "real", "distribut", "interfaceth", "interfac", "conclus", "wa", "never", "implement", "we", "deprec", "these", "properti", "realdistribut", "real", "distribut", "interfac", "but", "sinc", "remov", "will", "have", "wait", "until", "we", "agre", "precis", "definit", "fix", "code", "match", "it", "mean", "time", "definit", "that", "propos", "that", "issupportxxxinclus", "support", "xxx", "inclus", "mean", "that", "when", "densiti", "function", "appli", "upper", "or", "lower", "bound", "support", "return", "by", "getsupportxxxbound", "get", "support", "xxx", "bound", "finit", "not", "infinit", "not", "nan", "na", "valu", "return", "http", "markmail", "org", "messag", "dxuxh7eybl7xejd"], "B_title": "support lower bound in FDistribution. Fix UniformRealDistribution . isSupportUpperBoundInclusive. ", "B_clean_title": ["support", "lower", "bound", "fdistribut", "distribut", "fix", "uniformrealdistribut", "uniform", "real", "distribut", "issupportupperboundinclus", "support", "upper", "bound", "inclus"]},
{"A_title": "Fix and then deprecate isSupportXxxInclusive in RealDistribution interfaceThe conclusion from 1 was never implemented. We should deprecate these properties from the RealDistribution interface but since removal will have to wait until 4.0 we should agree on a precise definition and fix the code to match it in the mean time. The definition that I propose is that isSupportXxxInclusive means that when the density function is applied to the upper or lower bound of support returned by getSupportXxxBound a finite (i.e. not infinite) not NaN value is returned. 1 http://markmail.org/message/dxuxh7eybl7xejde", "A_clean_title": ["fix", "then", "deprec", "issupportxxxinclus", "support", "xxx", "inclus", "realdistribut", "real", "distribut", "interfaceth", "interfac", "conclus", "wa", "never", "implement", "we", "deprec", "these", "properti", "realdistribut", "real", "distribut", "interfac", "but", "sinc", "remov", "will", "have", "wait", "until", "we", "agre", "precis", "definit", "fix", "code", "match", "it", "mean", "time", "definit", "that", "propos", "that", "issupportxxxinclus", "support", "xxx", "inclus", "mean", "that", "when", "densiti", "function", "appli", "upper", "or", "lower", "bound", "support", "return", "by", "getsupportxxxbound", "get", "support", "xxx", "bound", "finit", "not", "infinit", "not", "nan", "na", "valu", "return", "http", "markmail", "org", "messag", "dxuxh7eybl7xejd"], "B_title": "UniformRealDistribution copy ( ). ", "B_clean_title": ["uniformrealdistribut", "uniform", "real", "distribut", "copi"]},
{"A_title": "NaN in equals methodsIn MathUtils some equals methods will return true if both argument are NaN. Unless Im mistaken this contradicts the IEEE standard. If nobody objects Im going to make the changes.", "A_clean_title": ["nan", "na", "equal", "methodsin", "method", "mathutil", "math", "util", "some", "equal", "method", "will", "return", "true", "both", "argument", "are", "nan", "na", "unless", "im", "mistaken", "thi", "contradict", "ieee", "standard", "nobodi", "object", "im", "go", "make", "chang"], "B_title": "Fix a bug in MathUtils . equals ( double  double  int ). ", "B_clean_title": ["fix", "bug", "mathutil", "math", "util", "equal", "doubl", "doubl", "int"]},
{"A_title": "NaN in equals methodsIn MathUtils some equals methods will return true if both argument are NaN. Unless Im mistaken this contradicts the IEEE standard. If nobody objects Im going to make the changes.", "A_clean_title": ["nan", "na", "equal", "methodsin", "method", "mathutil", "math", "util", "some", "equal", "method", "will", "return", "true", "both", "argument", "are", "nan", "na", "unless", "im", "mistaken", "thi", "contradict", "ieee", "standard", "nobodi", "object", "im", "go", "make", "chang"], "B_title": "Fix MathUtils . equals ( double  double  int ). ", "B_clean_title": ["fix", "mathutil", "math", "util", "equal", "doubl", "doubl", "int"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Fix try / catch in minimizeExitPoints. ", "B_clean_title": ["fix", "tri", "catch", "minimizeexitpoint", "minim", "exit", "point"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Remove  finally  keyword from  try / rescue . ", "B_clean_title": ["remov", "final", "keyword", "tri", "rescu"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Fix tryMinimizeExitPoints. ", "B_clean_title": ["fix", "tryminimizeexitpoint", "tri", "minim", "exit", "point"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Fix tryMinimizeExits. ", "B_clean_title": ["fix", "tryminimizeexit", "tri", "minim", "exit"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Remove tryMinimizeExits from tryMinimizeExits. ", "B_clean_title": ["remov", "tryminimizeexit", "tri", "minim", "exit", "tryminimizeexit", "tri", "minim", "exit"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Improve program minimization. ", "B_clean_title": ["improv", "program", "minim"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "try minimize exits on finally blocks. ", "B_clean_title": ["tri", "minim", "exit", "final", "block"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Remove tryMinimizeExits from tryMinimizeExits. ", "B_clean_title": ["remov", "tryminimizeexit", "tri", "minim", "exit", "tryminimizeexit", "tri", "minim", "exit"]},
{"A_title": "Wrong code generated if mixing types in ternary operatorNone", "A_clean_title": ["wrong", "code", "gener", "mix", "type", "ternari", "operatornon", "oper", "none"], "B_title": "Remove mayBeStringHelper from matchAll. ", "B_clean_title": ["remov", "maybestringhelp", "may", "string", "helper", "matchal", "match", "all"]},
{"A_title": "Inconsistent interpretation of ambiguous time during DSTThe inconsistency appears for timezone Europe/London.  These three DateTime objects should all represent the same moment in time even if they are ambiguous. Now it always returns the earlier instant (summer time) during an overlap.", "A_clean_title": ["inconsist", "interpret", "ambigu", "time", "dure", "dstthe", "dst", "inconsist", "appear", "timezon", "europ", "london", "these", "three", "datetim", "date", "time", "object", "all", "repres", "same", "moment", "time", "even", "they", "are", "ambigu", "now", "it", "alway", "return", "earlier", "instant", "summer", "time", "dure", "overlap"], "B_title": "fixed typo .. ", "B_clean_title": ["fix", "typo"]},
{"A_title": "Inconsistent interpretation of ambiguous time during DSTThe inconsistency appears for timezone Europe/London.  These three DateTime objects should all represent the same moment in time even if they are ambiguous. Now it always returns the earlier instant (summer time) during an overlap.", "A_clean_title": ["inconsist", "interpret", "ambigu", "time", "dure", "dstthe", "dst", "inconsist", "appear", "timezon", "europ", "london", "these", "three", "datetim", "date", "time", "object", "all", "repres", "same", "moment", "time", "even", "they", "are", "ambigu", "now", "it", "alway", "return", "earlier", "instant", "summer", "time", "dure", "overlap"], "B_title": "Added transition marker. ", "B_clean_title": ["ad", "transit", "marker"]},
{"A_title": "Inconsistent interpretation of ambiguous time during DSTThe inconsistency appears for timezone Europe/London.  These three DateTime objects should all represent the same moment in time even if they are ambiguous. Now it always returns the earlier instant (summer time) during an overlap.", "A_clean_title": ["inconsist", "interpret", "ambigu", "time", "dure", "dstthe", "dst", "inconsist", "appear", "timezon", "europ", "london", "these", "three", "datetim", "date", "time", "object", "all", "repres", "same", "moment", "time", "even", "they", "are", "ambigu", "now", "it", "alway", "return", "earlier", "instant", "summer", "time", "dure", "overlap"], "B_title": "fixed typo .. ", "B_clean_title": ["fix", "typo"]},
{"A_title": "smartNameRemoval causing compiler crashNone", "A_clean_title": ["smartnameremov", "smart", "name", "remov", "caus", "compil", "crashnon", "crash", "none"], "B_title": "Fix dead code. ", "B_clean_title": ["fix", "dead", "code"]},
{"A_title": "IndexOutOfBoundsException when receiving empty buffer at remote channelReceiving buffers from remote input channels with size 0 results in an IndexOutOfBoundsException.  code Caused by: java.lang.IndexOutOfBoundsException: index: 30 (expected: range(0 30)) at io.netty.buffer.AbstractByteBuf.checkIndex(AbstractByteBuf.java:1123) at io.netty.buffer.PooledUnsafeDirectByteBuf.getBytes(PooledUnsafeDirectByteBuf.java:156) at io.netty.buffer.PooledUnsafeDirectByteBuf.getBytes(PooledUnsafeDirectByteBuf.java:151) at io.netty.buffer.SlicedByteBuf.getBytes(SlicedByteBuf.java:179) at io.netty.buffer.AbstractByteBuf.readBytes(AbstractByteBuf.java:717) at org.apache.flink.runtime.io.network.netty.PartitionRequestClientHandler.decodeBufferOrEvent(PartitionRequestClientHandler.java:205) at org.apache.flink.runtime.io.network.netty.PartitionRequestClientHandler.decodeMsg(PartitionRequestClientHandler.java:164) at org.apache.flink.runtime.io.network.netty.PartitionRequestClientHandler.channelRead(PartitionRequestClientHandler.java:118) code", "A_clean_title": ["indexoutofboundsexcept", "index", "out", "bound", "except", "when", "receiv", "empti", "buffer", "at", "remot", "channelreceiv", "channel", "receiv", "buffer", "remot", "input", "channel", "size", "result", "indexoutofboundsexcept", "index", "out", "bound", "except", "code", "caus", "by", "java", "lang", "indexoutofboundsexcept", "index", "out", "bound", "except", "index", "30", "expect", "rang", "30", "at", "io", "netti", "buffer", "abstractbytebuf", "checkindex", "abstract", "byte", "buf", "check", "index", "abstractbytebuf", "java:1123", "abstract", "byte", "buf", "at", "io", "netti", "buffer", "pooledunsafedirectbytebuf", "getbyt", "pool", "unsaf", "direct", "byte", "buf", "get", "byte", "pooledunsafedirectbytebuf", "java:156", "pool", "unsaf", "direct", "byte", "buf", "at", "io", "netti", "buffer", "pooledunsafedirectbytebuf", "getbyt", "pool", "unsaf", "direct", "byte", "buf", "get", "byte", "pooledunsafedirectbytebuf", "java:151", "pool", "unsaf", "direct", "byte", "buf", "at", "io", "netti", "buffer", "slicedbytebuf", "getbyt", "slice", "byte", "buf", "get", "byte", "slicedbytebuf", "java:179", "slice", "byte", "buf", "at", "io", "netti", "buffer", "abstractbytebuf", "readbyt", "abstract", "byte", "buf", "read", "byte", "abstractbytebuf", "java:717", "abstract", "byte", "buf", "at", "org", "apach", "flink", "runtim", "io", "network", "netti", "partitionrequestclienthandl", "decodebufferorev", "partit", "request", "client", "handler", "decod", "buffer", "or", "event", "partitionrequestclienthandl", "java:205", "partit", "request", "client", "handler", "at", "org", "apach", "flink", "runtim", "io", "network", "netti", "partitionrequestclienthandl", "decodemsg", "partit", "request", "client", "handler", "decod", "msg", "partitionrequestclienthandl", "java:164", "partit", "request", "client", "handler", "at", "org", "apach", "flink", "runtim", "io", "network", "netti", "partitionrequestclienthandl", "channelread", "partit", "request", "client", "handler", "channel", "read", "partitionrequestclienthandl", "java:118", "partit", "request", "client", "handler", "code"], "B_title": "Fix IndexOutOfBoundsException when receiving empty buffer", "B_clean_title": ["fix", "indexoutofboundsexcept", "index", "out", "bound", "except", "when", "receiv", "empti", "buffer"]},
{"A_title": "unescapeXml(&12345678;) should be &12345678;Following test (in EntitiesTest.java) fails:     public void testNumberOverflow() throws Exception           doTestUnescapeEntity(&#12345678; &#12345678;);         doTestUnescapeEntity(x&#12345678;y x&#12345678;y);         doTestUnescapeEntity(&#x12345678; &#x12345678;);         doTestUnescapeEntity(x&#x12345678;y x&#x12345678;y);       Maximim value for char is 0xFFFF so &#12345678; is invalid entity reference and so should be left as is.", "A_clean_title": ["unescapexml", "unescap", "xml", "12345678", "12345678", "follow", "test", "entitiestest", "java", "entiti", "test", "fail", "public", "void", "testnumberoverflow", "test", "number", "overflow", "throw", "except", "dotestunescapeent", "test", "unescap", "entiti", "12345678", "12345678", "dotestunescapeent", "test", "unescap", "entiti", "12345678", "12345678", "dotestunescapeent", "test", "unescap", "entiti", "x12345678", "x12345678", "dotestunescapeent", "test", "unescap", "entiti", "x12345678", "x12345678", "maximim", "valu", "char", "0xffff", "0x", "ffff", "so", "12345678", "invalid", "entiti", "refer", "so", "left", "as"], "B_title": "Applying unit test and fix for #LANG-292. Also fixes a couple of problems with the unescape(Writer..) overload that came up", "B_clean_title": ["appli", "unit", "test", "fix", "lang", "292", "also", "fix", "coupl", "problem", "unescap", "writer", "overload", "that", "came", "up"]},
{"A_title": "Adding behavior in component instantiation listener causes Page.onInitialize() being called even if constructor throws an exceptionPage.onInitialize() will be called even if constructor throws an exception in case below code is added in wicket WebApplication.init(): getComponentInstantiationListeners().add(new IComponentInstantiationListener()                @Override               public void onInstantiation(Component component)                    component.add(new Behavior()                     );                                        );  It seems that the instantiation listener adds the behavior to the page at very start of the page constructor and then the page is marked as dirty to cause onInitialize() being called afterwards.", "A_clean_title": ["ad", "behavior", "compon", "instanti", "listen", "caus", "page", "oniniti", "initi", "be", "call", "even", "constructor", "throw", "exceptionpag", "oniniti", "except", "page", "initi", "will", "call", "even", "constructor", "throw", "except", "case", "below", "code", "ad", "wicket", "webappl", "init", "web", "applic", "getcomponentinstantiationlisten", "get", "compon", "instanti", "listen", "add", "new", "icomponentinstantiationlisten", "compon", "instanti", "listen", "overrid", "public", "void", "oninstanti", "instanti", "compon", "compon", "compon", "add", "new", "behavior", "it", "seem", "that", "instanti", "listen", "add", "behavior", "page", "at", "veri", "start", "page", "constructor", "then", "page", "mark", "as", "dirti", "caus", "oniniti", "initi", "be", "call", "afterward"], "B_title": "initialize Page before calling into instantiationListeners", "B_clean_title": ["initi", "page", "befor", "call", "into", "instantiationlisten", "instanti", "listen"]},
{"A_title": "read is inefficient when there are many split documentsAs reported in OAK-2358 there is a potential problem with revisionGC not cleaning up split documents properly (in 1.0.8.r1644758 at least).   As a side-effect having many garbage-revisions renders the diffImpl algorithm to become very slow - normally it would take only a few millis but with nodes that have many split-documents I can see diffImpl take hundres of millis sometimes up to a few seconds. Which causes the observation dequeuing to be slower than the rate in which observation events are enqueued which results in observation queue never being cleaned up and event handling being delayed more and more.  Adding some logging showed that diffImpl would often read many split-documents which supports the assumption that the revisionGC not cleaning up revisions has the diffImpl-slowness as a side-effect. Having said that - diffImpl should probably still be able to run fast since all the revisions it should look at should be in the main document not in split documents.  I dont have a test case handy for this at the moment unfortunately - if more is coming up Ill add more details here.", "A_clean_title": ["read", "ineffici", "when", "there", "are", "mani", "split", "documentsa", "document", "as", "report", "oak", "2358", "there", "potenti", "problem", "revisiongc", "revis", "gc", "not", "clean", "up", "split", "document", "properli", "r1644758", "at", "least", "as", "side", "effect", "have", "mani", "garbag", "revis", "render", "diffimpl", "diff", "impl", "algorithm", "becom", "veri", "slow", "normal", "it", "would", "take", "onli", "few", "milli", "but", "node", "that", "have", "mani", "split", "document", "see", "diffimpl", "diff", "impl", "take", "hundr", "milli", "sometim", "up", "few", "second", "which", "caus", "observ", "dequeu", "slower", "than", "rate", "which", "observ", "event", "are", "enqueu", "which", "result", "observ", "queue", "never", "be", "clean", "up", "event", "handl", "be", "delay", "more", "more", "ad", "some", "log", "show", "that", "diffimpl", "diff", "impl", "would", "often", "read", "mani", "split", "document", "which", "support", "assumpt", "that", "revisiongc", "revis", "gc", "not", "clean", "up", "revis", "ha", "diffimpl", "slow", "diff", "impl", "as", "side", "effect", "have", "said", "that", "diffimpl", "diff", "impl", "probabl", "still", "abl", "run", "fast", "sinc", "all", "revis", "it", "look", "at", "main", "document", "not", "split", "document", "dont", "have", "test", "case", "handi", "thi", "at", "moment", "unfortun", "more", "come", "up", "ill", "add", "more", "detail", "here"], "B_title": "read is inefficient when there are many split documents", "B_clean_title": ["read", "ineffici", "when", "there", "are", "mani", "split", "document"]},
{"A_title": "Shell.config()s return value is ignored.Shell.config() returns a boolean which is true if there was an error configuring the shell but the value is never observed. This can result in other unintended errors (like trying to use the ConsoleReader member when its not initialized).", "A_clean_title": ["shell", "config", "return", "valu", "ignor", "shell", "config", "return", "boolean", "which", "true", "there", "wa", "error", "configur", "shell", "but", "valu", "never", "observ", "thi", "result", "other", "unintend", "error", "like", "tri", "use", "consoleread", "consol", "reader", "member", "when", "it", "not", "initi"], "B_title": "Remove configError and use config(String...) retval", "B_clean_title": ["remov", "configerror", "config", "error", "use", "config", "string", "retval"]},
{"A_title": "catch(e) yields JSC_UNDEFINED_NAME warning when e is used in catch in advanced modeNone", "A_clean_title": ["catch", "yield", "jsc", "undefin", "name", "warn", "when", "use", "catch", "advanc", "modenon", "mode", "none"], "B_title": "Fix for errors wrt exceptions in the global scope. Fixes issue 1070 R=blickly", "B_clean_title": ["fix", "error", "wrt", "except", "global", "scope", "fix", "issu", "1070", "r=blickli"]},
{"A_title": "UrlUtils.isRelative returns false if URL parameter contains an absolute URLI have a page that gets a return path for a back link as a parameter. A link to this page looks like this:  ./mypage?return=http://example.com  In WebRequestCodingStrategy.encode this URL is returned by pathForTarget. Then it is checked whether this URL is relative using UrlUtils.isRelative. The URL is apparently relative but UrlUtils.isRelative returns false since the check contains:  (url.indexOf(://) < 0  this is false for the above example. Thus an incorrect path is returned by WebRequestCodingStrategy.encode (relative path resolution does not take place).  A fix for the problem would be to check for   !(url.startsWith(http://) || url.startsWith(https://))  Or if other protocols should also be supported a regular expression like ^^/?*:// should work.", "A_clean_title": ["urlutil", "isrel", "url", "util", "rel", "return", "fals", "url", "paramet", "contain", "absolut", "urli", "have", "page", "that", "get", "return", "path", "back", "link", "as", "paramet", "link", "thi", "page", "look", "like", "thi", "mypag", "return=http", "com", "exampl", "webrequestcodingstrategi", "encod", "web", "request", "code", "strategi", "thi", "url", "return", "by", "pathfortarget", "path", "target", "then", "it", "check", "whether", "thi", "url", "rel", "urlutil", "isrel", "url", "util", "rel", "url", "appar", "rel", "but", "urlutil", "isrel", "url", "util", "rel", "return", "fals", "sinc", "check", "contain", "url", "indexof", "index", "thi", "fals", "abov", "exampl", "thu", "incorrect", "path", "return", "by", "webrequestcodingstrategi", "encod", "web", "request", "code", "strategi", "rel", "path", "resolut", "not", "take", "place", "fix", "problem", "would", "check", "url", "startswith", "start", "http", "url", "startswith", "start", "http", "or", "other", "protocol", "also", "support", "regular", "express", "like", "work"], "B_title": "UrlUtils.isRelative returns false if URL parameter contains an absolute URL", "B_clean_title": ["urlutil", "isrel", "url", "util", "rel", "return", "fals", "url", "paramet", "contain", "absolut", "url"]},
{"A_title": "Bounds error in PageableListView#getCurrentPage()In the getCurrentPage() method of class PageableListView the following code:  while ((currentPage * rowsPerPage) > getList().size())             currentPage--;   checks if first cell if out of range. However the index of that first cell is (currentPage * rowsPerPage) and then the comparison with getList().size() should use a >= instead a >.", "A_clean_title": ["bound", "error", "pageablelistview", "pageabl", "list", "view", "getcurrentpag", "get", "current", "page", "getcurrentpag", "get", "current", "page", "method", "class", "pageablelistview", "pageabl", "list", "view", "follow", "code", "while", "currentpag", "current", "page", "rowsperpag", "row", "per", "page", "getlist", "get", "list", "size", "currentpag", "current", "page", "check", "first", "cell", "out", "rang", "howev", "index", "that", "first", "cell", "currentpag", "current", "page", "rowsperpag", "row", "per", "page", "then", "comparison", "getlist", "get", "list", "size", "use", "instead"], "B_title": "fix needed additional adjustment Issue: WICKET-2181", "B_clean_title": ["fix", "need", "addit", "adjust", "issu", "wicket", "2181"]},
{"A_title": "Possible overflow in checkpoint creationCreating a checkpoint with Long.MAX_VALUE lifetime will overflow the value allowing the store to immediately release the checkpoint.", "A_clean_title": ["possibl", "overflow", "checkpoint", "creationcr", "creation", "creat", "checkpoint", "long", "max", "valu", "lifetim", "will", "overflow", "valu", "allow", "store", "immedi", "releas", "checkpoint"], "B_title": "Possible overflow in checkpoint creation", "B_clean_title": ["possibl", "overflow", "checkpoint", "creation"]},
{"A_title": "WAL handling fails to deal with 1.4 -> 1.5 -> 1.6After doing a 1.4 -> 1.5 -> 1.6 upgrade that still has WALs for some tables the 1.6 instance fails to correctly handle the 1.4 recovered WALs.  This can happen either through not waiting long enough after the upgrade to 1.5 or because of an offline table brought online on 1.6 (ala ACCUMULO-2816).", "A_clean_title": ["wal", "handl", "fail", "deal", "6after", "do", "upgrad", "that", "still", "ha", "wal", "wa", "ls", "some", "tabl", "instanc", "fail", "correctli", "handl", "recov", "wal", "wa", "ls", "thi", "happen", "either", "through", "not", "wait", "long", "enough", "after", "upgrad", "or", "becaus", "offlin", "tabl", "brought", "onlin", "ala", "accumulo", "2816"], "B_title": "Correctly handle older internals.", "B_clean_title": ["correctli", "handl", "older", "intern"]},
{"A_title": "Inconsistency in Node#setProperty in case of null valueSetting a null value to a single valued property will result in null being returned while executing the same on a multivalued property will return the removed property.  jr2 returned the removed property in both cases as far as i  remember and i would suggest that we dont change that behavior. in particular since the specification IMO doesnt allow to return null-values for these methods.", "A_clean_title": ["inconsist", "node", "setproperti", "set", "properti", "case", "null", "valueset", "valu", "set", "null", "valu", "singl", "valu", "properti", "will", "result", "null", "be", "return", "while", "execut", "same", "multivalu", "properti", "will", "return", "remov", "properti", "jr2", "return", "remov", "properti", "both", "case", "as", "far", "as", "rememb", "would", "suggest", "that", "we", "dont", "chang", "that", "behavior", "particular", "sinc", "specif", "imo", "doesnt", "allow", "return", "null", "valu", "these", "method"], "B_title": ": Inconsistency in Node#setProperty in case of null value", "B_clean_title": ["inconsist", "node", "setproperti", "set", "properti", "case", "null", "valu"]},
{"A_title": "Fragment and Component with same id fail with misleading exceptionA page having a component from inherited markup *and* fragment with the *same* id fails with misleading exception message.  Exception message: The component(s) below failed to render. Possible reasons could be that: 1) you have added a component in code but forgot to reference it in the markup (thus the component will never be rendered) 2) if your components were added in a parent container then make sure the markup for the child container includes them in <wicket:extend> ... and list of component ids from fragment multiplied by amount of rows in DataTable  Cause: The markup of the component is used by the fragment.", "A_clean_title": ["fragment", "compon", "same", "id", "fail", "mislead", "exceptiona", "except", "page", "have", "compon", "inherit", "markup", "fragment", "same", "id", "fail", "mislead", "except", "messag", "except", "messag", "compon", "below", "fail", "render", "possibl", "reason", "could", "that", "you", "have", "ad", "compon", "code", "but", "forgot", "refer", "it", "markup", "thu", "compon", "will", "never", "render", "your", "compon", "were", "ad", "parent", "contain", "then", "make", "sure", "markup", "child", "contain", "includ", "them", "wicket", "extend", "list", "compon", "id", "fragment", "multipli", "by", "amount", "row", "datat", "data", "tabl", "caus", "markup", "compon", "use", "by", "fragment"], "B_title": "fail early if fragment markup is no fragment tag", "B_clean_title": ["fail", "earli", "fragment", "markup", "no", "fragment", "tag"]},
{"A_title": "MarkupNotFoundException when refreshing a component with AJAX inside a TransparentWebMarkupContainerA component placed inside a TransparentWebMarkupContainer added to its parent cannot be refreshed with AJAX. See quickstart.", "A_clean_title": ["markupnotfoundexcept", "markup", "not", "found", "except", "when", "refresh", "compon", "ajax", "insid", "transparentwebmarkupcontainera", "transpar", "web", "markup", "contain", "compon", "place", "insid", "transparentwebmarkupcontain", "transpar", "web", "markup", "contain", "ad", "it", "parent", "not", "refresh", "ajax", "see", "quickstart"], "B_title": "fixed by letting the sourcing strategies also look for transparent containers Issue: WICKET-3989", "B_clean_title": ["fix", "by", "let", "sourc", "strategi", "also", "look", "transpar", "contain", "issu", "wicket", "3989"]},
{"A_title": "NPE in JsonUtils when the value is nullMost part of org.apache.wicket.ajax.json.JsonUtils.asArray(Map<String Object> map) is trying carefully avoid null value. But there is following line  else if (value.getClass().isArray())  which cause NPE in case of empty value for some key.   P.S. Will provide patch.", "A_clean_title": ["npe", "jsonutil", "json", "util", "when", "valu", "nullmost", "null", "most", "part", "org", "apach", "wicket", "ajax", "json", "jsonutil", "asarray", "json", "util", "as", "array", "map", "string", "object", "map", "tri", "care", "avoid", "null", "valu", "but", "there", "follow", "line", "valu", "getclass", "get", "class", "isarray", "array", "which", "caus", "npe", "case", "empti", "valu", "some", "key", "will", "provid", "patch"], "B_title": "NPE in JsonUtils when the value is null", "B_clean_title": ["npe", "jsonutil", "json", "util", "when", "valu", "null"]},
{"A_title": "@JsonProperty(access = Access.READ_ONLY) - unexpected behaviourHey  I was hoping to make use of @JsonProperty(access = Access.READ_ONLY) but failed.  Assume this class:   I couldnt find a way to stop the deserializer from attempting to deserialize the field fullName.  The only thing that helps is to create a setter and annotate it with @JsonIgnore . However that setter does not make sense and I dont want to have it. Is this a bug in behaviour or am I missing something? Thanks", "A_clean_title": ["jsonproperti", "json", "properti", "access", "access", "read", "onli", "unexpect", "behaviourhey", "behaviour", "hey", "wa", "hope", "make", "use", "jsonproperti", "json", "properti", "access", "access", "read", "onli", "but", "fail", "assum", "thi", "class", "couldnt", "find", "way", "stop", "deseri", "attempt", "deseri", "field", "fullnam", "full", "name", "onli", "thing", "that", "help", "creat", "setter", "annot", "it", "jsonignor", "json", "ignor", "howev", "that", "setter", "not", "make", "sens", "dont", "want", "have", "it", "thi", "bug", "behaviour", "or", "am", "miss", "someth", "thank"], "B_title": "Fix #935", "B_clean_title": ["fix", "935"]},
{"A_title": "StopWatch: suspend() acts as split() if followed by stop()In my opinion it is a bug that suspend() acts as split() if followed by stop(); see below:         StopWatch sw = new StopWatch();         sw.start();         Thread.sleep(1000);         sw.suspend();         // Time 1 (ok)         System.out.println(sw.getTime());         Thread.sleep(2000);         // Time 1 (again ok)         System.out.println(sw.getTime());         sw.resume();         Thread.sleep(3000);         sw.suspend();         // Time 2 (ok)         System.out.println(sw.getTime());         Thread.sleep(4000);         // Time 2 (again ok)         System.out.println(sw.getTime());         Thread.sleep(5000);         sw.stop();         // Time 2 (should be but is Time 3 => NOT ok)         System.out.println(sw.getTime()); suspend/resume is like a pause where time counter doesnt continue. So a following stop()-call shouldnt increase the time counter should it?", "A_clean_title": ["stopwatch", "stop", "watch", "suspend", "act", "as", "split", "follow", "by", "stop", "my", "opinion", "it", "bug", "that", "suspend", "act", "as", "split", "follow", "by", "stop", "see", "below", "stopwatch", "stop", "watch", "sw", "new", "stopwatch", "stop", "watch", "sw", "start", "thread", "sleep", "1000", "sw", "suspend", "time", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "thread", "sleep", "2000", "time", "again", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "sw", "resum", "thread", "sleep", "3000", "sw", "suspend", "time", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "thread", "sleep", "4000", "time", "again", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "thread", "sleep", "5000", "sw", "stop", "time", "but", "time", "not", "ok", "system", "out", "println", "sw", "gettim", "get", "time", "suspend", "resum", "like", "paus", "where", "time", "counter", "doesnt", "continu", "so", "follow", "stop", "call", "shouldnt", "increas", "time", "counter", "it"], "B_title": "Applying test and fix for LANG-315", "B_clean_title": ["appli", "test", "fix", "lang", "315"]},
{"A_title": "URL query parameter values containing equals sign get cut offWhen calling a page with a query parameter like param1=val1=val2 the value of param1 obtained from PageParameters will be val1. Everything after the equals sign inside the parameter value gets cut off.", "A_clean_title": ["url", "queri", "paramet", "valu", "contain", "equal", "sign", "get", "cut", "offwhen", "off", "when", "call", "page", "queri", "paramet", "like", "param1=val1=val2", "valu", "param1", "obtain", "pageparamet", "page", "paramet", "will", "val1", "everyth", "after", "equal", "sign", "insid", "paramet", "valu", "get", "cut", "off"], "B_title": "URL query parameter values containing equals sign get cut off", "B_clean_title": ["url", "queri", "paramet", "valu", "contain", "equal", "sign", "get", "cut", "off"]},
{"A_title": "support custom response headers in AbstractResource.ResourceResponseIm converting an application to Wicket 1.5 and I see some problems with resources.  There is a case I need to add headers (not present in ResourceResponse properties) and it looks ugly.  This is what I need to do:      @Override     protected void configureCache(ResourceResponse data Attributes attributes)              super.configureCache(data attributes);         ((WebResponse) attributes.getResponse()).setHeader(Accept-Ranges bytes);       Its a hack to use configureCache here but this cant be added to setResponseHeaders which seams a better apparent method name for it.", "A_clean_title": ["support", "custom", "respons", "header", "abstractresourc", "resourceresponseim", "abstract", "resourc", "resourc", "respons", "im", "convert", "applic", "wicket", "see", "some", "problem", "resourc", "there", "case", "need", "add", "header", "not", "present", "resourcerespons", "resourc", "respons", "properti", "it", "look", "ugli", "thi", "what", "need", "overrid", "protect", "void", "configurecach", "configur", "cach", "resourcerespons", "resourc", "respons", "data", "attribut", "attribut", "super", "configurecach", "configur", "cach", "data", "attribut", "webrespons", "web", "respons", "attribut", "getrespons", "get", "respons", "sethead", "set", "header", "accept", "rang", "byte", "it", "hack", "use", "configurecach", "configur", "cach", "here", "but", "thi", "cant", "ad", "setresponsehead", "set", "respons", "header", "which", "seam", "better", "appar", "method", "name", "it"], "B_title": "allow empty header values since they are valid based on RFC2616", "B_clean_title": ["allow", "empti", "header", "valu", "sinc", "they", "are", "valid", "base", "rfc2616"]},
{"A_title": "WebPageRenderer should honor RedirectPolicy.ALWAYS_REDIRECT more consistentlyIn WebPageRenderer shouldPreserveClientUrl() currently has precedence over RedirectPolicy.ALWAYS_REDIRECT.  This can lead to confusion or unexpected behavior when RedirectPolicy.ALWAYS_REDIRECT is explicitely set but for some reason shouldPreserveClientUrl() returns true and thus no redirect is performed due to the logic in WebPageRenderer.  A fix for this particular problem could be implemented in  WebPageRenderer as of Wicket 6.12.0 by changing line 211 to:                  || (shouldPreserveClientUrl && getRedirectPolicy() != RedirectPolicy.ALWAYS_REDIRECT)) //   Note that this problem is slightly related to WICKET-5484. Both fixes combined the line could look like this:                  || (shouldPreserveClientUrl && !isAjax && getRedirectPolicy() != RedirectPolicy.ALWAYS_REDIRECT)) //", "A_clean_title": ["webpagerender", "web", "page", "render", "honor", "redirectpolici", "redirect", "polici", "alway", "redirect", "more", "consistentlyin", "consist", "webpagerender", "web", "page", "render", "shouldpreserveclienturl", "preserv", "client", "url", "current", "ha", "preced", "over", "redirectpolici", "redirect", "polici", "alway", "redirect", "thi", "lead", "confus", "or", "unexpect", "behavior", "when", "redirectpolici", "redirect", "polici", "alway", "redirect", "explicit", "set", "but", "some", "reason", "shouldpreserveclienturl", "preserv", "client", "url", "return", "true", "thu", "no", "redirect", "perform", "due", "logic", "webpagerender", "web", "page", "render", "fix", "thi", "particular", "problem", "could", "implement", "webpagerender", "web", "page", "render", "as", "wicket", "12", "by", "chang", "line", "211", "shouldpreserveclienturl", "preserv", "client", "url", "getredirectpolici", "get", "redirect", "polici", "redirectpolici", "redirect", "polici", "alway", "redirect", "note", "that", "thi", "problem", "slightli", "relat", "wicket", "5484", "both", "fix", "combin", "line", "could", "look", "like", "thi", "shouldpreserveclienturl", "preserv", "client", "url", "isajax", "ajax", "getredirectpolici", "get", "redirect", "polici", "redirectpolici", "redirect", "polici", "alway", "redirect"], "B_title": "WebPageRenderer should honor RedirectPolicy.ALWAYS_REDIRECT more consistently", "B_clean_title": ["webpagerender", "web", "page", "render", "honor", "redirectpolici", "redirect", "polici", "alway", "redirect", "more", "consist"]},
{"A_title": "XPath to SQL-2 conversion fails due to escaping errorThe problem is that the comment is not properly escaped (a C-style comment) so that */ in the XPath query accidentally ends the comment in the SQL-2 query.  The following query cant be converted to SQL-2 because it contains */:  noformat /jcr:root/etc//*@type = product  and ((@size = M or */@size= M or */*/@size = M  or */*/*/@size = M or */*/*/*/@size = M or */*/*/*/*/@size = M)) noformat  I think this was introduced by OAK-2354  http://svn.apache.org/viewvc?view=revision&amp;revision=1645616", "A_clean_title": ["xpath", "path", "sql", "convers", "fail", "due", "escap", "errorth", "error", "problem", "that", "comment", "not", "properli", "escap", "style", "comment", "so", "that", "xpath", "path", "queri", "accident", "end", "comment", "sql", "queri", "follow", "queri", "cant", "convert", "sql", "becaus", "it", "contain", "noformat", "jcr", "root", "etc", "type", "product", "size", "or", "size=", "or", "size", "or", "size", "or", "size", "or", "size", "noformat", "think", "thi", "wa", "introduc", "by", "oak", "2354", "http", "apach", "svn", "org", "viewvc", "view=revis", "amp", "revision=1645616"], "B_title": "XPath to SQL-2 conversion fails due to escaping error", "B_clean_title": ["xpath", "path", "sql", "convers", "fail", "due", "escap", "error"]},
{"A_title": "Errors in BOBYQAOptimizer when numberOfInterpolationPoints is greater than 2*dim+1Ive been having trouble getting BOBYQA to minimize a function (actually a non-linear least squares fit) so as one change I increased the number of interpolation points.  It seems that anything larger than 2*dim+1 causes an error (typically at line 1662                    interpolationPoints.setEntry(nfm ipt interpolationPoints.getEntry(ipt ipt)); Im guessing there is an off by one error in the translation from FORTRAN.  Changing the BOBYQAOptimizerTest as follows (increasing number of interpolation points by one) will cause failures. Bruce Index: src/test/java/org/apache/commons/math/optimization/direct/BOBYQAOptimizerTest.java =================================================================== — src/test/java/org/apache/commons/math/optimization/direct/BOBYQAOptimizerTest.java(revision 1221065) +++ src/test/java/org/apache/commons/math/optimization/direct/BOBYQAOptimizerTest.java(working copy) @@ -2587 +2587 @@  //        RealPointValuePair result = optim.optimize(100000 func goal startPoint);          final double lB = boundaries == null ? null : boundaries0;          final double uB = boundaries == null ? null : boundaries1;  BOBYQAOptimizer optim = new BOBYQAOptimizer(2 * dim + 1); +        BOBYQAOptimizer optim = new BOBYQAOptimizer(2 * dim + 2);          RealPointValuePair result = optim.optimize(maxEvaluations func goal startPoint lB uB);  //        System.out.println(func.getClass().getName() +  =    //              + optim.getEvaluations() +  f();", "A_clean_title": ["error", "bobyqaoptim", "bobyqa", "optim", "when", "numberofinterpolationpoint", "number", "interpol", "point", "greater", "than", "dim+1iv", "been", "have", "troubl", "get", "bobyqa", "minim", "function", "actual", "non", "linear", "least", "squar", "fit", "so", "as", "one", "chang", "increas", "number", "interpol", "point", "it", "seem", "that", "anyth", "larger", "than", "dim+1", "caus", "error", "typic", "at", "line", "1662", "interpolationpoint", "setentri", "interpol", "point", "set", "entri", "nfm", "ipt", "interpolationpoint", "getentri", "interpol", "point", "get", "entri", "ipt", "ipt", "im", "guess", "there", "off", "by", "one", "error", "translat", "fortran", "chang", "bobyqaoptimizertest", "bobyqa", "optim", "test", "as", "follow", "increas", "number", "interpol", "point", "by", "one", "will", "caus", "failur", "bruce", "index", "java", "src", "test", "java", "org", "apach", "common", "math", "optim", "direct", "bobyqaoptimizertest", "bobyqa", "optim", "test", "java", "src", "test", "java", "org", "apach", "common", "math", "optim", "direct", "bobyqaoptimizertest", "bobyqa", "optim", "test", "revis", "1221065", "java", "src", "test", "java", "org", "apach", "common", "math", "optim", "direct", "bobyqaoptimizertest", "bobyqa", "optim", "test", "work", "copi", "2587", "+2587", "realpointvaluepair", "real", "point", "valu", "pair", "result", "optim", "optim", "100000", "func", "goal", "startpoint", "start", "point", "final", "doubl", "lb", "boundari", "null", "null", "boundaries0", "final", "doubl", "ub", "boundari", "null", "null", "boundaries1", "bobyqaoptim", "bobyqa", "optim", "optim", "new", "bobyqaoptim", "bobyqa", "optim", "dim", "bobyqaoptim", "bobyqa", "optim", "optim", "new", "bobyqaoptim", "bobyqa", "optim", "dim", "realpointvaluepair", "real", "point", "valu", "pair", "result", "optim", "optim", "maxevalu", "max", "evalu", "func", "goal", "startpoint", "start", "point", "lb", "ub", "system", "out", "println", "func", "getclass", "get", "class", "getnam", "get", "name", "optim", "getevalu", "get", "evalu"], "B_title": "Offset by one bug. Suggested fix provided by Bruce Johnson. Ive added a unit test that exercises the use of more interpolation points; two previously unexplored code paths are now being traversed.", "B_clean_title": ["offset", "by", "one", "bug", "suggest", "fix", "provid", "by", "bruce", "johnson", "ive", "ad", "unit", "test", "that", "exercis", "use", "more", "interpol", "point", "two", "previous", "unexplor", "code", "path", "are", "now", "be", "travers"]},
{"A_title": "Significant Performance Degradation From Wicket 6.20.0 to Wicket 7.0.0I am experiencing a significant performance degradation for component adds in Wicket 7.0.0 once the component tree for a page gets reasonably large.  The attached quick start can be used to reproduce the issue.  Please note that NUM_ROWS is set to 10000 to exaggerate the performance degradation as the size of the component tree increases.  The same degradation (to a lesser extent) can be viewed with a smaller NUM_ROWS variable.  In Wicket 6.20.0 as the size of the component tree increases the cost of add() remains relatively constant time-wise.  In Wicket 7.0.0 a component add () is much more expensive (and actually makes our internal web application unusable) with form submits taking more than two or three minutes to come back from the server.  Heres some timing examples.    =============================================================================================================  NUM_ROWS = 5000 Wicket 6.20.0 -> ~200 milliseconds of server side rendering (before browser paints HTML). Wicket 7.0.0 -> ~ 10 seconds of server side rendering  NUM_ROWS = 10000 Wicket 6.20.0 -> ~ 500 milliseconds of server side rendering Wicket 7.0.0 -> ~ 40 seconds of server side rendering  =============================================================================================================  The attached quickstart can be used to reproduce the issue on your side.  My guess is that this has to do with the new component queuing feature that was added as part of Wicket 7.0.0.", "A_clean_title": ["signific", "perform", "degrad", "wicket", "20", "wicket", "0i", "am", "experienc", "signific", "perform", "degrad", "compon", "add", "wicket", "onc", "compon", "tree", "page", "get", "reason", "larg", "attach", "quick", "start", "use", "reproduc", "issu", "pleas", "note", "that", "num", "row", "set", "10000", "exagger", "perform", "degrad", "as", "size", "compon", "tree", "increas", "same", "degrad", "lesser", "extent", "view", "smaller", "num", "row", "variabl", "wicket", "20", "as", "size", "compon", "tree", "increas", "cost", "add", "remain", "rel", "constant", "time", "wise", "wicket", "compon", "add", "much", "more", "expens", "actual", "make", "our", "intern", "web", "applic", "unus", "form", "submit", "take", "more", "than", "two", "or", "three", "minut", "come", "back", "server", "here", "some", "time", "exampl", "num", "row", "5000", "wicket", "20", "~200", "millisecond", "server", "side", "render", "befor", "browser", "paint", "html", "wicket", "10", "second", "server", "side", "render", "num", "row", "10000", "wicket", "20", "500", "millisecond", "server", "side", "render", "wicket", "40", "second", "server", "side", "render", "attach", "quickstart", "use", "reproduc", "issu", "your", "side", "my", "guess", "that", "thi", "ha", "new", "compon", "queu", "featur", "that", "wa", "ad", "as", "part", "wicket"], "B_title": "Fix the behavior of MarkupContainer#get(int) for non-empty MarkupContainer and non-existing index", "B_clean_title": ["fix", "behavior", "markupcontain", "markup", "contain", "get", "int", "non", "empti", "markupcontain", "markup", "contain", "non", "exist", "index"]},
{"A_title": "TarMK Cold Standby can corrupt bulk segmentsTheres a race condition on the segment transfer code that may introduce corrupted binary segments on the secondary instance. What can happen during the head sync phase is that the master may send the head segment twice which will make the client receive&store the second segment thinking its a different one.", "A_clean_title": ["tarmk", "tar", "mk", "cold", "standbi", "corrupt", "bulk", "segmentsther", "segment", "there", "race", "condit", "segment", "transfer", "code", "that", "may", "introduc", "corrupt", "binari", "segment", "secondari", "instanc", "what", "happen", "dure", "head", "sync", "phase", "that", "master", "may", "send", "head", "segment", "twice", "which", "will", "make", "client", "receiv", "store", "second", "segment", "think", "it", "differ", "one"], "B_title": "TarMK Cold Standby can corrupt bulk segments", "B_clean_title": ["tarmk", "tar", "mk", "cold", "standbi", "corrupt", "bulk", "segment"]},
{"A_title": "FormComponent.updateCollectionModel  does not handle unmodifiableListFormComponent.updateCollectionModel should handle situation when getter returns unmodifiable list.  Proposed solution:  formComponent.modelChanging(); booelan isChanged; try  collection.clear(); if (convertedInput != null)  collection.addAll(convertedInput);  isChanged = true; catch (Exception e)  // ignore this exception as Unmodifiable list does not allow change  logger.info(An error occurred while trying to modify list attached to  + formComponent e);   try  if(isChanged) formComponent.getModel().setObject(collection); else  // TODO: create here collection as non-abstract successor of setObject declared argument formComponent.getModel().setObject(new ArrayList(convertedInput)); isChanged = true;  catch (Exception e)  // ignore this exception because it could be that there // is not setter for this collection. logger.info(An error occurred while trying to set the new value for the property attached to  + formComponent e);  // at least one update method should pass successfully if(isChanged) formComponent.modelChanged(); else throw new RuntimeException(An error occurred while trying to modify value for the property attached to  + formComponent);", "A_clean_title": ["formcompon", "updatecollectionmodel", "form", "compon", "updat", "collect", "model", "not", "handl", "unmodifiablelistformcompon", "updatecollectionmodel", "unmodifi", "list", "form", "compon", "updat", "collect", "model", "handl", "situat", "when", "getter", "return", "unmodifi", "list", "propos", "solut", "formcompon", "modelchang", "form", "compon", "model", "chang", "booelan", "ischang", "chang", "tri", "collect", "clear", "convertedinput", "convert", "input", "null", "collect", "addal", "add", "all", "convertedinput", "convert", "input", "ischang", "chang", "true", "catch", "except", "ignor", "thi", "except", "as", "unmodifi", "list", "not", "allow", "chang", "logger", "info", "error", "occur", "while", "tri", "modifi", "list", "attach", "formcompon", "form", "compon", "tri", "ischang", "chang", "formcompon", "getmodel", "form", "compon", "get", "model", "setobject", "set", "object", "collect", "todo", "creat", "here", "collect", "as", "non", "abstract", "successor", "setobject", "set", "object", "declar", "argument", "formcompon", "getmodel", "form", "compon", "get", "model", "setobject", "set", "object", "new", "arraylist", "array", "list", "convertedinput", "convert", "input", "ischang", "chang", "true", "catch", "except", "ignor", "thi", "except", "becaus", "it", "could", "that", "there", "not", "setter", "thi", "collect", "logger", "info", "error", "occur", "while", "tri", "set", "new", "valu", "properti", "attach", "formcompon", "form", "compon", "at", "least", "one", "updat", "method", "pass", "success", "ischang", "chang", "formcompon", "modelchang", "form", "compon", "model", "chang", "throw", "new", "runtimeexcept", "runtim", "except", "error", "occur", "while", "tri", "modifi", "valu", "properti", "attach", "formcompon", "form", "compon"], "B_title": "support unmodifiable collections as well as models without setter", "B_clean_title": ["support", "unmodifi", "collect", "as", "well", "as", "model", "without", "setter"]},
{"A_title": "WrongTypeOfReturnValue when abstract class have two abstract method.This is strange behavior because the method lol() should not be called but when I delete one abstract method everything is good.", "A_clean_title": ["wrongtypeofreturnvalu", "wrong", "type", "return", "valu", "when", "abstract", "class", "have", "two", "abstract", "method", "thi", "strang", "behavior", "becaus", "method", "lol", "not", "call", "but", "when", "delet", "one", "abstract", "method", "everyth", "good"], "B_title": "Merge pull request #30 from marcingrzejszczak/issue399", "B_clean_title": ["merg", "pull", "request", "30", "marcingrzejszczak", "issue399"]},
{"A_title": "SplitOperations purges _commitRoot entries too eagerlyOAK-2528 introduced purging of _commitRoot entries without associated local changes on the document. Those _commitRoot entries are created when a child nodes is added and the _children flag is touched on the parent.  The purge operation is too eager and removes all such entries which may result in an undetected hierarchy conflict.", "A_clean_title": ["splitoper", "split", "oper", "purg", "commitroot", "commit", "root", "entri", "too", "eagerlyoak", "2528", "eagerli", "oak", "introduc", "purg", "commitroot", "commit", "root", "entri", "without", "associ", "local", "chang", "document", "those", "commitroot", "commit", "root", "entri", "are", "creat", "when", "child", "node", "ad", "children", "flag", "touch", "parent", "purg", "oper", "too", "eager", "remov", "all", "such", "entri", "which", "may", "result", "undetect", "hierarchi", "conflict"], "B_title": "SplitOperations purges _commitRoot entries too eagerly", "B_clean_title": ["splitoper", "split", "oper", "purg", "commitroot", "commit", "root", "entri", "too", "eagerli"]},
{"A_title": "Record type invalid property not reported on function with @this annotationNone", "A_clean_title": ["record", "type", "invalid", "properti", "not", "report", "function", "thi", "annotationnon", "annot", "none"], "B_title": "fix a bogus if branch. I have no idea what this was doing. Fixes issue 810", "B_clean_title": ["fix", "bogu", "branch", "have", "no", "idea", "what", "thi", "wa", "do", "fix", "issu", "810"]},
{"A_title": "Result of multiplying and equals for complex numbers is wrongHi. The bug relates on complex numbers. The methods multiply and equals of the class Complex are involved. mathematic background:  (0i) * (-10i) = (0-i). little java program + output that shows the bug: -----------------------------------------------------------------------  import org.apache.commons.math.complex.*; public class TestProg          public static void main(String args)                   ComplexFormat f = new ComplexFormat();                 Complex c1 = new Complex(01);                 Complex c2 = new Complex(-10);                  Complex res = c1.multiply(c2);                 Complex comp = new Complex(0-1);                  System.out.println(res:  +f.format(res));                 System.out.println(comp: +f.format(comp));                  System.out.println(res=comp: +res.equals(comp));             ----------------------------------------------------------------------- res:  -0 - 1i comp: 0 - 1i res=comp: false ----------------------------------------------------------------------- I think the equals should return true. The problem could either be the multiply method that gives (-0-1i) instead of (0-1i) or if you think thats right the equals method has to be modified. Good Luck Dieter", "A_clean_title": ["result", "multipli", "equal", "complex", "number", "wronghi", "wrong", "hi", "bug", "relat", "complex", "number", "method", "multipli", "equal", "class", "complex", "are", "involv", "mathemat", "background", "0i", "10i", "littl", "java", "program", "output", "that", "show", "bug", "import", "org", "apach", "common", "math", "complex", "public", "class", "testprog", "test", "prog", "public", "static", "void", "main", "string", "arg", "complexformat", "complex", "format", "new", "complexformat", "complex", "format", "complex", "c1", "new", "complex", "01", "complex", "c2", "new", "complex", "10", "complex", "re", "c1", "multipli", "c2", "complex", "comp", "new", "complex", "system", "out", "println", "re", "+f", "format", "re", "system", "out", "println", "comp", "+f", "format", "comp", "system", "out", "println", "res=comp", "+re", "equal", "comp", "re", "1i", "comp", "1i", "res=comp", "fals", "think", "equal", "return", "true", "problem", "could", "either", "multipli", "method", "that", "give", "1i", "instead", "1i", "or", "you", "think", "that", "right", "equal", "method", "ha", "modifi", "good", "luck", "dieter"], "B_title": "Changed the Complex.equals() method so that it considers +0 and -0 are equal as required by IEEE-754 standard. JIRA: MATH-221", "B_clean_title": ["chang", "complex", "equal", "method", "so", "that", "it", "consid", "+0", "are", "equal", "as", "requir", "by", "ieee", "754", "standard", "jira", "math", "221"]},
{"A_title": "rest api returns wrong address status isReady:truephase:Pendingaddress-space: standard  addresses: queue(sharded-queue)/topic(sharded-topic)  addresses deployed into address-space are ready to use (simple send/receive) but .status.phase is set to Pending reproducer    create     deploy     get all addresses     result:   address_space definition: standardSpace.json   addresses definition: standard_qt.json   however in standard-controller log you can see that addresses are in phase Active:   ConfigMap of myqueue contains phase Active as well   Ill try to reproduce with brokered...", "A_clean_title": ["rest", "api", "return", "wrong", "address", "statu", "isreadi", "readi", "truephas", "pendingaddress", "space", "standard", "address", "queue", "shard", "queue", "topic", "shard", "topic", "address", "deploy", "into", "address", "space", "are", "readi", "use", "simpl", "send", "receiv", "but", "statu", "phase", "set", "pend", "reproduc", "creat", "deploy", "get", "all", "address", "result", "address", "space", "definit", "standardspac", "json", "standard", "space", "address", "definit", "json", "standard", "qt", "howev", "standard", "control", "log", "you", "see", "that", "address", "are", "phase", "activ", "configmap", "config", "map", "myqueu", "contain", "phase", "activ", "as", "well", "ill", "tri", "reproduc", "broker"], "B_title": "Copy phase in Status copy constructor  This fixes #927", "B_clean_title": ["copi", "phase", "statu", "copi", "constructor", "thi", "fix", "927"]},
{"A_title": "Node.addNode(String String) may check nt-mgt-permission against the wrong nodeWhile I was troubleshooting an issue were having in AEM 6.1 Ive noticed an impossible access denied exception in the logs: the user had permission to add nodes under the node in question but still got an error.  Some testing narrowed the issue down to a difference in behavior between the following two invocations: someNode.getNode(child).addNode(grandchild nt:unstructured); someNode.addNode(child/grandchild nt:unstructured);  As far as I can tell both should behave identically per the JCR spec but the second one fails if the user doesnt have node type management permission to someNode even if they have that permission to someNode/child.  I believe the issue is in line 283 of NodeImpl|https://svn.apache.org/repos/asf/jackrabbit/oak/trunk/oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/NodeImpl.java: it is checking permissions against dlg.getTree() but it should really check against parent.getTree() or if possible the path of the node thats about to be created (so glob restrictions can be evaluated).", "A_clean_title": ["node", "addnod", "add", "node", "string", "string", "may", "check", "nt", "mgt", "permiss", "against", "wrong", "nodewhil", "node", "while", "wa", "troubleshoot", "issu", "were", "have", "aem", "ive", "notic", "imposs", "access", "deni", "except", "log", "user", "had", "permiss", "add", "node", "under", "node", "question", "but", "still", "got", "error", "some", "test", "narrow", "issu", "down", "differ", "behavior", "between", "follow", "two", "invoc", "somenod", "getnod", "some", "node", "get", "node", "child", "addnod", "add", "node", "grandchild", "nt", "unstructur", "somenod", "addnod", "some", "node", "add", "node", "child", "grandchild", "nt", "unstructur", "as", "far", "as", "tell", "both", "behav", "ident", "per", "jcr", "spec", "but", "second", "one", "fail", "user", "doesnt", "have", "node", "type", "manag", "permiss", "somenod", "some", "node", "even", "they", "have", "that", "permiss", "somenod", "child", "some", "node", "believ", "issu", "line", "283", "nodeimpl|http", "node", "impl|http", "apach", "java", "svn", "org", "repo", "asf", "jackrabbit", "oak", "trunk", "oak", "jcr", "src", "main", "java", "org", "apach", "jackrabbit", "oak", "jcr", "session", "nodeimpl", "node", "impl", "it", "check", "permiss", "against", "dlg", "gettre", "get", "tree", "but", "it", "realli", "check", "against", "parent", "gettre", "get", "tree", "or", "possibl", "path", "node", "that", "about", "creat", "so", "glob", "restrict", "evalu"], "B_title": ": Node.addNode(String String) may check permissions against the wrong node", "B_clean_title": ["node", "addnod", "add", "node", "string", "string", "may", "check", "permiss", "against", "wrong", "node"]},
{"A_title": "HypergeometricDistribution.sample suffers from integer overflowHi I have an application which broke when ported from commons math 2.2 to 3.2. It looks like the HypergeometricDistribution.sample() method doesnt work as well as it used to with large integer values – the example code below should return a sample between 0 and 50 but usually returns -50.  import org.apache.commons.math3.distribution.HypergeometricDistribution;  public class Foo    public static void main(String args)      HypergeometricDistribution a = new HypergeometricDistribution(         43130568 42976365 50);     System.out.printf(%d %d%n a.getSupportLowerBound() a.getSupportUpperBound()); // Prints 0 50     System.out.printf(%d%na.sample());                                             // Prints -50       In the debugger I traced it as far as an integer overflow in HypergeometricDistribution.getNumericalMean() – instead of doing  return (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();   it could do:  return getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());   This seemed to fix it based on a quick test.", "A_clean_title": ["hypergeometricdistribut", "sampl", "hypergeometr", "distribut", "suffer", "integ", "overflowhi", "overflow", "hi", "have", "applic", "which", "broke", "when", "port", "common", "math", "it", "look", "like", "hypergeometricdistribut", "sampl", "hypergeometr", "distribut", "method", "doesnt", "work", "as", "well", "as", "it", "use", "larg", "integ", "valu", "exampl", "code", "below", "return", "sampl", "between", "50", "but", "usual", "return", "50", "import", "org", "apach", "common", "math3", "distribut", "hypergeometricdistribut", "hypergeometr", "distribut", "public", "class", "foo", "public", "static", "void", "main", "string", "arg", "hypergeometricdistribut", "hypergeometr", "distribut", "new", "hypergeometricdistribut", "hypergeometr", "distribut", "43130568", "42976365", "50", "system", "out", "printf", "getsupportlowerbound", "get", "support", "lower", "bound", "getsupportupperbound", "get", "support", "upper", "bound", "print", "50", "system", "out", "printf", "na", "sampl", "print", "50", "debugg", "trace", "it", "as", "far", "as", "integ", "overflow", "hypergeometricdistribut", "getnumericalmean", "hypergeometr", "distribut", "get", "numer", "mean", "instead", "do", "return", "doubl", "getsamples", "get", "sampl", "size", "getnumberofsuccess", "get", "number", "success", "doubl", "getpopulations", "get", "popul", "size", "it", "could", "return", "getsamples", "get", "sampl", "size", "doubl", "getnumberofsuccess", "get", "number", "success", "doubl", "getpopulations", "get", "popul", "size", "thi", "seem", "fix", "it", "base", "quick", "test"], "B_title": "Reordering can prevent some overflow occurrences (fix suggested by Brian Bloniarz). Added unit test.", "B_clean_title": ["reorder", "prevent", "some", "overflow", "occurr", "fix", "suggest", "by", "brian", "bloniarz", "ad", "unit", "test"]},
{"A_title": "Component markup caching inconsistenciesIn WICKET-3891 we found that Component#markup field is not being reset between requests. The problem is that this field is transient and it is null-ified only when the page is read from the second level page cache (see https://cwiki.apache.org/confluence/x/qIaoAQ). If the page instance is read from first level cache (http session) then its non-serialized version is used and the markup field value is still non-null.  In WICKET-3891 this looked like a minor issue with the markup caching in development mode but actually this problem is valid even in production mode. See the attached application. When the panels variation is changed every MarkupContainer inside still uses its old markup.", "A_clean_title": ["compon", "markup", "cach", "inconsistenciesin", "inconsist", "wicket", "3891", "we", "found", "that", "compon", "markup", "field", "not", "be", "reset", "between", "request", "problem", "that", "thi", "field", "transient", "it", "null", "ifi", "onli", "when", "page", "read", "second", "level", "page", "cach", "see", "http", "apach", "cwiki", "org", "confluenc", "qiaoaq", "iao", "aq", "page", "instanc", "read", "first", "level", "cach", "http", "session", "then", "it", "non", "serial", "version", "use", "markup", "field", "valu", "still", "non", "null", "wicket", "3891", "thi", "look", "like", "minor", "issu", "markup", "cach", "develop", "mode", "but", "actual", "thi", "problem", "valid", "even", "product", "mode", "see", "attach", "applic", "when", "panel", "variat", "chang", "everi", "markupcontain", "markup", "contain", "insid", "still", "use", "it", "old", "markup"], "B_title": "Component markup caching inconsistencies", "B_clean_title": ["compon", "markup", "cach", "inconsist"]},
{"A_title": "Url#toString(StringMode.FULL) throws exception if a segment contains two dotsWhen invoking toString(StringMode.FULL) for a URL like /mountPoint/whatever.../ an IllegalStateException is thrown with message: Cannot render this url in FULL mode because it has a `..` segment: /mountPoint/whatever.../  The method does not actually check for `..` segments but rather checks whether path.contains(..)", "A_clean_title": ["url", "tostr", "string", "stringmod", "full", "string", "mode", "throw", "except", "segment", "contain", "two", "dotswhen", "dot", "when", "invok", "tostr", "string", "stringmod", "full", "string", "mode", "url", "like", "mountpoint", "whatev", "mount", "point", "illegalstateexcept", "illeg", "state", "except", "thrown", "messag", "not", "render", "thi", "url", "full", "mode", "becaus", "it", "ha", "segment", "mountpoint", "whatev", "mount", "point", "method", "not", "actual", "check", "segment", "but", "rather", "check", "whether", "path", "contain"], "B_title": "Url#toString(StringMode.FULL) throws exception if a segment contains two dots", "B_clean_title": ["url", "tostr", "string", "stringmod", "full", "string", "mode", "throw", "except", "segment", "contain", "two", "dot"]},
{"A_title": "too large first step with embedded Runge-Kutta integrators (Dormand-Prince 8(53) ...)Adaptive step size integrators compute the first step size by themselves if it is not provided. For embedded Runge-Kutta type this step size is not checked against the integration range so if the integration range is extremely short this step size may evaluate the function out of the range (and in fact it tries afterward to go back and fails to stop). Gragg-Bulirsch-Stoer integrators do not have this problem the step size is checked and truncated if needed.", "A_clean_title": ["too", "larg", "first", "step", "embed", "rung", "kutta", "integr", "dormand", "princ", "53", "adapt", "step", "size", "integr", "comput", "first", "step", "size", "by", "themselv", "it", "not", "provid", "embed", "rung", "kutta", "type", "thi", "step", "size", "not", "check", "against", "integr", "rang", "so", "integr", "rang", "extrem", "short", "thi", "step", "size", "may", "evalu", "function", "out", "rang", "fact", "it", "tri", "afterward", "go", "back", "fail", "stop", "gragg", "bulirsch", "stoer", "integr", "not", "have", "thi", "problem", "step", "size", "check", "truncat", "need"], "B_title": "Check first step size in embedded Runge-Kutta integrators.", "B_clean_title": ["check", "first", "step", "size", "embed", "rung", "kutta", "integr"]},
{"A_title": "Session Window State is Not CheckpointedThe merging window state in the WindowOperator is not checkpointed. This means that programs containing session windows will fail upon restore after a failure.  I propose adding a simulated snapshot/restore cycle to the tests in WindowOperatorTest to catch these problems in the future.", "A_clean_title": ["session", "window", "state", "not", "checkpointedth", "checkpoint", "merg", "window", "state", "windowoper", "window", "oper", "not", "checkpoint", "thi", "mean", "that", "program", "contain", "session", "window", "will", "fail", "upon", "restor", "after", "failur", "propos", "ad", "simul", "snapshot", "restor", "cycl", "test", "windowoperatortest", "window", "oper", "test", "catch", "these", "problem", "futur"], "B_title": "Make Session Window State Checkpointed", "B_clean_title": ["make", "session", "window", "state", "checkpoint"]},
{"A_title": "NamePathMapper should fail on absolute paths escaping rootThe name path mapper should no accept invalid paths of type  code /.. code  I.e. paths which escape beyond the root of the hierarchy.", "A_clean_title": ["namepathmapp", "name", "path", "mapper", "fail", "absolut", "path", "escap", "rootth", "root", "name", "path", "mapper", "no", "accept", "invalid", "path", "type", "code", "code", "path", "which", "escap", "beyond", "root", "hierarchi"], "B_title": "NamePathMapper should fail on absolute paths escaping root", "B_clean_title": ["namepathmapp", "name", "path", "mapper", "fail", "absolut", "path", "escap", "root"]},
{"A_title": "Add support for --manage_closure_dependencies and --only_closure_dependencies with compilation level WHITESPACE_ONLYNone", "A_clean_title": ["add", "support", "manag", "closur", "depend", "onli", "closur", "depend", "compil", "level", "whitespac", "onlynon", "onli", "none"], "B_title": "add dependency management in whitespace-only mode contributed by Chris Peisert fixes issue 703", "B_clean_title": ["add", "depend", "manag", "whitespac", "onli", "mode", "contribut", "by", "chri", "peisert", "fix", "issu", "703"]},
{"A_title": "Converting to Vavr Option fails for present value DATACMNS-1087opened and commented Curently  QueryExecutionConverters tries to invoke Vavrs Optional.of like an instance method rather than static one. This causes exception:    Affects: 1.13.4 (Ingalls SR4)  Referenced from: commits", "A_clean_title": ["convert", "vavr", "option", "fail", "present", "valu", "datacmn", "1087open", "comment", "curent", "queryexecutionconvert", "queri", "execut", "convert", "tri", "invok", "vavr", "option", "like", "instanc", "method", "rather", "than", "static", "one", "thi", "caus", "except", "affect", "13", "ingal", "sr4", "referenc", "commit"], "B_title": "DATACMNS-1087 - Fixed Vavr Option creation from present value.  We now reflectively invoke the static method Option.of(…) while we previously tried to invoke an instance method on the parameter value.", "B_clean_title": ["datacmn", "1087", "fix", "vavr", "option", "creation", "present", "valu", "we", "now", "reflect", "invok", "static", "method", "option", "while", "we", "previous", "tri", "invok", "instanc", "method", "paramet", "valu"]},
{"A_title": "FastMath.max(50.0f -50.0f) => -50.0f; should be +50.0fFastMath.max(50.0f -50.0f) => -50.0f; should be +50.0f. This is because the wrong variable is returned. The bug was not detected by the test case testMinMaxFloat() because that has a bug too - it tests doubles not floats.", "A_clean_title": ["fastmath", "max", "fast", "math", "50", "0f", "50", "0f", "50", "0f", "+50", "0ffastmath", "max", "0f", "fast", "math", "50", "0f", "50", "0f", "50", "0f", "+50", "0f", "thi", "becaus", "wrong", "variabl", "return", "bug", "wa", "not", "detect", "by", "test", "case", "testminmaxfloat", "test", "min", "max", "float", "becaus", "that", "ha", "bug", "too", "it", "test", "doubl", "not", "float"], "B_title": "FastMath.max(50.0f -50.0f) => -50.0f; should be +50.0f", "B_clean_title": ["fastmath", "max", "fast", "math", "50", "0f", "50", "0f", "50", "0f", "+50", "0f"]},
{"A_title": "DateTimeZone.getOffsetFromLocal error during DST transitionThis may be a failure of my understanding but the comments in DateTimeZone.getOffsetFromLocal lead me to believe that if an ambiguous local time is given the offset corresponding to the later of the two possible UTC instants will be returned - i.e. the greater offset.  This doesnt appear to tally with my experience. In fall 2009 America/Los_Angeles changed from -7 to -8 at 2am wall time on November 11. Thus 2am became 1am - so 1:30am is ambiguous. I would therefore expect that constructing a DateTime for November 11th 1:30am would give an instant corresponding with the later value (i.e. 9:30am UTC).", "A_clean_title": ["datetimezon", "getoffsetfromloc", "date", "time", "zone", "get", "offset", "local", "error", "dure", "dst", "transitionthi", "transit", "thi", "may", "failur", "my", "understand", "but", "comment", "datetimezon", "getoffsetfromloc", "date", "time", "zone", "get", "offset", "local", "lead", "me", "believ", "that", "ambigu", "local", "time", "given", "offset", "correspond", "later", "two", "possibl", "utc", "instant", "will", "return", "greater", "offset", "thi", "doesnt", "appear", "talli", "my", "experi", "fall", "2009", "angel", "america", "lo", "chang", "at", "2am", "wall", "time", "novemb", "11", "thu", "2am", "becam", "1am", "so", "1:30am", "ambigu", "would", "therefor", "expect", "that", "construct", "datetim", "date", "time", "novemb", "11th", "1:30am", "would", "give", "instant", "correspond", "later", "valu", "9:30am", "utc"], "B_title": "2952991 The behaviour during DST overlaps is now defined to always return the earlier instant which is normally known as daylight or summer time. Previously the result varied by hemisphere. This affects the constructor of DateTime and other methods", "B_clean_title": ["2952991", "behaviour", "dure", "dst", "overlap", "now", "defin", "alway", "return", "earlier", "instant", "which", "normal", "known", "as", "daylight", "or", "summer", "time", "previous", "result", "vari", "by", "hemispher", "thi", "affect", "constructor", "datetim", "date", "time", "other", "method"]},
{"A_title": "EnumeratedRealDistribution.inverseCumulativeProbability returns values not in the samples setThe method EnumeratedRealDistribution.inverseCumulativeProbability() sometimes returns values that are not in the initial samples domain... I will attach a test to exploit this bug.", "A_clean_title": ["enumeratedrealdistribut", "inversecumulativeprob", "enumer", "real", "distribut", "invers", "cumul", "probabl", "return", "valu", "not", "sampl", "setth", "set", "method", "enumeratedrealdistribut", "inversecumulativeprob", "enumer", "real", "distribut", "invers", "cumul", "probabl", "sometim", "return", "valu", "that", "are", "not", "initi", "sampl", "domain", "will", "attach", "test", "exploit", "thi", "bug"], "B_title": "Fix EnumeratedRealDistribution.inverseCumulativeProbability. Thanks to matteodg and Phil.", "B_clean_title": ["fix", "enumeratedrealdistribut", "inversecumulativeprob", "enumer", "real", "distribut", "invers", "cumul", "probabl", "thank", "matteodg", "phil"]},
{"A_title": "Blob GC throws NPEBlob GC when registered without a shared data store throws NPE. The ClusterRepositoryInfo#getId method should check if clusterId is registered or not.", "A_clean_title": ["blob", "gc", "throw", "npeblob", "npe", "blob", "gc", "when", "regist", "without", "share", "data", "store", "throw", "npe", "clusterrepositoryinfo", "cluster", "repositori", "info", "getid", "get", "id", "method", "check", "clusterid", "cluster", "id", "regist", "or", "not"], "B_title": "Blob GC throws NPE", "B_clean_title": ["blob", "gc", "throw", "npe"]},
{"A_title": "Jackson configuration is not used by ProjectingJackson2HttpMessageConverter  DATACMNS-1152opened and commented  ProjectingJackson2HttpMessageConverter is not using the default MappingJackson2HttpMessageConverter constructor to instantiate an ObjectMapper (that uses Jackson2ObjectMapperBuilder to create a Jackson ObjectMapper based on application configuration) instead ObjectMapper is created directly in SpringDataWebConfiguration.extendMessageConverters(…) . That causes  ProjectingJackson2HttpMessageConverter to not use Jackson configuration from application.properties to create the ObjectMapper and there is no possibility to configure Jackson ObjectMapper . That also breaks MappingJackson2HttpMessageConverter configuration functionality. To solve that issue ObjectMapper creation should be delegated to MappingJackson2HttpMessageConverter default constructor   Affects: 1.13.6 (Ingalls SR6) 2.0 RC2 (Kay)  Backported to:  1.13.7 (Ingalls SR7)", "A_clean_title": ["jackson", "configur", "not", "use", "by", "projectingjackson2httpmessageconvert", "project", "jackson2http", "messag", "convert", "datacmn", "1152open", "comment", "projectingjackson2httpmessageconvert", "project", "jackson2http", "messag", "convert", "not", "default", "mappingjackson2httpmessageconvert", "map", "jackson2http", "messag", "convert", "constructor", "instanti", "objectmapp", "object", "mapper", "that", "use", "jackson2objectmapperbuild", "jackson2object", "mapper", "builder", "creat", "jackson", "objectmapp", "object", "mapper", "base", "applic", "configur", "instead", "objectmapp", "object", "mapper", "creat", "directli", "springdatawebconfigur", "extendmessageconvert", "spring", "data", "web", "configur", "extend", "messag", "convert", "that", "caus", "projectingjackson2httpmessageconvert", "project", "jackson2http", "messag", "convert", "not", "use", "jackson", "configur", "applic", "properti", "creat", "objectmapp", "object", "mapper", "there", "no", "possibl", "configur", "jackson", "objectmapp", "object", "mapper", "that", "also", "break", "mappingjackson2httpmessageconvert", "map", "jackson2http", "messag", "convert", "configur", "function", "solv", "that", "issu", "objectmapp", "object", "mapper", "creation", "deleg", "mappingjackson2httpmessageconvert", "map", "jackson2http", "messag", "convert", "default", "constructor", "affect", "13", "ingal", "sr6", "rc2", "kay", "backport", "13", "ingal", "sr7"], "B_title": "DATACMNS-1152 - Setup of ProjectingJackson2HttpMessageConverter now tries to use unique ObjectMapper from ApplicationContext.  Were now trying to look up a uniquely available ObjectMapper instance from the application context falling back to a simple new instance in case none can be found.", "B_clean_title": ["datacmn", "1152", "setup", "projectingjackson2httpmessageconvert", "project", "jackson2http", "messag", "convert", "now", "tri", "use", "uniqu", "objectmapp", "object", "mapper", "applicationcontext", "applic", "context", "were", "now", "tri", "look", "up", "uniqu", "avail", "objectmapp", "object", "mapper", "instanc", "applic", "context", "fall", "back", "simpl", "new", "instanc", "case", "none", "found"]},
{"A_title": "IndexOutOfBoundsException in FileStore.writeStreamWhen writing streams of specific length I get  code java.lang.IndexOutOfBoundsException at java.nio.Buffer.checkIndex(Buffer.java:538) at java.nio.HeapByteBuffer.getInt(HeapByteBuffer.java:359) at org.apache.jackrabbit.oak.segment.Segment.getGcGen(Segment.java:318) at org.apache.jackrabbit.oak.segment.file.FileStore.writeSegment(FileStore.java:1371) at org.apache.jackrabbit.oak.segment.SegmentWriter SegmentWriteOperation.internalWriteStream(SegmentWriter.java:661) code", "A_clean_title": ["indexoutofboundsexcept", "index", "out", "bound", "except", "filestor", "writestreamwhen", "file", "store", "write", "stream", "when", "write", "stream", "specif", "length", "get", "code", "java", "lang", "indexoutofboundsexcept", "index", "out", "bound", "except", "at", "java", "nio", "buffer", "checkindex", "check", "index", "buffer", "java:538", "at", "java", "nio", "heapbytebuff", "getint", "heap", "byte", "buffer", "get", "int", "heapbytebuff", "java:359", "heap", "byte", "buffer", "at", "org", "apach", "jackrabbit", "oak", "segment", "segment", "getgcgen", "get", "gc", "gen", "segment", "java:318", "at", "org", "apach", "jackrabbit", "oak", "segment", "file", "filestor", "writeseg", "file", "store", "write", "segment", "filestor", "java:1371", "file", "store", "at", "org", "apach", "jackrabbit", "oak", "segment", "segmentwrit", "segment", "writer", "segmentwriteoper", "internalwritestream", "segment", "write", "oper", "intern", "write", "stream", "segmentwrit", "java:661", "segment", "writer", "code"], "B_title": "IndexOutOfBoundsException in FileStore.writeStream Define segment gc generation = 0 for bulk segments and consider the type of the segment in the gc generation methods accordingly", "B_clean_title": ["indexoutofboundsexcept", "index", "out", "bound", "except", "filestor", "writestream", "file", "store", "write", "stream", "defin", "segment", "gc", "gener", "bulk", "segment", "consid", "type", "segment", "gc", "gener", "method", "accordingli"]},
{"A_title": "Bad type inference with goog.isFunction and friendsNone", "A_clean_title": ["bad", "type", "infer", "goog", "isfunct", "function", "friendsnon", "friend", "none"], "B_title": "Fix goog.isFunction typeof x == function and similiar type inference. Fixes issue 841.", "B_clean_title": ["fix", "goog", "isfunct", "function", "typeof", "function", "similiar", "type", "infer", "fix", "issu", "841"]},
{"A_title": "ContentMirrorStoreStrategy #insert fails to enforce uniqueness and is slowFollowing OAK-734 Ive noticed that the _ContentMirrorStoreStrategy_ fails to enforce the uniqueness constraints assumed on the #insert method.  It is also responsible for a slowdown on the #insert method because of the behavior change of the Property2Index (very frequent saves instead of a bulk one).", "A_clean_title": ["contentmirrorstorestrategi", "content", "mirror", "store", "strategi", "insert", "fail", "enforc", "uniqu", "slowfollow", "slow", "follow", "oak", "734", "ive", "notic", "that", "contentmirrorstorestrategi", "content", "mirror", "store", "strategi", "fail", "enforc", "uniqu", "constraint", "assum", "insert", "method", "it", "also", "respons", "slowdown", "insert", "method", "becaus", "behavior", "chang", "property2index", "veri", "frequent", "save", "instead", "bulk", "one"], "B_title": "ContentMirrorStoreStrategy fails to enforce uniqueness and is slow", "B_clean_title": ["contentmirrorstorestrategi", "content", "mirror", "store", "strategi", "fail", "enforc", "uniqu", "slow"]},
{"A_title": "Unable to add days to a MonthDay set to the ISO leap dateIts not possible to add days to a MonthDay set to the ISO leap date (February 29th). This is even more bizarre given the exact error message thrown.", "A_clean_title": ["unabl", "add", "day", "monthday", "month", "day", "set", "iso", "leap", "dateit", "date", "it", "not", "possibl", "add", "day", "monthday", "month", "day", "set", "iso", "leap", "date", "februari", "29th", "thi", "even", "more", "bizarr", "given", "exact", "error", "messag", "thrown"], "B_title": "Fix MonthDay add/subtract around Feb29 3528941", "B_clean_title": ["fix", "monthday", "month", "day", "add", "subtract", "around", "feb29", "3528941"]},
{"A_title": "Empty branch commit returns head revision on trunkMicroKernelImpl returns the head revision on trunk when an empty commit happens on a branch revision.", "A_clean_title": ["empti", "branch", "commit", "return", "head", "revis", "trunkmicrokernelimpl", "trunk", "micro", "kernel", "impl", "return", "head", "revis", "trunk", "when", "empti", "commit", "happen", "branch", "revis"], "B_title": "Empty branch commit returns head revision on trunk", "B_clean_title": ["empti", "branch", "commit", "return", "head", "revis", "trunk"]},
{"A_title": "WebRequestCodingStrategy: path mounting and matchingAssuming a mount path to /p it will match /pxyz  Assuming this is the desired behavior of matching (warning) then to avoid this match it should be declared /p/ but it will create urls such as /app/p//SomePage. which is wrong.  In the servlet specs  the mapping syntax /p is an exact match this is not what you want in your case since youre doing path mapping so the syntax if you want to stick close to the servlet specs should be /p/* or if you wan to get close to mod_proxy syntax it would be /p/  Note that the examples are also using this wrong mapping declaration. In the example below: both should throw a 404: http://www.wicket-library.com/wicket-examples/niceurl/my/mounted/packageXXX http://www.wicket-library.com/wicket-examples/niceurl/my/mounted/Xpackage", "A_clean_title": ["webrequestcodingstrategi", "web", "request", "code", "strategi", "path", "mount", "matchingassum", "match", "assum", "mount", "path", "it", "will", "match", "pxyz", "assum", "thi", "desir", "behavior", "match", "warn", "then", "avoid", "thi", "match", "it", "declar", "but", "it", "will", "creat", "url", "such", "as", "app", "somepag", "some", "page", "which", "wrong", "servlet", "spec", "map", "syntax", "exact", "match", "thi", "not", "what", "you", "want", "your", "case", "sinc", "your", "do", "path", "map", "so", "syntax", "you", "want", "stick", "close", "servlet", "spec", "or", "you", "wan", "get", "close", "mod", "proxi", "syntax", "it", "would", "note", "that", "exampl", "are", "also", "thi", "wrong", "map", "declar", "exampl", "below", "both", "throw", "404", "http", "wicket", "librari", "exampl", "niceurl", "my", "mount", "packagexxx", "www", "com", "wicket", "packag", "xxx", "http", "wicket", "librari", "exampl", "niceurl", "my", "mount", "xpackag", "www", "com", "wicket"], "B_title": "WebRequestCodingStrategy: path mounting and matching", "B_clean_title": ["webrequestcodingstrategi", "web", "request", "code", "strategi", "path", "mount", "match"]},
{"A_title": "arguments is moved to another scopeNone", "A_clean_title": ["argument", "move", "anoth", "scopenon", "scope", "none"], "B_title": "Dont attempt to inline aliases of external names during collapse properties as all the sets can not be accounted for. Fixes issue 931 ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=43187988", "B_clean_title": ["dont", "attempt", "inlin", "alias", "extern", "name", "dure", "collaps", "properti", "as", "all", "set", "not", "account", "fix", "issu", "931", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=43187988"]},
{"A_title": "MiniAccumuloConfig doesnt set 0 for monitor log4j portMonitorLoggingIT will fail on a host if the monitor is already running because MAC doesnt configure itself to use an ephemeral port. We havent really noticed this because MAC doesnt start a monitor by default.", "A_clean_title": ["miniaccumuloconfig", "mini", "accumulo", "config", "doesnt", "set", "monitor", "log4j", "portmonitorloggingit", "port", "monitor", "log", "it", "will", "fail", "host", "monitor", "alreadi", "run", "becaus", "mac", "doesnt", "configur", "itself", "use", "ephemer", "port", "we", "havent", "realli", "notic", "thi", "becaus", "mac", "doesnt", "start", "monitor", "by", "default"], "B_title": "Set 0 for monitor log4j port config value", "B_clean_title": ["set", "monitor", "log4j", "port", "config", "valu"]},
{"A_title": "POST params ignored by IPageParametersEncoder#decodePageParameters()As per this conversation: http://apache-wicket.1842946.n4.nabble.com/how-to-get-https-port-number-in-Wicket-1-5-td4295139.html  it seems that POST params are not properly processed and made available as PageParameters. Can anyone say whether this is intended behavior or not? I will attach a Quickstart to demonstrate.  Martins proposed fix is straightforward but I am not comfortable enough with Wicket internals to say whether or not this would break something.  Thanks", "A_clean_title": ["post", "param", "ignor", "by", "ipageparametersencod", "page", "paramet", "encod", "decodepageparamet", "decod", "page", "paramet", "as", "per", "thi", "convers", "http", "get", "http", "port", "number", "wicket", "apach", "wicket", "1842946", "n4", "nabbl", "td4295139", "html", "com", "how", "it", "seem", "that", "post", "param", "are", "not", "properli", "process", "made", "avail", "as", "pageparamet", "page", "paramet", "anyon", "say", "whether", "thi", "intend", "behavior", "or", "not", "will", "attach", "quickstart", "demonstr", "martin", "propos", "fix", "straightforward", "but", "am", "not", "comfort", "enough", "wicket", "intern", "say", "whether", "or", "not", "thi", "would", "break", "someth", "thank"], "B_title": "POST params ignored by IPageParametersEncoder#decodePageParameters()", "B_clean_title": ["post", "param", "ignor", "by", "ipageparametersencod", "page", "paramet", "encod", "decodepageparamet", "decod", "page", "paramet"]},
{"A_title": "inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials.The inverseCumulativeProbability method of the BinomialDistributionImpl class returns wrong value for large trials.  Following code will be reproduce the problem.  System.out.println(new BinomialDistributionImpl(1000000 0.5).inverseCumulativeProbability(0.5));  This returns 499525 though it should be 499999.  Im not sure how it should be fixed but the cause is that the cumulativeProbability method returns Infinity not NaN.  As the result the checkedCumulativeProbability method doesnt work as expected.", "A_clean_title": ["inversecumulativeprob", "invers", "cumul", "probabl", "binomialdistribut", "binomi", "distribut", "return", "wrong", "valu", "larg", "trial", "inversecumulativeprob", "invers", "cumul", "probabl", "method", "binomialdistributionimpl", "binomi", "distribut", "impl", "class", "return", "wrong", "valu", "larg", "trial", "follow", "code", "will", "reproduc", "problem", "system", "out", "println", "new", "binomialdistributionimpl", "binomi", "distribut", "impl", "1000000", "inversecumulativeprob", "invers", "cumul", "probabl", "thi", "return", "499525", "though", "it", "499999", "im", "not", "sure", "how", "it", "fix", "but", "caus", "that", "cumulativeprob", "cumul", "probabl", "method", "return", "infin", "not", "nan", "na", "as", "result", "checkedcumulativeprob", "check", "cumul", "probabl", "method", "doesnt", "work", "as", "expect"], "B_title": "Use modified Lentz-Thompson algorithm for continued fraction evaluation.", "B_clean_title": ["use", "modifi", "lentz", "thompson", "algorithm", "continu", "fraction", "evalu"]},
{"A_title": "MockHttpServletRequest is broken when used with CryptedUrlWebRequestCodingStrategyUpgraded to 1.3.6. One of my test cases started to fail with  org.apache.wicket.WicketRuntimeException: Internal error parsing wicket:interface = ?x=GR7uTj8e-D8FE0tmM9vvYcwdiASd9OJ5GgveAhSNaig       I tracked down the issue to MockHttpServletRequest .setRequestToComponent() In line 1253 it check for url starting with 6*. However in CryptedUrlWebRequestCodingStrategy following encryption is employed:  198:queryString = shortenUrl(queryString).toString(); 199: 200:// encrypt the query string 201:String encryptedQueryString = urlCrypt.encryptUrlSafe(queryString);   shortenUrl will replace wicket:interface= with 6* but then it gets immediately encrypted consequently MockHttpServletRequest  will never recognize it correctly.", "A_clean_title": ["mockhttpservletrequest", "mock", "http", "servlet", "request", "broken", "when", "use", "cryptedurlwebrequestcodingstrategyupgrad", "crypt", "url", "web", "request", "code", "strategi", "upgrad", "one", "my", "test", "case", "start", "fail", "org", "apach", "wicket", "wicketruntimeexcept", "wicket", "runtim", "except", "intern", "error", "pars", "wicket", "interfac", "x=gr7utj8", "d8fe0tmm9vvycwdiasd9oj5ggveahsnaig", "x=gr7u", "tj8e", "d8fe0tm", "m9vv", "ycwdi", "sd9oj5ggv", "ah", "naig", "track", "down", "issu", "mockhttpservletrequest", "mock", "http", "servlet", "request", "setrequesttocompon", "set", "request", "compon", "line", "1253", "it", "check", "url", "start", "howev", "cryptedurlwebrequestcodingstrategi", "crypt", "url", "web", "request", "code", "strategi", "follow", "encrypt", "employ", "198", "querystr", "queri", "string", "shortenurl", "shorten", "url", "querystr", "queri", "string", "tostr", "string", "199", "200", "encrypt", "queri", "string", "201", "string", "encryptedquerystr", "encrypt", "queri", "string", "urlcrypt", "encrypturlsaf", "url", "crypt", "encrypt", "url", "safe", "querystr", "queri", "string", "shortenurl", "shorten", "url", "will", "replac", "wicket", "interface=", "but", "then", "it", "get", "immedi", "encrypt", "consequ", "mockhttpservletrequest", "mock", "http", "servlet", "request", "will", "never", "recogn", "it", "correctli"], "B_title": "fixed: MockHttpServletRequest is broken when used with CryptedUrlWebRequestCodingStrategy Issue: WICKET-2281", "B_clean_title": ["fix", "mockhttpservletrequest", "mock", "http", "servlet", "request", "broken", "when", "use", "cryptedurlwebrequestcodingstrategi", "crypt", "url", "web", "request", "code", "strategi", "issu", "wicket", "2281"]},
{"A_title": "AutocompleteTextField after Submit does not workI use an AutocompleteTextfield together with a submit-Button. After once submitting the content oft the AutocompleteTextField the parameter q is added to the URL. After that the autocompletion will only complete the parameter q in the url and not the parameter given by ajax.  I tracked the problem down to the callbackURL.  It contains a pattern looking as follows: ....&q=<paramproducedbysubmit>&q=<paramproducedbyajaxautocomplete>  The callbackurl is build of the parameter q and the extraction of parameters only accepts the first parameter", "A_clean_title": ["autocompletetextfield", "autocomplet", "text", "field", "after", "submit", "not", "worki", "work", "use", "autocompletetextfield", "autocomplet", "textfield", "togeth", "submit", "button", "after", "onc", "submit", "content", "oft", "autocompletetextfield", "autocomplet", "text", "field", "paramet", "ad", "url", "after", "that", "autocomplet", "will", "onli", "complet", "paramet", "url", "not", "paramet", "given", "by", "ajax", "track", "problem", "down", "callbackurl", "callback", "url", "it", "contain", "pattern", "look", "as", "follow", "q=", "paramproducedbysubmit", "q=", "paramproducedbyajaxautocomplet", "callbackurl", "build", "paramet", "extract", "paramet", "onli", "accept", "first", "paramet"], "B_title": "AutocompleteTextField after Submit does not work - PageProvider no longer pushes PageParameters into previously stored pages.", "B_clean_title": ["autocompletetextfield", "autocomplet", "text", "field", "after", "submit", "not", "work", "pageprovid", "page", "provid", "no", "longer", "push", "pageparamet", "page", "paramet", "into", "previous", "store", "page"]},
{"A_title": "Dynamically adding component via an IComponentResolver fails within an enclosure for versions after 1.4.1We have been using an IComponentResolver implementation for a long time to allow the inclusion of certain panels to be determined by the markup. Some panels are included inside enclosures and some are not. Both cases worked fine in wicket 1.4.1 but in versions 1.4.2 and later a Tag expected error occurs if the component is wrapped inside a wicket enclosure.  A quickstart example has been included to demonstrate the problem.", "A_clean_title": ["dynam", "ad", "compon", "via", "icomponentresolv", "compon", "resolv", "fail", "within", "enclosur", "version", "after", "1we", "have", "been", "icomponentresolv", "compon", "resolv", "implement", "long", "time", "allow", "inclus", "certain", "panel", "determin", "by", "markup", "some", "panel", "are", "includ", "insid", "enclosur", "some", "are", "not", "both", "case", "work", "fine", "wicket", "but", "version", "later", "tag", "expect", "error", "occur", "compon", "wrap", "insid", "wicket", "enclosur", "quickstart", "exampl", "ha", "been", "includ", "demonstr", "problem"], "B_title": "fixed WICKET-2882: IComponentResolver usage with Enclosure Issue: WICKET-2882", "B_clean_title": ["fix", "wicket", "2882", "icomponentresolv", "compon", "resolv", "usag", "enclosur", "issu", "wicket", "2882"]},
{"A_title": "Unnecessary invocations of LastRevRecovery when recovery already done.Even after _lastRev recovery executed on a cluster node there are unnecessary  invocations of recovery happening on that cluster node till that cluster node comes online again.", "A_clean_title": ["unnecessari", "invoc", "lastrevrecoveri", "last", "rev", "recoveri", "when", "recoveri", "alreadi", "done", "even", "after", "lastrev", "last", "rev", "recoveri", "execut", "cluster", "node", "there", "are", "unnecessari", "invoc", "recoveri", "happen", "that", "cluster", "node", "till", "that", "cluster", "node", "come", "onlin", "again"], "B_title": "- Unnecessary invocations of LastRevRecovery when recovery already done.", "B_clean_title": ["unnecessari", "invoc", "lastrevrecoveri", "last", "rev", "recoveri", "when", "recoveri", "alreadi", "done"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Reverted to original behaviour.", "B_clean_title": ["revert", "origin", "behaviour"]},
{"A_title": "UpdateOp.Key.equals() incorrectAs reported on the dev list 0 the equals implementation of UpdateOp.Key is incorrect.  0 http://markmail.org/message/acpg2mhbxjn4lglu", "A_clean_title": ["updateop", "key", "equal", "updat", "op", "incorrecta", "incorrect", "as", "report", "dev", "list", "equal", "implement", "updateop", "key", "updat", "op", "incorrect", "http", "markmail", "org", "messag", "acpg2mhbxjn4lglu"], "B_title": "UpdateOp.Key.equals() incorrect", "B_clean_title": ["updateop", "key", "equal", "updat", "op", "incorrect"]},
{"A_title": "UrlValidator failes to validate urls that containt multiple dots in pathrefer to UrlValidator.java:466 (isValidPath). if we have an url that contains more than two consequent dots for example http://www.somedomain.com/this_one_is_tricky...but...still.....valid validator will fail. btw the other side effect is that countTokens actually counts ... a two 2dots. One possible workaround is not just count .. tokens but count them along with slash like ../.", "A_clean_title": ["urlvalid", "url", "valid", "fail", "valid", "url", "that", "containt", "multipl", "dot", "pathref", "urlvalid", "java:466", "url", "valid", "isvalidpath", "valid", "path", "we", "have", "url", "that", "contain", "more", "than", "two", "consequ", "dot", "exampl", "http", "somedomain", "www", "one", "tricki", "com", "thi", "but", "still", "valid", "valid", "will", "fail", "btw", "other", "side", "effect", "that", "counttoken", "count", "token", "actual", "count", "two", "2dot", "one", "possibl", "workaround", "not", "just", "count", "token", "but", "count", "them", "along", "slash", "like"], "B_title": "Issue: WICKET-3196", "B_clean_title": ["issu", "wicket", "3196"]},
{"A_title": "StrBuilder appendFixedWidth does not handle nullsAppending a null value with fixed width causes a null pointer exception if getNullText() has not been set.", "A_clean_title": ["strbuilder", "str", "builder", "appendfixedwidth", "append", "fix", "width", "not", "handl", "nullsappend", "null", "append", "null", "valu", "fix", "width", "caus", "null", "pointer", "except", "getnulltext", "get", "null", "text", "ha", "not", "been", "set"], "B_title": "Applying my patch from LANG-412; fixing Peter Oxenhams report that the appendFixedWidthPadRight and appendFixedWidthPadLeft are not null safe if the nullText has not been set", "B_clean_title": ["appli", "my", "patch", "lang", "412", "fix", "peter", "oxenham", "report", "that", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "appendfixedwidthpadleft", "append", "fix", "width", "pad", "left", "are", "not", "null", "safe", "nulltext", "null", "text", "ha", "not", "been", "set"]},
{"A_title": "Closure removes needed code.None", "A_clean_title": ["closur", "remov", "need", "code", "none"], "B_title": "Automated g4 rollback.", "B_clean_title": ["autom", "g4", "rollback"]},
{"A_title": "TypeExtractor.analyzePojo has some problems around the default constructor detectionIf a class does have a default constructor but the user forgot to make it public then TypeExtractor.analyzePojo still thinks everything is OK so it creates a PojoTypeInfo. Then PojoSerializer.createInstance blows up.  Furthermore a return null seems to be missing from the then case of the if after catching the NoSuchMethodException which would also cause a headache for PojoSerializer.  An additional minor issue is that the word class is printed twice in several places because class.toString also prepends it to the class name.", "A_clean_title": ["typeextractor", "analyzepojo", "type", "extractor", "analyz", "pojo", "ha", "some", "problem", "around", "default", "constructor", "detectionif", "detect", "class", "have", "default", "constructor", "but", "user", "forgot", "make", "it", "public", "then", "typeextractor", "analyzepojo", "type", "extractor", "analyz", "pojo", "still", "think", "everyth", "ok", "so", "it", "creat", "pojotypeinfo", "pojo", "type", "info", "then", "pojoseri", "createinst", "pojo", "serial", "creat", "instanc", "blow", "up", "furthermor", "return", "null", "seem", "miss", "then", "case", "after", "catch", "nosuchmethodexcept", "no", "such", "method", "except", "which", "would", "also", "caus", "headach", "pojoseri", "pojo", "serial", "addit", "minor", "issu", "that", "word", "class", "print", "twice", "sever", "place", "becaus", "class", "tostr", "string", "also", "prepend", "it", "class", "name"], "B_title": "handle the case of a non-public default ctor in TypeExtractor.analyzePojo", "B_clean_title": ["handl", "case", "non", "public", "default", "ctor", "typeextractor", "analyzepojo", "type", "extractor", "analyz", "pojo"]},
{"A_title": "-0.0 becomes 0 even in whitespace modeNone", "A_clean_title": ["becom", "even", "whitespac", "modenon", "mode", "none"], "B_title": "Correct output of -0.0. Fixes issue 582.", "B_clean_title": ["correct", "output", "fix", "issu", "582"]},
{"A_title": "Invalid javascript when setStripJavascriptCommentsAndWhitespace is enabledWhen setStripJavascriptCommentsAndWhitespace is enabled (for example in deployment mode) some javascript files get corrupted. For example the following line (notice the 2 spaces after return) return  this.__unbind__(type fn); is compacted to return this.__unbind__(type fn); which does not execute the unbind function.", "A_clean_title": ["invalid", "javascript", "when", "setstripjavascriptcommentsandwhitespac", "set", "strip", "javascript", "comment", "whitespac", "enabledwhen", "enabl", "when", "setstripjavascriptcommentsandwhitespac", "set", "strip", "javascript", "comment", "whitespac", "enabl", "exampl", "deploy", "mode", "some", "javascript", "file", "get", "corrupt", "exampl", "follow", "line", "notic", "space", "after", "return", "return", "thi", "unbind", "type", "fn", "compact", "return", "thi", "unbind", "type", "fn", "which", "not", "execut", "unbind", "function"], "B_title": "", "B_clean_title": []},
{"A_title": "SimplexSolver not working as expected 2SimplexSolver didnt find the optimal solution. Program for Lpsolve: ===================== /* Objective function */ max: 7 a 3 b; /* Constraints */ R1: +3 a -5 c <= 0; R2: +2 a -5 d <= 0; R3: +2 b -5 c <= 0; R4: +3 b -5 d <= 0; R5: +3 a +2 b <= 5; R6: +2 a +3 b <= 5; /* Variable bounds */ a <= 1; b <= 1; ===================== Results(correct): a = 1 b = 1 value = 10 Program for SimplexSolve: ===================== LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double 7 3 0 0  0); Collection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>(); podmienky.add(new LinearConstraint(new double 1 0 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 0 1 0 0  Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double 3 0 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 2 0 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 2 -5 0  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 0 3 0 -5  Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double 3 2 0 0  Relationship.LEQ 5)); podmienky.add(new LinearConstraint(new double 2 3 0 0  Relationship.LEQ 5)); SimplexSolver solver = new SimplexSolver(); RealPointValuePair result = solver.optimize(kritFcia podmienky GoalType.MAXIMIZE true); ===================== Results(incorrect): a = 1 b = 0.5 value = 8.5 P.S. I used the latest software from the repository (including MATH-286 fix).", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "2simplexsolv", "2simplex", "solver", "didnt", "find", "optim", "solut", "program", "lpsolv", "object", "function", "max", "constraint", "r1", "+3", "r2", "+2", "r3", "+2", "r4", "+3", "r5", "+3", "+2", "r6", "+2", "+3", "variabl", "bound", "result", "correct", "valu", "10", "program", "simplexsolv", "simplex", "solv", "linearobjectivefunct", "linear", "object", "function", "kritfcia", "krit", "fcia", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "podmienki", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "leq", "simplexsolv", "simplex", "solver", "solver", "new", "simplexsolv", "simplex", "solver", "realpointvaluepair", "real", "point", "valu", "pair", "result", "solver", "optim", "kritfcia", "krit", "fcia", "podmienki", "goaltyp", "maxim", "goal", "type", "true", "result", "incorrect", "valu", "use", "latest", "softwar", "repositori", "includ", "math", "286", "fix"], "B_title": "fixed an error induced by zero entries in simplex solver JIRA: MATH-288", "B_clean_title": ["fix", "error", "induc", "by", "zero", "entri", "simplex", "solver", "jira", "math", "288"]},
{"A_title": "true/false are not always replaced for !0/!1None", "A_clean_title": ["true", "fals", "are", "not", "alway", "replac", "1none"], "B_title": "Fixes issue 787.  Removing or replacing a Node is the AST caused any following Function nodes to be skipped in the late peephole folding. To prevent this save off the next node before visiting a Node.", "B_clean_title": ["fix", "issu", "787", "remov", "or", "replac", "node", "ast", "caus", "ani", "follow", "function", "node", "skip", "late", "peephol", "fold", "prevent", "thi", "save", "off", "next", "node", "befor", "visit", "node"]},
{"A_title": "Missing properties when deserializing using a builder class with a non-default constructor and a mutator annotated with  @JsonUnwrappedWhen deserializing using a builder class with a non-default constructor and any number of mutator methods annotated with @JsonUnwrapped the  BuilderBasedDeserializer::deserializeUsingPropertyBasedWithUnwrapped method cuts short the process of adding SettableBeanProperties. The logic dictates that once all properties necessary to construct the builder have been found the builder is constructed using all known SettableBeanProperties that have been found up to that point in the tokenizing process.  Therefore in the case that the builder has a single property required for construction and that property is found anywhere other than at the end of the JSON content any properties subsequent to the constructor property are not evaluated and are left with their default values.  Given the following classes:   And given the following JSON string:    We will see the following output:   However if we place the  emp_id property at the end of the JSON string we would get the following output:  If we were to place  emp_age and emp_first_name and emp_last_name all after the emp_id property in the JSON string we would get the following output:", "A_clean_title": ["miss", "properti", "when", "deseri", "builder", "class", "non", "default", "constructor", "mutat", "annot", "jsonunwrappedwhen", "json", "unwrap", "when", "deseri", "builder", "class", "non", "default", "constructor", "ani", "number", "mutat", "method", "annot", "jsonunwrap", "json", "unwrap", "builderbaseddeseri", "builder", "base", "deseri", ":deserializeusingpropertybasedwithunwrap", ":deseri", "properti", "base", "unwrap", "method", "cut", "short", "process", "ad", "settablebeanproperti", "settabl", "bean", "properti", "logic", "dictat", "that", "onc", "all", "properti", "necessari", "construct", "builder", "have", "been", "found", "builder", "construct", "all", "known", "settablebeanproperti", "settabl", "bean", "properti", "that", "have", "been", "found", "up", "that", "point", "token", "process", "therefor", "case", "that", "builder", "ha", "singl", "properti", "requir", "construct", "that", "properti", "found", "anywher", "other", "than", "at", "end", "json", "content", "ani", "properti", "subsequ", "constructor", "properti", "are", "not", "evalu", "are", "left", "their", "default", "valu", "given", "follow", "class", "given", "follow", "json", "string", "we", "will", "see", "follow", "output", "howev", "we", "place", "emp", "id", "properti", "at", "end", "json", "string", "we", "would", "get", "follow", "output", "we", "were", "place", "emp", "age", "emp", "first", "name", "emp", "last", "name", "all", "after", "emp", "id", "properti", "json", "string", "we", "would", "get", "follow", "output"], "B_title": "Merge pull request #1574 from jjware/2.8  Fixes #1573", "B_clean_title": ["merg", "pull", "request", "1574", "jjware", "fix", "1573"]},
{"A_title": "Type checking error when replacing a function with a stub after calling.None", "A_clean_title": ["type", "check", "error", "when", "replac", "function", "stub", "after", "call", "none"], "B_title": "Fix issue 586. Distinguishing declared functions from inferred functions is really hard!", "B_clean_title": ["fix", "issu", "586", "distinguish", "declar", "function", "infer", "function", "realli", "hard"]},
{"A_title": "MathUtils.equals(double double) does not work properly for floatsMathUtils.equals(double double) does not work properly for floats.  There is no equals(floatfloat) so float parameters are automatically promoted to double. However that is not necessarily appropriate given that the ULP for a double is much smaller than the ULP for a float.  So for example:  code double oneDouble = 1.0d; assertTrue(MathUtils.equals(oneDouble Double.longBitsToDouble(1 + Double.doubleToLongBits(oneDouble)))); // OK float oneFloat = 1.0f; assertTrue(MathUtils.equals(oneFloat Float.intBitsToFloat(1 + Float.floatToIntBits(oneFloat)))); // FAILS float  f1 = 333.33334f; double d1 = 333.33334d; assertTrue(MathUtils.equals(d1 f1)); // FAILS code  I think the equals() methods need to be duplicated with the appropriate changes for floats to avoid any problems with the promotion of floats.", "A_clean_title": ["mathutil", "equal", "math", "util", "doubl", "doubl", "not", "work", "properli", "floatsmathutil", "equal", "float", "math", "util", "doubl", "doubl", "not", "work", "properli", "float", "there", "no", "equal", "floatfloat", "so", "float", "paramet", "are", "automat", "promot", "doubl", "howev", "that", "not", "necessarili", "appropri", "given", "that", "ulp", "doubl", "much", "smaller", "than", "ulp", "float", "so", "exampl", "code", "doubl", "onedoubl", "one", "doubl", "0d", "asserttru", "assert", "true", "mathutil", "equal", "math", "util", "onedoubl", "one", "doubl", "doubl", "longbitstodoubl", "long", "bit", "doubl", "doubl", "doubletolongbit", "doubl", "long", "bit", "onedoubl", "one", "doubl", "ok", "float", "onefloat", "one", "float", "0f", "asserttru", "assert", "true", "mathutil", "equal", "math", "util", "onefloat", "one", "float", "float", "intbitstofloat", "int", "bit", "float", "float", "floattointbit", "float", "int", "bit", "onefloat", "one", "float", "fail", "float", "f1", "333", "33334f", "doubl", "d1", "333", "33334d", "asserttru", "assert", "true", "mathutil", "equal", "math", "util", "d1", "f1", "fail", "code", "think", "equal", "method", "need", "duplic", "appropri", "chang", "float", "avoid", "ani", "problem", "promot", "float"], "B_title": "MathUtils.equals(double double) does not work properly for floats - add equivalent (float float) methods and basic tests", "B_clean_title": ["mathutil", "equal", "math", "util", "doubl", "doubl", "not", "work", "properli", "float", "add", "equival", "float", "float", "method", "basic", "test"]},
{"A_title": "ArrayIndexOutOfBoundException in EigenDecompositionImplThe following test triggers an ArrayIndexOutOfBoundException:      public void testMath308()           double mainTridiagonal =              22.330154644539597 46.65485522478641 17.393672330044705 54.46687435351116 80.17800767709437         ;         double secondaryTridiagonal =              13.04450406501361 -5.977590941539671 2.9040909856707517 7.1570352792841225         ;          // the reference values have been computed using routine DSTEMR         // from the fortran library LAPACK version 3.2.1         double refEigenValues =              14.138204224043099 18.847969733754262 52.536278520113882 53.456697699894512 82.044413207204002         ;         RealVector refEigenVectors =              new ArrayRealVector(new double   0.584677060845929 -0.367177264979103 -0.721453187784497  0.052971054621812 -0.005740715188257 )             new ArrayRealVector(new double   0.713933751051495 -0.190582113553930  0.671410443368332 -0.056056055955050  0.006541576993581 )             new ArrayRealVector(new double   0.222368839324646  0.514921891363332 -0.021377019336614  0.801196801016305 -0.207446991247740 )             new ArrayRealVector(new double   0.314647769490148  0.750806415553905 -0.167700312025760 -0.537092972407375  0.143854968127780 )             new ArrayRealVector(new double  -0.000462690386766 -0.002118073109055  0.011530080757413  0.252322434584915  0.967572088232592 )         ;          // the following line triggers the exception         EigenDecomposition decomposition =             new EigenDecompositionImpl(mainTridiagonal secondaryTridiagonal MathUtils.SAFE_MIN);          double eigenValues = decomposition.getRealEigenvalues();         for (int i = 0; i < refEigenValues.length; ++i)              assertEquals(refEigenValuesi eigenValuesi 1.0e-6);             if (refEigenVectorsi.dotProduct(decomposition.getEigenvector(i)) < 0)                  assertEquals(0 refEigenVectorsi.add(decomposition.getEigenvector(i)).getNorm() 1.0e-6);              else                  assertEquals(0 refEigenVectorsi.subtract(decomposition.getEigenvector(i)).getNorm() 1.0e-6);                               Running the previous method as a Junit test triggers the exception when the EigenDecompositionImpl instance is built. The first few lines of the stack trace are:  java.lang.ArrayIndexOutOfBoundsException: -1 at org.apache.commons.math.linear.EigenDecompositionImpl.computeShiftIncrement(EigenDecompositionImpl.java:1545) at org.apache.commons.math.linear.EigenDecompositionImpl.goodStep(EigenDecompositionImpl.java:1072) at org.apache.commons.math.linear.EigenDecompositionImpl.processGeneralBlock(EigenDecompositionImpl.java:894) at org.apache.commons.math.linear.EigenDecompositionImpl.findEigenvalues(EigenDecompositionImpl.java:658) at org.apache.commons.math.linear.EigenDecompositionImpl.decompose(EigenDecompositionImpl.java:246) at org.apache.commons.math.linear.EigenDecompositionImpl.<init>(EigenDecompositionImpl.java:205) at org.apache.commons.math.linear.EigenDecompositionImplTest.testMath308(EigenDecompositionImplTest.java:136)   Im currently investigating this bug. It is not a simple index translation error between the original fortran (Lapack) and commons-math implementation.", "A_clean_title": ["arrayindexoutofboundexcept", "array", "index", "out", "bound", "except", "eigendecompositionimplth", "eigen", "decomposit", "impl", "follow", "test", "trigger", "arrayindexoutofboundexcept", "array", "index", "out", "bound", "except", "public", "void", "testmath308", "test", "math308", "doubl", "maintridiagon", "main", "tridiagon", "22", "330154644539597", "46", "65485522478641", "17", "393672330044705", "54", "46687435351116", "80", "17800767709437", "doubl", "secondarytridiagon", "secondari", "tridiagon", "13", "04450406501361", "977590941539671", "9040909856707517", "1570352792841225", "refer", "valu", "have", "been", "comput", "routin", "dstemr", "fortran", "librari", "lapack", "version", "doubl", "refeigenvalu", "ref", "eigen", "valu", "14", "138204224043099", "18", "847969733754262", "52", "536278520113882", "53", "456697699894512", "82", "044413207204002", "realvector", "real", "vector", "refeigenvector", "ref", "eigen", "vector", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "584677060845929", "367177264979103", "721453187784497", "052971054621812", "005740715188257", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "713933751051495", "190582113553930", "671410443368332", "056056055955050", "006541576993581", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "222368839324646", "514921891363332", "021377019336614", "801196801016305", "207446991247740", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "314647769490148", "750806415553905", "167700312025760", "537092972407375", "143854968127780", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "000462690386766", "002118073109055", "011530080757413", "252322434584915", "967572088232592", "follow", "line", "trigger", "except", "eigendecomposit", "eigen", "decomposit", "decomposit", "new", "eigendecompositionimpl", "eigen", "decomposit", "impl", "maintridiagon", "main", "tridiagon", "secondarytridiagon", "secondari", "tridiagon", "mathutil", "math", "util", "safe", "min", "doubl", "eigenvalu", "eigen", "valu", "decomposit", "getrealeigenvalu", "get", "real", "eigenvalu", "int", "refeigenvalu", "length", "ref", "eigen", "valu", "++i", "assertequ", "assert", "equal", "refeigenvaluesi", "ref", "eigen", "valuesi", "eigenvaluesi", "eigen", "valuesi", "0e", "refeigenvectorsi", "dotproduct", "ref", "eigen", "vectorsi", "dot", "product", "decomposit", "geteigenvector", "get", "eigenvector", "assertequ", "assert", "equal", "refeigenvectorsi", "add", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e", "assertequ", "assert", "equal", "refeigenvectorsi", "subtract", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e", "run", "previou", "method", "as", "junit", "test", "trigger", "except", "when", "eigendecompositionimpl", "eigen", "decomposit", "impl", "instanc", "built", "first", "few", "line", "stack", "trace", "are", "java", "lang", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "at", "org", "apach", "common", "math", "linear", "eigendecompositionimpl", "computeshiftincr", "eigen", "decomposit", "impl", "comput", "shift", "increment", "eigendecompositionimpl", "java:1545", "eigen", "decomposit", "impl", "at", "org", "apach", "common", "math", "linear", "eigendecompositionimpl", "goodstep", "eigen", "decomposit", "impl", "good", "step", "eigendecompositionimpl", "java:1072", "eigen", "decomposit", "impl", "at", "org", "apach", "common", "math", "linear", "eigendecompositionimpl", "processgeneralblock", "eigen", "decomposit", "impl", "process", "gener", "block", "eigendecompositionimpl", "java:894", "eigen", "decomposit", "impl", "at", "org", "apach", "common", "math", "linear", "eigendecompositionimpl", "findeigenvalu", "eigen", "decomposit", "impl", "find", "eigenvalu", "eigendecompositionimpl", "java:658", "eigen", "decomposit", "impl", "at", "org", "apach", "common", "math", "linear", "eigendecompositionimpl", "decompos", "eigen", "decomposit", "impl", "eigendecompositionimpl", "java:246", "eigen", "decomposit", "impl", "at", "org", "apach", "common", "math", "linear", "eigendecompositionimpl", "eigen", "decomposit", "impl", "init", "eigendecompositionimpl", "java:205", "eigen", "decomposit", "impl", "at", "org", "apach", "common", "math", "linear", "eigendecompositionimpltest", "testmath308", "eigen", "decomposit", "impl", "test", "test", "math308", "eigendecompositionimpltest", "java:136", "eigen", "decomposit", "impl", "test", "im", "current", "investig", "thi", "bug", "it", "not", "simpl", "index", "translat", "error", "between", "origin", "fortran", "lapack", "common", "math", "implement"], "B_title": "fixed an ArrayIndexOutOfBoundsException Kudos to Dimitri who debugged this mess of fortran/java array indices translation JIRA: MATH-308", "B_clean_title": ["fix", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "kudo", "dimitri", "who", "debug", "thi", "mess", "fortran", "java", "array", "indic", "translat", "jira", "math", "308"]},
{"A_title": "implementation of smallest enclosing ball algorithm sometime failsThe algorithm for finding the smallest ball is designed in such a way the radius should be strictly increasing at each iteration.  In some cases it is not true and one iteration has a smaller ball. In most cases there is no consequence there is just one or two more iterations. However in rare cases discovered while testing 3D this generates an infinite loop.  Some very short offending cases have already been identified and added to the test suite. These cases are currently deactivated in the main repository while I am already working on them. The test cases are  * WelzlEncloser2DTest.testReducingBall * WelzlEncloser2DTest.testLargeSamples * WelzlEncloser3DTest.testInfiniteLoop * WelzlEncloser3DTest.testLargeSamples", "A_clean_title": ["implement", "smallest", "enclos", "ball", "algorithm", "sometim", "failsth", "fail", "algorithm", "find", "smallest", "ball", "design", "such", "way", "radiu", "strictli", "increas", "at", "each", "iter", "some", "case", "it", "not", "true", "one", "iter", "ha", "smaller", "ball", "most", "case", "there", "no", "consequ", "there", "just", "one", "or", "two", "more", "iter", "howev", "rare", "case", "discov", "while", "test", "3d", "thi", "gener", "infinit", "loop", "some", "veri", "short", "offend", "case", "have", "alreadi", "been", "identifi", "ad", "test", "suit", "these", "case", "are", "current", "deactiv", "main", "repositori", "while", "am", "alreadi", "work", "them", "test", "case", "are", "welzlencloser2dtest", "testreducingbal", "welzl", "encloser2d", "test", "test", "reduc", "ball", "welzlencloser2dtest", "testlargesampl", "welzl", "encloser2d", "test", "test", "larg", "sampl", "welzlencloser3dtest", "testinfiniteloop", "welzl", "encloser3d", "test", "test", "infinit", "loop", "welzlencloser3dtest", "testlargesampl", "welzl", "encloser3d", "test", "test", "larg", "sampl"], "B_title": "Fixed sphere generation in degenerated cases.", "B_clean_title": ["fix", "sphere", "gener", "degener", "case"]},
{"A_title": "math Function math.fraction.ProperFractionFormat.parse(String ParsePosition) return illogical resultHello I find illogical returned result from function Fraction parse(String source  ParsePostion pos) (in class ProperFractionFormat of the Fraction Package) of  the Commons Math library. Please see the following code segment for more  details:  ProperFractionFormat properFormat = new ProperFractionFormat(); result = null; String source = 1 -1 / 2; ParsePosition pos = new ParsePosition(0); //Test 1 : fail  public void testParseNegative()    String source = -1 -2 / 3;    ParsePosition pos = new ParsePosition(0);    Fraction actual = properFormat.parse(source pos);    assertNull(actual);  // Test2: success public void testParseNegative()    String source = -1 -2 / 3;    ParsePosition pos = new ParsePosition(0);    Fraction actual = properFormat.parse(source pos);  // return Fraction 1/3    assertEquals(1 source.getNumerator());    assertEquals(3 source.getDenominator());   Note: Similarly when I passed in the following inputs:    input 2: (source = “1 2 / -3” pos = 0)   input 3: ( source = ” -1 -2 / 3” pos = 0) Function Fraction parse(String ParsePosition) returned Fraction 1/3 (means  the result Fraction had numerator = 1 and  denominator = 3)for all 3 inputs  above. I think the function does not handle parsing the numberator/ denominator  properly incase input string provide invalid numerator/denominator.  Thank you!", "A_clean_title": ["math", "function", "math", "fraction", "properfractionformat", "pars", "proper", "fraction", "format", "string", "parseposit", "pars", "posit", "return", "illog", "resulthello", "result", "hello", "find", "illog", "return", "result", "function", "fraction", "pars", "string", "sourc", "parsepost", "pars", "postion", "po", "class", "properfractionformat", "proper", "fraction", "format", "fraction", "packag", "common", "math", "librari", "pleas", "see", "follow", "code", "segment", "more", "detail", "properfractionformat", "proper", "fraction", "format", "properformat", "proper", "format", "new", "properfractionformat", "proper", "fraction", "format", "result", "null", "string", "sourc", "parseposit", "pars", "posit", "po", "new", "parseposit", "pars", "posit", "test", "fail", "public", "void", "testparseneg", "test", "pars", "neg", "string", "sourc", "parseposit", "pars", "posit", "po", "new", "parseposit", "pars", "posit", "fraction", "actual", "properformat", "pars", "proper", "format", "sourc", "po", "assertnul", "assert", "null", "actual", "test2", "success", "public", "void", "testparseneg", "test", "pars", "neg", "string", "sourc", "parseposit", "pars", "posit", "po", "new", "parseposit", "pars", "posit", "fraction", "actual", "properformat", "pars", "proper", "format", "sourc", "po", "return", "fraction", "assertequ", "assert", "equal", "sourc", "getnumer", "get", "numer", "assertequ", "assert", "equal", "sourc", "getdenomin", "get", "denomin", "note", "similarli", "when", "pass", "follow", "input", "input", "sourc", "po", "input", "sourc", "po", "function", "fraction", "pars", "string", "parseposit", "pars", "posit", "return", "fraction", "mean", "result", "fraction", "had", "numer", "denomin", "all", "input", "abov", "think", "function", "not", "handl", "pars", "number", "denomin", "properli", "incas", "input", "string", "provid", "invalid", "numer", "denomin", "thank", "you"], "B_title": "Modified ProperFractionFormat to reject embedded minus signs. JIRA: MATH-60 Reported by Nhung Nnguyen", "B_clean_title": ["modifi", "properfractionformat", "proper", "fraction", "format", "reject", "embed", "minu", "sign", "jira", "math", "60", "report", "by", "nhung", "nnguyen"]},
{"A_title": "LevenbergMarquardtOptimizer reports 0 iterationsThe method LevenbergMarquardtOptimizer.getIterations() does not report the correct number of iterations; It always returns 0. A quick look at the code shows that only SimplexOptimizer calls BaseOptimizer.incrementEvaluationsCount() Ive put a test case below. Notice how the evaluations count is correctly incremented but the iterations count is not.      @Test     public void testGetIterations()          // setup         LevenbergMarquardtOptimizer otim = new LevenbergMarquardtOptimizer();          // action         otim.optimize(new MaxEval(100) new Target(new double  1 )                 new Weight(new double  1 ) new InitialGuess(                         new double  3 ) new ModelFunction(                         new MultivariateVectorFunction()                              @Override                             public double value(double point)                                     throws IllegalArgumentException                                  return new double  FastMath.pow(point0 4) ;                                                      ) new ModelFunctionJacobian(                         new MultivariateMatrixFunction()                              @Override                             public double value(double point)                                     throws IllegalArgumentException                                  return new double   0.25 * FastMath.pow(                                         point0 3)  ;                                                      ));          // verify         assertThat(otim.getEvaluations() greaterThan(1));         assertThat(otim.getIterations() greaterThan(1));", "A_clean_title": ["levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "report", "iterationsth", "iter", "method", "levenbergmarquardtoptim", "getiter", "levenberg", "marquardt", "optim", "get", "iter", "not", "report", "correct", "number", "iter", "it", "alway", "return", "quick", "look", "at", "code", "show", "that", "onli", "simplexoptim", "simplex", "optim", "call", "baseoptim", "incrementevaluationscount", "base", "optim", "increment", "evalu", "count", "ive", "put", "test", "case", "below", "notic", "how", "evalu", "count", "correctli", "increment", "but", "iter", "count", "not", "test", "public", "void", "testgetiter", "test", "get", "iter", "setup", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "otim", "new", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "action", "otim", "optim", "new", "maxev", "max", "eval", "100", "new", "target", "new", "doubl", "new", "weight", "new", "doubl", "new", "initialguess", "initi", "guess", "new", "doubl", "new", "modelfunct", "model", "function", "new", "multivariatevectorfunct", "multivari", "vector", "function", "overrid", "public", "doubl", "valu", "doubl", "point", "throw", "illegalargumentexcept", "illeg", "argument", "except", "return", "new", "doubl", "fastmath", "pow", "fast", "math", "point0", "new", "modelfunctionjacobian", "model", "function", "jacobian", "new", "multivariatematrixfunct", "multivari", "matrix", "function", "overrid", "public", "doubl", "valu", "doubl", "point", "throw", "illegalargumentexcept", "illeg", "argument", "except", "return", "new", "doubl", "25", "fastmath", "pow", "fast", "math", "point0", "verifi", "assertthat", "assert", "that", "otim", "getevalu", "get", "evalu", "greaterthan", "greater", "than", "assertthat", "assert", "that", "otim", "getiter", "get", "iter", "greaterthan", "greater", "than"], "B_title": "Increment iteration counter. By default the maximum number of iterations is Integer.MAX_VALUE.", "B_clean_title": ["increment", "iter", "counter", "by", "default", "maximum", "number", "iter", "integ", "max", "valu"]},
{"A_title": "Incorrect output if a function is assigned to a variable and the function contains a variable with the same nameNone", "A_clean_title": ["incorrect", "output", "function", "assign", "variabl", "function", "contain", "variabl", "same", "namenon", "name", "none"], "B_title": "Modify normalization to distinguish function expression names from parameters and local variables. Fixes issue 539.", "B_clean_title": ["modifi", "normal", "distinguish", "function", "express", "name", "paramet", "local", "variabl", "fix", "issu", "539"]},
{"A_title": "XPath: Query with mixed full-text and or conditions failsWhen performing a query like   noformat         //element(* test:Asset)             (                 jcr:contains(. summer)                 or                 jcr:content/metadata/@tags = namespace:season/summer             ) and                 jcr:contains(jcr:content/metadata/@format image)               noformat  The Lucene/Aggregate returns as well nodes that does not match all the criterias.", "A_clean_title": ["xpath", "path", "queri", "mix", "full", "text", "or", "condit", "failswhen", "fail", "when", "perform", "queri", "like", "noformat", "element", "test", "asset", "jcr", "contain", "summer", "or", "jcr", "content", "metadata", "tag", "namespac", "season", "summer", "jcr", "contain", "jcr", "content", "metadata", "format", "imag", "noformat", "lucen", "aggreg", "return", "as", "well", "node", "that", "not", "match", "all", "criteria"], "B_title": "Query with mixed full-text and or conditions fails", "B_clean_title": ["queri", "mix", "full", "text", "or", "condit", "fail"]},
{"A_title": "Initial read of _lastRev creates incorrect RevisionComparatorThe logic in backgroundRead(false) orders the local lastRev  before external lastRev. This the last change done by the local cluster node will look as if it happend before a potentially older external change.", "A_clean_title": ["initi", "read", "lastrev", "last", "rev", "creat", "incorrect", "revisioncomparatorth", "revis", "compar", "logic", "backgroundread", "background", "read", "fals", "order", "local", "lastrev", "last", "rev", "befor", "extern", "lastrev", "last", "rev", "thi", "last", "chang", "done", "by", "local", "cluster", "node", "will", "look", "as", "it", "happend", "befor", "potenti", "older", "extern", "chang"], "B_title": "Initial read of _lastRev creates incorrect RevisionComparator", "B_clean_title": ["initi", "read", "lastrev", "last", "rev", "creat", "incorrect", "revisioncompar", "revis", "compar"]},
{"A_title": "Oak Lucene index doesnt get notified about updates when index is stored on the file systemIt looks like the the lucene IndexTracked class responsible for refreshing the in-memory cache of the lucene index doesnt get the update notification when the index is stored on the file system. This results in searches not working until the next restart", "A_clean_title": ["oak", "lucen", "index", "doesnt", "get", "notifi", "about", "updat", "when", "index", "store", "file", "systemit", "system", "it", "look", "like", "lucen", "indextrack", "index", "track", "class", "respons", "refresh", "memori", "cach", "lucen", "index", "doesnt", "get", "updat", "notif", "when", "index", "store", "file", "system", "thi", "result", "search", "not", "work", "until", "next", "restart"], "B_title": "- Oak Lucene index doesnt get notified about updates when index is stored on the file system", "B_clean_title": ["oak", "lucen", "index", "doesnt", "get", "notifi", "about", "updat", "when", "index", "store", "file", "system"]},
{"A_title": "ExecutionGraph gets stuck in state FAILINGIt is a bit of a rare case but the following can currently happen:    1. Jobs runs for a while some tasks are already finished.   2. Job fails goes to state failing and restarting. Non-finished tasks fail or are canceled.   3. For the finished tasks ask-futures from certain messages (for example for releasing intermediate result partitions) can fail (timeout) and cause the execution to go from FINISHED to FAILED   4. This triggers the execution graph to go to FAILING without ever going further into RESTARTING again   5. The job is stuck  It initially looks like this is mainly an issue for batch jobs (jobs where tasks do finish rather than run infinitely).  The log that shows how this manifests: code -------------------------------------------------------------------------------- 17:19:19782 INFO  akka.event.slf4j.Slf4jLogger                                  - Slf4jLogger started 17:19:19844 INFO  Remoting                                                      - Starting remoting 17:19:20065 INFO  Remoting                                                      - Remoting started; listening on addresses :akka.tcp://flink@127.0.0.1:56722 17:19:20090 INFO  org.apache.flink.runtime.blob.BlobServer                      - Created BLOB server storage directory /tmp/blobStore-6766f51a-1c51-4a03-acfb-08c2c29c11f0 17:19:20096 INFO  org.apache.flink.runtime.blob.BlobServer                      - Started BLOB server at 0.0.0.0:43327 - max concurrent requests: 50 - max backlog: 1000 17:19:20113 INFO  org.apache.flink.runtime.jobmanager.MemoryArchivist           - Started memory archivist akka://flink/user/archive 17:19:20115 INFO  org.apache.flink.runtime.checkpoint.SavepointStoreFactory     - No savepoint state backend configured. Using job manager savepoint state backend. 17:19:20118 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Starting JobManager at akka.tcp://flink@127.0.0.1:56722/user/jobmanager. 17:19:20123 INFO  org.apache.flink.runtime.jobmanager.JobManager                - JobManager akka.tcp://flink@127.0.0.1:56722/user/jobmanager was granted leadership with leader session ID None. 17:19:25605 INFO  org.apache.flink.runtime.instance.InstanceManager             - Registered TaskManager at testing-worker-linux-docker-e6d6931f-3200-linux-4 (akka.tcp://flink@172.17.0.253:43702/user/taskmanager) as f213232054587f296a12140d56f63ed1. Current number of registered hosts is 1. Current number of alive task slots is 2. 17:19:26758 INFO  org.apache.flink.runtime.instance.InstanceManager             - Registered TaskManager at testing-worker-linux-docker-e6d6931f-3200-linux-4 (akka.tcp://flink@172.17.0.253:43956/user/taskmanager) as f9e78baa14fb38c69517fb1bcf4f419c. Current number of registered hosts is 2. Current number of alive task slots is 4. 17:19:27064 INFO  org.apache.flink.api.java.ExecutionEnvironment                - The job has 0 registered types and 0 default Kryo serializers 17:19:27071 INFO  org.apache.flink.client.program.Client                        - Starting client actor system 17:19:27072 INFO  org.apache.flink.runtime.client.JobClient                     - Starting JobClient actor system 17:19:27110 INFO  akka.event.slf4j.Slf4jLogger                                  - Slf4jLogger started 17:19:27121 INFO  Remoting                                                      - Starting remoting 17:19:27143 INFO  org.apache.flink.runtime.client.JobClient                     - Started JobClient actor system at 127.0.0.1:51198 17:19:27145 INFO  Remoting                                                      - Remoting started; listening on addresses :akka.tcp://flink@127.0.0.1:51198 17:19:27325 INFO  org.apache.flink.runtime.client.JobClientActor                - Disconnect from JobManager null. 17:19:27362 INFO  org.apache.flink.runtime.client.JobClientActor                - Received job Flink Java Job at Mon Jan 18 17:19:27 UTC 2016 (fa05fd25993a8742da09cc5023c1e38d). 17:19:27362 INFO  org.apache.flink.runtime.client.JobClientActor                - Could not submit job Flink Java Job at Mon Jan 18 17:19:27 UTC 2016 (fa05fd25993a8742da09cc5023c1e38d) because there is no connection to a JobManager. 17:19:27379 INFO  org.apache.flink.runtime.client.JobClientActor                - Connect to JobManager Actorakka.tcp://flink@127.0.0.1:56722/user/jobmanager#-1489998809. 17:19:27379 INFO  org.apache.flink.runtime.client.JobClientActor                - Connected to new JobManager akka.tcp://flink@127.0.0.1:56722/user/jobmanager. 17:19:27379 INFO  org.apache.flink.runtime.client.JobClientActor                - Sending message to JobManager akka.tcp://flink@127.0.0.1:56722/user/jobmanager to submit job Flink Java Job at Mon Jan 18 17:19:27 UTC 2016 (fa05fd25993a8742da09cc5023c1e38d) and wait for progress 17:19:27380 INFO  org.apache.flink.runtime.client.JobClientActor                - Upload jar files to job manager akka.tcp://flink@127.0.0.1:56722/user/jobmanager. 17:19:27380 INFO  org.apache.flink.runtime.client.JobClientActor                - Submit job to the job manager akka.tcp://flink@127.0.0.1:56722/user/jobmanager. 17:19:27453 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Submitting job fa05fd25993a8742da09cc5023c1e38d (Flink Java Job at Mon Jan 18 17:19:27 UTC 2016). 17:19:27591 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Scheduling job fa05fd25993a8742da09cc5023c1e38d (Flink Java Job at Mon Jan 18 17:19:27 UTC 2016). 17:19:27592 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (1/4) (c79bf4381462c690f5999f2d1949ab50) switched from CREATED to SCHEDULED 17:19:27596 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (1/4) (c79bf4381462c690f5999f2d1949ab50) switched from SCHEDULED to DEPLOYING 17:19:27597 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (1/4) (attempt #0) to testing-worker-linux-docker-e6d6931f-3200-linux-4 17:19:27606 INFO  org.apache.flink.runtime.client.JobClientActor                - Job was successfully submitted to the JobManager akka.tcp://flink@127.0.0.1:56722/user/jobmanager. 17:19:27630 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Status of job fa05fd25993a8742da09cc5023c1e38d (Flink Java Job at Mon Jan 18 17:19:27 UTC 2016) changed to RUNNING. 17:19:27637 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (2/4) (e73af91028cb76f7d3cd887cb6d66755) switched from CREATED to SCHEDULED 17:19:27654 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27Job execution switched to status RUNNING. 17:19:27655 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(1/4) switched to SCHEDULED  17:19:27656 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(1/4) switched to DEPLOYING  17:19:27666 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (2/4) (e73af91028cb76f7d3cd887cb6d66755) switched from SCHEDULED to DEPLOYING 17:19:27667 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (2/4) (attempt #0) to testing-worker-linux-docker-e6d6931f-3200-linux-4 17:19:27667 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(2/4) switched to SCHEDULED  17:19:27669 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(2/4) switched to DEPLOYING  17:19:27681 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (3/4) (807daf978da9dc347dca930822c78f8f) switched from CREATED to SCHEDULED 17:19:27682 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (3/4) (807daf978da9dc347dca930822c78f8f) switched from SCHEDULED to DEPLOYING 17:19:27682 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (3/4) (attempt #0) to testing-worker-linux-docker-e6d6931f-3200-linux-4 17:19:27682 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (4/4) (ba45c37065b67fc8f5005a50d0e88fff) switched from CREATED to SCHEDULED 17:19:27682 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (4/4) (ba45c37065b67fc8f5005a50d0e88fff) switched from SCHEDULED to DEPLOYING 17:19:27685 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (4/4) (attempt #0) to testing-worker-linux-docker-e6d6931f-3200-linux-4 17:19:27686 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(3/4) switched to SCHEDULED  17:19:27687 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(3/4) switched to DEPLOYING  17:19:27687 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(4/4) switched to SCHEDULED  17:19:27692 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(4/4) switched to DEPLOYING  17:19:27833 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (4/4) (ba45c37065b67fc8f5005a50d0e88fff) switched from DEPLOYING to RUNNING 17:19:27839 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(4/4) switched to RUNNING  17:19:27840 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (2/4) (e73af91028cb76f7d3cd887cb6d66755) switched from DEPLOYING to RUNNING 17:19:27852 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(2/4) switched to RUNNING  17:19:27896 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (1/4) (c79bf4381462c690f5999f2d1949ab50) switched from DEPLOYING to RUNNING 17:19:27898 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (3/4) (807daf978da9dc347dca930822c78f8f) switched from DEPLOYING to RUNNING 17:19:27901 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(1/4) switched to RUNNING  17:19:27905 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:27DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(3/4) switched to RUNNING  17:19:28114 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (3/4) (7997918330ecf2610b3298a8c8ef2852) switched from CREATED to SCHEDULED 17:19:28126 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (1/4) (6421c8f88b191ea844619a40a523773b) switched from CREATED to SCHEDULED 17:19:28134 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (1/4) (6421c8f88b191ea844619a40a523773b) switched from SCHEDULED to DEPLOYING 17:19:28134 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (1/4) (attempt #0) to testing-worker-linux-docker-e6d6931f-3200-linux-4 17:19:28126 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (2/4) (d0d011dc0a0823bcec5a57a369b334ed) switched from CREATED to SCHEDULED 17:19:28139 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (2/4) (d0d011dc0a0823bcec5a57a369b334ed) switched from SCHEDULED to DEPLOYING 17:19:28139 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (2/4) (attempt #0) to testing-worker-linux-docker-e6d6931f-3200-linux-4 17:19:28117 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (4/4) (c928d19f73d700e80cdfad650689febb) switched from CREATED to SCHEDULED 17:19:28134 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (3/4) (7997918330ecf2610b3298a8c8ef2852) switched from SCHEDULED to DEPLOYING 17:19:28140 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (3/4) (attempt #0) to testing-worker-linux-docker-e6d6931f-3200-linux-4 17:19:28140 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (4/4) (c928d19f73d700e80cdfad650689febb) switched from SCHEDULED to DEPLOYING 17:19:28141 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (4/4) (attempt #0) to testing-worker-linux-docker-e6d6931f-3200-linux-4 17:19:28147 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(3/4) switched to SCHEDULED  17:19:28153 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(1/4) switched to SCHEDULED  17:19:28153 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(1/4) switched to DEPLOYING  17:19:28153 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(2/4) switched to SCHEDULED  17:19:28153 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(2/4) switched to DEPLOYING  17:19:28156 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(3/4) switched to DEPLOYING  17:19:28158 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(4/4) switched to SCHEDULED  17:19:28165 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(4/4) switched to DEPLOYING  17:19:28238 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (2/4) (e73af91028cb76f7d3cd887cb6d66755) switched from RUNNING to FINISHED 17:19:28242 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(2/4) switched to FINISHED  17:19:28308 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (3/4) (807daf978da9dc347dca930822c78f8f) switched from RUNNING to FINISHED 17:19:28315 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (1/4) (c79bf4381462c690f5999f2d1949ab50) switched from RUNNING to FINISHED 17:19:28317 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(3/4) switched to FINISHED  17:19:28318 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(1/4) switched to FINISHED  17:19:28328 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (1/4) (6421c8f88b191ea844619a40a523773b) switched from DEPLOYING to RUNNING 17:19:28336 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(1/4) switched to RUNNING  17:19:28338 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (3/4) (7997918330ecf2610b3298a8c8ef2852) switched from DEPLOYING to RUNNING 17:19:28341 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(3/4) switched to RUNNING  17:19:28459 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat)) (4/4) (ba45c37065b67fc8f5005a50d0e88fff) switched from RUNNING to FINISHED 17:19:28463 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28DataSource (at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73) (org.apache.flink.api.java.io.ParallelIteratorInputFormat))(4/4) switched to FINISHED  17:19:28520 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (4/4) (c928d19f73d700e80cdfad650689febb) switched from DEPLOYING to RUNNING 17:19:28529 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(4/4) switched to RUNNING  17:19:28540 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (2/4) (d0d011dc0a0823bcec5a57a369b334ed) switched from DEPLOYING to RUNNING 17:19:28545 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:28CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(2/4) switched to RUNNING  17:19:32384 INFO  org.apache.flink.runtime.instance.InstanceManager             - Registered TaskManager at testing-worker-linux-docker-e6d6931f-3200-linux-4 (akka.tcp://flink@172.17.0.253:60852/user/taskmanager) as 5848d44035a164a0302da6c8701ff748. Current number of registered hosts is 3. Current number of alive task slots is 6. 17:19:32598 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Reduce (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (1/1) (d0f8f69f9047c3154b860850955de20f) switched from CREATED to SCHEDULED 17:19:32598 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Reduce (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (1/1) (d0f8f69f9047c3154b860850955de20f) switched from SCHEDULED to DEPLOYING 17:19:32598 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying Reduce (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (1/1) (attempt #0) to testing-worker-linux-docker-e6d6931f-3200-linux-4 17:19:32605 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:32Reduce (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(1/1) switched to SCHEDULED  17:19:32605 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:32Reduce (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(1/1) switched to DEPLOYING  17:19:32611 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (4/4) (c928d19f73d700e80cdfad650689febb) switched from RUNNING to FINISHED 17:19:32614 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:32CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(4/4) switched to FINISHED  17:19:32717 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (1/4) (6421c8f88b191ea844619a40a523773b) switched from RUNNING to FINISHED 17:19:32719 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:32CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(1/4) switched to FINISHED  17:19:32724 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Reduce (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (1/1) (d0f8f69f9047c3154b860850955de20f) switched from DEPLOYING to RUNNING 17:19:32726 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:32Reduce (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(1/1) switched to RUNNING  17:19:32843 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (2/4) (d0d011dc0a0823bcec5a57a369b334ed) switched from RUNNING to FINISHED 17:19:32845 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:32CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(2/4) switched to FINISHED  17:19:33092 WARN  akka.remote.ReliableDeliverySupervisor                        - Association with remote system akka.tcp://flink@172.17.0.253:43702 has failed address is now gated for 5000 ms. Reason is: Disassociated. 17:19:39111 WARN  Remoting                                                      - Tried to associate with unreachable remote address akka.tcp://flink@172.17.0.253:43702. Address is now gated for 5000 ms all messages to this address will be delivered to dead letters. Reason: Connection refused: /172.17.0.253:43702 17:19:39113 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Task manager akka.tcp://flink@172.17.0.253:43702/user/taskmanager terminated. 17:19:39114 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (3/4) (7997918330ecf2610b3298a8c8ef2852) switched from RUNNING to FAILED 17:19:39120 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:39CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(3/4) switched to FAILED  java.lang.Exception: The slot in which the task was executed has been released. Probably loss of TaskManager f213232054587f296a12140d56f63ed1 @ testing-worker-linux-docker-e6d6931f-3200-linux-4 - 2 slots - URL: akka.tcp://flink@172.17.0.253:43702/user/taskmanager at org.apache.flink.runtime.instance.SimpleSlot.releaseSlot(SimpleSlot.java:151) at org.apache.flink.runtime.instance.SlotSharingGroupAssignment.releaseSharedSlot(SlotSharingGroupAssignment.java:547) at org.apache.flink.runtime.instance.SharedSlot.releaseSlot(SharedSlot.java:119) at org.apache.flink.runtime.instance.Instance.markDead(Instance.java:156) at org.apache.flink.runtime.instance.InstanceManager.unregisterTaskManager(InstanceManager.java:215) at org.apache.flink.runtime.jobmanager.JobManager  anonfun handleMessage 1.applyOrElse(JobManager.scala:792) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LeaderSessionMessageFilter  anonfun receive 1.applyOrElse(LeaderSessionMessageFilter.scala:44) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:33) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:28) at scala.PartialFunction class.applyOrElse(PartialFunction.scala:118) at org.apache.flink.runtime.LogMessages  anon 1.applyOrElse(LogMessages.scala:28) at akka.actor.Actor class.aroundReceive(Actor.scala:465) at org.apache.flink.runtime.jobmanager.JobManager.aroundReceive(JobManager.scala:100) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) at akka.actor.dungeon.DeathWatch class.receivedTerminated(DeathWatch.scala:46) at akka.actor.ActorCell.receivedTerminated(ActorCell.scala:369) at akka.actor.ActorCell.autoReceiveMessage(ActorCell.scala:501) at akka.actor.ActorCell.invoke(ActorCell.scala:486) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:254) at akka.dispatch.Mailbox.run(Mailbox.scala:221) at akka.dispatch.Mailbox.exec(Mailbox.scala:231) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)  17:19:39129 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Reduce (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (1/1) (d0f8f69f9047c3154b860850955de20f) switched from RUNNING to CANCELING 17:19:39132 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - DataSink (collect()) (1/1) (895e1ea552281a665ae390c966cdb3b7) switched from CREATED to CANCELED 17:19:39149 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:39Job execution switched to status FAILING. java.lang.Exception: The slot in which the task was executed has been released. Probably loss of TaskManager f213232054587f296a12140d56f63ed1 @ testing-worker-linux-docker-e6d6931f-3200-linux-4 - 2 slots - URL: akka.tcp://flink@172.17.0.253:43702/user/taskmanager at org.apache.flink.runtime.instance.SimpleSlot.releaseSlot(SimpleSlot.java:151) at org.apache.flink.runtime.instance.SlotSharingGroupAssignment.releaseSharedSlot(SlotSharingGroupAssignment.java:547) at org.apache.flink.runtime.instance.SharedSlot.releaseSlot(SharedSlot.java:119) at org.apache.flink.runtime.instance.Instance.markDead(Instance.java:156) at org.apache.flink.runtime.instance.InstanceManager.unregisterTaskManager(InstanceManager.java:215) at org.apache.flink.runtime.jobmanager.JobManager  anonfun handleMessage 1.applyOrElse(JobManager.scala:792) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LeaderSessionMessageFilter  anonfun receive 1.applyOrElse(LeaderSessionMessageFilter.scala:44) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:33) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:28) at scala.PartialFunction class.applyOrElse(PartialFunction.scala:118) at org.apache.flink.runtime.LogMessages  anon 1.applyOrElse(LogMessages.scala:28) at akka.actor.Actor class.aroundReceive(Actor.scala:465) at org.apache.flink.runtime.jobmanager.JobManager.aroundReceive(JobManager.scala:100) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) at akka.actor.dungeon.DeathWatch class.receivedTerminated(DeathWatch.scala:46) at akka.actor.ActorCell.receivedTerminated(ActorCell.scala:369) at akka.actor.ActorCell.autoReceiveMessage(ActorCell.scala:501) at akka.actor.ActorCell.invoke(ActorCell.scala:486) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:254) at akka.dispatch.Mailbox.run(Mailbox.scala:221) at akka.dispatch.Mailbox.exec(Mailbox.scala:231) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) 17:19:39173 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:39Reduce (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(1/1) switched to CANCELING  17:19:39173 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:39DataSink (collect())(1/1) switched to CANCELED  17:19:39174 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Reduce (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (1/1) (d0f8f69f9047c3154b860850955de20f) switched from CANCELING to FAILED 17:19:39177 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:39Reduce (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(1/1) switched to FAILED  java.lang.Exception: The slot in which the task was executed has been released. Probably loss of TaskManager f213232054587f296a12140d56f63ed1 @ testing-worker-linux-docker-e6d6931f-3200-linux-4 - 2 slots - URL: akka.tcp://flink@172.17.0.253:43702/user/taskmanager at org.apache.flink.runtime.instance.SimpleSlot.releaseSlot(SimpleSlot.java:151) at org.apache.flink.runtime.instance.SlotSharingGroupAssignment.releaseSharedSlot(SlotSharingGroupAssignment.java:547) at org.apache.flink.runtime.instance.SharedSlot.releaseSlot(SharedSlot.java:119) at org.apache.flink.runtime.instance.Instance.markDead(Instance.java:156) at org.apache.flink.runtime.instance.InstanceManager.unregisterTaskManager(InstanceManager.java:215) at org.apache.flink.runtime.jobmanager.JobManager  anonfun handleMessage 1.applyOrElse(JobManager.scala:792) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LeaderSessionMessageFilter  anonfun receive 1.applyOrElse(LeaderSessionMessageFilter.scala:44) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:33) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:28) at scala.PartialFunction class.applyOrElse(PartialFunction.scala:118) at org.apache.flink.runtime.LogMessages  anon 1.applyOrElse(LogMessages.scala:28) at akka.actor.Actor class.aroundReceive(Actor.scala:465) at org.apache.flink.runtime.jobmanager.JobManager.aroundReceive(JobManager.scala:100) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) at akka.actor.dungeon.DeathWatch class.receivedTerminated(DeathWatch.scala:46) at akka.actor.ActorCell.receivedTerminated(ActorCell.scala:369) at akka.actor.ActorCell.autoReceiveMessage(ActorCell.scala:501) at akka.actor.ActorCell.invoke(ActorCell.scala:486) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:254) at akka.dispatch.Mailbox.run(Mailbox.scala:221) at akka.dispatch.Mailbox.exec(Mailbox.scala:231) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)  17:19:39179 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:39Job execution switched to status RESTARTING. 17:19:39179 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Delaying retry of job execution for 10000 ms ... 17:19:39179 INFO  org.apache.flink.runtime.instance.InstanceManager             - Unregistered task manager akka.tcp://flink@172.17.0.253:43702/user/taskmanager. Number of registered task managers 2. Number of available slots 4. 17:19:39179 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Status of job fa05fd25993a8742da09cc5023c1e38d (Flink Java Job at Mon Jan 18 17:19:27 UTC 2016) changed to FAILING. java.lang.Exception: The slot in which the task was executed has been released. Probably loss of TaskManager f213232054587f296a12140d56f63ed1 @ testing-worker-linux-docker-e6d6931f-3200-linux-4 - 2 slots - URL: akka.tcp://flink@172.17.0.253:43702/user/taskmanager at org.apache.flink.runtime.instance.SimpleSlot.releaseSlot(SimpleSlot.java:151) at org.apache.flink.runtime.instance.SlotSharingGroupAssignment.releaseSharedSlot(SlotSharingGroupAssignment.java:547) at org.apache.flink.runtime.instance.SharedSlot.releaseSlot(SharedSlot.java:119) at org.apache.flink.runtime.instance.Instance.markDead(Instance.java:156) at org.apache.flink.runtime.instance.InstanceManager.unregisterTaskManager(InstanceManager.java:215) at org.apache.flink.runtime.jobmanager.JobManager  anonfun handleMessage 1.applyOrElse(JobManager.scala:792) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LeaderSessionMessageFilter  anonfun receive 1.applyOrElse(LeaderSessionMessageFilter.scala:44) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:33) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:28) at scala.PartialFunction class.applyOrElse(PartialFunction.scala:118) at org.apache.flink.runtime.LogMessages  anon 1.applyOrElse(LogMessages.scala:28) at akka.actor.Actor class.aroundReceive(Actor.scala:465) at org.apache.flink.runtime.jobmanager.JobManager.aroundReceive(JobManager.scala:100) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) at akka.actor.dungeon.DeathWatch class.receivedTerminated(DeathWatch.scala:46) at akka.actor.ActorCell.receivedTerminated(ActorCell.scala:369) at akka.actor.ActorCell.autoReceiveMessage(ActorCell.scala:501) at akka.actor.ActorCell.invoke(ActorCell.scala:486) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:254) at akka.dispatch.Mailbox.run(Mailbox.scala:221) at akka.dispatch.Mailbox.exec(Mailbox.scala:231) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) 17:19:39180 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Status of job fa05fd25993a8742da09cc5023c1e38d (Flink Java Job at Mon Jan 18 17:19:27 UTC 2016) changed to RESTARTING. 17:19:42766 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) (2/4) (d0d011dc0a0823bcec5a57a369b334ed) switched from FINISHED to FAILED 17:19:42773 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:42CHAIN Partition -> Map (Map at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73)) -> Combine (Reduce at testTaskManagerFailure(TaskManagerProcessFailureBatchRecoveryITCase.java:73))(2/4) switched to FAILED  java.lang.IllegalStateException: Update task on instance f213232054587f296a12140d56f63ed1 @ testing-worker-linux-docker-e6d6931f-3200-linux-4 - 2 slots - URL: akka.tcp://flink@172.17.0.253:43702/user/taskmanager failed due to: at org.apache.flink.runtime.executiongraph.Execution 5.onFailure(Execution.java:915) at akka.dispatch.OnFailure.internal(Future.scala:228) at akka.dispatch.OnFailure.internal(Future.scala:227) at akka.dispatch.japi CallbackBridge.apply(Future.scala:174) at akka.dispatch.japi CallbackBridge.apply(Future.scala:171) at scala.PartialFunction class.applyOrElse(PartialFunction.scala:118) at scala.runtime.AbstractPartialFunction.applyOrElse(AbstractPartialFunction.scala:25) at scala.concurrent.Future  anonfun onFailure 1.apply(Future.scala:136) at scala.concurrent.Future  anonfun onFailure 1.apply(Future.scala:134) at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) at scala.concurrent.impl.ExecutionContextImpl  anon 3.exec(ExecutionContextImpl.scala:107) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) Caused by: akka.pattern.AskTimeoutException: Ask timed out on Actorakka.tcp://flink@172.17.0.253:43702/user/taskmanager#-1712955384 after 10000 ms at akka.pattern.PromiseActorRef  anonfun 1.apply mcV sp(AskSupport.scala:333) at akka.actor.Scheduler  anon 7.run(Scheduler.scala:117) at scala.concurrent.Future InternalCallbackExecutor .scala concurrent Future InternalCallbackExecutor  unbatchedExecute(Future.scala:694) at scala.concurrent.Future InternalCallbackExecutor .execute(Future.scala:691) at akka.actor.LightArrayRevolverScheduler TaskHolder.executeTask(Scheduler.scala:467) at akka.actor.LightArrayRevolverScheduler  anon 8.executeBucket 1(Scheduler.scala:419) at akka.actor.LightArrayRevolverScheduler  anon 8.nextTick(Scheduler.scala:423) at akka.actor.LightArrayRevolverScheduler  anon 8.run(Scheduler.scala:375) at java.lang.Thread.run(Thread.java:745)  17:19:42774 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Status of job fa05fd25993a8742da09cc5023c1e38d (Flink Java Job at Mon Jan 18 17:19:27 UTC 2016) changed to FAILING. java.lang.IllegalStateException: Update task on instance f213232054587f296a12140d56f63ed1 @ testing-worker-linux-docker-e6d6931f-3200-linux-4 - 2 slots - URL: akka.tcp://flink@172.17.0.253:43702/user/taskmanager failed due to: at org.apache.flink.runtime.executiongraph.Execution 5.onFailure(Execution.java:915) at akka.dispatch.OnFailure.internal(Future.scala:228) at akka.dispatch.OnFailure.internal(Future.scala:227) at akka.dispatch.japi CallbackBridge.apply(Future.scala:174) at akka.dispatch.japi CallbackBridge.apply(Future.scala:171) at scala.PartialFunction class.applyOrElse(PartialFunction.scala:118) at scala.runtime.AbstractPartialFunction.applyOrElse(AbstractPartialFunction.scala:25) at scala.concurrent.Future  anonfun onFailure 1.apply(Future.scala:136) at scala.concurrent.Future  anonfun onFailure 1.apply(Future.scala:134) at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) at scala.concurrent.impl.ExecutionContextImpl  anon 3.exec(ExecutionContextImpl.scala:107) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) Caused by: akka.pattern.AskTimeoutException: Ask timed out on Actorakka.tcp://flink@172.17.0.253:43702/user/taskmanager#-1712955384 after 10000 ms at akka.pattern.PromiseActorRef  anonfun 1.apply mcV sp(AskSupport.scala:333) at akka.actor.Scheduler  anon 7.run(Scheduler.scala:117) at scala.concurrent.Future InternalCallbackExecutor .scala concurrent Future InternalCallbackExecutor  unbatchedExecute(Future.scala:694) at scala.concurrent.Future InternalCallbackExecutor .execute(Future.scala:691) at akka.actor.LightArrayRevolverScheduler TaskHolder.executeTask(Scheduler.scala:467) at akka.actor.LightArrayRevolverScheduler  anon 8.executeBucket 1(Scheduler.scala:419) at akka.actor.LightArrayRevolverScheduler  anon 8.nextTick(Scheduler.scala:423) at akka.actor.LightArrayRevolverScheduler  anon 8.run(Scheduler.scala:375) at java.lang.Thread.run(Thread.java:745) 17:19:42780 INFO  org.apache.flink.runtime.client.JobClientActor                - 01/18/2016 17:19:42Job execution switched to status FAILING. java.lang.IllegalStateException: Update task on instance f213232054587f296a12140d56f63ed1 @ testing-worker-linux-docker-e6d6931f-3200-linux-4 - 2 slots - URL: akka.tcp://flink@172.17.0.253:43702/user/taskmanager failed due to: at org.apache.flink.runtime.executiongraph.Execution 5.onFailure(Execution.java:915) at akka.dispatch.OnFailure.internal(Future.scala:228) at akka.dispatch.OnFailure.internal(Future.scala:227) at akka.dispatch.japi CallbackBridge.apply(Future.scala:174) at akka.dispatch.japi CallbackBridge.apply(Future.scala:171) at scala.PartialFunction class.applyOrElse(PartialFunction.scala:118) at scala.runtime.AbstractPartialFunction.applyOrElse(AbstractPartialFunction.scala:25) at scala.concurrent.Future  anonfun onFailure 1.apply(Future.scala:136) at scala.concurrent.Future  anonfun onFailure 1.apply(Future.scala:134) at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) at scala.concurrent.impl.ExecutionContextImpl  anon 3.exec(ExecutionContextImpl.scala:107) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) Caused by: akka.pattern.AskTimeoutException: Ask timed out on Actorakka.tcp://flink@172.17.0.253:43702/user/taskmanager#-1712955384 after 10000 ms at akka.pattern.PromiseActorRef  anonfun 1.apply mcV sp(AskSupport.scala:333) at akka.actor.Scheduler  anon 7.run(Scheduler.scala:117) at scala.concurrent.Future InternalCallbackExecutor .scala concurrent Future InternalCallbackExecutor  unbatchedExecute(Future.scala:694) at scala.concurrent.Future InternalCallbackExecutor .execute(Future.scala:691) at akka.actor.LightArrayRevolverScheduler TaskHolder.executeTask(Scheduler.scala:467) at akka.actor.LightArrayRevolverScheduler  anon 8.executeBucket 1(Scheduler.scala:419) at akka.actor.LightArrayRevolverScheduler  anon 8.nextTick(Scheduler.scala:423) at akka.actor.LightArrayRevolverScheduler  anon 8.run(Scheduler.scala:375) at java.lang.Thread.run(Thread.java:745) 17:19:49152 WARN  Remoting                                                      - Tried to associate with unreachable remote address akka.tcp://flink@172.17.0.253:43702. Address is now gated for 5000 ms all messages to this address will be delivered to dead letters. Reason: Connection refused: /172.17.0.253:43702 17:19:59172 WARN  Remoting                                                      - Tried to associate with unreachable remote address akka.tcp://flink@172.17.0.253:43702. Address is now gated for 5000 ms all messages to this address will be delivered to dead letters. Reason: Connection refused: /172.17.0.253:43702 17:20:09191 WARN  Remoting                                                      - Tried to associate with unreachable remote address akka.tcp://flink@172.17.0.253:43702. Address is now gated for 5000 ms all messages to this address will be delivered to dead letters. Reason: Connection refused: /172.17.0.253:43702 17:24:32423 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Stopping JobManager akka.tcp://flink@127.0.0.1:56722/user/jobmanager. 17:24:32440 ERROR org.apache.flink.test.recovery.TaskManagerProcessFailureBatchRecoveryITCase  -  -------------------------------------------------------------------------------- Test testTaskManagerProcessFailure0(org.apache.flink.test.recovery.TaskManagerProcessFailureBatchRecoveryITCase) failed with: java.lang.AssertionError: The program did not finish in time at org.junit.Assert.fail(Assert.java:88) at org.junit.Assert.assertTrue(Assert.java:41) at org.junit.Assert.assertFalse(Assert.java:64) at org.apache.flink.test.recovery.AbstractTaskManagerProcessFailureRecoveryTest.testTaskManagerProcessFailure(AbstractTaskManagerProcessFailureRecoveryTest.java:212) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.junit.runners.model.FrameworkMethod 1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.rules.TestWatcher 1.evaluate(TestWatcher.java:55) at org.junit.rules.RunRules.evaluate(RunRules.java:20) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) at org.junit.runners.ParentRunner 3.run(ParentRunner.java:238) at org.junit.runners.ParentRunner 1.schedule(ParentRunner.java:63) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) at org.junit.runners.ParentRunner.access 000(ParentRunner.java:53) at org.junit.runners.ParentRunner 2.evaluate(ParentRunner.java:229) at org.junit.runners.ParentRunner.run(ParentRunner.java:309) at org.junit.runners.Suite.runChild(Suite.java:127) at org.junit.runners.Suite.runChild(Suite.java:26) at org.junit.runners.ParentRunner 3.run(ParentRunner.java:238) at org.junit.runners.ParentRunner 1.schedule(ParentRunner.java:63) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) at org.junit.runners.ParentRunner.access 000(ParentRunner.java:53) at org.junit.runners.ParentRunner 2.evaluate(ParentRunner.java:229) at org.junit.runners.ParentRunner.run(ParentRunner.java:309) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283) at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128) code", "A_clean_title": ["executiongraph", "execut", "graph", "get", "stuck", "state", "failingit", "fail", "it", "bit", "rare", "case", "but", "follow", "current", "happen", "job", "run", "while", "some", "task", "are", "alreadi", "finish", "job", "fail", "goe", "state", "fail", "restart", "non", "finish", "task", "fail", "or", "are", "cancel", "finish", "task", "ask", "futur", "certain", "messag", "exampl", "releas", "intermedi", "result", "partit", "fail", "timeout", "caus", "execut", "go", "finish", "fail", "thi", "trigger", "execut", "graph", "go", "fail", "without", "ever", "go", "further", "into", "restart", "again", "job", "stuck", "it", "initi", "look", "like", "thi", "mainli", "issu", "batch", "job", "job", "where", "task", "finish", "rather", "than", "run", "infinit", "log", "that", "show", "how", "thi", "manifest", "code", "17:19:19782", "info", "akka", "event", "slf4j", "slf4jlogger", "slf4j", "logger", "slf4jlogger", "slf4j", "logger", "start", "17:19:19844", "info", "remot", "start", "remot", "17:19:20065", "info", "remot", "remot", "start", "listen", "address", "akka", "tcp", "flink", "127", "1:56722", "17:19:20090", "info", "org", "apach", "flink", "runtim", "blob", "blobserv", "blob", "server", "creat", "blob", "server", "storag", "directori", "6766f51a", "1c51", "4a03", "acfb", "08c2c29c11f0", "tmp", "blobstor", "blob", "store", "17:19:20096", "info", "org", "apach", "flink", "runtim", "blob", "blobserv", "blob", "server", "start", "blob", "server", "at", "0:43327", "max", "concurr", "request", "50", "max", "backlog", "1000", "17:19:20113", "info", "org", "apach", "flink", "runtim", "jobmanag", "memoryarchivist", "memori", "archivist", "start", "memori", "archivist", "akka", "flink", "user", "archiv", "17:19:20115", "info", "org", "apach", "flink", "runtim", "checkpoint", "savepointstorefactori", "savepoint", "store", "factori", "no", "savepoint", "state", "backend", "configur", "job", "manag", "savepoint", "state", "backend", "17:19:20118", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "start", "jobmanag", "job", "manag", "at", "akka", "tcp", "flink", "127", "1:56722", "user", "jobmanag", "17:19:20123", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "jobmanag", "job", "manag", "akka", "tcp", "flink", "127", "1:56722", "user", "jobmanag", "wa", "grant", "leadership", "leader", "session", "id", "none", "17:19:25605", "info", "org", "apach", "flink", "runtim", "instanc", "instancemanag", "instanc", "manag", "regist", "taskmanag", "task", "manag", "at", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "akka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "as", "f213232054587f296a12140d56f63ed1", "current", "number", "regist", "host", "current", "number", "aliv", "task", "slot", "17:19:26758", "info", "org", "apach", "flink", "runtim", "instanc", "instancemanag", "instanc", "manag", "regist", "taskmanag", "task", "manag", "at", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "akka", "tcp", "flink", "172", "17", "253:43956", "user", "taskmanag", "as", "f9e78baa14fb38c69517fb1bcf4f419c", "current", "number", "regist", "host", "current", "number", "aliv", "task", "slot", "17:19:27064", "info", "org", "apach", "flink", "api", "java", "executionenviron", "execut", "environ", "job", "ha", "regist", "type", "default", "kryo", "serial", "17:19:27071", "info", "org", "apach", "flink", "client", "program", "client", "start", "client", "actor", "system", "17:19:27072", "info", "org", "apach", "flink", "runtim", "client", "jobclient", "job", "client", "start", "jobclient", "job", "client", "actor", "system", "17:19:27110", "info", "akka", "event", "slf4j", "slf4jlogger", "slf4j", "logger", "slf4jlogger", "slf4j", "logger", "start", "17:19:27121", "info", "remot", "start", "remot", "17:19:27143", "info", "org", "apach", "flink", "runtim", "client", "jobclient", "job", "client", "start", "jobclient", "job", "client", "actor", "system", "at", "127", "1:51198", "17:19:27145", "info", "remot", "remot", "start", "listen", "address", "akka", "tcp", "flink", "127", "1:51198", "17:19:27325", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "disconnect", "jobmanag", "job", "manag", "null", "17:19:27362", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "receiv", "job", "flink", "java", "job", "at", "mon", "jan", "18", "17:19:27", "utc", "2016", "fa05fd25993a8742da09cc5023c1e38d", "17:19:27362", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "could", "not", "submit", "job", "flink", "java", "job", "at", "mon", "jan", "18", "17:19:27", "utc", "2016", "fa05fd25993a8742da09cc5023c1e38d", "becaus", "there", "no", "connect", "jobmanag", "job", "manag", "17:19:27379", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "connect", "jobmanag", "job", "manag", "actorakka", "tcp", "flink", "127", "1:56722", "user", "jobmanag", "1489998809", "17:19:27379", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "connect", "new", "jobmanag", "job", "manag", "akka", "tcp", "flink", "127", "1:56722", "user", "jobmanag", "17:19:27379", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "send", "messag", "jobmanag", "job", "manag", "akka", "tcp", "flink", "127", "1:56722", "user", "jobmanag", "submit", "job", "flink", "java", "job", "at", "mon", "jan", "18", "17:19:27", "utc", "2016", "fa05fd25993a8742da09cc5023c1e38d", "wait", "progress", "17:19:27380", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "upload", "jar", "file", "job", "manag", "akka", "tcp", "flink", "127", "1:56722", "user", "jobmanag", "17:19:27380", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "submit", "job", "job", "manag", "akka", "tcp", "flink", "127", "1:56722", "user", "jobmanag", "17:19:27453", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "submit", "job", "fa05fd25993a8742da09cc5023c1e38d", "flink", "java", "job", "at", "mon", "jan", "18", "17:19:27", "utc", "2016", "17:19:27591", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "schedul", "job", "fa05fd25993a8742da09cc5023c1e38d", "flink", "java", "job", "at", "mon", "jan", "18", "17:19:27", "utc", "2016", "17:19:27592", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "c79bf4381462c690f5999f2d1949ab50", "switch", "creat", "schedul", "17:19:27596", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "c79bf4381462c690f5999f2d1949ab50", "switch", "schedul", "deploy", "17:19:27597", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "deploy", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "attempt", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "17:19:27606", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "job", "wa", "success", "submit", "jobmanag", "job", "manag", "akka", "tcp", "flink", "127", "1:56722", "user", "jobmanag", "17:19:27630", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "statu", "job", "fa05fd25993a8742da09cc5023c1e38d", "flink", "java", "job", "at", "mon", "jan", "18", "17:19:27", "utc", "2016", "chang", "run", "17:19:27637", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "e73af91028cb76f7d3cd887cb6d66755", "switch", "creat", "schedul", "17:19:27654", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "job", "execut", "switch", "statu", "run", "17:19:27655", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "schedul", "17:19:27656", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "deploy", "17:19:27666", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "e73af91028cb76f7d3cd887cb6d66755", "switch", "schedul", "deploy", "17:19:27667", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "deploy", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "attempt", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "17:19:27667", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "schedul", "17:19:27669", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "deploy", "17:19:27681", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "807daf978da9dc347dca930822c78f8f", "switch", "creat", "schedul", "17:19:27682", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "807daf978da9dc347dca930822c78f8f", "switch", "schedul", "deploy", "17:19:27682", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "deploy", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "attempt", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "17:19:27682", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "ba45c37065b67fc8f5005a50d0e88fff", "switch", "creat", "schedul", "17:19:27682", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "ba45c37065b67fc8f5005a50d0e88fff", "switch", "schedul", "deploy", "17:19:27685", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "deploy", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "attempt", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "17:19:27686", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "schedul", "17:19:27687", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "deploy", "17:19:27687", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "schedul", "17:19:27692", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "deploy", "17:19:27833", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "ba45c37065b67fc8f5005a50d0e88fff", "switch", "deploy", "run", "17:19:27839", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "run", "17:19:27840", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "e73af91028cb76f7d3cd887cb6d66755", "switch", "deploy", "run", "17:19:27852", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "run", "17:19:27896", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "c79bf4381462c690f5999f2d1949ab50", "switch", "deploy", "run", "17:19:27898", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "807daf978da9dc347dca930822c78f8f", "switch", "deploy", "run", "17:19:27901", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "run", "17:19:27905", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:27", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "run", "17:19:28114", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "7997918330ecf2610b3298a8c8ef2852", "switch", "creat", "schedul", "17:19:28126", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "6421c8f88b191ea844619a40a523773b", "switch", "creat", "schedul", "17:19:28134", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "6421c8f88b191ea844619a40a523773b", "switch", "schedul", "deploy", "17:19:28134", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "deploy", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "attempt", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "17:19:28126", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "d0d011dc0a0823bcec5a57a369b334", "switch", "creat", "schedul", "17:19:28139", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "d0d011dc0a0823bcec5a57a369b334", "switch", "schedul", "deploy", "17:19:28139", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "deploy", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "attempt", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "17:19:28117", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "c928d19f73d700e80cdfad650689febb", "switch", "creat", "schedul", "17:19:28134", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "7997918330ecf2610b3298a8c8ef2852", "switch", "schedul", "deploy", "17:19:28140", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "deploy", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "attempt", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "17:19:28140", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "c928d19f73d700e80cdfad650689febb", "switch", "schedul", "deploy", "17:19:28141", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "deploy", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "attempt", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "17:19:28147", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "schedul", "17:19:28153", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "schedul", "17:19:28153", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "deploy", "17:19:28153", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "schedul", "17:19:28153", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "deploy", "17:19:28156", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "deploy", "17:19:28158", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "schedul", "17:19:28165", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "deploy", "17:19:28238", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "e73af91028cb76f7d3cd887cb6d66755", "switch", "run", "finish", "17:19:28242", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "finish", "17:19:28308", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "807daf978da9dc347dca930822c78f8f", "switch", "run", "finish", "17:19:28315", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "c79bf4381462c690f5999f2d1949ab50", "switch", "run", "finish", "17:19:28317", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "finish", "17:19:28318", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "finish", "17:19:28328", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "6421c8f88b191ea844619a40a523773b", "switch", "deploy", "run", "17:19:28336", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "run", "17:19:28338", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "7997918330ecf2610b3298a8c8ef2852", "switch", "deploy", "run", "17:19:28341", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "run", "17:19:28459", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "ba45c37065b67fc8f5005a50d0e88fff", "switch", "run", "finish", "17:19:28463", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "datasourc", "data", "sourc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "org", "apach", "flink", "api", "java", "io", "paralleliteratorinputformat", "parallel", "iter", "input", "format", "switch", "finish", "17:19:28520", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "c928d19f73d700e80cdfad650689febb", "switch", "deploy", "run", "17:19:28529", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "run", "17:19:28540", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "d0d011dc0a0823bcec5a57a369b334", "switch", "deploy", "run", "17:19:28545", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:28", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "run", "17:19:32384", "info", "org", "apach", "flink", "runtim", "instanc", "instancemanag", "instanc", "manag", "regist", "taskmanag", "task", "manag", "at", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "akka", "tcp", "flink", "172", "17", "253:60852", "user", "taskmanag", "as", "5848d44035a164a0302da6c8701ff748", "current", "number", "regist", "host", "current", "number", "aliv", "task", "slot", "17:19:32598", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "reduc", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "d0f8f69f9047c3154b860850955de20f", "switch", "creat", "schedul", "17:19:32598", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "reduc", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "d0f8f69f9047c3154b860850955de20f", "switch", "schedul", "deploy", "17:19:32598", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "deploy", "reduc", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "attempt", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "17:19:32605", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:32", "reduc", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "schedul", "17:19:32605", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:32", "reduc", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "deploy", "17:19:32611", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "c928d19f73d700e80cdfad650689febb", "switch", "run", "finish", "17:19:32614", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:32", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "finish", "17:19:32717", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "6421c8f88b191ea844619a40a523773b", "switch", "run", "finish", "17:19:32719", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:32", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "finish", "17:19:32724", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "reduc", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "d0f8f69f9047c3154b860850955de20f", "switch", "deploy", "run", "17:19:32726", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:32", "reduc", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "run", "17:19:32843", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "d0d011dc0a0823bcec5a57a369b334", "switch", "run", "finish", "17:19:32845", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:32", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "finish", "17:19:33092", "warn", "akka", "remot", "reliabledeliverysupervisor", "reliabl", "deliveri", "supervisor", "associ", "remot", "system", "akka", "tcp", "flink", "172", "17", "253:43702", "ha", "fail", "address", "now", "gate", "5000", "ms", "reason", "disassoci", "17:19:39111", "warn", "remot", "tri", "associ", "unreach", "remot", "address", "akka", "tcp", "flink", "172", "17", "253:43702", "address", "now", "gate", "5000", "ms", "all", "messag", "thi", "address", "will", "deliv", "dead", "letter", "reason", "connect", "refus", "17", "253:43702", "172", "17:19:39113", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "task", "manag", "akka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "termin", "17:19:39114", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "7997918330ecf2610b3298a8c8ef2852", "switch", "run", "fail", "17:19:39120", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:39", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "fail", "java", "lang", "except", "slot", "which", "task", "wa", "execut", "ha", "been", "releas", "probabl", "loss", "taskmanag", "task", "manag", "f213232054587f296a12140d56f63ed1", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "slot", "url", "akka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "at", "org", "apach", "flink", "runtim", "instanc", "simpleslot", "releaseslot", "simpl", "slot", "releas", "slot", "simpleslot", "java:151", "simpl", "slot", "at", "org", "apach", "flink", "runtim", "instanc", "slotsharinggroupassign", "releasesharedslot", "slot", "share", "group", "assign", "releas", "share", "slot", "slotsharinggroupassign", "java:547", "slot", "share", "group", "assign", "at", "org", "apach", "flink", "runtim", "instanc", "sharedslot", "releaseslot", "share", "slot", "releas", "slot", "sharedslot", "java:119", "share", "slot", "at", "org", "apach", "flink", "runtim", "instanc", "instanc", "markdead", "mark", "dead", "instanc", "java:156", "at", "org", "apach", "flink", "runtim", "instanc", "instancemanag", "unregistertaskmanag", "instanc", "manag", "unregist", "task", "manag", "instancemanag", "java:215", "instanc", "manag", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "anonfun", "handlemessag", "handl", "messag", "applyorels", "appli", "or", "jobmanag", "scala:792", "job", "manag", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "leadersessionmessagefilt", "leader", "session", "messag", "filter", "anonfun", "receiv", "applyorels", "appli", "or", "leadersessionmessagefilt", "scala:44", "leader", "session", "messag", "filter", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:33", "log", "messag", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:28", "log", "messag", "at", "scala", "partialfunct", "partial", "function", "class", "applyorels", "appli", "or", "partialfunct", "scala:118", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "applyorels", "appli", "or", "logmessag", "scala:28", "log", "messag", "at", "akka", "actor", "actor", "class", "aroundrec", "around", "receiv", "actor", "scala:465", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "aroundrec", "job", "manag", "around", "receiv", "jobmanag", "scala:100", "job", "manag", "at", "akka", "actor", "actorcel", "receivemessag", "actor", "cell", "receiv", "messag", "actorcel", "scala:516", "actor", "cell", "at", "akka", "actor", "dungeon", "deathwatch", "death", "watch", "class", "receivedtermin", "receiv", "termin", "deathwatch", "scala:46", "death", "watch", "at", "akka", "actor", "actorcel", "receivedtermin", "actor", "cell", "receiv", "termin", "actorcel", "scala:369", "actor", "cell", "at", "akka", "actor", "actorcel", "autoreceivemessag", "actor", "cell", "auto", "receiv", "messag", "actorcel", "scala:501", "actor", "cell", "at", "akka", "actor", "actorcel", "invok", "actor", "cell", "actorcel", "scala:486", "actor", "cell", "at", "akka", "dispatch", "mailbox", "processmailbox", "process", "mailbox", "mailbox", "scala:254", "at", "akka", "dispatch", "mailbox", "run", "mailbox", "scala:221", "at", "akka", "dispatch", "mailbox", "exec", "mailbox", "scala:231", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "17:19:39129", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "reduc", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "d0f8f69f9047c3154b860850955de20f", "switch", "run", "cancel", "17:19:39132", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "datasink", "data", "sink", "collect", "895e1ea552281a665ae390c966cdb3b7", "switch", "creat", "cancel", "17:19:39149", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:39", "job", "execut", "switch", "statu", "fail", "java", "lang", "except", "slot", "which", "task", "wa", "execut", "ha", "been", "releas", "probabl", "loss", "taskmanag", "task", "manag", "f213232054587f296a12140d56f63ed1", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "slot", "url", "akka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "at", "org", "apach", "flink", "runtim", "instanc", "simpleslot", "releaseslot", "simpl", "slot", "releas", "slot", "simpleslot", "java:151", "simpl", "slot", "at", "org", "apach", "flink", "runtim", "instanc", "slotsharinggroupassign", "releasesharedslot", "slot", "share", "group", "assign", "releas", "share", "slot", "slotsharinggroupassign", "java:547", "slot", "share", "group", "assign", "at", "org", "apach", "flink", "runtim", "instanc", "sharedslot", "releaseslot", "share", "slot", "releas", "slot", "sharedslot", "java:119", "share", "slot", "at", "org", "apach", "flink", "runtim", "instanc", "instanc", "markdead", "mark", "dead", "instanc", "java:156", "at", "org", "apach", "flink", "runtim", "instanc", "instancemanag", "unregistertaskmanag", "instanc", "manag", "unregist", "task", "manag", "instancemanag", "java:215", "instanc", "manag", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "anonfun", "handlemessag", "handl", "messag", "applyorels", "appli", "or", "jobmanag", "scala:792", "job", "manag", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "leadersessionmessagefilt", "leader", "session", "messag", "filter", "anonfun", "receiv", "applyorels", "appli", "or", "leadersessionmessagefilt", "scala:44", "leader", "session", "messag", "filter", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:33", "log", "messag", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:28", "log", "messag", "at", "scala", "partialfunct", "partial", "function", "class", "applyorels", "appli", "or", "partialfunct", "scala:118", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "applyorels", "appli", "or", "logmessag", "scala:28", "log", "messag", "at", "akka", "actor", "actor", "class", "aroundrec", "around", "receiv", "actor", "scala:465", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "aroundrec", "job", "manag", "around", "receiv", "jobmanag", "scala:100", "job", "manag", "at", "akka", "actor", "actorcel", "receivemessag", "actor", "cell", "receiv", "messag", "actorcel", "scala:516", "actor", "cell", "at", "akka", "actor", "dungeon", "deathwatch", "death", "watch", "class", "receivedtermin", "receiv", "termin", "deathwatch", "scala:46", "death", "watch", "at", "akka", "actor", "actorcel", "receivedtermin", "actor", "cell", "receiv", "termin", "actorcel", "scala:369", "actor", "cell", "at", "akka", "actor", "actorcel", "autoreceivemessag", "actor", "cell", "auto", "receiv", "messag", "actorcel", "scala:501", "actor", "cell", "at", "akka", "actor", "actorcel", "invok", "actor", "cell", "actorcel", "scala:486", "actor", "cell", "at", "akka", "dispatch", "mailbox", "processmailbox", "process", "mailbox", "mailbox", "scala:254", "at", "akka", "dispatch", "mailbox", "run", "mailbox", "scala:221", "at", "akka", "dispatch", "mailbox", "exec", "mailbox", "scala:231", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "17:19:39173", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:39", "reduc", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "cancel", "17:19:39173", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:39", "datasink", "data", "sink", "collect", "switch", "cancel", "17:19:39174", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "reduc", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "d0f8f69f9047c3154b860850955de20f", "switch", "cancel", "fail", "17:19:39177", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:39", "reduc", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "fail", "java", "lang", "except", "slot", "which", "task", "wa", "execut", "ha", "been", "releas", "probabl", "loss", "taskmanag", "task", "manag", "f213232054587f296a12140d56f63ed1", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "slot", "url", "akka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "at", "org", "apach", "flink", "runtim", "instanc", "simpleslot", "releaseslot", "simpl", "slot", "releas", "slot", "simpleslot", "java:151", "simpl", "slot", "at", "org", "apach", "flink", "runtim", "instanc", "slotsharinggroupassign", "releasesharedslot", "slot", "share", "group", "assign", "releas", "share", "slot", "slotsharinggroupassign", "java:547", "slot", "share", "group", "assign", "at", "org", "apach", "flink", "runtim", "instanc", "sharedslot", "releaseslot", "share", "slot", "releas", "slot", "sharedslot", "java:119", "share", "slot", "at", "org", "apach", "flink", "runtim", "instanc", "instanc", "markdead", "mark", "dead", "instanc", "java:156", "at", "org", "apach", "flink", "runtim", "instanc", "instancemanag", "unregistertaskmanag", "instanc", "manag", "unregist", "task", "manag", "instancemanag", "java:215", "instanc", "manag", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "anonfun", "handlemessag", "handl", "messag", "applyorels", "appli", "or", "jobmanag", "scala:792", "job", "manag", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "leadersessionmessagefilt", "leader", "session", "messag", "filter", "anonfun", "receiv", "applyorels", "appli", "or", "leadersessionmessagefilt", "scala:44", "leader", "session", "messag", "filter", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:33", "log", "messag", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:28", "log", "messag", "at", "scala", "partialfunct", "partial", "function", "class", "applyorels", "appli", "or", "partialfunct", "scala:118", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "applyorels", "appli", "or", "logmessag", "scala:28", "log", "messag", "at", "akka", "actor", "actor", "class", "aroundrec", "around", "receiv", "actor", "scala:465", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "aroundrec", "job", "manag", "around", "receiv", "jobmanag", "scala:100", "job", "manag", "at", "akka", "actor", "actorcel", "receivemessag", "actor", "cell", "receiv", "messag", "actorcel", "scala:516", "actor", "cell", "at", "akka", "actor", "dungeon", "deathwatch", "death", "watch", "class", "receivedtermin", "receiv", "termin", "deathwatch", "scala:46", "death", "watch", "at", "akka", "actor", "actorcel", "receivedtermin", "actor", "cell", "receiv", "termin", "actorcel", "scala:369", "actor", "cell", "at", "akka", "actor", "actorcel", "autoreceivemessag", "actor", "cell", "auto", "receiv", "messag", "actorcel", "scala:501", "actor", "cell", "at", "akka", "actor", "actorcel", "invok", "actor", "cell", "actorcel", "scala:486", "actor", "cell", "at", "akka", "dispatch", "mailbox", "processmailbox", "process", "mailbox", "mailbox", "scala:254", "at", "akka", "dispatch", "mailbox", "run", "mailbox", "scala:221", "at", "akka", "dispatch", "mailbox", "exec", "mailbox", "scala:231", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "17:19:39179", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:39", "job", "execut", "switch", "statu", "restart", "17:19:39179", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "delay", "retri", "job", "execut", "10000", "ms", "17:19:39179", "info", "org", "apach", "flink", "runtim", "instanc", "instancemanag", "instanc", "manag", "unregist", "task", "manag", "akka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "number", "regist", "task", "manag", "number", "avail", "slot", "17:19:39179", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "statu", "job", "fa05fd25993a8742da09cc5023c1e38d", "flink", "java", "job", "at", "mon", "jan", "18", "17:19:27", "utc", "2016", "chang", "fail", "java", "lang", "except", "slot", "which", "task", "wa", "execut", "ha", "been", "releas", "probabl", "loss", "taskmanag", "task", "manag", "f213232054587f296a12140d56f63ed1", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "slot", "url", "akka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "at", "org", "apach", "flink", "runtim", "instanc", "simpleslot", "releaseslot", "simpl", "slot", "releas", "slot", "simpleslot", "java:151", "simpl", "slot", "at", "org", "apach", "flink", "runtim", "instanc", "slotsharinggroupassign", "releasesharedslot", "slot", "share", "group", "assign", "releas", "share", "slot", "slotsharinggroupassign", "java:547", "slot", "share", "group", "assign", "at", "org", "apach", "flink", "runtim", "instanc", "sharedslot", "releaseslot", "share", "slot", "releas", "slot", "sharedslot", "java:119", "share", "slot", "at", "org", "apach", "flink", "runtim", "instanc", "instanc", "markdead", "mark", "dead", "instanc", "java:156", "at", "org", "apach", "flink", "runtim", "instanc", "instancemanag", "unregistertaskmanag", "instanc", "manag", "unregist", "task", "manag", "instancemanag", "java:215", "instanc", "manag", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "anonfun", "handlemessag", "handl", "messag", "applyorels", "appli", "or", "jobmanag", "scala:792", "job", "manag", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "leadersessionmessagefilt", "leader", "session", "messag", "filter", "anonfun", "receiv", "applyorels", "appli", "or", "leadersessionmessagefilt", "scala:44", "leader", "session", "messag", "filter", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:33", "log", "messag", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:28", "log", "messag", "at", "scala", "partialfunct", "partial", "function", "class", "applyorels", "appli", "or", "partialfunct", "scala:118", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "applyorels", "appli", "or", "logmessag", "scala:28", "log", "messag", "at", "akka", "actor", "actor", "class", "aroundrec", "around", "receiv", "actor", "scala:465", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "aroundrec", "job", "manag", "around", "receiv", "jobmanag", "scala:100", "job", "manag", "at", "akka", "actor", "actorcel", "receivemessag", "actor", "cell", "receiv", "messag", "actorcel", "scala:516", "actor", "cell", "at", "akka", "actor", "dungeon", "deathwatch", "death", "watch", "class", "receivedtermin", "receiv", "termin", "deathwatch", "scala:46", "death", "watch", "at", "akka", "actor", "actorcel", "receivedtermin", "actor", "cell", "receiv", "termin", "actorcel", "scala:369", "actor", "cell", "at", "akka", "actor", "actorcel", "autoreceivemessag", "actor", "cell", "auto", "receiv", "messag", "actorcel", "scala:501", "actor", "cell", "at", "akka", "actor", "actorcel", "invok", "actor", "cell", "actorcel", "scala:486", "actor", "cell", "at", "akka", "dispatch", "mailbox", "processmailbox", "process", "mailbox", "mailbox", "scala:254", "at", "akka", "dispatch", "mailbox", "run", "mailbox", "scala:221", "at", "akka", "dispatch", "mailbox", "exec", "mailbox", "scala:231", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "17:19:39180", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "statu", "job", "fa05fd25993a8742da09cc5023c1e38d", "flink", "java", "job", "at", "mon", "jan", "18", "17:19:27", "utc", "2016", "chang", "restart", "17:19:42766", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "d0d011dc0a0823bcec5a57a369b334", "switch", "finish", "fail", "17:19:42773", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:42", "chain", "partit", "map", "map", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "combin", "reduc", "at", "testtaskmanagerfailur", "test", "task", "manag", "failur", "taskmanagerprocessfailurebatchrecoveryitcas", "java:73", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "switch", "fail", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "updat", "task", "instanc", "f213232054587f296a12140d56f63ed1", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "slot", "url", "akka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "fail", "due", "at", "org", "apach", "flink", "runtim", "executiongraph", "execut", "onfailur", "failur", "execut", "java:915", "at", "akka", "dispatch", "onfailur", "intern", "failur", "futur", "scala:228", "at", "akka", "dispatch", "onfailur", "intern", "failur", "futur", "scala:227", "at", "akka", "dispatch", "japi", "callbackbridg", "appli", "callback", "bridg", "futur", "scala:174", "at", "akka", "dispatch", "japi", "callbackbridg", "appli", "callback", "bridg", "futur", "scala:171", "at", "scala", "partialfunct", "partial", "function", "class", "applyorels", "appli", "or", "partialfunct", "scala:118", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "applyorels", "abstract", "partial", "function", "appli", "or", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "scala", "concurr", "futur", "anonfun", "onfailur", "failur", "appli", "futur", "scala:136", "at", "scala", "concurr", "futur", "anonfun", "onfailur", "failur", "appli", "futur", "scala:134", "at", "scala", "concurr", "impl", "callbackrunn", "run", "callback", "runnabl", "promis", "scala:32", "at", "scala", "concurr", "impl", "executioncontextimpl", "execut", "context", "impl", "anon", "exec", "executioncontextimpl", "scala:107", "execut", "context", "impl", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "caus", "by", "akka", "pattern", "asktimeoutexcept", "ask", "timeout", "except", "ask", "time", "out", "actorakka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "1712955384", "after", "10000", "ms", "at", "akka", "pattern", "promiseactorref", "promis", "actor", "ref", "anonfun", "appli", "mcv", "mc", "sp", "asksupport", "scala:333", "ask", "support", "at", "akka", "actor", "schedul", "anon", "run", "schedul", "scala:117", "at", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "unbatchedexecut", "unbatch", "execut", "futur", "scala:694", "at", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "execut", "futur", "scala:691", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "taskhold", "executetask", "task", "holder", "execut", "task", "schedul", "scala:467", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "executebucket", "execut", "bucket", "schedul", "scala:419", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "nexttick", "next", "tick", "schedul", "scala:423", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "run", "schedul", "scala:375", "at", "java", "lang", "thread", "run", "thread", "java:745", "17:19:42774", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "statu", "job", "fa05fd25993a8742da09cc5023c1e38d", "flink", "java", "job", "at", "mon", "jan", "18", "17:19:27", "utc", "2016", "chang", "fail", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "updat", "task", "instanc", "f213232054587f296a12140d56f63ed1", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "slot", "url", "akka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "fail", "due", "at", "org", "apach", "flink", "runtim", "executiongraph", "execut", "onfailur", "failur", "execut", "java:915", "at", "akka", "dispatch", "onfailur", "intern", "failur", "futur", "scala:228", "at", "akka", "dispatch", "onfailur", "intern", "failur", "futur", "scala:227", "at", "akka", "dispatch", "japi", "callbackbridg", "appli", "callback", "bridg", "futur", "scala:174", "at", "akka", "dispatch", "japi", "callbackbridg", "appli", "callback", "bridg", "futur", "scala:171", "at", "scala", "partialfunct", "partial", "function", "class", "applyorels", "appli", "or", "partialfunct", "scala:118", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "applyorels", "abstract", "partial", "function", "appli", "or", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "scala", "concurr", "futur", "anonfun", "onfailur", "failur", "appli", "futur", "scala:136", "at", "scala", "concurr", "futur", "anonfun", "onfailur", "failur", "appli", "futur", "scala:134", "at", "scala", "concurr", "impl", "callbackrunn", "run", "callback", "runnabl", "promis", "scala:32", "at", "scala", "concurr", "impl", "executioncontextimpl", "execut", "context", "impl", "anon", "exec", "executioncontextimpl", "scala:107", "execut", "context", "impl", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "caus", "by", "akka", "pattern", "asktimeoutexcept", "ask", "timeout", "except", "ask", "time", "out", "actorakka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "1712955384", "after", "10000", "ms", "at", "akka", "pattern", "promiseactorref", "promis", "actor", "ref", "anonfun", "appli", "mcv", "mc", "sp", "asksupport", "scala:333", "ask", "support", "at", "akka", "actor", "schedul", "anon", "run", "schedul", "scala:117", "at", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "unbatchedexecut", "unbatch", "execut", "futur", "scala:694", "at", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "execut", "futur", "scala:691", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "taskhold", "executetask", "task", "holder", "execut", "task", "schedul", "scala:467", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "executebucket", "execut", "bucket", "schedul", "scala:419", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "nexttick", "next", "tick", "schedul", "scala:423", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "run", "schedul", "scala:375", "at", "java", "lang", "thread", "run", "thread", "java:745", "17:19:42780", "info", "org", "apach", "flink", "runtim", "client", "jobclientactor", "job", "client", "actor", "01", "18", "2016", "17:19:42", "job", "execut", "switch", "statu", "fail", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "updat", "task", "instanc", "f213232054587f296a12140d56f63ed1", "test", "worker", "linux", "docker", "e6d6931f", "3200", "linux", "slot", "url", "akka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "fail", "due", "at", "org", "apach", "flink", "runtim", "executiongraph", "execut", "onfailur", "failur", "execut", "java:915", "at", "akka", "dispatch", "onfailur", "intern", "failur", "futur", "scala:228", "at", "akka", "dispatch", "onfailur", "intern", "failur", "futur", "scala:227", "at", "akka", "dispatch", "japi", "callbackbridg", "appli", "callback", "bridg", "futur", "scala:174", "at", "akka", "dispatch", "japi", "callbackbridg", "appli", "callback", "bridg", "futur", "scala:171", "at", "scala", "partialfunct", "partial", "function", "class", "applyorels", "appli", "or", "partialfunct", "scala:118", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "applyorels", "abstract", "partial", "function", "appli", "or", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "scala", "concurr", "futur", "anonfun", "onfailur", "failur", "appli", "futur", "scala:136", "at", "scala", "concurr", "futur", "anonfun", "onfailur", "failur", "appli", "futur", "scala:134", "at", "scala", "concurr", "impl", "callbackrunn", "run", "callback", "runnabl", "promis", "scala:32", "at", "scala", "concurr", "impl", "executioncontextimpl", "execut", "context", "impl", "anon", "exec", "executioncontextimpl", "scala:107", "execut", "context", "impl", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "caus", "by", "akka", "pattern", "asktimeoutexcept", "ask", "timeout", "except", "ask", "time", "out", "actorakka", "tcp", "flink", "172", "17", "253:43702", "user", "taskmanag", "1712955384", "after", "10000", "ms", "at", "akka", "pattern", "promiseactorref", "promis", "actor", "ref", "anonfun", "appli", "mcv", "mc", "sp", "asksupport", "scala:333", "ask", "support", "at", "akka", "actor", "schedul", "anon", "run", "schedul", "scala:117", "at", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "unbatchedexecut", "unbatch", "execut", "futur", "scala:694", "at", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "execut", "futur", "scala:691", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "taskhold", "executetask", "task", "holder", "execut", "task", "schedul", "scala:467", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "executebucket", "execut", "bucket", "schedul", "scala:419", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "nexttick", "next", "tick", "schedul", "scala:423", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "run", "schedul", "scala:375", "at", "java", "lang", "thread", "run", "thread", "java:745", "17:19:49152", "warn", "remot", "tri", "associ", "unreach", "remot", "address", "akka", "tcp", "flink", "172", "17", "253:43702", "address", "now", "gate", "5000", "ms", "all", "messag", "thi", "address", "will", "deliv", "dead", "letter", "reason", "connect", "refus", "17", "253:43702", "172", "17:19:59172", "warn", "remot", "tri", "associ", "unreach", "remot", "address", "akka", "tcp", "flink", "172", "17", "253:43702", "address", "now", "gate", "5000", "ms", "all", "messag", "thi", "address", "will", "deliv", "dead", "letter", "reason", "connect", "refus", "17", "253:43702", "172", "17:20:09191", "warn", "remot", "tri", "associ", "unreach", "remot", "address", "akka", "tcp", "flink", "172", "17", "253:43702", "address", "now", "gate", "5000", "ms", "all", "messag", "thi", "address", "will", "deliv", "dead", "letter", "reason", "connect", "refus", "17", "253:43702", "172", "17:24:32423", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "stop", "jobmanag", "job", "manag", "akka", "tcp", "flink", "127", "1:56722", "user", "jobmanag", "17:24:32440", "error", "org", "apach", "flink", "test", "recoveri", "taskmanagerprocessfailurebatchrecoveryitcas", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "test", "testtaskmanagerprocessfailure0", "test", "task", "manag", "process", "failure0", "org", "apach", "flink", "test", "recoveri", "taskmanagerprocessfailurebatchrecoveryitcas", "task", "manag", "process", "failur", "batch", "recoveri", "it", "case", "fail", "java", "lang", "assertionerror", "assert", "error", "program", "did", "not", "finish", "time", "at", "org", "junit", "assert", "fail", "assert", "java:88", "at", "org", "junit", "assert", "asserttru", "assert", "true", "assert", "java:41", "at", "org", "junit", "assert", "assertfals", "assert", "fals", "assert", "java:64", "at", "org", "apach", "flink", "test", "recoveri", "abstracttaskmanagerprocessfailurerecoverytest", "testtaskmanagerprocessfailur", "abstract", "task", "manag", "process", "failur", "recoveri", "test", "test", "task", "manag", "process", "failur", "abstracttaskmanagerprocessfailurerecoverytest", "java:212", "abstract", "task", "manag", "process", "failur", "recoveri", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:57", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:43", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:606", "at", "org", "junit", "runner", "model", "frameworkmethod", "framework", "method", "runreflectivecal", "run", "reflect", "call", "frameworkmethod", "java:47", "framework", "method", "at", "org", "junit", "intern", "runner", "model", "reflectivecal", "run", "reflect", "callabl", "reflectivecal", "java:12", "reflect", "callabl", "at", "org", "junit", "runner", "model", "frameworkmethod", "invokeexplos", "framework", "method", "invok", "explos", "frameworkmethod", "java:44", "framework", "method", "at", "org", "junit", "intern", "runner", "statement", "invokemethod", "evalu", "invok", "method", "invokemethod", "java:17", "invok", "method", "at", "org", "junit", "rule", "testwatch", "test", "watcher", "evalu", "testwatch", "java:55", "test", "watcher", "at", "org", "junit", "rule", "runrul", "evalu", "run", "rule", "runrul", "java:20", "run", "rule", "at", "org", "junit", "runner", "parentrunn", "runleaf", "parent", "runner", "run", "leaf", "parentrunn", "java:271", "parent", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:70", "block", "unit4class", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:50", "block", "unit4class", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "run", "parentrunn", "java:238", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "schedul", "parentrunn", "java:63", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "runchildren", "parent", "runner", "run", "children", "parentrunn", "java:236", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "access", "parent", "runner", "000", "parentrunn", "java:53", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "evalu", "parentrunn", "java:229", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "run", "parent", "runner", "parentrunn", "java:309", "parent", "runner", "at", "org", "junit", "runner", "suit", "runchild", "run", "child", "suit", "java:127", "at", "org", "junit", "runner", "suit", "runchild", "run", "child", "suit", "java:26", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "run", "parentrunn", "java:238", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "schedul", "parentrunn", "java:63", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "runchildren", "parent", "runner", "run", "children", "parentrunn", "java:236", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "access", "parent", "runner", "000", "parentrunn", "java:53", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "evalu", "parentrunn", "java:229", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "run", "parent", "runner", "parentrunn", "java:309", "parent", "runner", "at", "org", "apach", "maven", "surefir", "junit4", "junit4provid", "execut", "unit4provid", "junit4provid", "java:283", "unit4provid", "at", "org", "apach", "maven", "surefir", "junit4", "junit4provid", "executewithrerun", "unit4provid", "execut", "rerun", "junit4provid", "java:173", "unit4provid", "at", "org", "apach", "maven", "surefir", "junit4", "junit4provid", "executetestset", "unit4provid", "execut", "test", "set", "junit4provid", "java:153", "unit4provid", "at", "org", "apach", "maven", "surefir", "junit4", "junit4provid", "invok", "unit4provid", "junit4provid", "java:128", "unit4provid", "code"], "B_title": "runtime Enforce terminal state of Executions", "B_clean_title": ["runtim", "enforc", "termin", "state", "execut"]},
{"A_title": "SplitOperations may not retain most recent committed _commitRoot entryIn some rare cases it may happen that SplitOperations does not retain the most recent committed _commitRoot entry on a document. This may result in an undetected hierarchy conflict.", "A_clean_title": ["splitoper", "split", "oper", "may", "not", "retain", "most", "recent", "commit", "commitroot", "commit", "root", "entryin", "entri", "some", "rare", "case", "it", "may", "happen", "that", "splitoper", "split", "oper", "not", "retain", "most", "recent", "commit", "commitroot", "commit", "root", "entri", "document", "thi", "may", "result", "undetect", "hierarchi", "conflict"], "B_title": "SplitOperations may not retain most recent committed _commitRoot entry", "B_clean_title": ["splitoper", "split", "oper", "may", "not", "retain", "most", "recent", "commit", "commitroot", "commit", "root", "entri"]},
{"A_title": "Generates code with invalid for/in left-hand assignmentNone", "A_clean_title": ["gener", "code", "invalid", "left", "hand", "assignmentnon", "assign", "none"], "B_title": "Printing of IN statement inside HOOK inside FOR.", "B_clean_title": ["print", "statement", "insid", "hook", "insid"]},
{"A_title": "Node#setProperty(String Calendar) doesnt take time zone in accountNode#setProperty(String Calendar) doesnt take time zone in account.  It looks the Calendar value is straightly stored as a long without take in consideration the time zone  Unit test to follow", "A_clean_title": ["node", "setproperti", "set", "properti", "string", "calendar", "doesnt", "take", "time", "zone", "accountnod", "account", "node", "setproperti", "set", "properti", "string", "calendar", "doesnt", "take", "time", "zone", "account", "it", "look", "calendar", "valu", "straightli", "store", "as", "long", "without", "take", "consider", "time", "zone", "unit", "test", "follow"], "B_title": "Node#setProperty(String Calendar) doesnt take time zone in account", "B_clean_title": ["node", "setproperti", "set", "properti", "string", "calendar", "doesnt", "take", "time", "zone", "account"]},
{"A_title": "NumberTextField doesnt accept values <=0 for Double and FloatThe org.apache.wicket.util.lang.Numbers class defines the method : public static Number getMinValue(Class<? extends Number> numberType)  This method return the MatchingNumberTypeClass.MIN_VALUE. But for Double.MIN_VALUE and Float.MIN_VALUE return the smallest positive number not the smallest negative number like for the other number classes.  One side effect is that by default you cant enter a negative value or a 0 in a NumberTextField<Double> or NumberTextField<Float>.", "A_clean_title": ["numbertextfield", "number", "text", "field", "doesnt", "accept", "valu", "=0", "doubl", "floatth", "float", "org", "apach", "wicket", "util", "lang", "number", "class", "defin", "method", "public", "static", "number", "getminvalu", "get", "min", "valu", "class", "extend", "number", "numbertyp", "number", "type", "thi", "method", "return", "matchingnumbertypeclass", "match", "number", "type", "class", "min", "valu", "but", "doubl", "min", "valu", "float", "min", "valu", "return", "smallest", "posit", "number", "not", "smallest", "neg", "number", "like", "other", "number", "class", "one", "side", "effect", "that", "by", "default", "you", "cant", "enter", "neg", "valu", "or", "numbertextfield", "number", "text", "field", "doubl", "or", "numbertextfield", "number", "text", "field", "float"], "B_title": "MIN_VALUE of Double and Float is not minimum number", "B_clean_title": ["min", "valu", "doubl", "float", "not", "minimum", "number"]},
{"A_title": "Unsigned Shift Right (>>>) bug operating on negative numbersNone", "A_clean_title": ["unsign", "shift", "right", "bug", "oper", "neg", "numbersnon", "number", "none"], "B_title": "Propertly fold >>> 0 on negative values. Fixes issue 200", "B_clean_title": ["propertli", "fold", "neg", "valu", "fix", "issu", "200"]},
{"A_title": "MathUtils.gcd(Integer.MIN_VALUE 0) should throw an Exception instead of returning Integer.MIN_VALUEThe gcd method should throw an Exception for gcd(Integer.MIN_VALUE 0) like for gcd(Integer.MIN_VALUE Integer.MIN_VALUE). The method should only return nonnegative results.", "A_clean_title": ["mathutil", "gcd", "math", "util", "integ", "min", "valu", "throw", "except", "instead", "return", "integ", "min", "valueth", "valu", "gcd", "method", "throw", "except", "gcd", "integ", "min", "valu", "like", "gcd", "integ", "min", "valu", "integ", "min", "valu", "method", "onli", "return", "nonneg", "result"], "B_title": "Fixed an error in computing gcd and lcm for some extreme values at integer range boundaries. JIRA: MATH-243", "B_clean_title": ["fix", "error", "comput", "gcd", "lcm", "some", "extrem", "valu", "at", "integ", "rang", "boundari", "jira", "math", "243"]},
{"A_title": "getLInfNorm() uses wrong formula in both ArrayRealVector and OpenMapRealVector (in different ways)the L_infinity norm of a finite dimensional vector is just the max of the absolute value of its entries.  The current implementation in ArrayRealVector has a typo:  code     public double getLInfNorm()          double max = 0;         for (double a : data)              max += Math.max(max Math.abs(a));                  return max;      code  the += should just be an =.  There is sadly a unit test assuring us that this is the correct behavior (effectively a regression-only test not a test for correctness).  Worse the implementation in OpenMapRealVector is not even positive semi-definite:  code        public double getLInfNorm()          double max = 0;         Iterator iter = entries.iterator();         while (iter.hasNext())              iter.advance();             max += iter.value();                  return max;      code  I would suggest that this method be moved up to the AbstractRealVector superclass and implemented using the sparseIterator():  code   public double getLInfNorm()      double norm = 0;     Iterator<Entry> it = sparseIterator();     Entry e;     while(it.hasNext() && (e = it.next()) != null)        norm = Math.max(norm Math.abs(e.getValue()));          return norm;    code  Unit tests with negative valued vectors would be helpful to check for this kind of thing in the future.", "A_clean_title": ["getlinfnorm", "get", "inf", "norm", "use", "wrong", "formula", "both", "arrayrealvector", "array", "real", "vector", "openmaprealvector", "open", "map", "real", "vector", "differ", "way", "infin", "norm", "finit", "dimension", "vector", "just", "max", "absolut", "valu", "it", "entri", "current", "implement", "arrayrealvector", "array", "real", "vector", "ha", "typo", "code", "public", "doubl", "getlinfnorm", "get", "inf", "norm", "doubl", "max", "doubl", "data", "max", "math", "max", "max", "math", "ab", "return", "max", "code", "just", "there", "sadli", "unit", "test", "assur", "us", "that", "thi", "correct", "behavior", "effect", "regress", "onli", "test", "not", "test", "correct", "wors", "implement", "openmaprealvector", "open", "map", "real", "vector", "not", "even", "posit", "semi", "definit", "code", "public", "doubl", "getlinfnorm", "get", "inf", "norm", "doubl", "max", "iter", "iter", "entri", "iter", "while", "iter", "hasnext", "ha", "next", "iter", "advanc", "max", "iter", "valu", "return", "max", "code", "would", "suggest", "that", "thi", "method", "move", "up", "abstractrealvector", "abstract", "real", "vector", "superclass", "implement", "sparseiter", "spars", "iter", "code", "public", "doubl", "getlinfnorm", "get", "inf", "norm", "doubl", "norm", "iter", "entri", "it", "sparseiter", "spars", "iter", "entri", "while", "it", "hasnext", "ha", "next", "it", "next", "null", "norm", "math", "max", "norm", "math", "ab", "getvalu", "get", "valu", "return", "norm", "code", "unit", "test", "neg", "valu", "vector", "would", "help", "check", "thi", "kind", "thing", "futur"], "B_title": "fixed a wrong implementation of the Linf vector norm JIRA: MATH-326", "B_clean_title": ["fix", "wrong", "implement", "linf", "vector", "norm", "jira", "math", "326"]},
{"A_title": "In ADVANCED mode Compiler fails to warn about overridden methods with different signatures.None", "A_clean_title": ["advanc", "mode", "compil", "fail", "warn", "about", "overridden", "method", "differ", "signatur", "none"], "B_title": "When inferring a function type there may be formal parameters that do not appear in the function literal Fixes issue 368", "B_clean_title": ["when", "infer", "function", "type", "there", "may", "formal", "paramet", "that", "not", "appear", "function", "liter", "fix", "issu", "368"]},
{"A_title": "Null Pointer when invoking Whitebox.invokeMethod() with null one of the params null.None", "A_clean_title": ["null", "pointer", "when", "invok", "whitebox", "invokemethod", "invok", "method", "null", "one", "param", "null", "none"], "B_title": "Merge branch issue230", "B_clean_title": ["merg", "branch", "issue230"]},
{"A_title": "Problems with cookies disabled when using 301/302 and also 303 (even with cookies)As mentioned in the mailing list by Martin i open this as a bug...  Its not possible to use 303 as redirect (SC_SEE_OTHER) because thats not supported only 302 and 301 are supported but this is defined in RFC HTTP 1.1 from 1997.   301 will add the Location header - which works as expected when disabling cookies. But a 302 (which is what i prefer) will redirect to the same page because the Location header is missing. When i enable cookies its working.  Example can be found here: https://github.com/olze/WicketRedirect", "A_clean_title": ["problem", "cooki", "disabl", "when", "301", "302", "also", "303", "even", "cooki", "as", "mention", "mail", "list", "by", "martin", "open", "thi", "as", "bug", "it", "not", "possibl", "use", "303", "as", "redirect", "sc", "see", "other", "becaus", "that", "not", "support", "onli", "302", "301", "are", "support", "but", "thi", "defin", "rfc", "http", "1997", "301", "will", "add", "locat", "header", "which", "work", "as", "expect", "when", "disabl", "cooki", "but", "302", "which", "what", "prefer", "will", "redirect", "same", "page", "becaus", "locat", "header", "miss", "when", "enabl", "cooki", "it", "work", "exampl", "found", "here", "http", "github", "com", "olz", "wicketredirect", "wicket", "redirect"], "B_title": "Problems with cookies disabled when using 301/302 and also 303 (even with cookies)", "B_clean_title": ["problem", "cooki", "disabl", "when", "301", "302", "also", "303", "even", "cooki"]},
{"A_title": "Wrong parameter for first step size guess for Embedded Runge Kutta methodsIn a space application using DOP853 i detected what seems to be a bad parameter in the call to the method  initializeStep of class AdaptiveStepsizeIntegrator. Here DormandPrince853Integrator is a subclass for EmbeddedRungeKuttaIntegrator which perform the call to initializeStep at the beginning of its method integrate(...) The problem comes from the array scale that is used as a parameter in the call off initializeStep(..) Following the theory described by Hairer in his book Solving Ordinary Differential Equations 1 : Nonstiff Problems the scaling should be : sci = Atol i + |y0i| * Rtoli Whereas EmbeddedRungeKuttaIntegrator uses :  sci = Atoli Note that the Gragg-Bulirsch-Stoer integrator uses the good implementation sci = Atol i + |y0i| * Rtoli   when he performs the call to the same method initializeStep(..) In the method initializeStep the error leads to a wrong step size h used to perform an  Euler step. Most of the time it is unvisible for the user. But in my space application the Euler step with this wrong step size h (much bigger than it should be)  makes an exception occur (my satellite hits the ground...) To fix the bug one should use the same algorithm as in the rescale method in GraggBulirschStoerIntegrator For exemple :  final double scale= new doubley0.length;;           if (vecAbsoluteTolerance == null)                for (int i = 0; i < scale.length; ++i)                   final double yi = Math.max(Math.abs(y0i) Math.abs(y0i));                 scalei = scalAbsoluteTolerance + scalRelativeTolerance * yi;                             else                for (int i = 0; i < scale.length; ++i)                   final double yi = Math.max(Math.abs(y0i) Math.abs(y0i));                 scalei = vecAbsoluteTolerancei + vecRelativeTolerancei * yi;                                       hNew = initializeStep(equations forward getOrder() scale                            stepStart y yDotK0 yTmp yDotK1); Sorry for the length of this message looking forward to hearing from you soon Vincent Morand", "A_clean_title": ["wrong", "paramet", "first", "step", "size", "guess", "embed", "rung", "kutta", "methodsin", "method", "space", "applic", "dop853", "detect", "what", "seem", "bad", "paramet", "call", "method", "initializestep", "initi", "step", "class", "adaptivestepsizeintegr", "adapt", "stepsiz", "integr", "here", "dormandprince853integr", "dormand", "prince853integr", "subclass", "embeddedrungekuttaintegr", "embed", "rung", "kutta", "integr", "which", "perform", "call", "initializestep", "initi", "step", "at", "begin", "it", "method", "integr", "problem", "come", "array", "scale", "that", "use", "as", "paramet", "call", "off", "initializestep", "initi", "step", "follow", "theori", "describ", "by", "hairer", "hi", "book", "solv", "ordinari", "differenti", "equat", "nonstiff", "problem", "scale", "sci", "atol", "|y0i|", "rtoli", "wherea", "embeddedrungekuttaintegr", "embed", "rung", "kutta", "integr", "use", "sci", "atoli", "note", "that", "gragg", "bulirsch", "stoer", "integr", "use", "good", "implement", "sci", "atol", "|y0i|", "rtoli", "when", "he", "perform", "call", "same", "method", "initializestep", "initi", "step", "method", "initializestep", "initi", "step", "error", "lead", "wrong", "step", "size", "use", "perform", "euler", "step", "most", "time", "it", "unvis", "user", "but", "my", "space", "applic", "euler", "step", "thi", "wrong", "step", "size", "much", "bigger", "than", "it", "make", "except", "occur", "my", "satellit", "hit", "ground", "fix", "bug", "one", "use", "same", "algorithm", "as", "rescal", "method", "graggbulirschstoerintegr", "gragg", "bulirsch", "stoer", "integr", "exempl", "final", "doubl", "scale=", "new", "doubley0", "length", "vecabsolutetoler", "vec", "absolut", "toler", "null", "int", "scale", "length", "++i", "final", "doubl", "yi", "math", "max", "math", "ab", "y0i", "math", "ab", "y0i", "scalei", "scalabsolutetoler", "scal", "absolut", "toler", "scalrelativetoler", "scal", "rel", "toler", "yi", "int", "scale", "length", "++i", "final", "doubl", "yi", "math", "max", "math", "ab", "y0i", "math", "ab", "y0i", "scalei", "vecabsolutetolerancei", "vec", "absolut", "tolerancei", "vecrelativetolerancei", "vec", "rel", "tolerancei", "yi", "hnew", "new", "initializestep", "initi", "step", "equat", "forward", "getord", "get", "order", "scale", "stepstart", "step", "start", "ydotk0", "dot", "k0", "ytmp", "tmp", "ydotk1", "dot", "k1", "sorri", "length", "thi", "messag", "look", "forward", "hear", "you", "soon", "vincent", "morand"], "B_title": "Fixed automatic step initialization in embedded Runge-Kutta integrators. The relative tolerance setting was never used only the absolute tolerance was used. JIRA: MATH-338", "B_clean_title": ["fix", "automat", "step", "initi", "embed", "rung", "kutta", "integr", "rel", "toler", "set", "wa", "never", "use", "onli", "absolut", "toler", "wa", "use", "jira", "math", "338"]},
{"A_title": "Large HTML File conversion to PDF hangs.Hi  I am trying to convert large HTML File approximately 600 pages which is not passing the conversion and hangs.  Following is my observation after debugging the core.  PdfRendererBuilder.class file has following method call.   renderer.layout(); // This action takes significant time but completes the process.  when I looked into it renderer.createPDF()  is trying to create entire PDF in memory (document) and after completion it starts writing to OutputStream.  Can we write it directly to OutputStream page by page? I think this might solve the problem.  Following is my code snippet please check the same if I am doing anything wrong here.   In  above code snippet it is not completing  builder.run(); process and hangs. Please help me with the solution.  Thanks in advance.", "A_clean_title": ["larg", "html", "file", "convers", "pdf", "hang", "hi", "am", "tri", "convert", "larg", "html", "file", "approxim", "600", "page", "which", "not", "pass", "convers", "hang", "follow", "my", "observ", "after", "debug", "core", "pdfrendererbuild", "class", "pdf", "render", "builder", "file", "ha", "follow", "method", "call", "render", "layout", "thi", "action", "take", "signific", "time", "but", "complet", "process", "when", "look", "into", "it", "render", "createpdf", "creat", "pdf", "tri", "creat", "entir", "pdf", "memori", "document", "after", "complet", "it", "start", "write", "outputstream", "output", "stream", "we", "write", "it", "directli", "outputstream", "output", "stream", "page", "by", "page", "think", "thi", "might", "solv", "problem", "follow", "my", "code", "snippet", "pleas", "check", "same", "am", "do", "anyth", "wrong", "here", "abov", "code", "snippet", "it", "not", "complet", "builder", "run", "process", "hang", "pleas", "help", "me", "solut", "thank", "advanc"], "B_title": "#180 - Tests and fixes around rtl overflow pages.", "B_clean_title": ["180", "test", "fix", "around", "rtl", "overflow", "page"]},
{"A_title": "Provide Simple Exception Name in Credentials Attribute for PW Expirycurrently upon encountering a pw history exception while changing the password of a user the credential attribute is set with the FQ class name instead of the simple name. this requires consumers (e.g. sling) to use oak package names instead of a simple class name to react to the situation.", "A_clean_title": ["provid", "simpl", "except", "name", "credenti", "attribut", "pw", "expirycurr", "upon", "encount", "pw", "histori", "except", "while", "chang", "password", "user", "credenti", "attribut", "set", "fq", "class", "name", "instead", "simpl", "name", "thi", "requir", "consum", "sling", "use", "oak", "packag", "name", "instead", "simpl", "class", "name", "react", "situat"], "B_title": ": Provide Simple Exception Name in Credentials Attribute for PW Expiry", "B_clean_title": ["provid", "simpl", "except", "name", "credenti", "attribut", "pw", "expiri"]},
{"A_title": "Allow convenient spying on abstract classes.Mockito is easy to use when the test needs to provide canned values for a certain method. But it gets harder when a canned value isnt sufficient.", "A_clean_title": ["allow", "conveni", "spi", "abstract", "class", "mockito", "easi", "use", "when", "test", "need", "provid", "can", "valu", "certain", "method", "but", "it", "get", "harder", "when", "can", "valu", "isnt", "suffici"], "B_title": "Adds support for issue #92 with ByteBuddy", "B_clean_title": ["add", "support", "issu", "92", "bytebuddi", "byte", "buddi"]},
{"A_title": "ACCEPT_CASE_INSENSITIVE_PROPERTIES fails with @JsonUnwrapped(note: moved from  FasterXML/jackson-dataformat-csv#133 ) When trying to deserialize type like:   with case-insensitive mapper (  mapper.enable(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES); ) I get exception:", "A_clean_title": ["accept", "case", "insensit", "properti", "fail", "jsonunwrap", "json", "unwrap", "note", "move", "dataformat", "csv", "fasterxml", "jackson", "faster", "xml", "133", "when", "tri", "deseri", "type", "like", "case", "insensit", "mapper", "mapper", "enabl", "mapperfeatur", "mapper", "featur", "accept", "case", "insensit", "properti", "get", "except"], "B_title": "Fix #1493", "B_clean_title": ["fix", "1493"]},
{"A_title": "SegmentWriter doesnt properly check the length of external blob IDsTo store the length field of an external binary ID the following encoding is used:  noformat 1110 + 4bit + 8bit noformat  which allows to store numbers between 0 and 2^12^ - 1.   The current implementation of SegmentWriter allows the length of binary IDs to range between 0 and 2^13^ - 1 writing incorrect data when the length of the binary ID ranges from 2^12^ to 2^13^ - 1.  When reading this incorrect data back an IllegalStateException is thrown complaining that the first byte of the length fields has an unexpected value record type. See OAK-1842 for an example.", "A_clean_title": ["segmentwrit", "segment", "writer", "doesnt", "properli", "check", "length", "extern", "blob", "idsto", "ds", "store", "length", "field", "extern", "binari", "id", "follow", "encod", "use", "noformat", "1110", "4bit", "8bit", "noformat", "which", "allow", "store", "number", "between", "2^12^", "current", "implement", "segmentwrit", "segment", "writer", "allow", "length", "binari", "id", "ds", "rang", "between", "2^13^", "write", "incorrect", "data", "when", "length", "binari", "id", "rang", "2^12^", "2^13^", "when", "read", "thi", "incorrect", "data", "back", "illegalstateexcept", "illeg", "state", "except", "thrown", "complain", "that", "first", "byte", "length", "field", "ha", "unexpect", "valu", "record", "type", "see", "oak", "1842", "exampl"], "B_title": "SegmentWriter doesnt properly check the length of external blob IDs Proper length check and unit test. Credits to Francesco Mari for the patch", "B_clean_title": ["segmentwrit", "segment", "writer", "doesnt", "properli", "check", "length", "extern", "blob", "id", "ds", "proper", "length", "check", "unit", "test", "credit", "francesco", "mari", "patch"]},
{"A_title": "Set state checkpointer before default state for PartitionedStreamOperatorStateCurrently the default state is set before the passed StateCheckpointer instance for operator states.  What currently happens because of this is that the default value is serialized with Java serialization and then deserialized on the opstate.value() call using the StateCheckpointer most likely causing a failure.  This can be trivially fixed by swaping the order of the 2 calls.", "A_clean_title": ["set", "state", "checkpoint", "befor", "default", "state", "partitionedstreamoperatorstatecurr", "partit", "stream", "oper", "state", "current", "default", "state", "set", "befor", "pass", "statecheckpoint", "state", "checkpoint", "instanc", "oper", "state", "what", "current", "happen", "becaus", "thi", "that", "default", "valu", "serial", "java", "serial", "then", "deseri", "opstat", "valu", "call", "statecheckpoint", "state", "checkpoint", "most", "like", "caus", "failur", "thi", "trivial", "fix", "by", "swape", "order", "call"], "B_title": "streaming Set StateCheckpointer before default state value", "B_clean_title": ["stream", "set", "statecheckpoint", "state", "checkpoint", "befor", "default", "state", "valu"]},
{"A_title": "ProcessCommonJSModules module exports failures when checkTypes enabledNone", "A_clean_title": ["processcommonjsmodul", "process", "common", "js", "modul", "modul", "export", "failur", "when", "checktyp", "check", "type", "enablednon", "enabl", "none"], "B_title": "dont bother with module exports if theres nothing to export Fixes issue 732", "B_clean_title": ["dont", "bother", "modul", "export", "there", "noth", "export", "fix", "issu", "732"]},
{"A_title": "Slow event listeners do not scale as expectedorg.apache.jackrabbit.oak.jcr.LargeOperationIT#slowListener does not scale to O n log n on the document node store.", "A_clean_title": ["slow", "event", "listen", "not", "scale", "as", "expectedorg", "apach", "jackrabbit", "oak", "jcr", "largeoperationit", "larg", "oper", "it", "slowlisten", "slow", "listen", "not", "scale", "log", "document", "node", "store"], "B_title": "Slow event listeners do not scale as expected", "B_clean_title": ["slow", "event", "listen", "not", "scale", "as", "expect"]},
{"A_title": "Try/catch blocks incorporate code not inside original blocksNone", "A_clean_title": ["tri", "catch", "block", "incorpor", "code", "not", "insid", "origin", "blocksnon", "block", "none"], "B_title": "Fix may-use data flow analysis in the presence of ON_EX edges. Fixes issue 794", "B_clean_title": ["fix", "may", "use", "data", "flow", "analysi", "presenc", "ex", "edg", "fix", "issu", "794"]},
{"A_title": "Page not recognized as stateless although stateful component is hidden in #onConfigure()Page#stateless gets cached. If Page#isStateless() is called before rendering a page might not be considered stateless although in #onConfigure() all stateful components are hidden.", "A_clean_title": ["page", "not", "recogn", "as", "stateless", "although", "state", "compon", "hidden", "onconfigur", "configur", "page", "stateless", "get", "cach", "page", "isstateless", "stateless", "call", "befor", "render", "page", "might", "not", "consid", "stateless", "although", "onconfigur", "configur", "all", "state", "compon", "are", "hidden"], "B_title": "reset stateless flag on render since stateful components might be added *and* removed", "B_clean_title": ["reset", "stateless", "flag", "render", "sinc", "state", "compon", "might", "ad", "remov"]},
{"A_title": "WordUtils.abbreviate bug when lower is greater than str.lengthIn WordUtils.abbreviate upper is adjusted to the length of the string then to lower. But lower is never adjusted to the length of the string so if lower is greater than str.lengt() upper will be too... Then str.substring(0 upper) throw a StringIndexOutOfBoundsException The fix is to adjust lower to the length of the string", "A_clean_title": ["wordutil", "abbrevi", "word", "util", "bug", "when", "lower", "greater", "than", "str", "lengthin", "length", "wordutil", "abbrevi", "word", "util", "upper", "adjust", "length", "string", "then", "lower", "but", "lower", "never", "adjust", "length", "string", "so", "lower", "greater", "than", "str", "lengt", "upper", "will", "too", "then", "str", "substr", "upper", "throw", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "fix", "adjust", "lower", "length", "string"], "B_title": "Applying Vincent Behars second patch for LANG-419 - fixing a bug in abbreviate such that lower limits greater than the length of the string werent working correctly", "B_clean_title": ["appli", "vincent", "behar", "second", "patch", "lang", "419", "fix", "bug", "abbrevi", "such", "that", "lower", "limit", "greater", "than", "length", "string", "werent", "work", "correctli"]},
{"A_title": "Incorrect recovery of _lastRev for branch commitThe recovery process for _lastRevs is incorrect for branch commits. It propagates the revision of the commit to the branch up to the root node instead of the revision of the merge for the changes.", "A_clean_title": ["incorrect", "recoveri", "lastrev", "last", "rev", "branch", "committh", "commit", "recoveri", "process", "lastrev", "last", "rev", "incorrect", "branch", "commit", "it", "propag", "revis", "commit", "branch", "up", "root", "node", "instead", "revis", "merg", "chang"], "B_title": "Incorrect recovery of _lastRev for branch commit", "B_clean_title": ["incorrect", "recoveri", "lastrev", "last", "rev", "branch", "commit"]},
{"A_title": "Components onAfterRender() is called so many times as it is depth in the component tree + 1org.apache.wicket.Component.afterRender() calls org.apache.wicket.Component.onAfterRenderChildren() which for MarkupContainers calls afterRender() for its children.  So for code like:   WebMarkupContainer comp1 = new WebMarkupContainer(c1);         add(comp1);                  WebMarkupContainer comp2 = new WebMarkupContainer(c2);         comp1.add(comp2);                  WebMarkupContainer comp3 = new WebMarkupContainer(c3)               @Override             protected void onAfterRender()                  super.onAfterRender();                 System.err.println(called);                                   ;         comp2.add(comp3);  youll see called printed 4 times in a single request.  Additionally I think onAfterRenderChildren() should be called before onAfterRender() in Component.afterRender(). The flow should be first-in last-out: onBeforeRender > onBeforeRenderChildren > onAfterRenderChildren > onAfterRender", "A_clean_title": ["compon", "onafterrend", "after", "render", "call", "so", "mani", "time", "as", "it", "depth", "compon", "tree", "1org", "apach", "wicket", "compon", "afterrend", "after", "render", "call", "org", "apach", "wicket", "compon", "onafterrenderchildren", "after", "render", "children", "which", "markupcontain", "markup", "contain", "call", "afterrend", "after", "render", "it", "children", "so", "code", "like", "webmarkupcontain", "web", "markup", "contain", "comp1", "new", "webmarkupcontain", "web", "markup", "contain", "c1", "add", "comp1", "webmarkupcontain", "web", "markup", "contain", "comp2", "new", "webmarkupcontain", "web", "markup", "contain", "c2", "comp1", "add", "comp2", "webmarkupcontain", "web", "markup", "contain", "comp3", "new", "webmarkupcontain", "web", "markup", "contain", "c3", "overrid", "protect", "void", "onafterrend", "after", "render", "super", "onafterrend", "after", "render", "system", "err", "println", "call", "comp2", "add", "comp3", "youll", "see", "call", "print", "time", "singl", "request", "addit", "think", "onafterrenderchildren", "after", "render", "children", "call", "befor", "onafterrend", "after", "render", "compon", "afterrend", "after", "render", "flow", "first", "last", "out", "onbeforerend", "befor", "render", "onbeforerenderchildren", "befor", "render", "children", "onafterrenderchildren", "after", "render", "children", "onafterrend", "after", "render"], "B_title": "Components onAfterRender() is called so many times as it is depth in the component tree + 1", "B_clean_title": ["compon", "onafterrend", "after", "render", "call", "so", "mani", "time", "as", "it", "depth", "compon", "tree"]},
{"A_title": "BarrierBuffer does not properly clean up temp filesNone", "A_clean_title": ["barrierbuff", "barrier", "buffer", "not", "properli", "clean", "up", "temp", "filesnon", "file", "none"], "B_title": "streaming BarrierBuffer releases temp files properly.", "B_clean_title": ["stream", "barrierbuff", "barrier", "buffer", "releas", "temp", "file", "properli"]},
{"A_title": "Query constraints marked as invalid in the case of an mvpIt seems that in the case of a query that has more constraints on the same property like bq. //*(@prop = aaa and @prop = bbb and @prop = ccc)  the filter is marked as invalid (_#isAlwaysFalse_) and the query returns no results.  This is incorrect and affects queries that search for multi-valued properties on nodes.  This comes from/affects OAK-1075.", "A_clean_title": ["queri", "constraint", "mark", "as", "invalid", "case", "mvpit", "mvp", "it", "seem", "that", "case", "queri", "that", "ha", "more", "constraint", "same", "properti", "like", "bq", "prop", "aaa", "prop", "bbb", "prop", "ccc", "filter", "mark", "as", "invalid", "isalwaysfals", "alway", "fals", "queri", "return", "no", "result", "thi", "incorrect", "affect", "queri", "that", "search", "multi", "valu", "properti", "node", "thi", "come", "affect", "oak", "1075"], "B_title": "Query constraints marked as invalid in the case of an mvp", "B_clean_title": ["queri", "constraint", "mark", "as", "invalid", "case", "mvp"]},
{"A_title": "Template types on methods incorrectly trigger inference of a template on the class if that template type is unknownNone", "A_clean_title": ["templat", "type", "method", "incorrectli", "trigger", "infer", "templat", "class", "that", "templat", "type", "unknownnon", "unknown", "none"], "B_title": "Dont infer class template keys when inferring method template keys. Fixes issue 1058. ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=53874505", "B_clean_title": ["dont", "infer", "class", "templat", "key", "when", "infer", "method", "templat", "key", "fix", "issu", "1058", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=53874505"]},
{"A_title": "Missing privileges after repository upgradeAfter upgrading from Jackrabbit classic all Oak specific privileges are missing (rep:userManagement rep:readNodes rep:readProperties rep:addProperties rep:alterProperties rep:removeProperties rep:indexDefinitionManagement).  The reason seems to be that the PrivilegeInitializer is not run during upgrade.", "A_clean_title": ["miss", "privileg", "after", "repositori", "upgradeaft", "upgrad", "after", "upgrad", "jackrabbit", "classic", "all", "oak", "specif", "privileg", "are", "miss", "rep", "usermanag", "user", "manag", "rep", "readnod", "read", "node", "rep", "readproperti", "read", "properti", "rep", "addproperti", "add", "properti", "rep", "alterproperti", "alter", "properti", "rep", "removeproperti", "remov", "properti", "rep", "indexdefinitionmanag", "index", "definit", "manag", "reason", "seem", "that", "privilegeiniti", "privileg", "initi", "not", "run", "dure", "upgrad"], "B_title": "Missing privileges after repository upgrade Dont copy built in privileges", "B_clean_title": ["miss", "privileg", "after", "repositori", "upgrad", "dont", "copi", "built", "privileg"]},
{"A_title": "importdirectory failing on split tablebulk import for the wikisearch example isnt working properly: files are not being assigned to partitions if there are splits.", "A_clean_title": ["importdirectori", "fail", "split", "tablebulk", "import", "wikisearch", "exampl", "isnt", "work", "properli", "file", "are", "not", "be", "assign", "partit", "there", "are", "split"], "B_title": "merge to trunk", "B_clean_title": ["merg", "trunk"]},
{"A_title": "Token class option always requires token propertyIn testing out ACCUMULO-2815 I attempted to manually provide a KerberosToken to authenticate myself and then launch the shell but ran into an issue. The KerberosToken (in its current state) needs no options: its wholly functional on its own.  accumulo shell -tc org.apache.accumulo.core.client.security.tokens.KerberosToken  gives an error  noformat 2014-12-16 11:41:09712 shell.Shell ERROR: com.beust.jcommander.ParameterException: Must supply either both or neither of --tokenClass and --tokenProperty noformat  And providing an empty option just prints the help message accumulo shell -tc org.apache.accumulo.core.client.security.tokens.KerberosToken -l   Im guessing the latter is just how the JCommander DynamicParameter is implemented but I dont see a reason why every authentication *must* have some properties provided to it.", "A_clean_title": ["token", "class", "option", "alway", "requir", "token", "propertyin", "properti", "test", "out", "accumulo", "2815", "attempt", "manual", "provid", "kerberostoken", "kerbero", "token", "authent", "myself", "then", "launch", "shell", "but", "ran", "into", "issu", "kerberostoken", "kerbero", "token", "it", "current", "state", "need", "no", "option", "it", "wholli", "function", "it", "own", "accumulo", "shell", "tc", "org", "apach", "accumulo", "core", "client", "secur", "token", "kerberostoken", "kerbero", "token", "give", "error", "noformat", "2014", "12", "16", "11:41:09712", "shell", "shell", "error", "com", "beust", "jcommand", "parameterexcept", "paramet", "except", "must", "suppli", "either", "both", "or", "neither", "tokenclass", "token", "class", "tokenproperti", "token", "properti", "noformat", "provid", "empti", "option", "just", "print", "help", "messag", "accumulo", "shell", "tc", "org", "apach", "accumulo", "core", "client", "secur", "token", "kerberostoken", "kerbero", "token", "im", "guess", "latter", "just", "how", "jcommand", "command", "dynamicparamet", "dynam", "paramet", "implement", "but", "dont", "see", "reason", "whi", "everi", "authent", "must", "have", "some", "properti", "provid", "it"], "B_title": "Remove requirement for properties on provided token.", "B_clean_title": ["remov", "requir", "properti", "provid", "token"]},
{"A_title": "Converts string properties into numbers in literal object definitionsNone", "A_clean_title": ["convert", "string", "properti", "into", "number", "liter", "object", "definitionsnon", "definit", "none"], "B_title": "numbers are hard! fixes issue 569", "B_clean_title": ["number", "are", "hard", "fix", "issu", "569"]},
{"A_title": "ArrayIndexOutOfBoundsException in MathArrays.linearCombinationWhen MathArrays.linearCombination is passed arguments with length 1 it throws an ArrayOutOfBoundsException. This is caused by this line: double prodHighNext = prodHigh1; linearCombination should check the length of the arguments and fall back to simple multiplication if length == 1.", "A_clean_title": ["arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "matharray", "linearcombinationwhen", "math", "array", "linear", "combin", "when", "matharray", "linearcombin", "math", "array", "linear", "combin", "pass", "argument", "length", "it", "throw", "arrayoutofboundsexcept", "array", "out", "bound", "except", "thi", "caus", "by", "thi", "line", "doubl", "prodhighnext", "prod", "high", "next", "prodhigh1", "prod", "high1", "linearcombin", "linear", "combin", "check", "length", "argument", "fall", "back", "simpl", "multipl", "length"], "B_title": "Array of length 1 must be handled as a special case.", "B_clean_title": ["array", "length", "must", "handl", "as", "special", "case"]},
{"A_title": "BigFraction.doubleValue() returns Double.NaN for large numerators or denominatorsThe current implementation of doubleValue() divides numerator.doubleValue() / denominator.doubleValue().  BigInteger.doubleValue() fails for any number greater than Double.MAX_VALUE.  So if the user has 308-digit numerator or denominator the resulting quotient fails even in cases where the result would be well inside Doubles range.  I have a patch to fix it if I can figure out how to attach it here I will.", "A_clean_title": ["bigfract", "doublevalu", "big", "fraction", "doubl", "valu", "return", "doubl", "nan", "na", "larg", "numer", "or", "denominatorsth", "denomin", "current", "implement", "doublevalu", "doubl", "valu", "divid", "numer", "doublevalu", "doubl", "valu", "denomin", "doublevalu", "doubl", "valu", "biginteg", "doublevalu", "big", "integ", "doubl", "valu", "fail", "ani", "number", "greater", "than", "doubl", "max", "valu", "so", "user", "ha", "308", "digit", "numer", "or", "denomin", "result", "quotient", "fail", "even", "case", "where", "result", "would", "well", "insid", "doubl", "rang", "have", "patch", "fix", "it", "figur", "out", "how", "attach", "it", "here", "will"], "B_title": "Fixed doubleValue() and floatValue() when numerator and denominator are larger than the range of the corresponding primitive type.", "B_clean_title": ["fix", "doublevalu", "doubl", "valu", "floatvalu", "float", "valu", "when", "numer", "denomin", "are", "larger", "than", "rang", "correspond", "primit", "type"]},
{"A_title": "Add support for handling primitive/discrepancy problem with type refinements(note: derived from  FasterXML/jackson-module-jaxb-annotations#64 ) The problem is that although  int and java.lang.Integer are related logically they are not related by inheritance (or implementation). Since some legacy code may try refinements in this axis itd be nice to handle this somehow. Two basic approaches would be:   Just ignore primitive/wrapper override return original type as is  Allow wrapper to refine primitive return wrapper.  There is also related question of whether to allow int to long and similar refinements but start with basics.", "A_clean_title": ["add", "support", "handl", "primit", "discrep", "problem", "type", "refin", "note", "deriv", "modul", "jaxb", "annot", "fasterxml", "jackson", "faster", "xml", "64", "problem", "that", "although", "int", "java", "lang", "integ", "are", "relat", "logic", "they", "are", "not", "relat", "by", "inherit", "or", "implement", "sinc", "some", "legaci", "code", "may", "tri", "refin", "thi", "axi", "itd", "nice", "handl", "thi", "somehow", "two", "basic", "approach", "would", "just", "ignor", "primit", "wrapper", "overrid", "return", "origin", "type", "as", "allow", "wrapper", "refin", "primit", "return", "wrapper", "there", "also", "relat", "question", "whether", "allow", "int", "long", "similar", "refin", "but", "start", "basic"], "B_title": "Fix #1592", "B_clean_title": ["fix", "1592"]},
{"A_title": "Unable to find markup for children of deeply nested IComponentResolvers during Ajax responseComponent hierarchy: Page -> WebMarkupContainer -> IComponentResolver (that uses Page to resolve) and Page -> Panel.  Markup hierarchy: Page -> WebMarkupContainer -> IComponentResolver -> Panel.  When rendering whole page it works because it is markup driven. Wicket encounters ComponentTag for Panel and resolves the Panel using IComponentResolver which retrieves the Panel from the Page.  When you add the Panel to an AjaxRequestTarget the render is component driven. In order to render the Panel we must retrieve the markup for the Panel from its parent MarkupContainer which happens to be the Page.  Markup.java around line 230 skips to closing tags of ComponentTag so when Page gets to the opening tag of the WebMarkupContainer it skips to the closing tag of the WebMarkupContainer and so passes over the ComponentTag for Panel without noticing it. There is actually another check in DefaultMarkupSourcingStrategy that tries to fetch from all the transparent components in the markup container but this is not good enough because in our example the IComponentResolver is not actually a direct child of the Panels parent to it is never used to try find the markup.  One solution might be to traverse the tree and attempt to find the markup from all IComponentResolving MarkupContainers but we should be careful. Im a bit concerned at how various parts of Wicket just assume that an IComponentResolver is transparent and resolves from its direct parent only.  If we do go down the route of traversing the tree to find IComponentResolvers then try find the markup from each of them we really should add a check in AbstractMarkupSourcingStrategy#searchMarkupInTransparentResolvers() to check that the Component that the IComponentResolver resolves for the markup id is the same component for which we are looking for markup.  This is a difficult one. I am working around it for the mean time just recording the difficulty here. Will try make a patch when I can.", "A_clean_title": ["unabl", "find", "markup", "children", "deepli", "nest", "icomponentresolv", "compon", "resolv", "dure", "ajax", "responsecompon", "respons", "compon", "hierarchi", "page", "webmarkupcontain", "web", "markup", "contain", "icomponentresolv", "compon", "resolv", "that", "use", "page", "resolv", "page", "panel", "markup", "hierarchi", "page", "webmarkupcontain", "web", "markup", "contain", "icomponentresolv", "compon", "resolv", "panel", "when", "render", "whole", "page", "it", "work", "becaus", "it", "markup", "driven", "wicket", "encount", "componenttag", "compon", "tag", "panel", "resolv", "panel", "icomponentresolv", "compon", "resolv", "which", "retriev", "panel", "page", "when", "you", "add", "panel", "ajaxrequesttarget", "ajax", "request", "target", "render", "compon", "driven", "order", "render", "panel", "we", "must", "retriev", "markup", "panel", "it", "parent", "markupcontain", "markup", "contain", "which", "happen", "page", "markup", "java", "around", "line", "230", "skip", "close", "tag", "componenttag", "compon", "tag", "so", "when", "page", "get", "open", "tag", "webmarkupcontain", "web", "markup", "contain", "it", "skip", "close", "tag", "webmarkupcontain", "web", "markup", "contain", "so", "pass", "over", "componenttag", "compon", "tag", "panel", "without", "notic", "it", "there", "actual", "anoth", "check", "defaultmarkupsourcingstrategi", "default", "markup", "sourc", "strategi", "that", "tri", "fetch", "all", "transpar", "compon", "markup", "contain", "but", "thi", "not", "good", "enough", "becaus", "our", "exampl", "icomponentresolv", "compon", "resolv", "not", "actual", "direct", "child", "panel", "parent", "it", "never", "use", "tri", "find", "markup", "one", "solut", "might", "travers", "tree", "attempt", "find", "markup", "all", "icomponentresolv", "compon", "resolv", "markupcontain", "markup", "contain", "but", "we", "care", "im", "bit", "concern", "at", "how", "variou", "part", "wicket", "just", "assum", "that", "icomponentresolv", "compon", "resolv", "transpar", "resolv", "it", "direct", "parent", "onli", "we", "go", "down", "rout", "travers", "tree", "find", "icomponentresolv", "compon", "resolv", "then", "tri", "find", "markup", "each", "them", "we", "realli", "add", "check", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "searchmarkupintransparentresolv", "search", "markup", "transpar", "resolv", "check", "that", "compon", "that", "icomponentresolv", "compon", "resolv", "resolv", "markup", "id", "same", "compon", "which", "we", "are", "look", "markup", "thi", "difficult", "one", "am", "work", "around", "it", "mean", "time", "just", "record", "difficulti", "here", "will", "tri", "make", "patch", "when"], "B_title": "Unable to find markup for children of deeply nested IComponentResolvers during Ajax response", "B_clean_title": ["unabl", "find", "markup", "children", "deepli", "nest", "icomponentresolv", "compon", "resolv", "dure", "ajax", "respons"]},
{"A_title": "Miscellaneous issues concerning the optimization packageRevision 990792 contains changes triggered the following issues:  MATH-394 MATH-397 MATH-404  This issue collects the currently still unsatisfactory code (not necessarily sorted in order of annoyance):  BrentOptimizer: a specific convergence checker must be used. LevenbergMarquardtOptimizer also has specific convergence checks. Trying to make convergence checking independent of the optimization algorithm creates problems (conceptual and practical):  See BrentOptimizer and LevenbergMarquardtOptimizer the algorithm passes points to the convergence checker but the actual meaning of the points can very well be different in the caller (optimization algorithm) and the callee (convergence checker). In PowellOptimizer the line search (BrentOptimizer) tolerances depend on the tolerances within the main algorithm. Since tolerances come with ConvergenceChecker and so can be changed at any time it is awkward to adapt the values within the line search optimizer without exposing its internals (BrentOptimizer field) to the enclosing class (PowellOptimizer).   Given the numerous changes some Javadoc comments might be out-of-sync although I did try to update them all. Class DirectSearchOptimizer (in package optimization.direct) inherits from class AbstractScalarOptimizer (in package optimization.general). Some interfaces are defined in package optimization but their base implementations (abstract class that contain the boiler-plate code) are in package optimization.general (e.g. DifferentiableMultivariateVectorialOptimizer and BaseAbstractVectorialOptimizer). No check is performed to ensure the the convergence checker has been set (see e.g. BrentOptimizer and PowellOptimizer); if it hasnt there will be a NPE. The alternative is to initialize a default checker that will never be used in case the user had intended to explicitly sets the checker. NonLinearConjugateGradientOptimizer: Ugly workaround for the checked ConvergenceException. Everywhere we trail the checked FunctionEvaluationException although it is never used. There remains some duplicate code (such as the multi-start loop in the various MultiStart... implementations). The ConvergenceChecker interface is very general (the converged method can take any number of ...PointValuePair). However there remains a semantic problem: One cannot be sure that the list of points means the same thing for the caller of converged and within the implementation of the ConvergenceChecker that was independently set. It is not clear whether it is wise to aggregate the counter of gradient evaluations to the function evaluation counter. In LevenbergMarquartdOptimizer for example it would be unfair to do so. Currently I had to remove all tests referring to gradient and Jacobian evaluations. In AbstractLeastSquaresOptimizer and LevenbergMarquardtOptimizer occurences of OptimizationException were replaced by the unchecked ConvergenceException but in some cases it might not be the most appropriate one. MultiStartUnivariateRealOptimizer: in the other classes (MultiStartMultivariate...) similar to this one the randomization is on the firts-guess value while in this class it is on the search interval. I think that here also we should randomly choose the start value (within the user-selected interval). The Javadoc utility raises warnings (see output of mvn site) which I couldnt figure out how to correct. Some previously existing classes and interfaces have become no more than a specialisation of new generics classes; it might be interesting to remove them in order to reduce the number of classes and thus limit the potential for confusion.", "A_clean_title": ["miscellan", "issu", "concern", "optim", "packagerevis", "packag", "revis", "990792", "contain", "chang", "trigger", "follow", "issu", "math", "394", "math", "397", "math", "404", "thi", "issu", "collect", "current", "still", "unsatisfactori", "code", "not", "necessarili", "sort", "order", "annoy", "brentoptim", "brent", "optim", "specif", "converg", "checker", "must", "use", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "also", "ha", "specif", "converg", "check", "tri", "make", "converg", "check", "independ", "optim", "algorithm", "creat", "problem", "conceptu", "practic", "see", "brentoptim", "brent", "optim", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "algorithm", "pass", "point", "converg", "checker", "but", "actual", "mean", "point", "veri", "well", "differ", "caller", "optim", "algorithm", "calle", "converg", "checker", "powelloptim", "powel", "optim", "line", "search", "brentoptim", "brent", "optim", "toler", "depend", "toler", "within", "main", "algorithm", "sinc", "toler", "come", "convergencecheck", "converg", "checker", "so", "chang", "at", "ani", "time", "it", "awkward", "adapt", "valu", "within", "line", "search", "optim", "without", "expos", "it", "intern", "brentoptim", "brent", "optim", "field", "enclos", "class", "powelloptim", "powel", "optim", "given", "numer", "chang", "some", "javadoc", "comment", "might", "out", "sync", "although", "did", "tri", "updat", "them", "all", "class", "directsearchoptim", "direct", "search", "optim", "packag", "optim", "direct", "inherit", "class", "abstractscalaroptim", "abstract", "scalar", "optim", "packag", "optim", "gener", "some", "interfac", "are", "defin", "packag", "optim", "but", "their", "base", "implement", "abstract", "class", "that", "contain", "boiler", "plate", "code", "are", "packag", "optim", "gener", "differentiablemultivariatevectorialoptim", "differenti", "multivari", "vectori", "optim", "baseabstractvectorialoptim", "base", "abstract", "vectori", "optim", "no", "check", "perform", "ensur", "converg", "checker", "ha", "been", "set", "see", "brentoptim", "brent", "optim", "powelloptim", "powel", "optim", "it", "hasnt", "there", "will", "npe", "altern", "initi", "default", "checker", "that", "will", "never", "use", "case", "user", "had", "intend", "explicitli", "set", "checker", "nonlinearconjugategradientoptim", "non", "linear", "conjug", "gradient", "optim", "ugli", "workaround", "check", "convergenceexcept", "converg", "except", "everywher", "we", "trail", "check", "functionevaluationexcept", "function", "evalu", "except", "although", "it", "never", "use", "there", "remain", "some", "duplic", "code", "such", "as", "multi", "start", "loop", "variou", "multistart", "multi", "start", "implement", "convergencecheck", "converg", "checker", "interfac", "veri", "gener", "converg", "method", "take", "ani", "number", "pointvaluepair", "point", "valu", "pair", "howev", "there", "remain", "semant", "problem", "one", "not", "sure", "that", "list", "point", "mean", "same", "thing", "caller", "converg", "within", "implement", "convergencecheck", "converg", "checker", "that", "wa", "independ", "set", "it", "not", "clear", "whether", "it", "wise", "aggreg", "counter", "gradient", "evalu", "function", "evalu", "counter", "levenbergmarquartdoptim", "levenberg", "marquartd", "optim", "exampl", "it", "would", "unfair", "so", "current", "had", "remov", "all", "test", "refer", "gradient", "jacobian", "evalu", "abstractleastsquaresoptim", "abstract", "least", "squar", "optim", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "occur", "optimizationexcept", "optim", "except", "were", "replac", "by", "uncheck", "convergenceexcept", "converg", "except", "but", "some", "case", "it", "might", "not", "most", "appropri", "one", "multistartunivariaterealoptim", "multi", "start", "univari", "real", "optim", "other", "class", "multistartmultivari", "multi", "start", "multivari", "similar", "thi", "one", "random", "firt", "guess", "valu", "while", "thi", "class", "it", "search", "interv", "think", "that", "here", "also", "we", "randomli", "choos", "start", "valu", "within", "user", "select", "interv", "javadoc", "util", "rais", "warn", "see", "output", "mvn", "site", "which", "couldnt", "figur", "out", "how", "correct", "some", "previous", "exist", "class", "interfac", "have", "becom", "no", "more", "than", "specialis", "new", "gener", "class", "it", "might", "interest", "remov", "them", "order", "reduc", "number", "class", "thu", "limit", "potenti", "confus"], "B_title": "(point 13) Selecting a random start value (instead of interval bounds).", "B_clean_title": ["point", "13", "select", "random", "start", "valu", "instead", "interv", "bound"]},
{"A_title": "Unresolved conflicts in TokenProviderImpl#createToken()In certain situations (e.g. heavy load) TokenProviderImpl#createToken() might create some unresolved conflicts.  e.g.   code org.apache.jackrabbit.oak.api.CommitFailedException: OakState0001: Unresolved conflicts in /home/users/..../..../.tokens/2014-04-07T11.55.58.167+02.00 code  and  code 01.04.2014 17:52:41.216 *WARN* qtp218544742-286 org.apache.jackrabbit.oak.security.authentication.token.TokenProviderImpl Failed to create login token. 01.04.2014 17:52:41.218 *WARN* qtp218544742-300 org.eclipse.jetty.servlet.ServletHandler /projects.html java.lang.IllegalArgumentException: Invalid token      at org.apache.jackrabbit.api.security.authentication.token.TokenCredentials.<init>(TokenCredentials.java:42) code", "A_clean_title": ["unresolv", "conflict", "tokenproviderimpl", "token", "provid", "impl", "createtoken", "creat", "token", "certain", "situat", "heavi", "load", "tokenproviderimpl", "token", "provid", "impl", "createtoken", "creat", "token", "might", "creat", "some", "unresolv", "conflict", "code", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "commit", "fail", "except", "oakstate0001", "oak", "state0001", "unresolv", "conflict", "home", "user", "04", "07t11", "55", "58", "167+02", "00", "token", "2014", "code", "code", "01", "04", "2014", "17:52:41", "216", "warn", "qtp218544742", "286", "org", "apach", "jackrabbit", "oak", "secur", "authent", "token", "tokenproviderimpl", "token", "provid", "impl", "fail", "creat", "login", "token", "01", "04", "2014", "17:52:41", "218", "warn", "qtp218544742", "300", "org", "eclips", "jetti", "servlet", "servlethandl", "servlet", "handler", "html", "project", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "invalid", "token", "at", "org", "apach", "jackrabbit", "api", "secur", "authent", "token", "tokencredenti", "token", "credenti", "init", "tokencredenti", "java:42", "token", "credenti", "code"], "B_title": ": Unresolved conflicts in TokenProviderImpl#createToken()", "B_clean_title": ["unresolv", "conflict", "tokenproviderimpl", "token", "provid", "impl", "createtoken", "creat", "token"]},
{"A_title": "ArrayKeySelector returns wrong positions (or fails)The ArrayKeySelector is broken and returns wrong values in all cases except for 0 as a single only key position.", "A_clean_title": ["arraykeyselector", "array", "key", "selector", "return", "wrong", "posit", "or", "fail", "arraykeyselector", "array", "key", "selector", "broken", "return", "wrong", "valu", "all", "case", "except", "as", "singl", "onli", "key", "posit"], "B_title": "streaming Fix ArrayKeySelector", "B_clean_title": ["stream", "fix", "arraykeyselector", "array", "key", "selector"]},
{"A_title": "Missing type-checks for var_args notationNone", "A_clean_title": ["miss", "type", "check", "var", "arg", "notationnon", "notat", "none"], "B_title": "check var_args properly Fixes issue 229.", "B_clean_title": ["check", "var", "arg", "properli", "fix", "issu", "229"]},
{"A_title": "Negative value with restrictNonNegativeProblem: commons-math-2.2 SimplexSolver. A variable with 0 coefficient may be assigned a negative value nevertheless restrictToNonnegative flag in call: SimplexSolver.optimize(function constraints GoalType.MINIMIZE true); Function 1 * x + 1 * y + 0 Constraints: 1 * x + 0 * y = 1 Result: x = 1; y = -1; Probably variables with 0 coefficients are omitted at some point of computation and because of that the restrictions do not affect their values.", "A_clean_title": ["neg", "valu", "restrictnonnegativeproblem", "restrict", "non", "neg", "problem", "common", "math", "simplexsolv", "simplex", "solver", "variabl", "coeffici", "may", "assign", "neg", "valu", "nevertheless", "restricttononneg", "restrict", "nonneg", "flag", "call", "simplexsolv", "optim", "simplex", "solver", "function", "constraint", "goaltyp", "minim", "goal", "type", "true", "function", "constraint", "result", "probabl", "variabl", "coeffici", "are", "omit", "at", "some", "point", "comput", "becaus", "that", "restrict", "not", "affect", "their", "valu"], "B_title": "Fixed case of unconstrained variables that still occur in the objective function in simplex solver.", "B_clean_title": ["fix", "case", "unconstrain", "variabl", "that", "still", "occur", "object", "function", "simplex", "solver"]},
{"A_title": "Polygon difference produces erronious results in some casesThe 2D polygon difference method is returning incorrect results.  Below is a test case of subtracting two polygons (Sorry this is the simplest case that I could find that duplicates the problem).    There are three problems with the result. The first is that the first point of the first set of vertices is null (and the first point of the second set is also null).  The second is that even if the first null points are ignored  the returned polygon is not the correct result. The first and last points are way off and the remaining points do not match the original polygon boundaries.  Additionally there are two holes that are returned in the results.  This subtraction case should not have holes.  code:title=Complex Polygon Difference Test public void testComplexDifference()          Vector2D vertices1 = new Vector2D              new Vector2D                      new Vector2D( 90.08714908223715  38.370299337260235)                     new Vector2D( 90.08709517675004  38.3702895991413)                     new Vector2D( 90.08401538704919  38.368849330127944)                     new Vector2D( 90.08258210430711  38.367634558585564)                     new Vector2D( 90.08251455106665  38.36763409247078)                     new Vector2D( 90.08106599752608  38.36761621664249)                     new Vector2D( 90.08249585300035  38.36753627557965)                     new Vector2D( 90.09075743352184  38.35914647644972)                     new Vector2D( 90.09099945896571  38.35896264724079)                     new Vector2D( 90.09269383800086  38.34595756121246)                     new Vector2D( 90.09638631543191  38.3457988093121)                     new Vector2D( 90.09666417351019  38.34523360999418)                     new Vector2D( 90.1297082145872  38.337670454923625)                     new Vector2D( 90.12971687748956  38.337669827794684)                     new Vector2D( 90.1240820219179  38.34328502001131)                     new Vector2D( 90.13084259656404  38.34017811765017)                     new Vector2D( 90.13378567942857  38.33860579180606)                     new Vector2D( 90.13519557833206  38.33621054663689)                     new Vector2D( 90.13545616732307  38.33614965452864)                     new Vector2D( 90.13553111202748  38.33613962818305)                     new Vector2D( 90.1356903436448  38.33610227127048)                     new Vector2D( 90.13576283227428  38.33609255422783)                     new Vector2D( 90.13595870833188  38.33604606376991)                     new Vector2D( 90.1361556630693  38.3360024198866)                     new Vector2D( 90.13622408795709  38.335987048115726)                     new Vector2D( 90.13696189099994  38.33581914328681)                     new Vector2D( 90.13746655304897  38.33616706665265)                     new Vector2D( 90.13845973716064  38.33650776167099)                     new Vector2D( 90.13950901827667  38.3368469456463)                     new Vector2D( 90.14393814424852  38.337591835857495)                     new Vector2D( 90.14483839716831  38.337076122362475)                     new Vector2D( 90.14565474433601  38.33769000964429)                     new Vector2D( 90.14569421179482  38.3377117256905)                     new Vector2D( 90.14577067124333  38.33770883625908)                     new Vector2D( 90.14600350631684  38.337714326520995)                     new Vector2D( 90.14600355139731  38.33771435193319)                     new Vector2D( 90.14600369112401  38.33771443882085)                     new Vector2D( 90.14600382486884  38.33771453466096)                     new Vector2D( 90.14600395205912  38.33771463904344)                     new Vector2D( 90.14600407214999  38.337714751520764)                     new Vector2D( 90.14600418462749  38.337714871611695)                     new Vector2D( 90.14600422249327  38.337714915811034)                     new Vector2D( 90.14867838361471  38.34113888210675)                     new Vector2D( 90.14923750157374  38.341582537502575)                     new Vector2D( 90.14877083250991  38.34160685841391)                     new Vector2D( 90.14816667319519  38.34244232585684)                     new Vector2D( 90.14797696744586  38.34248455284745)                     new Vector2D( 90.14484318014337  38.34385573215269)                     new Vector2D( 90.14477919958296  38.3453797747614)                     new Vector2D( 90.14202393306448  38.34464324839456)                     new Vector2D( 90.14198920640195  38.344651155237216)                     new Vector2D( 90.14155207025175  38.34486424263724)                     new Vector2D( 90.1415196143314  38.344871730519)                     new Vector2D( 90.14128611910814  38.34500196593859)                     new Vector2D( 90.14047850603913  38.34600084496253)                     new Vector2D( 90.14045907000337  38.34601860032171)                     new Vector2D( 90.14039496493928  38.346223030432384)                     new Vector2D( 90.14037626063737  38.346240203360026)                     new Vector2D( 90.14030005823724  38.34646920000705)                     new Vector2D( 90.13799164754806  38.34903093011013)                     new Vector2D( 90.11045289492762  38.36801537312368)                     new Vector2D( 90.10871471476526  38.36878044144294)                     new Vector2D( 90.10424901707671  38.374300101757)                     new Vector2D( 90.10263482039932  38.37310041316073)                     new Vector2D( 90.09834601753448  38.373615053823414)                     new Vector2D( 90.0979455456843  38.373578376172475)                     new Vector2D( 90.09086514328669  38.37527884194668)                     new Vector2D( 90.09084931407364  38.37590801712463)                     new Vector2D( 90.09081227075944  38.37526295920463)                     new Vector2D( 90.09081378927135  38.375193883266434)                      ;         PolygonsSet set1 = buildSet(vertices1);          Vector2D vertices2 = new Vector2D              new Vector2D                      new Vector2D( 90.13067558880044  38.36977255037573)                     new Vector2D( 90.12907570488  38.36817308242706)                     new Vector2D( 90.1342774136516  38.356886880294724)                     new Vector2D( 90.13090330629757  38.34664392676211)                     new Vector2D( 90.13078571364593  38.344904617518466)                     new Vector2D( 90.1315602208914  38.3447185040846)                     new Vector2D( 90.1316336226821  38.34470643148342)                     new Vector2D( 90.134020944832  38.340936644972885)                     new Vector2D( 90.13912536387306  38.335497255122334)                     new Vector2D( 90.1396178806582  38.334878075552126)                     new Vector2D( 90.14083049696671  38.33316530644106)                     new Vector2D( 90.14145252901329  38.33152722916191)                     new Vector2D( 90.1404779335565  38.32863516047786)                     new Vector2D( 90.14282712131586  38.327504432532066)                     new Vector2D( 90.14616669875488  38.3237354115015)                     new Vector2D( 90.14860976050608  38.315714862457924)                     new Vector2D( 90.14999277782437  38.3164932507504)                     new Vector2D( 90.15005207194997  38.316534677663356)                     new Vector2D( 90.15508513859612  38.31878731691609)                     new Vector2D( 90.15919938519221  38.31852743183782)                     new Vector2D( 90.16093758658837  38.31880662005153)                     new Vector2D( 90.16099420184912  38.318825953291594)                     new Vector2D( 90.1665411125756  38.31859497874757)                     new Vector2D( 90.16999653861313  38.32505772048029)                     new Vector2D( 90.17475243391698  38.32594398441148)                     new Vector2D( 90.17940844844992  38.327427213761325)                     new Vector2D( 90.20951909541378  38.330616833491774)                     new Vector2D( 90.2155400467941  38.331746223670336)                     new Vector2D( 90.21559881391778  38.33175551425302)                     new Vector2D( 90.21916646426041  38.332584299620805)                     new Vector2D( 90.23863749852285  38.34778978875795)                     new Vector2D( 90.25459855175802  38.357790570608984)                     new Vector2D( 90.25964298227257  38.356918010203174)                     new Vector2D( 90.26024593994703  38.361692743151366)                     new Vector2D( 90.26146187570015  38.36311080550837)                     new Vector2D( 90.26614159359622  38.36510808579902)                     new Vector2D( 90.26621342936448  38.36507942500333)                     new Vector2D( 90.26652190211962  38.36494042196722)                     new Vector2D( 90.26621240678867  38.365113172030874)                     new Vector2D( 90.26614057102057  38.365141832826794)                     new Vector2D( 90.26380080055299  38.3660381760273)                     new Vector2D( 90.26315345241  38.36670658276421)                     new Vector2D( 90.26251574942881  38.367490323488084)                     new Vector2D( 90.26247873448426  38.36755266444749)                     new Vector2D( 90.26234628016698  38.36787989125406)                     new Vector2D( 90.26214559424784  38.36945909356126)                     new Vector2D( 90.25861728442555  38.37200753430875)                     new Vector2D( 90.23905557537864  38.375405314295904)                     new Vector2D( 90.22517251874075  38.38984691662256)                     new Vector2D( 90.22549955153215  38.3911564273979)                     new Vector2D( 90.22434386063355  38.391476432092134)                     new Vector2D( 90.22147729457276  38.39134652252034)                     new Vector2D( 90.22142070120117  38.391349167741964)                     new Vector2D( 90.20665060751588  38.39475580900313)                     new Vector2D( 90.20042268367109  38.39842558622888)                     new Vector2D( 90.17423771242085  38.402727751805344)                     new Vector2D( 90.16756796257476  38.40913898597597)                     new Vector2D( 90.16728283954308  38.411255399912875)                     new Vector2D( 90.16703538220418  38.41136059866693)                     new Vector2D( 90.16725865657685  38.41013618805954)                     new Vector2D( 90.16746107640665  38.40902614307544)                     new Vector2D( 90.16122795307462  38.39773101873203)                      ;         PolygonsSet set2 = buildSet(vertices2);         PolygonsSet set  = (PolygonsSet) new RegionFactory<Euclidean2D>().difference(set1.copySelf()                set2.copySelf());          Vector2D verticies = set.getVertices();         Assert.assertTrue(verticies00 != null);         Assert.assertEquals(1 verticies.length);      code", "A_clean_title": ["polygon", "differ", "produc", "erroni", "result", "some", "casesth", "case", "2d", "polygon", "differ", "method", "return", "incorrect", "result", "below", "test", "case", "subtract", "two", "polygon", "sorri", "thi", "simplest", "case", "that", "could", "find", "that", "duplic", "problem", "there", "are", "three", "problem", "result", "first", "that", "first", "point", "first", "set", "vertic", "null", "first", "point", "second", "set", "also", "null", "second", "that", "even", "first", "null", "point", "are", "ignor", "return", "polygon", "not", "correct", "result", "first", "last", "point", "are", "way", "off", "remain", "point", "not", "match", "origin", "polygon", "boundari", "addit", "there", "are", "two", "hole", "that", "are", "return", "result", "thi", "subtract", "case", "not", "have", "hole", "code", "title=complex", "polygon", "differ", "test", "public", "void", "testcomplexdiffer", "test", "complex", "differ", "vector2d", "vertices1", "new", "vector2d", "new", "vector2d", "new", "vector2d", "90", "08714908223715", "38", "370299337260235", "new", "vector2d", "90", "08709517675004", "38", "3702895991413", "new", "vector2d", "90", "08401538704919", "38", "368849330127944", "new", "vector2d", "90", "08258210430711", "38", "367634558585564", "new", "vector2d", "90", "08251455106665", "38", "36763409247078", "new", "vector2d", "90", "08106599752608", "38", "36761621664249", "new", "vector2d", "90", "08249585300035", "38", "36753627557965", "new", "vector2d", "90", "09075743352184", "38", "35914647644972", "new", "vector2d", "90", "09099945896571", "38", "35896264724079", "new", "vector2d", "90", "09269383800086", "38", "34595756121246", "new", "vector2d", "90", "09638631543191", "38", "3457988093121", "new", "vector2d", "90", "09666417351019", "38", "34523360999418", "new", "vector2d", "90", "1297082145872", "38", "337670454923625", "new", "vector2d", "90", "12971687748956", "38", "337669827794684", "new", "vector2d", "90", "1240820219179", "38", "34328502001131", "new", "vector2d", "90", "13084259656404", "38", "34017811765017", "new", "vector2d", "90", "13378567942857", "38", "33860579180606", "new", "vector2d", "90", "13519557833206", "38", "33621054663689", "new", "vector2d", "90", "13545616732307", "38", "33614965452864", "new", "vector2d", "90", "13553111202748", "38", "33613962818305", "new", "vector2d", "90", "1356903436448", "38", "33610227127048", "new", "vector2d", "90", "13576283227428", "38", "33609255422783", "new", "vector2d", "90", "13595870833188", "38", "33604606376991", "new", "vector2d", "90", "1361556630693", "38", "3360024198866", "new", "vector2d", "90", "13622408795709", "38", "335987048115726", "new", "vector2d", "90", "13696189099994", "38", "33581914328681", "new", "vector2d", "90", "13746655304897", "38", "33616706665265", "new", "vector2d", "90", "13845973716064", "38", "33650776167099", "new", "vector2d", "90", "13950901827667", "38", "3368469456463", "new", "vector2d", "90", "14393814424852", "38", "337591835857495", "new", "vector2d", "90", "14483839716831", "38", "337076122362475", "new", "vector2d", "90", "14565474433601", "38", "33769000964429", "new", "vector2d", "90", "14569421179482", "38", "3377117256905", "new", "vector2d", "90", "14577067124333", "38", "33770883625908", "new", "vector2d", "90", "14600350631684", "38", "337714326520995", "new", "vector2d", "90", "14600355139731", "38", "33771435193319", "new", "vector2d", "90", "14600369112401", "38", "33771443882085", "new", "vector2d", "90", "14600382486884", "38", "33771453466096", "new", "vector2d", "90", "14600395205912", "38", "33771463904344", "new", "vector2d", "90", "14600407214999", "38", "337714751520764", "new", "vector2d", "90", "14600418462749", "38", "337714871611695", "new", "vector2d", "90", "14600422249327", "38", "337714915811034", "new", "vector2d", "90", "14867838361471", "38", "34113888210675", "new", "vector2d", "90", "14923750157374", "38", "341582537502575", "new", "vector2d", "90", "14877083250991", "38", "34160685841391", "new", "vector2d", "90", "14816667319519", "38", "34244232585684", "new", "vector2d", "90", "14797696744586", "38", "34248455284745", "new", "vector2d", "90", "14484318014337", "38", "34385573215269", "new", "vector2d", "90", "14477919958296", "38", "3453797747614", "new", "vector2d", "90", "14202393306448", "38", "34464324839456", "new", "vector2d", "90", "14198920640195", "38", "344651155237216", "new", "vector2d", "90", "14155207025175", "38", "34486424263724", "new", "vector2d", "90", "1415196143314", "38", "344871730519", "new", "vector2d", "90", "14128611910814", "38", "34500196593859", "new", "vector2d", "90", "14047850603913", "38", "34600084496253", "new", "vector2d", "90", "14045907000337", "38", "34601860032171", "new", "vector2d", "90", "14039496493928", "38", "346223030432384", "new", "vector2d", "90", "14037626063737", "38", "346240203360026", "new", "vector2d", "90", "14030005823724", "38", "34646920000705", "new", "vector2d", "90", "13799164754806", "38", "34903093011013", "new", "vector2d", "90", "11045289492762", "38", "36801537312368", "new", "vector2d", "90", "10871471476526", "38", "36878044144294", "new", "vector2d", "90", "10424901707671", "38", "374300101757", "new", "vector2d", "90", "10263482039932", "38", "37310041316073", "new", "vector2d", "90", "09834601753448", "38", "373615053823414", "new", "vector2d", "90", "0979455456843", "38", "373578376172475", "new", "vector2d", "90", "09086514328669", "38", "37527884194668", "new", "vector2d", "90", "09084931407364", "38", "37590801712463", "new", "vector2d", "90", "09081227075944", "38", "37526295920463", "new", "vector2d", "90", "09081378927135", "38", "375193883266434", "polygonsset", "polygon", "set", "set1", "buildset", "build", "set", "vertices1", "vector2d", "vertices2", "new", "vector2d", "new", "vector2d", "new", "vector2d", "90", "13067558880044", "38", "36977255037573", "new", "vector2d", "90", "12907570488", "38", "36817308242706", "new", "vector2d", "90", "1342774136516", "38", "356886880294724", "new", "vector2d", "90", "13090330629757", "38", "34664392676211", "new", "vector2d", "90", "13078571364593", "38", "344904617518466", "new", "vector2d", "90", "1315602208914", "38", "3447185040846", "new", "vector2d", "90", "1316336226821", "38", "34470643148342", "new", "vector2d", "90", "134020944832", "38", "340936644972885", "new", "vector2d", "90", "13912536387306", "38", "335497255122334", "new", "vector2d", "90", "1396178806582", "38", "334878075552126", "new", "vector2d", "90", "14083049696671", "38", "33316530644106", "new", "vector2d", "90", "14145252901329", "38", "33152722916191", "new", "vector2d", "90", "1404779335565", "38", "32863516047786", "new", "vector2d", "90", "14282712131586", "38", "327504432532066", "new", "vector2d", "90", "14616669875488", "38", "3237354115015", "new", "vector2d", "90", "14860976050608", "38", "315714862457924", "new", "vector2d", "90", "14999277782437", "38", "3164932507504", "new", "vector2d", "90", "15005207194997", "38", "316534677663356", "new", "vector2d", "90", "15508513859612", "38", "31878731691609", "new", "vector2d", "90", "15919938519221", "38", "31852743183782", "new", "vector2d", "90", "16093758658837", "38", "31880662005153", "new", "vector2d", "90", "16099420184912", "38", "318825953291594", "new", "vector2d", "90", "1665411125756", "38", "31859497874757", "new", "vector2d", "90", "16999653861313", "38", "32505772048029", "new", "vector2d", "90", "17475243391698", "38", "32594398441148", "new", "vector2d", "90", "17940844844992", "38", "327427213761325", "new", "vector2d", "90", "20951909541378", "38", "330616833491774", "new", "vector2d", "90", "2155400467941", "38", "331746223670336", "new", "vector2d", "90", "21559881391778", "38", "33175551425302", "new", "vector2d", "90", "21916646426041", "38", "332584299620805", "new", "vector2d", "90", "23863749852285", "38", "34778978875795", "new", "vector2d", "90", "25459855175802", "38", "357790570608984", "new", "vector2d", "90", "25964298227257", "38", "356918010203174", "new", "vector2d", "90", "26024593994703", "38", "361692743151366", "new", "vector2d", "90", "26146187570015", "38", "36311080550837", "new", "vector2d", "90", "26614159359622", "38", "36510808579902", "new", "vector2d", "90", "26621342936448", "38", "36507942500333", "new", "vector2d", "90", "26652190211962", "38", "36494042196722", "new", "vector2d", "90", "26621240678867", "38", "365113172030874", "new", "vector2d", "90", "26614057102057", "38", "365141832826794", "new", "vector2d", "90", "26380080055299", "38", "3660381760273", "new", "vector2d", "90", "26315345241", "38", "36670658276421", "new", "vector2d", "90", "26251574942881", "38", "367490323488084", "new", "vector2d", "90", "26247873448426", "38", "36755266444749", "new", "vector2d", "90", "26234628016698", "38", "36787989125406", "new", "vector2d", "90", "26214559424784", "38", "36945909356126", "new", "vector2d", "90", "25861728442555", "38", "37200753430875", "new", "vector2d", "90", "23905557537864", "38", "375405314295904", "new", "vector2d", "90", "22517251874075", "38", "38984691662256", "new", "vector2d", "90", "22549955153215", "38", "3911564273979", "new", "vector2d", "90", "22434386063355", "38", "391476432092134", "new", "vector2d", "90", "22147729457276", "38", "39134652252034", "new", "vector2d", "90", "22142070120117", "38", "391349167741964", "new", "vector2d", "90", "20665060751588", "38", "39475580900313", "new", "vector2d", "90", "20042268367109", "38", "39842558622888", "new", "vector2d", "90", "17423771242085", "38", "402727751805344", "new", "vector2d", "90", "16756796257476", "38", "40913898597597", "new", "vector2d", "90", "16728283954308", "38", "411255399912875", "new", "vector2d", "90", "16703538220418", "38", "41136059866693", "new", "vector2d", "90", "16725865657685", "38", "41013618805954", "new", "vector2d", "90", "16746107640665", "38", "40902614307544", "new", "vector2d", "90", "16122795307462", "38", "39773101873203", "polygonsset", "polygon", "set", "set2", "buildset", "build", "set", "vertices2", "polygonsset", "polygon", "set", "set", "polygonsset", "polygon", "set", "new", "regionfactori", "region", "factori", "euclidean2d", "differ", "set1", "copyself", "copi", "self", "set2", "copyself", "copi", "self", "vector2d", "vertici", "set", "getvertic", "get", "vertic", "assert", "asserttru", "assert", "true", "verticies00", "null", "assert", "assertequ", "assert", "equal", "vertici", "length", "code"], "B_title": "Finalized fix for MATH-880.", "B_clean_title": ["final", "fix", "math", "880"]},
{"A_title": "Some version copy settings conflicts with the earlyShutdownThe RepositoryUpgrade#earlyShutdown property causes the source CRX2 repository to shutdown right after copying the content before the first commit hook is launched. However the VersionableEditor hook sometimes needs access to the source repository to read the version histories that hasnt been copied yet (as the version histories are copied in two stages). As a result the earlyShutdown may cause the upgrade process to fail.  earlyShutdown should be overriden for all cases in which the source repository is still needed in the commit hook phase. In particular it should be set to false if:  * orphaned version histories are not copied * orphaned version histories are copied but the copyOrphanedVersion date is set after the copyVersion date.", "A_clean_title": ["some", "version", "copi", "set", "conflict", "earlyshutdownth", "earli", "shutdown", "repositoryupgrad", "repositori", "upgrad", "earlyshutdown", "earli", "shutdown", "properti", "caus", "sourc", "crx2", "repositori", "shutdown", "right", "after", "copi", "content", "befor", "first", "commit", "hook", "launch", "howev", "versionableeditor", "version", "editor", "hook", "sometim", "need", "access", "sourc", "repositori", "read", "version", "histori", "that", "hasnt", "been", "copi", "yet", "as", "version", "histori", "are", "copi", "two", "stage", "as", "result", "earlyshutdown", "earli", "shutdown", "may", "caus", "upgrad", "process", "fail", "earlyshutdown", "earli", "shutdown", "overriden", "all", "case", "which", "sourc", "repositori", "still", "need", "commit", "hook", "phase", "particular", "it", "set", "fals", "orphan", "version", "histori", "are", "not", "copi", "orphan", "version", "histori", "are", "copi", "but", "copyorphanedvers", "copi", "orphan", "version", "date", "set", "after", "copyvers", "copi", "version", "date"], "B_title": "Some version copy settings conflicts with the earlyShutdown", "B_clean_title": ["some", "version", "copi", "set", "conflict", "earlyshutdown", "earli", "shutdown"]},
{"A_title": "Parsing of ChinUnionPay credit card should use the first 6 charactersUser report:  A China UnionPay number has to start with 622 (622126-622925) and has to have a length between 16 and 19. The source code of CreditCardValidator is:    220   private boolean isChinaUnionPay(String creditCardNumber)   221      222   cardId = CreditCardValidator.INVALID;   223   boolean returnValue = false;   224      225   if ((creditCardNumber.length() >= 16 && creditCardNumber.length() <= 19) &&   226   (creditCardNumber.startsWith(622)))   227      228   int firstDigits = Integer.parseInt(creditCardNumber.substring(0 5));   229   if (firstDigits >= 622126 && firstDigits <= 622925)   230      231   cardId = CreditCardValidator.CHINA_UNIONPAY;   232   returnValue = true;   233      234      235      236   return returnValue;   237    The problem is on the line 228 because the substring returns the first 5 digits and it is compared to 6 digits so firstDigits is always < than 622126. The fix is to do #substring(0 6).", "A_clean_title": ["pars", "chinunionpay", "chin", "union", "pay", "credit", "card", "use", "first", "charactersus", "charact", "user", "report", "china", "unionpay", "union", "pay", "number", "ha", "start", "622", "622126", "622925", "ha", "have", "length", "between", "16", "19", "sourc", "code", "creditcardvalid", "credit", "card", "valid", "220", "privat", "boolean", "ischinaunionpay", "china", "union", "pay", "string", "creditcardnumb", "credit", "card", "number", "221", "222", "cardid", "card", "id", "creditcardvalid", "invalid", "credit", "card", "valid", "223", "boolean", "returnvalu", "return", "valu", "fals", "224", "225", "creditcardnumb", "length", "credit", "card", "number", "16", "creditcardnumb", "length", "credit", "card", "number", "19", "226", "creditcardnumb", "startswith", "credit", "card", "number", "start", "622", "227", "228", "int", "firstdigit", "first", "digit", "integ", "parseint", "pars", "int", "creditcardnumb", "substr", "credit", "card", "number", "229", "firstdigit", "first", "digit", "622126", "firstdigit", "first", "digit", "622925", "230", "231", "cardid", "card", "id", "creditcardvalid", "credit", "card", "valid", "china", "unionpay", "232", "returnvalu", "return", "valu", "true", "233", "234", "235", "236", "return", "returnvalu", "return", "valu", "237", "problem", "line", "228", "becaus", "substr", "return", "first", "digit", "it", "compar", "digit", "so", "firstdigit", "first", "digit", "alway", "than", "622126", "fix", "substr"], "B_title": "Parsing of ChinUnionPay credit card should use the first 6 characters", "B_clean_title": ["pars", "chinunionpay", "chin", "union", "pay", "credit", "card", "use", "first", "charact"]},
{"A_title": "TableTrees NodeBorder does not properly close divsNodeBorder fails to properly close generated <div>s.", "A_clean_title": ["tabletre", "tabl", "tree", "nodebord", "node", "border", "not", "properli", "close", "divsnodebord", "div", "node", "border", "fail", "properli", "close", "gener", "div"], "B_title": "close generated divs", "B_clean_title": ["close", "gener", "div"]},
{"A_title": "RandomDataImpl.nextInt does not distribute uniformly for negative lower boundWhen using the RandomDataImpl.nextInt function to get a uniform sample in a lower upper interval when the lower value is less than zero the output is not uniformly distributed as the lowest value is practically never returned.  See the attached NextIntUniformTest.java file. It uses a -3 5 interval. For several values between 0 and 1 testNextIntUniform1 prints the return value of RandomDataImpl.nextInt (as double and as int). We see that -2 through 5 are returned several times. The -3 value however is only returned for 0.0 and is thus under-respresented in the integer samples. The output of test method testNextIntUniform2 also clearly shows that value -3 is never sampled.", "A_clean_title": ["randomdataimpl", "nextint", "random", "data", "impl", "next", "int", "not", "distribut", "uniformli", "neg", "lower", "boundwhen", "bound", "when", "randomdataimpl", "nextint", "random", "data", "impl", "next", "int", "function", "get", "uniform", "sampl", "lower", "upper", "interv", "when", "lower", "valu", "less", "than", "zero", "output", "not", "uniformli", "distribut", "as", "lowest", "valu", "practic", "never", "return", "see", "attach", "nextintuniformtest", "java", "next", "int", "uniform", "test", "file", "it", "use", "interv", "sever", "valu", "between", "testnextintuniform1", "test", "next", "int", "uniform1", "print", "return", "valu", "randomdataimpl", "nextint", "random", "data", "impl", "next", "int", "as", "doubl", "as", "int", "we", "see", "that", "through", "are", "return", "sever", "time", "valu", "howev", "onli", "return", "thu", "under", "respres", "integ", "sampl", "output", "test", "method", "testnextintuniform2", "test", "next", "int", "uniform2", "also", "clearli", "show", "that", "valu", "never", "sampl"], "B_title": "Fixed rounding error in RandomDataImpl nextInt nextLong methods causing lower endpoints to be excluded when negative. Also improved robustness of nextUniform for extreme values and changed its contract to throw IAE when provided bounds are infinite or NaN.", "B_clean_title": ["fix", "round", "error", "randomdataimpl", "random", "data", "impl", "nextint", "next", "int", "nextlong", "next", "long", "method", "caus", "lower", "endpoint", "exclud", "when", "neg", "also", "improv", "robust", "nextuniform", "next", "uniform", "extrem", "valu", "chang", "it", "contract", "throw", "iae", "when", "provid", "bound", "are", "infinit", "or", "nan", "na"]},
{"A_title": "missing support for relative path consisting of parent-elementcould not reopen OAK-95 -> cloning. during testing of user-mgt api found that relpath consisting of a single parent element doesnt work (but used to):  code @Test     public void getNode3() throws RepositoryException          Node node = getNode(/foo);         Node root = node.getNode(..);         assertNotNull(root);         assertEquals( root.getName());         assertTrue(/.equals(root.getPath()));      :  code", "A_clean_title": ["miss", "support", "rel", "path", "consist", "parent", "elementcould", "not", "reopen", "oak", "95", "clone", "dure", "test", "user", "mgt", "api", "found", "that", "relpath", "consist", "singl", "parent", "element", "doesnt", "work", "but", "use", "code", "test", "public", "void", "getnode3", "get", "node3", "throw", "repositoryexcept", "repositori", "except", "node", "node", "getnod", "get", "node", "foo", "node", "root", "node", "getnod", "get", "node", "assertnotnul", "assert", "not", "null", "root", "assertequ", "assert", "equal", "root", "getnam", "get", "name", "asserttru", "assert", "true", "equal", "root", "getpath", "get", "path", "code"], "B_title": "missing support for relative path consisting of parent-element", "B_clean_title": ["miss", "support", "rel", "path", "consist", "parent", "element"]},
{"A_title": "Invalid generics resolution for locally declared wildcard and fully resolved target type DATACMNS-1138opened and commented Given the following context:    An entity declares a field which type is a class with a wildcard type  An implementation of the fields class is typed with a custom object  A custom converter has been declared for the custom object  We persist an entity with the custom class in Mongo  Then when we retrieve the entity from the database the field with the custom type is not deserialized by the custom converter.  This problem does not happen if:   We remove the wildcard from the declared field  We use a type that does not require a custom converter (e.g. Integer)  Im not sure if this description is clear please take a look at the project on GitHub:  https://github.com/mclem/spring-data-mongodb-generics to reproduce the problem by running mvn test   Affects: 1.12.11 (Hopper SR11) 1.13.6 (Ingalls SR6) 2.0 RC2 (Kay)  Reference URL:  https://github.com/mclem/spring-data-mongodb-generics  Issue Links:     Backported to:  1.13.7 (Ingalls SR7)  1.12.12 (Hopper SR12)", "A_clean_title": ["invalid", "gener", "resolut", "local", "declar", "wildcard", "fulli", "resolv", "target", "type", "datacmn", "1138open", "comment", "given", "follow", "context", "entiti", "declar", "field", "which", "type", "class", "wildcard", "type", "implement", "field", "class", "type", "custom", "object", "custom", "convert", "ha", "been", "declar", "custom", "object", "we", "persist", "entiti", "custom", "class", "mongo", "then", "when", "we", "retriev", "entiti", "databas", "field", "custom", "type", "not", "deseri", "by", "custom", "convert", "thi", "problem", "not", "happen", "we", "remov", "wildcard", "declar", "field", "we", "use", "type", "that", "not", "requir", "custom", "convert", "integ", "im", "not", "sure", "thi", "descript", "clear", "pleas", "take", "look", "at", "project", "github", "git", "hub", "http", "data", "mongodb", "gener", "github", "com", "mclem", "spring", "reproduc", "problem", "by", "run", "mvn", "test", "affect", "12", "11", "hopper", "sr11", "13", "ingal", "sr6", "rc2", "kay", "refer", "url", "http", "data", "mongodb", "gener", "github", "com", "mclem", "spring", "issu", "link", "backport", "13", "ingal", "sr7", "12", "12", "hopper", "sr12"], "B_title": "DATACMNS-1138 - TypeInformation.specialize(…) now only specializes unresolved parameterized types.  Type specialization - i.e. enrichment of a raw type with a current generic context - is now only done if the current type is not yet resolved completely. This allows wildcarded target references to just fall back to the type to specialize which will then by definition carry more generics information than the one to be specialized.", "B_clean_title": ["datacmn", "1138", "typeinform", "special", "type", "inform", "now", "onli", "special", "unresolv", "parameter", "type", "type", "special", "enrich", "raw", "type", "current", "gener", "context", "now", "onli", "done", "current", "type", "not", "yet", "resolv", "complet", "thi", "allow", "wildcard", "target", "refer", "just", "fall", "back", "type", "special", "which", "will", "then", "by", "definit", "carri", "more", "gener", "inform", "than", "one", "special"]},
{"A_title": "OakIndexInput cloned instances are not closedRelated to the inspections I was doing for OAK-2798 I also noticed that we dont fully comply with the IndexInput javadoc 1 as the cloned instances should throw the given exception if original is closed but I also think that the original instance should close the cloned instances see also ByteBufferIndexInput#close|https://github.com/apache/lucene-solr/blob/lucene_solr_4_7_1/lucene/core/src/java/org/apache/lucene/store/ByteBufferIndexInput.java#L271.  1 : code /** Abstract base class for input from a file in a @link Directory.  A  * random-access input stream.  Used for all Lucene index input operations.  *  * <p>@code IndexInput may only be used from one thread because it is not  * thread safe (it keeps internal state like file position). To allow  * multithreaded use every @code IndexInput instance must be cloned before  * used in another thread. Subclasses must therefore implement @link #clone()  * returning a new @code IndexInput which operates on the same underlying  * resource but positioned independently. Lucene never closes cloned  * @code IndexInputs it will only do this on the original one.  * The original instance must take care that cloned instances throw  * @link AlreadyClosedException when the original one is closed. code", "A_clean_title": ["oakindexinput", "oak", "index", "input", "clone", "instanc", "are", "not", "closedrel", "close", "relat", "inspect", "wa", "do", "oak", "2798", "also", "notic", "that", "we", "dont", "fulli", "compli", "indexinput", "index", "input", "javadoc", "as", "clone", "instanc", "throw", "given", "except", "origin", "close", "but", "also", "think", "that", "origin", "instanc", "close", "clone", "instanc", "see", "also", "bytebufferindexinput", "byte", "buffer", "index", "input", "close|http", "java", "github", "com", "apach", "lucen", "solr", "solr", "blob", "lucen", "lucen", "core", "src", "java", "org", "apach", "lucen", "store", "bytebufferindexinput", "byte", "buffer", "index", "input", "l271", "code", "abstract", "base", "class", "input", "file", "link", "directori", "random", "access", "input", "stream", "use", "all", "lucen", "index", "input", "oper", "code", "indexinput", "index", "input", "may", "onli", "use", "one", "thread", "becaus", "it", "not", "thread", "safe", "it", "keep", "intern", "state", "like", "file", "posit", "allow", "multithread", "use", "everi", "code", "indexinput", "index", "input", "instanc", "must", "clone", "befor", "use", "anoth", "thread", "subclass", "must", "therefor", "implement", "link", "clone", "return", "new", "code", "indexinput", "index", "input", "which", "oper", "same", "underli", "resourc", "but", "posit", "independ", "lucen", "never", "close", "clone", "code", "indexinput", "index", "input", "it", "will", "onli", "thi", "origin", "one", "origin", "instanc", "must", "take", "care", "that", "clone", "instanc", "throw", "link", "alreadyclosedexcept", "alreadi", "close", "except", "when", "origin", "one", "close", "code"], "B_title": "- close cloned OakIndexInput instances on close of main one", "B_clean_title": ["close", "clone", "oakindexinput", "oak", "index", "input", "instanc", "close", "main", "one"]},
{"A_title": "Spaces in path cause ModifcationWatcher to failThe ModificationWatcher isnt able to reload resource files if theres a space in the path.  The problem is that Files#getLocalFileFromUrl(String) receives an URL encoded String in which spaces are encoded to %20. They are never decoded and passed to File(). The fix is not to use the external representation of an URL but the file representation.", "A_clean_title": ["space", "path", "caus", "modifcationwatch", "modifc", "watcher", "failth", "fail", "modificationwatch", "modif", "watcher", "isnt", "abl", "reload", "resourc", "file", "there", "space", "path", "problem", "that", "file", "getlocalfilefromurl", "get", "local", "file", "url", "string", "receiv", "url", "encod", "string", "which", "space", "are", "encod", "20", "they", "are", "never", "decod", "pass", "file", "fix", "not", "use", "extern", "represent", "url", "but", "file", "represent"], "B_title": "url must be decoded for local files", "B_clean_title": ["url", "must", "decod", "local", "file"]},
{"A_title": "Parent of unseen children must not be removableWith OAK-2673 its now possible to have hidden intermediate nodes created concurrently. So a scenario like: noformat start -> /:hidden N1 creates /:hiddent/parent/node1 N2 creates /:hidden/parent/node2 noformat is allowed.  But if N2s creation of parent got persisted later than that on N1 then N2 is currently able to delete parent even though theres node1.", "A_clean_title": ["parent", "unseen", "children", "must", "not", "removablewith", "remov", "oak", "2673", "it", "now", "possibl", "have", "hidden", "intermedi", "node", "creat", "concurr", "so", "scenario", "like", "noformat", "start", "hidden", "n1", "creat", "hiddent", "parent", "node1", "n2", "creat", "hidden", "parent", "node2", "noformat", "allow", "but", "n2", "creation", "parent", "got", "persist", "later", "than", "that", "n1", "then", "n2", "current", "abl", "delet", "parent", "even", "though", "there", "node1"], "B_title": "Parent of unseen children must not be removable", "B_clean_title": ["parent", "unseen", "children", "must", "not", "remov"]},
{"A_title": "Adding a node with the name of a removed node can lead to an inconsistent hierarchy of node buildersNone", "A_clean_title": ["ad", "node", "name", "remov", "node", "lead", "inconsist", "hierarchi", "node", "buildersnon", "builder", "none"], "B_title": "Adding a node with the name of a removed node can lead to an inconsistent hierarchy of node builders", "B_clean_title": ["ad", "node", "name", "remov", "node", "lead", "inconsist", "hierarchi", "node", "builder"]},
{"A_title": "Async index update persists conflict markersA long running test I performed yesterday failed with a FileNotFoundException in the lucene index. After analyzing the issue it turned  out the async index update persisted a conflict markers introduced by a rebase call. So far Im not able to reproduce it with a more simple test setup and after a shorter time (the initial test failed after 10 hours). Given the way the async index update work there shouldnt be any conflicts because its the only component writing into this location of the repository.   As an immediate workaround Id like to add the AnnotatingConflictHandler & ConflictValidator combo to the merge call to make sure a commit with conflict markers does not get persisted.", "A_clean_title": ["async", "index", "updat", "persist", "conflict", "markersa", "marker", "long", "run", "test", "perform", "yesterday", "fail", "filenotfoundexcept", "file", "not", "found", "except", "lucen", "index", "after", "analyz", "issu", "it", "turn", "out", "async", "index", "updat", "persist", "conflict", "marker", "introduc", "by", "rebas", "call", "so", "far", "im", "not", "abl", "reproduc", "it", "more", "simpl", "test", "setup", "after", "shorter", "time", "initi", "test", "fail", "after", "10", "hour", "given", "way", "async", "index", "updat", "work", "there", "shouldnt", "ani", "conflict", "becaus", "it", "onli", "compon", "write", "into", "thi", "locat", "repositori", "as", "immedi", "workaround", "id", "like", "add", "annotatingconflicthandl", "annot", "conflict", "handler", "conflictvalid", "conflict", "valid", "combo", "merg", "call", "make", "sure", "commit", "conflict", "marker", "not", "get", "persist"], "B_title": "Async index update persists conflict markers", "B_clean_title": ["async", "index", "updat", "persist", "conflict", "marker"]},
{"A_title": "Reindex removes all nodes under index definition nodeReindex logic in IndexUpdate removes all child node from index definition node thus removing valid nodes which might be part of index defintion. It should only remove hidden nodes", "A_clean_title": ["reindex", "remov", "all", "node", "under", "index", "definit", "nodereindex", "node", "reindex", "logic", "indexupd", "index", "updat", "remov", "all", "child", "node", "index", "definit", "node", "thu", "remov", "valid", "node", "which", "might", "part", "index", "defint", "it", "onli", "remov", "hidden", "node"], "B_title": "- Reindex removes all nodes under index defenition node", "B_clean_title": ["reindex", "remov", "all", "node", "under", "index", "defenit", "node"]},
{"A_title": "Ignore the path parameters when reading the page classhttp://localhost:8080/linkomatic/wicket/bookmarkable/org.apache.wicket.examples.linkomatic.Page3;myjsessionid=123456 leads to :  WARN  - AbstractRepeater           - Child component of repeater org.apache.wicket.markup.repeater.RepeatingView:area has a non-safe child id of page1. Safe child ids must be composed of digits only. WARN  - WicketObjects              - Could not resolve class org.apache.wicket.examples.linkomatic.Page3;blass=koko java.lang.ClassNotFoundException: org/apache/wicket/examples/linkomatic/Page3;blass=koko at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:264) at org.apache.wicket.application.AbstractClassResolver.resolveClass(AbstractClassResolver.java:108) at org.apache.wicket.core.util.lang.WicketObjects.resolveClass(WicketObjects.java:72) at org.apache.wicket.core.request.mapper.AbstractComponentMapper.getPageClass(AbstractComponentMapper.java:139) at org.apache.wicket.core.request.mapper.BookmarkableMapper.parseRequest(BookmarkableMapper.java:118) at org.apache.wicket.core.request.mapper.AbstractBookmarkableMapper.mapRequest(AbstractBookmarkableMapper.java:292) at org.apache.wicket.request.mapper.CompoundRequestMapper.mapRequest(CompoundRequestMapper.java:152) at org.apache.wicket.request.cycle.RequestCycle.resolveRequestHandler(RequestCycle.java:190) ...  Such request at the moment works only if the the path parameter name is jsessionid", "A_clean_title": ["ignor", "path", "paramet", "when", "read", "page", "classhttp", "apach", "wicket", "exampl", "linkomat", "page3", "localhost:8080", "linkomat", "wicket", "bookmark", "org", "myjsessionid=123456", "lead", "warn", "abstractrepeat", "abstract", "repeat", "child", "compon", "repeat", "org", "apach", "wicket", "markup", "repeat", "repeatingview", "repeat", "view", "area", "ha", "non", "safe", "child", "id", "page1", "safe", "child", "id", "must", "compos", "digit", "onli", "warn", "wicketobject", "wicket", "object", "could", "not", "resolv", "class", "org", "apach", "wicket", "exampl", "linkomat", "page3", "blass=koko", "java", "lang", "classnotfoundexcept", "class", "not", "found", "except", "org", "apach", "wicket", "exampl", "linkomat", "page3", "blass=koko", "at", "java", "lang", "class", "forname0", "name0", "nativ", "method", "at", "java", "lang", "class", "fornam", "name", "class", "java:264", "at", "org", "apach", "wicket", "applic", "abstractclassresolv", "resolveclass", "abstract", "class", "resolv", "resolv", "class", "abstractclassresolv", "java:108", "abstract", "class", "resolv", "at", "org", "apach", "wicket", "core", "util", "lang", "wicketobject", "resolveclass", "wicket", "object", "resolv", "class", "wicketobject", "java:72", "wicket", "object", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractcomponentmapp", "getpageclass", "abstract", "compon", "mapper", "get", "page", "class", "abstractcomponentmapp", "java:139", "abstract", "compon", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "bookmarkablemapp", "parserequest", "bookmark", "mapper", "pars", "request", "bookmarkablemapp", "java:118", "bookmark", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractbookmarkablemapp", "maprequest", "abstract", "bookmark", "mapper", "map", "request", "abstractbookmarkablemapp", "java:292", "abstract", "bookmark", "mapper", "at", "org", "apach", "wicket", "request", "mapper", "compoundrequestmapp", "maprequest", "compound", "request", "mapper", "map", "request", "compoundrequestmapp", "java:152", "compound", "request", "mapper", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "resolverequesthandl", "request", "cycl", "resolv", "request", "handler", "requestcycl", "java:190", "request", "cycl", "such", "request", "at", "moment", "work", "onli", "path", "paramet", "name", "jsessionid"], "B_title": "Ignore the path parameters when reading the page class", "B_clean_title": ["ignor", "path", "paramet", "when", "read", "page", "class"]},
{"A_title": "Index path property should be considered optional for copy on read logicAs part of changes done for OAK-4347 logic assumes that indexPath is always non null. This works fine for fresh setup where the indexPath would have been set by the initial indexing. However for upgraded setup this assumption would break as it might happen that index does not get updated with new approach and before that a read is performed.  Currently with updated code on upgraded setup following exception is seen   noformat Caused by: javax.security.auth.login.LoginException: java.lang.NullPointerException: Index path property :indexPath not found         at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:236)         at org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinition.getIndexPathFromConfig(IndexDefinition.java:664)         at org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier.getSharedWorkingSet(IndexCopier.java:242)         at org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier.wrapForRead(IndexCopier.java:140)         at org.apache.jackrabbit.oak.plugins.index.lucene.IndexNode.open(IndexNode.java:53)         at org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker.findIndexNode(IndexTracker.java:179)         at org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker.acquireIndexNode(IndexTracker.java:154)         at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex.getPlans(LucenePropertyIndex.java:250) noformat  For this specific flow the indexPath can be passed in and not looked up from IndexDefinition", "A_clean_title": ["index", "path", "properti", "consid", "option", "copi", "read", "logica", "logic", "as", "part", "chang", "done", "oak", "4347", "logic", "assum", "that", "indexpath", "index", "path", "alway", "non", "null", "thi", "work", "fine", "fresh", "setup", "where", "indexpath", "index", "path", "would", "have", "been", "set", "by", "initi", "index", "howev", "upgrad", "setup", "thi", "assumpt", "would", "break", "as", "it", "might", "happen", "that", "index", "not", "get", "updat", "new", "approach", "befor", "that", "read", "perform", "current", "updat", "code", "upgrad", "setup", "follow", "except", "seen", "noformat", "caus", "by", "javax", "secur", "auth", "login", "loginexcept", "login", "except", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "index", "path", "properti", "indexpath", "index", "path", "not", "found", "at", "com", "googl", "common", "base", "precondit", "checknotnul", "check", "not", "null", "precondit", "java:236", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexdefinit", "getindexpathfromconfig", "index", "definit", "get", "index", "path", "config", "indexdefinit", "java:664", "index", "definit", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexcopi", "getsharedworkingset", "index", "copier", "get", "share", "work", "set", "indexcopi", "java:242", "index", "copier", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexcopi", "wrapforread", "index", "copier", "wrap", "read", "indexcopi", "java:140", "index", "copier", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexnod", "open", "index", "node", "indexnod", "java:53", "index", "node", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indextrack", "findindexnod", "index", "tracker", "find", "index", "node", "indextrack", "java:179", "index", "tracker", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indextrack", "acquireindexnod", "index", "tracker", "acquir", "index", "node", "indextrack", "java:154", "index", "tracker", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "getplan", "lucen", "properti", "index", "get", "plan", "lucenepropertyindex", "java:250", "lucen", "properti", "index", "noformat", "thi", "specif", "flow", "indexpath", "index", "path", "pass", "not", "look", "up", "indexdefinit", "index", "definit"], "B_title": "- Index path property should be considered optional for copy on read logic", "B_clean_title": ["index", "path", "properti", "consid", "option", "copi", "read", "logic"]},
{"A_title": "StringResourceModels doesnt seem to detach properlyIf a StringResourceModel contains a model for property substitutions and there has not been assigned a component it is relative to on construction time it will not detach the property substitution model.  See this thread for a full explanation http://apache-wicket.1842946.n4.nabble.com/StringResourceModels-doesn-t-seem-to-detach-properly-td4257267.html", "A_clean_title": ["stringresourcemodel", "string", "resourc", "model", "doesnt", "seem", "detach", "properlyif", "properli", "stringresourcemodel", "string", "resourc", "model", "contain", "model", "properti", "substitut", "there", "ha", "not", "been", "assign", "compon", "it", "rel", "construct", "time", "it", "will", "not", "detach", "properti", "substitut", "model", "see", "thi", "thread", "full", "explan", "http", "doesn", "seem", "detach", "properli", "apach", "wicket", "1842946", "n4", "nabbl", "td4257267", "html", "com", "stringresourcemodel", "string", "resourc", "model"], "B_title": "StringResourceModels doesnt seem to detach properly", "B_clean_title": ["stringresourcemodel", "string", "resourc", "model", "doesnt", "seem", "detach", "properli"]},
{"A_title": "Rare case for updateMembershipMatrix() in FuzzyKMeansClustererThe function updateMembershipMatrix() in FuzzyKMeansClusterer assigns the points to the cluster with the highest membership. Consider the following case:  If the distance between a point and the cluster center is zero then we will have a cluster membership of one and all other membership values will be zero.  So the if condition: if (membershipMatrixij > maxMembership)                      maxMembership = membershipMatrixij;                     newCluster = j;  will never be true during the for loop and newCluster will remain -1. This will throw an exception because of the line: clusters.get(newCluster)                     .addPoint(point);  Adding the following condition can solve the problem: double d; if (sum == 0) d = 1; else d = 1.0/sum;", "A_clean_title": ["rare", "case", "updatemembershipmatrix", "updat", "membership", "matrix", "fuzzykmeansclustererth", "fuzzi", "mean", "cluster", "function", "updatemembershipmatrix", "updat", "membership", "matrix", "fuzzykmeanscluster", "fuzzi", "mean", "cluster", "assign", "point", "cluster", "highest", "membership", "consid", "follow", "case", "distanc", "between", "point", "cluster", "center", "zero", "then", "we", "will", "have", "cluster", "membership", "one", "all", "other", "membership", "valu", "will", "zero", "so", "condit", "membershipmatrixij", "membership", "matrixij", "maxmembership", "max", "membership", "maxmembership", "max", "membership", "membershipmatrixij", "membership", "matrixij", "newclust", "new", "cluster", "will", "never", "true", "dure", "loop", "newclust", "new", "cluster", "will", "remain", "thi", "will", "throw", "except", "becaus", "line", "cluster", "get", "newclust", "new", "cluster", "addpoint", "add", "point", "point", "ad", "follow", "condit", "solv", "problem", "doubl", "sum", "sum"], "B_title": "Fix FuzzyKMeansClusterer when data points equal a cluster center. Thanks to Pashutan Modaresi", "B_clean_title": ["fix", "fuzzykmeanscluster", "fuzzi", "mean", "cluster", "when", "data", "point", "equal", "cluster", "center", "thank", "pashutan", "modaresi"]},
{"A_title": "BookmarkablePageLinks not working on a forwarded pageWhile migrating our app from 1.4 to 1.5 we have discovered a problem with how BookmarkablePageLinks are rendered.  The attached quickstart demonstrates the problem:  Two pages: HomePage and OtherPage mounted at: /content/home and /content/other respectively.  These are mounted using the encoder UrlPathPageParametersEncoder for backwards compatibility with existing 1.4 style URLs.  A filter has been established in web.xml to forward requests to root (eg. localhost) to localhost/content/home Note: I have left out the port :8080 part from all URL references so please insert when testing  Point browser to http://localhost and the page is forwarded to http://localhost/content/home and displays correctly (browser URL still shows http://localhost as desired) but the links do not work because they remove the content segment of the URL:  eg. Home link -> http://localhost/home - fails - should have been http://localhost/content/home  If you type in the full URL: http://localhost/content/home  then the home page displays and the links work correctly.  A similar page set  up works fine in 1.4.", "A_clean_title": ["bookmarkablepagelink", "bookmark", "page", "link", "not", "work", "forward", "pagewhil", "page", "while", "migrat", "our", "app", "we", "have", "discov", "problem", "how", "bookmarkablepagelink", "bookmark", "page", "link", "are", "render", "attach", "quickstart", "demonstr", "problem", "two", "page", "homepag", "home", "page", "otherpag", "other", "page", "mount", "at", "content", "home", "content", "other", "respect", "these", "are", "mount", "encod", "urlpathpageparametersencod", "url", "path", "page", "paramet", "encod", "backward", "compat", "exist", "style", "url", "ur", "ls", "filter", "ha", "been", "establish", "web", "xml", "forward", "request", "root", "eg", "localhost", "localhost", "content", "home", "note", "have", "left", "out", "port", ":8080", "part", "all", "url", "refer", "so", "pleas", "insert", "when", "test", "point", "browser", "http", "localhost", "page", "forward", "http", "localhost", "content", "home", "display", "correctli", "browser", "url", "still", "show", "http", "localhost", "as", "desir", "but", "link", "not", "work", "becaus", "they", "remov", "content", "segment", "url", "eg", "home", "link", "http", "localhost", "home", "fail", "have", "been", "http", "localhost", "content", "home", "you", "type", "full", "url", "http", "localhost", "content", "home", "then", "home", "page", "display", "link", "work", "correctli", "similar", "page", "set", "up", "work", "fine"], "B_title": "BookmarkablePageLinks not working on a forwarded page", "B_clean_title": ["bookmarkablepagelink", "bookmark", "page", "link", "not", "work", "forward", "page"]},
{"A_title": "BinomialDistribution deals with degenerate cases incorrectlyThe following calculation returns false results:  new BinomialDistribution(0 0.01).logProbability(0)  It evaluates to Double.NaN when it should be 0 (cf. for example dbinom(0 0 0.01 log=T) in R).  I attach a patch dealing with the problem. The patch also adds a test for this bug.", "A_clean_title": ["binomialdistribut", "binomi", "distribut", "deal", "degener", "case", "incorrectlyth", "incorrectli", "follow", "calcul", "return", "fals", "result", "new", "binomialdistribut", "binomi", "distribut", "01", "logprob", "log", "probabl", "it", "evalu", "doubl", "nan", "na", "when", "it", "cf", "exampl", "dbinom", "01", "log=t", "attach", "patch", "deal", "problem", "patch", "also", "add", "test", "thi", "bug"], "B_title": "Fixed BinomialDistribution to deal with degenerate cases correctly.", "B_clean_title": ["fix", "binomialdistribut", "binomi", "distribut", "deal", "degener", "case", "correctli"]},
{"A_title": "Wicket 1.5 RC-3 Bug with conditional commentsIE Conditional Comments with script block causes malformed HTML on Chrome and Firefox.", "A_clean_title": ["wicket", "rc", "bug", "condit", "commentsi", "comment", "ie", "condit", "comment", "script", "block", "caus", "malform", "html", "chrome", "firefox"], "B_title": "Wicket 1.5 RC-3 Bug with conditional comments", "B_clean_title": ["wicket", "rc", "bug", "condit", "comment"]},
{"A_title": "BufferedWebResponse fails to add/clear cookie in redirectbufferedWebResponse.addCookie( cookie );  That fails under certain conditions: (1) when called on the last of three 302 redirects during OpenID login; and (2) on single redirect immediately after container startup though it later recovers.  Failure confirmed in Firebug; no cookies sent in any of the response headers.  My workaround is to bypass the buffered response.  This works:  ((HttpServletResponse)bufferedWebResponse.getContainerResponse()).addCookie( cookie );", "A_clean_title": ["bufferedwebrespons", "buffer", "web", "respons", "fail", "add", "clear", "cooki", "redirectbufferedwebrespons", "addcooki", "redirectbuff", "web", "respons", "add", "cooki", "cooki", "that", "fail", "under", "certain", "condit", "when", "call", "last", "three", "302", "redirect", "dure", "openid", "open", "id", "login", "singl", "redirect", "immedi", "after", "contain", "startup", "though", "it", "later", "recov", "failur", "confirm", "firebug", "no", "cooki", "sent", "ani", "respons", "header", "my", "workaround", "bypass", "buffer", "respons", "thi", "work", "httpservletrespons", "http", "servlet", "respons", "bufferedwebrespons", "getcontainerrespons", "buffer", "web", "respons", "get", "contain", "respons", "addcooki", "add", "cooki", "cooki"], "B_title": "BufferedWebResponse fails to add/clear cookie in redirect", "B_clean_title": ["bufferedwebrespons", "buffer", "web", "respons", "fail", "add", "clear", "cooki", "redirect"]},
{"A_title": "MiniMap.iterator().next() should throw NoSuchElementExceptionThe wicket.util.collections.MiniMap.iterator().next() should throw NoSuchElementException when there are no more elements to return (line 235) please add: if(i >= size)     throw new NoSuchElementException();", "A_clean_title": ["minimap", "iter", "mini", "map", "next", "throw", "nosuchelementexceptionth", "no", "such", "element", "except", "wicket", "util", "collect", "minimap", "iter", "mini", "map", "next", "throw", "nosuchelementexcept", "no", "such", "element", "except", "when", "there", "are", "no", "more", "element", "return", "line", "235", "pleas", "add", "size", "throw", "new", "nosuchelementexcept", "no", "such", "element", "except"], "B_title": "More fixes off the back of WICKET-428 this time for MicroMap.", "B_clean_title": ["more", "fix", "off", "back", "wicket", "428", "thi", "time", "micromap", "micro", "map"]},
{"A_title": "Revisit PrivilegeDefinitionStores use of null as a child name parameterAs discussed on OAK-635 Im extracting the PrivilegeDefinitionStore code&patch into a dedicated issue.  Following the discussion on the dev list Ive filed it as a bug as nulls are not considered valid input parameters.", "A_clean_title": ["revisit", "privilegedefinitionstor", "privileg", "definit", "store", "use", "null", "as", "child", "name", "parametera", "paramet", "as", "discuss", "oak", "635", "im", "extract", "privilegedefinitionstor", "privileg", "definit", "store", "code", "patch", "into", "dedic", "issu", "follow", "discuss", "dev", "list", "ive", "file", "it", "as", "bug", "as", "null", "are", "not", "consid", "valid", "input", "paramet"], "B_title": ": Revisit PrivilegeDefinitionStores use of null as a child name parameter", "B_clean_title": ["revisit", "privilegedefinitionstor", "privileg", "definit", "store", "use", "null", "as", "child", "name", "paramet"]},
{"A_title": "Wide bounds to CMAESOptimizer result in NaN parameters passed to fitness functionIf you give large values as lower/upper bounds (for example -Double.MAX_VALUE as a lower bound) the optimizer can call the fitness function with parameters set to NaN.  My guess is this is due to FitnessFunction.encode/decode generating NaN when normalizing/denormalizing parameters.  For example if the difference between the lower and upper bound is greater than Double.MAX_VALUE encode could divide infinity by infinity.", "A_clean_title": ["wide", "bound", "cmaesoptim", "cmae", "optim", "result", "nan", "na", "paramet", "pass", "fit", "functionif", "function", "you", "give", "larg", "valu", "as", "lower", "upper", "bound", "exampl", "doubl", "max", "valu", "as", "lower", "bound", "optim", "call", "fit", "function", "paramet", "set", "nan", "na", "my", "guess", "thi", "due", "fitnessfunct", "fit", "function", "encod", "decod", "gener", "nan", "na", "when", "normal", "denorm", "paramet", "exampl", "differ", "between", "lower", "upper", "bound", "greater", "than", "doubl", "max", "valu", "encod", "could", "divid", "infin", "by", "infin"], "B_title": "Early detection that overflow will occur in the variables normalization procedure (encode method). Warning mentioned in the documentation.", "B_clean_title": ["earli", "detect", "that", "overflow", "will", "occur", "variabl", "normal", "procedur", "encod", "method", "warn", "mention", "document"]},
{"A_title": "Generate change list separated by types using labelsAs discussed on the mailing list instead of one big list of Improvements the change list for the release is divided into change types based on labels. It is required to specify which labels should be considered separately. Some other labels can be excluded (like question or refactoring). There is also headerForOtherChanges method to override default Other header.", "A_clean_title": ["gener", "chang", "list", "separ", "by", "type", "labelsa", "label", "as", "discuss", "mail", "list", "instead", "one", "big", "list", "improv", "chang", "list", "releas", "divid", "into", "chang", "type", "base", "label", "it", "requir", "specifi", "which", "label", "consid", "separ", "some", "other", "label", "exclud", "like", "question", "or", "refactor", "there", "also", "headerforotherchang", "header", "other", "chang", "method", "overrid", "default", "other", "header"], "B_title": "In order to fixed issue 79 (NPE) added null handling code", "B_clean_title": ["order", "fix", "issu", "79", "npe", "ad", "null", "handl", "code"]},
{"A_title": "NPE in BSPTree#fitToCell()Hello  I faced a NPE using  BSPTree#fitToCell() from the SVN trunk. I fixed the problem using a small patch I will attach to the ticket.", "A_clean_title": ["npe", "bsptree", "bsp", "tree", "fittocel", "fit", "cell", "hello", "face", "npe", "bsptree", "bsp", "tree", "fittocel", "fit", "cell", "svn", "trunk", "fix", "problem", "small", "patch", "will", "attach", "ticket"], "B_title": "Fixed NullPointerException in BSPTree.", "B_clean_title": ["fix", "nullpointerexcept", "null", "pointer", "except", "bsptree", "bsp", "tree"]},
{"A_title": "In wicket 1.5 urlFor returns incorrect string for package mounted pagesAttached two quickstart projects for 1.4 and 1.5.  Then access http://localhost:8080/app/Page1 and see 1.5 returns wrong address.", "A_clean_title": ["wicket", "urlfor", "url", "return", "incorrect", "string", "packag", "mount", "pagesattach", "page", "attach", "two", "quickstart", "project", "then", "access", "http", "localhost:8080", "app", "page1", "see", "return", "wrong", "address"], "B_title": "In wicket 1.5 urlFor returns incorrect string for package mounted pages", "B_clean_title": ["wicket", "urlfor", "url", "return", "incorrect", "string", "packag", "mount", "page"]},
{"A_title": "MemoryNodeBuilder.setNode() loses property valuescode builder.setNode(a nodeA); builder.child(a).setProperty(...); code  After the 2nd line executed properties initially present on nodeA are gone on builder.getNodeState().", "A_clean_title": ["memorynodebuild", "setnod", "memori", "node", "builder", "set", "node", "lose", "properti", "valuescod", "builder", "setnod", "set", "node", "nodea", "node", "builder", "child", "setproperti", "set", "properti", "code", "after", "2nd", "line", "execut", "properti", "initi", "present", "nodea", "node", "are", "gone", "builder", "getnodest", "get", "node", "state"], "B_title": "MemoryNodeBuilder.setNode() loses property values", "B_clean_title": ["memorynodebuild", "setnod", "memori", "node", "builder", "set", "node", "lose", "properti", "valu"]},
{"A_title": "XPath queries with ISO9075 escaped properties dont workXPath queries with ISO9075 escaped properties or relative path dont work as expected. Example:   code /jcr:root//*/element(*rep:User)_x002e_tokens/@jcr:primaryType code  The relative property should be converted to .tokens/@jcr:primaryType but is not.  This issue is similar to OAK-1000 but for property names or relative properties.", "A_clean_title": ["xpath", "path", "queri", "iso9075", "escap", "properti", "dont", "workxpath", "work", "path", "queri", "iso9075", "escap", "properti", "or", "rel", "path", "dont", "work", "as", "expect", "exampl", "code", "jcr", "root", "element", "rep", "user", "x002e", "token", "jcr", "primarytyp", "primari", "type", "code", "rel", "properti", "convert", "token", "jcr", "primarytyp", "primari", "type", "but", "not", "thi", "issu", "similar", "oak", "1000", "but", "properti", "name", "or", "rel", "properti"], "B_title": "XPath queries with ISO9075 escaped properties dont work", "B_clean_title": ["xpath", "path", "queri", "iso9075", "escap", "properti", "dont", "work"]},
{"A_title": "AbstractRandomGenerator nextInt() and nextLong() default implementations generate only positive valuesThe javadoc for these methods (and what is specified in the RandomGenerator interface) says that all int / long values should be in the range of these methods.  The default implementations provided in this class do not generate negative values.", "A_clean_title": ["abstractrandomgener", "abstract", "random", "gener", "nextint", "next", "int", "nextlong", "next", "long", "default", "implement", "gener", "onli", "posit", "valuesth", "valu", "javadoc", "these", "method", "what", "specifi", "randomgener", "random", "gener", "interfac", "say", "that", "all", "int", "long", "valu", "rang", "these", "method", "default", "implement", "provid", "thi", "class", "not", "gener", "neg", "valu"], "B_title": "Fixed bugs in AbstractRandomGenerator nextInt() and nextLong() default implementations.  Prior to the fix for this issue these methods generated only positive values.", "B_clean_title": ["fix", "bug", "abstractrandomgener", "abstract", "random", "gener", "nextint", "next", "int", "nextlong", "next", "long", "default", "implement", "prior", "fix", "thi", "issu", "these", "method", "gener", "onli", "posit", "valu"]},
{"A_title": "NumberUtils#createNumber - bad behaviour for leading --NumberUtils#createNumber checks for a leading -- in the string and returns null if found. This is documented as a work round for a bug in BigDecimal. Returning nulll is contrary to the Javadoc and the behaviour for other methods which would throw NumberFormatException. Its not clear whether the BigDecimal problem still exists with recent versions of Java. However if it does exist then the check needs to be done for all invocations of BigDecimal i.e. needs to be moved to createBigDecimal.", "A_clean_title": ["numberutil", "number", "util", "createnumb", "creat", "number", "bad", "behaviour", "lead", "numberutil", "number", "util", "createnumb", "creat", "number", "check", "lead", "string", "return", "null", "found", "thi", "document", "as", "work", "round", "bug", "bigdecim", "big", "decim", "return", "nulll", "contrari", "javadoc", "behaviour", "other", "method", "which", "would", "throw", "numberformatexcept", "number", "format", "except", "it", "not", "clear", "whether", "bigdecim", "big", "decim", "problem", "still", "exist", "recent", "version", "java", "howev", "it", "exist", "then", "check", "need", "done", "all", "invoc", "bigdecim", "big", "decim", "need", "move", "createbigdecim", "creat", "big", "decim"], "B_title": "NumberUtils#createNumber - bad behaviour for leading --", "B_clean_title": ["numberutil", "number", "util", "createnumb", "creat", "number", "bad", "behaviour", "lead"]},
{"A_title": "ZooKeeperCheckpointIDCounter.start() can block JobManager actorIn HA mode the job manager enables checkpoints during submission of streaming programs.  This leads to call to ZooKeeperCheckpointIDCounter.start() which communicates with ZooKeeper. This can block the job manager actor.  A solution is to start the counter later instead of the CheckpointCoordinator constructor.", "A_clean_title": ["zookeepercheckpointidcount", "start", "zoo", "keeper", "checkpoint", "id", "counter", "block", "jobmanag", "job", "manag", "actorin", "actor", "mode", "job", "manag", "enabl", "checkpoint", "dure", "submiss", "stream", "program", "thi", "lead", "call", "zookeepercheckpointidcount", "start", "zoo", "keeper", "checkpoint", "id", "counter", "which", "commun", "zookeep", "zoo", "keeper", "thi", "block", "job", "manag", "actor", "solut", "start", "counter", "later", "instead", "checkpointcoordin", "checkpoint", "coordin", "constructor"], "B_title": "runtime Defer start of checkpoint ID counter", "B_clean_title": ["runtim", "defer", "start", "checkpoint", "id", "counter"]},
{"A_title": "Missing properties from base class when recursive types are involved.When a type hierarchy as follows is constructed and the base class type is constructed first by the TypeFactory then serializing the sub class fails due to missing properties from the base class.   Serializes sub as  sub:2 where base:1sub:2 is expected. Ive created a minimal scenario of this bug here:  https://github.com/slobo-showbie/jackson-recursive-type-bug Ive experienced this bug in 2.7.8 2.8.8 and 2.8.8.1", "A_clean_title": ["miss", "properti", "base", "class", "when", "recurs", "type", "are", "involv", "when", "type", "hierarchi", "as", "follow", "construct", "base", "class", "type", "construct", "first", "by", "typefactori", "type", "factori", "then", "serial", "sub", "class", "fail", "due", "miss", "properti", "base", "class", "serial", "sub", "as", "sub:2", "where", "base:1sub:2", "expect", "ive", "creat", "minim", "scenario", "thi", "bug", "here", "http", "recurs", "type", "bug", "showbi", "jackson", "github", "com", "slobo", "ive", "experienc", "thi", "bug"], "B_title": "Merge pull request #1650 from slobo-showbie/2.8  Fix #1647: Missing properties from base class when recursive types are involved", "B_clean_title": ["merg", "pull", "request", "1650", "slobo", "showbi", "fix", "1647", "miss", "properti", "base", "class", "when", "recurs", "type", "are", "involv"]},
{"A_title": "ConditionalWriterIT is failingI noticed that the ConditionalWriterIT was failing in master.   Using the following command with git bisect I tracked it down to commit 3af75fc for ACCUMULO-4077 as the change which broke the IT.  Have not looked into why its failing yet.  noformat mvn clean verify -Dit.test=ConditionalWriterIT -Dfindbugs.skip -Dcheckstyle.skip -Dtest=foo -DfailIfNoTests=false noformat", "A_clean_title": ["conditionalwriterit", "condit", "writer", "it", "failingi", "fail", "notic", "that", "conditionalwriterit", "condit", "writer", "it", "wa", "fail", "master", "follow", "command", "git", "bisect", "track", "it", "down", "commit", "3af75fc", "accumulo", "4077", "as", "chang", "which", "broke", "it", "have", "not", "look", "into", "whi", "it", "fail", "yet", "noformat", "mvn", "clean", "verifi", "dit", "test=conditionalwriterit", "test=condit", "writer", "it", "dfindbug", "skip", "dcheckstyl", "skip", "dtest=foo", "dfailifnotests=fals", "dfail", "no", "tests=fals", "noformat"], "B_title": "Fixed bug with ByteBuffers thats do not start at 0", "B_clean_title": ["fix", "bug", "bytebuff", "byte", "buffer", "that", "not", "start", "at"]},
{"A_title": "RequestCycleListenerCollection.onException should not throw an exception when multiple listeners handle the exceptionWhen multiple listeners handle the exception RequestCycleListenerCollection should simple take the first handler. The current approach makes it impossible to add a listener that handles all exceptions and later add listeners for specific exceptions. Simply removing the if (handlers.size() > 1) should suffice.", "A_clean_title": ["requestcyclelistenercollect", "onexcept", "request", "cycl", "listen", "collect", "except", "not", "throw", "except", "when", "multipl", "listen", "handl", "exceptionwhen", "except", "when", "multipl", "listen", "handl", "except", "requestcyclelistenercollect", "request", "cycl", "listen", "collect", "simpl", "take", "first", "handler", "current", "approach", "make", "it", "imposs", "add", "listen", "that", "handl", "all", "except", "later", "add", "listen", "specif", "except", "simpli", "remov", "handler", "size", "suffic"], "B_title": "Improved exception handling strategy to not fail when multiple handlers are returned: just use the first one that is available. Issue: WICKET-3644", "B_clean_title": ["improv", "except", "handl", "strategi", "not", "fail", "when", "multipl", "handler", "are", "return", "just", "use", "first", "one", "that", "avail", "issu", "wicket", "3644"]},
{"A_title": "Unable to assign single tablet table migrated to 1.6.0Sorry for the screen caps no copy/paste from machines.  Background- several tables migrated from 1.5.1 to 1.6.0. Only one of which was a single tablet. Upon starting we noticed that that single table was not loading and the master was reporting an unassigned tablet. Had a stack trace in the monitor (attached).  Also attached is a a metadata scan of the table in question (ID: 12). I was able to get a functional copy of the table by offlining 12 and cloning it. It functioned without issues. Attached is a copy of its metadata scan as well (ID: 9o)  The stack trace leads me to it being a specific issue with the contents of srv:dir and the only difference is the relative vs. absolute file names. This cluster was not changed to multiple namenodes and ../tables/default_tablet does not exist. There are other tables which still use the relative naming scheme and the system does not seem to be having issues with them.", "A_clean_title": ["unabl", "assign", "singl", "tablet", "tabl", "migrat", "0sorri", "screen", "cap", "no", "copi", "past", "machin", "background", "sever", "tabl", "migrat", "onli", "one", "which", "wa", "singl", "tablet", "upon", "start", "we", "notic", "that", "that", "singl", "tabl", "wa", "not", "load", "master", "wa", "report", "unassign", "tablet", "had", "stack", "trace", "monitor", "attach", "also", "attach", "metadata", "scan", "tabl", "question", "id", "12", "wa", "abl", "get", "function", "copi", "tabl", "by", "offlin", "12", "clone", "it", "it", "function", "without", "issu", "attach", "copi", "it", "metadata", "scan", "as", "well", "id", "9o", "stack", "trace", "lead", "me", "it", "be", "specif", "issu", "content", "srv", "dir", "onli", "differ", "rel", "vs", "absolut", "file", "name", "thi", "cluster", "wa", "not", "chang", "multipl", "namenod", "tablet", "tabl", "default", "not", "exist", "there", "are", "other", "tabl", "which", "still", "use", "rel", "name", "scheme", "system", "not", "seem", "have", "issu", "them"], "B_title": "Include the table id when constructing an absolute path from a relative.", "B_clean_title": ["includ", "tabl", "id", "when", "construct", "absolut", "path", "rel"]},
{"A_title": "Original source line numbers are one-based in source maps.None", "A_clean_title": ["origin", "sourc", "line", "number", "are", "one", "base", "sourc", "map", "none"], "B_title": "Fix how source line numbers are stored in the source files. Fixes issue 575", "B_clean_title": ["fix", "how", "sourc", "line", "number", "are", "store", "sourc", "file", "fix", "issu", "575"]},
{"A_title": "ParentNotInitializedException on CtCommentsHello  When I build JavaFileTest from javapoet with comments enabled the build throw me the following error:   snippet example:   assertThat(source)", "A_clean_title": ["parentnotinitializedexcept", "parent", "not", "initi", "except", "ctcommentshello", "ct", "comment", "hello", "when", "build", "javafiletest", "java", "file", "test", "javapoet", "comment", "enabl", "build", "throw", "me", "follow", "error", "snippet", "exampl", "assertthat", "assert", "that", "sourc"], "B_title": "fix(comment): support comment on string concatenation (#1124)  fix #1123", "B_clean_title": ["fix", "comment", "support", "comment", "string", "concaten", "1124", "fix", "1123"]},
{"A_title": "Unable to set a compression input/output decorator to a  SmileFactoryI have a special need for the  riak-java-client which only allows me to use an ObjectMapper to serialize/deserialize key-values I would like to decorate a SmileFactory with compressors like LZ4 Snappy or GZip but at the moment this is not possible when I try a mapper like the following:   This is the exception I get:  I used Gzip as an example in reality Im using both LZ4 and Gzip and both throw exceptions when I try with a  SmileFactory  this works perfectly with a JsonFactory  the reason for me to prefer a SmileFactory over a JsonFactory is because it is notice-able faster than the JsonFactory so basically itll help compensate the price I pay for compression.", "A_clean_title": ["unabl", "set", "compress", "input", "output", "decor", "smilefactoryi", "smile", "factori", "have", "special", "need", "riak", "java", "client", "which", "onli", "allow", "me", "use", "objectmapp", "object", "mapper", "serial", "deseri", "key", "valu", "would", "like", "decor", "smilefactori", "smile", "factori", "compressor", "like", "lz4", "snappi", "or", "gzip", "zip", "but", "at", "moment", "thi", "not", "possibl", "when", "tri", "mapper", "like", "follow", "thi", "except", "get", "use", "gzip", "as", "exampl", "realiti", "im", "both", "lz4", "gzip", "both", "throw", "except", "when", "tri", "smilefactori", "smile", "factori", "thi", "work", "perfectli", "jsonfactori", "json", "factori", "reason", "me", "prefer", "smilefactori", "smile", "factori", "over", "jsonfactori", "json", "factori", "becaus", "it", "notic", "abl", "faster", "than", "jsonfactori", "json", "factori", "so", "basic", "itll", "help", "compens", "price", "pay", "compress"], "B_title": "Fix #153", "B_clean_title": ["fix", "153"]},
{"A_title": "arcs set split covers full circle instead of being emptyWhen splitting an arcs set using an arc very close to one of the boundaries (but not at the boundary) the algorithm confuses cases for which end - start = 2pi from cases for which end - start = epsilon.  The following test case shows such a failure: code     @Test     public void testSplitWithinEpsilon()          double epsilon = 1.0e-10;         double a = 6.25;         double b = a - 0.5 * epsilon;         ArcsSet set = new ArcsSet(a - 1 a epsilon);         Arc arc = new Arc(b b + FastMath.PI epsilon);         ArcsSet.Split split = set.split(arc);         Assert.assertEquals(set.getSize() split.getPlus().getSize()  epsilon);         Assert.assertNull(split.getMinus());      code  The last assertion (split.getMinus() being null) fails as with current code split.getMinus() covers the full circle from 0 to 2pi.", "A_clean_title": ["arc", "set", "split", "cover", "full", "circl", "instead", "be", "emptywhen", "empti", "when", "split", "arc", "set", "arc", "veri", "close", "one", "boundari", "but", "not", "at", "boundari", "algorithm", "confus", "case", "which", "end", "start", "2pi", "case", "which", "end", "start", "epsilon", "follow", "test", "case", "show", "such", "failur", "code", "test", "public", "void", "testsplitwithinepsilon", "test", "split", "within", "epsilon", "doubl", "epsilon", "10", "0e", "doubl", "25", "doubl", "epsilon", "arcsset", "arc", "set", "set", "new", "arcsset", "arc", "set", "epsilon", "arc", "arc", "new", "arc", "fastmath", "pi", "fast", "math", "epsilon", "arcsset", "split", "arc", "set", "split", "set", "split", "arc", "assert", "assertequ", "assert", "equal", "set", "getsiz", "get", "size", "split", "getplu", "get", "plu", "getsiz", "get", "size", "epsilon", "assert", "assertnul", "assert", "null", "split", "getminu", "get", "minu", "code", "last", "assert", "split", "getminu", "get", "minu", "be", "null", "fail", "as", "current", "code", "split", "getminu", "get", "minu", "cover", "full", "circl", "2pi"], "B_title": "Fixed error when splitting an arc close to its end.", "B_clean_title": ["fix", "error", "when", "split", "arc", "close", "it", "end"]},
{"A_title": "Wicket does not correctly handle http OPTIONS requestscurrently these requests cause regular processing (page rendering) when in fact they should have a special response.  rendering the page in OPTIONS causes renderCount to be incremented and this messes with the subsequent request to the same url via a GET or POST", "A_clean_title": ["wicket", "not", "correctli", "handl", "http", "option", "requestscurr", "these", "request", "caus", "regular", "process", "page", "render", "when", "fact", "they", "have", "special", "respons", "render", "page", "option", "caus", "rendercount", "render", "count", "increment", "thi", "mess", "subsequ", "request", "same", "url", "via", "get", "or", "post"], "B_title": "", "B_clean_title": []},
{"A_title": "Cannot cancel failing/restarting streaming job from the command lineI cannot seem to be able to cancel a failing/restarting job from the command line client. The job cannot be rescheduled so it keeps failing:  The exception I get: 13:58:11240 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Status of job 0c895d22c632de5dfe16c42a9ba818d5 (player-id) changed to RESTARTING. 13:58:25234 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Trying to cancel job with ID 0c895d22c632de5dfe16c42a9ba818d5. 13:58:25561 WARN  akka.remote.ReliableDeliverySupervisor                        - Association with remote system akka.tcp://flink@127.0.0.1:42012 has failed address is now gated for 5000 ms. Reason is: Disassociated.", "A_clean_title": ["not", "cancel", "fail", "restart", "stream", "job", "command", "linei", "line", "not", "seem", "abl", "cancel", "fail", "restart", "job", "command", "line", "client", "job", "not", "reschedul", "so", "it", "keep", "fail", "except", "get", "13:58:11240", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "statu", "job", "0c895d22c632de5dfe16c42a9ba818d5", "player", "id", "chang", "restart", "13:58:25234", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "tri", "cancel", "job", "id", "0c895d22c632de5dfe16c42a9ba818d5", "13:58:25561", "warn", "akka", "remot", "reliabledeliverysupervisor", "reliabl", "deliveri", "supervisor", "associ", "remot", "system", "akka", "tcp", "flink", "127", "1:42012", "ha", "fail", "address", "now", "gate", "5000", "ms", "reason", "disassoci"], "B_title": "runtime Disallow ExecutionGraph state transition from FAILED to RESTARTING", "B_clean_title": ["runtim", "disallow", "executiongraph", "execut", "graph", "state", "transit", "fail", "restart"]},
{"A_title": "Convergence Checker FixesNone", "A_clean_title": ["converg", "checker", "fixesnon", "fix", "none"], "B_title": "Fix checker seeing not old point", "B_clean_title": ["fix", "checker", "see", "not", "old", "point"]},
{"A_title": "Custom StateCheckpointers should be included in the snapshotsCurrently the restoreInitialState call fails when the user uses a custom StateCheckpointer to create the snapshot because the state is restored before the StateCheckpointer is set for the StreamOperatorState. (because the restoreInitialState() call precedes the open() call)  To avoid this issue the custom StateCheckpointer instance should be stored within the snapshot and should be set in the StreamOperatorState before calling restoreState(..).  To reduce the overhead induced by this we can do 2 optimizations:  - We only include custom StateCheckpointers (the default java serializer one is always available)  - We only serialize the checkpointer once and store the byte array in the snapshot", "A_clean_title": ["custom", "statecheckpoint", "state", "checkpoint", "includ", "snapshotscurr", "snapshot", "current", "restoreinitialst", "restor", "initi", "state", "call", "fail", "when", "user", "use", "custom", "statecheckpoint", "state", "checkpoint", "creat", "snapshot", "becaus", "state", "restor", "befor", "statecheckpoint", "state", "checkpoint", "set", "streamoperatorst", "stream", "oper", "state", "becaus", "restoreinitialst", "restor", "initi", "state", "call", "preced", "open", "call", "avoid", "thi", "issu", "custom", "statecheckpoint", "state", "checkpoint", "instanc", "store", "within", "snapshot", "set", "streamoperatorst", "stream", "oper", "state", "befor", "call", "restorest", "restor", "state", "reduc", "overhead", "induc", "by", "thi", "we", "optim", "we", "onli", "includ", "custom", "statecheckpoint", "state", "checkpoint", "default", "java", "serial", "one", "alway", "avail", "we", "onli", "serial", "checkpoint", "onc", "store", "byte", "array", "snapshot"], "B_title": "streaming Set state restore to lazy to avoid StateCheckpointer issues and reduce checkpoint overhead", "B_clean_title": ["stream", "set", "state", "restor", "lazi", "avoid", "statecheckpoint", "state", "checkpoint", "issu", "reduc", "checkpoint", "overhead"]},
{"A_title": "LuceneIndexProviderService may miss on registering PreExtractedTextProviderLuceneIndexProviderService has an optional dependency on PreExtractedTextProvider. In such a case it can happen that bind for the provided is invoked before the activate is called. In such a case the provider would not be registered.", "A_clean_title": ["luceneindexproviderservic", "lucen", "index", "provid", "servic", "may", "miss", "regist", "preextractedtextproviderluceneindexproviderservic", "pre", "extract", "text", "provid", "lucen", "index", "provid", "servic", "ha", "option", "depend", "preextractedtextprovid", "pre", "extract", "text", "provid", "such", "case", "it", "happen", "that", "bind", "provid", "invok", "befor", "activ", "call", "such", "case", "provid", "would", "not", "regist"], "B_title": "- LuceneIndexProviderService may miss on registering PreExtractedTextProvider", "B_clean_title": ["luceneindexproviderservic", "lucen", "index", "provid", "servic", "may", "miss", "regist", "preextractedtextprovid", "pre", "extract", "text", "provid"]},
{"A_title": "lang DateUtils.truncate method is buggy when dealing with DST switching hoursTry to truncate 2004-10-31 01:00:00 MDT by hour and youll actually get 2004-10- 31 01:00:00 MST which is one hour after the input hour.     // truncate 2004-10-31 01:00:00 MDT     Date oct31_01MDT = new Date(1099206000000L);         Date result = DateUtils.truncate(oct31_01MDT Calendar.HOUR_OF_DAY);     assertEquals(oct31_01MDT result);", "A_clean_title": ["lang", "dateutil", "truncat", "date", "util", "method", "buggi", "when", "deal", "dst", "switch", "hourstri", "hour", "tri", "truncat", "2004", "10", "31", "01:00:00", "mdt", "by", "hour", "youll", "actual", "get", "2004", "10", "31", "01:00:00", "mst", "which", "one", "hour", "after", "input", "hour", "truncat", "2004", "10", "31", "01:00:00", "mdt", "date", "oct31", "01mdt", "new", "date", "1099206000000l", "date", "result", "dateutil", "truncat", "date", "util", "oct31", "01mdt", "calendar", "hour", "day", "assertequ", "assert", "equal", "oct31", "01mdt", "result"], "B_title": "Adding Nialls fix for LANG-59 - an edge case in date truncation - and his enhancement for the unit test that was there.", "B_clean_title": ["ad", "niall", "fix", "lang", "59", "edg", "case", "date", "truncat", "hi", "enhanc", "unit", "test", "that", "wa", "there"]},
{"A_title": "IResourceCachingStrategy implementations should only set caching if version matchesImplementations of IResourceCachingStrategy (FilenameWithVersionResourceCachingStrategy and QueryStringWithVersionResourceCachingStrategy) should only set cache duration to maximum if the version matches. Currently if a user requests a resource with an arbitrary version the version will be cached for one year (WebResponse.MAX_CACHE_DURATION). So people could polute proxy caches with potentially upcoming version.", "A_clean_title": ["iresourcecachingstrategi", "resourc", "cach", "strategi", "implement", "onli", "set", "cach", "version", "matchesimplement", "match", "implement", "iresourcecachingstrategi", "resourc", "cach", "strategi", "filenamewithversionresourcecachingstrategi", "filenam", "version", "resourc", "cach", "strategi", "querystringwithversionresourcecachingstrategi", "queri", "string", "version", "resourc", "cach", "strategi", "onli", "set", "cach", "durat", "maximum", "version", "match", "current", "user", "request", "resourc", "arbitrari", "version", "version", "will", "cach", "one", "year", "webrespons", "web", "respons", "max", "cach", "durat", "so", "peopl", "could", "polut", "proxi", "cach", "potenti", "upcom", "version"], "B_title": "IResourceCachingStrategy implementations should only set caching if version matches", "B_clean_title": ["iresourcecachingstrategi", "resourc", "cach", "strategi", "implement", "onli", "set", "cach", "version", "match"]},
{"A_title": "Uploading large number of files to single folder fails.Repository: OAK with TarPM  Upload is successful till 254 files and it started failing afterwards with exception in server logs.  1  code 14.11.2013 12:36:34.608 *ERROR* 10.40.146.206 1384412794576 POST /content/dam/cq9032/./Coconut-5mb-110.jpg HTTP/1.1 org.apache.sling.servlets.post.impl.operations.ModifyOperation Exception during response processing. java.lang.IllegalStateException: null at com.google.common.base.Preconditions.checkState(Preconditions.java:133) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeRecordId(SegmentWriter.java:259) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeListBucket(SegmentWriter.java:346) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeList(SegmentWriter.java:508) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeProperty(SegmentWriter.java:669) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:847) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter 3.childNodeChanged(SegmentWriter.java:806) ~na:na at org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:387) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:797) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter 3.childNodeChanged(SegmentWriter.java:806) ~na:na at org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:387) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:797) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter 3.childNodeChanged(SegmentWriter.java:806) ~na:na at org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:387) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:797) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentRootBuilder.getNodeState(SegmentRootBuilder.java:53) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentRootBuilder.getNodeState(SegmentRootBuilder.java:21) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.rebase(SegmentNodeStore.java:135) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.merge(SegmentNodeStore.java:113) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.merge(SegmentNodeStoreService.java:174) ~na:na at org.apache.jackrabbit.oak.core.AbstractRoot.commit(AbstractRoot.java:260) ~na:na at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.commit(SessionDelegate.java:224) ~na:na at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.commit(SessionDelegate.java:219) ~na:na at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.commit(SessionDelegate.java:207) ~na:na at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:332) ~na:na at org.apache.jackrabbit.oak.jcr.session.SessionImpl 8.perform(SessionImpl.java:399) ~na:na at org.apache.jackrabbit.oak.jcr.session.SessionImpl 8.perform(SessionImpl.java:396) ~na:na at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:128) ~na:na at org.apache.jackrabbit.oak.jcr.session.SessionImpl.perform(SessionImpl.java:117) ~na:na at org.apache.jackrabbit.oak.jcr.session.SessionImpl.save(SessionImpl.java:396) ~na:na at sun.reflect.GeneratedMethodAccessor18.invoke(Unknown Source) ~na:na at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~na:1.6.0_26 at java.lang.reflect.Method.invoke(Unknown Source) ~na:1.6.0_26 at org.apache.sling.jcr.base.SessionProxyHandler SessionProxyInvocationHandler.invoke(SessionProxyHandler.java:109) ~na:na at  Proxy9.save(Unknown Source) ~na:na code", "A_clean_title": ["upload", "larg", "number", "file", "singl", "folder", "fail", "repositori", "oak", "tarpm", "tar", "pm", "upload", "success", "till", "254", "file", "it", "start", "fail", "afterward", "except", "server", "log", "code", "14", "11", "2013", "12:36:34", "608", "error", "10", "40", "146", "206", "1384412794576", "post", "5mb", "110", "jpg", "content", "dam", "cq9032", "coconut", "http", "org", "apach", "sling", "servlet", "post", "impl", "oper", "modifyoper", "modifi", "oper", "except", "dure", "respons", "process", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "null", "at", "com", "googl", "common", "base", "precondit", "checkstat", "check", "state", "precondit", "java:133", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentwrit", "writerecordid", "segment", "writer", "write", "record", "id", "segmentwrit", "java:259", "segment", "writer", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentwrit", "writelistbucket", "segment", "writer", "write", "list", "bucket", "segmentwrit", "java:346", "segment", "writer", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentwrit", "writelist", "segment", "writer", "write", "list", "segmentwrit", "java:508", "segment", "writer", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentwrit", "writeproperti", "segment", "writer", "write", "properti", "segmentwrit", "java:669", "segment", "writer", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentwrit", "writenod", "segment", "writer", "write", "node", "segmentwrit", "java:847", "segment", "writer", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentwrit", "segment", "writer", "childnodechang", "child", "node", "chang", "segmentwrit", "java:806", "segment", "writer", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "modifiednodest", "compareagainstbasest", "modifi", "node", "state", "compar", "against", "base", "state", "modifiednodest", "java:387", "modifi", "node", "state", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentwrit", "writenod", "segment", "writer", "write", "node", "segmentwrit", "java:797", "segment", "writer", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentwrit", "segment", "writer", "childnodechang", "child", "node", "chang", "segmentwrit", "java:806", "segment", "writer", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "modifiednodest", "compareagainstbasest", "modifi", "node", "state", "compar", "against", "base", "state", "modifiednodest", "java:387", "modifi", "node", "state", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentwrit", "writenod", "segment", "writer", "write", "node", "segmentwrit", "java:797", "segment", "writer", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentwrit", "segment", "writer", "childnodechang", "child", "node", "chang", "segmentwrit", "java:806", "segment", "writer", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "modifiednodest", "compareagainstbasest", "modifi", "node", "state", "compar", "against", "base", "state", "modifiednodest", "java:387", "modifi", "node", "state", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentwrit", "writenod", "segment", "writer", "write", "node", "segmentwrit", "java:797", "segment", "writer", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentrootbuild", "getnodest", "segment", "root", "builder", "get", "node", "state", "segmentrootbuild", "java:53", "segment", "root", "builder", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentrootbuild", "getnodest", "segment", "root", "builder", "get", "node", "state", "segmentrootbuild", "java:21", "segment", "root", "builder", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodestor", "rebas", "segment", "node", "store", "segmentnodestor", "java:135", "segment", "node", "store", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodestor", "merg", "segment", "node", "store", "segmentnodestor", "java:113", "segment", "node", "store", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodestoreservic", "merg", "segment", "node", "store", "servic", "segmentnodestoreservic", "java:174", "segment", "node", "store", "servic", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "core", "abstractroot", "commit", "abstract", "root", "abstractroot", "java:260", "abstract", "root", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "commit", "session", "deleg", "sessiondeleg", "java:224", "session", "deleg", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "commit", "session", "deleg", "sessiondeleg", "java:219", "session", "deleg", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "commit", "session", "deleg", "sessiondeleg", "java:207", "session", "deleg", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:332", "session", "deleg", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "session", "impl", "perform", "sessionimpl", "java:399", "session", "impl", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "session", "impl", "perform", "sessionimpl", "java:396", "session", "impl", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "perform", "session", "deleg", "sessiondeleg", "java:128", "session", "deleg", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "perform", "session", "impl", "sessionimpl", "java:117", "session", "impl", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "save", "session", "impl", "sessionimpl", "java:396", "session", "impl", "~na", "na", "at", "sun", "reflect", "generatedmethodaccessor18", "invok", "gener", "method", "accessor18", "unknown", "sourc", "~na", "na", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "unknown", "sourc", "~na:1", "26", "at", "java", "lang", "reflect", "method", "invok", "unknown", "sourc", "~na:1", "26", "at", "org", "apach", "sling", "jcr", "base", "sessionproxyhandl", "session", "proxi", "handler", "sessionproxyinvocationhandl", "invok", "session", "proxi", "invoc", "handler", "sessionproxyhandl", "java:109", "session", "proxi", "handler", "~na", "na", "at", "proxy9", "save", "unknown", "sourc", "~na", "na", "code"], "B_title": "Uploading large number of files to single folder fails.", "B_clean_title": ["upload", "larg", "number", "file", "singl", "folder", "fail"]},
{"A_title": "Field boost not working if the property for indexing is picked using aggregate index rulesFor below index definition -  code       jcr:primaryType:oak:QueryIndexDefinition    compatVersion:2    type:lucene    async:async    reindex:false    reindexCount:12    aggregates:         jcr:primaryType:oak:Unstructured       app:Asset:            jcr:primaryType:oak:Unstructured          include0:               jcr:primaryType:oak:Unstructured             path:jcr:content/metadata/*                         indexRules:         jcr:primaryType:nt:unstructured       app:Asset:            jcr:primaryType:nt:unstructured          properties:               jcr:primaryType:nt:unstructured             foo:                  jcr:primaryType:nt:unstructured                nodeScopeIndex:true                ordered:true                propertyIndex:true                name:jcr:content/metadata/foo                type:Long                boost:3                nodeName:foo                                    code  On executing query of form -   code //element(* app:Asset)       jcr:contains(. bar )  code  should boost the results containing property - jcr:content/metadata/foo but its ignoring index time boosting for it.", "A_clean_title": ["field", "boost", "not", "work", "properti", "index", "pick", "aggreg", "index", "rulesfor", "rule", "below", "index", "definit", "code", "jcr", "primarytyp", "primari", "type", "oak", "queryindexdefinit", "queri", "index", "definit", "compatversion:2", "compat", "version:2", "type", "lucen", "async", "async", "reindex", "fals", "reindexcount:12", "reindex", "count:12", "aggreg", "jcr", "primarytyp", "primari", "type", "oak", "unstructur", "app", "asset", "jcr", "primarytyp", "primari", "type", "oak", "unstructur", "include0", "jcr", "primarytyp", "primari", "type", "oak", "unstructur", "path", "jcr", "content", "metadata", "indexrul", "index", "rule", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "app", "asset", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "properti", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "foo", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "nodescopeindex", "node", "scope", "index", "true", "order", "true", "propertyindex", "properti", "index", "true", "name", "jcr", "content", "metadata", "foo", "type", "long", "boost:3", "nodenam", "node", "name", "foo", "code", "execut", "queri", "form", "code", "element", "app", "asset", "jcr", "contain", "bar", "code", "boost", "result", "contain", "properti", "jcr", "content", "metadata", "foo", "but", "it", "ignor", "index", "time", "boost", "it"], "B_title": "- Field boost not working if the property for indexing is picked using aggregate index rules", "B_clean_title": ["field", "boost", "not", "work", "properti", "index", "pick", "aggreg", "index", "rule"]},
{"A_title": "org.apache.wicket.validation.ValidatorAdapter class causes problem with validator properties to be loadedPROBLEM: <e1nPL> hi I am having such problem:  <e1nPL> I have implemented validator by implementing IValidator<T> interface <e1nPL> and I have impelemnted the same validator by extending AbstractValidator<T> class  CODE:     ===================== VALIDATOR EXTENDED FROM AbstractValidator =====================     package com.mycompany;           import java.util.regex.Pattern;     import org.apache.wicket.IClusterable;     import org.apache.wicket.util.lang.Classes;     import org.apache.wicket.validation.IValidatable;     import org.apache.wicket.validation.IValidator;     import org.apache.wicket.validation.ValidationError;     import org.apache.wicket.validation.validator.AbstractValidator;           /**      *      * @author e1n      */     public class PasswordPolicyValidator<T> extends AbstractValidator<T>                private static final Pattern UPPER = Pattern.compile(A-Z);         private static final Pattern LOWER = Pattern.compile(a-z);         private static final Pattern NUMBER = Pattern.compile(0-9);                 @Override         public void onValidate(IValidatable<T> validatable)              final String password = (String)validatable.getValue();                         if (!NUMBER.matcher(password).find())                  error(validatable no-digit);                          if (!LOWER.matcher(password).find())                  error(validatable no-lower);                          if (!UPPER.matcher(password).find())                  error(validatable no-upper);                                             @Override         public void error(IValidatable<T> validatable String errorKey)              ValidationError err = new ValidationError();             err.addMessageKey(Classes.simpleName(getClass()) + . + errorKey);             validatable.error(err);                                       =============== VALIDATOR directly implementing IValidator interfce ====================     package com.mycompany;           import java.util.regex.Pattern;     import org.apache.wicket.IClusterable;     import org.apache.wicket.util.lang.Classes;     import org.apache.wicket.validation.IValidatable;     import org.apache.wicket.validation.IValidator;     import org.apache.wicket.validation.ValidationError;     import org.apache.wicket.validation.validator.AbstractValidator;           /**      *      * @author e1n      */     public class PasswordPolicyValidator<T> implements IValidator<T>                private static final Pattern UPPER = Pattern.compile(A-Z);         private static final Pattern LOWER = Pattern.compile(a-z);         private static final Pattern NUMBER = Pattern.compile(0-9);               public void validate(IValidatable<T> validatable)              final String password = (String)validatable.getValue();                         if (!NUMBER.matcher(password).find())                  error(validatable no-digit);                          if (!LOWER.matcher(password).find())                  error(validatable no-lower);                          if (!UPPER.matcher(password).find())                  error(validatable no-upper);                                             public void error(IValidatable<T> validatable String errorKey)              ValidationError err = new ValidationError();             err.addMessageKey(Classes.simpleName(getClass()) + . + errorKey);             validatable.error(err);                          <e1nPL> I also have properties file which is named after validator class <e1nPL> and placed in the same package <e1nPL> my problem is that when i use to validate my form field validator which implements IValidator interface it is not capable of loading error messages from properties file <e1nPL> but when i am using validator which is extending AbstractValidator class <e1nPL> properties file with error msgs gets loaded POSSIBLE FIX: <e1nPL> ok i have found class which is responsible for my problem and it is probably a bug <e1nPL> org.apache.wicket.validation.ValidatorAdapter <e1nPL> which wraps classes that directly implements IValidator interface <e1nPL> then when resources are loaded and properties file are searched in class path etc. loaders search in wrong path that is build against org.apache.wicket.validation.ValidatorAdapter  PLACE WHER FIX SHOULD OCCOUR org.apache.wicket.resource.loader.ValidatorStringResourceLoader::loadStringResource(java.lang.Classjava.lang.Stringjava.util.Localejava.lang.Stringjava.lang.String)", "A_clean_title": ["org", "apach", "wicket", "valid", "validatoradapt", "valid", "adapt", "class", "caus", "problem", "valid", "properti", "loadedproblem", "load", "problem", "e1npl", "e1n", "pl", "hi", "am", "have", "such", "problem", "e1npl", "e1n", "pl", "have", "implement", "valid", "by", "implement", "ivalid", "valid", "interfac", "e1npl", "e1n", "pl", "have", "impelemnt", "same", "valid", "by", "extend", "abstractvalid", "abstract", "valid", "class", "code", "valid", "extend", "abstractvalid", "abstract", "valid", "packag", "com", "mycompani", "import", "java", "util", "regex", "pattern", "import", "org", "apach", "wicket", "icluster", "cluster", "import", "org", "apach", "wicket", "util", "lang", "class", "import", "org", "apach", "wicket", "valid", "ivalidat", "validat", "import", "org", "apach", "wicket", "valid", "ivalid", "valid", "import", "org", "apach", "wicket", "valid", "validationerror", "valid", "error", "import", "org", "apach", "wicket", "valid", "valid", "abstractvalid", "abstract", "valid", "author", "e1n", "public", "class", "passwordpolicyvalid", "password", "polici", "valid", "extend", "abstractvalid", "abstract", "valid", "privat", "static", "final", "pattern", "upper", "pattern", "compil", "privat", "static", "final", "pattern", "lower", "pattern", "compil", "privat", "static", "final", "pattern", "number", "pattern", "compil", "overrid", "public", "void", "onvalid", "valid", "ivalidat", "validat", "validat", "final", "string", "password", "string", "validat", "getvalu", "get", "valu", "number", "matcher", "password", "find", "error", "validat", "no", "digit", "lower", "matcher", "password", "find", "error", "validat", "no", "lower", "upper", "matcher", "password", "find", "error", "validat", "no", "upper", "overrid", "public", "void", "error", "ivalidat", "validat", "validat", "string", "errorkey", "error", "key", "validationerror", "valid", "error", "err", "new", "validationerror", "valid", "error", "err", "addmessagekey", "add", "messag", "key", "class", "simplenam", "simpl", "name", "getclass", "get", "class", "errorkey", "error", "key", "validat", "error", "err", "valid", "directli", "implement", "ivalid", "valid", "interfc", "packag", "com", "mycompani", "import", "java", "util", "regex", "pattern", "import", "org", "apach", "wicket", "icluster", "cluster", "import", "org", "apach", "wicket", "util", "lang", "class", "import", "org", "apach", "wicket", "valid", "ivalidat", "validat", "import", "org", "apach", "wicket", "valid", "ivalid", "valid", "import", "org", "apach", "wicket", "valid", "validationerror", "valid", "error", "import", "org", "apach", "wicket", "valid", "valid", "abstractvalid", "abstract", "valid", "author", "e1n", "public", "class", "passwordpolicyvalid", "password", "polici", "valid", "implement", "ivalid", "valid", "privat", "static", "final", "pattern", "upper", "pattern", "compil", "privat", "static", "final", "pattern", "lower", "pattern", "compil", "privat", "static", "final", "pattern", "number", "pattern", "compil", "public", "void", "valid", "ivalidat", "validat", "validat", "final", "string", "password", "string", "validat", "getvalu", "get", "valu", "number", "matcher", "password", "find", "error", "validat", "no", "digit", "lower", "matcher", "password", "find", "error", "validat", "no", "lower", "upper", "matcher", "password", "find", "error", "validat", "no", "upper", "public", "void", "error", "ivalidat", "validat", "validat", "string", "errorkey", "error", "key", "validationerror", "valid", "error", "err", "new", "validationerror", "valid", "error", "err", "addmessagekey", "add", "messag", "key", "class", "simplenam", "simpl", "name", "getclass", "get", "class", "errorkey", "error", "key", "validat", "error", "err", "e1npl", "e1n", "pl", "also", "have", "properti", "file", "which", "name", "after", "valid", "class", "e1npl", "e1n", "pl", "place", "same", "packag", "e1npl", "e1n", "pl", "my", "problem", "that", "when", "use", "valid", "my", "form", "field", "valid", "which", "implement", "ivalid", "valid", "interfac", "it", "not", "capabl", "load", "error", "messag", "properti", "file", "e1npl", "e1n", "pl", "but", "when", "am", "valid", "which", "extend", "abstractvalid", "abstract", "valid", "class", "e1npl", "e1n", "pl", "properti", "file", "error", "msg", "get", "load", "possibl", "fix", "e1npl", "e1n", "pl", "ok", "have", "found", "class", "which", "respons", "my", "problem", "it", "probabl", "bug", "e1npl", "e1n", "pl", "org", "apach", "wicket", "valid", "validatoradapt", "valid", "adapt", "e1npl", "e1n", "pl", "which", "wrap", "class", "that", "directli", "implement", "ivalid", "valid", "interfac", "e1npl", "e1n", "pl", "then", "when", "resourc", "are", "load", "properti", "file", "are", "search", "class", "path", "etc", "loader", "search", "wrong", "path", "that", "build", "against", "org", "apach", "wicket", "valid", "validatoradapt", "valid", "adapt", "place", "wher", "fix", "occour", "org", "apach", "wicket", "resourc", "loader", "validatorstringresourceload", "valid", "string", "resourc", "loader", ":loadstringresourc", ":load", "string", "resourc", "java", "lang", "classjava", "lang", "stringjava", "util", "localejava", "lang", "stringjava", "lang", "string"], "B_title": "org.apache.wicket.validation.ValidatorAdapter class causes problem with validator properties to be loaded", "B_clean_title": ["org", "apach", "wicket", "valid", "validatoradapt", "valid", "adapt", "class", "caus", "problem", "valid", "properti", "load"]},
{"A_title": "AjaxEventBehavior#onEvent is invoked on disabled behaviorSecurity bug  AjaxEventBehavior#onEvent is invoked on disabled behavior. It should not be - it is really dangerous can you fix it.  I think it is security bug.", "A_clean_title": ["ajaxeventbehavior", "ajax", "event", "behavior", "onev", "event", "invok", "disabl", "behaviorsecur", "behavior", "secur", "bug", "ajaxeventbehavior", "ajax", "event", "behavior", "onev", "event", "invok", "disabl", "behavior", "it", "not", "it", "realli", "danger", "you", "fix", "it", "think", "it", "secur", "bug"], "B_title": "Issue: WICKET-3098", "B_clean_title": ["issu", "wicket", "3098"]},
{"A_title": "CreditCardValidator returns incorrect cardId for VISAWhen the validation for a VISA is correct it returns a SWITCH cardId instead of a VISA. This error occurs in both 1.4.x and 1.5.X", "A_clean_title": ["creditcardvalid", "credit", "card", "valid", "return", "incorrect", "cardid", "card", "id", "visawhen", "visa", "when", "valid", "visa", "correct", "it", "return", "switch", "cardid", "card", "id", "instead", "visa", "thi", "error", "occur", "both"], "B_title": "CreditCardValidator returns incorrect cardId for VISA", "B_clean_title": ["creditcardvalid", "credit", "card", "valid", "return", "incorrect", "cardid", "card", "id", "visa"]},
{"A_title": "DocumentNodeStore.diffManyChildren() reads too many nodesDocumentNodeStore.diffManyChildren() compares too many nodes when running in a non-clustered setup and there are many changes below a location with many children.  This is a regression introduced by OAK-2232. The fix changed the way how the minimum revision is calculated based on the two revisions to compare. The seen-at revision of the RevisionComparator is taken into account. However in a single cluster node setup the revision range for the current clusterId is never updated. This means the minimum revision is calculated too far back and causes queries with too many nodes than necessary.", "A_clean_title": ["documentnodestor", "diffmanychildren", "document", "node", "store", "diff", "mani", "children", "read", "too", "mani", "nodesdocumentnodestor", "diffmanychildren", "node", "document", "node", "store", "diff", "mani", "children", "compar", "too", "mani", "node", "when", "run", "non", "cluster", "setup", "there", "are", "mani", "chang", "below", "locat", "mani", "children", "thi", "regress", "introduc", "by", "oak", "2232", "fix", "chang", "way", "how", "minimum", "revis", "calcul", "base", "two", "revis", "compar", "seen", "at", "revis", "revisioncompar", "revis", "compar", "taken", "into", "account", "howev", "singl", "cluster", "node", "setup", "revis", "rang", "current", "clusterid", "cluster", "id", "never", "updat", "thi", "mean", "minimum", "revis", "calcul", "too", "far", "back", "caus", "queri", "too", "mani", "node", "than", "necessari"], "B_title": "DocumentNodeStore.diffManyChildren() reads too many nodes", "B_clean_title": ["documentnodestor", "diffmanychildren", "document", "node", "store", "diff", "mani", "children", "read", "too", "mani", "node"]},
{"A_title": "NodeStoreKernel doesnt handle array properties correctlyNodeStoreKernel currently only supports array properties of type long. For other types it will fail with an IllegalStateException. See also the FIXME in the code.", "A_clean_title": ["nodestorekernel", "node", "store", "kernel", "doesnt", "handl", "array", "properti", "correctlynodestorekernel", "correctli", "node", "store", "kernel", "current", "onli", "support", "array", "properti", "type", "long", "other", "type", "it", "will", "fail", "illegalstateexcept", "illeg", "state", "except", "see", "also", "fixm", "code"], "B_title": "NodeStoreKernel doesnt handle array properties correctly", "B_clean_title": ["nodestorekernel", "node", "store", "kernel", "doesnt", "handl", "array", "properti", "correctli"]},
{"A_title": "EigenDecomposition may not converge for certain matricesJama-1.0.3 contains a bugfix for certain matrices where the original code goes into an infinite loop.  The commons-math translations would throw a MaxCountExceededException so fails to compute the eigen decomposition.  Port the fix from jama to CM.", "A_clean_title": ["eigendecomposit", "eigen", "decomposit", "may", "not", "converg", "certain", "matricesjama", "matric", "jama", "contain", "bugfix", "certain", "matric", "where", "origin", "code", "goe", "into", "infinit", "loop", "common", "math", "translat", "would", "throw", "maxcountexceededexcept", "max", "count", "exceed", "except", "so", "fail", "comput", "eigen", "decomposit", "port", "fix", "jama", "cm"], "B_title": "Fix EigenDecomposition for certain non-symmetric matrices.", "B_clean_title": ["fix", "eigendecomposit", "eigen", "decomposit", "certain", "non", "symmetr", "matric"]},
{"A_title": "DiskDataStore returns the wrong page when the page disk space is fullIf the configured file size for the session data is overflowed (see org.apache.wicket.settings.IStoreSettings#setMaxSizePerSession(Bytes)) then Wicket may return wrong page data (bytes) for a expired page.  The problem is in org.apache.wicket.pageStore.PageWindowManager#idToWindowIndex which may have several page ids (the keys) pointing to the same window index (values).", "A_clean_title": ["diskdatastor", "disk", "data", "store", "return", "wrong", "page", "when", "page", "disk", "space", "fullif", "full", "configur", "file", "size", "session", "data", "overflow", "see", "org", "apach", "wicket", "set", "istoreset", "store", "set", "setmaxsizepersess", "set", "max", "size", "per", "session", "byte", "then", "wicket", "may", "return", "wrong", "page", "data", "byte", "expir", "page", "problem", "org", "apach", "wicket", "pagestor", "pagewindowmanag", "page", "store", "page", "window", "manag", "idtowindowindex", "id", "window", "index", "which", "may", "have", "sever", "page", "id", "key", "point", "same", "window", "index", "valu"], "B_title": "DiskDataStore returns the wrong page when the page disk space is full", "B_clean_title": ["diskdatastor", "disk", "data", "store", "return", "wrong", "page", "when", "page", "disk", "space", "full"]},
{"A_title": "Long overflow in PermissionEntryProviderImplPermissionEntryProviderImpl#init can end up in a Long overflow if the underlying implementation does not know the exact value of the number children and the child node count is higher than maxSize.  I will attach a patch with a test case", "A_clean_title": ["long", "overflow", "permissionentryproviderimplpermissionentryproviderimpl", "permiss", "entri", "provid", "impl", "permiss", "entri", "provid", "impl", "init", "end", "up", "long", "overflow", "underli", "implement", "not", "know", "exact", "valu", "number", "children", "child", "node", "count", "higher", "than", "maxsiz", "max", "size", "will", "attach", "patch", "test", "case"], "B_title": ": Long overflow in PermissionEntryProviderImpl", "B_clean_title": ["long", "overflow", "permissionentryproviderimpl", "permiss", "entri", "provid", "impl"]},
{"A_title": "Bugs in Frequency APII think the existing Frequency API has some bugs in it. The addValue(Object v) method allows one to add a plain Object but one cannot add anything further to the instance as the second add fails with IllegalArgumentException. In fact the problem is with the first call to addValue(Object) which should not allow a plain Object to be added - it should only allow Comparable objects. This could be fixed by checking that the object is Comparable. Similar considerations apply to the getCumFreq(Object) and getCumPct(Object) methods - they will only work with objects that implement Comparable. The getCount(Object) and getPct(Object) methods dont fail when given a non-Comparable object (because the class cast exception is caught) however they just return 0 as if the object was not present:          final Object OBJ = new Object();         f.addValue(OBJ); // This ought to fail but doesnt causing the unexpected behaviour below         System.out.println(f.getCount(OBJ)); // 0         System.out.println(f.getPct(OBJ)); // 0.0   Rather than adding extra checks for Comparable it seems to me that the API would be much improved by using Comparable instead of Object. Also it should make it easier to implement generics. However this would cause compilation failures for some programs that pass Object rather than Comparable to the class. These would need recoding but I think they would continue to run OK against the new API. It would also affect the run-time behaviour slightly as the first attempt to add a non-Comparable object would fail rather than the second add of a possibly valid object. But is that a viable program? It can only add one object and any attempt to get statistics will either return 0 or an Exception and applying the instanceof fix would also cause it to fail.", "A_clean_title": ["bug", "frequenc", "apii", "think", "exist", "frequenc", "api", "ha", "some", "bug", "it", "addvalu", "add", "valu", "object", "method", "allow", "one", "add", "plain", "object", "but", "one", "not", "add", "anyth", "further", "instanc", "as", "second", "add", "fail", "illegalargumentexcept", "illeg", "argument", "except", "fact", "problem", "first", "call", "addvalu", "add", "valu", "object", "which", "not", "allow", "plain", "object", "ad", "it", "onli", "allow", "compar", "object", "thi", "could", "fix", "by", "check", "that", "object", "compar", "similar", "consider", "appli", "getcumfreq", "get", "cum", "freq", "object", "getcumpct", "get", "cum", "pct", "object", "method", "they", "will", "onli", "work", "object", "that", "implement", "compar", "getcount", "get", "count", "object", "getpct", "get", "pct", "object", "method", "dont", "fail", "when", "given", "non", "compar", "object", "becaus", "class", "cast", "except", "caught", "howev", "they", "just", "return", "as", "object", "wa", "not", "present", "final", "object", "obj", "new", "object", "addvalu", "add", "valu", "obj", "thi", "ought", "fail", "but", "doesnt", "caus", "unexpect", "behaviour", "below", "system", "out", "println", "getcount", "get", "count", "obj", "system", "out", "println", "getpct", "get", "pct", "obj", "rather", "than", "ad", "extra", "check", "compar", "it", "seem", "me", "that", "api", "would", "much", "improv", "by", "compar", "instead", "object", "also", "it", "make", "it", "easier", "implement", "gener", "howev", "thi", "would", "caus", "compil", "failur", "some", "program", "that", "pass", "object", "rather", "than", "compar", "class", "these", "would", "need", "recod", "but", "think", "they", "would", "continu", "run", "ok", "against", "new", "api", "it", "would", "also", "affect", "run", "time", "behaviour", "slightli", "as", "first", "attempt", "add", "non", "compar", "object", "would", "fail", "rather", "than", "second", "add", "possibl", "valid", "object", "but", "that", "viabl", "program", "it", "onli", "add", "one", "object", "ani", "attempt", "get", "statist", "will", "either", "return", "or", "except", "appli", "instanceof", "fix", "would", "also", "caus", "it", "fail"], "B_title": "- check for Comparable when adding values", "B_clean_title": ["check", "compar", "when", "ad", "valu"]},
{"A_title": "Ordered index fails with old index contentWith the latest changes the ordered index no longer works with old index data. When running the latest Oak 1.0.2 snapshot run against an Oak 1.0.0 repository with an existing ordered index the index fails with the exception below.  As a workaround the ordered index can be manually re-built. Either the index re-build needs to be automatic or the ordered index needs to work with the old index content.  noformat java.lang.IndexOutOfBoundsException: index (3) must be less than size (1)     at com.google.common.base.Preconditions.checkElementIndex(Preconditions.java:306)     at com.google.common.base.Preconditions.checkElementIndex(Preconditions.java:285)     at org.apache.jackrabbit.oak.plugins.segment.SegmentPropertyState.getValue(SegmentPropertyState.java:157)     at org.apache.jackrabbit.oak.plugins.index.property.strategy.OrderedContentMirrorStoreStrategy.getPropertyNext(OrderedContentMirrorStoreStrategy.java:1024) noformat", "A_clean_title": ["order", "index", "fail", "old", "index", "contentwith", "content", "latest", "chang", "order", "index", "no", "longer", "work", "old", "index", "data", "when", "run", "latest", "oak", "snapshot", "run", "against", "oak", "repositori", "exist", "order", "index", "index", "fail", "except", "below", "as", "workaround", "order", "index", "manual", "re", "built", "either", "index", "re", "build", "need", "automat", "or", "order", "index", "need", "work", "old", "index", "content", "noformat", "java", "lang", "indexoutofboundsexcept", "index", "out", "bound", "except", "index", "must", "less", "than", "size", "at", "com", "googl", "common", "base", "precondit", "checkelementindex", "check", "element", "index", "precondit", "java:306", "at", "com", "googl", "common", "base", "precondit", "checkelementindex", "check", "element", "index", "precondit", "java:285", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentpropertyst", "getvalu", "segment", "properti", "state", "get", "valu", "segmentpropertyst", "java:157", "segment", "properti", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "properti", "strategi", "orderedcontentmirrorstorestrategi", "getpropertynext", "order", "content", "mirror", "store", "strategi", "get", "properti", "next", "orderedcontentmirrorstorestrategi", "java:1024", "order", "content", "mirror", "store", "strategi", "noformat"], "B_title": "Ordered index fails with old index content", "B_clean_title": ["order", "index", "fail", "old", "index", "content"]},
{"A_title": "NullPointerException in isAvailableLocale(Locale)FindBugs pointed out:    UwF: Field not initialized in constructor: org.apache.commons.lang.LocaleUtils.cAvailableLocaleSet cAvailableSet is used directly once in the source - and if availableLocaleSet() hasnt been called it will cause a NullPointerException.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "isavailablelocal", "avail", "local", "local", "findbug", "find", "bug", "point", "out", "uwf", "uw", "field", "not", "initi", "constructor", "org", "apach", "common", "lang", "localeutil", "cavailablelocaleset", "local", "util", "avail", "local", "set", "cavailableset", "avail", "set", "use", "directli", "onc", "sourc", "availablelocaleset", "avail", "local", "set", "hasnt", "been", "call", "it", "will", "caus", "nullpointerexcept", "null", "pointer", "except"], "B_title": "Applying test for LANG-304 and fix to LocaleUtils", "B_clean_title": ["appli", "test", "lang", "304", "fix", "localeutil", "local", "util"]},
{"A_title": "Ignore files in the root directory of the FileDataStore in #getAllIdentifiersThe call to OakFileDataStore#getAllIdentifiers should ignore the the files directly at the root of the DataStore (These files are used for SharedDataStore etc). This does not cause any functional problems but leads to logging warning in the logs.  There is already a check but it fails when the data store root is specified as a relative path.", "A_clean_title": ["ignor", "file", "root", "directori", "filedatastor", "file", "data", "store", "getallidentifiersth", "get", "all", "identifi", "call", "oakfiledatastor", "oak", "file", "data", "store", "getallidentifi", "get", "all", "identifi", "ignor", "file", "directli", "at", "root", "datastor", "data", "store", "these", "file", "are", "use", "shareddatastor", "share", "data", "store", "etc", "thi", "not", "caus", "ani", "function", "problem", "but", "lead", "log", "warn", "log", "there", "alreadi", "check", "but", "it", "fail", "when", "data", "store", "root", "specifi", "as", "rel", "path"], "B_title": "Ignore files in the root directory of the FileDataStore in #getAllIdentifiers", "B_clean_title": ["ignor", "file", "root", "directori", "filedatastor", "file", "data", "store", "getallidentifi", "get", "all", "identifi"]},
{"A_title": "Node name having non space whitspace chars should not be allowedDue to the changes done in OAK-1174 node with non space whitespace chars like n r etc can be created. This is not desirable and also JR2 does not allow such node to be created so check must be added to prevent such a name from getting created.  As discussed in 1 this is regression due to usage of incorrect utility method as part of 2 the fix can be simply using a Character#isWhitespace instead of Character#isSpaceChar  1 http://mail-archives.apache.org/mod_mbox/jackrabbit-oak-dev/201509.mbox/%3CCAHCW-mkkGtxkn%2B9xfXuvMTfgykewjMPsLwrVH%2B00%2BXaBQjA0sg%40mail.gmail.com%3E 2 https://github.com/apache/jackrabbit-oak/commit/342809f7f04221782ca6bbfbde9392ec4ff441c2", "A_clean_title": ["node", "name", "have", "non", "space", "whitspac", "char", "not", "alloweddu", "allow", "due", "chang", "done", "oak", "1174", "node", "non", "space", "whitespac", "char", "like", "etc", "creat", "thi", "not", "desir", "also", "jr2", "not", "allow", "such", "node", "creat", "so", "check", "must", "ad", "prevent", "such", "name", "get", "creat", "as", "discuss", "thi", "regress", "due", "usag", "incorrect", "util", "method", "as", "part", "fix", "simpli", "charact", "iswhitespac", "whitespac", "instead", "charact", "isspacechar", "space", "char", "http", "oak", "mail", "archiv", "apach", "dev", "201509", "mbox", "org", "mod", "mbox", "jackrabbit", "3ccahcw", "mkkgtxkn", "mkk", "gtxkn", "2b9xfxuvmtfgykewjmpslwrvh", "2b9xf", "xuv", "tfgykewj", "ps", "lwr", "vh", "2b00", "2bxabqja0sg", "2b", "xa", "qj", "a0sg", "40mail", "gmail", "com", "3e", "http", "oak", "commit", "342809f7f04221782ca6bbfbde9392ec4ff441c2", "github", "com", "apach", "jackrabbit"], "B_title": "- Node name having non space whitspace chars should not be allowed", "B_clean_title": ["node", "name", "have", "non", "space", "whitspac", "char", "not", "allow"]},
{"A_title": "DateTimeSerializerBase ignores configured date format when creating contextualDateTimeSerializerBase#createContextual creates a new serializer with StdDateFormat.DATE_FORMAT_STR_ISO8601 format instead of re-using the actual format that may have been specified on the configuration. See the following code:  Using the  @JsonFormat annotation on a field will therefore reset the format to Jacksons default even if the annotation doesnt specify any custom format.  DateBasedDeserializer#createContextual behaves differently and tries to re-use the configured format:  Shouldnt the serializer follow the same approach ?", "A_clean_title": ["datetimeserializerbas", "date", "time", "serial", "base", "ignor", "configur", "date", "format", "when", "creat", "contextualdatetimeserializerbas", "contextu", "date", "time", "serial", "base", "createcontextu", "creat", "contextu", "creat", "new", "serial", "stddateformat", "std", "date", "format", "date", "format", "str", "iso8601", "format", "instead", "re", "actual", "format", "that", "may", "have", "been", "specifi", "configur", "see", "follow", "code", "jsonformat", "json", "format", "annot", "field", "will", "therefor", "reset", "format", "jackson", "default", "even", "annot", "doesnt", "specifi", "ani", "custom", "format", "datebaseddeseri", "date", "base", "deseri", "createcontextu", "creat", "contextu", "behav", "differ", "tri", "re", "use", "configur", "format", "shouldnt", "serial", "follow", "same", "approach"], "B_title": "Fix #1648", "B_clean_title": ["fix", "1648"]},
{"A_title": "Fraction specified with maxDenominator and a value very close to a simple fraction should not throw an overflow exceptionAn overflow exception is thrown when a Fraction is initialized with a maxDenominator from a double that is very close to a simple fraction.  For example: double d = 0.5000000001; Fraction f = new Fraction(d 10); Patch with unit test on way.", "A_clean_title": ["fraction", "specifi", "maxdenomin", "max", "denomin", "valu", "veri", "close", "simpl", "fraction", "not", "throw", "overflow", "exceptionan", "except", "overflow", "except", "thrown", "when", "fraction", "initi", "maxdenomin", "max", "denomin", "doubl", "that", "veri", "close", "simpl", "fraction", "exampl", "doubl", "5000000001", "fraction", "new", "fraction", "10", "patch", "unit", "test", "way"], "B_title": "Fix creation of Fraction/BigFraction objects in maxDenominator mode when the value is close to an actual fraction.", "B_clean_title": ["fix", "creation", "fraction", "bigfract", "big", "fraction", "object", "maxdenomin", "max", "denomin", "mode", "when", "valu", "close", "actual", "fraction"]},
{"A_title": "better this type checkingNone", "A_clean_title": ["better", "thi", "type", "checkingnon", "check", "none"], "B_title": "Fix parts of issue 635 mostly by deleting hacks that are now obsolete", "B_clean_title": ["fix", "part", "issu", "635", "mostli", "by", "delet", "hack", "that", "are", "now", "obsolet"]},
{"A_title": "PhraseQuery fails due to missing posiion info in indexed fieldsFollowing OAK-1487 Ive introduced a regression in the indexing of fields on the Lucene index. There are some types of queries (the ones that use property restrictions) that cannot run anymore.  bq. /jcr:root/content/dam//*jcr:contains(jcr:content/metadata/@dc:format application/pdf)   bq. Caused by: java.lang.IllegalStateException: field dc:format was indexed without position data; cannot run PhraseQuery (term=text)  I could not reproduce this in an unit test so far.", "A_clean_title": ["phrasequeri", "phrase", "queri", "fail", "due", "miss", "posiion", "info", "index", "fieldsfollow", "field", "follow", "oak", "1487", "ive", "introduc", "regress", "index", "field", "lucen", "index", "there", "are", "some", "type", "queri", "one", "that", "use", "properti", "restrict", "that", "not", "run", "anymor", "bq", "jcr", "root", "content", "dam", "jcr", "contain", "jcr", "content", "metadata", "dc", "format", "applic", "pdf", "bq", "caus", "by", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "field", "dc", "format", "wa", "index", "without", "posit", "data", "not", "run", "phrasequeri", "phrase", "queri", "term=text", "could", "not", "reproduc", "thi", "unit", "test", "so", "far"], "B_title": "PhraseQuery fails due to missing posiion info in indexed fields", "B_clean_title": ["phrasequeri", "phrase", "queri", "fail", "due", "miss", "posiion", "info", "index", "field"]},
{"A_title": "Ajax link reports weird error when session is expiredReproducing steps:  1. Put below simple page into a Wicket application and get it mounted:  TestPage.java:  import org.apache.wicket.ajax.AjaxRequestTarget; import org.apache.wicket.ajax.markup.html.AjaxLink; import org.apache.wicket.markup.html.WebPage;  @SuppressWarnings(serial) public class TestPage extends WebPage   public TestPage()   add(new AjaxLink<Void>(test)   @Override public void onClick(AjaxRequestTarget target)    );      TestPage.html:  <!DOCTYPE html PUBLIC -//W3C//DTD XHTML 1.0 Strict//EN http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd> <?xml version=1.0 encoding=UTF-8?> <html xmlns=http://www.w3.org/1999/xhtml> <head> <title>Test Page</title> </head> <body> <a wicket:id=test>test</a> </body> </html>  2. Access the page in browser via mounted url the page will display a link.   3. Wait until current session is expired (do not refresh the page or click the link while waiting).   4. Hit the link and below exception will be thrown: Message: Cannot find behavior with id: 0 on component:  Component id = test. Perhaps the behavior did not properly implement getStatelessHint() and returned true to indicate that it is stateless instead of returning false to indicate that it is stateful.  5. In wicket 1.5.0 this results in a PageExpiredException which is more comprehensive.", "A_clean_title": ["ajax", "link", "report", "weird", "error", "when", "session", "expiredreproduc", "expir", "reproduc", "step", "put", "below", "simpl", "page", "into", "wicket", "applic", "get", "it", "mount", "testpag", "java", "test", "page", "import", "org", "apach", "wicket", "ajax", "ajaxrequesttarget", "ajax", "request", "target", "import", "org", "apach", "wicket", "ajax", "markup", "html", "ajaxlink", "ajax", "link", "import", "org", "apach", "wicket", "markup", "html", "webpag", "web", "page", "suppresswarn", "suppress", "warn", "serial", "public", "class", "testpag", "test", "page", "extend", "webpag", "web", "page", "public", "testpag", "test", "page", "add", "new", "ajaxlink", "ajax", "link", "void", "test", "overrid", "public", "void", "onclick", "click", "ajaxrequesttarget", "ajax", "request", "target", "target", "testpag", "html", "test", "page", "doctyp", "html", "public", "w3c", "dtd", "xhtml", "strict", "en", "http", "w3", "strict", "dtd", "www", "org", "tr", "xhtml1", "dtd", "xhtml1", "xml", "version=1", "encoding=utf", "html", "xmlns=http", "w3", "www", "org", "1999", "xhtml", "head", "titl", "test", "page", "titl", "head", "bodi", "wicket", "id=test", "test", "bodi", "html", "access", "page", "browser", "via", "mount", "url", "page", "will", "display", "link", "wait", "until", "current", "session", "expir", "not", "refresh", "page", "or", "click", "link", "while", "wait", "hit", "link", "below", "except", "will", "thrown", "messag", "not", "find", "behavior", "id", "compon", "compon", "id", "test", "perhap", "behavior", "did", "not", "properli", "implement", "getstatelesshint", "get", "stateless", "hint", "return", "true", "indic", "that", "it", "stateless", "instead", "return", "fals", "indic", "that", "it", "state", "wicket", "thi", "result", "pageexpiredexcept", "page", "expir", "except", "which", "more", "comprehens"], "B_title": "Ajax link reports wield error when session is expired", "B_clean_title": ["ajax", "link", "report", "wield", "error", "when", "session", "expir"]},
{"A_title": "kryo serialization problemPerforming a cross of two dataset of POJOs I have got the exception below. The first time I run the process there was no problem. When I run it the second time I have got the exception. My guess is that it could be a race condition related to the reuse of the Kryo serializer object. However it could also be a bug where type registrations are not properly forwarded to all Serializers as suggested by Stephan.  ------------------------------------------------------------------------ 2015-10-01 18:18:21 INFO  JobClient:161 - 10/01/2015 18:18:21Cross(Cross at main(FlinkMongoHadoop2LinkPOI2CDA.java:160))(3/4) switched to FAILED  com.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 114 at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:119) at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:641) at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:752) at org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.deserialize(KryoSerializer.java:210) at org.apache.flink.api.java.typeutils.runtime.TupleSerializer.deserialize(TupleSerializer.java:127) at org.apache.flink.api.java.typeutils.runtime.TupleSerializer.deserialize(TupleSerializer.java:30) at org.apache.flink.runtime.operators.resettable.AbstractBlockResettableIterator.getNextRecord(AbstractBlockResettableIterator.java:180) at org.apache.flink.runtime.operators.resettable.BlockResettableMutableObjectIterator.next(BlockResettableMutableObjectIterator.java:111) at org.apache.flink.runtime.operators.CrossDriver.runBlockedOuterSecond(CrossDriver.java:309) at org.apache.flink.runtime.operators.CrossDriver.run(CrossDriver.java:162) at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:489) at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:354) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:581) at java.lang.Thread.run(Thread.java:745)", "A_clean_title": ["kryo", "serial", "problemperform", "problem", "perform", "cross", "two", "dataset", "pojo", "poj", "os", "have", "got", "except", "below", "first", "time", "run", "process", "there", "wa", "no", "problem", "when", "run", "it", "second", "time", "have", "got", "except", "my", "guess", "that", "it", "could", "race", "condit", "relat", "reus", "kryo", "serial", "object", "howev", "it", "could", "also", "bug", "where", "type", "registr", "are", "not", "properli", "forward", "all", "serial", "as", "suggest", "by", "stephan", "2015", "10", "01", "18:18:21", "info", "jobclient:161", "job", "client:161", "10", "01", "2015", "18:18:21", "cross", "cross", "at", "main", "flinkmongohadoop2linkpoi2cda", "java:160", "flink", "mongo", "hadoop2link", "poi2cda", "switch", "fail", "com", "esotericsoftwar", "kryo", "kryoexcept", "kryo", "except", "encount", "unregist", "class", "id", "114", "at", "com", "esotericsoftwar", "kryo", "util", "defaultclassresolv", "readclass", "default", "class", "resolv", "read", "class", "defaultclassresolv", "java:119", "default", "class", "resolv", "at", "com", "esotericsoftwar", "kryo", "kryo", "readclass", "read", "class", "kryo", "java:641", "at", "com", "esotericsoftwar", "kryo", "kryo", "readclassandobject", "read", "class", "object", "kryo", "java:752", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "kryo", "kryoseri", "deseri", "kryo", "serial", "kryoseri", "java:210", "kryo", "serial", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "tupleseri", "deseri", "tupl", "serial", "tupleseri", "java:127", "tupl", "serial", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "tupleseri", "deseri", "tupl", "serial", "tupleseri", "java:30", "tupl", "serial", "at", "org", "apach", "flink", "runtim", "oper", "resett", "abstractblockresettableiter", "getnextrecord", "abstract", "block", "resett", "iter", "get", "next", "record", "abstractblockresettableiter", "java:180", "abstract", "block", "resett", "iter", "at", "org", "apach", "flink", "runtim", "oper", "resett", "blockresettablemutableobjectiter", "next", "block", "resett", "mutabl", "object", "iter", "blockresettablemutableobjectiter", "java:111", "block", "resett", "mutabl", "object", "iter", "at", "org", "apach", "flink", "runtim", "oper", "crossdriv", "runblockedoutersecond", "cross", "driver", "run", "block", "outer", "second", "crossdriv", "java:309", "cross", "driver", "at", "org", "apach", "flink", "runtim", "oper", "crossdriv", "run", "cross", "driver", "crossdriv", "java:162", "cross", "driver", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "run", "regular", "pact", "task", "regularpacttask", "java:489", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "invok", "regular", "pact", "task", "regularpacttask", "java:354", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "taskmanag", "task", "run", "task", "java:581", "at", "java", "lang", "thread", "run", "thread", "java:745"], "B_title": "kryo Fix Kryo serialization to clear buffered data", "B_clean_title": ["kryo", "fix", "kryo", "serial", "clear", "buffer", "data"]},
{"A_title": "Mounted page is not throwing ExpireException with setting setRecreateMountedPagesAfterExpiry(false)We have a page that is both bookmarkable (and accessible with certain page parameters) and has a second constructor taking an object.  When ever the session time-out we want to show a session expired page. But we get a exception because Wicket is trying to rebuild the page with no page parameters.  We have set the setting getPageSettings().setRecreateMountedPagesAfterExpiry(false); This works when clicking on (ajax)links but its not working when using the back/forward button in the browser (or javascript:history.go(-1)).  Ill attache a quickstart.", "A_clean_title": ["mount", "page", "not", "throw", "expireexcept", "expir", "except", "set", "setrecreatemountedpagesafterexpiri", "set", "recreat", "mount", "page", "after", "expiri", "fals", "we", "have", "page", "that", "both", "bookmark", "access", "certain", "page", "paramet", "ha", "second", "constructor", "take", "object", "when", "ever", "session", "time", "out", "we", "want", "show", "session", "expir", "page", "but", "we", "get", "except", "becaus", "wicket", "tri", "rebuild", "page", "no", "page", "paramet", "we", "have", "set", "set", "getpageset", "get", "page", "set", "setrecreatemountedpagesafterexpiri", "set", "recreat", "mount", "page", "after", "expiri", "fals", "thi", "work", "when", "click", "ajax", "link", "but", "it", "not", "work", "when", "back", "forward", "button", "browser", "or", "javascript", "histori", "go", "ill", "attach", "quickstart"], "B_title": "testing recreateMountedPagesAfterExpiry before to recreate a mounted page", "B_clean_title": ["test", "recreatemountedpagesafterexpiri", "recreat", "mount", "page", "after", "expiri", "befor", "recreat", "mount", "page"]},
{"A_title": "StringEscapeUtils.escapeXML() cant process UTF-16 supplementary charactersSupplementary characters in UTF-16 are those whose code points are above 0xffff that is require more than 1 Java char to be encoded as explained here: http://java.sun.com/developer/technicalArticles/Intl/Supplementary/ Currently StringEscapeUtils.escapeXML() isnt aware of this coding scheme and treats each char as one character which is not always right. A possible solution in class Entities would be:     public void escape(Writer writer String str) throws IOException          int len = str.length();         for (int i = 0; i < len; i++)              int code = str.codePointAt;             String entityName = this.entityName(code);             if (entityName != null)                   writer.write(&);                 writer.write(entityName);                 writer.write(;);               else if (code > 0x7F)                       writer.write(&#);                     writer.write(code);                     writer.write(;);               else                       writer.write((char) code);                           if (code > 0xffff)                       i++;                            Besides fixing escapeXML() this will also affect HTML escaping functions. I guess thats a good thing but please remember I have only tested escapeXML().", "A_clean_title": ["stringescapeutil", "escapexml", "string", "escap", "util", "escap", "xml", "cant", "process", "utf", "16", "supplementari", "characterssupplementari", "charact", "supplementari", "charact", "utf", "16", "are", "those", "whose", "code", "point", "are", "abov", "0xffff", "that", "requir", "more", "than", "java", "char", "encod", "as", "explain", "here", "http", "sun", "java", "com", "develop", "technicalarticl", "intl", "supplementari", "technic", "articl", "current", "stringescapeutil", "escapexml", "string", "escap", "util", "escap", "xml", "isnt", "awar", "thi", "code", "scheme", "treat", "each", "char", "as", "one", "charact", "which", "not", "alway", "right", "possibl", "solut", "class", "entiti", "would", "public", "void", "escap", "writer", "writer", "string", "str", "throw", "ioexcept", "io", "except", "int", "len", "str", "length", "int", "len", "i++", "int", "code", "str", "codepointat", "code", "point", "at", "string", "entitynam", "entiti", "name", "thi", "entitynam", "entiti", "name", "code", "entitynam", "entiti", "name", "null", "writer", "write", "writer", "write", "entitynam", "entiti", "name", "writer", "write", "code", "0x7f", "writer", "write", "writer", "write", "code", "writer", "write", "writer", "write", "char", "code", "code", "0xffff", "i++", "besid", "fix", "escapexml", "escap", "xml", "thi", "will", "also", "affect", "html", "escap", "function", "guess", "that", "good", "thing", "but", "pleas", "rememb", "have", "onli", "test", "escapexml", "escap", "xml"], "B_title": "Adding a test and code fix to have supplementary chars working in numeric entity unescaping. See LANG-617", "B_clean_title": ["ad", "test", "code", "fix", "have", "supplementari", "char", "work", "numer", "entiti", "unescap", "see", "lang", "617"]},
{"A_title": "WicketTester.assertRedirectUrl always fails because it always thinks the redirect was nullI have a page which always redirects.  When I write a test for this page tester.assertRedirectUrl(...) always fails with the assertion failure showing that the redirect URL was null.  The page does redirect when running the application for real and I have stepped through in the debugger when running the test and it goes all the way to the HttpServletResponse.sendRedirect call.  However in the same debugging session tester.getLastResponse().getRedirectLocation() == null  Cut-down example follows.   public class AlwaysRedirectPage extends WebPage      public AlwaysRedirectPage()              // redirects to another web server on the same computer         throw new RedirectToUrlException(http://localhost:4333/);        public class TestAlwaysRedirectPage      @Test     public void test()              WicketTester tester = new WicketTester();         tester.startPage(AlwaysRedirectPage.class);         tester.assertRedirectUrl(http://localhost:4333/);", "A_clean_title": ["wickettest", "assertredirecturl", "wicket", "tester", "assert", "redirect", "url", "alway", "fail", "becaus", "it", "alway", "think", "redirect", "wa", "nulli", "null", "have", "page", "which", "alway", "redirect", "when", "write", "test", "thi", "page", "tester", "assertredirecturl", "assert", "redirect", "url", "alway", "fail", "assert", "failur", "show", "that", "redirect", "url", "wa", "null", "page", "redirect", "when", "run", "applic", "real", "have", "step", "through", "debugg", "when", "run", "test", "it", "goe", "all", "way", "httpservletrespons", "sendredirect", "http", "servlet", "respons", "send", "redirect", "call", "howev", "same", "debug", "session", "tester", "getlastrespons", "get", "last", "respons", "getredirectloc", "get", "redirect", "locat", "null", "cut", "down", "exampl", "follow", "public", "class", "alwaysredirectpag", "alway", "redirect", "page", "extend", "webpag", "web", "page", "public", "alwaysredirectpag", "alway", "redirect", "page", "redirect", "anoth", "web", "server", "same", "comput", "throw", "new", "redirecttourlexcept", "redirect", "url", "except", "http", "localhost:4333", "public", "class", "testalwaysredirectpag", "test", "alway", "redirect", "page", "test", "public", "void", "test", "wickettest", "wicket", "tester", "tester", "new", "wickettest", "wicket", "tester", "tester", "startpag", "start", "page", "alwaysredirectpag", "class", "alway", "redirect", "page", "tester", "assertredirecturl", "assert", "redirect", "url", "http", "localhost:4333"], "B_title": "WicketTester.assertRedirectUrl always fails because it always thinks the redirect was null", "B_clean_title": ["wickettest", "assertredirecturl", "wicket", "tester", "assert", "redirect", "url", "alway", "fail", "becaus", "it", "alway", "think", "redirect", "wa", "null"]},
{"A_title": "ValuedEnum.compareTo(Object other) not typesafe - it easily could be...int org.apache.commons.lang.enums.ValuedEnum.compareTo(Object other)  is not typesafe - if the int-values are the same it will return 0 even for two totally different sub-classes of ValuedEnum", "A_clean_title": ["valuedenum", "compareto", "valu", "enum", "compar", "object", "other", "not", "typesaf", "it", "easili", "could", "int", "org", "apach", "common", "lang", "enum", "valuedenum", "compareto", "valu", "enum", "compar", "object", "other", "not", "typesaf", "int", "valu", "are", "same", "it", "will", "return", "even", "two", "total", "differ", "sub", "class", "valuedenum", "valu", "enum"], "B_title": "- Fix compareTo to check the type is the same", "B_clean_title": ["fix", "compareto", "compar", "check", "type", "same"]},
{"A_title": "StringEscapeUtils.escapeXml(input) outputs wrong results when an input contains characters in Supplementary Planes.Hello. I use StringEscapeUtils.escapeXml(input) to escape special characters for XML. This method outputs wrong results when input contains characters in Supplementary Planes. String str1 = uD842uDFB7 + A; String str2 = StringEscapeUtils.escapeXml(str1); // The value of str2 must be equal to the one of str1 // because str1 does not contain characters to be escaped. // However str2 is diffrent from str1. System.out.println(URLEncoder.encode(str1 UTF-16BE)); //%D8%42%DF%B7A System.out.println(URLEncoder.encode(str2 UTF-16BE)); //%D8%42%DF%B7%FF%FD The cause of this problem is that the loop to translate input character by character is wrong. In CharSequenceTranslator.translate(CharSequence input Writer out) loop counter i moves from 0 to Character.codePointCount(input 0 input.length()) but it should move from 0 to input.length().", "A_clean_title": ["stringescapeutil", "escapexml", "string", "escap", "util", "escap", "xml", "input", "output", "wrong", "result", "when", "input", "contain", "charact", "supplementari", "plane", "hello", "use", "stringescapeutil", "escapexml", "string", "escap", "util", "escap", "xml", "input", "escap", "special", "charact", "xml", "thi", "method", "output", "wrong", "result", "when", "input", "contain", "charact", "supplementari", "plane", "string", "str1", "ud842udfb7", "d842u", "dfb7", "string", "str2", "stringescapeutil", "escapexml", "string", "escap", "util", "escap", "xml", "str1", "valu", "str2", "must", "equal", "one", "str1", "becaus", "str1", "not", "contain", "charact", "escap", "howev", "str2", "diffrent", "str1", "system", "out", "println", "urlencod", "encod", "url", "encod", "str1", "utf", "16be", "d8", "42", "df", "b7a", "system", "out", "println", "urlencod", "encod", "url", "encod", "str2", "utf", "16be", "d8", "42", "df", "b7", "ff", "fd", "caus", "thi", "problem", "that", "loop", "translat", "input", "charact", "by", "charact", "wrong", "charsequencetransl", "translat", "char", "sequenc", "translat", "charsequ", "char", "sequenc", "input", "writer", "out", "loop", "counter", "move", "charact", "codepointcount", "code", "point", "count", "input", "input", "length", "but", "it", "move", "input", "length"], "B_title": "StringEscapeUtils.escapeXml(input) outputs wrong results when an input contains characters in Supplementary Planes.  ALSO rewrite method to avoid modification of counter variable in for loop", "B_clean_title": ["stringescapeutil", "escapexml", "string", "escap", "util", "escap", "xml", "input", "output", "wrong", "result", "when", "input", "contain", "charact", "supplementari", "plane", "also", "rewrit", "method", "avoid", "modif", "counter", "variabl", "loop"]},
{"A_title": "ReactiveCommandSegmentCommandFactory resolves StreamingOutput for all reactive typesIm using Redis Lettuce dynamic client as described in official documentation  https://github.com/lettuce-io/lettuce-core/wiki/Redis-Command-Interfaces#command-interfaces.response-types My commands interface looks exactly the same   The problem is when method get cannot find value by key theres exception thrown instead of returning empty Mono.   When using predefined RedisReactiveCommands get works fine it returns empty Mono. So it seems like a bug to me.  The Redis Lettuce version being used is   < Also checked with 5.0.4 RELEASE - issue remained", "A_clean_title": ["reactivecommandsegmentcommandfactori", "reactiv", "command", "segment", "command", "factori", "resolv", "streamingoutput", "stream", "output", "all", "reactiv", "typesim", "type", "im", "redi", "lettuc", "dynam", "client", "as", "describ", "offici", "document", "http", "command", "interfac", "io", "lettuc", "core", "wiki", "redi", "github", "com", "lettuc", "command", "type", "interfac", "respons", "my", "command", "interfac", "look", "exactli", "same", "problem", "when", "method", "get", "not", "find", "valu", "by", "key", "there", "except", "thrown", "instead", "return", "empti", "mono", "when", "predefin", "redisreactivecommand", "redi", "reactiv", "command", "get", "work", "fine", "it", "return", "empti", "mono", "so", "it", "seem", "like", "bug", "me", "redi", "lettuc", "version", "be", "use", "also", "check", "releas", "issu", "remain"], "B_title": "Consider value multiplicity in reactive output resolution #879  Lettuce now checks for the value multiplicity when resolving the actual output type for reactive Redis commands methods.  Previously all reactive types were considered streaming ones which caused usage of a not applicable output type. So Mono<String> used KeyListOutput which propagated null values.", "B_clean_title": ["consid", "valu", "multipl", "reactiv", "output", "resolut", "879", "lettuc", "now", "check", "valu", "multipl", "when", "resolv", "actual", "output", "type", "reactiv", "redi", "command", "method", "previous", "all", "reactiv", "type", "were", "consid", "stream", "one", "which", "caus", "usag", "not", "applic", "output", "type", "so", "mono", "string", "use", "keylistoutput", "key", "list", "output", "which", "propag", "null", "valu"]},
{"A_title": "IllegalStateException: Header was already written to response!Getting this error for no apparent reason the code works fine on wicket 1.4.17. Code example with error is attached.  Click on the click here link to see the error occur in the console below is part of the stack trace.   ERROR - DefaultExceptionMapper     - Unexpected error occurred java.lang.IllegalStateException: Header was already written to response!         at org.apache.wicket.protocol.http.HeaderBufferingWebResponse.checkHeader(HeaderBufferingWebResponse.java:62)         at org.apache.wicket.protocol.http.HeaderBufferingWebResponse.setDateHeader(HeaderBufferingWebResponse.java:131)          at org.apache.wicket.protocol.http.BufferedWebResponse SetDateHeaderAction.invoke(BufferedWebResponse.java:241)         at org.apache.wicket.protocol.http.BufferedWebResponse.writeTo(BufferedWebResponse.java:487)         at org.apache.wicket.request.handler.render.WebPageRenderer.respond(WebPageRenderer.java:225)         at org.apache.wicket.request.handler.RenderPageRequestHandler.respond(RenderPageRequestHandler.java:139)         at org.apache.wicket.request.cycle.RequestCycle HandlerExecutor.respond(RequestCycle.java:715)         at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:63)         at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:274)         at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:283)         at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:283)         at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:283)         at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:283)         at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:283)         at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:227)         at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:253)         at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:138)         at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:194)         at org.eclipse.jetty.servlet.ServletHandler CachedChain.doFilter(ServletHandler.java:1323)         at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:474)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:119)         at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:517)         at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)         at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:935)         at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:404)         at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:184)         at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:870)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:117)         at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:247)         at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:151)         at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)         at org.eclipse.jetty.server.Server.handle(Server.java:346)         at org.eclipse.jetty.server.HttpConnection.handleRequest(HttpConnection.java:596)         at org.eclipse.jetty.server.HttpConnection RequestHandler.headerComplete(HttpConnection.java:1051)         at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:592)         at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:214)         at org.eclipse.jetty.server.HttpConnection.handle(HttpConnection.java:426)         at org.eclipse.jetty.server.bio.SocketConnector ConnectorEndPoint.run(SocketConnector.java:241)         at org.eclipse.jetty.server.ssl.SslSocketConnector SslConnectorEndPoint.run(SslSocketConnector.java:646)         at org.eclipse.jetty.util.thread.QueuedThreadPool 3.run(QueuedThreadPool.java:528)         at java.lang.Thread.run(Thread.java:619)", "A_clean_title": ["illegalstateexcept", "illeg", "state", "except", "header", "wa", "alreadi", "written", "respons", "get", "thi", "error", "no", "appar", "reason", "code", "work", "fine", "wicket", "17", "code", "exampl", "error", "attach", "click", "click", "here", "link", "see", "error", "occur", "consol", "below", "part", "stack", "trace", "error", "defaultexceptionmapp", "default", "except", "mapper", "unexpect", "error", "occur", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "header", "wa", "alreadi", "written", "respons", "at", "org", "apach", "wicket", "protocol", "http", "headerbufferingwebrespons", "checkhead", "header", "buffer", "web", "respons", "check", "header", "headerbufferingwebrespons", "java:62", "header", "buffer", "web", "respons", "at", "org", "apach", "wicket", "protocol", "http", "headerbufferingwebrespons", "setdatehead", "header", "buffer", "web", "respons", "set", "date", "header", "headerbufferingwebrespons", "java:131", "header", "buffer", "web", "respons", "at", "org", "apach", "wicket", "protocol", "http", "bufferedwebrespons", "buffer", "web", "respons", "setdateheaderact", "invok", "set", "date", "header", "action", "bufferedwebrespons", "java:241", "buffer", "web", "respons", "at", "org", "apach", "wicket", "protocol", "http", "bufferedwebrespons", "writeto", "buffer", "web", "respons", "write", "bufferedwebrespons", "java:487", "buffer", "web", "respons", "at", "org", "apach", "wicket", "request", "handler", "render", "webpagerender", "respond", "web", "page", "render", "webpagerender", "java:225", "web", "page", "render", "at", "org", "apach", "wicket", "request", "handler", "renderpagerequesthandl", "respond", "render", "page", "request", "handler", "renderpagerequesthandl", "java:139", "render", "page", "request", "handler", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "request", "cycl", "handlerexecutor", "respond", "handler", "executor", "requestcycl", "java:715", "request", "cycl", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:63", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:274", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:283", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:283", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:283", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:283", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:283", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:227", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:253", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:138", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:194", "wicket", "filter", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "servlet", "handler", "cachedchain", "dofilt", "cach", "chain", "filter", "servlethandl", "java:1323", "servlet", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "dohandl", "servlet", "handler", "handl", "servlethandl", "java:474", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:119", "scope", "handler", "at", "org", "eclips", "jetti", "secur", "securityhandl", "handl", "secur", "handler", "securityhandl", "java:517", "secur", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "dohandl", "session", "handler", "handl", "sessionhandl", "java:226", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "dohandl", "context", "handler", "handl", "contexthandl", "java:935", "context", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "doscop", "servlet", "handler", "scope", "servlethandl", "java:404", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "doscop", "session", "handler", "scope", "sessionhandl", "java:184", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "doscop", "context", "handler", "scope", "contexthandl", "java:870", "context", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:117", "scope", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandlercollect", "handl", "context", "handler", "collect", "contexthandlercollect", "java:247", "context", "handler", "collect", "at", "org", "eclips", "jetti", "server", "handler", "handlercollect", "handl", "handler", "collect", "handlercollect", "java:151", "handler", "collect", "at", "org", "eclips", "jetti", "server", "handler", "handlerwrapp", "handl", "handler", "wrapper", "handlerwrapp", "java:116", "handler", "wrapper", "at", "org", "eclips", "jetti", "server", "server", "handl", "server", "java:346", "at", "org", "eclips", "jetti", "server", "httpconnect", "handlerequest", "http", "connect", "handl", "request", "httpconnect", "java:596", "http", "connect", "at", "org", "eclips", "jetti", "server", "httpconnect", "http", "connect", "requesthandl", "headercomplet", "request", "handler", "header", "complet", "httpconnect", "java:1051", "http", "connect", "at", "org", "eclips", "jetti", "http", "httpparser", "parsenext", "http", "parser", "pars", "next", "httpparser", "java:592", "http", "parser", "at", "org", "eclips", "jetti", "http", "httpparser", "parseavail", "http", "parser", "pars", "avail", "httpparser", "java:214", "http", "parser", "at", "org", "eclips", "jetti", "server", "httpconnect", "handl", "http", "connect", "httpconnect", "java:426", "http", "connect", "at", "org", "eclips", "jetti", "server", "bio", "socketconnector", "socket", "connector", "connectorendpoint", "run", "connector", "end", "point", "socketconnector", "java:241", "socket", "connector", "at", "org", "eclips", "jetti", "server", "ssl", "sslsocketconnector", "ssl", "socket", "connector", "sslconnectorendpoint", "run", "ssl", "connector", "end", "point", "sslsocketconnector", "java:646", "ssl", "socket", "connector", "at", "org", "eclips", "jetti", "util", "thread", "queuedthreadpool", "queu", "thread", "pool", "run", "queuedthreadpool", "java:528", "queu", "thread", "pool", "at", "java", "lang", "thread", "run", "thread", "java:619"], "B_title": "improving BufferedWebResponse to invoke set header actions before write in response. Issue: WICKET-3618", "B_clean_title": ["improv", "bufferedwebrespons", "buffer", "web", "respons", "invok", "set", "header", "action", "befor", "write", "respons", "issu", "wicket", "3618"]},
{"A_title": "Stale cache after MongoMK GCAfter a MongoMK revision GC the docChildrenCache may be stale and lead to a NPE when reading children with deleted and GCed siblings.", "A_clean_title": ["stale", "cach", "after", "mongomk", "mongo", "mk", "gcafter", "gc", "after", "mongomk", "mongo", "mk", "revis", "gc", "docchildrencach", "doc", "children", "cach", "may", "stale", "lead", "npe", "when", "read", "children", "delet", "gced", "ced", "sibl"], "B_title": "Stale cache after MongoMK GC", "B_clean_title": ["stale", "cach", "after", "mongomk", "mongo", "mk", "gc"]},
{"A_title": "Events at unitialized input channels are lostIf a program sends an event backwards to the producer task it might happen that some of it input channels have not been initialized yet (UnknownInputChannel). In that case the events are lost and will never be received at the producer.", "A_clean_title": ["event", "at", "uniti", "input", "channel", "are", "lostif", "lost", "program", "send", "event", "backward", "produc", "task", "it", "might", "happen", "that", "some", "it", "input", "channel", "have", "not", "been", "initi", "yet", "unknowninputchannel", "unknown", "input", "channel", "that", "case", "event", "are", "lost", "will", "never", "receiv", "at", "produc"], "B_title": "distributed runtime Fix loss of events at uninitialized input channels", "B_clean_title": ["distribut", "runtim", "fix", "loss", "event", "at", "uniniti", "input", "channel"]},
{"A_title": "Type extractor cannot determine type of functionThis function fails in the type extractor.  code public static final class DuplicateValue<T> implements MapFunction<Tuple1<T> Tuple2<T T>>   @Override public Tuple2<T T> map(Tuple1<T> vertex)  return new Tuple2<T T>(vertex.f0 vertex.f0);   code", "A_clean_title": ["type", "extractor", "not", "determin", "type", "functionthi", "function", "thi", "function", "fail", "type", "extractor", "code", "public", "static", "final", "class", "duplicatevalu", "duplic", "valu", "implement", "mapfunct", "map", "function", "tuple1", "tuple2", "overrid", "public", "tuple2", "map", "tuple1", "vertex", "return", "new", "tuple2", "vertex", "f0", "vertex", "f0", "code"], "B_title": "TypeExtractor now also supports nested Tuple-input derivation", "B_clean_title": ["typeextractor", "type", "extractor", "now", "also", "support", "nest", "tupl", "input", "deriv"]},
{"A_title": "StringIndexOutOfBoundsException in CharSequenceTranslatorI found that there is bad surrogate pair handling in the CharSequenceTranslator This is a simple test case for this problem. uD83DuDE30 is a surrogate pair.  @Test public void testEscapeSurrogatePairs() throws Exception      assertEquals(uD83DuDE30 StringEscapeUtils.escapeCsv(uD83DuDE30));    Youll get the exception as shown below.  java.lang.StringIndexOutOfBoundsException: String index out of range: 2 at java.lang.String.charAt(String.java:658) at java.lang.Character.codePointAt(Character.java:4668) at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:95) at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:59) at org.apache.commons.lang3.StringEscapeUtils.escapeCsv(StringEscapeUtils.java:556)   Patch attached the method affected:  public final void translate(CharSequence input Writer out) throws IOException", "A_clean_title": ["stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "charsequencetranslatori", "char", "sequenc", "translat", "found", "that", "there", "bad", "surrog", "pair", "handl", "charsequencetransl", "char", "sequenc", "translat", "thi", "simpl", "test", "case", "thi", "problem", "ud83dude30", "d83du", "de30", "surrog", "pair", "test", "public", "void", "testescapesurrogatepair", "test", "escap", "surrog", "pair", "throw", "except", "assertequ", "assert", "equal", "ud83dude30", "d83du", "de30", "stringescapeutil", "escapecsv", "string", "escap", "util", "escap", "csv", "ud83dude30", "d83du", "de30", "youll", "get", "except", "as", "shown", "below", "java", "lang", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "string", "index", "out", "rang", "at", "java", "lang", "string", "charat", "char", "at", "string", "java:658", "at", "java", "lang", "charact", "codepointat", "code", "point", "at", "charact", "java:4668", "at", "org", "apach", "common", "lang3", "text", "translat", "charsequencetransl", "translat", "char", "sequenc", "translat", "charsequencetransl", "java:95", "char", "sequenc", "translat", "at", "org", "apach", "common", "lang3", "text", "translat", "charsequencetransl", "translat", "char", "sequenc", "translat", "charsequencetransl", "java:59", "char", "sequenc", "translat", "at", "org", "apach", "common", "lang3", "stringescapeutil", "escapecsv", "string", "escap", "util", "escap", "csv", "stringescapeutil", "java:556", "string", "escap", "util", "patch", "attach", "method", "affect", "public", "final", "void", "translat", "charsequ", "char", "sequenc", "input", "writer", "out", "throw", "ioexcept", "io", "except"], "B_title": "StringIndexOutOfBoundsException in CharSequenceTranslator.", "B_clean_title": ["stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "charsequencetransl", "char", "sequenc", "translat"]},
{"A_title": "Fraction specified with maxDenominator and a value very close to a simple fraction should not throw an overflow exceptionAn overflow exception is thrown when a Fraction is initialized with a maxDenominator from a double that is very close to a simple fraction.  For example:  double d = 0.5000000001; Fraction f = new Fraction(d 10);  Patch with unit test on way.", "A_clean_title": ["fraction", "specifi", "maxdenomin", "max", "denomin", "valu", "veri", "close", "simpl", "fraction", "not", "throw", "overflow", "exceptionan", "except", "overflow", "except", "thrown", "when", "fraction", "initi", "maxdenomin", "max", "denomin", "doubl", "that", "veri", "close", "simpl", "fraction", "exampl", "doubl", "5000000001", "fraction", "new", "fraction", "10", "patch", "unit", "test", "way"], "B_title": "Fix creation of Fraction/BigFraction objects in maxDenominator mode when the value is close to an actual fraction.", "B_clean_title": ["fix", "creation", "fraction", "bigfract", "big", "fraction", "object", "maxdenomin", "max", "denomin", "mode", "when", "valu", "close", "actual", "fraction"]},
{"A_title": "NaN singular value from SVDThe following jython code Start code from org.apache.commons.math.linear import * Alist = 1.0 2.0 3.02.03.04.03.05.07.0 A = Array2DRowRealMatrix(Alist) decomp = SingularValueDecompositionImpl(A) print decomp.getSingularValues() End code prints array(d 11.218599757513008 0.3781791648535976 nan) The last singular value should be something very close to 0 since the matrix is rank deficient.  When i use the result from getSolver() to solve a system i end  up with a bunch of NaNs in the solution.  I assumed i would get back a least squares solution. Does this SVD implementation require that the matrix be full rank?  If so then i would expect an exception to be thrown from the constructor or one of the methods.", "A_clean_title": ["nan", "na", "singular", "valu", "svdthe", "svd", "follow", "jython", "code", "start", "code", "org", "apach", "common", "math", "linear", "import", "alist", "02", "03", "04", "03", "05", "07", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "alist", "decomp", "singularvaluedecompositionimpl", "singular", "valu", "decomposit", "impl", "print", "decomp", "getsingularvalu", "get", "singular", "valu", "end", "code", "print", "array", "11", "218599757513008", "3781791648535976", "nan", "last", "singular", "valu", "someth", "veri", "close", "sinc", "matrix", "rank", "defici", "when", "use", "result", "getsolv", "get", "solver", "solv", "system", "end", "up", "bunch", "nan", "na", "ns", "solut", "assum", "would", "get", "back", "least", "squar", "solut", "thi", "svd", "implement", "requir", "that", "matrix", "full", "rank", "so", "then", "would", "expect", "except", "thrown", "constructor", "or", "one", "method"], "B_title": "Singular Value Decomposition now computes either the compact SVD (using only positive singular values) or truncated SVD (using a user-specified maximal number of singular values). Fixed Singular Value Decomposition solving of singular systems. JIRA: MATH-320 MATH-321", "B_clean_title": ["singular", "valu", "decomposit", "now", "comput", "either", "compact", "svd", "onli", "posit", "singular", "valu", "or", "truncat", "svd", "user", "specifi", "maxim", "number", "singular", "valu", "fix", "singular", "valu", "decomposit", "solv", "singular", "system", "jira", "math", "320", "math", "321"]},
{"A_title": "XPath: queries starting with // are not always converted correctlyXPath queries starting with // are not always converted to the expected SQL-2 query. Examples:  noformat //element(* oak:QueryIndexDefinition)/* select jcr:path jcr:score * from oak:QueryIndexDefinition as a  //element(* oak:QueryIndexDefinition)//* select jcr:path jcr:score * from oak:QueryIndexDefinition as a noformat  This is wrong. Instead a join should be used.", "A_clean_title": ["xpath", "path", "queri", "start", "are", "not", "alway", "convert", "correctlyxpath", "correctli", "path", "queri", "start", "are", "not", "alway", "convert", "expect", "sql", "queri", "exampl", "noformat", "element", "oak", "queryindexdefinit", "queri", "index", "definit", "select", "jcr", "path", "jcr", "score", "oak", "queryindexdefinit", "queri", "index", "definit", "as", "element", "oak", "queryindexdefinit", "queri", "index", "definit", "select", "jcr", "path", "jcr", "score", "oak", "queryindexdefinit", "queri", "index", "definit", "as", "noformat", "thi", "wrong", "instead", "join", "use"], "B_title": "XPath: queries starting with // are not always converted correctly", "B_clean_title": ["xpath", "path", "queri", "start", "are", "not", "alway", "convert", "correctli"]},
{"A_title": "Not expected UnboundedSolutionExceptionSimplexSolver throws UnboundedSolutionException when trying to solve minimization linear programming problem. The number of exception thrown depends on the number of variables. In order to see that behavior of SimplexSolver first try to run JUnit test setting a final variable ENTITIES_COUNT = 2 and that will give almost good result and then set it to 15 and youll get a massive of unbounded exceptions. First iteration is runned with predefined set of input data with which the Solver gives back an appropriate result. The problem itself is well tested by its authors (mathematicians who I believe know what they developed) using Matlab 10 with no unbounded solutions on the same rules of creatnig random variables values. What is strange to me is the dependence of the number of UnboundedSolutionException exceptions on the number of variables in the problem. The problem is formulated as min(1*t + 0*L) (for every r-th subject) s.t. -q(r) + QL >= 0 x(r)t - XL >= 0 L >= 0 where  r = 1..R  L =  l(1) l(2) ... l(R)  (vector of R rows and 1 column) Q - coefficients matrix MxR X - coefficients matrix NxR", "A_clean_title": ["not", "expect", "unboundedsolutionexceptionsimplexsolv", "unbound", "solut", "except", "simplex", "solver", "throw", "unboundedsolutionexcept", "unbound", "solut", "except", "when", "tri", "solv", "minim", "linear", "program", "problem", "number", "except", "thrown", "depend", "number", "variabl", "order", "see", "that", "behavior", "simplexsolv", "simplex", "solver", "first", "tri", "run", "junit", "unit", "test", "set", "final", "variabl", "entiti", "count", "that", "will", "give", "almost", "good", "result", "then", "set", "it", "15", "youll", "get", "massiv", "unbound", "except", "first", "iter", "run", "predefin", "set", "input", "data", "which", "solver", "give", "back", "appropri", "result", "problem", "itself", "well", "test", "by", "it", "author", "mathematician", "who", "believ", "know", "what", "they", "develop", "matlab", "10", "no", "unbound", "solut", "same", "rule", "creatnig", "random", "variabl", "valu", "what", "strang", "me", "depend", "number", "unboundedsolutionexcept", "unbound", "solut", "except", "except", "number", "variabl", "problem", "problem", "formul", "as", "min", "everi", "th", "subject", "ql", "xl", "where", "vector", "row", "column", "coeffici", "matrix", "mxr", "mx", "coeffici", "matrix", "nxr", "nx"], "B_title": "Add additional heuristic for rare cases in pivotRow selection.", "B_clean_title": ["add", "addit", "heurist", "rare", "case", "pivotrow", "pivot", "row", "select"]},
{"A_title": "DurationFormatUtils returns wrong resultDurationFormatUtils returns wrong result.  oddly it is only when Date is set to Dec 31 2005 The following code will result in a String of -2 which is way off. Ive tested against 2.1 and 2.2.         Calendar cal = Calendar.getInstance();         cal.set(Calendar.MONTH Calendar.DECEMBER);         cal.set(Calendar.DAY_OF_MONTH 31);         cal.set(Calendar.YEAR 2005);         cal.set(Calendar.HOUR_OF_DAY 0);         cal.set(Calendar.MINUTE 0);         cal.set(Calendar.SECOND 0);         cal.set(Calendar.MILLISECOND 0);         String result = DurationFormatUtils.formatPeriod(cal.getTimeInMillis() System.currentTimeMillis() MM);         System.out.println(result);", "A_clean_title": ["durationformatutil", "durat", "format", "util", "return", "wrong", "resultdurationformatutil", "result", "durat", "format", "util", "return", "wrong", "result", "oddli", "it", "onli", "when", "date", "set", "dec", "31", "2005", "follow", "code", "will", "result", "string", "which", "way", "off", "ive", "test", "against", "calendar", "cal", "calendar", "getinst", "get", "instanc", "cal", "set", "calendar", "month", "calendar", "decemb", "cal", "set", "calendar", "day", "month", "31", "cal", "set", "calendar", "year", "2005", "cal", "set", "calendar", "hour", "day", "cal", "set", "calendar", "minut", "cal", "set", "calendar", "second", "cal", "set", "calendar", "millisecond", "string", "result", "durationformatutil", "formatperiod", "durat", "format", "util", "format", "period", "cal", "gettimeinmilli", "get", "time", "milli", "system", "currenttimemilli", "current", "time", "milli", "mm", "system", "out", "println", "result"], "B_title": "Adding a unit test for #LANG-281 and a fix. The fix involves removing the reduceAndCorrect method. It appears that this method was doing sod all - which is worrying as it used to be important. Im guessing that it was a bad fix for a bug that was then subsequently fixed with other code. Ill create a JIRA issue to create more tests to test out the +31 block of code.", "B_clean_title": ["ad", "unit", "test", "lang", "281", "fix", "fix", "involv", "remov", "reduceandcorrect", "reduc", "correct", "method", "it", "appear", "that", "thi", "method", "wa", "do", "sod", "all", "which", "worri", "as", "it", "use", "import", "im", "guess", "that", "it", "wa", "bad", "fix", "bug", "that", "wa", "then", "subsequ", "fix", "other", "code", "ill", "creat", "jira", "issu", "creat", "more", "test", "test", "out", "+31", "block", "code"]},
{"A_title": "goog.isArray doesnt hint compilerNone", "A_clean_title": ["goog", "isarray", "array", "doesnt", "hint", "compilernon", "compil", "none"], "B_title": "Restrict goog.isArray to * properly. Fixes issue 1114 R=blickly", "B_clean_title": ["restrict", "goog", "isarray", "array", "properli", "fix", "issu", "1114", "r=blickli"]},
{"A_title": "Stale cluster ids can potentially lead to lots of previous docs traversal in NodeDocument.getNewestRevisionWhen some (actual test case and conditions still being investigated) of the following conditions are met: * There are property value changes from different cluster id * There are very old and stale cluster id (probably older incarnations of current node itself) * A parallel background split removes all _commitRoot _revision entries such that the latest one (which is less that baseRev) is very old   finding newest revision traverses a lot of previous docs. Since root document gets split a lot and is a very common commitRoot (thus participating during checkConflicts in lot of commits) the issue can slow down commits by a lot", "A_clean_title": ["stale", "cluster", "id", "potenti", "lead", "lot", "previou", "doc", "travers", "nodedocu", "getnewestrevisionwhen", "node", "document", "get", "newest", "revis", "when", "some", "actual", "test", "case", "condit", "still", "be", "investig", "follow", "condit", "are", "met", "there", "are", "properti", "valu", "chang", "differ", "cluster", "id", "there", "are", "veri", "old", "stale", "cluster", "id", "probabl", "older", "incarn", "current", "node", "itself", "parallel", "background", "split", "remov", "all", "commitroot", "commit", "root", "revis", "entri", "such", "that", "latest", "one", "which", "less", "that", "baserev", "base", "rev", "veri", "old", "find", "newest", "revis", "travers", "lot", "previou", "doc", "sinc", "root", "document", "get", "split", "lot", "veri", "common", "commitroot", "commit", "root", "thu", "particip", "dure", "checkconflict", "check", "conflict", "lot", "commit", "issu", "slow", "down", "commit", "by", "lot"], "B_title": "Stale cluster ids can potentially lead to lots of previous docs traversal in NodeDocument.getNewestRevision", "B_clean_title": ["stale", "cluster", "id", "potenti", "lead", "lot", "previou", "doc", "travers", "nodedocu", "getnewestrevis", "node", "document", "get", "newest", "revis"]},
{"A_title": "numerical problems in rotation creationbuilding a rotation from the following vector pairs leads to NaN: u1 = -4921140.837095533 -2.1512094250440013E7 -890093.279426377 u2 = -2.7238580938724895E9 -2.169664921341876E9 6.749688708885301E10 v1 = 1 0 0 v2 = 0 0 1  The constructor first changes the (v1 v2) pair into (v1 v2) ensuring the following scalar products hold:  <v1|v1> == <u1|u1>  <v2|v2> == <u2|u2>  <u1 |u2>  == <v1|v2>  Once the (v1 v2) pair has been computed we compute the cross product:   k = (v1 - u1)^(v2 - u2)  and the scalar product:   c = <k | (u1^u2)>  By construction c is positive or null and the quaternion axis we want to build is q = k/2*sqrt(c). c should be null only if some of the vectors are aligned and this is dealt with later in the algorithm.  However there are numerical problems with the vector above with the way these computations are done as shown by the following comparisons showing the result we get from our Java code and the result we get from manual computation with the same formulas but with enhanced precision:  commons math:   k = 38514476.5            -84.                           -1168590144 high precision: k = 38514410.36093388...  -0.374075245201180409222711... -1168590152.10599715208...  and it becomes worse when computing c because the vectors are almost orthogonal to each other hence inducing additional cancellations. We get: commons math    c = -1.2397173627587605E20 high precision: c =  558382746168463196.7079627...  We have lost ALL significant digits in cancellations and even the sign is wrong!", "A_clean_title": ["numer", "problem", "rotat", "creationbuild", "rotat", "follow", "vector", "pair", "lead", "nan", "na", "u1", "4921140", "837095533", "1512094250440013e7", "890093", "279426377", "u2", "7238580938724895e9", "169664921341876e9", "749688708885301e10", "v1", "v2", "constructor", "first", "chang", "v1", "v2", "pair", "into", "v1", "v2", "ensur", "follow", "scalar", "product", "hold", "v1|v1", "u1|u1", "v2|v2", "u2|u2", "u1", "|u2", "v1|v2", "onc", "v1", "v2", "pair", "ha", "been", "comput", "we", "comput", "cross", "product", "v1", "u1", "v2", "u2", "scalar", "product", "u1^u2", "by", "construct", "posit", "or", "null", "quaternion", "axi", "we", "want", "build", "sqrt", "null", "onli", "some", "vector", "are", "align", "thi", "dealt", "later", "algorithm", "howev", "there", "are", "numer", "problem", "vector", "abov", "way", "these", "comput", "are", "done", "as", "shown", "by", "follow", "comparison", "show", "result", "we", "get", "our", "java", "code", "result", "we", "get", "manual", "comput", "same", "formula", "but", "enhanc", "precis", "common", "math", "38514476", "84", "1168590144", "high", "precis", "38514410", "36093388", "374075245201180409222711", "1168590152", "10599715208", "it", "becom", "wors", "when", "comput", "becaus", "vector", "are", "almost", "orthogon", "each", "other", "henc", "induc", "addit", "cancel", "we", "get", "common", "math", "2397173627587605e20", "high", "precis", "558382746168463196", "7079627", "we", "have", "lost", "all", "signific", "digit", "cancel", "even", "sign", "wrong"], "B_title": "Fixed a wrong detection of rotation axis versus vectors plane in Rotation constructor using two vectors pairs.", "B_clean_title": ["fix", "wrong", "detect", "rotat", "axi", "versu", "vector", "plane", "rotat", "constructor", "two", "vector", "pair"]},
{"A_title": "StringValueConversionException for correct situationStringValue.toOptionalLong() produces org.apache.wicket.util.string.StringValueConversionException if empty string was passed. Let me suggest that this behavior should be changes for all toOptionalXXX methods except getOptionalString method.  The problem in inner code:  The problem in following code:  public final Long toOptionalLong() throws StringValueConversionException              return (text == null) ? null : toLongObject();       Should be something like this:  The problem in following code:  public final Long toOptionalLong() throws StringValueConversionException              return Strings.isEmpty() ? null : toLongObject();       But there is another problem: what to do if incorrect param was passed - for example abc for parameter of Long type?", "A_clean_title": ["stringvalueconversionexcept", "string", "valu", "convers", "except", "correct", "situationstringvalu", "tooptionallong", "situat", "string", "valu", "option", "long", "produc", "org", "apach", "wicket", "util", "string", "stringvalueconversionexcept", "string", "valu", "convers", "except", "empti", "string", "wa", "pass", "let", "me", "suggest", "that", "thi", "behavior", "chang", "all", "tooptionalxxx", "option", "xxx", "method", "except", "getoptionalstr", "get", "option", "string", "method", "problem", "inner", "code", "problem", "follow", "code", "public", "final", "long", "tooptionallong", "option", "long", "throw", "stringvalueconversionexcept", "string", "valu", "convers", "except", "return", "text", "null", "null", "tolongobject", "long", "object", "someth", "like", "thi", "problem", "follow", "code", "public", "final", "long", "tooptionallong", "option", "long", "throw", "stringvalueconversionexcept", "string", "valu", "convers", "except", "return", "string", "isempti", "empti", "null", "tolongobject", "long", "object", "but", "there", "anoth", "problem", "what", "incorrect", "param", "wa", "pass", "exampl", "abc", "paramet", "long", "type"], "B_title": "StringValueConversionException for correct situation", "B_clean_title": ["stringvalueconversionexcept", "string", "valu", "convers", "except", "correct", "situat"]},
{"A_title": "Form components name/value are encoded in stateless forms action urlStateless forms arent working well as you can see on wicket examples: http://www.wicket-library.com/wicket-examples/stateless/foo  The first time you submit (for example the value 10) everything works as supposed to. If you now change the value (to 11 for example) and submit the form the value wicket shows is 10.  I think the problem is stateless forms are generating an action URL with submitted values on query string and when you resubmit the form this values on query string replace the POST(or GET) values.", "A_clean_title": ["form", "compon", "name", "valu", "are", "encod", "stateless", "form", "action", "urlstateless", "url", "stateless", "form", "arent", "work", "well", "as", "you", "see", "wicket", "exampl", "http", "wicket", "librari", "exampl", "stateless", "foo", "www", "com", "wicket", "first", "time", "you", "submit", "exampl", "valu", "10", "everyth", "work", "as", "suppos", "you", "now", "chang", "valu", "11", "exampl", "submit", "form", "valu", "wicket", "show", "10", "think", "problem", "stateless", "form", "are", "gener", "action", "url", "submit", "valu", "queri", "string", "when", "you", "resubmit", "form", "thi", "valu", "queri", "string", "replac", "post", "or", "get", "valu"], "B_title": "Form components name/value are encoded in stateless forms action url", "B_clean_title": ["form", "compon", "name", "valu", "are", "encod", "stateless", "form", "action", "url"]},
{"A_title": "TimeOfDay.valueOf(Calendar Time) and TimeOfDay.valueOf(Time) incorrectly use 12-hour clockTimeOfDay.valueOf(Calendar Time) is implemented as:     return militaryTime(time.getHour(calendar) time.getMinute(calendar) time.getSecond(calendar));  This is flawed because Time.getHour() is implemented as:     return get(calendar Calendar.HOUR); and Calendar.HOUR is for the 12-hour clock. The result is that TimeOfDay.valueOf(Calendar Time) incorrectly only returns 12-hour results not 24-hour results. This affects TimeOfDay.valueOf(Time) as well since it is implemented in terms of the previously-named method.  One fix would be to change Time.getHour() to use Calendar.HOUR_OF_DAY. Since Time doesnt have an am/pm indicator this seems reasonable. An alternate more localized fix would be to change TimeOfDay.valueOf(Calendar Time) to call time.get(Calendar.HOUR_OF_DAY) to get the hour value.", "A_clean_title": ["timeofday", "valueof", "time", "day", "valu", "calendar", "time", "timeofday", "valueof", "time", "day", "valu", "time", "incorrectli", "use", "12", "hour", "clocktimeofday", "valueof", "clock", "time", "day", "valu", "calendar", "time", "implement", "as", "return", "militarytim", "militari", "time", "time", "gethour", "get", "hour", "calendar", "time", "getminut", "get", "minut", "calendar", "time", "getsecond", "get", "second", "calendar", "thi", "flaw", "becaus", "time", "gethour", "get", "hour", "implement", "as", "return", "get", "calendar", "calendar", "hour", "calendar", "hour", "12", "hour", "clock", "result", "that", "timeofday", "valueof", "time", "day", "valu", "calendar", "time", "incorrectli", "onli", "return", "12", "hour", "result", "not", "24", "hour", "result", "thi", "affect", "timeofday", "valueof", "time", "day", "valu", "time", "as", "well", "sinc", "it", "implement", "term", "previous", "name", "method", "one", "fix", "would", "chang", "time", "gethour", "get", "hour", "use", "calendar", "hour", "day", "sinc", "time", "doesnt", "have", "am", "pm", "indic", "thi", "seem", "reason", "altern", "more", "local", "fix", "would", "chang", "timeofday", "valueof", "time", "day", "valu", "calendar", "time", "call", "time", "get", "calendar", "hour", "day", "get", "hour", "valu"], "B_title": "fixed Time.getHour() to use 24-hour clock", "B_clean_title": ["fix", "time", "gethour", "get", "hour", "use", "24", "hour", "clock"]},
{"A_title": "CheckpointCoordinator triggers checkpoints even if not all sources are running any moreWhen some sources finish early they will not emit checkpoint barriers any more. That means that pending checkpoint alignments will never be able to complete locking the flow.", "A_clean_title": ["checkpointcoordin", "checkpoint", "coordin", "trigger", "checkpoint", "even", "not", "all", "sourc", "are", "run", "ani", "morewhen", "more", "when", "some", "sourc", "finish", "earli", "they", "will", "not", "emit", "checkpoint", "barrier", "ani", "more", "that", "mean", "that", "pend", "checkpoint", "align", "will", "never", "abl", "complet", "lock", "flow"], "B_title": "job manager Checkpoint coordinator triggers checkpoints only when tasks are running.", "B_clean_title": ["job", "manag", "checkpoint", "coordin", "trigger", "checkpoint", "onli", "when", "task", "are", "run"]},
{"A_title": "Exception at compilation due to a constructor with private visibilityHello  Im having an issue while instrumenting the source code of  AssertJ with Spoon. The instrumentation part will work but the compilation part will fail due to the following error:  I created a small Maven project with the part of the AssertJ source code that I cannot instrument/compile with Spoon.  The project architecture is the following:   According to the Exception message the problems comes from the class  BooleanArraysBaseTest  which contains the following code:  The statement  arrays = new BooleanArrays(); refers to the BooleanArrays class contained in the same package (internal) which is a Singleton having a constructor with the package visibility:  The other class also called  BooleanArrays  but contained in the other package (test) has a private constructor. My Launcher configuration is the following:   Is there something wrong with my configuration ? I managed to instrument several other projects but not this one.  Tell me if you need any other information. An archive containing this project is available  here . Thank you  Thibault", "A_clean_title": ["except", "at", "compil", "due", "constructor", "privat", "visibilityhello", "visibl", "hello", "im", "have", "issu", "while", "instrument", "sourc", "code", "assertj", "assert", "spoon", "instrument", "part", "will", "work", "but", "compil", "part", "will", "fail", "due", "follow", "error", "creat", "small", "maven", "project", "part", "assertj", "assert", "sourc", "code", "that", "not", "instrument", "compil", "spoon", "project", "architectur", "follow", "accord", "except", "messag", "problem", "come", "class", "booleanarraysbasetest", "boolean", "array", "base", "test", "which", "contain", "follow", "code", "statement", "array", "new", "booleanarray", "boolean", "array", "refer", "booleanarray", "boolean", "array", "class", "contain", "same", "packag", "intern", "which", "singleton", "have", "constructor", "packag", "visibl", "other", "class", "also", "call", "booleanarray", "boolean", "array", "but", "contain", "other", "packag", "test", "ha", "privat", "constructor", "my", "launcher", "configur", "follow", "there", "someth", "wrong", "my", "configur", "manag", "instrument", "sever", "other", "project", "but", "not", "thi", "one", "tell", "me", "you", "need", "ani", "other", "inform", "archiv", "contain", "thi", "project", "avail", "here", "thank", "you", "thibault"], "B_title": "fix: fix bug in import inference (auto-import mode). Close #1306. (#1308)", "B_clean_title": ["fix", "fix", "bug", "import", "infer", "auto", "import", "mode", "close", "1306", "1308"]},
{"A_title": "InlineEnclosure are piling up on each renderInlineEnclosureHandler#resolve() uses an auto-incremented id for its resolved InlineEnclosure   On the next render a new instance will be resolved since the id of the already resolved InlineEnclosure does not match the id in the markup.  But InlineEnclosures are not removed after render as other auto-components thus all instances pile up in the owning container of the markup.", "A_clean_title": ["inlineenclosur", "inlin", "enclosur", "are", "pile", "up", "each", "renderinlineenclosurehandl", "render", "inlin", "enclosur", "handler", "resolv", "use", "auto", "increment", "id", "it", "resolv", "inlineenclosur", "inlin", "enclosur", "next", "render", "new", "instanc", "will", "resolv", "sinc", "id", "alreadi", "resolv", "inlineenclosur", "inlin", "enclosur", "not", "match", "id", "markup", "but", "inlineenclosur", "inlin", "enclosur", "are", "not", "remov", "after", "render", "as", "other", "auto", "compon", "thu", "all", "instanc", "pile", "up", "own", "contain", "markup"], "B_title": "make id of enclosure stable in markup so that InlineEnclosure is resolved once only", "B_clean_title": ["make", "id", "enclosur", "stabl", "markup", "so", "that", "inlineenclosur", "inlin", "enclosur", "resolv", "onc", "onli"]},
{"A_title": "Stateless/Statefull pages - incorrect behaviourPlease advise how to do in following situation or confirm thats a bug and should be fixed.  There is a page (login page) with stateless form. That page has lots of common components (menu and etc.). There are some stateful components in the components tree that are visible only for signed in users: but once user isnt signed in - that components are hidden. Thats why page is becoming stateless (no visible components) and form prepared correspondingly. But when form data is submitted: during obtaining of form component to process request - wicket thinks that page actually is stateful. As a result - the page is recreated and fully rendered - instead of processing of the form.  There is a workaround: setStatelessHint(false). But imho reason is a little bit another: 1) After construction of page: page is stateful - because of some stateful components are in the tree. 2) After initialization of page: page is still stateful - because there are that stateful components 3) After configuration of page (method onConfigure) - page is becoming stateless - because all stateful components marked as invisible. 4) Form has been rendered as stateless - with no version number is in the URL. 5) Page canbe reconstructed correctly because of p.1 and p.2  I think that stateless flag should be precalculated right after initialization step and should be changed due to some stuff in configuration methods.  What do you think?  Will provide quick start in near future!", "A_clean_title": ["stateless", "stateful", "page", "incorrect", "behaviourpleas", "behaviour", "pleas", "advis", "how", "follow", "situat", "or", "confirm", "that", "bug", "fix", "there", "page", "login", "page", "stateless", "form", "that", "page", "ha", "lot", "common", "compon", "menu", "etc", "there", "are", "some", "state", "compon", "compon", "tree", "that", "are", "visibl", "onli", "sign", "user", "but", "onc", "user", "isnt", "sign", "that", "compon", "are", "hidden", "that", "whi", "page", "becom", "stateless", "no", "visibl", "compon", "form", "prepar", "correspondingli", "but", "when", "form", "data", "submit", "dure", "obtain", "form", "compon", "process", "request", "wicket", "think", "that", "page", "actual", "state", "as", "result", "page", "recreat", "fulli", "render", "instead", "process", "form", "there", "workaround", "setstatelesshint", "set", "stateless", "hint", "fals", "but", "imho", "reason", "littl", "bit", "anoth", "after", "construct", "page", "page", "state", "becaus", "some", "state", "compon", "are", "tree", "after", "initi", "page", "page", "still", "state", "becaus", "there", "are", "that", "state", "compon", "after", "configur", "page", "method", "onconfigur", "configur", "page", "becom", "stateless", "becaus", "all", "state", "compon", "mark", "as", "invis", "form", "ha", "been", "render", "as", "stateless", "no", "version", "number", "url", "page", "canb", "reconstruct", "correctli", "becaus", "think", "that", "stateless", "flag", "precalcul", "right", "after", "initi", "step", "chang", "due", "some", "stuff", "configur", "method", "what", "you", "think", "will", "provid", "quick", "start", "near", "futur"], "B_title": "Stateless/Statefull pages - incorrect behaviour", "B_clean_title": ["stateless", "stateful", "page", "incorrect", "behaviour"]},
{"A_title": "TimestampFilter should serialize start and end as longs in the IteratorSettingAlthough the TimestampFilter supports using longs to set the start or end timestamp it formats them as strings using SimpleDateFormat when storing or retrieving them in the IteratorSetting.  This results in exceptions when the timestamps being used arent able to be formatted as _yyyyMMddHHmmssz_. For example try setEnd(253402300800001true)  Instead setStart() and setEnd() could just as easily use String.valueOf(long i) to store the values and init() could retrieve them using Long.valueOf(String s).", "A_clean_title": ["timestampfilt", "timestamp", "filter", "serial", "start", "end", "as", "long", "iteratorsettingalthough", "iter", "set", "although", "timestampfilt", "timestamp", "filter", "support", "long", "set", "start", "or", "end", "timestamp", "it", "format", "them", "as", "string", "simpledateformat", "simpl", "date", "format", "when", "store", "or", "retriev", "them", "iteratorset", "iter", "set", "thi", "result", "except", "when", "timestamp", "be", "use", "arent", "abl", "format", "as", "yyyymmddhhmmssz", "yyyi", "mdd", "hmmssz", "exampl", "tri", "setend", "set", "end", "253402300800001true", "instead", "setstart", "set", "start", "setend", "set", "end", "could", "just", "as", "easili", "use", "string", "valueof", "valu", "long", "store", "valu", "init", "could", "retriev", "them", "long", "valueof", "valu", "string"], "B_title": "made timestamp filter support longs greater than max date - merged to trunk", "B_clean_title": ["made", "timestamp", "filter", "support", "long", "greater", "than", "max", "date", "merg", "trunk"]},
{"A_title": "1.10 regression (StackOverflowError) with interface where generic type has itself as upper bound.None", "A_clean_title": ["10", "regress", "stackoverflowerror", "stack", "overflow", "error", "interfac", "where", "gener", "type", "ha", "itself", "as", "upper", "bound", "none"], "B_title": "Fixes issue #114", "B_clean_title": ["fix", "issu", "114"]},
{"A_title": "@JsonProperty(access = READ_ONLY) together with generated constructor (lombok) causes JsonMappingException: Could not find creator property with name ...The following class fails to deserialise with a  com.fasterxml.jackson.databind.JsonMappingException: Could not find creator property with name s (in class LombokObject) :  Whereas the following class - which is functionally identical but with constructors getters and setters in the code - can be deserialised:   The exception is", "A_clean_title": ["jsonproperti", "json", "properti", "access", "read", "onli", "togeth", "gener", "constructor", "lombok", "caus", "jsonmappingexcept", "json", "map", "except", "could", "not", "find", "creator", "properti", "name", "follow", "class", "fail", "deserialis", "com", "fasterxml", "jackson", "databind", "jsonmappingexcept", "json", "map", "except", "could", "not", "find", "creator", "properti", "name", "class", "lombokobject", "lombok", "object", "wherea", "follow", "class", "which", "function", "ident", "but", "constructor", "getter", "setter", "code", "deserialis", "except"], "B_title": "Fixed #1345", "B_clean_title": ["fix", "1345"]},
{"A_title": "Make Mockito JUnit rule easier to useMockito JUnit rule easier to use by avoiding the need to pass test instance. Make it compatible with JUnit 4.7+ instead of 4.9+.", "A_clean_title": ["make", "mockito", "junit", "unit", "rule", "easier", "usemockito", "use", "mockito", "junit", "unit", "rule", "easier", "use", "by", "avoid", "need", "pass", "test", "instanc", "make", "it", "compat", "junit", "unit", "7+", "instead", "9+"], "B_title": "Inform the user immediately when she tries to callRealMethod() on a mock of a interface. Fixed issue 140", "B_clean_title": ["inform", "user", "immedi", "when", "she", "tri", "callrealmethod", "call", "real", "method", "mock", "interfac", "fix", "issu", "140"]},
{"A_title": "ValueFactory: Missing identifier validation when creating (weak)reference value from Stringthe JCR specification mandates validation of the identifier during value conversion from STRING to REFERENCE or WEAK_REFERENCE:  <quote from 3.6.4.1 From STRING To)> REFERENCE or WEAKREFERENCE: If the string is a syntactically valid  identifier according to the implementation it is converted directly otherwise a  ValueFormatException is thrown. The identifier is not required to be that of an  existing node in the current workspace.  <end_quote>  the current ValueFactory implementation in oak-jcr lacks that validation: creating a REFERENCE or WEAKREFERENCE value using ValueFactory#createValue(String int) succeeds even if the specified string isnt a valid referenceable node identifier.", "A_clean_title": ["valuefactori", "valu", "factori", "miss", "identifi", "valid", "when", "creat", "weak", "refer", "valu", "stringth", "jcr", "specif", "mandat", "valid", "identifi", "dure", "valu", "convers", "string", "refer", "or", "weak", "refer", "quot", "string", "refer", "or", "weakrefer", "string", "syntact", "valid", "identifi", "accord", "implement", "it", "convert", "directli", "otherwis", "valueformatexcept", "valu", "format", "except", "thrown", "identifi", "not", "requir", "that", "exist", "node", "current", "workspac", "end", "quot", "current", "valuefactori", "valu", "factori", "implement", "oak", "jcr", "lack", "that", "valid", "creat", "refer", "or", "weakrefer", "valu", "valuefactori", "valu", "factori", "createvalu", "creat", "valu", "string", "int", "succe", "even", "specifi", "string", "isnt", "valid", "referenc", "node", "identifi"], "B_title": "ValueFactory: Missing identifier validation when creating (weak)reference value from String", "B_clean_title": ["valuefactori", "valu", "factori", "miss", "identifi", "valid", "when", "creat", "weak", "refer", "valu", "string"]},
{"A_title": "MathUtils round method should propagate rather than wrap Runitme exceptionsMathUtils.round(double int int) can generate IllegalArgumentException or ArithmeticException.  Instead of wrapping these exceptions in MathRuntimeException the conditions under which these exceptions can be thrown should be documented and the exceptions should be propagated directly to the caller.", "A_clean_title": ["mathutil", "math", "util", "round", "method", "propag", "rather", "than", "wrap", "runitm", "exceptionsmathutil", "round", "except", "math", "util", "doubl", "int", "int", "gener", "illegalargumentexcept", "illeg", "argument", "except", "or", "arithmeticexcept", "arithmet", "except", "instead", "wrap", "these", "except", "mathruntimeexcept", "math", "runtim", "except", "condit", "under", "which", "these", "except", "thrown", "document", "except", "propag", "directli", "caller"], "B_title": "Changed MathUtils.round(doubleintint) to propagate rather than wrap runtime exceptions.  Instead of MathRuntimeException this method now throws IllegalArgumentException or ArithmeticException under the conditions specified in the javadoc. JIRA: MATH-555", "B_clean_title": ["chang", "mathutil", "round", "math", "util", "doubleintint", "propag", "rather", "than", "wrap", "runtim", "except", "instead", "mathruntimeexcept", "math", "runtim", "except", "thi", "method", "now", "throw", "illegalargumentexcept", "illeg", "argument", "except", "or", "arithmeticexcept", "arithmet", "except", "under", "condit", "specifi", "javadoc", "jira", "math", "555"]},
{"A_title": "Incompatible API changes in 1.6.0While examining API changes for 1.6.0 I noticed some non-deprecated methods were removed.  I am not sure how important these are but technically these methods are in the public API.  Opening this issue to document what I found.  I compared 1.6.0 to 1.5.0.  In ACCUMULO-1674 the following methods were removed  noformat package org.apache.accumulo.core.client.mapreduce.lib.util ConfiguratorBase.getToken ( Class<?> Configuration ) static  :  byte  ConfiguratorBase.getTokenClass ( Class<?> Configuration) static  :  String noformat  In ACCUMULO-391 the following method was removed  noformat package org.apache.accumulo.core.client.mapreduce.lib.util InputConfigurator.getTabletLocator ( Class<?> Configuration ) static  : TabletLocator  noformat  In ACCUMULO-391 the following method was removed and not properly fixed in ACCUMULO-2586  noformat accumulo-core.jar RangeInputSplit.class package org.apache.accumulo.core.client.mapred InputFormatBase.RangeInputSplit.InputFormatBase.RangeInputSplit ( String table Range range String  locations ) package org.apache.accumulo.core.client.mapreduce InputFormatBase.RangeInputSplit.InputFormatBase.RangeInputSplit ( String table Range range String  locations )  noformat   It seems like the following were removed in ACCUMULO-1854   noformat package org.apache.accumulo.core.client.mapred InputFormatBase.RecordReaderBase<K.setupIterators (JobConf job Scanner scanner )  :  void package org.apache.accumulo.core.client.mapreduce InputFormatBase.RecordReaderBase<K.setupIterators (TaskAttemptContext context Scanner scanner)  :  void noformat  In ACCUMULO-1018 the following method was removed  noformat package org.apache.accumulo.core.client MutationsRejectedException.MutationsRejectedException ( List HashMap Set Collection int cause Throwable cvsList )  noformat", "A_clean_title": ["incompat", "api", "chang", "0while", "examin", "api", "chang", "notic", "some", "non", "deprec", "method", "were", "remov", "am", "not", "sure", "how", "import", "these", "are", "but", "technic", "these", "method", "are", "public", "api", "open", "thi", "issu", "document", "what", "found", "compar", "accumulo", "1674", "follow", "method", "were", "remov", "noformat", "packag", "org", "apach", "accumulo", "core", "client", "mapreduc", "lib", "util", "configuratorbas", "gettoken", "configur", "base", "get", "token", "class", "configur", "static", "byte", "configuratorbas", "gettokenclass", "configur", "base", "get", "token", "class", "class", "configur", "static", "string", "noformat", "accumulo", "391", "follow", "method", "wa", "remov", "noformat", "packag", "org", "apach", "accumulo", "core", "client", "mapreduc", "lib", "util", "inputconfigur", "gettabletloc", "input", "configur", "get", "tablet", "locat", "class", "configur", "static", "tabletloc", "tablet", "locat", "noformat", "accumulo", "391", "follow", "method", "wa", "remov", "not", "properli", "fix", "accumulo", "2586", "noformat", "accumulo", "core", "jar", "rangeinputsplit", "class", "rang", "input", "split", "packag", "org", "apach", "accumulo", "core", "client", "mapr", "inputformatbas", "rangeinputsplit", "inputformatbas", "rangeinputsplit", "input", "format", "base", "rang", "input", "split", "input", "format", "base", "rang", "input", "split", "string", "tabl", "rang", "rang", "string", "locat", "packag", "org", "apach", "accumulo", "core", "client", "mapreduc", "inputformatbas", "rangeinputsplit", "inputformatbas", "rangeinputsplit", "input", "format", "base", "rang", "input", "split", "input", "format", "base", "rang", "input", "split", "string", "tabl", "rang", "rang", "string", "locat", "noformat", "it", "seem", "like", "follow", "were", "remov", "accumulo", "1854", "noformat", "packag", "org", "apach", "accumulo", "core", "client", "mapr", "inputformatbas", "recordreaderbas", "input", "format", "base", "record", "reader", "base", "setupiter", "setup", "iter", "jobconf", "job", "conf", "job", "scanner", "scanner", "void", "packag", "org", "apach", "accumulo", "core", "client", "mapreduc", "inputformatbas", "recordreaderbas", "input", "format", "base", "record", "reader", "base", "setupiter", "setup", "iter", "taskattemptcontext", "task", "attempt", "context", "context", "scanner", "scanner", "void", "noformat", "accumulo", "1018", "follow", "method", "wa", "remov", "noformat", "packag", "org", "apach", "accumulo", "core", "client", "mutationsrejectedexcept", "mutationsrejectedexcept", "mutat", "reject", "except", "mutat", "reject", "except", "list", "hashmap", "hash", "map", "set", "collect", "int", "caus", "throwabl", "cvslist", "cv", "list", "noformat"], "B_title": "Fall back to the configuration when the iterator setting arent in the split", "B_clean_title": ["fall", "back", "configur", "when", "iter", "set", "arent", "split"]},
{"A_title": "MountMapper does not support correctly parameter placeholdersPackage mounting doesnt support parameter placeholders. The problem seems to be inside MountMapper which should wrap PackageMapper and take care of substituting placeholders with their actual value.  More precisely this class doesnt read parameter values from PageParameters and its not very clear to me how it tries to read these values. Does anybody have some hints about this class?", "A_clean_title": ["mountmapp", "mount", "mapper", "not", "support", "correctli", "paramet", "placeholderspackag", "placehold", "packag", "mount", "doesnt", "support", "paramet", "placehold", "problem", "seem", "insid", "mountmapp", "mount", "mapper", "which", "wrap", "packagemapp", "packag", "mapper", "take", "care", "substitut", "placehold", "their", "actual", "valu", "more", "precis", "thi", "class", "doesnt", "read", "paramet", "valu", "pageparamet", "page", "paramet", "it", "not", "veri", "clear", "me", "how", "it", "tri", "read", "these", "valu", "anybodi", "have", "some", "hint", "about", "thi", "class"], "B_title": "MountMapper does not support correctly parameter placeholders", "B_clean_title": ["mountmapp", "mount", "mapper", "not", "support", "correctli", "paramet", "placehold"]},
{"A_title": "Component Use Check always fails for visible components inside an invisible border bodyNone", "A_clean_title": ["compon", "use", "check", "alway", "fail", "visibl", "compon", "insid", "invis", "border", "bodynon", "bodi", "none"], "B_title": "", "B_clean_title": []},
{"A_title": "Incomplete journal when move and copy operations are involvedGiven a node at /source:  code head = mk.commit(/     >source : moved +     *moved : copy     head ); code  results in the following journal:  code >/source:/copy code  where the freshly created node at /moved is missing.  Similarly   code head = mk.commit(/     *source : copy +     >copy : moved     head ); code  results in  code +/moved: code  where moved away node at /source is missing.", "A_clean_title": ["incomplet", "journal", "when", "move", "copi", "oper", "are", "involvedgiven", "involv", "given", "node", "at", "sourc", "code", "head", "mk", "commit", "sourc", "move", "move", "copi", "head", "code", "result", "follow", "journal", "code", "sourc", "copi", "code", "where", "freshli", "creat", "node", "at", "move", "miss", "similarli", "code", "head", "mk", "commit", "sourc", "copi", "copi", "move", "head", "code", "result", "code", "move", "code", "where", "move", "away", "node", "at", "sourc", "miss"], "B_title": "Incomplete journal when move and copy operations are involved", "B_clean_title": ["incomplet", "journal", "when", "move", "copi", "oper", "are", "involv"]},
{"A_title": "Value implementation provides conflicting statementsThe javadoc for the no-arg constructor for Value states that it Creates a zero-size sequence. However the implementation of get will error in this case. code public byte get()      if (this.value == null)        throw new IllegalStateException(Uninitialized. Null constructor  + called w/o accompanying readFields invocation);      code  Either we need to change the javadoc to be more explicit or change the behaviour of various accessors in the class. I would consider both solutions to be breaking of the API contract since we are changing what clients can expect from us.", "A_clean_title": ["valu", "implement", "provid", "conflict", "statementsth", "statement", "javadoc", "no", "arg", "constructor", "valu", "state", "that", "it", "creat", "zero", "size", "sequenc", "howev", "implement", "get", "will", "error", "thi", "case", "code", "public", "byte", "get", "thi", "valu", "null", "throw", "new", "illegalstateexcept", "illeg", "state", "except", "uniniti", "null", "constructor", "call", "accompani", "readfield", "read", "field", "invoc", "code", "either", "we", "need", "chang", "javadoc", "more", "explicit", "or", "chang", "behaviour", "variou", "accessor", "class", "would", "consid", "both", "solut", "break", "api", "contract", "sinc", "we", "are", "chang", "what", "client", "expect", "us"], "B_title": "match Value implementation to javadocs. check for null args.", "B_clean_title": ["match", "valu", "implement", "javadoc", "check", "null", "arg"]},
{"A_title": "DocumentNodeStore revision GC may lead to NPEThe DocumentNodeStore revision GC may cause a NPE in a reader thread when the GC deletes documents currently accessed by the reader. The docChildrenCache is invalidated in VersionGarbageCollector.collectDeletedDocuments() after documents are removed in the DocumentStore. The NPE may occur if removed documents are access in between.", "A_clean_title": ["documentnodestor", "document", "node", "store", "revis", "gc", "may", "lead", "npeth", "npe", "documentnodestor", "document", "node", "store", "revis", "gc", "may", "caus", "npe", "reader", "thread", "when", "gc", "delet", "document", "current", "access", "by", "reader", "docchildrencach", "doc", "children", "cach", "invalid", "versiongarbagecollector", "collectdeleteddocu", "version", "garbag", "collector", "collect", "delet", "document", "after", "document", "are", "remov", "documentstor", "document", "store", "npe", "may", "occur", "remov", "document", "are", "access", "between"], "B_title": "DocumentNodeStore revision GC may lead to NPE", "B_clean_title": ["documentnodestor", "document", "node", "store", "revis", "gc", "may", "lead", "npe"]},
{"A_title": "getMarkupId() can be used only if the components markup is attachedWith change r1037139 Component#getMarkupImpl() first tries to get the markup id from the components markup. If the markup is not available/attached yet for this component the call ends with : org.apache.wicket.markup.MarkupException: Can not determine Markup. Component is not yet connected to a parent. Component id = label", "A_clean_title": ["getmarkupid", "get", "markup", "id", "use", "onli", "compon", "markup", "attachedwith", "attach", "chang", "r1037139", "compon", "getmarkupimpl", "get", "markup", "impl", "first", "tri", "get", "markup", "id", "compon", "markup", "markup", "not", "avail", "attach", "yet", "thi", "compon", "call", "end", "org", "apach", "wicket", "markup", "markupexcept", "markup", "except", "not", "determin", "markup", "compon", "not", "yet", "connect", "parent", "compon", "id", "label"], "B_title": "fixed WICKET-3197: addOrReplace() failed with exception while copying markupId Issue: WICKET-3197", "B_clean_title": ["fix", "wicket", "3197", "addorreplac", "add", "or", "replac", "fail", "except", "while", "copi", "markupid", "markup", "id", "issu", "wicket", "3197"]},
{"A_title": "Bugs in DatasetUtilities.iterateRangeBounds() methodsNone", "A_clean_title": ["bug", "datasetutil", "iteraterangebound", "dataset", "util", "iter", "rang", "bound", "methodsnon", "method", "none"], "B_title": "source/org/jfree/chart/DatasetUtilities.java (iterateRangeBounds(XYDataste boolean)): For IntervalXYDataset include regular value and account for nulls / Double.NaN.", "B_clean_title": ["java", "sourc", "org", "jfree", "chart", "datasetutil", "dataset", "util", "iteraterangebound", "iter", "rang", "bound", "xydatast", "xy", "datast", "boolean", "intervalxydataset", "interv", "xy", "dataset", "includ", "regular", "valu", "account", "null", "doubl", "nan", "na"]},
{"A_title": "Range queries and relative properties resultset should be consistent with JR2When running a range query like /jcr:root/content/nodes//*(*/*/*/@prop >= 9) the resultset is not consistent for the same use-case when running in jacrabbit 2.", "A_clean_title": ["rang", "queri", "rel", "properti", "resultset", "consist", "jr2when", "run", "rang", "queri", "like", "jcr", "root", "content", "node", "prop", "resultset", "not", "consist", "same", "use", "case", "when", "run", "jacrabbit"], "B_title": "Range queries and relative properties resultset should be consistent with JR2", "B_clean_title": ["rang", "queri", "rel", "properti", "resultset", "consist", "jr2"]},
{"A_title": "possibly a bug in org.joda.time.field.FieldUtils.safeMultiplyIt seems to me that as currently written in joda-time-2.1.jar org.joda.time.field.FieldUtils.safeMultiply(long val1 int scalar) doesnt detect the overflow if the long val1 == Long.MIN_VALUE and the int scalar == -1.  The attached file demonstrates what I think is the bug and suggests a patch.  I looked at the Joda Time bugs list in SourceForge but couldnt see anything that looked relevant.", "A_clean_title": ["possibl", "bug", "org", "joda", "time", "field", "fieldutil", "safemultiplyit", "field", "util", "safe", "multipli", "it", "seem", "me", "that", "as", "current", "written", "joda", "time", "jar", "org", "joda", "time", "field", "fieldutil", "safemultipli", "field", "util", "safe", "multipli", "long", "val1", "int", "scalar", "doesnt", "detect", "overflow", "long", "val1", "long", "min", "valu", "int", "scalar", "attach", "file", "demonstr", "what", "think", "bug", "suggest", "patch", "look", "at", "joda", "time", "bug", "list", "sourceforg", "sourc", "forg", "but", "couldnt", "see", "anyth", "that", "look", "relev"], "B_title": "FieldUtils.safeMultiply(longint) 3520651", "B_clean_title": ["fieldutil", "safemultipli", "field", "util", "safe", "multipli", "longint", "3520651"]},
{"A_title": "StringIndexOutOfBoundsException when calling unescapeHtml4(&#03)When calling unescapeHtml4() on the String &#03 (or any String that contains these characters) an Exception is thrown: Exception in thread main java.lang.StringIndexOutOfBoundsException: String index out of range: 4 at java.lang.String.charAt(String.java:686) at org.apache.commons.lang3.text.translate.NumericEntityUnescaper.translate(NumericEntityUnescaper.java:49) at org.apache.commons.lang3.text.translate.AggregateTranslator.translate(AggregateTranslator.java:53) at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:88) at org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:60) at org.apache.commons.lang3.StringEscapeUtils.unescapeHtml4(StringEscapeUtils.java:351)", "A_clean_title": ["stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "when", "call", "unescapehtml4", "unescap", "html4", "03", "when", "call", "unescapehtml4", "unescap", "html4", "string", "03", "or", "ani", "string", "that", "contain", "these", "charact", "except", "thrown", "except", "thread", "main", "java", "lang", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "string", "index", "out", "rang", "at", "java", "lang", "string", "charat", "char", "at", "string", "java:686", "at", "org", "apach", "common", "lang3", "text", "translat", "numericentityunescap", "translat", "numer", "entiti", "unescap", "numericentityunescap", "java:49", "numer", "entiti", "unescap", "at", "org", "apach", "common", "lang3", "text", "translat", "aggregatetransl", "translat", "aggreg", "translat", "aggregatetransl", "java:53", "aggreg", "translat", "at", "org", "apach", "common", "lang3", "text", "translat", "charsequencetransl", "translat", "char", "sequenc", "translat", "charsequencetransl", "java:88", "char", "sequenc", "translat", "at", "org", "apach", "common", "lang3", "text", "translat", "charsequencetransl", "translat", "char", "sequenc", "translat", "charsequencetransl", "java:60", "char", "sequenc", "translat", "at", "org", "apach", "common", "lang3", "stringescapeutil", "unescapehtml4", "string", "escap", "util", "unescap", "html4", "stringescapeutil", "java:351", "string", "escap", "util"], "B_title": "Adding tests and resolving LANG-710 reported by Benjamin Valentin. Note that this changed such that the code will now escape an unfinished entity (i.e. &#030). This matches browser behaviour.", "B_clean_title": ["ad", "test", "resolv", "lang", "710", "report", "by", "benjamin", "valentin", "note", "that", "thi", "chang", "such", "that", "code", "will", "now", "escap", "unfinish", "entiti", "030", "thi", "match", "browser", "behaviour"]},
{"A_title": "BooleanUtils.toBoolean() - invalid drop-thru in case statement causes StringIndexOutOfBoundsExceptionThe method BooleanUtils.toBoolean() has a case statement; case 3 drops through to case 4; this can cause StringIndexOutOfBoundsException for example with the test: assertEquals(false BooleanUtils.toBoolean(tru)); The end of case 3 should return false. Patch to follow for source and unit test.", "A_clean_title": ["booleanutil", "toboolean", "boolean", "util", "boolean", "invalid", "drop", "thru", "case", "statement", "caus", "stringindexoutofboundsexceptionth", "string", "index", "out", "bound", "except", "method", "booleanutil", "toboolean", "boolean", "util", "boolean", "ha", "case", "statement", "case", "drop", "through", "case", "thi", "caus", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "exampl", "test", "assertequ", "assert", "equal", "fals", "booleanutil", "toboolean", "boolean", "util", "boolean", "tru", "end", "case", "return", "fals", "patch", "follow", "sourc", "unit", "test"], "B_title": "Applying Sebbs test and fix for LANG-365", "B_clean_title": ["appli", "sebb", "test", "fix", "lang", "365"]},
{"A_title": "java.lang.StringIndexOutOfBoundsException in ComplexFormat.parse(String source ParsePosition pos)The parse(String source ParsePosition pos) method in the ComplexFormat class does not check whether the imaginary character is set or not which produces StringIndexOutOfBoundsException in the substring method : (line 375 of ComplexFormat) ...         // parse imaginary character         int n = getImaginaryCharacter().length();         startIndex = pos.getIndex();         int endIndex = startIndex + n;         if (source.substring(startIndex endIndex).compareTo(             getImaginaryCharacter()) != 0)  ... I encoutered this exception typing in a JTextFied with ComplexFormat set to look up an AbstractFormatter. If only the user types the imaginary part of the complex number first he gets this exception. Solution: Before setting to n length of the imaginary character check if the source contains it. My proposal: ...         int n = 0;         if (source.contains(getImaginaryCharacter()))         n = getImaginaryCharacter().length(); ...  F.S.", "A_clean_title": ["java", "lang", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "complexformat", "pars", "complex", "format", "string", "sourc", "parseposit", "pars", "posit", "po", "pars", "string", "sourc", "parseposit", "pars", "posit", "po", "method", "complexformat", "complex", "format", "class", "not", "check", "whether", "imaginari", "charact", "set", "or", "not", "which", "produc", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "substr", "method", "line", "375", "complexformat", "complex", "format", "pars", "imaginari", "charact", "int", "getimaginarycharact", "get", "imaginari", "charact", "length", "startindex", "start", "index", "po", "getindex", "get", "index", "int", "endindex", "end", "index", "startindex", "start", "index", "sourc", "substr", "startindex", "start", "index", "endindex", "end", "index", "compareto", "compar", "getimaginarycharact", "get", "imaginari", "charact", "encout", "thi", "except", "type", "jtextfi", "text", "fie", "complexformat", "complex", "format", "set", "look", "up", "abstractformatt", "abstract", "formatt", "onli", "user", "type", "imaginari", "part", "complex", "number", "first", "he", "get", "thi", "except", "solut", "befor", "set", "length", "imaginari", "charact", "check", "sourc", "contain", "it", "my", "propos", "int", "sourc", "contain", "getimaginarycharact", "get", "imaginari", "charact", "getimaginarycharact", "get", "imaginari", "charact", "length"], "B_title": "added an error detection for missing imaginary character while parsing complex string JIRA: MATH-198", "B_clean_title": ["ad", "error", "detect", "miss", "imaginari", "charact", "while", "pars", "complex", "string", "jira", "math", "198"]},
{"A_title": "issue with isOverriding behavior when extending TypeParametersIf you consider the interface  Iterable<E> which contain a method forEach(Consumer<? super E>) and if you create a class with a T extends String which implements Iterable<T>  then you implement your own version of forEach : if you use ClassTypingContext.isSameSignature() on the two forEach methods it will return false because they do not have the same type parameter. Im really not sure if this is a bug or not: in the overriding method the type parameter is more defined so the signature is not exactly the same. But then if we only use  isSameSignature in getAllMethods (see #1375 ) we will get both Iterable#forEach and ArrayList#forEach  when using it on ArrayList . WDYT? Should we consider the signature are the same or should we consider that  getAllMethods should indeed return the two different methods? Edit: Actually I extended my test to check with  isOverriding and it returns false which is obviously wrong. So theres a real issue here.", "A_clean_title": ["issu", "isoverrid", "overrid", "behavior", "when", "extend", "typeparametersif", "type", "paramet", "you", "consid", "interfac", "iter", "which", "contain", "method", "foreach", "each", "consum", "super", "you", "creat", "class", "extend", "string", "which", "implement", "iter", "then", "you", "implement", "your", "own", "version", "foreach", "each", "you", "use", "classtypingcontext", "issamesignatur", "class", "type", "context", "same", "signatur", "two", "foreach", "each", "method", "it", "will", "return", "fals", "becaus", "they", "not", "have", "same", "type", "paramet", "im", "realli", "not", "sure", "thi", "bug", "or", "not", "overrid", "method", "type", "paramet", "more", "defin", "so", "signatur", "not", "exactli", "same", "but", "then", "we", "onli", "use", "issamesignatur", "same", "signatur", "getallmethod", "get", "all", "method", "see", "1375", "we", "will", "get", "both", "iter", "foreach", "each", "arraylist", "array", "list", "foreach", "each", "when", "it", "arraylist", "array", "list", "wdyt", "we", "consid", "signatur", "are", "same", "or", "we", "consid", "that", "getallmethod", "get", "all", "method", "inde", "return", "two", "differ", "method", "edit", "actual", "extend", "my", "test", "check", "isoverrid", "overrid", "it", "return", "fals", "which", "obvious", "wrong", "so", "there", "real", "issu", "here"], "B_title": "fix: fix issue in ClassTypingContext#isOverriding (#1411)  close #1407", "B_clean_title": ["fix", "fix", "issu", "classtypingcontext", "class", "type", "context", "isoverrid", "overrid", "1411", "close", "1407"]},
{"A_title": "MongoMK GC removes documents with data still in useThe version garbage collector may delete previous documents that contain commit root information still in use by the main document.", "A_clean_title": ["mongomk", "mongo", "mk", "gc", "remov", "document", "data", "still", "useth", "use", "version", "garbag", "collector", "may", "delet", "previou", "document", "that", "contain", "commit", "root", "inform", "still", "use", "by", "main", "document"], "B_title": "MongoMK GC removes documents with data still in use", "B_clean_title": ["mongomk", "mongo", "mk", "gc", "remov", "document", "data", "still", "use"]},
{"A_title": "combining @interface and multiple @extends can crash compilerNone", "A_clean_title": ["combin", "interfac", "multipl", "extend", "crash", "compilernon", "compil", "none"], "B_title": "Fix null pointer bug encountered when trying to extend non-existent interfaces.", "B_clean_title": ["fix", "null", "pointer", "bug", "encount", "when", "tri", "extend", "non", "exist", "interfac"]},
{"A_title": "NullPointerException in SimplexTableau.initializeSimplexTableau throws a NullPointerException when no solution can be found instead of a NoFeasibleSolutionException  Here is the code that causes the NullPointerException:  LinearObjectiveFunction f = new LinearObjectiveFunction(new double  1 5  0 ); Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>(); constraints.add(new LinearConstraint(new double  2 0  Relationship.GEQ -1.0));  RealPointValuePair solution = new SimplexSolver().optimize(f constraints GoalType.MINIMIZE true);  Note: Tested both with Apache Commons Math 2.0 release and SVN trunk", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "simplextableau", "initializesimplextableau", "simplex", "tableau", "initi", "simplex", "tableau", "throw", "nullpointerexcept", "null", "pointer", "except", "when", "no", "solut", "found", "instead", "nofeasiblesolutionexcept", "no", "feasibl", "solut", "except", "here", "code", "that", "caus", "nullpointerexcept", "null", "pointer", "except", "linearobjectivefunct", "linear", "object", "function", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "constraint", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "realpointvaluepair", "real", "point", "valu", "pair", "solut", "new", "simplexsolv", "simplex", "solver", "optim", "constraint", "goaltyp", "minim", "goal", "type", "true", "note", "test", "both", "apach", "common", "math", "releas", "svn", "trunk"], "B_title": "fixed an error with negative constraints and unfeasible solution JIRA: MATH-290", "B_clean_title": ["fix", "error", "neg", "constraint", "unfeas", "solut", "jira", "math", "290"]},
{"A_title": "NodeDocument.getNodeAtRevision can go into property history traversal when latest rev on current doc isnt committedNodeDocument.getNodeAtRevision tried to look at latest revisions entries for each property in current document. But it just looks at the *last* entry for a given property. In case this last entry isnt committed the code would go into previous documents to look for a committed value.  (cc ~mreutegg)", "A_clean_title": ["nodedocu", "getnodeatrevis", "node", "document", "get", "node", "at", "revis", "go", "into", "properti", "histori", "travers", "when", "latest", "rev", "current", "doc", "isnt", "committednodedocu", "getnodeatrevis", "commit", "node", "document", "get", "node", "at", "revis", "tri", "look", "at", "latest", "revis", "entri", "each", "properti", "current", "document", "but", "it", "just", "look", "at", "last", "entri", "given", "properti", "case", "thi", "last", "entri", "isnt", "commit", "code", "would", "go", "into", "previou", "document", "look", "commit", "valu", "cc", "~mreutegg"], "B_title": "NodeDocument.getNodeAtRevision can go into property history traversal when latest rev on current doc isnt committed", "B_clean_title": ["nodedocu", "getnodeatrevis", "node", "document", "get", "node", "at", "revis", "go", "into", "properti", "histori", "travers", "when", "latest", "rev", "current", "doc", "isnt", "commit"]},
{"A_title": "AuthenticationTokenSecretManager might delete key while ZooAuthenticationKeyWatcher enumerates existing keysNoticed the following race condition.  The secret manager (in the master) on startup will enumerate the old keys used for creating delegation tokens and delete the keys that are expired.  At the same time the watcher (in each tserver) might see some updates to these keys and update the secret manager. Theres a race condition there that the watcher might try to read a key that the secret manager just deleted.  Need to catch the NoNodeException in the watcher and just accept that its ok if one of these children are deleted to avoid a scary error in the monitor.", "A_clean_title": ["authenticationtokensecretmanag", "authent", "token", "secret", "manag", "might", "delet", "key", "while", "zooauthenticationkeywatch", "zoo", "authent", "key", "watcher", "enumer", "exist", "keysnot", "key", "notic", "follow", "race", "condit", "secret", "manag", "master", "startup", "will", "enumer", "old", "key", "use", "creat", "deleg", "token", "delet", "key", "that", "are", "expir", "at", "same", "time", "watcher", "each", "tserver", "might", "see", "some", "updat", "these", "key", "updat", "secret", "manag", "there", "race", "condit", "there", "that", "watcher", "might", "tri", "read", "key", "that", "secret", "manag", "just", "delet", "need", "catch", "nonodeexcept", "no", "node", "except", "watcher", "just", "accept", "that", "it", "ok", "one", "these", "children", "are", "delet", "avoid", "scari", "error", "monitor"], "B_title": "Fix race condition where master might delete node before tserver sees deletion.", "B_clean_title": ["fix", "race", "condit", "where", "master", "might", "delet", "node", "befor", "tserver", "see", "delet"]},
{"A_title": "The Property2Index eagerly and unnecessarily fetches all dataCurrently the Property2Index (as well as the PropertyIndex and the NodeTypeIndex) loads all paths into a hash set. This is even the case for the getCost operation which should be fast and therefore not load too much data.  This strategy can cause ouf-of-memory if the result is too big. Also loading all data is not necessary unless the user reads all rows.  Instead the index should only load data on demand. Also the getCost operation should only estimate the number of read nodes and not actually read the data.", "A_clean_title": ["property2index", "eagerli", "unnecessarili", "fetch", "all", "datacurr", "data", "current", "property2index", "as", "well", "as", "propertyindex", "properti", "index", "nodetypeindex", "node", "type", "index", "load", "all", "path", "into", "hash", "set", "thi", "even", "case", "getcost", "get", "cost", "oper", "which", "fast", "therefor", "not", "load", "too", "much", "data", "thi", "strategi", "caus", "ouf", "memori", "result", "too", "big", "also", "load", "all", "data", "not", "necessari", "unless", "user", "read", "all", "row", "instead", "index", "onli", "load", "data", "demand", "also", "getcost", "get", "cost", "oper", "onli", "estim", "number", "read", "node", "not", "actual", "read", "data"], "B_title": "The Property2Index eagerly and unnecessarily fetches all data: remove unused code (the case where there is no index); make methods static when possible; use PathUtils instead of parsing the path itself", "B_clean_title": ["property2index", "eagerli", "unnecessarili", "fetch", "all", "data", "remov", "unus", "code", "case", "where", "there", "no", "index", "make", "method", "static", "when", "possibl", "use", "pathutil", "path", "util", "instead", "pars", "path", "itself"]},
{"A_title": "Dangerous code in PoissonDistributionImplIn the following excerpt from class PoissonDistributionImpl: PoissonDistributionImpl.java     public PoissonDistributionImpl(double p NormalDistribution z)          super();         setNormal(z);         setMean(p);        (1) Overridable methods are called within the constructor. (2) The reference z is stored and modified within the class. Ive encountered problem (1) in several classes while working on issue 348. In those cases in order to remove potential problems I copied/pasted the body of the setter methods inside the constructor but I think that a more elegant solution would be to remove the setters altogether (i.e. make the classes immutable). Problem (2) can also create unexpected behaviour. Is it really necessary to pass the NormalDistribution object; cant it be always created within the class?", "A_clean_title": ["danger", "code", "poissondistributionimplin", "poisson", "distribut", "impl", "follow", "excerpt", "class", "poissondistributionimpl", "poisson", "distribut", "impl", "poissondistributionimpl", "java", "poisson", "distribut", "impl", "public", "poissondistributionimpl", "poisson", "distribut", "impl", "doubl", "normaldistribut", "normal", "distribut", "super", "setnorm", "set", "normal", "setmean", "set", "mean", "overrid", "method", "are", "call", "within", "constructor", "refer", "store", "modifi", "within", "class", "ive", "encount", "problem", "sever", "class", "while", "work", "issu", "348", "those", "case", "order", "remov", "potenti", "problem", "copi", "past", "bodi", "setter", "method", "insid", "constructor", "but", "think", "that", "more", "eleg", "solut", "would", "remov", "setter", "altogeth", "make", "class", "immut", "problem", "also", "creat", "unexpect", "behaviour", "it", "realli", "necessari", "pass", "normaldistribut", "normal", "distribut", "object", "cant", "it", "alway", "creat", "within", "class"], "B_title": "Removed deprecated methods.", "B_clean_title": ["remov", "deprec", "method"]},
{"A_title": "Chained stream tasks share the same RuntimeContextChained stream operators currently share the same runtimecontext this will certainly lead to problems in the future.   We should create separate runtime contexts for each operator in the chain.", "A_clean_title": ["chain", "stream", "task", "share", "same", "runtimecontextchain", "runtim", "context", "chain", "stream", "oper", "current", "share", "same", "runtimecontext", "thi", "will", "certainli", "lead", "problem", "futur", "we", "creat", "separ", "runtim", "context", "each", "oper", "chain"], "B_title": "streaming Create own context for chained streaming operators", "B_clean_title": ["stream", "creat", "own", "context", "chain", "stream", "oper"]},
{"A_title": "Getter/Setter recognition for POJO fields with generics is not workingFields like code private List<Contributors> contributors; code  Are not recognized correctly even if they have getters and setters. Workaround: make them public.", "A_clean_title": ["getter", "setter", "recognit", "pojo", "field", "gener", "not", "workingfield", "work", "field", "like", "code", "privat", "list", "contributor", "contributor", "code", "are", "not", "recogn", "correctli", "even", "they", "have", "getter", "setter", "workaround", "make", "them", "public"], "B_title": "Fixed getter/setter recognition for POJOs", "B_clean_title": ["fix", "getter", "setter", "recognit", "pojo", "poj", "os"]},
{"A_title": "Session.nodeExists(/foo/bar2) must not throw PathNotFoundExceptionsimilar to OAK-1216 Session.nodeExists() of an SNS path with indexes > 1 should return false.", "A_clean_title": ["session", "nodeexist", "node", "exist", "foo", "bar2", "must", "not", "throw", "pathnotfoundexceptionsimilar", "path", "not", "found", "exceptionsimilar", "oak", "1216", "session", "nodeexist", "node", "exist", "sn", "path", "index", "return", "fals"], "B_title": "Session.nodeExists(/foo/bar2) must not throw PathNotFoundException", "B_clean_title": ["session", "nodeexist", "node", "exist", "foo", "bar2", "must", "not", "throw", "pathnotfoundexcept", "path", "not", "found", "except"]},
{"A_title": "CacheLIRS concurrency issueSome of the methods of the cache can throw a NullPointerException when the cache is used concurrently. Example stack trace:  code java.lang.NullPointerException: null org.apache.jackrabbit.oak.cache.CacheLIRS.values(CacheLIRS.java:470)  org.apache.jackrabbit.oak.cache.CacheLIRS 1.values(CacheLIRS.java:1432) org.apache.jackrabbit.oak.plugins.segment.file.FileStore.flush(FileStore.java:205) code", "A_clean_title": ["cachelir", "cach", "lir", "concurr", "issuesom", "issu", "some", "method", "cach", "throw", "nullpointerexcept", "null", "pointer", "except", "when", "cach", "use", "concurr", "exampl", "stack", "trace", "code", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "null", "org", "apach", "jackrabbit", "oak", "cach", "cachelir", "valu", "cach", "lir", "cachelir", "java:470", "cach", "lir", "org", "apach", "jackrabbit", "oak", "cach", "cachelir", "cach", "lir", "valu", "cachelir", "java:1432", "cach", "lir", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "file", "filestor", "flush", "file", "store", "filestor", "java:205", "file", "store", "code"], "B_title": "CacheLIRS concurrency issue", "B_clean_title": ["cachelir", "cach", "lir", "concurr", "issu"]},
{"A_title": "Version garbage collector doesnt collect a rolled back document if it was never deletedIf a commit gets rolled back it can leave (in case the document was never deleted explicitly) a document in a state like: noformat         _id : 7:/etc/workflow/packages/2014/10/12/rep:ours        _deleted :                  _commitRoot :                  jcr:primaryType :                  _modified : NumberLong(1413126245)        _children : true        _modCount : NumberLong(2)  noformat  If the path is fairly busy the document can get created naturally later and then follow the usual cycle. But at times such documents are ephemeral in nature and never re-used. In those cases such documents can remain silently without getting collected.", "A_clean_title": ["version", "garbag", "collector", "doesnt", "collect", "roll", "back", "document", "it", "wa", "never", "deletedif", "delet", "commit", "get", "roll", "back", "it", "leav", "case", "document", "wa", "never", "delet", "explicitli", "document", "state", "like", "noformat", "id", "etc", "workflow", "packag", "2014", "10", "12", "rep", "our", "delet", "commitroot", "commit", "root", "jcr", "primarytyp", "primari", "type", "modifi", "numberlong", "number", "long", "1413126245", "children", "true", "modcount", "mod", "count", "numberlong", "number", "long", "noformat", "path", "fairli", "busi", "document", "get", "creat", "natur", "later", "then", "follow", "usual", "cycl", "but", "at", "time", "such", "document", "are", "ephemer", "natur", "never", "re", "use", "those", "case", "such", "document", "remain", "silent", "without", "get", "collect"], "B_title": "Version garbage collector doesnt collect a rolled back document if it was never deleted", "B_clean_title": ["version", "garbag", "collector", "doesnt", "collect", "roll", "back", "document", "it", "wa", "never", "delet"]},
{"A_title": "DocumentNS may expose branch commit on earlier revisionThe DocumentNodeStore may expose the changes of a branch on a revision earlier than its commit revision. This only happens when the read revision equals the revision of the not yet merged changes on the branch.", "A_clean_title": ["documentn", "document", "ns", "may", "expos", "branch", "commit", "earlier", "revisionth", "revis", "documentnodestor", "document", "node", "store", "may", "expos", "chang", "branch", "revis", "earlier", "than", "it", "commit", "revis", "thi", "onli", "happen", "when", "read", "revis", "equal", "revis", "not", "yet", "merg", "chang", "branch"], "B_title": "DocumentNS may expose branch commit on earlier revision", "B_clean_title": ["documentn", "document", "ns", "may", "expos", "branch", "commit", "earlier", "revis"]},
{"A_title": "bulk imported files showing up in metadata after bulk import failsBulk import fails.  The file is moved to the failures directory.  But references in the !METADATA table remain.", "A_clean_title": ["bulk", "import", "file", "show", "up", "metadata", "after", "bulk", "import", "failsbulk", "fail", "bulk", "import", "fail", "file", "move", "failur", "directori", "but", "refer", "metadata", "tabl", "remain"], "B_title": "add a metadata table constraint to require the bulk load transaction to be alive when writing the bulk-loaded flags", "B_clean_title": ["add", "metadata", "tabl", "constraint", "requir", "bulk", "load", "transact", "aliv", "when", "write", "bulk", "load", "flag"]},
{"A_title": "Authorizations has inconsistent serializationThe same set of authorizations may not serialize to the same value each time if specified in a different order when constructed (like new Authorizations(a b) and new Authorizations(b a)) because serialization reproducibility depends on the insert order in the underlying HashSet.  So one could get the following to happen: code:java true == auths1.equals(auths2) && !auths1.serialize().equals(auths2.serialize()); code", "A_clean_title": ["author", "ha", "inconsist", "serializationth", "serial", "same", "set", "author", "may", "not", "serial", "same", "valu", "each", "time", "specifi", "differ", "order", "when", "construct", "like", "new", "author", "new", "author", "becaus", "serial", "reproduc", "depend", "insert", "order", "underli", "hashset", "hash", "set", "so", "one", "could", "get", "follow", "happen", "code", "java", "true", "auths1", "equal", "auths2", "auths1", "serial", "equal", "auths2", "serial", "code"], "B_title": "reverted previous change which broke unit tests. Awaiting updated patch based on test failures and ticket discussions.", "B_clean_title": ["revert", "previou", "chang", "which", "broke", "unit", "test", "await", "updat", "patch", "base", "test", "failur", "ticket", "discuss"]},
{"A_title": "Miscellaneous issues concerning the optimization packageRevision 990792 contains changes triggered the following issues: * MATH-394|https://issues.apache.org/jira/browse/MATH-394 * MATH-397|https://issues.apache.org/jira/browse/MATH-397 * MATH-404|https://issues.apache.org/jira/browse/MATH-404  This issue collects the currently still unsatisfactory code (not necessarily sorted in order of annoyance): # BrentOptimizer: a specific convergence checker must be used. LevenbergMarquardtOptimizer also has specific convergence checks. # Trying to make convergence checking independent of the optimization algorithm creates problems (conceptual and practical):  ** See BrentOptimizer and LevenbergMarquardtOptimizer the algorithm passes points to the convergence checker but the actual meaning of the points can very well be different in the caller (optimization algorithm) and the callee (convergence checker).  ** In PowellOptimizer the line search (BrentOptimizer) tolerances depend on the tolerances within the main algorithm. Since tolerances come with ConvergenceChecker and so can be changed at any time it is awkward to adapt the values within the line search optimizer without exposing its internals (BrentOptimizer field) to the enclosing class (PowellOptimizer). # Given the numerous changes some Javadoc comments might be out-of-sync although I did try to update them all. # Class DirectSearchOptimizer (in package optimization.direct) inherits from class AbstractScalarOptimizer (in package optimization.general). # Some interfaces are defined in package optimization but their base implementations (abstract class that contain the boiler-plate code) are in package optimization.general (e.g. DifferentiableMultivariateVectorialOptimizer and BaseAbstractVectorialOptimizer). # No check is performed to ensure the the convergence checker has been set (see e.g. BrentOptimizer and PowellOptimizer); if it hasnt there will be a NPE. The alternative is to initialize a default checker that will never be used in case the user had intended to explicitly sets the checker. # NonLinearConjugateGradientOptimizer: Ugly workaround for the checked ConvergenceException. # Everywhere we trail the checked FunctionEvaluationException although it is never used. # There remains some duplicate code (such as the multi-start loop in the various MultiStart... implementations). # The ConvergenceChecker interface is very general (the converged method can take any number of ...PointValuePair). However there remains a semantic problem: One cannot be sure that the list of points means the same thing for the caller of converged and within the implementation of the ConvergenceChecker that was independently set. # It is not clear whether it is wise to aggregate the counter of gradient evaluations to the function evaluation counter. In LevenbergMarquartdOptimizer for example it would be unfair to do so. Currently I had to remove all tests referring to gradient and Jacobian evaluations. # In AbstractLeastSquaresOptimizer and LevenbergMarquardtOptimizer occurences of OptimizationException were replaced by the unchecked ConvergenceException but in some cases it might not be the most appropriate one. # MultiStartUnivariateRealOptimizer: in the other classes (MultiStartMultivariate...) similar to this one the randomization is on the firts-guess value while in this class it is on the search interval. I think that here also we should randomly choose the start value (within the user-selected interval). # The Javadoc utility raises warnings (see output of mvn site) which I couldnt figure out how to correct. # Some previously existing classes and interfaces have become no more than a specialisation of new generics classes; it might be interesting to remove them in order to reduce the number of classes and thus limit the potential for confusion.", "A_clean_title": ["miscellan", "issu", "concern", "optim", "packagerevis", "packag", "revis", "990792", "contain", "chang", "trigger", "follow", "issu", "math", "394|http", "394", "apach", "issu", "org", "jira", "brows", "math", "math", "397|http", "397", "apach", "issu", "org", "jira", "brows", "math", "math", "404|http", "404", "apach", "issu", "org", "jira", "brows", "math", "thi", "issu", "collect", "current", "still", "unsatisfactori", "code", "not", "necessarili", "sort", "order", "annoy", "brentoptim", "brent", "optim", "specif", "converg", "checker", "must", "use", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "also", "ha", "specif", "converg", "check", "tri", "make", "converg", "check", "independ", "optim", "algorithm", "creat", "problem", "conceptu", "practic", "see", "brentoptim", "brent", "optim", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "algorithm", "pass", "point", "converg", "checker", "but", "actual", "mean", "point", "veri", "well", "differ", "caller", "optim", "algorithm", "calle", "converg", "checker", "powelloptim", "powel", "optim", "line", "search", "brentoptim", "brent", "optim", "toler", "depend", "toler", "within", "main", "algorithm", "sinc", "toler", "come", "convergencecheck", "converg", "checker", "so", "chang", "at", "ani", "time", "it", "awkward", "adapt", "valu", "within", "line", "search", "optim", "without", "expos", "it", "intern", "brentoptim", "brent", "optim", "field", "enclos", "class", "powelloptim", "powel", "optim", "given", "numer", "chang", "some", "javadoc", "comment", "might", "out", "sync", "although", "did", "tri", "updat", "them", "all", "class", "directsearchoptim", "direct", "search", "optim", "packag", "optim", "direct", "inherit", "class", "abstractscalaroptim", "abstract", "scalar", "optim", "packag", "optim", "gener", "some", "interfac", "are", "defin", "packag", "optim", "but", "their", "base", "implement", "abstract", "class", "that", "contain", "boiler", "plate", "code", "are", "packag", "optim", "gener", "differentiablemultivariatevectorialoptim", "differenti", "multivari", "vectori", "optim", "baseabstractvectorialoptim", "base", "abstract", "vectori", "optim", "no", "check", "perform", "ensur", "converg", "checker", "ha", "been", "set", "see", "brentoptim", "brent", "optim", "powelloptim", "powel", "optim", "it", "hasnt", "there", "will", "npe", "altern", "initi", "default", "checker", "that", "will", "never", "use", "case", "user", "had", "intend", "explicitli", "set", "checker", "nonlinearconjugategradientoptim", "non", "linear", "conjug", "gradient", "optim", "ugli", "workaround", "check", "convergenceexcept", "converg", "except", "everywher", "we", "trail", "check", "functionevaluationexcept", "function", "evalu", "except", "although", "it", "never", "use", "there", "remain", "some", "duplic", "code", "such", "as", "multi", "start", "loop", "variou", "multistart", "multi", "start", "implement", "convergencecheck", "converg", "checker", "interfac", "veri", "gener", "converg", "method", "take", "ani", "number", "pointvaluepair", "point", "valu", "pair", "howev", "there", "remain", "semant", "problem", "one", "not", "sure", "that", "list", "point", "mean", "same", "thing", "caller", "converg", "within", "implement", "convergencecheck", "converg", "checker", "that", "wa", "independ", "set", "it", "not", "clear", "whether", "it", "wise", "aggreg", "counter", "gradient", "evalu", "function", "evalu", "counter", "levenbergmarquartdoptim", "levenberg", "marquartd", "optim", "exampl", "it", "would", "unfair", "so", "current", "had", "remov", "all", "test", "refer", "gradient", "jacobian", "evalu", "abstractleastsquaresoptim", "abstract", "least", "squar", "optim", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "occur", "optimizationexcept", "optim", "except", "were", "replac", "by", "uncheck", "convergenceexcept", "converg", "except", "but", "some", "case", "it", "might", "not", "most", "appropri", "one", "multistartunivariaterealoptim", "multi", "start", "univari", "real", "optim", "other", "class", "multistartmultivari", "multi", "start", "multivari", "similar", "thi", "one", "random", "firt", "guess", "valu", "while", "thi", "class", "it", "search", "interv", "think", "that", "here", "also", "we", "randomli", "choos", "start", "valu", "within", "user", "select", "interv", "javadoc", "util", "rais", "warn", "see", "output", "mvn", "site", "which", "couldnt", "figur", "out", "how", "correct", "some", "previous", "exist", "class", "interfac", "have", "becom", "no", "more", "than", "specialis", "new", "gener", "class", "it", "might", "interest", "remov", "them", "order", "reduc", "number", "class", "thu", "limit", "potenti", "confus"], "B_title": "(point 13) Selecting a random start value (instead of interval bounds).", "B_clean_title": ["point", "13", "select", "random", "start", "valu", "instead", "interv", "bound"]},
{"A_title": "JavaScriptReference escapes given URLwhile trying to integrate gmaps3 in our webapp i had issues with the wicketstuff-gmap3 stuff ( - we need a client-id for our request) ...  so i have: noformat public static final String GMAP_API_URL = %s://maps.google.com/maps/api/js?v=3&sensor=%s&client-id=%s;  response.render(JavaScriptHeaderItem.forUrl(String.format(GMAP_API_URL schema sensor clientid))); noformat  the rendered result of this is: noformat <script type=text/javascript src=http://maps.google.com/maps/api/js?v=3&amp;sensor=false&amp;client-id=....></script> noformat  so the requestparameters are encoded  which is happening in the JavaScriptUtils Helper: noformat public static void writeJavaScriptUrl(final Response response final CharSequence url final String id boolean defer String charset)          response.write(<script type=text/javascript );         if (id != null)                      response.write(id= + Strings.escapeMarkup(id) +  );                  if (defer)                      response.write(defer=defer );                  if (charset != null)                      response.write(charset= + Strings.escapeMarkup(charset) +  );                  response.write(src=);         response.write(Strings.escapeMarkup(url));         response.write(></script>);         response.write(n);  noformat but ... is this right to escape the url?  when i open the above mentioned script google tells me i have no parameter sensor ... which i can understand as ther is only a parameter amp ...", "A_clean_title": ["javascriptrefer", "java", "script", "refer", "escap", "given", "urlwhil", "ur", "lwhile", "tri", "integr", "gmaps3", "our", "webapp", "had", "issu", "wicketstuff", "gmap3", "stuff", "we", "need", "client", "id", "our", "request", "so", "have", "noformat", "public", "static", "final", "string", "gmap", "api", "url", "googl", "map", "com", "map", "api", "js", "v=3", "sensor=", "client", "id=", "respons", "render", "javascriptheaderitem", "forurl", "java", "script", "header", "item", "url", "string", "format", "gmap", "api", "url", "schema", "sensor", "clientid", "noformat", "render", "result", "thi", "noformat", "script", "type=text", "javascript", "src=http", "googl", "map", "com", "map", "api", "js", "v=3", "amp", "sensor=fals", "amp", "client", "id=", "script", "noformat", "so", "requestparamet", "are", "encod", "which", "happen", "javascriptutil", "java", "script", "util", "helper", "noformat", "public", "static", "void", "writejavascripturl", "write", "java", "script", "url", "final", "respons", "respons", "final", "charsequ", "char", "sequenc", "url", "final", "string", "id", "boolean", "defer", "string", "charset", "respons", "write", "script", "type=text", "javascript", "id", "null", "respons", "write", "id=", "string", "escapemarkup", "escap", "markup", "id", "defer", "respons", "write", "defer=def", "charset", "null", "respons", "write", "charset=", "string", "escapemarkup", "escap", "markup", "charset", "respons", "write", "src=", "respons", "write", "string", "escapemarkup", "escap", "markup", "url", "respons", "write", "script", "respons", "write", "noformat", "but", "thi", "right", "escap", "url", "when", "open", "abov", "mention", "script", "googl", "tell", "me", "have", "no", "paramet", "sensor", "which", "understand", "as", "ther", "onli", "paramet", "amp"], "B_title": "JavaScriptReference escapes given URL", "B_clean_title": ["javascriptrefer", "java", "script", "refer", "escap", "given", "url"]},
{"A_title": "javascript with a less than character (<) fails to execute when added through a header contribution in ajax responseThis is adapted from a wicket users post I made (links are to the same thread in two archive systems):  http://markmail.org/search/?q=wicket%20users%20wicket-ajax.js#query:wicket%20users%20wicket-ajax.js+page:1+mid:rfts3ar3upffhbbt+state:results  http://mail-archives.apache.org/mod_mbox/wicket-users/201102.mbox/%3CAANLkTi=EkmTA0RnA+GyJE-CQWmkCxRLsjp+z8jwv-Aw9@mail.gmail.com%3E  The problem:  I have a panel with this:      <wicket:head> <script> if (someVariable < 0)  someVariable = 0;  </script>     </wicket:head>  This script fails to execute when the panel is loaded by ajax.  If I replace the less than character < with equals == then it executes (but of course this is not what I need).  I tested this in Firefox 4.0b10 and Chrome 8.  After some debugging it seems to me that this needs to be corrected in wicket-ajax.js. The header contribution is sent to the browser inside of a CDATA section so the < character arrives to javascript intact. However in parsing the script tag the < seems to signal the beginning of an HTML tag that then is considered malformed.   Possible workarounds for apps:   - Invert the logic so a greater-than is used. In my example this would be: if (0 > someVariable)   - Put the code into a separate JS file (the downside is it requires another network hop from the browser)  - Embed the script in <wicket:panel> rather than <wicket:head> (the disadvantage is the script will be re-sent with the panel content when the panel is re-used on the same page)", "A_clean_title": ["javascript", "less", "than", "charact", "fail", "execut", "when", "ad", "through", "header", "contribut", "ajax", "responsethi", "respons", "thi", "adapt", "wicket", "user", "post", "made", "link", "are", "same", "thread", "two", "archiv", "system", "http", "markmail", "org", "search", "q=wicket", "20user", "20wicket", "ajax", "js", "queri", "wicket", "20user", "20wicket", "ajax", "js+page:1+mid", "rfts3ar3upffhbbt+st", "result", "http", "mail", "archiv", "apach", "user", "201102", "mbox", "org", "mod", "mbox", "wicket", "3caanlkti=ekmta0rna+gyj", "cqwmkcxrlsjp+z8jwv", "aw9", "3caan", "lk", "ti=ekm", "ta0rn", "a+gi", "je", "cq", "wmk", "cx", "lsjp+z8jwv", "mail", "gmail", "com", "3e", "problem", "have", "panel", "thi", "wicket", "head", "script", "somevari", "some", "variabl", "somevari", "some", "variabl", "script", "wicket", "head", "thi", "script", "fail", "execut", "when", "panel", "load", "by", "ajax", "replac", "less", "than", "charact", "equal", "then", "it", "execut", "but", "cours", "thi", "not", "what", "need", "test", "thi", "firefox", "0b10", "chrome", "after", "some", "debug", "it", "seem", "me", "that", "thi", "need", "correct", "wicket", "ajax", "js", "header", "contribut", "sent", "browser", "insid", "cdata", "section", "so", "charact", "arriv", "javascript", "intact", "howev", "pars", "script", "tag", "seem", "signal", "begin", "html", "tag", "that", "then", "consid", "malform", "possibl", "workaround", "app", "invert", "logic", "so", "greater", "than", "use", "my", "exampl", "thi", "would", "somevari", "some", "variabl", "put", "code", "into", "separ", "js", "file", "downsid", "it", "requir", "anoth", "network", "hop", "browser", "emb", "script", "wicket", "panel", "rather", "than", "wicket", "head", "disadvantag", "script", "will", "re", "sent", "panel", "content", "when", "panel", "re", "use", "same", "page"], "B_title": "Test case preventing problems during the page serialization process outside Wicket lifecycle Issue: WICKET-3420", "B_clean_title": ["test", "case", "prevent", "problem", "dure", "page", "serial", "process", "outsid", "wicket", "lifecycl", "issu", "wicket", "3420"]},
{"A_title": "Assertion error when adding node with expanded namecode node.addNode(http://foonew); code  results in an assertion error", "A_clean_title": ["assert", "error", "when", "ad", "node", "expand", "namecod", "node", "addnod", "add", "node", "http", "foonew", "code", "result", "assert", "error"], "B_title": "Assertion error when adding node with expanded name", "B_clean_title": ["assert", "error", "when", "ad", "node", "expand", "name"]},
{"A_title": "DocumentNodeStore revision GC removes intermediate docsThe revision garbage collection in DocumentNodeStore removes intermediate documents of the revision history of a node even if it is still in use.", "A_clean_title": ["documentnodestor", "document", "node", "store", "revis", "gc", "remov", "intermedi", "docsth", "doc", "revis", "garbag", "collect", "documentnodestor", "document", "node", "store", "remov", "intermedi", "document", "revis", "histori", "node", "even", "it", "still", "use"], "B_title": "DocumentNodeStore revision GC removes intermediate docs", "B_clean_title": ["documentnodestor", "document", "node", "store", "revis", "gc", "remov", "intermedi", "doc"]},
{"A_title": "cloning of TimeSeriesIts just a minor bug!  When I clone a TimeSeries which has no items I get an IllegalArgumentException (Requires start <= end). But I dont think the user should be responsible for checking whether the TimeSeries has any items or not.", "A_clean_title": ["clone", "timeseriesit", "time", "seri", "it", "just", "minor", "bug", "when", "clone", "timeseri", "time", "seri", "which", "ha", "no", "item", "get", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "but", "dont", "think", "user", "respons", "check", "whether", "timeseri", "time", "seri", "ha", "ani", "item", "or", "not"], "B_title": "source/org/jfree/data/time/TimeSeries.java (clone): Reimplemented.", "B_clean_title": ["java", "sourc", "org", "jfree", "data", "time", "timeseri", "time", "seri", "clone", "reimplement"]},
{"A_title": "Intermittent IllegalMonitorStateException seen while releaseing IndexNodeAt times following exception seen. On this system the index got corrupted because backing index files got deleted from the system and hence index is not accessible.   noformat 21.09.2015 09:26:36.764 *ERROR* FelixStartLevel com.adobe.granite.repository.impl.SlingRepositoryManager start: Uncaught Throwable trying to access Repository calling stopRepository() java.lang.IllegalMonitorStateException: attempt to unlock read lock not locked by current thread         at java.util.concurrent.locks.ReentrantReadWriteLock Sync.unmatchedUnlockException(ReentrantReadWriteLock.java:444)         at java.util.concurrent.locks.ReentrantReadWriteLock Sync.tryReleaseShared(ReentrantReadWriteLock.java:428)         at java.util.concurrent.locks.AbstractQueuedSynchronizer.releaseShared(AbstractQueuedSynchronizer.java:1341)         at java.util.concurrent.locks.ReentrantReadWriteLock ReadLock.unlock(ReentrantReadWriteLock.java:881)         at org.apache.jackrabbit.oak.plugins.index.lucene.IndexNode.release(IndexNode.java:121)         at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex.getPlans(LucenePropertyIndex.java:212)         at org.apache.jackrabbit.oak.query.QueryImpl.getBestSelectorExecutionPlan(QueryImpl.java:847)         at org.apache.jackrabbit.oak.query.QueryImpl.getBestSelectorExecutionPlan(QueryImpl.java:793)         at org.apache.jackrabbit.oak.query.ast.SelectorImpl.prepare(SelectorImpl.java:283)         at org.apache.jackrabbit.oak.query.QueryImpl.prepare(QueryImpl.java:568)         at org.apache.jackrabbit.oak.query.QueryEngineImpl.executeQuery(QueryEngineImpl.java:183)         at org.apache.jackrabbit.oak.security.user.UserProvider.getAuthorizableByPrincipal(UserProvider.java:234)         at org.apache.jackrabbit.oak.security.user.UserManagerImpl.getAuthorizable(UserManagerImpl.java:116)         at org.apache.jackrabbit.oak.security.principal.PrincipalProviderImpl.getAuthorizable(PrincipalProviderImpl.java:140)         at org.apache.jackrabbit.oak.security.principal.PrincipalProviderImpl.getPrincipal(PrincipalProviderImpl.java:69)         at org.apache.jackrabbit.oak.spi.security.principal.CompositePrincipalProvider.getPrincipal(CompositePrincipalProvider.java:50)         at org.apache.jackrabbit.oak.spi.security.principal.PrincipalManagerImpl.getPrincipal(PrincipalManagerImpl.java:47)         at com.adobe.granite.repository.impl.SlingRepositoryManager.setupPermissions(SlingRepositoryManager.java:997)         at com.adobe.granite.repository.impl.SlingRepositoryManager.createRepository(SlingRepositoryManager.java:420)         at com.adobe.granite.repository.impl.SlingRepositoryManager.acquireRepository(SlingRepositoryManager.java:290)         at org.apache.sling.jcr.base.AbstractSlingRepositoryManager.start(AbstractSlingRepositoryManager.java:304)         at com.adobe.granite.repository.impl.SlingRepositoryManager.activate(SlingRepositoryManager.java:267)         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)         at java.lang.reflect.Method.invoke(Method.java:483)         at org.apache.felix.scr.impl.helper.BaseMethod.invokeMethod(BaseMethod.java:222)         at org.apache.felix.scr.impl.helper.BaseMethod.access 500(BaseMethod.java:37)         at org.apache.felix.scr.impl.helper.BaseMethod Resolved.invoke(BaseMethod.java:615)         at org.apache.felix.scr.impl.helper.BaseMethod.invoke(BaseMethod.java:499)         at org.apache.felix.scr.impl.helper.ActivateMethod.invoke(ActivateMethod.java:295)         at org.apache.felix.scr.impl.manager.SingleComponentManager.createImplementationObject(SingleComponentManager.java:302)         at org.apache.felix.scr.impl.manager.SingleComponentManager.createComponent(SingleComponentManager.java:113)         at org.apache.felix.scr.impl.manager.SingleComponentManager.getService(SingleComponentManager.java:832)         at org.apache.felix.scr.impl.manager.SingleComponentManager.getServiceInternal(SingleComponentManager.java:799)         at org.apache.felix.scr.impl.manager.AbstractComponentManager.activateInternal(AbstractComponentManager.java:724)         at org.apache.felix.scr.impl.manager.DependencyManager SingleStaticCustomizer.addedService(DependencyManager.java:927)         at org.apache.felix.scr.impl.manager.DependencyManager SingleStaticCustomizer.addedService(DependencyManager.java:891)         at org.apache.felix.scr.impl.manager.ServiceTracker Tracked.customizerAdded(ServiceTracker.java:1492)         at org.apache.felix.scr.impl.manager.ServiceTracker Tracked.customizerAdded(ServiceTracker.java:1413)         at org.apache.felix.scr.impl.manager.ServiceTracker AbstractTracked.trackAdding(ServiceTracker.java:1222)         at org.apache.felix.scr.impl.manager.ServiceTracker AbstractTracked.track(ServiceTracker.java:1158)         at org.apache.felix.scr.impl.manager.ServiceTracker Tracked.serviceChanged(ServiceTracker.java:1444)         at org.apache.felix.framework.util.EventDispatcher.invokeServiceListenerCallback(EventDispatcher.java:987)         at org.apache.felix.framework.util.EventDispatcher.fireEventImmediately(EventDispatcher.java:838)         at org.apache.felix.framework.util.EventDispatcher.fireServiceEvent(EventDispatcher.java:545)         at org.apache.felix.framework.Felix.fireServiceEvent(Felix.java:4547)         at org.apache.felix.framework.Felix.registerService(Felix.java:3521)         at org.apache.felix.framework.BundleContextImpl.registerService(BundleContextImpl.java:348)         at org.apache.sling.commons.threads.impl.Activator.start(Activator.java:55)         at org.apache.felix.framework.util.SecureAction.startActivator(SecureAction.java:697)         at org.apache.felix.framework.Felix.activateBundle(Felix.java:2223)         at org.apache.felix.framework.Felix.startBundle(Felix.java:2141)         at org.apache.felix.framework.Felix.setActiveStartLevel(Felix.java:1368)         at org.apache.felix.framework.FrameworkStartLevelImpl.run(FrameworkStartLevelImpl.java:308)         at java.lang.Thread.run(Thread.java:745) noformat  Above exception happens at  code for (String path : indexPaths)              try                  indexNode = tracker.acquireIndexNode(path);                  if (indexNode != null)                      IndexPlan plan = new IndexPlanner(indexNode path filter sortOrder).getPlan();                     if (plan != null)                          plans.add(plan);                                                    finally                  if (indexNode != null)                      indexNode.release();                                        code  It has been ensured that if indexNode is initialized then it has been acquired. So only way for such an exception to happen is that in a loop of say 2 paths indexNode got initialized for Loop 1 and then while acquiring in Loop 2 the indexNode still refers to old released value and that would cause the exception. The fix should be simply to null the variable once released", "A_clean_title": ["intermitt", "illegalmonitorstateexcept", "illeg", "monitor", "state", "except", "seen", "while", "releas", "indexnodeat", "index", "node", "at", "time", "follow", "except", "seen", "thi", "system", "index", "got", "corrupt", "becaus", "back", "index", "file", "got", "delet", "system", "henc", "index", "not", "access", "noformat", "21", "09", "2015", "09:26:36", "764", "error", "felixstartlevel", "felix", "start", "level", "com", "adob", "granit", "repositori", "impl", "slingrepositorymanag", "sling", "repositori", "manag", "start", "uncaught", "throwabl", "tri", "access", "repositori", "call", "stoprepositori", "stop", "repositori", "java", "lang", "illegalmonitorstateexcept", "illeg", "monitor", "state", "except", "attempt", "unlock", "read", "lock", "not", "lock", "by", "current", "thread", "at", "java", "util", "concurr", "lock", "reentrantreadwritelock", "reentrant", "read", "write", "lock", "sync", "unmatchedunlockexcept", "unmatch", "unlock", "except", "reentrantreadwritelock", "java:444", "reentrant", "read", "write", "lock", "at", "java", "util", "concurr", "lock", "reentrantreadwritelock", "reentrant", "read", "write", "lock", "sync", "tryreleaseshar", "tri", "releas", "share", "reentrantreadwritelock", "java:428", "reentrant", "read", "write", "lock", "at", "java", "util", "concurr", "lock", "abstractqueuedsynchron", "releaseshar", "abstract", "queu", "synchron", "releas", "share", "abstractqueuedsynchron", "java:1341", "abstract", "queu", "synchron", "at", "java", "util", "concurr", "lock", "reentrantreadwritelock", "reentrant", "read", "write", "lock", "readlock", "unlock", "read", "lock", "reentrantreadwritelock", "java:881", "reentrant", "read", "write", "lock", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexnod", "releas", "index", "node", "indexnod", "java:121", "index", "node", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "getplan", "lucen", "properti", "index", "get", "plan", "lucenepropertyindex", "java:212", "lucen", "properti", "index", "at", "org", "apach", "jackrabbit", "oak", "queri", "queryimpl", "getbestselectorexecutionplan", "queri", "impl", "get", "best", "selector", "execut", "plan", "queryimpl", "java:847", "queri", "impl", "at", "org", "apach", "jackrabbit", "oak", "queri", "queryimpl", "getbestselectorexecutionplan", "queri", "impl", "get", "best", "selector", "execut", "plan", "queryimpl", "java:793", "queri", "impl", "at", "org", "apach", "jackrabbit", "oak", "queri", "ast", "selectorimpl", "prepar", "selector", "impl", "selectorimpl", "java:283", "selector", "impl", "at", "org", "apach", "jackrabbit", "oak", "queri", "queryimpl", "prepar", "queri", "impl", "queryimpl", "java:568", "queri", "impl", "at", "org", "apach", "jackrabbit", "oak", "queri", "queryengineimpl", "executequeri", "queri", "engin", "impl", "execut", "queri", "queryengineimpl", "java:183", "queri", "engin", "impl", "at", "org", "apach", "jackrabbit", "oak", "secur", "user", "userprovid", "getauthorizablebyprincip", "user", "provid", "get", "authoriz", "by", "princip", "userprovid", "java:234", "user", "provid", "at", "org", "apach", "jackrabbit", "oak", "secur", "user", "usermanagerimpl", "getauthoriz", "user", "manag", "impl", "get", "authoriz", "usermanagerimpl", "java:116", "user", "manag", "impl", "at", "org", "apach", "jackrabbit", "oak", "secur", "princip", "principalproviderimpl", "getauthoriz", "princip", "provid", "impl", "get", "authoriz", "principalproviderimpl", "java:140", "princip", "provid", "impl", "at", "org", "apach", "jackrabbit", "oak", "secur", "princip", "principalproviderimpl", "getprincip", "princip", "provid", "impl", "get", "princip", "principalproviderimpl", "java:69", "princip", "provid", "impl", "at", "org", "apach", "jackrabbit", "oak", "spi", "secur", "princip", "compositeprincipalprovid", "getprincip", "composit", "princip", "provid", "get", "princip", "compositeprincipalprovid", "java:50", "composit", "princip", "provid", "at", "org", "apach", "jackrabbit", "oak", "spi", "secur", "princip", "principalmanagerimpl", "getprincip", "princip", "manag", "impl", "get", "princip", "principalmanagerimpl", "java:47", "princip", "manag", "impl", "at", "com", "adob", "granit", "repositori", "impl", "slingrepositorymanag", "setuppermiss", "sling", "repositori", "manag", "setup", "permiss", "slingrepositorymanag", "java:997", "sling", "repositori", "manag", "at", "com", "adob", "granit", "repositori", "impl", "slingrepositorymanag", "createrepositori", "sling", "repositori", "manag", "creat", "repositori", "slingrepositorymanag", "java:420", "sling", "repositori", "manag", "at", "com", "adob", "granit", "repositori", "impl", "slingrepositorymanag", "acquirerepositori", "sling", "repositori", "manag", "acquir", "repositori", "slingrepositorymanag", "java:290", "sling", "repositori", "manag", "at", "org", "apach", "sling", "jcr", "base", "abstractslingrepositorymanag", "start", "abstract", "sling", "repositori", "manag", "abstractslingrepositorymanag", "java:304", "abstract", "sling", "repositori", "manag", "at", "com", "adob", "granit", "repositori", "impl", "slingrepositorymanag", "activ", "sling", "repositori", "manag", "slingrepositorymanag", "java:267", "sling", "repositori", "manag", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:62", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:43", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:483", "at", "org", "apach", "felix", "scr", "impl", "helper", "basemethod", "invokemethod", "base", "method", "invok", "method", "basemethod", "java:222", "base", "method", "at", "org", "apach", "felix", "scr", "impl", "helper", "basemethod", "access", "base", "method", "500", "basemethod", "java:37", "base", "method", "at", "org", "apach", "felix", "scr", "impl", "helper", "basemethod", "base", "method", "resolv", "invok", "basemethod", "java:615", "base", "method", "at", "org", "apach", "felix", "scr", "impl", "helper", "basemethod", "invok", "base", "method", "basemethod", "java:499", "base", "method", "at", "org", "apach", "felix", "scr", "impl", "helper", "activatemethod", "invok", "activ", "method", "activatemethod", "java:295", "activ", "method", "at", "org", "apach", "felix", "scr", "impl", "manag", "singlecomponentmanag", "createimplementationobject", "singl", "compon", "manag", "creat", "implement", "object", "singlecomponentmanag", "java:302", "singl", "compon", "manag", "at", "org", "apach", "felix", "scr", "impl", "manag", "singlecomponentmanag", "createcompon", "singl", "compon", "manag", "creat", "compon", "singlecomponentmanag", "java:113", "singl", "compon", "manag", "at", "org", "apach", "felix", "scr", "impl", "manag", "singlecomponentmanag", "getservic", "singl", "compon", "manag", "get", "servic", "singlecomponentmanag", "java:832", "singl", "compon", "manag", "at", "org", "apach", "felix", "scr", "impl", "manag", "singlecomponentmanag", "getserviceintern", "singl", "compon", "manag", "get", "servic", "intern", "singlecomponentmanag", "java:799", "singl", "compon", "manag", "at", "org", "apach", "felix", "scr", "impl", "manag", "abstractcomponentmanag", "activateintern", "abstract", "compon", "manag", "activ", "intern", "abstractcomponentmanag", "java:724", "abstract", "compon", "manag", "at", "org", "apach", "felix", "scr", "impl", "manag", "dependencymanag", "depend", "manag", "singlestaticcustom", "addedservic", "singl", "static", "custom", "ad", "servic", "dependencymanag", "java:927", "depend", "manag", "at", "org", "apach", "felix", "scr", "impl", "manag", "dependencymanag", "depend", "manag", "singlestaticcustom", "addedservic", "singl", "static", "custom", "ad", "servic", "dependencymanag", "java:891", "depend", "manag", "at", "org", "apach", "felix", "scr", "impl", "manag", "servicetrack", "servic", "tracker", "track", "customizerad", "custom", "ad", "servicetrack", "java:1492", "servic", "tracker", "at", "org", "apach", "felix", "scr", "impl", "manag", "servicetrack", "servic", "tracker", "track", "customizerad", "custom", "ad", "servicetrack", "java:1413", "servic", "tracker", "at", "org", "apach", "felix", "scr", "impl", "manag", "servicetrack", "servic", "tracker", "abstracttrack", "trackad", "abstract", "track", "track", "ad", "servicetrack", "java:1222", "servic", "tracker", "at", "org", "apach", "felix", "scr", "impl", "manag", "servicetrack", "servic", "tracker", "abstracttrack", "track", "abstract", "track", "servicetrack", "java:1158", "servic", "tracker", "at", "org", "apach", "felix", "scr", "impl", "manag", "servicetrack", "servic", "tracker", "track", "servicechang", "servic", "chang", "servicetrack", "java:1444", "servic", "tracker", "at", "org", "apach", "felix", "framework", "util", "eventdispatch", "invokeservicelistenercallback", "event", "dispatch", "invok", "servic", "listen", "callback", "eventdispatch", "java:987", "event", "dispatch", "at", "org", "apach", "felix", "framework", "util", "eventdispatch", "fireeventimmedi", "event", "dispatch", "fire", "event", "immedi", "eventdispatch", "java:838", "event", "dispatch", "at", "org", "apach", "felix", "framework", "util", "eventdispatch", "fireserviceev", "event", "dispatch", "fire", "servic", "event", "eventdispatch", "java:545", "event", "dispatch", "at", "org", "apach", "felix", "framework", "felix", "fireserviceev", "fire", "servic", "event", "felix", "java:4547", "at", "org", "apach", "felix", "framework", "felix", "registerservic", "regist", "servic", "felix", "java:3521", "at", "org", "apach", "felix", "framework", "bundlecontextimpl", "registerservic", "bundl", "context", "impl", "regist", "servic", "bundlecontextimpl", "java:348", "bundl", "context", "impl", "at", "org", "apach", "sling", "common", "thread", "impl", "activ", "start", "activ", "java:55", "at", "org", "apach", "felix", "framework", "util", "secureact", "startactiv", "secur", "action", "start", "activ", "secureact", "java:697", "secur", "action", "at", "org", "apach", "felix", "framework", "felix", "activatebundl", "activ", "bundl", "felix", "java:2223", "at", "org", "apach", "felix", "framework", "felix", "startbundl", "start", "bundl", "felix", "java:2141", "at", "org", "apach", "felix", "framework", "felix", "setactivestartlevel", "set", "activ", "start", "level", "felix", "java:1368", "at", "org", "apach", "felix", "framework", "frameworkstartlevelimpl", "run", "framework", "start", "level", "impl", "frameworkstartlevelimpl", "java:308", "framework", "start", "level", "impl", "at", "java", "lang", "thread", "run", "thread", "java:745", "noformat", "abov", "except", "happen", "at", "code", "string", "path", "indexpath", "index", "path", "tri", "indexnod", "index", "node", "tracker", "acquireindexnod", "acquir", "index", "node", "path", "indexnod", "index", "node", "null", "indexplan", "index", "plan", "plan", "new", "indexplann", "index", "planner", "indexnod", "index", "node", "path", "filter", "sortord", "sort", "order", "getplan", "get", "plan", "plan", "null", "plan", "add", "plan", "final", "indexnod", "index", "node", "null", "indexnod", "releas", "index", "node", "code", "it", "ha", "been", "ensur", "that", "indexnod", "index", "node", "initi", "then", "it", "ha", "been", "acquir", "so", "onli", "way", "such", "except", "happen", "that", "loop", "say", "path", "indexnod", "index", "node", "got", "initi", "loop", "then", "while", "acquir", "loop", "indexnod", "index", "node", "still", "refer", "old", "releas", "valu", "that", "would", "caus", "except", "fix", "simpli", "null", "variabl", "onc", "releas"], "B_title": "- Intermittent IllegalMonitorStateException seen while releaseing IndexNode", "B_clean_title": ["intermitt", "illegalmonitorstateexcept", "illeg", "monitor", "state", "except", "seen", "while", "releas", "indexnod", "index", "node"]},
{"A_title": "Handling of NO_MINIFIED_NAME in PackageResourceReference#internalGetMinifiedName()The Value NO_MINIFIED_NAME is not handled correctly as entry in the MINIFIED_NAMES_CACHE in PackageResourceReference#internalGetMinifiedName()     private String internalGetMinifiedName()  String minifiedName = MINIFIED_NAMES_CACHE.get(this); if (minifiedName != null && minifiedName != NO_MINIFIED_NAME)                                                         ^^^^^^^ return minifiedName;                                  ...  You should remove the condition minifiedName != NO_MINIFIED_NAME here to leverage the  MINIFIED_NAMES_CACHE for NO_MINIFIED_NAME cache entries. Otherwise you always run into the resource resolving code if there is no minified resource.", "A_clean_title": ["handl", "no", "minifi", "name", "packageresourcerefer", "packag", "resourc", "refer", "internalgetminifiednam", "intern", "get", "minifi", "name", "valu", "no", "minifi", "name", "not", "handl", "correctli", "as", "entri", "minifi", "name", "cach", "packageresourcerefer", "packag", "resourc", "refer", "internalgetminifiednam", "intern", "get", "minifi", "name", "privat", "string", "internalgetminifiednam", "intern", "get", "minifi", "name", "string", "minifiednam", "minifi", "name", "get", "minifi", "name", "cach", "thi", "minifiednam", "minifi", "name", "null", "minifiednam", "minifi", "name", "no", "minifi", "name", "return", "minifiednam", "minifi", "name", "you", "remov", "condit", "minifiednam", "minifi", "name", "no", "minifi", "name", "here", "leverag", "minifi", "name", "cach", "no", "minifi", "name", "cach", "entri", "otherwis", "you", "alway", "run", "into", "resourc", "resolv", "code", "there", "no", "minifi", "resourc"], "B_title": "cache minified name correctly", "B_clean_title": ["cach", "minifi", "name", "correctli"]},
{"A_title": "isPrimary check is not applied to beans in parent contextssee this comment in WICKET-2771: https://issues.apache.org/jira/browse/WICKET-2771?focusedCommentId=12872246&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12872246", "A_clean_title": ["isprimari", "primari", "check", "not", "appli", "bean", "parent", "contextsse", "thi", "comment", "wicket", "2771", "http", "2771", "apach", "issu", "org", "jira", "brows", "wicket", "focusedcommentid=12872246", "focus", "comment", "id=12872246", "page=com", "atlassian", "jira", "plugin", "system", "issuetabpanel", "3acom", "tabpanel", "action", "12872246"], "B_title": "look for bean definition in parent contexts WICKET-2901: only return a primary bean if its the only one", "B_clean_title": ["look", "bean", "definit", "parent", "context", "wicket", "2901", "onli", "return", "primari", "bean", "it", "onli", "one"]},
{"A_title": "TARMK Cold Standby size increase due to checkpoints copyThe current sync design gets confused by existing checkpoints and tries to copy them by value bypassing the current storage optimization where there are a lot of references to existing content. this can result in a considerable size increase on the standby.", "A_clean_title": ["tarmk", "cold", "standbi", "size", "increas", "due", "checkpoint", "copyth", "copi", "current", "sync", "design", "get", "confus", "by", "exist", "checkpoint", "tri", "copi", "them", "by", "valu", "bypass", "current", "storag", "optim", "where", "there", "are", "lot", "refer", "exist", "content", "thi", "result", "consider", "size", "increas", "standbi"], "B_title": "TARMK Cold Standby size increase due to checkpoints copy  - switched sync to a different approach to leverage existing recordid info", "B_clean_title": ["tarmk", "cold", "standbi", "size", "increas", "due", "checkpoint", "copi", "switch", "sync", "differ", "approach", "leverag", "exist", "recordid", "info"]},
{"A_title": "onError call order doesnt match onSubmitonError in Forms and Buttons should be called in the same order as onSubmit (i.e. post-order).", "A_clean_title": ["onerror", "error", "call", "order", "doesnt", "match", "onsubmitonerror", "submiton", "error", "form", "button", "call", "same", "order", "as", "onsubmit", "submit", "post", "order"], "B_title": "onError now called post-order just like onSubmit", "B_clean_title": ["onerror", "error", "now", "call", "post", "order", "just", "like", "onsubmit", "submit"]},
{"A_title": "StringValidator.exactLength has wrong variable in ErrorMessageIn error message for StringValidator.exactLength is variable  exact  but in StringValidator.decorate is added variable length to map and not exact.   Exception when is error message interpolate for show in feedback.  Caused by: java.lang.IllegalArgumentException: Value of variable exact could not be resolved while interpolating  label is not exactly  exact characters long.  property from application. StringValidator.exact= label is not exactly  exact characters long.  When I added same property in my own properties and change exact to length it works.", "A_clean_title": ["stringvalid", "exactlength", "string", "valid", "exact", "length", "ha", "wrong", "variabl", "errormessagein", "error", "messag", "error", "messag", "stringvalid", "exactlength", "string", "valid", "exact", "length", "variabl", "exact", "but", "stringvalid", "decor", "string", "valid", "ad", "variabl", "length", "map", "not", "exact", "except", "when", "error", "messag", "interpol", "show", "feedback", "caus", "by", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "valu", "variabl", "exact", "could", "not", "resolv", "while", "interpol", "label", "not", "exactli", "exact", "charact", "long", "properti", "applic", "stringvalid", "exact=", "string", "valid", "label", "not", "exactli", "exact", "charact", "long", "when", "ad", "same", "properti", "my", "own", "properti", "chang", "exact", "length", "it", "work"], "B_title": "exact variable is missing", "B_clean_title": ["exact", "variabl", "miss"]},
{"A_title": "DerivativeStructure.atan2(yx) does not handle special cases properlyThe four special cases +/-0 for both x and y should give the same values as Math.atan2 and FastMath.atan2. However they give NaN for the value in all cases.", "A_clean_title": ["derivativestructur", "atan2", "deriv", "structur", "yx", "not", "handl", "special", "case", "properlyth", "properli", "four", "special", "case", "both", "give", "same", "valu", "as", "math", "atan2", "fastmath", "atan2", "fast", "math", "howev", "they", "give", "nan", "na", "valu", "all", "case"], "B_title": "Fixed DerivativeStructure.atan2 for special cases when both arguments are +/-0.", "B_clean_title": ["fix", "derivativestructur", "atan2", "deriv", "structur", "special", "case", "when", "both", "argument", "are"]},
{"A_title": "RangeInputSplit Writable methods dont serialize IteratorSettingsWas trying to figure out why some information was getting lost on a RangeInputSplit after serialization and found out it was because the serialization and deserialization of the class didnt include the configured IteratorSettings.  This likely isnt a big problem for normal users as when no IteratorSettings are configured on the RangeInputSplit it falls back to pulling from the Configuration but its possible with non-standard uses of mapreduce that information could be missing in the Configuration that the mappers receive and would subsequently error.", "A_clean_title": ["rangeinputsplit", "rang", "input", "split", "writabl", "method", "dont", "serial", "iteratorsettingswa", "iter", "set", "wa", "tri", "figur", "out", "whi", "some", "inform", "wa", "get", "lost", "rangeinputsplit", "rang", "input", "split", "after", "serial", "found", "out", "it", "wa", "becaus", "serial", "deseri", "class", "didnt", "includ", "configur", "iteratorset", "iter", "set", "thi", "like", "isnt", "big", "problem", "normal", "user", "as", "when", "no", "iteratorset", "iter", "set", "are", "configur", "rangeinputsplit", "rang", "input", "split", "it", "fall", "back", "pull", "configur", "but", "it", "possibl", "non", "standard", "use", "mapreduc", "that", "inform", "could", "miss", "configur", "that", "mapper", "receiv", "would", "subsequ", "error"], "B_title": "(De)serialize IteratorSettings on RangeInputSplit(s).", "B_clean_title": ["de", "serial", "iteratorset", "iter", "set", "rangeinputsplit", "rang", "input", "split"]},
{"A_title": "DocumentNodeStore does not make use of References while serializing BlobThe BlobSerializer in DocumentNodeStore does not make use of Blob references which results in copying the blobs by value hence significantly slowing down any migration", "A_clean_title": ["documentnodestor", "document", "node", "store", "not", "make", "use", "refer", "while", "serial", "blobth", "blob", "blobseri", "blob", "serial", "documentnodestor", "document", "node", "store", "not", "make", "use", "blob", "refer", "which", "result", "copi", "blob", "by", "valu", "henc", "significantli", "slow", "down", "ani", "migrat"], "B_title": "- DocumentNodeStore does not make use of References while serializing Blob", "B_clean_title": ["documentnodestor", "document", "node", "store", "not", "make", "use", "refer", "while", "serial", "blob"]},
{"A_title": "INullAcceptingValidator behavior seems broken in 1.5-RC4.2As discussed in this forum thread: http://apache-wicket.1842946.n4.nabble.com/INullAcceptingValidator-behavior-tp3570352p3570352.html  It appears that Wicket no longer calls INullAcceptingValidator intances when the validatable value is null.  Wicket wraps validators  as behaviors using the adapter pattern. The adapter class (org.apache.wicket.validation.ValidatorAdapter) implements  the interface IValidator<T>. This hides the case where the actual validator is an INullAcceptingValidator. Therefore when going through a components attached validators the code of org.apache.wicket.markup.html.form.FormComponent will never call INullAcceptingValidators when the value is null.", "A_clean_title": ["inullacceptingvalid", "null", "accept", "valid", "behavior", "seem", "broken", "rc4", "2a", "discuss", "thi", "forum", "thread", "http", "behavior", "apach", "wicket", "1842946", "n4", "nabbl", "tp3570352p3570352", "html", "com", "inullacceptingvalid", "null", "accept", "valid", "it", "appear", "that", "wicket", "no", "longer", "call", "inullacceptingvalid", "null", "accept", "valid", "intanc", "when", "validat", "valu", "null", "wicket", "wrap", "valid", "as", "behavior", "adapt", "pattern", "adapt", "class", "org", "apach", "wicket", "valid", "validatoradapt", "valid", "adapt", "implement", "interfac", "ivalid", "valid", "thi", "hide", "case", "where", "actual", "valid", "inullacceptingvalid", "null", "accept", "valid", "therefor", "when", "go", "through", "compon", "attach", "valid", "code", "org", "apach", "wicket", "markup", "html", "form", "formcompon", "form", "compon", "will", "never", "call", "inullacceptingvalid", "null", "accept", "valid", "when", "valu", "null"], "B_title": "Issue: WICKET-3767", "B_clean_title": ["issu", "wicket", "3767"]},
{"A_title": "Wrong serializer causing JsonMappingExceptionIm using spring-data-rest (3.0.0) which uses jackson-databind 2.9.0.pr2.  Im not sure what have changed since not so long ago I had an functional application. But now Im getting:  Could not write JSON document: java.lang.Double cannot be cast to java.lang.Integer (through reference chain: org.springframework.data.rest.webmvc.json.PersistentEntityJackson2Module$PersistentEntityResourceSerializer$1content->**.ContratostorageUtilizado); nested exception is com.fasterxml.jackson.databind.JsonMappingException: java.lang.Double cannot be cast to java.lang.Integer (through reference chain: org.springframework.data.rest.webmvc.json.PersistentEntityJackson2Module$PersistentEntityResourceSerializer$1content->**.ContratostorageUtilizado) Ive been stucked with this problem for a while and Im just assuming that there is something wrong when de Serializer for this specific field is defined   I need at least some directions...", "A_clean_title": ["wrong", "serial", "caus", "jsonmappingexceptionim", "json", "map", "except", "im", "spring", "data", "rest", "which", "use", "jackson", "databind", "pr2", "im", "not", "sure", "what", "have", "chang", "sinc", "not", "so", "long", "ago", "had", "function", "applic", "but", "now", "im", "get", "could", "not", "write", "json", "document", "java", "lang", "doubl", "not", "cast", "java", "lang", "integ", "through", "refer", "chain", "org", "springframework", "data", "rest", "webmvc", "json", "persistententityjackson2modul", "persist", "entiti", "jackson2modul", "persistententityresourceseri", "persist", "entiti", "resourc", "serial", "1content", "contratostorageutilizado", "contratostorag", "utilizado", "nest", "except", "com", "fasterxml", "jackson", "databind", "jsonmappingexcept", "json", "map", "except", "java", "lang", "doubl", "not", "cast", "java", "lang", "integ", "through", "refer", "chain", "org", "springframework", "data", "rest", "webmvc", "json", "persistententityjackson2modul", "persist", "entiti", "jackson2modul", "persistententityresourceseri", "persist", "entiti", "resourc", "serial", "1content", "contratostorageutilizado", "contratostorag", "utilizado", "ive", "been", "stuck", "thi", "problem", "while", "im", "just", "assum", "that", "there", "someth", "wrong", "when", "de", "serial", "thi", "specif", "field", "defin", "need", "at", "least", "some", "direct"], "B_title": "Improve error handling wrt #1612; add a test to verify exception being thrown", "B_clean_title": ["improv", "error", "handl", "wrt", "1612", "add", "test", "verifi", "except", "be", "thrown"]},
{"A_title": "NodeBuilder.reset might lead to inconsistent builderThe following test fails: code NodeBuilder root = new MemoryNodeBuilder(BASE); NodeBuilder x = root.child(x); NodeBuilder y = x.child(y);  root.reset(BASE); assertTrue(root.hasChildNode(x)); assertFalse(x.hasChildNode(y));  // fails code", "A_clean_title": ["nodebuild", "reset", "node", "builder", "might", "lead", "inconsist", "builderth", "builder", "follow", "test", "fail", "code", "nodebuild", "node", "builder", "root", "new", "memorynodebuild", "memori", "node", "builder", "base", "nodebuild", "node", "builder", "root", "child", "nodebuild", "node", "builder", "child", "root", "reset", "base", "asserttru", "assert", "true", "root", "haschildnod", "ha", "child", "node", "assertfals", "assert", "fals", "haschildnod", "ha", "child", "node", "fail", "code"], "B_title": "NodeBuilder.reset might lead to inconsistent builder", "B_clean_title": ["nodebuild", "reset", "node", "builder", "might", "lead", "inconsist", "builder"]},
{"A_title": "Method getResult() in MultiStartUnivariateRealOptimizerIn MultiStartUnivariateRealOptimizer (package optimization) the method getResult returns the result of the last run of the underlying optimizer; this last result might not be the best one in which case it will not correspond to the value returned by the optimize method. This is confusing and does not seem very useful. I think that getResult should be defined as code  public double getResult()      return optima0;  code and similarly code public double getFunctionValue()      return optimaValues0;  code", "A_clean_title": ["method", "getresult", "get", "result", "multistartunivariaterealoptimizerin", "multi", "start", "univari", "real", "optim", "multistartunivariaterealoptim", "multi", "start", "univari", "real", "optim", "packag", "optim", "method", "getresult", "get", "result", "return", "result", "last", "run", "underli", "optim", "thi", "last", "result", "might", "not", "best", "one", "which", "case", "it", "will", "not", "correspond", "valu", "return", "by", "optim", "method", "thi", "confus", "not", "seem", "veri", "use", "think", "that", "getresult", "get", "result", "defin", "as", "code", "public", "doubl", "getresult", "get", "result", "return", "optima0", "code", "similarli", "code", "public", "doubl", "getfunctionvalu", "get", "function", "valu", "return", "optimavalues0", "optima", "values0", "code"], "B_title": "Fixed inconsistent definition of getResult. Modified associated test accordingly.", "B_clean_title": ["fix", "inconsist", "definit", "getresult", "get", "result", "modifi", "associ", "test", "accordingli"]},
{"A_title": "AssertionError thrown for Lucene index with empty suggest disctionaryCreate an index where one field is enabled for suggestion but no content is indexed for that index i.e. no matching content. Then while performing any query following exception is thrown  noformat java.lang.AssertionError at org.apache.lucene.search.suggest.analyzing.AnalyzingInfixSuggester.<init>(AnalyzingInfixSuggester.java:167) at org.apache.jackrabbit.oak.plugins.index.lucene.util.SuggestHelper 2.<init>(SuggestHelper.java:127) at org.apache.jackrabbit.oak.plugins.index.lucene.util.SuggestHelper.getLookup(SuggestHelper.java:127) at org.apache.jackrabbit.oak.plugins.index.lucene.util.SuggestHelper.getLookup(SuggestHelper.java:123) at org.apache.jackrabbit.oak.plugins.index.lucene.IndexNode.<init>(IndexNode.java:109) at org.apache.jackrabbit.oak.plugins.index.lucene.IndexNode.open(IndexNode.java:69) at org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker.findIndexNode(IndexTracker.java:162) at org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker.acquireIndexNode(IndexTracker.java:137) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex.getPlans(LucenePropertyIndex.java:249) at org.apache.jackrabbit.oak.query.QueryImpl.getBestSelectorExecutionPlan(QueryImpl.java:1016) at org.apache.jackrabbit.oak.query.QueryImpl.getBestSelectorExecutionPlan(QueryImpl.java:949) at org.apache.jackrabbit.oak.query.ast.SelectorImpl.prepare(SelectorImpl.java:288) noformat  This happens with -ea flag i.e. java assertions enabled. It caused here|https://github.com/apache/lucene-solr/blob/releases/lucene-solr/4.7.1/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester.java#L167", "A_clean_title": ["assertionerror", "assert", "error", "thrown", "lucen", "index", "empti", "suggest", "disctionarycr", "disctionari", "creat", "index", "where", "one", "field", "enabl", "suggest", "but", "no", "content", "index", "that", "index", "no", "match", "content", "then", "while", "perform", "ani", "queri", "follow", "except", "thrown", "noformat", "java", "lang", "assertionerror", "assert", "error", "at", "org", "apach", "lucen", "search", "suggest", "analyz", "analyzinginfixsuggest", "analyz", "infix", "suggest", "init", "analyzinginfixsuggest", "java:167", "analyz", "infix", "suggest", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "util", "suggesthelp", "suggest", "helper", "init", "suggesthelp", "java:127", "suggest", "helper", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "util", "suggesthelp", "getlookup", "suggest", "helper", "get", "lookup", "suggesthelp", "java:127", "suggest", "helper", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "util", "suggesthelp", "getlookup", "suggest", "helper", "get", "lookup", "suggesthelp", "java:123", "suggest", "helper", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexnod", "index", "node", "init", "indexnod", "java:109", "index", "node", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexnod", "open", "index", "node", "indexnod", "java:69", "index", "node", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indextrack", "findindexnod", "index", "tracker", "find", "index", "node", "indextrack", "java:162", "index", "tracker", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indextrack", "acquireindexnod", "index", "tracker", "acquir", "index", "node", "indextrack", "java:137", "index", "tracker", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "getplan", "lucen", "properti", "index", "get", "plan", "lucenepropertyindex", "java:249", "lucen", "properti", "index", "at", "org", "apach", "jackrabbit", "oak", "queri", "queryimpl", "getbestselectorexecutionplan", "queri", "impl", "get", "best", "selector", "execut", "plan", "queryimpl", "java:1016", "queri", "impl", "at", "org", "apach", "jackrabbit", "oak", "queri", "queryimpl", "getbestselectorexecutionplan", "queri", "impl", "get", "best", "selector", "execut", "plan", "queryimpl", "java:949", "queri", "impl", "at", "org", "apach", "jackrabbit", "oak", "queri", "ast", "selectorimpl", "prepar", "selector", "impl", "selectorimpl", "java:288", "selector", "impl", "noformat", "thi", "happen", "ea", "flag", "java", "assert", "enabl", "it", "caus", "here|http", "solr", "blob", "releas", "lucen", "java", "github", "com", "apach", "lucen", "solr", "lucen", "suggest", "src", "java", "org", "apach", "lucen", "search", "suggest", "analyz", "analyzinginfixsuggest", "analyz", "infix", "suggest", "l167"], "B_title": "- avoid building suggester with existing directory when no content is indexed", "B_clean_title": ["avoid", "build", "suggest", "exist", "directori", "when", "no", "content", "index"]},
{"A_title": "Bugs in BrentOptimizerI apologize for having provided a buggy implementation of Brents optimization algorithm (class BrentOptimizer in package optimization.univariate). The unit tests didnt show that there was something wrong although (from the changes.xml file) I discovered that at the time Luc had noticed something weird in the implementations behaviour. Comparing with an implementation in Python I could figure out the fixes. Ill modify BrentOptimizer and add a test. I also propose to change the name of the unit test class from BrentMinimizerTest to BrentOptimizerTest.", "A_clean_title": ["bug", "brentoptimizeri", "brent", "optim", "apolog", "have", "provid", "buggi", "implement", "brent", "optim", "algorithm", "class", "brentoptim", "brent", "optim", "packag", "optim", "univari", "unit", "test", "didnt", "show", "that", "there", "wa", "someth", "wrong", "although", "chang", "xml", "file", "discov", "that", "at", "time", "luc", "had", "notic", "someth", "weird", "implement", "behaviour", "compar", "implement", "python", "could", "figur", "out", "fix", "ill", "modifi", "brentoptim", "brent", "optim", "add", "test", "also", "propos", "chang", "name", "unit", "test", "class", "brentminimizertest", "brent", "minim", "test", "brentoptimizertest", "brent", "optim", "test"], "B_title": "Another bug uncovered; all things being equal the code now behaves like the Puthon implementation. MATH-397: Modified BrentOptimizer following the changes in AbstractUnivariateRealOptimizer.", "B_clean_title": ["anoth", "bug", "uncov", "all", "thing", "be", "equal", "code", "now", "behav", "like", "puthon", "implement", "math", "397", "modifi", "brentoptim", "brent", "optim", "follow", "chang", "abstractunivariaterealoptim", "abstract", "univari", "real", "optim"]},
{"A_title": "Prevent partitioning pushdown unless partitions fields match exactlyConsider an operation grouped on fields (A B) followed by an operation grouped on field (A).  Right now the optimizer can push down the partitioning on (A) which serves both operations (the first step locally still groups by A and B). This may however by a bad idea for the cases where the field A has a low cardinality or the value distribution is skewed.  Since we cannot determine that robustly yet I suggest to disable this optimization for now.", "A_clean_title": ["prevent", "partit", "pushdown", "unless", "partit", "field", "match", "exactlyconsid", "exactli", "consid", "oper", "group", "field", "follow", "by", "oper", "group", "field", "right", "now", "optim", "push", "down", "partit", "which", "serv", "both", "oper", "first", "step", "local", "still", "group", "by", "thi", "may", "howev", "by", "bad", "idea", "case", "where", "field", "ha", "low", "cardin", "or", "valu", "distribut", "skew", "sinc", "we", "not", "determin", "that", "robustli", "yet", "suggest", "disabl", "thi", "optim", "now"], "B_title": "Prevent partitionings on subsets of fields from being pushed down", "B_clean_title": ["prevent", "partit", "subset", "field", "be", "push", "down"]},
{"A_title": "Always create new UUID on ImportBehavior.IMPORT_UUID_CREATE_NEWThe implementation should create a new UUID for each referenceable node even if there is no existing node with that UUID. This spec says:  bq.  Incoming nodes are assigned newly created identifiers upon addition to the workspace. As a result identifier collisions never occur.  This will break backward compatibility but is IMO the correct behavior and the only way to guarantee import of referenceable nodes does not fail in a concurrent import scenario. See OAK-1186 for more details.", "A_clean_title": ["alway", "creat", "new", "uuid", "importbehavior", "import", "behavior", "import", "uuid", "creat", "newth", "new", "implement", "creat", "new", "uuid", "each", "referenc", "node", "even", "there", "no", "exist", "node", "that", "uuid", "thi", "spec", "say", "bq", "incom", "node", "are", "assign", "newli", "creat", "identifi", "upon", "addit", "workspac", "as", "result", "identifi", "collis", "never", "occur", "thi", "will", "break", "backward", "compat", "but", "imo", "correct", "behavior", "onli", "way", "guarante", "import", "referenc", "node", "not", "fail", "concurr", "import", "scenario", "see", "oak", "1186", "more", "detail"], "B_title": "Always create new UUID on ImportBehavior.IMPORT_UUID_CREATE_NEW", "B_clean_title": ["alway", "creat", "new", "uuid", "importbehavior", "import", "behavior", "import", "uuid", "creat", "new"]},
{"A_title": "Consolidate ZK code WRT retriesA couple of general ZK things that should be fixed up:  # Multiple means of automatic retrying of recoverable ZooKeeper errors through use of an InvocationHandler and a Proxy around IZooReader(Writer) # Encapsulate retry logic # Switch over callers to use the retrying instance instead of the non-retrying instance", "A_clean_title": ["consolid", "zk", "code", "wrt", "retriesa", "retri", "coupl", "gener", "zk", "thing", "that", "fix", "up", "multipl", "mean", "automat", "retri", "recover", "zookeep", "zoo", "keeper", "error", "through", "use", "invocationhandl", "invoc", "handler", "proxi", "around", "izooread", "zoo", "reader", "writer", "encapsul", "retri", "logic", "switch", "over", "caller", "use", "retri", "instanc", "instead", "non", "retri", "instanc"], "B_title": "Spelling error missing hashCode/toString/equals on ZKConnectionInfo and some extra braces.", "B_clean_title": ["spell", "error", "miss", "hashcod", "tostr", "equal", "hash", "code", "string", "zkconnectioninfo", "zk", "connect", "info", "some", "extra", "brace"]},
{"A_title": "LongConverter converts some values greater than Long.MAX_VALUECurrently its possible to submit some values via Long Textfield<Long> that are greater than Long.MAX_VALUE. This will produce converted input and model update with value of Long.MAX_VALUE  Im not sure what the behavior should be - imho throwing ConversionException seems fair as the input isnt a valid Long.  The reason seems to be precision loss during Double.valueOf(input) execution while converting and then comparing to Long.MAX_VALUE  using Long.doubleValue() in *AbstractNumberConverter* which by casting leads to to the same precision loss and the numbers are seemingly equal during comparison of ranges.  Maybe using BigDecimals for parsing could help here.  The quickstart is available at https://github.com/zeratul021/wicket-number-conversion.  For the fastest demonstration I extended Wickets _longConversion()_ test-case in *ConvertersTest*: https://github.com/zeratul021/wicket-number-conversion/blob/master/src/test/java/com/github/zeratul021/wicketnumberconversion/ConvertersTest.java#L300", "A_clean_title": ["longconvert", "long", "convert", "convert", "some", "valu", "greater", "than", "long", "max", "valuecurr", "valu", "current", "it", "possibl", "submit", "some", "valu", "via", "long", "textfield", "long", "that", "are", "greater", "than", "long", "max", "valu", "thi", "will", "produc", "convert", "input", "model", "updat", "valu", "long", "max", "valu", "im", "not", "sure", "what", "behavior", "imho", "throw", "conversionexcept", "convers", "except", "seem", "fair", "as", "input", "isnt", "valid", "long", "reason", "seem", "precis", "loss", "dure", "doubl", "valueof", "valu", "input", "execut", "while", "convert", "then", "compar", "long", "max", "valu", "long", "doublevalu", "doubl", "valu", "abstractnumberconvert", "abstract", "number", "convert", "which", "by", "cast", "lead", "same", "precis", "loss", "number", "are", "seemingli", "equal", "dure", "comparison", "rang", "mayb", "bigdecim", "big", "decim", "pars", "could", "help", "here", "quickstart", "avail", "at", "http", "number", "convers", "github", "com", "zeratul021", "wicket", "fastest", "demonstr", "extend", "wicket", "longconvers", "long", "convers", "test", "case", "converterstest", "convert", "test", "http", "number", "java", "github", "com", "zeratul021", "wicket", "convers", "blob", "master", "src", "test", "java", "com", "github", "zeratul021", "wicketnumberconvers", "converterstest", "convert", "test", "l300"], "B_title": "and WICKET-5861: number converters are based on BigDecimals now", "B_clean_title": ["wicket", "5861", "number", "convert", "are", "base", "bigdecim", "big", "decim", "now"]},
{"A_title": "Deep stubbing with generic responses in the call chain is not workingDeep stubbing will throw an Exception if multiple generics occur in the call chain. For instance consider having a mock myMock1 that provides a function that returns a generic T. If T also has a function that returns a generic an Exception with the message Raw extraction not supported for : null will be thrown. I think the issue is that further generics are not possible to be mocked by ReturnsDeepStubsSerializationFallback since the GenericMetadataSupport is closed at this point.", "A_clean_title": ["deep", "stub", "gener", "respons", "call", "chain", "not", "workingdeep", "work", "deep", "stub", "will", "throw", "except", "multipl", "gener", "occur", "call", "chain", "instanc", "consid", "have", "mock", "mymock1", "my", "mock1", "that", "provid", "function", "that", "return", "gener", "also", "ha", "function", "that", "return", "gener", "except", "messag", "raw", "extract", "not", "support", "null", "will", "thrown", "think", "issu", "that", "further", "gener", "are", "not", "possibl", "mock", "by", "returnsdeepstubsserializationfallback", "return", "deep", "stub", "serial", "fallback", "sinc", "genericmetadatasupport", "gener", "metadata", "support", "close", "at", "thi", "point"], "B_title": "Merge branch pbielicki-bug#128", "B_clean_title": ["merg", "branch", "pbielicki", "bug", "128"]},
{"A_title": "weird object literal invalid property error on unrelated object prototypeNone", "A_clean_title": ["weird", "object", "liter", "invalid", "properti", "error", "unrel", "object", "prototypenon", "prototyp", "none"], "B_title": "fix a bug in constraint-matching fixes issue 700", "B_clean_title": ["fix", "bug", "constraint", "match", "fix", "issu", "700"]},
{"A_title": "StringUtils equals() relies on undefined behaviorSince the java.lang.CharSequence class was first introduced in 1.4 the JavaDoc block has contained the following note:  This interface does not refine the general contracts of the equals and hashCode methods. The result of comparing two objects that implement CharSequence is therefore in general undefined. Each object may be implemented by a different class and there is no guarantee that each class will be capable of testing its instances for equality with those of the other. When the signature of the StringUtils equals() method was changed from equals(String String) to equals(CharSequence CharSequence) in R920543 the implementation still relied on calling CharSequence#equals(Object) even though in general the result is undefined. One example where equals(Object) returns false even though as CharSequences two objects represent equal sequences is when one object is an instance of javax.lang.model.element.Name and the other object is a String.", "A_clean_title": ["stringutil", "string", "util", "equal", "reli", "undefin", "behaviorsinc", "behavior", "sinc", "java", "lang", "charsequ", "char", "sequenc", "class", "wa", "first", "introduc", "javadoc", "java", "doc", "block", "ha", "contain", "follow", "note", "thi", "interfac", "not", "refin", "gener", "contract", "equal", "hashcod", "hash", "code", "method", "result", "compar", "two", "object", "that", "implement", "charsequ", "char", "sequenc", "therefor", "gener", "undefin", "each", "object", "may", "implement", "by", "differ", "class", "there", "no", "guarante", "that", "each", "class", "will", "capabl", "test", "it", "instanc", "equal", "those", "other", "when", "signatur", "stringutil", "string", "util", "equal", "method", "wa", "chang", "equal", "string", "string", "equal", "charsequ", "char", "sequenc", "charsequ", "char", "sequenc", "r920543", "implement", "still", "reli", "call", "charsequ", "char", "sequenc", "equal", "object", "even", "though", "gener", "result", "undefin", "one", "exampl", "where", "equal", "object", "return", "fals", "even", "though", "as", "charsequ", "char", "sequenc", "two", "object", "repres", "equal", "sequenc", "when", "one", "object", "instanc", "javax", "lang", "model", "element", "name", "other", "object", "string"], "B_title": "StringUtils equals() relies on undefined behavior; thanks to Daniel Trebbien", "B_clean_title": ["stringutil", "string", "util", "equal", "reli", "undefin", "behavior", "thank", "daniel", "trebbien"]},
{"A_title": "Moving or deleting tree instances with status NEW doesnt change its status to DISCONNECTEDFurther fall out from OAK-606:  code         Tree t = tree.addChild(new);          root.move(/x /y/x);         assertEquals(Status.DISCONNECTED t.getStatus()); code  The assertion fails.", "A_clean_title": ["move", "or", "delet", "tree", "instanc", "statu", "new", "doesnt", "chang", "it", "statu", "disconnectedfurth", "disconnect", "further", "fall", "out", "oak", "606", "code", "tree", "tree", "addchild", "add", "child", "new", "root", "move", "assertequ", "assert", "equal", "statu", "disconnect", "getstatu", "get", "statu", "code", "assert", "fail"], "B_title": "Moving or deleting tree instances with status NEW doesnt change its status to DISCONNECTED", "B_clean_title": ["move", "or", "delet", "tree", "instanc", "statu", "new", "doesnt", "chang", "it", "statu", "disconnect"]},
{"A_title": "ZooKeeperInstance only uses first ZooKeeper in list of quorumHad tests running which had a quorum of 3 ZooKeeper servers. One appears to have died and the test was then unable to connect to the Accumulo shell hanging on trying to connect to ZooKeeper.  There was no client.conf file present so a ClientConfiguration was constructed from accumulo-site.xml.  code this.zooKeepers = clientConf.get(ClientProperty.INSTANCE_ZK_HOST); code  When the commons configuration AbstractConfiguration class is used with the get() method only the first element in the value is returned as the implementation treats the other items as a list because of the default separator of a comma.  Its easily reproduced with the following:  code     ZooKeeperInstance inst = new ZooKeeperInstance(accumulo localhost127.0.0.1);     System.out.println(inst.getZooKeepers()); code  The above will print  noformat localhost noformat  instead of the expected  noformat localhost127.0.0.1 noformat", "A_clean_title": ["zookeeperinst", "zoo", "keeper", "instanc", "onli", "use", "first", "zookeep", "zoo", "keeper", "list", "quorumhad", "quorum", "had", "test", "run", "which", "had", "quorum", "zookeep", "zoo", "keeper", "server", "one", "appear", "have", "die", "test", "wa", "then", "unabl", "connect", "accumulo", "shell", "hang", "tri", "connect", "zookeep", "zoo", "keeper", "there", "wa", "no", "client", "conf", "file", "present", "so", "clientconfigur", "client", "configur", "wa", "construct", "accumulo", "site", "xml", "code", "thi", "zookeep", "zoo", "keeper", "clientconf", "get", "client", "conf", "clientproperti", "client", "properti", "instanc", "zk", "host", "code", "when", "common", "configur", "abstractconfigur", "abstract", "configur", "class", "use", "get", "method", "onli", "first", "element", "valu", "return", "as", "implement", "treat", "other", "item", "as", "list", "becaus", "default", "separ", "comma", "it", "easili", "reproduc", "follow", "code", "zookeeperinst", "zoo", "keeper", "instanc", "inst", "new", "zookeeperinst", "zoo", "keeper", "instanc", "accumulo", "localhost127", "system", "out", "println", "inst", "getzookeep", "get", "zoo", "keeper", "code", "abov", "will", "print", "noformat", "localhost", "noformat", "instead", "expect", "noformat", "localhost127", "noformat"], "B_title": "Set the list separator to 0 to disable list interpretation", "B_clean_title": ["set", "list", "separ", "disabl", "list", "interpret"]},
{"A_title": "Stack overflow in Beta.regularizedBetaIn org.apache.commons.math3.special.Beta.regularizedBeta(doubledoubledoubledoubleint) the case    else if (x > (a + 1.0) / (a + b + 2.0))        ret = 1.0 - regularizedBeta(1.0 - x b a epsilon maxIterations);    is prone to infinite recursion: If x is approximately the tested value then 1-x is approximately the tested value in the recursion. Thus due to loss of precision after the subtraction this condition can be true for the recursive call as well.  Example: double x= Double.longBitsToDouble(4597303555101269224L); double a= Double.longBitsToDouble(4634227472812299606L); double b = Double.longBitsToDouble(4642050131540049920L); System.out.println(x > (a + 1.0) / (a + b + 2.0)); System.out.println(1-x>(b + 1.0) / (b + a + 2.0)); System.out.println(1-(1-x)>(a + 1.0) / (a + b + 2.0));  Possible solution: change the condition to x > (a + 1.0) / (a + b + 2.0) && 1-x<=(b + 1.0) / (b + a + 2.0)", "A_clean_title": ["stack", "overflow", "beta", "regularizedbetain", "regular", "beta", "org", "apach", "common", "math3", "special", "beta", "regularizedbeta", "regular", "beta", "doubledoubledoubledoubleint", "case", "ret", "regularizedbeta", "regular", "beta", "epsilon", "maxiter", "max", "iter", "prone", "infinit", "recurs", "approxim", "test", "valu", "then", "approxim", "test", "valu", "recurs", "thu", "due", "loss", "precis", "after", "subtract", "thi", "condit", "true", "recurs", "call", "as", "well", "exampl", "doubl", "x=", "doubl", "longbitstodoubl", "long", "bit", "doubl", "4597303555101269224l", "doubl", "a=", "doubl", "longbitstodoubl", "long", "bit", "doubl", "4634227472812299606l", "doubl", "doubl", "longbitstodoubl", "long", "bit", "doubl", "4642050131540049920l", "system", "out", "println", "system", "out", "println", "system", "out", "println", "possibl", "solut", "chang", "condit"], "B_title": "Avoid infinite recursion. Thanks to Florian Erhard.", "B_clean_title": ["avoid", "infinit", "recurs", "thank", "florian", "erhard"]},
{"A_title": "NPE on DefaultJavaPrettyPrinter#printCtFieldAccessMore intel about bug reproduction can be found on the following issue:  HabchiSarra/SmellDetector#8 The full stack trace using spoon 5.9.0-SNAPSHOT below", "A_clean_title": ["npe", "defaultjavaprettyprint", "default", "java", "pretti", "printer", "printctfieldaccessmor", "print", "ct", "field", "access", "more", "intel", "about", "bug", "reproduct", "found", "follow", "issu", "habchisarra", "smelldetector", "habchi", "sarra", "smell", "detector", "full", "stack", "trace", "spoon", "snapshot", "below"], "B_title": "fix: fix NPE in noclasspath mode (#1502)  Fix #1501", "B_clean_title": ["fix", "fix", "npe", "noclasspath", "mode", "1502", "fix", "1501"]},
{"A_title": "Line.revert() is impreciseLine.revert() only maintains ~10 digits for the direction. This becomes an issue when the lines position is evaluated far from the origin. A simple fix would be to use Vector3D.negate() for the direction.  Also is there a reason why Line is not immutable? It is just comprised of two vectors.", "A_clean_title": ["line", "revert", "impreciselin", "revert", "imprecis", "line", "onli", "maintain", "~10", "digit", "direct", "thi", "becom", "issu", "when", "line", "posit", "evalu", "far", "origin", "simpl", "fix", "would", "use", "vector3d", "negat", "direct", "also", "there", "reason", "whi", "line", "not", "immut", "it", "just", "compris", "two", "vector"], "B_title": "Fixed accuracy of 3D Line.revert().", "B_clean_title": ["fix", "accuraci", "3d", "line", "revert"]},
{"A_title": "Write operations on Property do not check checked-out state of NodeWrite operations on Property do not check the checked-out state. The same is true for Node.setProperty(... null).", "A_clean_title": ["write", "oper", "properti", "not", "check", "check", "out", "state", "nodewrit", "node", "write", "oper", "properti", "not", "check", "check", "out", "state", "same", "true", "node", "setproperti", "set", "properti", "null"], "B_title": "consistently check the checked-out state of a Node for property modifications", "B_clean_title": ["consist", "check", "check", "out", "state", "node", "properti", "modif"]},
{"A_title": "Source files should not be put in binary JARSource files (*.java) should not be put into binary mockito-core.jar. It stupefies Idea to show decompiled file even when source jar is available.", "A_clean_title": ["sourc", "file", "not", "put", "binari", "jarsourc", "jar", "sourc", "file", "java", "not", "put", "into", "binari", "mockito", "core", "jar", "it", "stupefi", "idea", "show", "decompil", "file", "even", "when", "sourc", "jar", "avail"], "B_title": "Fixed issue 157 In order to avoid ArrayIndexOutOfBoundsException when anyvarag() matcher in use", "B_clean_title": ["fix", "issu", "157", "order", "avoid", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "when", "anyvarag", "matcher", "use"]},
{"A_title": "Trying to remove a missing property throws PathNotFoundExceptionThe following code snippet throws a PathNotFoundException if the missing property is not present.  code:java node.setProperty(missing (String) null); code  A better way to handle such a case would be for the above statement to simply do nothing.", "A_clean_title": ["tri", "remov", "miss", "properti", "throw", "pathnotfoundexceptionth", "path", "not", "found", "except", "follow", "code", "snippet", "throw", "pathnotfoundexcept", "path", "not", "found", "except", "miss", "properti", "not", "present", "code", "java", "node", "setproperti", "set", "properti", "miss", "string", "null", "code", "better", "way", "handl", "such", "case", "would", "abov", "statement", "simpli", "noth"], "B_title": "Trying to remove a missing property throws PathNotFoundException", "B_clean_title": ["tri", "remov", "miss", "properti", "throw", "pathnotfoundexcept", "path", "not", "found", "except"]},
{"A_title": "Resource bundles are not resolved on PriorityHeaderItemsIf a bundle X provides resource A and resource A is rendered as priority header item the resource A is rendered not bundle X.", "A_clean_title": ["resourc", "bundl", "are", "not", "resolv", "priorityheaderitemsif", "prioriti", "header", "item", "bundl", "provid", "resourc", "resourc", "render", "as", "prioriti", "header", "item", "resourc", "render", "not", "bundl"], "B_title": "unwrap wrapped header items when resolving bundles", "B_clean_title": ["unwrap", "wrap", "header", "item", "when", "resolv", "bundl"]},
{"A_title": "CachingResourceLocator lookup key doesnt take strict into accountCachingResourceLocator uses a CacheKey to store lookups for resources.   With e.g.  - b_nl.js - b.js  When e.g. a strict resource lookup for b.js with locale us is performed it will store the not-found for locale us under the cache key. The cache key consists of resource name locale style and variation. However when you search non-strict for locale us the resource locator should find the non-localized resource b.js but since a matching key for the lookup was stored for this particular resource it will fail.", "A_clean_title": ["cachingresourceloc", "cach", "resourc", "locat", "lookup", "key", "doesnt", "take", "strict", "into", "accountcachingresourceloc", "account", "cach", "resourc", "locat", "use", "cachekey", "cach", "key", "store", "lookup", "resourc", "js", "nl", "js", "when", "strict", "resourc", "lookup", "js", "local", "us", "perform", "it", "will", "store", "not", "found", "local", "us", "under", "cach", "key", "cach", "key", "consist", "resourc", "name", "local", "style", "variat", "howev", "when", "you", "search", "non", "strict", "local", "us", "resourc", "locat", "find", "non", "local", "resourc", "js", "but", "sinc", "match", "key", "lookup", "wa", "store", "thi", "particular", "resourc", "it", "will", "fail"], "B_title": "CachingResourceLocator lookup key doesnt take strict into account", "B_clean_title": ["cachingresourceloc", "cach", "resourc", "locat", "lookup", "key", "doesnt", "take", "strict", "into", "account"]},
{"A_title": "Precision.round() returns different results when provided negative zero as double or floatPrecision.round(-0.0d x) = 0.0 Precision.round(-0.0f x) = -0.0  After discussion on the mailinglist the result should always be -0.0.", "A_clean_title": ["precis", "round", "return", "differ", "result", "when", "provid", "neg", "zero", "as", "doubl", "or", "floatprecis", "round", "float", "precis", "0d", "precis", "round", "0f", "after", "discuss", "mailinglist", "result", "alway"], "B_title": "Precision.round(double ...) will return negative zero for negative values rounded to zero.", "B_clean_title": ["precis", "round", "doubl", "will", "return", "neg", "zero", "neg", "valu", "round", "zero"]},
{"A_title": "Diff reads too many nodesDocumentNodeStore.diffManyChildren() may read too many nodes when there is an inactive cluster node with an old _lastRev on the root document. This is a regression introduced with the fix for OAK-2232.  The fix assumes an inactive cluster node does not have a revision range with an old revision seen at a current timestamp. The DocumentNodeStore will in fact purge revisions from the range in the RevisionComparator after an hour. But on startup the first background read may populate the RevisionComparator with a revision which is potentially very old (e.g. if the clusterId is not used anymore).", "A_clean_title": ["diff", "read", "too", "mani", "nodesdocumentnodestor", "diffmanychildren", "node", "document", "node", "store", "diff", "mani", "children", "may", "read", "too", "mani", "node", "when", "there", "inact", "cluster", "node", "old", "lastrev", "last", "rev", "root", "document", "thi", "regress", "introduc", "fix", "oak", "2232", "fix", "assum", "inact", "cluster", "node", "not", "have", "revis", "rang", "old", "revis", "seen", "at", "current", "timestamp", "documentnodestor", "document", "node", "store", "will", "fact", "purg", "revis", "rang", "revisioncompar", "revis", "compar", "after", "hour", "but", "startup", "first", "background", "read", "may", "popul", "revisioncompar", "revis", "compar", "revis", "which", "potenti", "veri", "old", "clusterid", "cluster", "id", "not", "use", "anymor"], "B_title": "Diff reads too many nodes", "B_clean_title": ["diff", "read", "too", "mani", "node"]},
{"A_title": "Bulk random walk test failedThe bulk random walk test failed while running on a 10 node cluster w/ the following error message.  noformat 18 23:36:05167 bulk.Setup INFO : Starting bulk test on 459a04a0   19 00:24:33950 randomwalk.Framework ERROR: Error during random walk java.lang.Exception: Error running node Bulk.xml         at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:253)         at org.apache.accumulo.server.test.randomwalk.Framework.run(Framework.java:61)         at org.apache.accumulo.server.test.randomwalk.Framework.main(Framework.java:114)         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)         at java.lang.reflect.Method.invoke(Method.java:597)         at org.apache.accumulo.start.Main 1.run(Main.java:89)         at java.lang.Thread.run(Thread.java:662) Caused by: java.lang.Exception: Error running node bulk.Verify         at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:253)         at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:249)         ... 8 more Caused by: java.lang.Exception: Bad key at r0d646 cf:000  1326932285943 false -1         at org.apache.accumulo.server.test.randomwalk.bulk.Verify.visit(Verify.java:51)         at org.apache.accumulo.server.test.randomwalk.Module.visit(Module.java:249)         ... 9 more noformat  Looking at the table the rows r0d646 r0edd9 and r0f056 r10467 all had -1 values.  There was a tablet that overlapped the first range of -1 rows exactly 268;r0edd9;r0d645.  This tablet had only the following activity on a tablet server and was then merged out of existence.  The merge operation was 268;r10eff;r093b1.  noformat 19 00:05:10966 tabletserver.Tablet DEBUG: Files for low split 268;r0edd9;r0d645  /b-0001azp/I0001azt.rf /b-0001azp/I0001azu.rf /t-0001ale/A0001an3.rf 19 00:05:10974 tabletserver.Tablet TABLET_HIST: 268;r0f055;r0d645 split 268;r0edd9;r0d645 268;r0f055;r0edd9 19 00:05:10975 tabletserver.Tablet TABLET_HIST: 268;r0edd9;r0d645 opened  19 00:05:15029 tabletserver.Tablet TABLET_HIST: 268;r0edd9;r0d645 import /b-0001azi/I0001azm.rf 17138 0 19 00:05:15103 tabletserver.Tablet DEBUG: Starting MajC 268;r0edd9;r0d645 /b-0001azi/I0001azm.rf /b-0001azp/I0001azt.rf /b-0001azp/I0001azu.rf /t-0001ale/A0001an3.rf --> /t-0001apj/A0001bri.rf_tmp 19 00:05:15339 tabletserver.Tablet TABLET_HIST: 268;r0edd9;r0d645 import /b-0001azx/I0001azy.rf 16620 0 19 00:05:15651 tabletserver.Compactor DEBUG: Compaction 268;r0edd9;r0d645 181080 read | 60360 written | 553761 entries/sec |  0.327 secs 19 00:05:15661 tabletserver.Tablet TABLET_HIST: 268;r0edd9;r0d645 MajC /b-0001azi/I0001azm.rf /b-0001azp/I0001azt.rf /b-0001azp/I0001azu.rf /t-0001ale/A0001an3.rf --> /t-0001apj/A0001bri.rf 19 00:05:30672 tabletserver.Tablet DEBUG: Starting MajC 268;r0edd9;r0d645 /b-0001azx/I0001azy.rf --> /t-0001apj/C0001brn.rf_tmp 19 00:05:30810 tabletserver.Compactor DEBUG: Compaction 268;r0edd9;r0d645 60360 read | 60360 written | 534159 entries/sec |  0.113 secs 19 00:05:30824 tabletserver.Tablet TABLET_HIST: 268;r0edd9;r0d645 MajC /b-0001azx/I0001azy.rf --> /t-0001apj/C0001brn.rf 19 00:05:30943 tabletserver.Tablet DEBUG: initiateClose(saveState=true queueMinC=false disableWrites=false) 268;r0edd9;r0d645 19 00:05:30943 tabletserver.Tablet DEBUG: completeClose(saveState=true completeClose=true) 268;r0edd9;r0d645 19 00:05:30947 tabletserver.Tablet TABLET_HIST: 268;r0edd9;r0d645 closed 19 00:05:30947 tabletserver.TabletServer DEBUG: Unassigning 268;r0edd9;r0d645@(nullxxx.xxx.xxx.xxx:9997134d7425fc59413null) 19 00:05:30949 tabletserver.TabletServer INFO : unloaded 268;r0edd9;r0d645 19 00:05:30949 tabletserver.TabletServer INFO : unloaded 268;r0edd9;r0d645  noformat   For the second range of -1 values r0f056 r10467 r0f056 corresponds to the split point r0f055.  Howerver there is no split point corresponding to r10467. All of the tablets w/ a split of r0f055 lived on one tablet server.    noformat 19 00:02:21262 tabletserver.Tablet TABLET_HIST: 268<;r0d645 split 268;r0f055;r0d645 268<;r0f055 19 00:02:21263 tabletserver.Tablet TABLET_HIST: 268;r0f055;r0d645 opened  19 00:02:21264 tabletserver.Tablet TABLET_HIST: 268<;r0f055 opened  19 00:02:44504 tabletserver.Tablet TABLET_HIST: 268<;r0f055 split 268;r11da6;r0f055 268<;r11da6 19 00:02:44505 tabletserver.Tablet TABLET_HIST: 268;r11da6;r0f055 opened  19 00:05:10974 tabletserver.Tablet TABLET_HIST: 268;r0f055;r0d645 split 268;r0edd9;r0d645 268;r0f055;r0edd9 19 00:05:10975 tabletserver.Tablet TABLET_HIST: 268;r0f055;r0edd9 opened  19 00:05:15023 tabletserver.Tablet TABLET_HIST: 268;r11da6;r0f055 split 268;r0f622;r0f055 268;r11da6;r0f622 19 00:05:15024 tabletserver.Tablet TABLET_HIST: 268;r0f622;r0f055 opened  noformat  All of the tablets mentioned so far were all merged away in the same merge operation making this operation a possible place were data loss occurred.  However I can not pinpoint the issue at this point in time.  Below is a little info about the merge from the master logs showing which tablets were involved in the merge.  noformat 19 00:05:30616 master.EventCoordinator INFO : Merge state of 268;r10eff;r093b1 set to WAITING_FOR_CHOPPED 19 00:05:30677 master.Master INFO : Asking xxx.xxx.xxx.xxx:9997134d7425fc5940c to chop 268;r09927;r0903a 19 00:05:30678 master.Master INFO : Asking xxx.xxx.xxx.xxx:9997134d7425fc5940c to chop 268;r0ca9e;r09927 19 00:05:30678 master.Master INFO : Asking xxx.xxx.xxx.xxx:9997134d7425fc5940a to chop 268;r0d2b5;r0ca9e 19 00:05:30678 master.Master INFO : Asking xxx.xxx.xxx.xxx:9997134d7425fc59412 to chop 268;r0d645;r0d2b5 19 00:05:30678 master.Master INFO : Asking xxx.xxx.xxx.xxx:9997134d7425fc59413 to chop 268;r0edd9;r0d645 19 00:05:30678 master.Master INFO : Asking xxx.xxx.xxx.xxx:9997134d7425fc59413 to chop 268;r0f055;r0edd9 19 00:05:30678 master.Master INFO : Asking xxx.xxx.xxx.xxx:9997134d7425fc59413 to chop 268;r0f622;r0f055 19 00:05:30678 master.Master INFO : Asking xxx.xxx.xxx.xxx:9997134d7425fc59413 to chop 268;r0f68b;r0f622 19 00:05:30678 master.Master INFO : Asking xxx.xxx.xxx.xxx:9997134d7425fc59413 to chop 268;r10c14;r0f68b 19 00:05:30678 master.Master INFO : Asking xxx.xxx.xxx.xxx:9997134d7425fc59413 to chop 268;r110f7;r10c14 noformat  When this test verifies its data and detects data loss there is no easy way to determine at what time the data loss occurred.  It might be useful to modify the data in the bulk test such that it is easier to determine the time when data was lost.  For example the continuous ingest test creates linked list and it is possible to determine tight time bounds when a node was ingested.  However that may change the nature of this test and the bugs that it might find.", "A_clean_title": ["bulk", "random", "walk", "test", "failedth", "fail", "bulk", "random", "walk", "test", "fail", "while", "run", "10", "node", "cluster", "follow", "error", "messag", "noformat", "18", "23:36:05167", "bulk", "setup", "info", "start", "bulk", "test", "459a04a0", "19", "00:24:33950", "randomwalk", "framework", "error", "error", "dure", "random", "walk", "java", "lang", "except", "error", "run", "node", "bulk", "xml", "at", "org", "apach", "accumulo", "server", "test", "randomwalk", "modul", "visit", "modul", "java:253", "at", "org", "apach", "accumulo", "server", "test", "randomwalk", "framework", "run", "framework", "java:61", "at", "org", "apach", "accumulo", "server", "test", "randomwalk", "framework", "main", "framework", "java:114", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "org", "apach", "accumulo", "start", "main", "run", "main", "java:89", "at", "java", "lang", "thread", "run", "thread", "java:662", "caus", "by", "java", "lang", "except", "error", "run", "node", "bulk", "verifi", "at", "org", "apach", "accumulo", "server", "test", "randomwalk", "modul", "visit", "modul", "java:253", "at", "org", "apach", "accumulo", "server", "test", "randomwalk", "modul", "visit", "modul", "java:249", "more", "caus", "by", "java", "lang", "except", "bad", "key", "at", "r0d646", "cf:000", "1326932285943", "fals", "at", "org", "apach", "accumulo", "server", "test", "randomwalk", "bulk", "verifi", "visit", "verifi", "java:51", "at", "org", "apach", "accumulo", "server", "test", "randomwalk", "modul", "visit", "modul", "java:249", "more", "noformat", "look", "at", "tabl", "row", "r0d646", "r0edd9", "r0f056", "r10467", "all", "had", "valu", "there", "wa", "tablet", "that", "overlap", "first", "rang", "row", "exactli", "268", "r0edd9", "r0d645", "thi", "tablet", "had", "onli", "follow", "activ", "tablet", "server", "wa", "then", "merg", "out", "exist", "merg", "oper", "wa", "268", "r10eff", "r093b1", "noformat", "19", "00:05:10966", "tabletserv", "tablet", "debug", "file", "low", "split", "268", "r0edd9", "r0d645", "rf", "0001azp", "i0001azt", "rf", "0001azp", "i0001azu", "rf", "0001ale", "a0001an3", "19", "00:05:10974", "tabletserv", "tablet", "tablet", "hist", "268", "r0f055", "r0d645", "split", "268", "r0edd9", "r0d645", "268", "r0f055", "r0edd9", "19", "00:05:10975", "tabletserv", "tablet", "tablet", "hist", "268", "r0edd9", "r0d645", "open", "19", "00:05:15029", "tabletserv", "tablet", "tablet", "hist", "268", "r0edd9", "r0d645", "import", "rf", "0001azi", "i0001azm", "17138", "19", "00:05:15103", "tabletserv", "tablet", "debug", "start", "majc", "maj", "268", "r0edd9", "r0d645", "rf", "0001azi", "i0001azm", "rf", "0001azp", "i0001azt", "rf", "0001azp", "i0001azu", "rf", "0001ale", "a0001an3", "0001apj", "a0001bri", "rf", "tmp", "19", "00:05:15339", "tabletserv", "tablet", "tablet", "hist", "268", "r0edd9", "r0d645", "import", "rf", "0001azx", "i0001azi", "16620", "19", "00:05:15651", "tabletserv", "compactor", "debug", "compact", "268", "r0edd9", "r0d645", "181080", "read", "60360", "written", "553761", "entri", "sec", "327", "sec", "19", "00:05:15661", "tabletserv", "tablet", "tablet", "hist", "268", "r0edd9", "r0d645", "majc", "maj", "rf", "0001azi", "i0001azm", "rf", "0001azp", "i0001azt", "rf", "0001azp", "i0001azu", "rf", "0001ale", "a0001an3", "rf", "0001apj", "a0001bri", "19", "00:05:30672", "tabletserv", "tablet", "debug", "start", "majc", "maj", "268", "r0edd9", "r0d645", "rf", "0001azx", "i0001azi", "0001apj", "c0001brn", "rf", "tmp", "19", "00:05:30810", "tabletserv", "compactor", "debug", "compact", "268", "r0edd9", "r0d645", "60360", "read", "60360", "written", "534159", "entri", "sec", "113", "sec", "19", "00:05:30824", "tabletserv", "tablet", "tablet", "hist", "268", "r0edd9", "r0d645", "majc", "maj", "rf", "0001azx", "i0001azi", "rf", "0001apj", "c0001brn", "19", "00:05:30943", "tabletserv", "tablet", "debug", "initiateclos", "initi", "close", "savestate=tru", "save", "state=tru", "queueminc=fals", "queue", "min", "c=fals", "disablewrites=fals", "disabl", "writes=fals", "268", "r0edd9", "r0d645", "19", "00:05:30943", "tabletserv", "tablet", "debug", "completeclos", "complet", "close", "savestate=tru", "save", "state=tru", "completeclose=tru", "complet", "close=tru", "268", "r0edd9", "r0d645", "19", "00:05:30947", "tabletserv", "tablet", "tablet", "hist", "268", "r0edd9", "r0d645", "close", "19", "00:05:30947", "tabletserv", "tabletserv", "tablet", "server", "debug", "unassign", "268", "r0edd9", "r0d645", "nullxxx", "xxx", "xxx", "xxx:9997134d7425fc59413null", "19", "00:05:30949", "tabletserv", "tabletserv", "tablet", "server", "info", "unload", "268", "r0edd9", "r0d645", "19", "00:05:30949", "tabletserv", "tabletserv", "tablet", "server", "info", "unload", "268", "r0edd9", "r0d645", "noformat", "second", "rang", "valu", "r0f056", "r10467", "r0f056", "correspond", "split", "point", "r0f055", "howerv", "there", "no", "split", "point", "correspond", "r10467", "all", "tablet", "split", "r0f055", "live", "one", "tablet", "server", "noformat", "19", "00:02:21262", "tabletserv", "tablet", "tablet", "hist", "268", "r0d645", "split", "268", "r0f055", "r0d645", "268", "r0f055", "19", "00:02:21263", "tabletserv", "tablet", "tablet", "hist", "268", "r0f055", "r0d645", "open", "19", "00:02:21264", "tabletserv", "tablet", "tablet", "hist", "268", "r0f055", "open", "19", "00:02:44504", "tabletserv", "tablet", "tablet", "hist", "268", "r0f055", "split", "268", "r11da6", "r0f055", "268", "r11da6", "19", "00:02:44505", "tabletserv", "tablet", "tablet", "hist", "268", "r11da6", "r0f055", "open", "19", "00:05:10974", "tabletserv", "tablet", "tablet", "hist", "268", "r0f055", "r0d645", "split", "268", "r0edd9", "r0d645", "268", "r0f055", "r0edd9", "19", "00:05:10975", "tabletserv", "tablet", "tablet", "hist", "268", "r0f055", "r0edd9", "open", "19", "00:05:15023", "tabletserv", "tablet", "tablet", "hist", "268", "r11da6", "r0f055", "split", "268", "r0f622", "r0f055", "268", "r11da6", "r0f622", "19", "00:05:15024", "tabletserv", "tablet", "tablet", "hist", "268", "r0f622", "r0f055", "open", "noformat", "all", "tablet", "mention", "so", "far", "were", "all", "merg", "away", "same", "merg", "oper", "make", "thi", "oper", "possibl", "place", "were", "data", "loss", "occur", "howev", "not", "pinpoint", "issu", "at", "thi", "point", "time", "below", "littl", "info", "about", "merg", "master", "log", "show", "which", "tablet", "were", "involv", "merg", "noformat", "19", "00:05:30616", "master", "eventcoordin", "event", "coordin", "info", "merg", "state", "268", "r10eff", "r093b1", "set", "wait", "chop", "19", "00:05:30677", "master", "master", "info", "ask", "xxx", "xxx", "xxx", "xxx:9997134d7425fc5940c", "chop", "268", "r09927", "r0903a", "19", "00:05:30678", "master", "master", "info", "ask", "xxx", "xxx", "xxx", "xxx:9997134d7425fc5940c", "chop", "268", "r0ca9e", "r09927", "19", "00:05:30678", "master", "master", "info", "ask", "xxx", "xxx", "xxx", "xxx:9997134d7425fc5940a", "chop", "268", "r0d2b5", "r0ca9e", "19", "00:05:30678", "master", "master", "info", "ask", "xxx", "xxx", "xxx", "xxx:9997134d7425fc59412", "chop", "268", "r0d645", "r0d2b5", "19", "00:05:30678", "master", "master", "info", "ask", "xxx", "xxx", "xxx", "xxx:9997134d7425fc59413", "chop", "268", "r0edd9", "r0d645", "19", "00:05:30678", "master", "master", "info", "ask", "xxx", "xxx", "xxx", "xxx:9997134d7425fc59413", "chop", "268", "r0f055", "r0edd9", "19", "00:05:30678", "master", "master", "info", "ask", "xxx", "xxx", "xxx", "xxx:9997134d7425fc59413", "chop", "268", "r0f622", "r0f055", "19", "00:05:30678", "master", "master", "info", "ask", "xxx", "xxx", "xxx", "xxx:9997134d7425fc59413", "chop", "268", "r0f68b", "r0f622", "19", "00:05:30678", "master", "master", "info", "ask", "xxx", "xxx", "xxx", "xxx:9997134d7425fc59413", "chop", "268", "r10c14", "r0f68b", "19", "00:05:30678", "master", "master", "info", "ask", "xxx", "xxx", "xxx", "xxx:9997134d7425fc59413", "chop", "268", "r110f7", "r10c14", "noformat", "when", "thi", "test", "verifi", "it", "data", "detect", "data", "loss", "there", "no", "easi", "way", "determin", "at", "what", "time", "data", "loss", "occur", "it", "might", "use", "modifi", "data", "bulk", "test", "such", "that", "it", "easier", "determin", "time", "when", "data", "wa", "lost", "exampl", "continu", "ingest", "test", "creat", "link", "list", "it", "possibl", "determin", "tight", "time", "bound", "when", "node", "wa", "ingest", "howev", "that", "may", "chang", "natur", "thi", "test", "bug", "that", "it", "might", "find"], "B_title": "ACCUMULO-307 merged from 1.4", "B_clean_title": ["accumulo", "307", "merg"]},
{"A_title": "DateTimeField improperly converts time causing wrong dates when the servers current date is different from the clients date.The bug is in DateTimeField#convertInput(). <code> // Get year month and day ignoring any timezone of the Date object Calendar cal = Calendar.getInstance(); cal.setTime(dateFieldInput); int year = cal.get(Calendar.YEAR); int month = cal.get(Calendar.MONTH) + 1; int day = cal.get(Calendar.DAY_OF_MONTH); int hours = (hoursInput == null ? 0 : hoursInput % 24); int minutes = (minutesInput == null ? 0 : minutesInput);  // Use the input to create a date object with proper timezone MutableDateTime date = new MutableDateTime(year month day hours minutes 0 0 DateTimeZone.forTimeZone(getClientTimeZone())); </code> If the servers current date is different from the clients this produces wrong output. I attached a patch with a test case that simulates this condition.  I dont know why this casting of day month year is done.", "A_clean_title": ["datetimefield", "date", "time", "field", "improperli", "convert", "time", "caus", "wrong", "date", "when", "server", "current", "date", "differ", "client", "date", "bug", "datetimefield", "date", "time", "field", "convertinput", "convert", "input", "code", "get", "year", "month", "day", "ignor", "ani", "timezon", "date", "object", "calendar", "cal", "calendar", "getinst", "get", "instanc", "cal", "settim", "set", "time", "datefieldinput", "date", "field", "input", "int", "year", "cal", "get", "calendar", "year", "int", "month", "cal", "get", "calendar", "month", "int", "day", "cal", "get", "calendar", "day", "month", "int", "hour", "hoursinput", "hour", "input", "null", "hoursinput", "hour", "input", "24", "int", "minut", "minutesinput", "minut", "input", "null", "minutesinput", "minut", "input", "use", "input", "creat", "date", "object", "proper", "timezon", "mutabledatetim", "mutabl", "date", "time", "date", "new", "mutabledatetim", "mutabl", "date", "time", "year", "month", "day", "hour", "minut", "datetimezon", "fortimezon", "date", "time", "zone", "time", "zone", "getclienttimezon", "get", "client", "time", "zone", "code", "server", "current", "date", "differ", "client", "thi", "produc", "wrong", "output", "attach", "patch", "test", "case", "that", "simul", "thi", "condit", "dont", "know", "whi", "thi", "cast", "day", "month", "year", "done"], "B_title": "", "B_clean_title": []},
{"A_title": "Cancelling a running job can lead to restart instead of stoppingI just tried cancelling a regularly running job. Instead of the job stopping it restarted.   code 2016-02-29 10:39:28415 INFO  org.apache.flink.yarn.YarnJobManager                          - Trying to cancel job with ID 5c0604694c8469cfbb89daaa990068df. 2016-02-29 10:39:28416 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Source: Out of order data generator -> (Flat Map Timestamps/Watermarks) (1/1) (e3b05555ab0e373defb925898de9f200) switched from RUNNING to CANCELING .... 2016-02-29 10:39:28488 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - TriggerWindow(TumblingTimeWindows(60000) FoldingStateDescriptorname=window-contents defaultValue=(092233720368547758070) serializer=null EventTimeTrigger() WindowedStream.apply(WindowedStream.java:397)) (19/24) (c1be31b0be596d2521073b2d78ffa60a) switched from CANCELING to CANCELED 2016-02-29 10:40:08468 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Source: Out of order data generator -> (Flat Map Timestamps/Watermarks) (1/1) (e3b05555ab0e373defb925898de9f200) switched from CANCELING to FAILED 2016-02-29 10:40:08468 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - TriggerWindow(TumblingTimeWindows(60000) FoldingStateDescriptorname=window-contents defaultValue=(092233720368547758070) serializer=null EventTimeTrigger() WindowedStream.apply(WindowedStream.java:397)) (1/24) (5ad172ec9932b24d5a98377a2c82b0b3) switched from CANCELING to FAILED 2016-02-29 10:40:08472 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - TriggerWindow(TumblingTimeWindows(60000) FoldingStateDescriptorname=window-contents defaultValue=(092233720368547758070) serializer=null EventTimeTrigger() WindowedStream.apply(WindowedStream.java:397)) (2/24) (5404ca28ac7cf23b67dff30ef2309078) switched from CANCELING to FAILED 2016-02-29 10:40:08473 INFO  org.apache.flink.yarn.YarnJobManager                          - Status of job 5c0604694c8469cfbb89daaa990068df (Event counter: auto.offset.reset=earliest rocksdb=hdfs:///user/robert/rocksdb generateInPlace=soTrue parallelism=24 bootstrap.servers=cdh544-worker-0:9092 topic=eventsGenerator eventsPerKeyPerGenerator=2 numKeys=1000000000 zookeeper.connect=cdh544-worker-0:2181 timeSliceSize=60000 eventsKerPey=1 genPar=1) changed to FAILING. java.lang.Exception: Task could not be canceled. at org.apache.flink.runtime.executiongraph.Execution 5.onComplete(Execution.java:902) at akka.dispatch.OnComplete.internal(Future.scala:246) at akka.dispatch.OnComplete.internal(Future.scala:244) at akka.dispatch.japi CallbackBridge.apply(Future.scala:174) at akka.dispatch.japi CallbackBridge.apply(Future.scala:171) at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) at scala.concurrent.impl.ExecutionContextImpl  anon 3.exec(ExecutionContextImpl.scala:107) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) Caused by: akka.pattern.AskTimeoutException: Ask timed out on Actorakka.tcp://flink@10.240.242.143:50119/user/taskmanager#640539146 after 10000 ms at akka.pattern.PromiseActorRef  anonfun 1.apply mcV sp(AskSupport.scala:333) at akka.actor.Scheduler  anon 7.run(Scheduler.scala:117) at scala.concurrent.Future InternalCallbackExecutor .scala concurrent Future InternalCallbackExecutor  unbatchedExecute(Future.scala:694) at scala.concurrent.Future InternalCallbackExecutor .execute(Future.scala:691) at akka.actor.LightArrayRevolverScheduler TaskHolder.executeTask(Scheduler.scala:467) at akka.actor.LightArrayRevolverScheduler  anon 8.executeBucket 1(Scheduler.scala:419) at akka.actor.LightArrayRevolverScheduler  anon 8.nextTick(Scheduler.scala:423) at akka.actor.LightArrayRevolverScheduler  anon 8.run(Scheduler.scala:375) at java.lang.Thread.run(Thread.java:745) 2016-02-29 10:40:08477 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - TriggerWindow(TumblingTimeWindows(60000) FoldingStateDescriptorname=window-contents defaultValue=(092233720368547758070) serializer=null EventTimeTrigger() WindowedStream.apply(WindowedStream.java:397)) (3/24) (fc527d65ec8df3ccf68f882d968e776e) switched from CANCELING to FAILED 2016-02-29 10:40:08487 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - TriggerWindow(TumblingTimeWindows(60000) FoldingStateDescriptorname=window-contents defaultValue=(092233720368547758070) serializer=null EventTimeTrigger() WindowedStream.apply(WindowedStream.java:397)) (4/24) (afb1aa3c2d8acdee0f138cf344238e4e) switched from CANCELING to FAILED 2016-02-29 10:40:08488 INFO  org.apache.flink.runtime.executiongraph.restart.FixedDelayRestartStrategy  - Delaying retry of job execution for 3000 ms ... 2016-02-29 10:40:08488 INFO  org.apache.flink.yarn.YarnJobManager                          - Status of job 5c0604694c8469cfbb89daaa990068df (Event counter: auto.offset.reset=earliest rocksdb=hdfs:///user/robert/rocksdb generateInPlace=soTrue parallelism=24 bootstrap.servers=cdh544-worker-0:9092 topic=eventsGenerator eventsPerKeyPerGenerator=2 numKeys=1000000000 zookeeper.connect=cdh544-worker-0:2181 timeSliceSize=60000 eventsKerPey=1 genPar=1) changed to RESTARTING. 2016-02-29 10:40:11490 INFO  org.apache.flink.yarn.YarnJobManager                          - Status of job 5c0604694c8469cfbb89daaa990068df (Event counter: auto.offset.reset=earliest rocksdb=hdfs:///user/robert/rocksdb generateInPlace=soTrue parallelism=24 bootstrap.servers=cdh544-worker-0:9092 topic=eventsGenerator eventsPerKeyPerGenerator=2 numKeys=1000000000 zookeeper.connect=cdh544-worker-0:2181 timeSliceSize=60000 eventsKerPey=1 genPar=1) changed to CREATED. 2016-02-29 10:40:11490 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph        - Source: Out of order data generator -> (Flat Map Timestamps/Watermarks) (1/1) (1319b2f44d78d99948ffde4350c052d9) switched from CREATED to SCHEDULED 2016-02-29 10:40:11490 INFO  org.apache.flink.yarn.YarnJobManager                          - Status of job 5c0604694c8469cfbb89daaa990068df (Event counter: auto.offset.reset=earliest rocksdb=hdfs:///user/robert/rocksdb generateInPlace=soTrue parallelism=24 bootstrap.servers=cdh544-worker-0:9092 topic=eventsGenerator eventsPerKeyPerGenerator=2 numKeys=1000000000 zookeeper.connect=cdh544-worker-0:2181 timeSliceSize=60000 eventsKerPey=1 genPar=1) changed to RUNNING. code", "A_clean_title": ["cancel", "run", "job", "lead", "restart", "instead", "stoppingi", "stop", "just", "tri", "cancel", "regularli", "run", "job", "instead", "job", "stop", "it", "restart", "code", "2016", "02", "29", "10:39:28415", "info", "org", "apach", "flink", "yarn", "yarnjobmanag", "yarn", "job", "manag", "tri", "cancel", "job", "id", "5c0604694c8469cfbb89daaa990068df", "2016", "02", "29", "10:39:28416", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "sourc", "out", "order", "data", "gener", "flat", "map", "timestamp", "watermark", "e3b05555ab0e373defb925898de9f200", "switch", "run", "cancel", "2016", "02", "29", "10:39:28488", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "triggerwindow", "trigger", "window", "tumblingtimewindow", "tumbl", "time", "window", "60000", "foldingstatedescriptorname=window", "content", "fold", "state", "descriptorname=window", "defaultvalue=", "default", "value=", "092233720368547758070", "serializer=nul", "eventtimetrigg", "event", "time", "trigger", "windowedstream", "appli", "window", "stream", "windowedstream", "java:397", "window", "stream", "19", "24", "c1be31b0be596d2521073b2d78ffa60a", "switch", "cancel", "cancel", "2016", "02", "29", "10:40:08468", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "sourc", "out", "order", "data", "gener", "flat", "map", "timestamp", "watermark", "e3b05555ab0e373defb925898de9f200", "switch", "cancel", "fail", "2016", "02", "29", "10:40:08468", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "triggerwindow", "trigger", "window", "tumblingtimewindow", "tumbl", "time", "window", "60000", "foldingstatedescriptorname=window", "content", "fold", "state", "descriptorname=window", "defaultvalue=", "default", "value=", "092233720368547758070", "serializer=nul", "eventtimetrigg", "event", "time", "trigger", "windowedstream", "appli", "window", "stream", "windowedstream", "java:397", "window", "stream", "24", "5ad172ec9932b24d5a98377a2c82b0b3", "switch", "cancel", "fail", "2016", "02", "29", "10:40:08472", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "triggerwindow", "trigger", "window", "tumblingtimewindow", "tumbl", "time", "window", "60000", "foldingstatedescriptorname=window", "content", "fold", "state", "descriptorname=window", "defaultvalue=", "default", "value=", "092233720368547758070", "serializer=nul", "eventtimetrigg", "event", "time", "trigger", "windowedstream", "appli", "window", "stream", "windowedstream", "java:397", "window", "stream", "24", "5404ca28ac7cf23b67dff30ef2309078", "switch", "cancel", "fail", "2016", "02", "29", "10:40:08473", "info", "org", "apach", "flink", "yarn", "yarnjobmanag", "yarn", "job", "manag", "statu", "job", "5c0604694c8469cfbb89daaa990068df", "event", "counter", "auto", "offset", "reset=earliest", "rocksdb=hdf", "user", "robert", "rocksdb", "generateinplace=sotru", "gener", "place=so", "true", "parallelism=24", "worker", "0:9092", "bootstrap", "servers=cdh544", "topic=eventsgener", "topic=ev", "gener", "eventsperkeypergenerator=2", "event", "per", "key", "per", "generator=2", "numkeys=1000000000", "num", "keys=1000000000", "worker", "0:2181", "zookeep", "connect=cdh544", "timeslicesize=60000", "time", "slice", "size=60000", "eventskerpey=1", "event", "ker", "pey=1", "genpar=1", "gen", "par=1", "chang", "fail", "java", "lang", "except", "task", "could", "not", "cancel", "at", "org", "apach", "flink", "runtim", "executiongraph", "execut", "oncomplet", "complet", "execut", "java:902", "at", "akka", "dispatch", "oncomplet", "intern", "complet", "futur", "scala:246", "at", "akka", "dispatch", "oncomplet", "intern", "complet", "futur", "scala:244", "at", "akka", "dispatch", "japi", "callbackbridg", "appli", "callback", "bridg", "futur", "scala:174", "at", "akka", "dispatch", "japi", "callbackbridg", "appli", "callback", "bridg", "futur", "scala:171", "at", "scala", "concurr", "impl", "callbackrunn", "run", "callback", "runnabl", "promis", "scala:32", "at", "scala", "concurr", "impl", "executioncontextimpl", "execut", "context", "impl", "anon", "exec", "executioncontextimpl", "scala:107", "execut", "context", "impl", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "caus", "by", "akka", "pattern", "asktimeoutexcept", "ask", "timeout", "except", "ask", "time", "out", "actorakka", "tcp", "flink", "10", "240", "242", "143:50119", "user", "taskmanag", "640539146", "after", "10000", "ms", "at", "akka", "pattern", "promiseactorref", "promis", "actor", "ref", "anonfun", "appli", "mcv", "mc", "sp", "asksupport", "scala:333", "ask", "support", "at", "akka", "actor", "schedul", "anon", "run", "schedul", "scala:117", "at", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "unbatchedexecut", "unbatch", "execut", "futur", "scala:694", "at", "scala", "concurr", "futur", "internalcallbackexecutor", "intern", "callback", "executor", "execut", "futur", "scala:691", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "taskhold", "executetask", "task", "holder", "execut", "task", "schedul", "scala:467", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "executebucket", "execut", "bucket", "schedul", "scala:419", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "nexttick", "next", "tick", "schedul", "scala:423", "at", "akka", "actor", "lightarrayrevolverschedul", "light", "array", "revolv", "schedul", "anon", "run", "schedul", "scala:375", "at", "java", "lang", "thread", "run", "thread", "java:745", "2016", "02", "29", "10:40:08477", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "triggerwindow", "trigger", "window", "tumblingtimewindow", "tumbl", "time", "window", "60000", "foldingstatedescriptorname=window", "content", "fold", "state", "descriptorname=window", "defaultvalue=", "default", "value=", "092233720368547758070", "serializer=nul", "eventtimetrigg", "event", "time", "trigger", "windowedstream", "appli", "window", "stream", "windowedstream", "java:397", "window", "stream", "24", "fc527d65ec8df3ccf68f882d968e776", "switch", "cancel", "fail", "2016", "02", "29", "10:40:08487", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "triggerwindow", "trigger", "window", "tumblingtimewindow", "tumbl", "time", "window", "60000", "foldingstatedescriptorname=window", "content", "fold", "state", "descriptorname=window", "defaultvalue=", "default", "value=", "092233720368547758070", "serializer=nul", "eventtimetrigg", "event", "time", "trigger", "windowedstream", "appli", "window", "stream", "windowedstream", "java:397", "window", "stream", "24", "afb1aa3c2d8acdee0f138cf344238e4", "switch", "cancel", "fail", "2016", "02", "29", "10:40:08488", "info", "org", "apach", "flink", "runtim", "executiongraph", "restart", "fixeddelayrestartstrategi", "fix", "delay", "restart", "strategi", "delay", "retri", "job", "execut", "3000", "ms", "2016", "02", "29", "10:40:08488", "info", "org", "apach", "flink", "yarn", "yarnjobmanag", "yarn", "job", "manag", "statu", "job", "5c0604694c8469cfbb89daaa990068df", "event", "counter", "auto", "offset", "reset=earliest", "rocksdb=hdf", "user", "robert", "rocksdb", "generateinplace=sotru", "gener", "place=so", "true", "parallelism=24", "worker", "0:9092", "bootstrap", "servers=cdh544", "topic=eventsgener", "topic=ev", "gener", "eventsperkeypergenerator=2", "event", "per", "key", "per", "generator=2", "numkeys=1000000000", "num", "keys=1000000000", "worker", "0:2181", "zookeep", "connect=cdh544", "timeslicesize=60000", "time", "slice", "size=60000", "eventskerpey=1", "event", "ker", "pey=1", "genpar=1", "gen", "par=1", "chang", "restart", "2016", "02", "29", "10:40:11490", "info", "org", "apach", "flink", "yarn", "yarnjobmanag", "yarn", "job", "manag", "statu", "job", "5c0604694c8469cfbb89daaa990068df", "event", "counter", "auto", "offset", "reset=earliest", "rocksdb=hdf", "user", "robert", "rocksdb", "generateinplace=sotru", "gener", "place=so", "true", "parallelism=24", "worker", "0:9092", "bootstrap", "servers=cdh544", "topic=eventsgener", "topic=ev", "gener", "eventsperkeypergenerator=2", "event", "per", "key", "per", "generator=2", "numkeys=1000000000", "num", "keys=1000000000", "worker", "0:2181", "zookeep", "connect=cdh544", "timeslicesize=60000", "time", "slice", "size=60000", "eventskerpey=1", "event", "ker", "pey=1", "genpar=1", "gen", "par=1", "chang", "creat", "2016", "02", "29", "10:40:11490", "info", "org", "apach", "flink", "runtim", "executiongraph", "executiongraph", "execut", "graph", "sourc", "out", "order", "data", "gener", "flat", "map", "timestamp", "watermark", "1319b2f44d78d99948ffde4350c052d9", "switch", "creat", "schedul", "2016", "02", "29", "10:40:11490", "info", "org", "apach", "flink", "yarn", "yarnjobmanag", "yarn", "job", "manag", "statu", "job", "5c0604694c8469cfbb89daaa990068df", "event", "counter", "auto", "offset", "reset=earliest", "rocksdb=hdf", "user", "robert", "rocksdb", "generateinplace=sotru", "gener", "place=so", "true", "parallelism=24", "worker", "0:9092", "bootstrap", "servers=cdh544", "topic=eventsgener", "topic=ev", "gener", "eventsperkeypergenerator=2", "event", "per", "key", "per", "generator=2", "numkeys=1000000000", "num", "keys=1000000000", "worker", "0:2181", "zookeep", "connect=cdh544", "timeslicesize=60000", "time", "slice", "size=60000", "eventskerpey=1", "event", "ker", "pey=1", "genpar=1", "gen", "par=1", "chang", "run", "code"], "B_title": "runtime Prevent canceling Execution from failing", "B_clean_title": ["runtim", "prevent", "cancel", "execut", "fail"]},
{"A_title": "MockTables addMutation does not check for empty mutationWhen calling addMutation or addMutations on a MockBatchWriter the updates stored in the mutation are iterated over then committed in the MockTable class.   When this occurs in the TabletServerBatchWriter (eventually called from the BatchWriterImpl) however the mutation size is first checked and if the mutation size is 0 an IllegalArgumentException is thrown.  In practice if you have code that tries to submit an empty mutation to a BatchWriter it will fail and throw an exception in the real world but this will not be caught in tests against MockAccumulo.", "A_clean_title": ["mocktabl", "mock", "tabl", "addmut", "add", "mutat", "not", "check", "empti", "mutationwhen", "mutat", "when", "call", "addmut", "add", "mutat", "or", "addmut", "add", "mutat", "mockbatchwrit", "mock", "batch", "writer", "updat", "store", "mutat", "are", "iter", "over", "then", "commit", "mocktabl", "mock", "tabl", "class", "when", "thi", "occur", "tabletserverbatchwrit", "tablet", "server", "batch", "writer", "eventu", "call", "batchwriterimpl", "batch", "writer", "impl", "howev", "mutat", "size", "first", "check", "mutat", "size", "illegalargumentexcept", "illeg", "argument", "except", "thrown", "practic", "you", "have", "code", "that", "tri", "submit", "empti", "mutat", "batchwrit", "batch", "writer", "it", "will", "fail", "throw", "except", "real", "world", "but", "thi", "will", "not", "caught", "test", "against", "mockaccumulo", "mock", "accumulo"], "B_title": "- merging Ryan Learys patch with modifications to update and remove warnings", "B_clean_title": ["merg", "ryan", "leari", "patch", "modif", "updat", "remov", "warn"]},
{"A_title": "use @InjectMocks for final fields.Im trying to upgrade the mockito version that were using (1.8.5) to a newer version but there is a problem with @InjectMocks which since 1.9.0 doesnt inject into final field anymore.", "A_clean_title": ["use", "injectmock", "inject", "mock", "final", "field", "im", "tri", "upgrad", "mockito", "version", "that", "were", "newer", "version", "but", "there", "problem", "injectmock", "inject", "mock", "which", "sinc", "doesnt", "inject", "into", "final", "field", "anymor"], "B_title": "issue 352 : With answer ReturnsEmptyValues Mockito-mocked methods returning primitive types other than int throw ClassCastException: java.lang.Integer. Thanks to Jesse Wilson for spotting that one and providing a patch. I changed a few things however  especially:  - used Primitives utility class instead  - applied underscored names for test cases as decided internally", "B_clean_title": ["issu", "352", "answer", "returnsemptyvalu", "return", "empti", "valu", "mockito", "mock", "method", "return", "primit", "type", "other", "than", "int", "throw", "classcastexcept", "class", "cast", "except", "java", "lang", "integ", "thank", "jess", "wilson", "spot", "that", "one", "provid", "patch", "chang", "few", "thing", "howev", "especi", "use", "primit", "util", "class", "instead", "appli", "underscor", "name", "test", "case", "as", "decid", "intern"]},
{"A_title": "Return error code 400 when an Ajax request has no base url set in header/request parameters.Hello  currently weve got a problem with faked ajax requests. these ajax  requests misses some parameters but the wicket-ajax header flag is set.  So ServletWebRequest throws an exception:  java.lang.IllegalStateException: Current ajax request is missing the base url header or parameter          at org.apache.wicket.util.lang.Checks.notNull(Checks.java:38)          at org.apache.wicket.protocol.http.servlet.ServletWebRequest.getClientUrl(ServletWebRequest.java:171)          at org.apache.wicket.request.UrlRenderer.<init>(UrlRenderer.java:59)   These faked requests are so massive that our application is no longer  monitorable. Our workaround rejects these requests via apache config.   Instead of logging an exception in deployment mode wicket should log a warning and reject the request", "A_clean_title": ["return", "error", "code", "400", "when", "ajax", "request", "ha", "no", "base", "url", "set", "header", "request", "paramet", "hello", "current", "weve", "got", "problem", "fake", "ajax", "request", "these", "ajax", "request", "miss", "some", "paramet", "but", "wicket", "ajax", "header", "flag", "set", "so", "servletwebrequest", "servlet", "web", "request", "throw", "except", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "current", "ajax", "request", "miss", "base", "url", "header", "or", "paramet", "at", "org", "apach", "wicket", "util", "lang", "check", "notnul", "not", "null", "check", "java:38", "at", "org", "apach", "wicket", "protocol", "http", "servlet", "servletwebrequest", "getclienturl", "servlet", "web", "request", "get", "client", "url", "servletwebrequest", "java:171", "servlet", "web", "request", "at", "org", "apach", "wicket", "request", "urlrender", "url", "render", "init", "urlrender", "java:59", "url", "render", "these", "fake", "request", "are", "so", "massiv", "that", "our", "applic", "no", "longer", "monitor", "our", "workaround", "reject", "these", "request", "via", "apach", "config", "instead", "log", "except", "deploy", "mode", "wicket", "log", "warn", "reject", "request"], "B_title": "Return error code 400 when an Ajax request has no base url set in header/request parameters.", "B_clean_title": ["return", "error", "code", "400", "when", "ajax", "request", "ha", "no", "base", "url", "set", "header", "request", "paramet"]},
{"A_title": "meitrack temp sensor with negative valueHi Anton  Im receiving a wrong value from temp sensor for negative temp values example: data for temp is 06FB2E which should translate to -12.34°C according to doc for protocol v3.  Could you please check if traccar is reading temp correctly for negative values?  a sample data to test with:   Regards", "A_clean_title": ["meitrack", "temp", "sensor", "neg", "valuehi", "valu", "hi", "anton", "im", "receiv", "wrong", "valu", "temp", "sensor", "neg", "temp", "valu", "exampl", "data", "temp", "06fb2e", "which", "translat", "12", "34°c", "accord", "doc", "protocol", "v3", "could", "you", "pleas", "check", "traccar", "read", "temp", "correctli", "neg", "valu", "sampl", "data", "test", "regard"], "B_title": "Fix Meitrack temperature (fix #3604)", "B_clean_title": ["fix", "meitrack", "temperatur", "fix", "3604"]},
{"A_title": "Simplex Solver arrives at incorrect solutionI have reduced the problem reported to me down to a minimal test case which I will attach.", "A_clean_title": ["simplex", "solver", "arriv", "at", "incorrect", "solutioni", "solut", "have", "reduc", "problem", "report", "me", "down", "minim", "test", "case", "which", "will", "attach"], "B_title": "Fixed a problem when setting some variables (several variables were set instead of only one) JIRA: MATH-272", "B_clean_title": ["fix", "problem", "when", "set", "some", "variabl", "sever", "variabl", "were", "set", "instead", "onli", "one", "jira", "math", "272"]},
{"A_title": "Incorrect date parsed when week and month used togetherIt should print 2011-01-03 but it is printing 2010-01-04.", "A_clean_title": ["incorrect", "date", "pars", "when", "week", "month", "use", "togetherit", "togeth", "it", "print", "2011", "01", "03", "but", "it", "print", "2010", "01", "04"], "B_title": "Conversion from parsed values to a date-time handles weird sets of fields better 3161586 This change is mostly for combinations like weekyear-month-week The new code doesnt handle all combinations perfectly but its better than it was", "B_clean_title": ["convers", "pars", "valu", "date", "time", "handl", "weird", "set", "field", "better", "3161586", "thi", "chang", "mostli", "combin", "like", "weekyear", "month", "week", "new", "code", "doesnt", "handl", "all", "combin", "perfectli", "but", "it", "better", "than", "it", "wa"]},
{"A_title": "NativeQuery with Pagination validation error at startup DATAJPA-928opened and commented According to Example 50 at  Using @Query docs  its possible to use a native query with pagination using Pageable but in my case its failing with a org.springframework.data.jpa.repository.query.InvalidJpaQueryMethodException. NativeJpaQuery constructor is checking if the query has a Pageable parameter and if the queryString contains a #pageable or #sort sequence. The query has Pageable parameter but it  does not contain a #pageable string:   If I provide a #pageable string at the end of the query validation passes but when the query executes it fails saying that its expecting 3 parameters instead of 2.  Funny thing is that when the server is starting if I set a breakpoint inside NativeJpaQuery and change containsPageableOrSortInQueryExpression from false to true manually validation passes just fine and the query executes well paginating    Affects: 1.10.1 (Hopper SR1) 1.10.2 (Hopper SR2)  Reference URL:  http://stackoverflow.com/questions/38349930/spring-data-and-native-query-with-pagination  Issue Links:     Referenced from: pull request #246  and commits     Backported to:  2.0.4 (Kay SR4) 1 votes 12 watchers", "A_clean_title": ["nativequeri", "nativ", "queri", "pagin", "valid", "error", "at", "startup", "datajpa", "928open", "comment", "accord", "exampl", "50", "at", "queri", "doc", "it", "possibl", "use", "nativ", "queri", "pagin", "pageabl", "but", "my", "case", "it", "fail", "org", "springframework", "data", "jpa", "repositori", "queri", "invalidjpaquerymethodexcept", "invalid", "jpa", "queri", "method", "except", "nativejpaqueri", "nativ", "jpa", "queri", "constructor", "check", "queri", "ha", "pageabl", "paramet", "querystr", "queri", "string", "contain", "pageabl", "or", "sort", "sequenc", "queri", "ha", "pageabl", "paramet", "but", "it", "not", "contain", "pageabl", "string", "provid", "pageabl", "string", "at", "end", "queri", "valid", "pass", "but", "when", "queri", "execut", "it", "fail", "say", "that", "it", "expect", "paramet", "instead", "funni", "thing", "that", "when", "server", "start", "set", "breakpoint", "insid", "nativejpaqueri", "nativ", "jpa", "queri", "chang", "containspageableorsortinqueryexpress", "contain", "pageabl", "or", "sort", "queri", "express", "fals", "true", "manual", "valid", "pass", "just", "fine", "queri", "execut", "well", "pagin", "affect", "10", "hopper", "sr1", "10", "hopper", "sr2", "refer", "url", "http", "data", "nativ", "queri", "pagin", "stackoverflow", "com", "question", "38349930", "spring", "issu", "link", "referenc", "pull", "request", "246", "commit", "backport", "kay", "sr4", "vote", "12", "watcher"], "B_title": "DATAJPA-928 - Enabled native query with Pageable.  Just removed the check that was actively preventing the use of Pageable. Migrated to tests to AssertJ where applicable.  Original pull request: #246.", "B_clean_title": ["datajpa", "928", "enabl", "nativ", "queri", "pageabl", "just", "remov", "check", "that", "wa", "activ", "prevent", "use", "pageabl", "migrat", "test", "assertj", "assert", "where", "applic", "origin", "pull", "request", "246"]},
{"A_title": "BSPTree class and recovery of a Euclidean 3D BRepNew to the work here. Thanks for your efforts on this code.  I create a BSPTree from a BoundaryRep (Brep) my test Brep is a cube as represented by a float array containing 8 3D points in(xyz) order and an array of indices (12 triplets for the 12 faces of the cube). I construct a BSPMesh() as shown in the code below. I can construct the PolyhedronsSet() but have problems extracting the faces from the BSPTree to reconstruct the BRep. The attached code (BSPMesh2.java) shows that a small change to 1 of the vertex positions causes/corrects the problem.  Any ideas?", "A_clean_title": ["bsptree", "bsp", "tree", "class", "recoveri", "euclidean", "3d", "brepnew", "rep", "new", "work", "here", "thank", "your", "effort", "thi", "code", "creat", "bsptree", "bsp", "tree", "boundaryrep", "boundari", "rep", "brep", "my", "test", "brep", "cube", "as", "repres", "by", "float", "array", "contain", "3d", "point", "xyz", "order", "array", "indic", "12", "triplet", "12", "face", "cube", "construct", "bspmesh", "bsp", "mesh", "as", "shown", "code", "below", "construct", "polyhedronsset", "polyhedron", "set", "but", "have", "problem", "extract", "face", "bsptree", "bsp", "tree", "reconstruct", "brep", "rep", "attach", "code", "bspmesh2", "java", "bsp", "mesh2", "show", "that", "small", "chang", "vertex", "posit", "caus", "correct", "problem", "ani", "idea"], "B_title": "Fixed a wrong assumption on BSP tree attributes.", "B_clean_title": ["fix", "wrong", "assumpt", "bsp", "tree", "attribut"]},
{"A_title": "UnmergedBranch state growing with empty BranchCommit leading to performance degradationIn some cluster deployment cases it has been seen that in memory state of UnmergedBranches contains large number of empty commits. For e.g. in  one of of the runs there were 750 entries in the UnmergedBranches and each Branch had empty branch commits.  If there are large number of UnmergedBranches then read performance would degrade as for determining revision validity currently logic scans all branches  Below is some part of UnmergedBranch state  noformat Branch 1 1 -> br146d2edb7a7-0-1 (true) (revision: br146d2edb7a7-0-1 clusterId: 1 time: 2014-06-25 05:08:52.903 branch: true) 2 -> br146d2f0450b-0-1 (true) (revision: br146d2f0450b-0-1 clusterId: 1 time: 2014-06-25 05:11:40.171 branch: true) Branch 2 1 -> br146d2ef1d08-0-1 (true) (revision: br146d2ef1d08-0-1 clusterId: 1 time: 2014-06-25 05:10:24.392 branch: true) Branch 3 1 -> br146d2ed26ca-0-1 (true) (revision: br146d2ed26ca-0-1 clusterId: 1 time: 2014-06-25 05:08:15.818 branch: true) 2 -> br146d2edfd0e-0-1 (true) (revision: br146d2edfd0e-0-1 clusterId: 1 time: 2014-06-25 05:09:10.670 branch: true) Branch 4 1 -> br146d2ecd85b-0-1 (true) (revision: br146d2ecd85b-0-1 clusterId: 1 time: 2014-06-25 05:07:55.739 branch: true) Branch 5 1 -> br146d2ec21a0-0-1 (true) (revision: br146d2ec21a0-0-1 clusterId: 1 time: 2014-06-25 05:07:08.960 branch: true) 2 -> br146d2ec8eca-0-1 (true) (revision: br146d2ec8eca-0-1 clusterId: 1 time: 2014-06-25 05:07:36.906 branch: true) Branch 6 1 -> br146d2eaf159-1-1 (true) (revision: br146d2eaf159-1-1 clusterId: 1 time: 2014-06-25 05:05:51.065 counter: 1 branch: true) Branch 7 1 -> br146d2e9a513-0-1 (true) (revision: br146d2e9a513-0-1 clusterId: 1 time: 2014-06-25 05:04:26.003 branch: true) noformat  ~mreutegg Suggested that these branch might be for those revision which have resulted in a collision and upon checking it indeed appears to be the case  (value true in brackets above indicate that). Further given the age of such revision it looks like they get populated upon startup itself  *Fix* * Need to check why we need to populate the UnermgedBranch * Possibly implement some purge job which would remove such stale entries", "A_clean_title": ["unmergedbranch", "unmerg", "branch", "state", "grow", "empti", "branchcommit", "branch", "commit", "lead", "perform", "degradationin", "degrad", "some", "cluster", "deploy", "case", "it", "ha", "been", "seen", "that", "memori", "state", "unmergedbranch", "unmerg", "branch", "contain", "larg", "number", "empti", "commit", "one", "run", "there", "were", "750", "entri", "unmergedbranch", "unmerg", "branch", "each", "branch", "had", "empti", "branch", "commit", "there", "are", "larg", "number", "unmergedbranch", "unmerg", "branch", "then", "read", "perform", "would", "degrad", "as", "determin", "revis", "valid", "current", "logic", "scan", "all", "branch", "below", "some", "part", "unmergedbranch", "unmerg", "branch", "state", "noformat", "branch", "br146d2edb7a7", "true", "revis", "br146d2edb7a7", "clusterid", "cluster", "id", "time", "2014", "06", "25", "05:08:52", "903", "branch", "true", "br146d2f0450b", "true", "revis", "br146d2f0450b", "clusterid", "cluster", "id", "time", "2014", "06", "25", "05:11:40", "171", "branch", "true", "branch", "br146d2ef1d08", "true", "revis", "br146d2ef1d08", "clusterid", "cluster", "id", "time", "2014", "06", "25", "05:10:24", "392", "branch", "true", "branch", "br146d2ed26ca", "true", "revis", "br146d2ed26ca", "clusterid", "cluster", "id", "time", "2014", "06", "25", "05:08:15", "818", "branch", "true", "br146d2edfd0", "true", "revis", "br146d2edfd0", "clusterid", "cluster", "id", "time", "2014", "06", "25", "05:09:10", "670", "branch", "true", "branch", "br146d2ecd85b", "true", "revis", "br146d2ecd85b", "clusterid", "cluster", "id", "time", "2014", "06", "25", "05:07:55", "739", "branch", "true", "branch", "br146d2ec21a0", "true", "revis", "br146d2ec21a0", "clusterid", "cluster", "id", "time", "2014", "06", "25", "05:07:08", "960", "branch", "true", "br146d2ec8eca", "true", "revis", "br146d2ec8eca", "clusterid", "cluster", "id", "time", "2014", "06", "25", "05:07:36", "906", "branch", "true", "branch", "br146d2eaf159", "true", "revis", "br146d2eaf159", "clusterid", "cluster", "id", "time", "2014", "06", "25", "05:05:51", "065", "counter", "branch", "true", "branch", "br146d2e9a513", "true", "revis", "br146d2e9a513", "clusterid", "cluster", "id", "time", "2014", "06", "25", "05:04:26", "003", "branch", "true", "noformat", "~mreutegg", "suggest", "that", "these", "branch", "might", "those", "revis", "which", "have", "result", "collis", "upon", "check", "it", "inde", "appear", "case", "valu", "true", "bracket", "abov", "indic", "that", "further", "given", "age", "such", "revis", "it", "look", "like", "they", "get", "popul", "upon", "startup", "itself", "fix", "need", "check", "whi", "we", "need", "popul", "unermgedbranch", "unermg", "branch", "possibl", "implement", "some", "purg", "job", "which", "would", "remov", "such", "stale", "entri"], "B_title": "- UnmergedBranch state growing with empty BranchCommit leading to performance degradation", "B_clean_title": ["unmergedbranch", "unmerg", "branch", "state", "grow", "empti", "branchcommit", "branch", "commit", "lead", "perform", "degrad"]},
{"A_title": "NumberUtils createNumber throws a StringIndexOutOfBoundsException when argument containing e and E is passed inNumberUtils createNumber throws a StringIndexOutOfBoundsException instead of NumberFormatException when a String containing both possible exponent indicators is passed in. One example of such a String is 1eE.", "A_clean_title": ["numberutil", "number", "util", "createnumb", "creat", "number", "throw", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "when", "argument", "contain", "pass", "innumberutil", "number", "util", "createnumb", "creat", "number", "throw", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "instead", "numberformatexcept", "number", "format", "except", "when", "string", "contain", "both", "possibl", "expon", "indic", "pass", "one", "exampl", "such", "string", "1ee", "1e"], "B_title": "Making it so that NumberUtils.createNumber throws a NumberFormatException instead of a StringIndexOutOfBoundsException when Strings such as 1eE are passed in. Thanks to Ingo Heinrichs report and patch in LANG-638", "B_clean_title": ["make", "it", "so", "that", "numberutil", "createnumb", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "instead", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "when", "string", "such", "as", "1ee", "1e", "are", "pass", "thank", "ingo", "heinrich", "report", "patch", "lang", "638"]},
{"A_title": "Need range checks for elitismRate in ElitisticListPopulation constructors.There is a range check for setting the elitismRate via ElitisticListPopulations setElitismRate method but not via the constructors.", "A_clean_title": ["need", "rang", "check", "elitismr", "elit", "rate", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "there", "rang", "check", "set", "elitismr", "elit", "rate", "via", "elitisticlistpopul", "elitist", "list", "popul", "setelitismr", "set", "elit", "rate", "method", "but", "not", "via", "constructor"], "B_title": "Use same range check in ctor as in setter for ElitisticListPopulation. Thanks to Reid Hochstedler", "B_clean_title": ["use", "same", "rang", "check", "ctor", "as", "setter", "elitisticlistpopul", "elitist", "list", "popul", "thank", "reid", "hochstedl"]},
{"A_title": "IndexRule not respecting inheritence based on mixinsIndexRule are meant to be applied based on both primaryType and minin type based inheritance. Currently it appears that only primaryType based inheritance is working", "A_clean_title": ["indexrul", "index", "rule", "not", "respect", "inherit", "base", "mixinsindexrul", "mixin", "index", "rule", "are", "meant", "appli", "base", "both", "primarytyp", "primari", "type", "minin", "type", "base", "inherit", "current", "it", "appear", "that", "onli", "primarytyp", "primari", "type", "base", "inherit", "work"], "B_title": "- IndexRule not respecting inheritence based on mixins", "B_clean_title": ["indexrul", "index", "rule", "not", "respect", "inherit", "base", "mixin"]},
{"A_title": "Broken Link in Tomcat because of Page MountI post this message on the user mailing List (http://apache-wicket.1842946.n4.nabble.com/Broken-Link-in-Tomcat-because-of-Page-Mount-tt4659663.html) and Martin Grigorov asked me to create a ticket on Jira.  Broken Link in Tomcat because of Page Mount  Following situation: -I have a Wicket Application(6.8.0) which runs under the context webapp on a Tomcat 7.0.41 -I mount a Page with two parameters (this is important) in the WicketApplication. mountPage(/mount/ parameter1/ parameter2 MountedPage.class); -The mounted Page(MountedPage.class) has only a simple Link -There are two links on the HomePage to the mounted Page.  They are declared as follows:   add(new Link<Void>(link)  @Override public void onClick()  setResponsePage(MountedPage.class linkParameters);  );  add(new Link<Void>(brokenLink)  @Override public void onClick()  setResponsePage(new MountedPage(linkParameters));  );  I deploy this Application as a war file on a Tomcat under the context webapp. When I call the first Link on the HomePage and then the Link on the mounted Page everything works fine.  But if I call the second Link and then the Link on the mounted Page the link is broken. The context is missing in the generated link http://localhost:8080/wicket/bookmarkable/com.mycompany.LinkedPage  Does anyone have an idea why the second link does not work on Tomcat?  I add a Quickstart and the war file as attachment.  Ps: Both links works fine in Jetty.  Pss:If I remove the mount command both links will work in  Tomcat too.", "A_clean_title": ["broken", "link", "tomcat", "becaus", "page", "mounti", "mount", "post", "thi", "messag", "user", "mail", "list", "http", "link", "tomcat", "becaus", "page", "mount", "apach", "wicket", "1842946", "n4", "nabbl", "tt4659663", "html", "com", "broken", "martin", "grigorov", "ask", "me", "creat", "ticket", "jira", "broken", "link", "tomcat", "becaus", "page", "mount", "follow", "situat", "have", "wicket", "applic", "which", "run", "under", "context", "webapp", "tomcat", "41", "mount", "page", "two", "paramet", "thi", "import", "wicketappl", "wicket", "applic", "mountpag", "mount", "page", "mount", "parameter1", "parameter2", "mountedpag", "class", "mount", "page", "mount", "page", "mountedpag", "class", "mount", "page", "ha", "onli", "simpl", "link", "there", "are", "two", "link", "homepag", "home", "page", "mount", "page", "they", "are", "declar", "as", "follow", "add", "new", "link", "void", "link", "overrid", "public", "void", "onclick", "click", "setresponsepag", "set", "respons", "page", "mountedpag", "class", "mount", "page", "linkparamet", "link", "paramet", "add", "new", "link", "void", "brokenlink", "broken", "link", "overrid", "public", "void", "onclick", "click", "setresponsepag", "set", "respons", "page", "new", "mountedpag", "mount", "page", "linkparamet", "link", "paramet", "deploy", "thi", "applic", "as", "war", "file", "tomcat", "under", "context", "webapp", "when", "call", "first", "link", "homepag", "home", "page", "then", "link", "mount", "page", "everyth", "work", "fine", "but", "call", "second", "link", "then", "link", "mount", "page", "link", "broken", "context", "miss", "gener", "link", "http", "mycompani", "linkedpag", "localhost:8080", "wicket", "bookmark", "com", "link", "page", "anyon", "have", "idea", "whi", "second", "link", "not", "work", "tomcat", "add", "quickstart", "war", "file", "as", "attach", "ps", "both", "link", "work", "fine", "jetti", "pss", "remov", "mount", "command", "both", "link", "will", "work", "tomcat", "too"], "B_title": "dont map handler when value for required placeholder is missing", "B_clean_title": ["dont", "map", "handler", "when", "valu", "requir", "placehold", "miss"]},
{"A_title": "JavaScriptStripper fails with single line commentsThe valid input x++ // x++  gets transformed to x++ x++  which is syntactically invalid. This breaks the unminified version of bootstrap 2.1.1.  The problem doesnt occur with multiline comments because the linebreaks are preserved there.", "A_clean_title": ["javascriptstripp", "java", "script", "stripper", "fail", "singl", "line", "commentsth", "comment", "valid", "input", "x++", "x++", "get", "transform", "x++", "x++", "which", "syntact", "invalid", "thi", "break", "unminifi", "version", "bootstrap", "problem", "doesnt", "occur", "multilin", "comment", "becaus", "linebreak", "are", "preserv", "there"], "B_title": "JavaScriptStripper fails with single line comments", "B_clean_title": ["javascriptstripp", "java", "script", "stripper", "fail", "singl", "line", "comment"]},
{"A_title": "Non-blocking reindexing doesnt finish properlyThe non blocking reindexer needs to run at least 2 cycles before setting the index definition back to synchronous mode. Currently it is too eager to mark the status as done which confuses the _PropertyIndexAsyncReindex_ mbean into thinking the indexing is over and so skipping the final round that is supposed to do the switch back to sync mode.", "A_clean_title": ["non", "block", "reindex", "doesnt", "finish", "properlyth", "properli", "non", "block", "reindex", "need", "run", "at", "least", "cycl", "befor", "set", "index", "definit", "back", "synchron", "mode", "current", "it", "too", "eager", "mark", "statu", "as", "done", "which", "confus", "propertyindexasyncreindex", "properti", "index", "async", "reindex", "mbean", "into", "think", "index", "over", "so", "skip", "final", "round", "that", "suppos", "switch", "back", "sync", "mode"], "B_title": "Non-blocking reindexing doesnt finish properly", "B_clean_title": ["non", "block", "reindex", "doesnt", "finish", "properli"]},
{"A_title": "SimplexSolver returns unfeasible solutionThe SimplexSolver is returning an unfeasible solution:  import java.util.ArrayList; import java.text.DecimalFormat; import org.apache.commons.math.linear.ArrayRealVector; import org.apache.commons.math.optimization.GoalType; import org.apache.commons.math.optimization.OptimizationException; import org.apache.commons.math.optimization.linear.*;  public class SimplexSolverBug           public static void main(String args) throws OptimizationException                   LinearObjectiveFunction c = new LinearObjectiveFunction(new double0.0d 1.0d 1.0d 0.0d 0.0d 0.0d 0.0d 0.0d);                  ArrayList<LinearConstraint> cnsts = new ArrayList<LinearConstraint>(5);         LinearConstraint cnst;         cnst = new LinearConstraint(new double 1.0d -0.1d 0.0d 0.0d 0.0d 0.0d 0.0d Relationship.EQ -0.1d);         cnsts.add(cnst);         cnst = new LinearConstraint(new double 1.0d 0.0d 0.0d 0.0d 0.0d 0.0d 0.0d Relationship.GEQ -1e-18d);         cnsts.add(cnst);         cnst = new LinearConstraint(new double 0.0d 1.0d 0.0d 0.0d 0.0d 0.0d 0.0d Relationship.GEQ 0.0d);         cnsts.add(cnst);         cnst = new LinearConstraint(new double 0.0d 0.0d 0.0d 1.0d 0.0d -0.0128588d 1e-5d Relationship.EQ 0.0d);         cnsts.add(cnst);         cnst = new LinearConstraint(new double 0.0d 0.0d 0.0d 0.0d 1.0d 1e-5d -0.0128586d Relationship.EQ 1e-10d);         cnsts.add(cnst);         cnst = new LinearConstraint(new double 0.0d 0.0d 1.0d -1.0d 0.0d 0.0d 0.0d Relationship.GEQ 0.0d);         cnsts.add(cnst);         cnst = new LinearConstraint(new double 0.0d 0.0d 1.0d 1.0d 0.0d 0.0d 0.0d Relationship.GEQ 0.0d);         cnsts.add(cnst);         cnst = new LinearConstraint(new double 0.0d 0.0d 1.0d 0.0d -1.0d 0.0d 0.0d Relationship.GEQ 0.0d);         cnsts.add(cnst);         cnst = new LinearConstraint(new double 0.0d 0.0d 1.0d 0.0d 1.0d 0.0d 0.0d Relationship.GEQ 0.0d);         cnsts.add(cnst);                          DecimalFormat df = new java.text.DecimalFormat(0.#####E0);                  System.out.println(Constraints:);         for(LinearConstraint con : cnsts)              for (int i = 0; i < con.getCoefficients().getDimension(); ++i)                 System.out.print(df.format(con.getCoefficients().getData()i) +  );             System.out.println(con.getRelationship() +   + con.getValue());                           SimplexSolver simplex = new SimplexSolver(1e-7);         double sol = simplex.optimize(c cnsts GoalType.MINIMIZE false).getPointRef();         System.out.println(Solution:n + new ArrayRealVector(sol));         System.out.println(Second constraint is violated!);         Its an odd problem but something I ran across.  I tracked the problem to the getPivotRow routine in SimplexSolver.  It was choosing a pivot that resulted in a negative right-hand-side.  I recommend a fix by replacing                 ...                 if (MathUtils.equals(ratio minRatio epsilon))                  ... with                 ...                 if (MathUtils.equals(ratio minRatio Math.abs(epsilon/entry)))                  ...  I believe this would be more appropriate (and at least resolves this particular problem).  Also you may want to consider making a change in getPivotColumn to replace             ...             if (MathUtils.compareTo(tableau.getEntry(0 i) minValue epsilon) < 0)              ... with             ...             if (tableau.getEntry(0 i) < minValue)              ... because I dont see the point of biasing earlier columns when multiple entries are within epsilon of each other.  Why not pick the absolute smallest.  I dont know that any problem can result from doing it the other way but the latter may be a safer bet.  VERY IMPORTANT: I discovered another bug that occurs when not restricting to non-negatives.  In SimplexTableu::getSolution()            ...                     if (basicRows.contains(basicRow))                // if multiple variables can take a given value               // then we choose the first and set the rest equal to 0               coefficientsi = 0;           ... should be           ...                     if (basicRows.contains(basicRow))                // if multiple variables can take a given value               // then we choose the first and set the rest equal to 0               coefficientsi = (restrictToNonNegative ? 0 : -mostNegative);           ... If necessary I can give an example of where this bug causes a problem but it should be fairly obvious why this was wrong.", "A_clean_title": ["simplexsolv", "simplex", "solver", "return", "unfeas", "solutionth", "solut", "simplexsolv", "simplex", "solver", "return", "unfeas", "solut", "import", "java", "util", "arraylist", "array", "list", "import", "java", "text", "decimalformat", "decim", "format", "import", "org", "apach", "common", "math", "linear", "arrayrealvector", "array", "real", "vector", "import", "org", "apach", "common", "math", "optim", "goaltyp", "goal", "type", "import", "org", "apach", "common", "math", "optim", "optimizationexcept", "optim", "except", "import", "org", "apach", "common", "math", "optim", "linear", "public", "class", "simplexsolverbug", "simplex", "solver", "bug", "public", "static", "void", "main", "string", "arg", "throw", "optimizationexcept", "optim", "except", "linearobjectivefunct", "linear", "object", "function", "new", "linearobjectivefunct", "linear", "object", "function", "new", "double0", "0d", "0d", "0d", "0d", "0d", "0d", "0d", "0d", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "cnst", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "linearconstraint", "linear", "constraint", "cnst", "cnst", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "0d", "1d", "0d", "0d", "0d", "0d", "0d", "relationship", "eq", "1d", "cnst", "add", "cnst", "cnst", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "0d", "0d", "0d", "0d", "0d", "0d", "0d", "relationship", "geq", "1e", "18d", "cnst", "add", "cnst", "cnst", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "0d", "0d", "0d", "0d", "0d", "0d", "0d", "relationship", "geq", "0d", "cnst", "add", "cnst", "cnst", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "0d", "0d", "0d", "0d", "0d", "0128588d", "1e", "5d", "relationship", "eq", "0d", "cnst", "add", "cnst", "cnst", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "0d", "0d", "0d", "0d", "0d", "1e", "5d", "0128586d", "relationship", "eq", "1e", "10d", "cnst", "add", "cnst", "cnst", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "0d", "0d", "0d", "0d", "0d", "0d", "0d", "relationship", "geq", "0d", "cnst", "add", "cnst", "cnst", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "0d", "0d", "0d", "0d", "0d", "0d", "0d", "relationship", "geq", "0d", "cnst", "add", "cnst", "cnst", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "0d", "0d", "0d", "0d", "0d", "0d", "0d", "relationship", "geq", "0d", "cnst", "add", "cnst", "cnst", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "0d", "0d", "0d", "0d", "0d", "0d", "0d", "relationship", "geq", "0d", "cnst", "add", "cnst", "decimalformat", "decim", "format", "df", "new", "java", "text", "decimalformat", "decim", "format", "e0", "system", "out", "println", "constraint", "linearconstraint", "linear", "constraint", "con", "cnst", "int", "con", "getcoeffici", "get", "coeffici", "getdimens", "get", "dimens", "++i", "system", "out", "print", "df", "format", "con", "getcoeffici", "get", "coeffici", "getdata", "get", "data", "system", "out", "println", "con", "getrelationship", "get", "relationship", "con", "getvalu", "get", "valu", "simplexsolv", "simplex", "solver", "simplex", "new", "simplexsolv", "simplex", "solver", "1e", "doubl", "sol", "simplex", "optim", "cnst", "goaltyp", "minim", "goal", "type", "fals", "getpointref", "get", "point", "ref", "system", "out", "println", "solut", "new", "arrayrealvector", "array", "real", "vector", "sol", "system", "out", "println", "second", "constraint", "violat", "it", "odd", "problem", "but", "someth", "ran", "across", "track", "problem", "getpivotrow", "get", "pivot", "row", "routin", "simplexsolv", "simplex", "solver", "it", "wa", "choos", "pivot", "that", "result", "neg", "right", "hand", "side", "recommend", "fix", "by", "replac", "mathutil", "equal", "math", "util", "ratio", "minratio", "min", "ratio", "epsilon", "mathutil", "equal", "math", "util", "ratio", "minratio", "min", "ratio", "math", "ab", "epsilon", "entri", "believ", "thi", "would", "more", "appropri", "at", "least", "resolv", "thi", "particular", "problem", "also", "you", "may", "want", "consid", "make", "chang", "getpivotcolumn", "get", "pivot", "column", "replac", "mathutil", "compareto", "math", "util", "compar", "tableau", "getentri", "get", "entri", "minvalu", "min", "valu", "epsilon", "tableau", "getentri", "get", "entri", "minvalu", "min", "valu", "becaus", "dont", "see", "point", "bias", "earlier", "column", "when", "multipl", "entri", "are", "within", "epsilon", "each", "other", "whi", "not", "pick", "absolut", "smallest", "dont", "know", "that", "ani", "problem", "result", "do", "it", "other", "way", "but", "latter", "may", "safer", "bet", "veri", "import", "discov", "anoth", "bug", "that", "occur", "when", "not", "restrict", "non", "neg", "simplextableu", "simplex", "tableu", ":getsolut", ":get", "solut", "basicrow", "contain", "basic", "row", "basicrow", "basic", "row", "multipl", "variabl", "take", "given", "valu", "then", "we", "choos", "first", "set", "rest", "equal", "coefficientsi", "basicrow", "contain", "basic", "row", "basicrow", "basic", "row", "multipl", "variabl", "take", "given", "valu", "then", "we", "choos", "first", "set", "rest", "equal", "coefficientsi", "restricttononneg", "restrict", "non", "neg", "mostneg", "most", "neg", "necessari", "give", "exampl", "where", "thi", "bug", "caus", "problem", "but", "it", "fairli", "obviou", "whi", "thi", "wa", "wrong"], "B_title": "Fixed two errors in simplex solver when entries are close together or when variables are not restricted to non-negative.", "B_clean_title": ["fix", "two", "error", "simplex", "solver", "when", "entri", "are", "close", "togeth", "or", "when", "variabl", "are", "not", "restrict", "non", "neg"]},
{"A_title": "Validity checks missing for readFields and Thrift deserializationClasses in o.a.a.core.data (and potentially elsewhere) that support construction from a Thrift object and/or population from a DataInput (via a readFields() method) often lack data validity checks that the classes constructors enforce. The missing checks make it possible for an attacker to create invalid objects by manipulating the bytes being read. The situation is analogous to the need to check objects deserialized from their Java serialized form within the readObject() method.", "A_clean_title": ["valid", "check", "miss", "readfield", "read", "field", "thrift", "deserializationclass", "deseri", "class", "core", "data", "potenti", "elsewher", "that", "support", "construct", "thrift", "object", "or", "popul", "datainput", "data", "input", "via", "readfield", "read", "field", "method", "often", "lack", "data", "valid", "check", "that", "class", "constructor", "enforc", "miss", "check", "make", "it", "possibl", "attack", "creat", "invalid", "object", "by", "manipul", "byte", "be", "read", "situat", "analog", "need", "check", "object", "deseri", "their", "java", "serial", "form", "within", "readobject", "read", "object", "method"], "B_title": "merge failed to pull null pointer checks from 1.4", "B_clean_title": ["merg", "fail", "pull", "null", "pointer", "check"]},
{"A_title": "No Object Id found for an instance when using @ConstructorPropertiesHi! We recently migrated from 2.4.6. to 2.8.1. and we encountered the issue. We use lomboks  @AllArgsConstructor which adds @ConstructorProperties to constructor. We also used @JsonIdentityInfo on our POJO which lead to JsonMappingException: No Object Id found for an instance exception. The following test code demonstrates the issue   Stack trace   Prior to the version 2.5.0 this was not an issue because the offending method (  com.fasterxml.jackson.databind.deser.impl.PropertyValueBuffer.handleIdValue(DeserializationContext Object) ) had a comment // TODO: is this an error case? and did nothing else.", "A_clean_title": ["no", "object", "id", "found", "instanc", "when", "constructorpropertieshi", "constructor", "properti", "hi", "we", "recent", "migrat", "we", "encount", "issu", "we", "use", "lombok", "allargsconstructor", "all", "arg", "constructor", "which", "add", "constructorproperti", "constructor", "properti", "constructor", "we", "also", "use", "jsonidentityinfo", "json", "ident", "info", "our", "pojo", "which", "lead", "jsonmappingexcept", "json", "map", "except", "no", "object", "id", "found", "instanc", "except", "follow", "test", "code", "demonstr", "issu", "stack", "trace", "prior", "version", "thi", "wa", "not", "issu", "becaus", "offend", "method", "com", "fasterxml", "jackson", "databind", "deser", "impl", "propertyvaluebuff", "handleidvalu", "properti", "valu", "buffer", "handl", "id", "valu", "deserializationcontext", "deseri", "context", "object", "had", "comment", "todo", "thi", "error", "case", "did", "noth"], "B_title": "Fixed #1367", "B_clean_title": ["fix", "1367"]},
{"A_title": "Simple versionable nodes are invalid after migrationOAK-3836 introduces a support for migrating mix:simpleVersionable nodes from JCR2 to mix:versionable nodes in Oak. It changes the mixin type however it doesnt add required properties: jcr:versionHistory jcr:baseVersion and jcr:predecessors. As a result versioning-related methods invoked on such nodes doesnt work correctly.", "A_clean_title": ["simpl", "version", "node", "are", "invalid", "after", "migrationoak", "3836", "migrat", "oak", "introduc", "support", "migrat", "mix", "simpleversion", "simpl", "version", "node", "jcr2", "mix", "version", "node", "oak", "it", "chang", "mixin", "type", "howev", "it", "doesnt", "add", "requir", "properti", "jcr", "versionhistori", "version", "histori", "jcr", "basevers", "base", "version", "jcr", "predecessor", "as", "result", "version", "relat", "method", "invok", "such", "node", "doesnt", "work", "correctli"], "B_title": "Fixed version-related properties for the simple versionable nodes", "B_clean_title": ["fix", "version", "relat", "properti", "simpl", "version", "node"]},
{"A_title": "Mockito cant create mock on public class that extends package-private classEven if it cant be implemented I think that mockito should throw some normal exception at time of creation. In my variant on first creation it returns wrong-working mock (invokes real method instead of stubbed). On second creation throws exception that doesnt really connected with problem. Everything works fine if you mock package-private parent.", "A_clean_title": ["mockito", "cant", "creat", "mock", "public", "class", "that", "extend", "packag", "privat", "classeven", "class", "even", "it", "cant", "implement", "think", "that", "mockito", "throw", "some", "normal", "except", "at", "time", "creation", "my", "variant", "first", "creation", "it", "return", "wrong", "work", "mock", "invok", "real", "method", "instead", "stub", "second", "creation", "throw", "except", "that", "doesnt", "realli", "connect", "problem", "everyth", "work", "fine", "you", "mock", "packag", "privat", "parent"], "B_title": "Fixed issue 216 @Spy did not have nice names in the verification errors", "B_clean_title": ["fix", "issu", "216", "spi", "did", "not", "have", "nice", "name", "verif", "error"]},
{"A_title": "Binaries might get removed by garbage collection while still referencedThe Microkernel contract|http://svn.apache.org/repos/asf/jackrabbit/oak/trunk/oak-mk-api/src/main/java/org/apache/jackrabbit/mk/api/MicroKernel.java specifies a specific format for references to binaries: :blobId:<blobId>. Currently oak-core uses a different format and thus risks premature garbage collection of such binaries.", "A_clean_title": ["binari", "might", "get", "remov", "by", "garbag", "collect", "while", "still", "referencedth", "referenc", "microkernel", "contract|http", "mk", "apach", "java", "svn", "org", "repo", "asf", "jackrabbit", "oak", "trunk", "oak", "api", "src", "main", "java", "org", "apach", "jackrabbit", "mk", "api", "microkernel", "micro", "kernel", "specifi", "specif", "format", "refer", "binari", "blobid", "blob", "id", "blobid", "blob", "id", "current", "oak", "core", "use", "differ", "format", "thu", "risk", "prematur", "garbag", "collect", "such", "binari"], "B_title": "Binaries might get removed by garbage collection while still referenced change prefix for binaries from bin: to :blobId:", "B_clean_title": ["binari", "might", "get", "remov", "by", "garbag", "collect", "while", "still", "referenc", "chang", "prefix", "binari", "bin", "blobid", "blob", "id"]},
{"A_title": "WebApplication doesnt recognize if an incoming request is multipart.Thanks to the mail at http://apache-wicket.1842946.n4.nabble.com/Read-POST-based-request-from-external-site-td4651269.html we have spotted a problem with method  newWebRequest of class WebApplication.  It seems that this method doesnt test if the original request is multipart and doing so post parameters go lost.  We should create a  MultipartServletWebRequestImpl when such a type of request is being served. I attach a possible patch but Im not 100% about two things: - which is the best way to determinate if a HttpServletRequest is multipart? - in order to build a MultipartServletWebRequestImpl we need to provide a string identifier for the upload.   How can we generate it (in my patch its a constant value)?", "A_clean_title": ["webappl", "web", "applic", "doesnt", "recogn", "incom", "request", "multipart", "thank", "mail", "at", "http", "post", "base", "request", "extern", "site", "apach", "wicket", "1842946", "n4", "nabbl", "td4651269", "html", "com", "read", "we", "have", "spot", "problem", "method", "newwebrequest", "new", "web", "request", "class", "webappl", "web", "applic", "it", "seem", "that", "thi", "method", "doesnt", "test", "origin", "request", "multipart", "do", "so", "post", "paramet", "go", "lost", "we", "creat", "multipartservletwebrequestimpl", "multipart", "servlet", "web", "request", "impl", "when", "such", "type", "request", "be", "serv", "attach", "possibl", "patch", "but", "im", "not", "100", "about", "two", "thing", "which", "best", "way", "determin", "httpservletrequest", "http", "servlet", "request", "multipart", "order", "build", "multipartservletwebrequestimpl", "multipart", "servlet", "web", "request", "impl", "we", "need", "provid", "string", "identifi", "upload", "how", "we", "gener", "it", "my", "patch", "it", "constant", "valu"], "B_title": "WebApplication doesnt recognize if an incoming request is multipart.", "B_clean_title": ["webappl", "web", "applic", "doesnt", "recogn", "incom", "request", "multipart"]},
{"A_title": "ClassCastExecptionHi  I have started using a meitrack tc68s device however when I try and generate a summary/trip report it returns the following error in console:  The device is not in the future and has the correct timezone also I am using the official build. Any recommendation?  All the other osram works fine.", "A_clean_title": ["classcastexecptionhi", "class", "cast", "execpt", "hi", "have", "start", "meitrack", "tc68", "devic", "howev", "when", "tri", "gener", "summari", "trip", "report", "it", "return", "follow", "error", "consol", "devic", "not", "futur", "ha", "correct", "timezon", "also", "am", "offici", "build", "ani", "recommend", "all", "other", "osram", "work", "fine"], "B_title": "Ensure that odometer is a number (fix #2967)", "B_clean_title": ["ensur", "that", "odomet", "number", "fix", "2967"]},
{"A_title": "Queueing component in autocomponentThere is an exception when a component is added to queue when its parent is an auto component  <body> <a href=panier.html> <span wicket:id=inlink></span> </a> </body>   Last cause: Unable to find component with id inlink in TransparentWebMarkupContainer Component id = wicket_relative_path_prefix_1 Expected: wicket_relative_path_prefix_1:inlink. Found with similar names:", "A_clean_title": ["queue", "compon", "autocomponentther", "autocompon", "there", "except", "when", "compon", "ad", "queue", "when", "it", "parent", "auto", "compon", "bodi", "href=pani", "html", "span", "wicket", "id=inlink", "span", "bodi", "last", "caus", "unabl", "find", "compon", "id", "inlink", "transparentwebmarkupcontain", "transpar", "web", "markup", "contain", "compon", "id", "wicket", "rel", "path", "prefix", "expect", "wicket", "rel", "path", "prefix", "inlink", "found", "similar", "name"], "B_title": "Queueing component in autocomponent", "B_clean_title": ["queue", "compon", "autocompon"]},
{"A_title": "LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to itLevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it. This makes it hard to specify custom stopping criteria for the optimizer.", "A_clean_title": ["levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "ignor", "vectorialconvergencecheck", "vectori", "converg", "checker", "paramet", "pass", "itlevenbergmarquardtoptim", "it", "levenberg", "marquardt", "optim", "ignor", "vectorialconvergencecheck", "vectori", "converg", "checker", "paramet", "pass", "it", "thi", "make", "it", "hard", "specifi", "custom", "stop", "criteria", "optim"], "B_title": "Fixed Levenberg-Marquardt optimizer that did not use the vectorial convergence checker. Now this optimizer can use either the general vectorial convergence checker or its own specialized convergence settings. Minor changes had to be introduced in the test data they have been validated JIRA: MATH-362", "B_clean_title": ["fix", "levenberg", "marquardt", "optim", "that", "did", "not", "use", "vectori", "converg", "checker", "now", "thi", "optim", "use", "either", "gener", "vectori", "converg", "checker", "or", "it", "own", "special", "converg", "set", "minor", "chang", "had", "introduc", "test", "data", "they", "have", "been", "valid", "jira", "math", "362"]},
{"A_title": "Simple Whitespace only compression removing each keyword from for each (var x in arr) loopNone", "A_clean_title": ["simpl", "whitespac", "onli", "compress", "remov", "each", "keyword", "each", "var", "arr", "loopnon", "loop", "none"], "B_title": "Dont silently ignore transform for each into for loops report an error instead. Fixes issue 644", "B_clean_title": ["dont", "silent", "ignor", "transform", "each", "into", "loop", "report", "error", "instead", "fix", "issu", "644"]},
{"A_title": "ProxyServer ignores value of isDeleted on ColumnUpdateThe ProxyServer ignores the actual boolean value of the isDeleted flag on a ColumnUpdate.  If the isDeleted value is set regardless of the actual boolean value the ProxyServer marks the update as a delete.  The ProxyServer should be updated to check the value of the flag.", "A_clean_title": ["proxyserv", "proxi", "server", "ignor", "valu", "isdelet", "delet", "columnupdateth", "column", "updat", "proxyserv", "proxi", "server", "ignor", "actual", "boolean", "valu", "isdelet", "delet", "flag", "columnupd", "column", "updat", "isdelet", "delet", "valu", "set", "regardless", "actual", "boolean", "valu", "proxyserv", "proxi", "server", "mark", "updat", "as", "delet", "proxyserv", "proxi", "server", "updat", "check", "valu", "flag"], "B_title": "use the value of the delete flag (with test)", "B_clean_title": ["use", "valu", "delet", "flag", "test"]},
{"A_title": "RETURNS_DEEP_STUBS automatically tries to create serializable mocksYou are using the setting withSettings().serializable() however the type you are trying to mock NotSerializableReturnValue do not implement Serializable AND do not have a no-arg constructor.", "A_clean_title": ["return", "deep", "stub", "automat", "tri", "creat", "serializ", "mocksyou", "mock", "you", "are", "set", "withset", "set", "serializ", "howev", "type", "you", "are", "tri", "mock", "notserializablereturnvalu", "not", "serializ", "return", "valu", "not", "implement", "serializ", "not", "have", "no", "arg", "constructor"], "B_title": "Merge pull request #103 from mockito/fixes-issue-99", "B_clean_title": ["merg", "pull", "request", "103", "issu", "99", "mockito", "fix"]},
{"A_title": "Query: unexpected result on negative limit / offsetCurrently running a query with limit of -1 never returns any rows the same as when using limit = 0.  Either the query engine should fail with a negative limit or offset (IllegalArgumentException) or it should ignore negative values (unlimited result rows for limit probably no offset for offset = -1).  I would prefer IllegalArgumentException but I can also live with -1 = unlimited at least for limit.", "A_clean_title": ["queri", "unexpect", "result", "neg", "limit", "offsetcurr", "offset", "current", "run", "queri", "limit", "never", "return", "ani", "row", "same", "as", "when", "limit", "either", "queri", "engin", "fail", "neg", "limit", "or", "offset", "illegalargumentexcept", "illeg", "argument", "except", "or", "it", "ignor", "neg", "valu", "unlimit", "result", "row", "limit", "probabl", "no", "offset", "offset", "would", "prefer", "illegalargumentexcept", "illeg", "argument", "except", "but", "also", "live", "unlimit", "at", "least", "limit"], "B_title": "Query: unexpected result on negative limit / offset", "B_clean_title": ["queri", "unexpect", "result", "neg", "limit", "offset"]},
{"A_title": "Classify non-rightmost expressions as problematicNone", "A_clean_title": ["classifi", "non", "rightmost", "express", "as", "problematicnon", "problemat", "none"], "B_title": "You are in a maze of twisty if branches all alike. cleanup the logic for identifying dead expressions. Fixes issue 753", "B_clean_title": ["you", "are", "maze", "twisti", "branch", "all", "alik", "cleanup", "logic", "identifi", "dead", "express", "fix", "issu", "753"]},
{"A_title": "IllegalArgumentException on Row.getValues()Calling row.getValues() is throwing an IllegalArgumentException when called on the QueryResult of the query SELECT properties FROM nt:base WHERE sling:resourceType=cq/personalization/components/contextstores/surferinfo  quote java.lang.IllegalArgumentException at com.google.common.base.Preconditions.checkArgument(Preconditions.java:76) at org.apache.jackrabbit.oak.plugins.value.ValueImpl.checkSingleValued(ValueImpl.java:85) at org.apache.jackrabbit.oak.plugins.value.ValueImpl.<init>(ValueImpl.java:72) at org.apache.jackrabbit.oak.plugins.value.ValueFactoryImpl.createValue(ValueFactoryImpl.java:95) at org.apache.jackrabbit.oak.jcr.query.QueryResultImpl.createValue(QueryResultImpl.java:266) at org.apache.jackrabbit.oak.jcr.query.RowImpl.getValues(RowImpl.java:99) at com.day.cq.analytics.sitecatalyst.impl.FrameworkComponentImpl.getListProperty(FrameworkComponentImpl.java:128) at com.day.cq.analytics.sitecatalyst.impl.FrameworkComponentImpl.<init>(FrameworkComponentImpl.java:91) quote", "A_clean_title": ["illegalargumentexcept", "illeg", "argument", "except", "row", "getvalu", "get", "valu", "call", "row", "getvalu", "get", "valu", "throw", "illegalargumentexcept", "illeg", "argument", "except", "when", "call", "queryresult", "queri", "result", "queri", "select", "properti", "nt", "base", "where", "sling", "resourcetype=cq", "person", "compon", "contextstor", "surferinfo", "resourc", "type=cq", "quot", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "at", "com", "googl", "common", "base", "precondit", "checkargu", "check", "argument", "precondit", "java:76", "at", "org", "apach", "jackrabbit", "oak", "plugin", "valu", "valueimpl", "checksinglevalu", "valu", "impl", "check", "singl", "valu", "valueimpl", "java:85", "valu", "impl", "at", "org", "apach", "jackrabbit", "oak", "plugin", "valu", "valueimpl", "valu", "impl", "init", "valueimpl", "java:72", "valu", "impl", "at", "org", "apach", "jackrabbit", "oak", "plugin", "valu", "valuefactoryimpl", "createvalu", "valu", "factori", "impl", "creat", "valu", "valuefactoryimpl", "java:95", "valu", "factori", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "queri", "queryresultimpl", "createvalu", "queri", "result", "impl", "creat", "valu", "queryresultimpl", "java:266", "queri", "result", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "queri", "rowimpl", "getvalu", "row", "impl", "get", "valu", "rowimpl", "java:99", "row", "impl", "at", "com", "day", "cq", "analyt", "sitecatalyst", "impl", "frameworkcomponentimpl", "getlistproperti", "framework", "compon", "impl", "get", "list", "properti", "frameworkcomponentimpl", "java:128", "framework", "compon", "impl", "at", "com", "day", "cq", "analyt", "sitecatalyst", "impl", "frameworkcomponentimpl", "framework", "compon", "impl", "init", "frameworkcomponentimpl", "java:91", "framework", "compon", "impl", "quot"], "B_title": "IllegalArgumentException on Row.getValues()", "B_clean_title": ["illegalargumentexcept", "illeg", "argument", "except", "row", "getvalu", "get", "valu"]},
{"A_title": "ajax not working due to bugs in resource handlingA couple of bugs were found that were preventing .js resources to be returned to the client correctly. One bug was returning the jar file size as the content length of the resource if it is in a jar file. The other was copying past a source buffer into the response.  After fixing these bugs the ajax functions in the trunk seems to be working.  A patch is provided. Test cases included.", "A_clean_title": ["ajax", "not", "work", "due", "bug", "resourc", "handlinga", "handl", "coupl", "bug", "were", "found", "that", "were", "prevent", "js", "resourc", "return", "client", "correctli", "one", "bug", "wa", "return", "jar", "file", "size", "as", "content", "length", "resourc", "it", "jar", "file", "other", "wa", "copi", "past", "sourc", "buffer", "into", "respons", "after", "fix", "these", "bug", "ajax", "function", "trunk", "seem", "work", "patch", "provid", "test", "case", "includ"], "B_title": "ajax not working due to bugs in resource handling Issue: WICKET-2839", "B_clean_title": ["ajax", "not", "work", "due", "bug", "resourc", "handl", "issu", "wicket", "2839"]},
{"A_title": "getLInfNorm() uses wrong formula in both ArrayRealVector and OpenMapRealVector (in different ways)the L_infinity norm of a finite dimensional vector is just the max of the absolute value of its entries. The current implementation in ArrayRealVector has a typo:      public double getLInfNorm()          double max = 0;         for (double a : data)              max += Math.max(max Math.abs(a));                  return max;        the += should just be an =. There is sadly a unit test assuring us that this is the correct behavior (effectively a regression-only test not a test for correctness). Worse the implementation in OpenMapRealVector is not even positive semi-definite:          public double getLInfNorm()          double max = 0;         Iterator iter = entries.iterator();         while (iter.hasNext())              iter.advance();             max += iter.value();                  return max;        I would suggest that this method be moved up to the AbstractRealVector superclass and implemented using the sparseIterator():    public double getLInfNorm()      double norm = 0;     Iterator<Entry> it = sparseIterator();     Entry e;     while(it.hasNext() && (e = it.next()) != null)        norm = Math.max(norm Math.abs(e.getValue()));          return norm;      Unit tests with negative valued vectors would be helpful to check for this kind of thing in the future.", "A_clean_title": ["getlinfnorm", "get", "inf", "norm", "use", "wrong", "formula", "both", "arrayrealvector", "array", "real", "vector", "openmaprealvector", "open", "map", "real", "vector", "differ", "way", "infin", "norm", "finit", "dimension", "vector", "just", "max", "absolut", "valu", "it", "entri", "current", "implement", "arrayrealvector", "array", "real", "vector", "ha", "typo", "public", "doubl", "getlinfnorm", "get", "inf", "norm", "doubl", "max", "doubl", "data", "max", "math", "max", "max", "math", "ab", "return", "max", "just", "there", "sadli", "unit", "test", "assur", "us", "that", "thi", "correct", "behavior", "effect", "regress", "onli", "test", "not", "test", "correct", "wors", "implement", "openmaprealvector", "open", "map", "real", "vector", "not", "even", "posit", "semi", "definit", "public", "doubl", "getlinfnorm", "get", "inf", "norm", "doubl", "max", "iter", "iter", "entri", "iter", "while", "iter", "hasnext", "ha", "next", "iter", "advanc", "max", "iter", "valu", "return", "max", "would", "suggest", "that", "thi", "method", "move", "up", "abstractrealvector", "abstract", "real", "vector", "superclass", "implement", "sparseiter", "spars", "iter", "public", "doubl", "getlinfnorm", "get", "inf", "norm", "doubl", "norm", "iter", "entri", "it", "sparseiter", "spars", "iter", "entri", "while", "it", "hasnext", "ha", "next", "it", "next", "null", "norm", "math", "max", "norm", "math", "ab", "getvalu", "get", "valu", "return", "norm", "unit", "test", "neg", "valu", "vector", "would", "help", "check", "thi", "kind", "thing", "futur"], "B_title": "fixed a wrong implementation of the Linf vector norm JIRA: MATH-326", "B_clean_title": ["fix", "wrong", "implement", "linf", "vector", "norm", "jira", "math", "326"]},
{"A_title": "Components markup cannot be found in Ajax requests if the parent is transparentWhen TransparentWebMarkupContainer is used an inner markup container cannot find its markup on Ajax updates. The problem seems to be caused by the fact that ComponentResolvers#resolve() is not executed and since there is transparent container involved Markup.find(String) cannot find the markup for non-transparent markup containers. Ill commit a disabled test case that shows the problem.", "A_clean_title": ["compon", "markup", "not", "found", "ajax", "request", "parent", "transparentwhen", "transpar", "when", "transparentwebmarkupcontain", "transpar", "web", "markup", "contain", "use", "inner", "markup", "contain", "not", "find", "it", "markup", "ajax", "updat", "problem", "seem", "caus", "by", "fact", "that", "componentresolv", "compon", "resolv", "resolv", "not", "execut", "sinc", "there", "transpar", "contain", "involv", "markup", "find", "string", "not", "find", "markup", "non", "transpar", "markup", "contain", "ill", "commit", "disabl", "test", "case", "that", "show", "problem"], "B_title": "fixed: Components markup cannot be found in Ajax requests if the parent is transparent Issue: WICKET-3719", "B_clean_title": ["fix", "compon", "markup", "not", "found", "ajax", "request", "parent", "transpar", "issu", "wicket", "3719"]},
{"A_title": "BOM in UTF markup file breaks encoding detectionI have project with internationalization and experienced this problem with one of the pages with non-english content. Page had UTF-8 encoding but my JVM encoding is different. I always use <?xml encoding ... ?> to specify encoding for markup pages (and MarkupSettings.defaultMarkupEncoding is not set).  Unexpectedly I got problem with bad encoding on page. After several hours of debugging I found what source of this issue was UTF BOM (Byte order mark) at the beggining of file and inability of XmlReader to process it. XmlReader.getXmlDeclaration tries to match xml declaration with regular expression but fails because of BOM. After that encoding defaults to JVM encoding.  Its possible to use org.apache.commons.io.input.BOMInputStream to handle BOM or you could handle it manually inside XmlReader.  PS: issue found with Wicket 1.5.10 and I see same code in 6.12.0 without BOM handling so I added it to Affects Version/s but no proof-in-code available from me at this moment.", "A_clean_title": ["bom", "utf", "markup", "file", "break", "encod", "detectioni", "detect", "have", "project", "internation", "experienc", "thi", "problem", "one", "page", "non", "english", "content", "page", "had", "utf", "encod", "but", "my", "jvm", "encod", "differ", "alway", "use", "xml", "encod", "specifi", "encod", "markup", "page", "markupset", "defaultmarkupencod", "markup", "set", "default", "markup", "encod", "not", "set", "unexpectedli", "got", "problem", "bad", "encod", "page", "after", "sever", "hour", "debug", "found", "what", "sourc", "thi", "issu", "wa", "utf", "bom", "byte", "order", "mark", "at", "beggin", "file", "inabl", "xmlreader", "xml", "reader", "process", "it", "xmlreader", "getxmldeclar", "xml", "reader", "get", "xml", "declar", "tri", "match", "xml", "declar", "regular", "express", "but", "fail", "becaus", "bom", "after", "that", "encod", "default", "jvm", "encod", "it", "possibl", "use", "org", "apach", "common", "io", "input", "bominputstream", "bom", "input", "stream", "handl", "bom", "or", "you", "could", "handl", "it", "manual", "insid", "xmlreader", "xml", "reader", "ps", "issu", "found", "wicket", "10", "see", "same", "code", "12", "without", "bom", "handl", "so", "ad", "it", "affect", "version", "but", "no", "proof", "code", "avail", "me", "at", "thi", "moment"], "B_title": "BOM in UTF markup file breaks encoding detection", "B_clean_title": ["bom", "utf", "markup", "file", "break", "encod", "detect"]},
{"A_title": "SQL2 query with union limit and offset can return invalid resultswhen using order limit and offset and a SQL2 query that contains an union of two subqueries that have common results can return invalid results  Example: assuming content tree /test/a/b/c/d/e exists code:sql SELECT jcr:path FROM nt:base AS a WHERE ISDESCENDANTNODE(a /test) UNION SELECT jcr:path FROM nt:base AS a WHERE ISDESCENDANTNODE(a /test) ORDER BY jcr:path code with limit=3 and offset 2 returns only one row ( instead of 3 )  the correct result set is noformat /test/a/b/c /test/a/b/c/d /test/a/b/c/d/e noformat", "A_clean_title": ["sql2", "queri", "union", "limit", "offset", "return", "invalid", "resultswhen", "order", "limit", "offset", "sql2", "queri", "that", "contain", "union", "two", "subqueri", "that", "have", "common", "result", "return", "invalid", "result", "exampl", "assum", "content", "tree", "test", "exist", "code", "sql", "select", "jcr", "path", "nt", "base", "as", "where", "isdescendantnod", "test", "union", "select", "jcr", "path", "nt", "base", "as", "where", "isdescendantnod", "test", "order", "by", "jcr", "path", "code", "limit=3", "offset", "return", "onli", "one", "row", "instead", "correct", "result", "set", "noformat", "test", "test", "test", "noformat"], "B_title": "SQL2 query with union limit and offset can return invalid results", "B_clean_title": ["sql2", "queri", "union", "limit", "offset", "return", "invalid", "result"]},
{"A_title": "Optimisation: convert array.join() to array.join()None", "A_clean_title": ["optimis", "convert", "array", "join", "array", "join", "none"], "B_title": ".join() --> .join() Fixes issue 558", "B_clean_title": ["join", "join", "fix", "issu", "558"]},
{"A_title": "adding (and querying) feedback messages at construction time fails.See http://www.nabble.com/error%28...%29-No-page-found-for-component-tf3497125.html  Currently adding (and querying) feedback messages fails whenever it is done on components that are not yet added to a page (or were removed from them due to component replacement).  There are two ways to fix this. The first fix is attached as a patch and basically uses a thread local to temporarily store the messages and distribute them to the relevant page instances just in time or when rendering starts. The advantage of this method is that it is completely back wards compatible.  The other way to fix this is to store all messages whether component specific or not in the session and pull them from there. We need to be careful about how/ when to clean these error messages up though. We can use this issue to think about it a little bit more.", "A_clean_title": ["ad", "queri", "feedback", "messag", "at", "construct", "time", "fail", "see", "http", "nabbl", "www", "com", "error", "28", "29", "no", "page", "found", "compon", "tf3497125", "html", "current", "ad", "queri", "feedback", "messag", "fail", "whenev", "it", "done", "compon", "that", "are", "not", "yet", "ad", "page", "or", "were", "remov", "them", "due", "compon", "replac", "there", "are", "two", "way", "fix", "thi", "first", "fix", "attach", "as", "patch", "basic", "use", "thread", "local", "temporarili", "store", "messag", "distribut", "them", "relev", "page", "instanc", "just", "time", "or", "when", "render", "start", "advantag", "thi", "method", "that", "it", "complet", "back", "ward", "compat", "other", "way", "fix", "thi", "store", "all", "messag", "whether", "compon", "specif", "or", "not", "session", "pull", "them", "there", "we", "need", "care", "about", "how", "when", "clean", "these", "error", "messag", "up", "though", "we", "use", "thi", "issu", "think", "about", "it", "littl", "bit", "more"], "B_title": "(with aggressive cleanup but with the option to override)", "B_clean_title": ["aggress", "cleanup", "but", "option", "overrid"]},
{"A_title": "HtmlHandler wrongly handles tags not requiring closed tags if the markup does not have top level tagHi   I have custom component (extends MarkupContainer implements IMarkupCacheKeyProvider IMarkupResourceStreamProvider) which fetches its HTML markup from database.  Following HTML markup:   <img alt= src=logo.png>  <br>Some text  <br>Some more text   causes following error:   2012-04-12 10:52:53012 http-8080-6 ERROR: Unexpected error occurred  Unable to find close tag for: <img alt=logo src=logo.png> in org.apache.wicket.util.resource.StringResourceStream@3d7e16fc   MarkupStream: unknown          at org.apache.wicket.markup.MarkupFragment.<init>(MarkupFragment.java:127)          at org.apache.wicket.markup.MarkupStream.getMarkupFragment(MarkupStream.java:485)          at org.apache.wicket.MarkupContainer.autoAdd(MarkupContainer.java:244)          at org.apache.wicket.MarkupContainer.renderNext(MarkupContainer.java:1421)          at org.apache.wicket.MarkupContainer.renderAll(MarkupContainer.java:1596)          at org.apache.wicket.MarkupContainer.renderComponentTagBody(MarkupContainer.java:1571)          at org.apache.wicket.MarkupContainer.onComponentTagBody(MarkupContainer.java:1525)   I think the problem is that org.apache.wicket.markup.parser.filter.HtmlHandler does not handle such markup correctly. It does not call ComponentTag.setHasNoCloseTag(true) for the img tag. Such call is missing in postProcess() method. I think that this problem can be fixed by inserting:   top.setHasNoCloseTag(true);   after line 80 in HtmlHandler.java file.    Michal", "A_clean_title": ["htmlhandler", "html", "handler", "wrongli", "handl", "tag", "not", "requir", "close", "tag", "markup", "not", "have", "top", "level", "taghi", "tag", "hi", "have", "custom", "compon", "extend", "markupcontain", "markup", "contain", "implement", "imarkupcachekeyprovid", "markup", "cach", "key", "provid", "imarkupresourcestreamprovid", "markup", "resourc", "stream", "provid", "which", "fetch", "it", "html", "markup", "databas", "follow", "html", "markup", "img", "alt=", "src=logo", "png", "br", "some", "text", "br", "some", "more", "text", "caus", "follow", "error", "2012", "04", "12", "10:52:53012", "http", "8080", "error", "unexpect", "error", "occur", "unabl", "find", "close", "tag", "img", "alt=logo", "src=logo", "png", "org", "apach", "wicket", "util", "resourc", "stringresourcestream", "string", "resourc", "stream", "3d7e16fc", "markupstream", "markup", "stream", "unknown", "at", "org", "apach", "wicket", "markup", "markupfrag", "markup", "fragment", "init", "markupfrag", "java:127", "markup", "fragment", "at", "org", "apach", "wicket", "markup", "markupstream", "getmarkupfrag", "markup", "stream", "get", "markup", "fragment", "markupstream", "java:485", "markup", "stream", "at", "org", "apach", "wicket", "markupcontain", "autoadd", "markup", "contain", "auto", "add", "markupcontain", "java:244", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "rendernext", "markup", "contain", "render", "next", "markupcontain", "java:1421", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "renderal", "markup", "contain", "render", "all", "markupcontain", "java:1596", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "rendercomponenttagbodi", "markup", "contain", "render", "compon", "tag", "bodi", "markupcontain", "java:1571", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "oncomponenttagbodi", "markup", "contain", "compon", "tag", "bodi", "markupcontain", "java:1525", "markup", "contain", "think", "problem", "that", "org", "apach", "wicket", "markup", "parser", "filter", "htmlhandler", "html", "handler", "not", "handl", "such", "markup", "correctli", "it", "not", "call", "componenttag", "sethasnoclosetag", "compon", "tag", "set", "ha", "no", "close", "tag", "true", "img", "tag", "such", "call", "miss", "postprocess", "post", "process", "method", "think", "that", "thi", "problem", "fix", "by", "insert", "top", "sethasnoclosetag", "set", "ha", "no", "close", "tag", "true", "after", "line", "80", "htmlhandler", "java", "html", "handler", "file", "michal"], "B_title": "HtmlHandler wrongly handles tags not requiring closed tags if the markup does not have top level tag", "B_clean_title": ["htmlhandler", "html", "handler", "wrongli", "handl", "tag", "not", "requir", "close", "tag", "markup", "not", "have", "top", "level", "tag"]},
{"A_title": "Form Input example fails when changing the languageTrying to change the language of http://localhost:8080/forminput example fails with:   Caused by: java.lang.ArrayIndexOutOfBoundsException: -1 at java.util.ArrayList.remove(ArrayList.java:390) at org.apache.wicket.request.Url.resolveRelative(Url.java:884) at org.apache.wicket.markup.html.form.Form.dispatchEvent(Form.java:1028) at org.apache.wicket.markup.html.form.Form.onFormSubmitted(Form.java:699) at org.apache.wicket.markup.html.form.Form.onFormSubmitted(Form.java:670) ... 37 more", "A_clean_title": ["form", "input", "exampl", "fail", "when", "chang", "languagetri", "languag", "tri", "chang", "languag", "http", "localhost:8080", "forminput", "exampl", "fail", "caus", "by", "java", "lang", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "at", "java", "util", "arraylist", "remov", "array", "list", "arraylist", "java:390", "array", "list", "at", "org", "apach", "wicket", "request", "url", "resolverel", "resolv", "rel", "url", "java:884", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "dispatchev", "dispatch", "event", "form", "java:1028", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "onformsubmit", "form", "submit", "form", "java:699", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "onformsubmit", "form", "submit", "form", "java:670", "37", "more"], "B_title": "", "B_clean_title": []},
{"A_title": "PearsonsCorrelation.getCorrelationPValues() precision limited by machine epsilonSimilar to the issue described in MATH-201 using PearsonsCorrelation.getCorrelationPValues() with many treatments results in p-values that are continuous down to 2.2e-16 but that drop to 0 after that. In MATH-201 the problem was described as such: > So in essence the p-value returned by TTestImpl.tTest() is: >  > 1.0 - (cumulativeProbability(t) - cumulativeProbabily(-t)) >  > For large-ish t-statistics cumulativeProbabilty(-t) can get quite small and cumulativeProbabilty(t) can get very close to 1.0. When  > cumulativeProbability(-t) is less than the machine epsilon we get p-values equal to zero because: >  > 1.0 - 1.0 + 0.0 = 0.0 The solution in MATH-201 was to modify the p-value calculation to this: > p = 2.0 * cumulativeProbability(-t) Here the problem is similar.  From PearsonsCorrelation.getCorrelationPValues():   p = 2 * (1 - tDistribution.cumulativeProbability(t)); Directly calculating the p-value using identical code as PearsonsCorrelation.getCorrelationPValues() but with the following change seems to solve the problem:   p = 2 * (tDistribution.cumulativeProbability(-t));", "A_clean_title": ["pearsonscorrel", "getcorrelationpvalu", "pearson", "correl", "get", "correl", "valu", "precis", "limit", "by", "machin", "epsilonsimilar", "epsilon", "similar", "issu", "describ", "math", "201", "pearsonscorrel", "getcorrelationpvalu", "pearson", "correl", "get", "correl", "valu", "mani", "treatment", "result", "valu", "that", "are", "continu", "down", "16", "2e", "but", "that", "drop", "after", "that", "math", "201", "problem", "wa", "describ", "as", "such", "so", "essenc", "valu", "return", "by", "ttestimpl", "ttest", "test", "impl", "test", "cumulativeprob", "cumul", "probabl", "cumulativeprobabili", "cumul", "probabili", "larg", "ish", "statist", "cumulativeprobabilti", "cumul", "probabilti", "get", "quit", "small", "cumulativeprobabilti", "cumul", "probabilti", "get", "veri", "close", "when", "cumulativeprob", "cumul", "probabl", "less", "than", "machin", "epsilon", "we", "get", "valu", "equal", "zero", "becaus", "solut", "math", "201", "wa", "modifi", "valu", "calcul", "thi", "cumulativeprob", "cumul", "probabl", "here", "problem", "similar", "pearsonscorrel", "getcorrelationpvalu", "pearson", "correl", "get", "correl", "valu", "tdistribut", "cumulativeprob", "distribut", "cumul", "probabl", "directli", "calcul", "valu", "ident", "code", "as", "pearsonscorrel", "getcorrelationpvalu", "pearson", "correl", "get", "correl", "valu", "but", "follow", "chang", "seem", "solv", "problem", "tdistribut", "cumulativeprob", "distribut", "cumul", "probabl"], "B_title": "Fixed loss of significance error in PersonsCorrelation p-value computation causing p-values smaller than the machine epsilon (~1E-16) to be reported as 0. JIRA: MATH-371 Reported and patched by Kevin Childs", "B_clean_title": ["fix", "loss", "signific", "error", "personscorrel", "person", "correl", "valu", "comput", "caus", "valu", "smaller", "than", "machin", "epsilon", "~1e", "16", "report", "as", "jira", "math", "371", "report", "patch", "by", "kevin", "child"]},
{"A_title": "WicketTester MockHttpRequest.getCookies very slow / OutOfMemoryWe have an extensive set of WicketTester tests. Recently the wicket RELEASE in the maven repository changed to 6.7.0. After the new version our tests got very slow.  When profiling I discovered that the MockHttpRequest.getCookies() was taking up a lot of time. Also tests failed because of OutOfMemory exceptions. My guess is that somehow a lot of objects are created at such speeds that the GC cannot clean them  I will investigate further but switching back to 6.6.0 solved the issue.   Edit The tests are run with TestNG and using mvn test", "A_clean_title": ["wickettest", "wicket", "tester", "mockhttprequest", "getcooki", "mock", "http", "request", "get", "cooki", "veri", "slow", "outofmemoryw", "out", "memori", "we", "have", "extens", "set", "wickettest", "wicket", "tester", "test", "recent", "wicket", "releas", "maven", "repositori", "chang", "after", "new", "version", "our", "test", "got", "veri", "slow", "when", "profil", "discov", "that", "mockhttprequest", "getcooki", "mock", "http", "request", "get", "cooki", "wa", "take", "up", "lot", "time", "also", "test", "fail", "becaus", "outofmemori", "out", "memori", "except", "my", "guess", "that", "somehow", "lot", "object", "are", "creat", "at", "such", "speed", "that", "gc", "not", "clean", "them", "will", "investig", "further", "but", "switch", "back", "solv", "issu", "edit", "test", "are", "run", "testng", "test", "ng", "mvn", "test"], "B_title": "Merge remote-tracking branch upstream/master into bugfix-WICKET-5147-cookies-wickettester-second-try", "B_clean_title": ["merg", "remot", "track", "branch", "upstream", "master", "into", "bugfix", "wicket", "5147", "cooki", "wickettest", "second", "tri"]},
{"A_title": "DerivativeStructure.atan2(yx) does not handle special cases properlyThe four special cases +/-0 for both x and y should give the same values as Math.atan2 and FastMath.atan2. However they give NaN for the value in all cases.", "A_clean_title": ["derivativestructur", "atan2", "deriv", "structur", "yx", "not", "handl", "special", "case", "properlyth", "properli", "four", "special", "case", "both", "give", "same", "valu", "as", "math", "atan2", "fastmath", "atan2", "fast", "math", "howev", "they", "give", "nan", "na", "valu", "all", "case"], "B_title": "Fixed DerivativeStructure.atan2 for special cases when both arguments are +/-0.", "B_clean_title": ["fix", "derivativestructur", "atan2", "deriv", "structur", "special", "case", "when", "both", "argument", "are"]},
{"A_title": "Interfaces and abstract classes are not valid typesI dont know whether this is by design or is a bug but I am having trouble working with DataSet and traits in scala which is a major limitation.  A simple example is shown below.    Compile time warning is Type Main.SimpleTrait has no fields that are visible from Scala Type analysis. Falling back to Java Type Analysis...  Run time error is Interfaces and abstract classes are not valid types: interface Main SimpleTrait  Regards John    val env = ExecutionEnvironment.getExecutionEnvironment    trait SimpleTrait      def contains(x: String): Boolean       class SimpleClass extends SimpleTrait      def contains(x: String) = true       val data: DataSetDouble = env.fromElements(1.0 2.0 3.0 4.0)    def f(data: DataSetDouble): DataSetSimpleTrait =       data.mapPartition(iterator =>        Iterator(new SimpleClass)     )        val g = f(data)   g.print()     env.execute(Simple example)", "A_clean_title": ["interfac", "abstract", "class", "are", "not", "valid", "typesi", "type", "dont", "know", "whether", "thi", "by", "design", "or", "bug", "but", "am", "have", "troubl", "work", "dataset", "data", "set", "trait", "scala", "which", "major", "limit", "simpl", "exampl", "shown", "below", "compil", "time", "warn", "type", "main", "simpletrait", "simpl", "trait", "ha", "no", "field", "that", "are", "visibl", "scala", "type", "analysi", "fall", "back", "java", "type", "analysi", "run", "time", "error", "interfac", "abstract", "class", "are", "not", "valid", "type", "interfac", "main", "simpletrait", "simpl", "trait", "regard", "john", "val", "env", "executionenviron", "getexecutionenviron", "execut", "environ", "get", "execut", "environ", "trait", "simpletrait", "simpl", "trait", "def", "contain", "string", "boolean", "class", "simpleclass", "simpl", "class", "extend", "simpletrait", "simpl", "trait", "def", "contain", "string", "true", "val", "data", "datasetdoubl", "data", "set", "doubl", "env", "fromel", "element", "def", "data", "datasetdoubl", "data", "set", "doubl", "datasetsimpletrait", "data", "set", "simpl", "trait", "data", "mappartit", "map", "partit", "iter", "iter", "new", "simpleclass", "simpl", "class", "val", "data", "print", "env", "execut", "simpl", "exampl"], "B_title": "Allow Interfaces and abstract types in TypeExtractor", "B_clean_title": ["allow", "interfac", "abstract", "type", "typeextractor", "type", "extractor"]},
{"A_title": "BracketingNthOrderBrentSolver exceeds maxIterationCount while updating always the same boundaryIn some cases the aging feature in BracketingNthOrderBrentSolver fails. It attempts to balance the bracketing points by targeting a non-zero value instead of the real root. However the chosen target is too close too zero and the inverse polynomial approximation is always on the same side thus always updates the same bracket. In the real used case for a large program I had a bracket point xA = 12500.0 yA = 3.7e-16 agingA = 0 which is the (really good) estimate of the zero on one side of the root and xB = 12500.03 yB = -7.0e-5 agingB = 97. This shows that the bracketing interval is completely unbalanced and we never succeed to rebalance it as we always updates (xA yA) and never updates (xB yB).", "A_clean_title": ["bracketingnthorderbrentsolv", "bracket", "nth", "order", "brent", "solver", "exce", "maxiterationcount", "max", "iter", "count", "while", "updat", "alway", "same", "boundaryin", "boundari", "some", "case", "age", "featur", "bracketingnthorderbrentsolv", "bracket", "nth", "order", "brent", "solver", "fail", "it", "attempt", "balanc", "bracket", "point", "by", "target", "non", "zero", "valu", "instead", "real", "root", "howev", "chosen", "target", "too", "close", "too", "zero", "invers", "polynomi", "approxim", "alway", "same", "side", "thu", "alway", "updat", "same", "bracket", "real", "use", "case", "larg", "program", "had", "bracket", "point", "xa", "12500", "ya", "16", "7e", "aginga", "age", "which", "realli", "good", "estim", "zero", "one", "side", "root", "xb", "12500", "03", "yb", "0e", "agingb", "age", "97", "thi", "show", "that", "bracket", "interv", "complet", "unbalanc", "we", "never", "succeed", "rebal", "it", "as", "we", "alway", "updat", "xa", "ya", "never", "updat", "xb", "yb"], "B_title": "Fixed bracketing interval balancing in BracketingNthOrderBrentSolver.", "B_clean_title": ["fix", "bracket", "interv", "balanc", "bracketingnthorderbrentsolv", "bracket", "nth", "order", "brent", "solver"]},
{"A_title": "Constructing invalid PartialsPartials can be constructed by invoking a constructor Partial(DateTimeFieldType int) or by merging together a set of partials using with each constructed by calling Partial(DateTimeFieldType int). However the above doesnt work in all cases: I suppose the Partials should not allow to be constructed in either case. Is that right?  Theres also a related issue (probably stems from the fact that the Partial is invalid):", "A_clean_title": ["construct", "invalid", "partialsparti", "partial", "partial", "construct", "by", "invok", "constructor", "partial", "datetimefieldtyp", "date", "time", "field", "type", "int", "or", "by", "merg", "togeth", "set", "partial", "each", "construct", "by", "call", "partial", "datetimefieldtyp", "date", "time", "field", "type", "int", "howev", "abov", "doesnt", "work", "all", "case", "suppos", "partial", "not", "allow", "construct", "either", "case", "that", "right", "there", "also", "relat", "issu", "probabl", "stem", "fact", "that", "partial", "invalid"], "B_title": "Prevent creation of invalid partials via Partial.with(DateTimeFieldTypeint)", "B_clean_title": ["prevent", "creation", "invalid", "partial", "via", "partial", "datetimefieldtypeint", "date", "time", "field", "typeint"]},
{"A_title": "Guard against invalid/missing checkpointsPlaying with the backup revealed a case where a checkpoint can become invalid after a manual restore of the repository. 0 The NodeStore#retrieve apis already specify that this can return null in the case the checkpoint doesnt exist anymore but it looks like the storage bits arent yet prepared for that scenario.    0 noformat org.apache.sling.commons.scheduler.impl.QuartzScheduler Exception during job execution of org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate@3a6d47 : Failed to load segment 8a8b281c-1a02-4950-aad5-aad8e436a0d8 java.lang.IllegalStateException: Failed to load segment 8a8b281c-1a02-4950-aad5-aad8e436a0d8 at org.apache.jackrabbit.oak.plugins.segment.AbstractStore.readSegment(AbstractStore.java:109) ~na:na at org.apache.jackrabbit.oak.plugins.segment.Segment.getSegment(Segment.java:189) ~na:na at org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:97) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplate(SegmentNodeState.java:56) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getChildNode(SegmentNodeState.java:209) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.retrieve(SegmentNodeStore.java:175) ~na:na at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.retrieve(SegmentNodeStoreService.java:198) ~na:na at org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:97) ~na:na at org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:105) ~org.apache.sling.commons.scheduler-2.4.2.jar:na at org.quartz.core.JobRunShell.run(JobRunShell.java:207) org.apache.sling.commons.scheduler-2.4.2.jar:na at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) na:1.7.0_40 at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:615) na:1.7.0_40 at java.lang.Thread.run(Thread.java:724) na:1.7.0_40 Caused by: java.lang.IllegalStateException: Segment 8a8b281c-1a02-4950-aad5-aad8e436a0d8 not found at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.loadSegment(FileStore.java:184) ~na:na noformat", "A_clean_title": ["guard", "against", "invalid", "miss", "checkpointsplay", "checkpoint", "play", "backup", "reveal", "case", "where", "checkpoint", "becom", "invalid", "after", "manual", "restor", "repositori", "nodestor", "node", "store", "retriev", "api", "alreadi", "specifi", "that", "thi", "return", "null", "case", "checkpoint", "doesnt", "exist", "anymor", "but", "it", "look", "like", "storag", "bit", "arent", "yet", "prepar", "that", "scenario", "noformat", "org", "apach", "sling", "common", "schedul", "impl", "quartzschedul", "quartz", "schedul", "except", "dure", "job", "execut", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "async", "index", "updat", "3a6d47", "fail", "load", "segment", "8a8b281c", "1a02", "4950", "aad5", "aad8e436a0d8", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "fail", "load", "segment", "8a8b281c", "1a02", "4950", "aad5", "aad8e436a0d8", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "abstractstor", "readseg", "abstract", "store", "read", "segment", "abstractstor", "java:109", "abstract", "store", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segment", "getseg", "get", "segment", "segment", "java:189", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "record", "getseg", "get", "segment", "record", "java:97", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "gettempl", "segment", "node", "state", "get", "templat", "segmentnodest", "java:56", "segment", "node", "state", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "getchildnod", "segment", "node", "state", "get", "child", "node", "segmentnodest", "java:209", "segment", "node", "state", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodestor", "retriev", "segment", "node", "store", "segmentnodestor", "java:175", "segment", "node", "store", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodestoreservic", "retriev", "segment", "node", "store", "servic", "segmentnodestoreservic", "java:198", "segment", "node", "store", "servic", "~na", "na", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "run", "async", "index", "updat", "asyncindexupd", "java:97", "async", "index", "updat", "~na", "na", "at", "org", "apach", "sling", "common", "schedul", "impl", "quartzjobexecutor", "execut", "quartz", "job", "executor", "quartzjobexecutor", "java:105", "quartz", "job", "executor", "~org", "apach", "sling", "common", "schedul", "jar", "na", "at", "org", "quartz", "core", "jobrunshel", "run", "job", "run", "shell", "jobrunshel", "java:207", "job", "run", "shell", "org", "apach", "sling", "common", "schedul", "jar", "na", "at", "java", "util", "concurr", "threadpoolexecutor", "runwork", "thread", "pool", "executor", "run", "worker", "threadpoolexecutor", "java:1145", "thread", "pool", "executor", "na:1", "40", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:615", "thread", "pool", "executor", "na:1", "40", "at", "java", "lang", "thread", "run", "thread", "java:724", "na:1", "40", "caus", "by", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "segment", "8a8b281c", "1a02", "4950", "aad5", "aad8e436a0d8", "not", "found", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "file", "filestor", "loadseg", "file", "store", "load", "segment", "filestor", "java:184", "file", "store", "~na", "na", "noformat"], "B_title": "Guard against invalid/missing checkpoints", "B_clean_title": ["guard", "against", "invalid", "miss", "checkpoint"]},
{"A_title": "potential clash of commit ids after restartthe commit ids in the current implementation are counter-based i.e. every commit (on HEAD or on a branch) gets its id by incrementing counter.  only the current HEAD id is recorded/persisted. on startup the counter is initialized with the current HEAD id.   assume the following sequence:  - ...startup... - counter == HEAD == 99 - commit on HEAD -> new HEAD rev: ++counter == 100 - create branch -> new branch rev: ++counter == 101 - ...restart... - counter == HEAD == 100 - commit on HEAD -> new HEAD rev: ++counter == 101 => clashes with older branch rev!   since a commit is never overwritten the above scenario results in a private branch revision marked as HEAD i.e. the revision history is corrupted.", "A_clean_title": ["potenti", "clash", "commit", "id", "after", "restartth", "commit", "id", "current", "implement", "are", "counter", "base", "everi", "commit", "head", "or", "branch", "get", "it", "id", "by", "increment", "counter", "onli", "current", "head", "id", "record", "persist", "startup", "counter", "initi", "current", "head", "id", "assum", "follow", "sequenc", "startup", "counter", "head", "99", "commit", "head", "new", "head", "rev", "++counter", "100", "creat", "branch", "new", "branch", "rev", "++counter", "101", "restart", "counter", "head", "100", "commit", "head", "new", "head", "rev", "++counter", "101", "clash", "older", "branch", "rev", "sinc", "commit", "never", "overwritten", "abov", "scenario", "result", "privat", "branch", "revis", "mark", "as", "head", "revis", "histori", "corrupt"], "B_title": "- potential clash of commit ids after restart - added test case", "B_clean_title": ["potenti", "clash", "commit", "id", "after", "restart", "ad", "test", "case"]},
{"A_title": "PagingNavigator.setEnabled(false) doesnt work1. Create paging navigator PagingNavigator  2. call PagingNavigator.setEnabled(false) 3. navigator will be rendered as enabled if click on any link (1 2 etc) - content of the data view will be changed.  In many cases its necessary disable navigator for example when user need to edit only single line of DataView other controls need to be disabled.", "A_clean_title": ["pagingnavig", "seten", "page", "navig", "set", "enabl", "fals", "doesnt", "work1", "creat", "page", "navig", "pagingnavig", "page", "navig", "call", "pagingnavig", "seten", "page", "navig", "set", "enabl", "fals", "navig", "will", "render", "as", "enabl", "click", "ani", "link", "etc", "content", "data", "view", "will", "chang", "mani", "case", "it", "necessari", "disabl", "navig", "exampl", "when", "user", "need", "edit", "onli", "singl", "line", "dataview", "data", "view", "other", "control", "need", "disabl"], "B_title": "", "B_clean_title": []},
{"A_title": "regression on strategy to integrate cas authenticationyes It happens in org.apache.wicket.request.handler.PageProvider.getPageInstance()  but not for the WelcomePage but the redirection page (RedirectPage). the CASPageAuthorizationStrategy as we are not authentified a org.apache.wicket.RestartResponseAtInterceptPageException with in parameter an instance of RedirectPage. On the second call of PageProvider.getPageInstance the pageId is of 0 an all other parameters are nulls.  The run seems quite different on 1.5-RC4.2 version - There is only one call of the method PageProvider.getPageInstance() and it come after the CASPageAuthorizationStrategy.isPageAuthorized  Le 27/06/2011 11:24 Martin Grigorov a écrit : > Put a breakpoint in > org.apache.wicket.request.handler.PageProvider.getPageInstance() and > see what happens. > It seems the test tries to retrieve a page from the page store by id > but there is no such. > > On Mon Jun 27 2011 at 12:20 PM Thomas Franconville > <tfranconville@tetraedge.com>  wrote: >> Hi >> >> Upgrading wicket from 1.5-RC4.2 to 1.5-RC5.1  make my Junit Test down with >> the error Page expired >> >> /** >>   * Simple test using the WicketTester >>   */ >> public class TestHomePage >>  >>     private WicketTester tester; >> >>     @Before >>     public void setUp() >>      >>         tester = new WicketTester(new MyApplication()); >>      >> >>     @Test >>     public void homepageRendersSuccessfully() >>      >>         //start and render the test page >>         tester.startPage(WelcomePage.class); >> >>         //assert rendered page class >>         tester.assertRenderedPage(RedirectPage.class); >>      >>  >> >> My application use a CASPageAuthorizationStrategy inspired of >> http://www.lunikon.net/2009/11/24/integrating-cas-and-wicket/ >> >> >> Kind Regards >> >> Thomas", "A_clean_title": ["regress", "strategi", "integr", "ca", "authenticationy", "it", "happen", "org", "apach", "wicket", "request", "handler", "pageprovid", "getpageinst", "page", "provid", "get", "page", "instanc", "but", "not", "welcomepag", "welcom", "page", "but", "redirect", "page", "redirectpag", "redirect", "page", "caspageauthorizationstrategi", "ca", "page", "author", "strategi", "as", "we", "are", "not", "authentifi", "org", "apach", "wicket", "restartresponseatinterceptpageexcept", "restart", "respons", "at", "intercept", "page", "except", "paramet", "instanc", "redirectpag", "redirect", "page", "second", "call", "pageprovid", "getpageinst", "page", "provid", "get", "page", "instanc", "pageid", "page", "id", "all", "other", "paramet", "are", "null", "run", "seem", "quit", "differ", "rc4", "version", "there", "onli", "one", "call", "method", "pageprovid", "getpageinst", "page", "provid", "get", "page", "instanc", "it", "come", "after", "caspageauthorizationstrategi", "ispageauthor", "ca", "page", "author", "strategi", "page", "author", "le", "27", "06", "2011", "11:24", "martin", "grigorov", "écrit", "put", "breakpoint", "org", "apach", "wicket", "request", "handler", "pageprovid", "getpageinst", "page", "provid", "get", "page", "instanc", "see", "what", "happen", "it", "seem", "test", "tri", "retriev", "page", "page", "store", "by", "id", "but", "there", "no", "such", "mon", "jun", "27", "2011", "at", "12:20", "pm", "thoma", "franconvil", "tfranconvil", "tetraedg", "com", "wrote", "hi", "upgrad", "wicket", "rc4", "rc5", "make", "my", "junit", "test", "down", "error", "page", "expir", "simpl", "test", "wickettest", "wicket", "tester", "public", "class", "testhomepag", "test", "home", "page", "privat", "wickettest", "wicket", "tester", "tester", "befor", "public", "void", "setup", "set", "up", "tester", "new", "wickettest", "wicket", "tester", "new", "myapplic", "my", "applic", "test", "public", "void", "homepagerenderssuccess", "homepag", "render", "success", "start", "render", "test", "page", "tester", "startpag", "start", "page", "welcomepag", "class", "welcom", "page", "assert", "render", "page", "class", "tester", "assertrenderedpag", "assert", "render", "page", "redirectpag", "class", "redirect", "page", "my", "applic", "use", "caspageauthorizationstrategi", "ca", "page", "author", "strategi", "inspir", "http", "ca", "lunikon", "wicket", "www", "net", "2009", "11", "24", "integr", "kind", "regard", "thoma"], "B_title": "regression on strategy to integrate cas authentication", "B_clean_title": ["regress", "strategi", "integr", "ca", "authent"]},
{"A_title": "stat.correlation.Covariance should allow one-column matricesCurrently (rev 1453206) passing 1-by-M matrix to the Covariance constructor throws IllegalArgumentException. For consistency the Covariance class should work for a single-column matrix (i.e. for a N-dimensional random variable with N=1) and it should return 1-by-1 covariance matrix with the variables variance in its only element.", "A_clean_title": ["stat", "correl", "covari", "allow", "one", "column", "matricescurr", "matric", "current", "rev", "1453206", "pass", "by", "matrix", "covari", "constructor", "throw", "illegalargumentexcept", "illeg", "argument", "except", "consist", "covari", "class", "work", "singl", "column", "matrix", "dimension", "random", "variabl", "n=1", "it", "return", "by", "covari", "matrix", "variabl", "varianc", "it", "onli", "element"], "B_title": "Allow covariance to be computed for one-dimensional variables.", "B_clean_title": ["allow", "covari", "comput", "one", "dimension", "variabl"]},
{"A_title": "ClassCastException during TypeCheck passNone", "A_clean_title": ["classcastexcept", "class", "cast", "except", "dure", "typecheck", "type", "check", "passnon", "pass", "none"], "B_title": "Fix a bunch of bugs in record type sup/inf with proxy types Fixes issue 603", "B_clean_title": ["fix", "bunch", "bug", "record", "type", "sup", "inf", "proxi", "type", "fix", "issu", "603"]},
{"A_title": "PropertyIndex cost calculation is faultyThe cost calculation can easily go out of bounds when it needs to estimate (whenever there are more than 100 nodes). The high value it returns can be higher than the traversal index which has a max of 10M but can be less smaller.   For example:   100 nodes in the index:   with a single level /content cost is 6250000   adding a second level /content/data cost jumps to 1.544804416E9    101 nodes in the index:   with a single level /content cost is 100   adding a second level /content/data stays at 100    100 nodes 12 levels deep cost is 2.147483647E9   101 nodes 12 levels deep cost is 6.7108864E7", "A_clean_title": ["propertyindex", "properti", "index", "cost", "calcul", "faultyth", "faulti", "cost", "calcul", "easili", "go", "out", "bound", "when", "it", "need", "estim", "whenev", "there", "are", "more", "than", "100", "node", "high", "valu", "it", "return", "higher", "than", "travers", "index", "which", "ha", "max", "10m", "but", "less", "smaller", "exampl", "100", "node", "index", "singl", "level", "content", "cost", "6250000", "ad", "second", "level", "content", "data", "cost", "jump", "544804416e9", "101", "node", "index", "singl", "level", "content", "cost", "100", "ad", "second", "level", "content", "data", "stay", "at", "100", "100", "node", "12", "level", "deep", "cost", "147483647e9", "101", "node", "12", "level", "deep", "cost", "7108864e7"], "B_title": "PropertyIndex cost calculation is faulty", "B_clean_title": ["propertyindex", "properti", "index", "cost", "calcul", "faulti"]},
{"A_title": "ContentMirrorStoreStrategy should utilize path restriction when availableCurrently ContentStoreMirrorStrategy has a mirror of content path under :index. Yet while query (and count) methods doesnt jump directly into restricted path.  This would be very useful for PropertyIndex where the queries can be optimized by supplying a path restriction along with an indexed property restriction (I dont know if queries with references would use paths so much though)", "A_clean_title": ["contentmirrorstorestrategi", "content", "mirror", "store", "strategi", "util", "path", "restrict", "when", "availablecurr", "avail", "current", "contentstoremirrorstrategi", "content", "store", "mirror", "strategi", "ha", "mirror", "content", "path", "under", "index", "yet", "while", "queri", "count", "method", "doesnt", "jump", "directli", "into", "restrict", "path", "thi", "would", "veri", "use", "propertyindex", "properti", "index", "where", "queri", "optim", "by", "suppli", "path", "restrict", "along", "index", "properti", "restrict", "dont", "know", "queri", "refer", "would", "use", "path", "so", "much", "though"], "B_title": "ContentMirrorStoreStrategy should utilize path restriction when available", "B_clean_title": ["contentmirrorstorestrategi", "content", "mirror", "store", "strategi", "util", "path", "restrict", "when", "avail"]},
{"A_title": "Operator checkpoint statistics state size overflowState sizes (long) of checkpoint stats overflow when summing them up per operator because the sum is stored in an int.", "A_clean_title": ["oper", "checkpoint", "statist", "state", "size", "overflowst", "overflow", "state", "size", "long", "checkpoint", "stat", "overflow", "when", "sum", "them", "up", "per", "oper", "becaus", "sum", "store", "int"], "B_title": "runtime Fix checkpoint statistics state size overflow", "B_clean_title": ["runtim", "fix", "checkpoint", "statist", "state", "size", "overflow"]},
{"A_title": "compiler-20110811 crashes with index(1) must be less than size(1)None", "A_clean_title": ["compil", "20110811", "crash", "index", "must", "less", "than", "size", "none"], "B_title": "Fix edge case in InlineObjectLiteral. Fixes issue 545", "B_clean_title": ["fix", "edg", "case", "inlineobjectliter", "inlin", "object", "liter", "fix", "issu", "545"]},
{"A_title": "Input type validation often fails on custom TypeInfo implementationsInput type validation often fails when used with custom type infos. One example of this behaviour can be reproduced by creating a custom type info with our own field type:  StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();  env.generateSequence(1 10).map(new MapFunction<Long Tuple1<Optional<Long>>>()  @Override public Tuple1<Optional<Long>> map(Long value) throws Exception  return Tuple1.of(Optional.of(value));  ).returns(new TupleTypeInfo<>(new OptionTypeInfo<Long>(BasicTypeInfo.LONG_TYPE_INFO))) .keyBy(new KeySelector<Tuple1<Optional<Long>> Optional<Long>>()   @Override public Optional<Long> getKey(Tuple1<Optional<Long>> value) throws Exception  return value.f0;  );  This will fail on Input type validation at the KeySelector (or any other function for example a mapper) with the following exception:  Input mismatch: Basic type expected.", "A_clean_title": ["input", "type", "valid", "often", "fail", "custom", "typeinfo", "type", "info", "implementationsinput", "implement", "input", "type", "valid", "often", "fail", "when", "use", "custom", "type", "info", "one", "exampl", "thi", "behaviour", "reproduc", "by", "creat", "custom", "type", "info", "our", "own", "field", "type", "streamexecutionenviron", "stream", "execut", "environ", "env", "streamexecutionenviron", "getexecutionenviron", "stream", "execut", "environ", "get", "execut", "environ", "env", "generatesequ", "gener", "sequenc", "10", "map", "new", "mapfunct", "map", "function", "long", "tuple1", "option", "long", "overrid", "public", "tuple1", "option", "long", "map", "long", "valu", "throw", "except", "return", "tuple1", "option", "valu", "return", "new", "tupletypeinfo", "tupl", "type", "info", "new", "optiontypeinfo", "option", "type", "info", "long", "basictypeinfo", "basic", "type", "info", "long", "type", "info", "keybi", "key", "by", "new", "keyselector", "key", "selector", "tuple1", "option", "long", "option", "long", "overrid", "public", "option", "long", "getkey", "get", "key", "tuple1", "option", "long", "valu", "throw", "except", "return", "valu", "f0", "thi", "will", "fail", "input", "type", "valid", "at", "keyselector", "key", "selector", "or", "ani", "other", "function", "exampl", "mapper", "follow", "except", "input", "mismatch", "basic", "type", "expect"], "B_title": "FLINK-3563 core TypeExtraction input type validation fixes", "B_clean_title": ["flink", "3563", "core", "typeextract", "type", "extract", "input", "type", "valid", "fix"]},
{"A_title": "AbstractMarkupParser doesnt remove Comments correctlyAbstractMarkupParser removeComment(...) doesnt remove Comments correctly  if two html comments stand to close together <!-- foo --> <!-- bar --> foo will be removed but not bar.  see:  https://github.com/mafulafunk/wicketComments  git@github.com:mafulafunk/wicketComments.git", "A_clean_title": ["abstractmarkuppars", "abstract", "markup", "parser", "doesnt", "remov", "comment", "correctlyabstractmarkuppars", "correctli", "abstract", "markup", "parser", "removecom", "remov", "comment", "doesnt", "remov", "comment", "correctli", "two", "html", "comment", "stand", "close", "togeth", "foo", "bar", "foo", "will", "remov", "but", "not", "bar", "see", "http", "github", "com", "mafulafunk", "wicketcom", "wicket", "comment", "git", "github", "com", "git", "mafulafunk", "wicketcom", "wicket", "comment"], "B_title": "fixed WICKET-3222 AbstractMarkupParser doesnt remove Comments correctly Issue: WICKET-3222", "B_clean_title": ["fix", "wicket", "3222", "abstractmarkuppars", "abstract", "markup", "parser", "doesnt", "remov", "comment", "correctli", "issu", "wicket", "3222"]},
{"A_title": "Tree has wrong parent after moveAfter a move operation Tree.getParent() still returns the old parent.  code Tree x = r.getChild(x); Tree y = r.getChild(y);  root.move(x y/x); assertEquals(y x.getParent().getName());  // Fails code", "A_clean_title": ["tree", "ha", "wrong", "parent", "after", "moveaft", "move", "after", "move", "oper", "tree", "getpar", "get", "parent", "still", "return", "old", "parent", "code", "tree", "getchild", "get", "child", "tree", "getchild", "get", "child", "root", "move", "assertequ", "assert", "equal", "getpar", "get", "parent", "getnam", "get", "name", "fail", "code"], "B_title": "Tree has wrong parent after move - Initial fix - Regression tests", "B_clean_title": ["tree", "ha", "wrong", "parent", "after", "move", "initi", "fix", "regress", "test"]},
{"A_title": "Compiler ignores delete statements can break functionality.None", "A_clean_title": ["compil", "ignor", "delet", "statement", "break", "function", "none"], "B_title": "Do not inline an object literal if it has a property that gets deleted.", "B_clean_title": ["not", "inlin", "object", "liter", "it", "ha", "properti", "that", "get", "delet"]},
{"A_title": "DataTable row groups are present in markup even when they contain no rows.As per the HTML spec : When present each THEAD TFOOT and TBODY contains a row group. Each row group must contain at least one row defined by the TR element.  There is no check in place to remove the row group tags from the output if they dont contain any row.", "A_clean_title": ["datat", "data", "tabl", "row", "group", "are", "present", "markup", "even", "when", "they", "contain", "no", "row", "as", "per", "html", "spec", "when", "present", "each", "thead", "tfoot", "tbodi", "contain", "row", "group", "each", "row", "group", "must", "contain", "at", "least", "one", "row", "defin", "by", "tr", "element", "there", "no", "check", "place", "remov", "row", "group", "tag", "output", "they", "dont", "contain", "ani", "row"], "B_title": "DataTable row groups are present in markup even when they contain no rows.", "B_clean_title": ["datat", "data", "tabl", "row", "group", "are", "present", "markup", "even", "when", "they", "contain", "no", "row"]},
{"A_title": "MemoryPropertyBuilder.assignFrom leads to ClassCastException on getPropertyState with date propertiesNone", "A_clean_title": ["memorypropertybuild", "assignfrom", "memori", "properti", "builder", "assign", "lead", "classcastexcept", "class", "cast", "except", "getpropertyst", "get", "properti", "state", "date", "propertiesnon", "properti", "none"], "B_title": "MemoryPropertyBuilder.assignFrom leads to ClassCastException on getPropertyState with date properties", "B_clean_title": ["memorypropertybuild", "assignfrom", "memori", "properti", "builder", "assign", "lead", "classcastexcept", "class", "cast", "except", "getpropertyst", "get", "properti", "state", "date", "properti"]},
{"A_title": "PojoType fields not supported by field position keysTuple fields which are Pojos (or any other non-tuple composite type) cannot be selected as keys by field position keys.  Something like   code DataSet<Tuple2<Integer MyPojo>> data = ... data.groupBy(1).reduce(...) code  fails with an exception.", "A_clean_title": ["pojotyp", "pojo", "type", "field", "not", "support", "by", "field", "posit", "keystupl", "key", "tupl", "field", "which", "are", "pojo", "or", "ani", "other", "non", "tupl", "composit", "type", "not", "select", "as", "key", "by", "field", "posit", "key", "someth", "like", "code", "dataset", "data", "set", "tuple2", "integ", "mypojo", "my", "pojo", "data", "data", "groupbi", "group", "by", "reduc", "code", "fail", "except"], "B_title": "fix FieldPositionKeys support Pojo fields", "B_clean_title": ["fix", "fieldpositionkey", "field", "posit", "key", "support", "pojo", "field"]},
{"A_title": "WicketTester Cookie handlingWhile trying to test my SecureForm implementation (https://issues.apache.org/jira/browse/WICKET-1885) with WicketTester I ran into this issue: A cookie set in the response never shows up in the next request because both have their own lists of cookies that arent shared.  Afaik both should share the same List instance to handle cookies. That way its possible to set a cookie in the response and read it from the request.  A simple testcase is attached.", "A_clean_title": ["wickettest", "wicket", "tester", "cooki", "handlingwhil", "handl", "while", "tri", "test", "my", "secureform", "secur", "form", "implement", "http", "1885", "apach", "issu", "org", "jira", "brows", "wicket", "wickettest", "wicket", "tester", "ran", "into", "thi", "issu", "cooki", "set", "respons", "never", "show", "up", "next", "request", "becaus", "both", "have", "their", "own", "list", "cooki", "that", "arent", "share", "afaik", "both", "share", "same", "list", "instanc", "handl", "cooki", "that", "way", "it", "possibl", "set", "cooki", "respons", "read", "it", "request", "simpl", "testcas", "attach"], "B_title": "Fixed testing things that require cookies persisted over multiple requests such as CSRF protection in a hidden Form fields. An even more straight forward option would have been to remove clearing cookies in MockWebApplication.initialize() and copy cookies to each request from response because after all the lifecycle of a WicketTester (MockWebApplication) instance should be such that cookies could be preserved there.", "B_clean_title": ["fix", "test", "thing", "that", "requir", "cooki", "persist", "over", "multipl", "request", "such", "as", "csrf", "protect", "hidden", "form", "field", "even", "more", "straight", "forward", "option", "would", "have", "been", "remov", "clear", "cooki", "mockwebappl", "initi", "mock", "web", "applic", "copi", "cooki", "each", "request", "respons", "becaus", "after", "all", "lifecycl", "wickettest", "wicket", "tester", "mockwebappl", "mock", "web", "applic", "instanc", "such", "that", "cooki", "could", "preserv", "there"]},
{"A_title": "unable to add nodes to an empty rootless Tree (e.g. LinkTree)2 scenarios which adding new nodes (via ajax) to a rootless Tree is not working as expected. the node is getting added to the treemodel but non is displayed.  1) adding a node to the rootnode. the newly added node is not displayed. 2) the rootless tree already has a node. if you add additional nodes to the root node they will be displayed (compare to 1) if you add an additional node to one of the added nodes the complete tree will disappear.  see attached quickstart", "A_clean_title": ["unabl", "add", "node", "empti", "rootless", "tree", "linktre", "link", "tree", "scenario", "which", "ad", "new", "node", "via", "ajax", "rootless", "tree", "not", "work", "as", "expect", "node", "get", "ad", "treemodel", "but", "non", "display", "ad", "node", "rootnod", "newli", "ad", "node", "not", "display", "rootless", "tree", "alreadi", "ha", "node", "you", "add", "addit", "node", "root", "node", "they", "will", "display", "compar", "you", "add", "addit", "node", "one", "ad", "node", "complet", "tree", "will", "disappear", "see", "attach", "quickstart"], "B_title": "Testing for not presented root nodes on root less trees Issue: WICKET-3309", "B_clean_title": ["test", "not", "present", "root", "node", "root", "less", "tree", "issu", "wicket", "3309"]},
{"A_title": "Lucene Index property definition is ignored if its not in includePropertyNames configLucene index property definition will not be used unless that property is in includePropertyNames config. This enforces including that property in includePropertyNames. includePropertyNames restricts all properties from getting indexed so user is now enforced to include all properties in includePropertyNames to be indexed.", "A_clean_title": ["lucen", "index", "properti", "definit", "ignor", "it", "not", "includepropertynam", "includ", "properti", "name", "configlucen", "config", "lucen", "index", "properti", "definit", "will", "not", "use", "unless", "that", "properti", "includepropertynam", "includ", "properti", "name", "config", "thi", "enforc", "includ", "that", "properti", "includepropertynam", "includ", "properti", "name", "includepropertynam", "includ", "properti", "name", "restrict", "all", "properti", "get", "index", "so", "user", "now", "enforc", "includ", "all", "properti", "includepropertynam", "includ", "properti", "name", "index"], "B_title": "- Lucene Index property definition is ignored if its not in includePropertyNames config", "B_clean_title": ["lucen", "index", "properti", "definit", "ignor", "it", "not", "includepropertynam", "includ", "properti", "name", "config"]},
{"A_title": "Mock does not implement locality groups or mergingThe Mock Instance does not implement locality groups and throws an exception if one attempts to set them. It would be useful for the unit tests that I am writing for the Accumulo proxy to have at least minimal locality group functionality in the Mock instance for example simply storing the groups and returning the stored groups when asked for.  *Edit: Tablet merging would be useful as well.", "A_clean_title": ["mock", "not", "implement", "local", "group", "or", "mergingth", "merg", "mock", "instanc", "not", "implement", "local", "group", "throw", "except", "one", "attempt", "set", "them", "it", "would", "use", "unit", "test", "that", "am", "write", "accumulo", "proxi", "have", "at", "least", "minim", "local", "group", "function", "mock", "instanc", "exampl", "simpli", "store", "group", "return", "store", "group", "when", "ask", "edit", "tablet", "merg", "would", "use", "as", "well"], "B_title": "implement deleteRows in MockAccumulo fake locality groups ignore merge requests", "B_clean_title": ["implement", "deleterow", "delet", "row", "mockaccumulo", "mock", "accumulo", "fake", "local", "group", "ignor", "merg", "request"]},
{"A_title": "OakDirectory not usable in readOnly mode with a readOnly builderWhen using OakDirectory with a read only builder say in LuceneCommand in oak-console following error is seen  noformat lc info /oak:index/users ERROR java.lang.UnsupportedOperationException: This builder is read-only.        at org.apache.jackrabbit.oak.spi.state.ReadOnlyBuilder.unsupported (ReadOnlyBuilder.java:45)        at org.apache.jackrabbit.oak.spi.state.ReadOnlyBuilder.child (ReadOnlyBuilder.java:190)        at org.apache.jackrabbit.oak.spi.state.ReadOnlyBuilder.child (ReadOnlyBuilder.java:35)        at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory.<init> (OakDirectory.java:93)        at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory.<init> (OakDirectory.java:87)        at org.apache.jackrabbit.oak.console.commands.LuceneCommand.getDirectory (LuceneCommand.groovy:128)        at org.apache.jackrabbit.oak.console.commands.LuceneCommand.this 4 getDirectory (LuceneCommand.groovy)        at org.apache.jackrabbit.oak.console.commands.LuceneCommand _closure1.doCall (LuceneCommand.groovy:55) noformat", "A_clean_title": ["oakdirectori", "oak", "directori", "not", "usabl", "readonli", "read", "onli", "mode", "readonli", "read", "onli", "builderwhen", "builder", "when", "oakdirectori", "oak", "directori", "read", "onli", "builder", "say", "lucenecommand", "lucen", "command", "oak", "consol", "follow", "error", "seen", "noformat", "lc", "info", "oak", "index", "user", "error", "java", "lang", "unsupportedoperationexcept", "unsupport", "oper", "except", "thi", "builder", "read", "onli", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "readonlybuild", "unsupport", "read", "onli", "builder", "readonlybuild", "java:45", "read", "onli", "builder", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "readonlybuild", "child", "read", "onli", "builder", "readonlybuild", "java:190", "read", "onli", "builder", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "readonlybuild", "child", "read", "onli", "builder", "readonlybuild", "java:35", "read", "onli", "builder", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "oakdirectori", "oak", "directori", "init", "oakdirectori", "java:93", "oak", "directori", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "oakdirectori", "oak", "directori", "init", "oakdirectori", "java:87", "oak", "directori", "at", "org", "apach", "jackrabbit", "oak", "consol", "command", "lucenecommand", "getdirectori", "lucen", "command", "get", "directori", "lucenecommand", "groovy:128", "lucen", "command", "at", "org", "apach", "jackrabbit", "oak", "consol", "command", "lucenecommand", "thi", "lucen", "command", "getdirectori", "get", "directori", "lucenecommand", "groovi", "lucen", "command", "at", "org", "apach", "jackrabbit", "oak", "consol", "command", "lucenecommand", "lucen", "command", "docal", "closure1", "call", "lucenecommand", "groovy:55", "lucen", "command", "noformat"], "B_title": "- OakDirectory not usable in readOnly mode with a readOnly builder", "B_clean_title": ["oakdirectori", "oak", "directori", "not", "usabl", "readonli", "read", "onli", "mode", "readonli", "read", "onli", "builder"]},
{"A_title": "FirstEntryInRowIterator is broken and has no testIn 1.4 and trunk the iterator throws a NullPointerException when seeked.  In 1.3 the iterator runs but there is a question as to what it should do when it is seeked to the middle of a row.  Currently it returns the first key found within the range.  I believe this should be changed to ignore the remaining portion of that row and return the first key of the next row.  Should this change be made in 1.3 or should I leave it as is and just change it in 1.4 and greater?", "A_clean_title": ["firstentryinrowiter", "first", "entri", "row", "iter", "broken", "ha", "no", "testin", "test", "trunk", "iter", "throw", "nullpointerexcept", "null", "pointer", "except", "when", "seek", "iter", "run", "but", "there", "question", "as", "what", "it", "when", "it", "seek", "middl", "row", "current", "it", "return", "first", "key", "found", "within", "rang", "believ", "thi", "chang", "ignor", "remain", "portion", "that", "row", "return", "first", "key", "next", "row", "thi", "chang", "made", "or", "leav", "it", "as", "just", "chang", "it", "greater"], "B_title": "created test and fixed seek behavior of FirstEntryInRowIterator - merged to trunk", "B_clean_title": ["creat", "test", "fix", "seek", "behavior", "firstentryinrowiter", "first", "entri", "row", "iter", "merg", "trunk"]},
{"A_title": "AsyncIndexer fails due to FileNotFoundException thrown by CopyOnWrite logicAt times the CopyOnWrite reports following exception  noformat 15.07.2015 14:20:35.930 *WARN* pool-58-thread-1 org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate The async index update failed org.apache.jackrabbit.oak.api.CommitFailedException: OakLucene0004: Failed to close the Lucene index at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.leave(LuceneIndexEditor.java:204) at org.apache.jackrabbit.oak.plugins.index.IndexUpdate.leave(IndexUpdate.java:219) at org.apache.jackrabbit.oak.spi.commit.VisibleEditor.leave(VisibleEditor.java:63) at org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(EditorDiff.java:56) at org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.updateIndex(AsyncIndexUpdate.java:366) at org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:311) at org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:105) at org.quartz.core.JobRunShell.run(JobRunShell.java:207) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745) Caused by: java.io.FileNotFoundException: _2s7.fdt at org.apache.lucene.store.FSDirectory.fileLength(FSDirectory.java:261) at org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier CopyOnWriteDirectory COWLocalFileReference.fileLength(IndexCopier.java:837) at org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier CopyOnWriteDirectory.fileLength(IndexCopier.java:607) at org.apache.lucene.index.SegmentCommitInfo.sizeInBytes(SegmentCommitInfo.java:141) at org.apache.lucene.index.DocumentsWriterPerThread.sealFlushedSegment(DocumentsWriterPerThread.java:529) at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:502) at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:508) at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:618) at org.apache.lucene.index.IndexWriter.doFlush(IndexWriter.java:3147) at org.apache.lucene.index.IndexWriter.flush(IndexWriter.java:3123) at org.apache.lucene.index.IndexWriter.closeInternal(IndexWriter.java:988) at org.apache.lucene.index.IndexWriter.close(IndexWriter.java:932) at org.apache.lucene.index.IndexWriter.close(IndexWriter.java:894) at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorContext.closeWriter(LuceneIndexEditorContext.java:192) at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.leave(LuceneIndexEditor.java:202) ... 10 common frames omitted noformat", "A_clean_title": ["asyncindex", "async", "index", "fail", "due", "filenotfoundexcept", "file", "not", "found", "except", "thrown", "by", "copyonwrit", "copi", "write", "logicat", "logic", "at", "time", "copyonwrit", "copi", "write", "report", "follow", "except", "noformat", "15", "07", "2015", "14:20:35", "930", "warn", "pool", "58", "thread", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "async", "index", "updat", "async", "index", "updat", "fail", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "commit", "fail", "except", "oaklucene0004", "oak", "lucene0004", "fail", "close", "lucen", "index", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexeditor", "leav", "lucen", "index", "editor", "luceneindexeditor", "java:204", "lucen", "index", "editor", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "indexupd", "leav", "index", "updat", "indexupd", "java:219", "index", "updat", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "visibleeditor", "leav", "visibl", "editor", "visibleeditor", "java:63", "visibl", "editor", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "editordiff", "process", "editor", "diff", "editordiff", "java:56", "editor", "diff", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "updateindex", "async", "index", "updat", "updat", "index", "asyncindexupd", "java:366", "async", "index", "updat", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "run", "async", "index", "updat", "asyncindexupd", "java:311", "async", "index", "updat", "at", "org", "apach", "sling", "common", "schedul", "impl", "quartzjobexecutor", "execut", "quartz", "job", "executor", "quartzjobexecutor", "java:105", "quartz", "job", "executor", "at", "org", "quartz", "core", "jobrunshel", "run", "job", "run", "shell", "jobrunshel", "java:207", "job", "run", "shell", "at", "java", "util", "concurr", "threadpoolexecutor", "runwork", "thread", "pool", "executor", "run", "worker", "threadpoolexecutor", "java:1145", "thread", "pool", "executor", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:615", "thread", "pool", "executor", "at", "java", "lang", "thread", "run", "thread", "java:745", "caus", "by", "java", "io", "filenotfoundexcept", "file", "not", "found", "except", "fdt", "2s7", "at", "org", "apach", "lucen", "store", "fsdirectori", "filelength", "fs", "directori", "file", "length", "fsdirectori", "java:261", "fs", "directori", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexcopi", "index", "copier", "copyonwritedirectori", "copi", "write", "directori", "cowlocalfilerefer", "filelength", "cow", "local", "file", "refer", "file", "length", "indexcopi", "java:837", "index", "copier", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexcopi", "index", "copier", "copyonwritedirectori", "filelength", "copi", "write", "directori", "file", "length", "indexcopi", "java:607", "index", "copier", "at", "org", "apach", "lucen", "index", "segmentcommitinfo", "sizeinbyt", "segment", "commit", "info", "size", "byte", "segmentcommitinfo", "java:141", "segment", "commit", "info", "at", "org", "apach", "lucen", "index", "documentswriterperthread", "sealflushedseg", "document", "writer", "per", "thread", "seal", "flush", "segment", "documentswriterperthread", "java:529", "document", "writer", "per", "thread", "at", "org", "apach", "lucen", "index", "documentswriterperthread", "flush", "document", "writer", "per", "thread", "documentswriterperthread", "java:502", "document", "writer", "per", "thread", "at", "org", "apach", "lucen", "index", "documentswrit", "doflush", "document", "writer", "flush", "documentswrit", "java:508", "document", "writer", "at", "org", "apach", "lucen", "index", "documentswrit", "flushallthread", "document", "writer", "flush", "all", "thread", "documentswrit", "java:618", "document", "writer", "at", "org", "apach", "lucen", "index", "indexwrit", "doflush", "index", "writer", "flush", "indexwrit", "java:3147", "index", "writer", "at", "org", "apach", "lucen", "index", "indexwrit", "flush", "index", "writer", "indexwrit", "java:3123", "index", "writer", "at", "org", "apach", "lucen", "index", "indexwrit", "closeintern", "index", "writer", "close", "intern", "indexwrit", "java:988", "index", "writer", "at", "org", "apach", "lucen", "index", "indexwrit", "close", "index", "writer", "indexwrit", "java:932", "index", "writer", "at", "org", "apach", "lucen", "index", "indexwrit", "close", "index", "writer", "indexwrit", "java:894", "index", "writer", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexeditorcontext", "closewrit", "lucen", "index", "editor", "context", "close", "writer", "luceneindexeditorcontext", "java:192", "lucen", "index", "editor", "context", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexeditor", "leav", "lucen", "index", "editor", "luceneindexeditor", "java:202", "lucen", "index", "editor", "10", "common", "frame", "omit", "noformat"], "B_title": "- AsyncIndexer fails due to FileNotFoundException thrown by CopyOnWrite logic", "B_clean_title": ["asyncindex", "async", "index", "fail", "due", "filenotfoundexcept", "file", "not", "found", "except", "thrown", "by", "copyonwrit", "copi", "write", "logic"]},
{"A_title": "Dangerous code in PoissonDistributionImplIn the following excerpt from class PoissonDistributionImpl:  code:title=PoissonDistributionImpl.java|borderStyle=solid     public PoissonDistributionImpl(double p NormalDistribution z)          super();         setNormal(z);         setMean(p);      code  (1) Overridable methods are called within the constructor. (2) The reference z is stored and modified within the class.  Ive encountered problem (1) in several classes while working on issue 348. In those cases in order to remove potential problems I copied/pasted the body of the setter methods inside the constructor but I think that a more elegant solution would be to remove the setters altogether (i.e. make the classes immutable). Problem (2) can also create unexpected behaviour. Is it really necessary to pass the NormalDistribution object; cant it be always created within the class?", "A_clean_title": ["danger", "code", "poissondistributionimplin", "poisson", "distribut", "impl", "follow", "excerpt", "class", "poissondistributionimpl", "poisson", "distribut", "impl", "code", "title=poissondistributionimpl", "java|borderstyle=solid", "title=poisson", "distribut", "impl", "java|bord", "style=solid", "public", "poissondistributionimpl", "poisson", "distribut", "impl", "doubl", "normaldistribut", "normal", "distribut", "super", "setnorm", "set", "normal", "setmean", "set", "mean", "code", "overrid", "method", "are", "call", "within", "constructor", "refer", "store", "modifi", "within", "class", "ive", "encount", "problem", "sever", "class", "while", "work", "issu", "348", "those", "case", "order", "remov", "potenti", "problem", "copi", "past", "bodi", "setter", "method", "insid", "constructor", "but", "think", "that", "more", "eleg", "solut", "would", "remov", "setter", "altogeth", "make", "class", "immut", "problem", "also", "creat", "unexpect", "behaviour", "it", "realli", "necessari", "pass", "normaldistribut", "normal", "distribut", "object", "cant", "it", "alway", "creat", "within", "class"], "B_title": "Removed deprecated methods.", "B_clean_title": ["remov", "deprec", "method"]},
{"A_title": "not possible to create a Mutation object from scala w/o some extra helper codeissue:   its not possible to create a Mutation object from scala without employing a standalone java jar wrapper. the preferred method for creating the object has you do it in two stages: create with table row then employ Mutation.put() to populate the object with the actual mutation data. when you do this in scala you get a  java.lang.IllegalStateException: Can not add to mutation after serializing it at org.apache.accumulo.core.data.Mutation.put(Mutation.java:168) at org.apache.accumulo.core.data.Mutation.put(Mutation.java:163) at org.apache.accumulo.core.data.Mutation.put(Mutation.java:211)  error. I *think* this has something to do with the byte array going out of scope in Scala but somehow not in Java. If you concat the operations (constuctor().put(data data ...) you dont run into the error but scala sees a Unit return type so you cant actually add the mutation to a BatchWriter. The only way I was able to get around this was to create a stand-alone jar with a method that created then returned a populated mutation object.   I wasnt sure whether or not to call this a bug or an enhancement. given that you probably want Accumulo to play nice with Scala I decided to call it a bug.   below is a link to the stack overflow thread I created whilst figuring all this out:   http://stackoverflow.com/questions/29497547/odd-error-when-populating-accumulo-1-6-mutation-object-via-spark-notebook/29527189#29527189", "A_clean_title": ["not", "possibl", "creat", "mutat", "object", "scala", "some", "extra", "helper", "codeissu", "it", "not", "possibl", "creat", "mutat", "object", "scala", "without", "employ", "standalon", "java", "jar", "wrapper", "prefer", "method", "creat", "object", "ha", "you", "it", "two", "stage", "creat", "tabl", "row", "then", "employ", "mutat", "put", "popul", "object", "actual", "mutat", "data", "when", "you", "thi", "scala", "you", "get", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "not", "add", "mutat", "after", "serial", "it", "at", "org", "apach", "accumulo", "core", "data", "mutat", "put", "mutat", "java:168", "at", "org", "apach", "accumulo", "core", "data", "mutat", "put", "mutat", "java:163", "at", "org", "apach", "accumulo", "core", "data", "mutat", "put", "mutat", "java:211", "error", "think", "thi", "ha", "someth", "byte", "array", "go", "out", "scope", "scala", "but", "somehow", "not", "java", "you", "concat", "oper", "constuctor", "put", "data", "data", "you", "dont", "run", "into", "error", "but", "scala", "see", "unit", "return", "type", "so", "you", "cant", "actual", "add", "mutat", "batchwrit", "batch", "writer", "onli", "way", "wa", "abl", "get", "around", "thi", "wa", "creat", "stand", "alon", "jar", "method", "that", "creat", "then", "return", "popul", "mutat", "object", "wasnt", "sure", "whether", "or", "not", "call", "thi", "bug", "or", "enhanc", "given", "that", "you", "probabl", "want", "accumulo", "play", "nice", "scala", "decid", "call", "it", "bug", "below", "link", "stack", "overflow", "thread", "creat", "whilst", "figur", "all", "thi", "out", "http", "error", "when", "popul", "accumulo", "mutat", "object", "via", "spark", "notebook", "29527189", "stackoverflow", "com", "question", "29497547", "odd", "29527189"], "B_title": "make Mutation#hashCode and Mutation#equals not change the state of the mutation", "B_clean_title": ["make", "mutat", "hashcod", "hash", "code", "mutat", "equal", "not", "chang", "state", "mutat"]},
{"A_title": "FastDateParser does not handle unterminated quotes correctlyFDP does not handled unterminated quotes the same way as SimpleDateFormat For example: Format: dd Date: d3 This should fail to parse the format and date but it actually works. The format is parsed as: Pattern: d(p IsNd ++)", "A_clean_title": ["fastdatepars", "fast", "date", "parser", "not", "handl", "untermin", "quot", "correctlyfdp", "correctli", "fdp", "not", "handl", "untermin", "quot", "same", "way", "as", "simpledateformat", "simpl", "date", "format", "exampl", "format", "dd", "date", "d3", "thi", "fail", "pars", "format", "date", "but", "it", "actual", "work", "format", "pars", "as", "pattern", "isnd", "nd"], "B_title": "FastDateParser does not handle unterminated quotes correctly", "B_clean_title": ["fastdatepars", "fast", "date", "parser", "not", "handl", "untermin", "quot", "correctli"]},
{"A_title": "Accumulo Shell does not respect exit when executing fileIf there is an exit statement in the file given via accumulo shell -f file the execution seems to skip it and go on to the next command instead of terminating.  To recreate: noformat mike@home ~ cat bug.accumulo exit scan -np -t !METADATA mike@home ~ bin/accumulo shell -f /home/mike/bug.accumulo noformat  Expected output: None Actual output: A full scan of the !METADATA", "A_clean_title": ["accumulo", "shell", "not", "respect", "exit", "when", "execut", "fileif", "file", "there", "exit", "statement", "file", "given", "via", "accumulo", "shell", "file", "execut", "seem", "skip", "it", "go", "next", "command", "instead", "termin", "recreat", "noformat", "mike", "home", "cat", "bug", "accumulo", "exit", "scan", "np", "metadata", "mike", "home", "bin", "accumulo", "shell", "accumulo", "home", "mike", "bug", "noformat", "expect", "output", "none", "actual", "output", "full", "scan", "metadata"], "B_title": "Applied patch from Mike Drob to 1.5 branch", "B_clean_title": ["appli", "patch", "mike", "drob", "branch"]},
{"A_title": "LocaleUtils.toLocale() rejects strings with only language+variantLocaleUtils.toLocale() throws an exception on strings containing a language and a variant but no country code. For example : fr__POSIX This string can be produced with the JDK by instanciating a Locale with an empty string for the country : new Locale(fr  POSIX).toString(). According to the javadoc for the Locale class a variant is allowed with just a language code or just a country code. Commons Configuration handles this case in its PropertyConverter.toLocale() method. Id like to replace our implementation by the one provided by LocaleUtils but our tests fail due to this case.", "A_clean_title": ["localeutil", "tolocal", "local", "util", "local", "reject", "string", "onli", "language+variantlocaleutil", "tolocal", "language+vari", "local", "util", "local", "throw", "except", "string", "contain", "languag", "variant", "but", "no", "countri", "code", "exampl", "fr", "posix", "thi", "string", "produc", "jdk", "by", "instanci", "local", "empti", "string", "countri", "new", "local", "fr", "posix", "tostr", "string", "accord", "javadoc", "local", "class", "variant", "allow", "just", "languag", "code", "or", "just", "countri", "code", "common", "configur", "handl", "thi", "case", "it", "propertyconvert", "tolocal", "properti", "convert", "local", "method", "id", "like", "replac", "our", "implement", "by", "one", "provid", "by", "localeutil", "local", "util", "but", "our", "test", "fail", "due", "thi", "case"], "B_title": "Applying unit test/fix for LANG-328", "B_clean_title": ["appli", "unit", "test", "fix", "lang", "328"]},
{"A_title": "Vector3D.crossProduct is sensitive to numerical cancellationCross product implementation uses the naive formulas (y1 z2 - y2 z1 ...). These formulas fail when vectors are almost colinear like in the following example:  Vector3D v1 = new Vector3D(9070467121.0 4535233560.0 1); Vector3D v2 = new Vector3D(9070467123.0 4535233561.0 1); System.out.println(Vector3D.crossProduct(v1 v2));   The previous code displays   -1 2 0   instead of the correct answer   -1 2 1", "A_clean_title": ["vector3d", "crossproduct", "cross", "product", "sensit", "numer", "cancellationcross", "cancel", "cross", "product", "implement", "use", "naiv", "formula", "y1", "z2", "y2", "z1", "these", "formula", "fail", "when", "vector", "are", "almost", "colinear", "like", "follow", "exampl", "vector3d", "v1", "new", "vector3d", "9070467121", "4535233560", "vector3d", "v2", "new", "vector3d", "9070467123", "4535233561", "system", "out", "println", "vector3d", "crossproduct", "cross", "product", "v1", "v2", "previou", "code", "display", "instead", "correct", "answer"], "B_title": "Reduced cancellation errors in Vector3D.crossProduct", "B_clean_title": ["reduc", "cancel", "error", "vector3d", "crossproduct", "cross", "product"]},
{"A_title": "Bugs in Frequency APII think the existing Frequency API has some bugs in it. The addValue(Object v) method allows one to add a plain Object but one cannot add anything further to the instance as the second add fails with IllegalArgumentException. In fact the problem is with the first call to addValue(Object) which should not allow a plain Object to be added - it should only allow Comparable objects. This could be fixed by checking that the object is Comparable. Similar considerations apply to the getCumFreq(Object) and getCumPct(Object) methods - they will only work with objects that implement Comparable. The getCount(Object) and getPct(Object) methods dont fail when given a non-Comparable object (because the class cast exception is caught) however they just return 0 as if the object was not present:          final Object OBJ = new Object();         f.addValue(OBJ); // This ought to fail but doesnt causing the unexpected behaviour below         System.out.println(f.getCount(OBJ)); // 0         System.out.println(f.getPct(OBJ)); // 0.0   Rather than adding extra checks for Comparable it seems to me that the API would be much improved by using Comparable instead of Object. Also it should make it easier to implement generics. However this would cause compilation failures for some programs that pass Object rather than Comparable to the class. These would need recoding but I think they would continue to run OK against the new API. It would also affect the run-time behaviour slightly as the first attempt to add a non-Comparable object would fail rather than the second add of a possibly valid object. But is that a viable program? It can only add one object and any attempt to get statistics will either return 0 or an Exception and applying the instanceof fix would also cause it to fail.", "A_clean_title": ["bug", "frequenc", "apii", "think", "exist", "frequenc", "api", "ha", "some", "bug", "it", "addvalu", "add", "valu", "object", "method", "allow", "one", "add", "plain", "object", "but", "one", "not", "add", "anyth", "further", "instanc", "as", "second", "add", "fail", "illegalargumentexcept", "illeg", "argument", "except", "fact", "problem", "first", "call", "addvalu", "add", "valu", "object", "which", "not", "allow", "plain", "object", "ad", "it", "onli", "allow", "compar", "object", "thi", "could", "fix", "by", "check", "that", "object", "compar", "similar", "consider", "appli", "getcumfreq", "get", "cum", "freq", "object", "getcumpct", "get", "cum", "pct", "object", "method", "they", "will", "onli", "work", "object", "that", "implement", "compar", "getcount", "get", "count", "object", "getpct", "get", "pct", "object", "method", "dont", "fail", "when", "given", "non", "compar", "object", "becaus", "class", "cast", "except", "caught", "howev", "they", "just", "return", "as", "object", "wa", "not", "present", "final", "object", "obj", "new", "object", "addvalu", "add", "valu", "obj", "thi", "ought", "fail", "but", "doesnt", "caus", "unexpect", "behaviour", "below", "system", "out", "println", "getcount", "get", "count", "obj", "system", "out", "println", "getpct", "get", "pct", "obj", "rather", "than", "ad", "extra", "check", "compar", "it", "seem", "me", "that", "api", "would", "much", "improv", "by", "compar", "instead", "object", "also", "it", "make", "it", "easier", "implement", "gener", "howev", "thi", "would", "caus", "compil", "failur", "some", "program", "that", "pass", "object", "rather", "than", "compar", "class", "these", "would", "need", "recod", "but", "think", "they", "would", "continu", "run", "ok", "against", "new", "api", "it", "would", "also", "affect", "run", "time", "behaviour", "slightli", "as", "first", "attempt", "add", "non", "compar", "object", "would", "fail", "rather", "than", "second", "add", "possibl", "valid", "object", "but", "that", "viabl", "program", "it", "onli", "add", "one", "object", "ani", "attempt", "get", "statist", "will", "either", "return", "or", "except", "appli", "instanceof", "fix", "would", "also", "caus", "it", "fail"], "B_title": "- throw IllegalArgument rather than ClassCast to better retain original behaviour", "B_clean_title": ["throw", "illegalargu", "illeg", "argument", "rather", "than", "classcast", "class", "cast", "better", "retain", "origin", "behaviour"]},
{"A_title": "Combiner default behavior is dangerousCurrently if the users does not give the combiner any columns to work against it will work against all columns.  This is dangerous if a user accidentally forgets to specify columns then their data could be unintentionally corrupted.  Something different needs to be done.    Also classes that extend combiner should call super.validateOptions().", "A_clean_title": ["combin", "default", "behavior", "dangerouscurr", "danger", "current", "user", "not", "give", "combin", "ani", "column", "work", "against", "it", "will", "work", "against", "all", "column", "thi", "danger", "user", "accident", "forget", "specifi", "column", "then", "their", "data", "could", "unintent", "corrupt", "someth", "differ", "need", "done", "also", "class", "that", "extend", "combin", "call", "super", "validateopt", "valid", "option"], "B_title": "changed default behavior of Combiner and modified default test", "B_clean_title": ["chang", "default", "behavior", "combin", "modifi", "default", "test"]},
{"A_title": "NPE for google cloud storageHi   Any time I try to access Resource from the google storage it throws the following NPE. It happens on both read and write . Here is how the pom looks like   Here is the code   I even tried checking out the entire repo and just run the code as it is  from spring-cloud-gcp-storage-resource-sample and class WebController by changing my bucket name and still get the same NPE  I removed the entire .m2 directory and started all over all and still the issue persists  I double checked I have access to my bucket and even tried the same form my service account that have project admin access  but the problem persists", "A_clean_title": ["npe", "googl", "cloud", "storagehi", "storag", "hi", "ani", "time", "tri", "access", "resourc", "googl", "storag", "it", "throw", "follow", "npe", "it", "happen", "both", "read", "write", "here", "how", "pom", "look", "like", "here", "code", "even", "tri", "check", "out", "entir", "repo", "just", "run", "code", "as", "it", "spring", "cloud", "gcp", "storag", "resourc", "sampl", "class", "webcontrol", "web", "control", "by", "chang", "my", "bucket", "name", "still", "get", "same", "npe", "remov", "entir", "m2", "directori", "start", "all", "over", "all", "still", "issu", "persist", "doubl", "check", "have", "access", "my", "bucket", "even", "tri", "same", "form", "my", "servic", "account", "that", "have", "project", "admin", "access", "but", "problem", "persist"], "B_title": "Fix NPE for GCS buckets that have underscores (#316)  Fixes #314.", "B_clean_title": ["fix", "npe", "gc", "bucket", "that", "have", "underscor", "316", "fix", "314"]},
{"A_title": "closure-compiler @define annotation does not allow line to be split on 80 characters.None", "A_clean_title": ["closur", "compil", "defin", "annot", "not", "allow", "line", "split", "80", "charact", "none"], "B_title": "Generalize define value handling allow ADD and other basic ops fix BITxxx handling so they dont allow invalid operands.", "B_clean_title": ["gener", "defin", "valu", "handl", "allow", "add", "other", "basic", "op", "fix", "bitxxx", "bi", "txxx", "handl", "so", "they", "dont", "allow", "invalid", "operand"]},
{"A_title": "Assignments within conditions are sometimes incorrectly removedNone", "A_clean_title": ["assign", "within", "condit", "are", "sometim", "incorrectli", "removednon", "remov", "none"], "B_title": "Correct handling of conditional branches within expressions when doing dead assignment elminination. Fixes issue 384.", "B_clean_title": ["correct", "handl", "condit", "branch", "within", "express", "when", "do", "dead", "assign", "elminin", "fix", "issu", "384"]},
{"A_title": "Hibernate Subselect Entity not supported by EntityMetamodelImplDescription  After playing a bit with table functions (see also  #181 ) I had the idea to experiment with mapping a generate_series query to an entity using the annotation. Find below the produced stack trace. A trivial work around is to wrap the query into to a view and map that instead. I am uncertain whether a fix for this is worthwhile but it could perhaps be a step towards implementing table functions (  #181 ).   Expected behavior  Actual behavior  Steps to reproduce  Environment  Version:            1.2.0.Alpha3  JPA-Provider:       Hibernate 5.2.12 DBMS:               PostgresSQL Application Server: Wildfly", "A_clean_title": ["hibern", "subselect", "entiti", "not", "support", "by", "entitymetamodelimpldescript", "entiti", "metamodel", "impl", "descript", "after", "play", "bit", "tabl", "function", "see", "also", "181", "had", "idea", "experi", "map", "gener", "seri", "queri", "entiti", "annot", "find", "below", "produc", "stack", "trace", "trivial", "work", "around", "wrap", "queri", "into", "view", "map", "that", "instead", "am", "uncertain", "whether", "fix", "thi", "worthwhil", "but", "it", "could", "perhap", "step", "toward", "implement", "tabl", "function", "181", "expect", "behavior", "actual", "behavior", "step", "reproduc", "environ", "version", "alpha3", "jpa", "provid", "hibern", "12", "dbm", "postgressql", "postgr", "sql", "applic", "server", "wildfli"], "B_title": "#519 Little cleanup and ensure tests run on all supported DBMS", "B_clean_title": ["519", "littl", "cleanup", "ensur", "test", "run", "all", "support", "dbm"]},
{"A_title": "PageProvider should create a new Page instance if PageParameters are changed even if a stored page exists.The getStoredPage(int) method returns a stored page instance even if user changes parameter values encoded into URL and the PageParameters object of the stored page instance is never changed. So same page is displayed always though user changes url on browser manually.  ** HOW TO REPRODUCT **  1. unpack the attached sample project pagebug.tar.gz. 2. mvn jetty:run 3. access to http://localhost:8080/user/user1  You will see a form filled with information about user 1. The users name is user 1 age is 30 and country is Japan. The mount path of this page is /user/ userId. so user1 in the accessed url is a parameter value.  after accessing to the url the url will be changed to http://localhost:8080/user/user1?0 .  it contains the page id of the currently displayed page.  4. change some values and submit the form. page id will be changed on every submit.  5. change only parameter value in url to user2. Never change page-id.  for example if you now access to http://localhost:8080/user/user1?5 change the url to http://localhost:8080/user/user2?5 .  6. This program must display information about user2 because the parameter value of url is changed. But you will see the information of user 1. Wicket always display the page of page-id = 5 (even though user changed url manually).  In this sample program I use LoadableDetachableModel for retrieving current parameter-value. But I dont get the new parameter-value because pageParameters object in a page instance is never changed after the construction. pageParameters is fixed in the constructor of Page class.  I think that there are no easy way to retrieve parameter-values encoded into mount-path. Request.getRequestParameters() does not contain parameters encoded into mount-path. So there are no work-around for this issue.   ** HOW TO FIX THIS ISSUE **  We must return null from getStoredPage(int) method of PageProvider class if current PageParameters is not same with the PageParameters of a stored page. In current code getStoredPage(int) checks only if the class of both pages are same. We must check the PageParameters of both pages.   ** PATCH **  I attached a pache for PageProvider class. try it.", "A_clean_title": ["pageprovid", "page", "provid", "creat", "new", "page", "instanc", "pageparamet", "page", "paramet", "are", "chang", "even", "store", "page", "exist", "getstoredpag", "get", "store", "page", "int", "method", "return", "store", "page", "instanc", "even", "user", "chang", "paramet", "valu", "encod", "into", "url", "pageparamet", "page", "paramet", "object", "store", "page", "instanc", "never", "chang", "so", "same", "page", "display", "alway", "though", "user", "chang", "url", "browser", "manual", "how", "reproduct", "unpack", "attach", "sampl", "project", "pagebug", "tar", "gz", "mvn", "jetti", "run", "access", "http", "localhost:8080", "user", "user1", "you", "will", "see", "form", "fill", "inform", "about", "user", "user", "name", "user", "age", "30", "countri", "japan", "mount", "path", "thi", "page", "user", "userid", "user", "id", "so", "user1", "access", "url", "paramet", "valu", "after", "access", "url", "url", "will", "chang", "http", "localhost:8080", "user", "user1", "it", "contain", "page", "id", "current", "display", "page", "chang", "some", "valu", "submit", "form", "page", "id", "will", "chang", "everi", "submit", "chang", "onli", "paramet", "valu", "url", "user2", "never", "chang", "page", "id", "exampl", "you", "now", "access", "http", "localhost:8080", "user", "user1", "chang", "url", "http", "localhost:8080", "user", "user2", "thi", "program", "must", "display", "inform", "about", "user2", "becaus", "paramet", "valu", "url", "chang", "but", "you", "will", "see", "inform", "user", "wicket", "alway", "display", "page", "page", "id", "even", "though", "user", "chang", "url", "manual", "thi", "sampl", "program", "use", "loadabledetachablemodel", "loadabl", "detach", "model", "retriev", "current", "paramet", "valu", "but", "dont", "get", "new", "paramet", "valu", "becaus", "pageparamet", "page", "paramet", "object", "page", "instanc", "never", "chang", "after", "construct", "pageparamet", "page", "paramet", "fix", "constructor", "page", "class", "think", "that", "there", "are", "no", "easi", "way", "retriev", "paramet", "valu", "encod", "into", "mount", "path", "request", "getrequestparamet", "get", "request", "paramet", "not", "contain", "paramet", "encod", "into", "mount", "path", "so", "there", "are", "no", "work", "around", "thi", "issu", "how", "fix", "thi", "issu", "we", "must", "return", "null", "getstoredpag", "get", "store", "page", "int", "method", "pageprovid", "page", "provid", "class", "current", "pageparamet", "page", "paramet", "not", "same", "pageparamet", "page", "paramet", "store", "page", "current", "code", "getstoredpag", "get", "store", "page", "int", "check", "onli", "class", "both", "page", "are", "same", "we", "must", "check", "pageparamet", "page", "paramet", "both", "page", "patch", "attach", "pach", "pageprovid", "page", "provid", "class", "tri", "it"], "B_title": "PageProvider should create a new Page instance if PageParameters are changed even if a stored page exists.", "B_clean_title": ["pageprovid", "page", "provid", "creat", "new", "page", "instanc", "pageparamet", "page", "paramet", "are", "chang", "even", "store", "page", "exist"]},
{"A_title": "UniformIntegerDistribution should make constructer a exclusive bound or made parameter check more relaxUniformIntegerDistribution constructer  public UniformIntegerDistribution(RandomGenerator rng                                       int lower                                       int upper)  the lower and the upper all inclusive. but the parameter check made a   if (lower >= upper)              throw new NumberIsTooLargeException(                             LocalizedFormats.LOWER_BOUND_NOT_BELOW_UPPER_BOUND                             lower upper false); check i think it is too strict to construct UniformIntegerDistribution (00)  this should make it possible", "A_clean_title": ["uniformintegerdistribut", "uniform", "integ", "distribut", "make", "construct", "exclus", "bound", "or", "made", "paramet", "check", "more", "relaxuniformintegerdistribut", "relax", "uniform", "integ", "distribut", "construct", "public", "uniformintegerdistribut", "uniform", "integ", "distribut", "randomgener", "random", "gener", "rng", "int", "lower", "int", "upper", "lower", "upper", "all", "inclus", "but", "paramet", "check", "made", "lower", "upper", "throw", "new", "numberistoolargeexcept", "number", "too", "larg", "except", "localizedformat", "local", "format", "lower", "bound", "not", "below", "upper", "bound", "lower", "upper", "fals", "check", "think", "it", "too", "strict", "construct", "uniformintegerdistribut", "uniform", "integ", "distribut", "00", "thi", "make", "it", "possibl"], "B_title": "Allow same value for lower and upper bounds.", "B_clean_title": ["allow", "same", "valu", "lower", "upper", "bound"]},
{"A_title": "FormTester doesnt correctly submit a form when a FileUploadField was not set (which is not required)FormTester doesnt correctly submit a form when  a FileUploadField was not set. This file is not required.  So it is impossible to create a real test because I am forced to always set a File to check to whole form.  There was discussion about this problem here: http://www.nabble.com/FormTester-and-FileUploadField-td18566869.html   I will be very grateful if you can fix it :) Artur", "A_clean_title": ["formtest", "form", "tester", "doesnt", "correctli", "submit", "form", "when", "fileuploadfield", "file", "upload", "field", "wa", "not", "set", "which", "not", "requir", "formtest", "form", "tester", "doesnt", "correctli", "submit", "form", "when", "fileuploadfield", "file", "upload", "field", "wa", "not", "set", "thi", "file", "not", "requir", "so", "it", "imposs", "creat", "real", "test", "becaus", "am", "forc", "alway", "set", "file", "check", "whole", "form", "there", "wa", "discuss", "about", "thi", "problem", "here", "http", "fileuploadfield", "nabbl", "file", "upload", "field", "td18566869", "html", "www", "com", "formtest", "form", "tester", "will", "veri", "grate", "you", "fix", "it", "artur"], "B_title": "", "B_clean_title": []},
{"A_title": "bogus missing return warningNone", "A_clean_title": ["bogu", "miss", "return", "warningnon", "warn", "none"], "B_title": "when handling a finally block like so try  alert(1)  finally   There needs to be 2 edges: an unconditional edge to the statement after the finally and an edge for the code path that continues handling the exception. Label the second edge with ON_EX instead of UNCOND. Fixes issue 779", "B_clean_title": ["when", "handl", "final", "block", "like", "so", "tri", "alert", "final", "there", "need", "edg", "uncondit", "edg", "statement", "after", "final", "edg", "code", "path", "that", "continu", "handl", "except", "label", "second", "edg", "ex", "instead", "uncond", "fix", "issu", "779"]},
{"A_title": "isVisibleInHierarchy() possibly unnecessarily checks children whose parents are invisible?Hi!  See attached quickstart with junit test reproducing the bug. See also patch proposal.  I have a page with two panels:  page.form.add(panel1); page.form.add(panel2);  in some situations panel1 is not visible.  However a form submit event will visit all formcomponents of panel1 via:         at org.apache.wicket.markup.html.form.FormComponent.visitFormComponentsPostOrder(FormComponent.java:400)        at org.apache.wicket.markup.html.form.Form.visitFormComponentsPostOrder(Form.java:1209)        at org.apache.wicket.markup.html.form.Form.inputChanged(Form.java:1403)        at org.apache.wicket.markup.html.form.Form.onFormSubmitted(Form.java:865)  This results in a crash because panel1 components are not prepared to be invoked via isvisible when the panel itself is not visible.  I wonder if the component.isVisibleInHierarchy could be changed as follows to first check parent visibility:   public final boolean isVisibleInHierarchy()      Component component = this;    while (component != null)          Component componentParent = component.getParent();       if (((componentParent == null) || componentParent.isVisibleInHierarchy()) && component.determineVisibility())              component = componentParent;            else              return false;              return true;    Similar change could/should maybe be possible also for isEnabledInHierarchy ?", "A_clean_title": ["isvisibleinhierarchi", "visibl", "hierarchi", "possibl", "unnecessarili", "check", "children", "whose", "parent", "are", "invis", "hi", "see", "attach", "quickstart", "junit", "test", "reproduc", "bug", "see", "also", "patch", "propos", "have", "page", "two", "panel", "page", "form", "add", "panel1", "page", "form", "add", "panel2", "some", "situat", "panel1", "not", "visibl", "howev", "form", "submit", "event", "will", "visit", "all", "formcompon", "panel1", "via", "at", "org", "apach", "wicket", "markup", "html", "form", "formcompon", "visitformcomponentspostord", "form", "compon", "visit", "form", "compon", "post", "order", "formcompon", "java:400", "form", "compon", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "visitformcomponentspostord", "visit", "form", "compon", "post", "order", "form", "java:1209", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "inputchang", "input", "chang", "form", "java:1403", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "onformsubmit", "form", "submit", "form", "java:865", "thi", "result", "crash", "becaus", "panel1", "compon", "are", "not", "prepar", "invok", "via", "isvis", "when", "panel", "itself", "not", "visibl", "wonder", "compon", "isvisibleinhierarchi", "visibl", "hierarchi", "could", "chang", "as", "follow", "first", "check", "parent", "visibl", "public", "final", "boolean", "isvisibleinhierarchi", "visibl", "hierarchi", "compon", "compon", "thi", "while", "compon", "null", "compon", "componentpar", "compon", "parent", "compon", "getpar", "get", "parent", "componentpar", "compon", "parent", "null", "componentpar", "isvisibleinhierarchi", "compon", "parent", "visibl", "hierarchi", "compon", "determinevis", "determin", "visibl", "compon", "componentpar", "compon", "parent", "return", "fals", "return", "true", "similar", "chang", "could", "mayb", "possibl", "also", "isenabledinhierarchi", "enabl", "hierarchi"], "B_title": "meh. this caching will probably slow things down. and it can be difficult to find all the places in code where caching should be invalidated. lets hold off until it is a hotspot. Issue: WICKET-3166", "B_clean_title": ["meh", "thi", "cach", "will", "probabl", "slow", "thing", "down", "it", "difficult", "find", "all", "place", "code", "where", "cach", "invalid", "let", "hold", "off", "until", "it", "hotspot", "issu", "wicket", "3166"]},
{"A_title": "MethodGetAndSet.setValue uses wrong source to determine which type to convert to when theres no setterMethodGetAndSet.setValue uses wrong source to determine which type to convert to when theres no setter resulting in exceptions like this: org.apache.wicket.WicketRuntimeException: Error setting field: private int PropertyResolverTest DirectFieldSetWithDifferentTypeThanGetter.value on object: PropertyResolverTest DirectFieldSetWithDifferentTypeThanGetter@396477d9 at org.apache.wicket.util.lang.PropertyResolver MethodGetAndSet.setValue(PropertyResolver.java:1150) at org.apache.wicket.util.lang.PropertyResolver ObjectAndGetSetter.setValue(PropertyResolver.java:588) at org.apache.wicket.util.lang.PropertyResolver.setValue(PropertyResolver.java:136) at PropertyResolverTest.testDirectFieldSetWithDifferentTypeThanGetter(PropertyResolverTest.java:12)  Bug is located in: converted = converter.convert(value getMethod.getReturnType());  Instead it should read: converted = converter.convert(value type);  Testcase attached.  Additional thoughts: if (setMethod != null)    type = getMethod.getReturnType();  This is really confusing (we check setMethod presence but get type from getMethod). Luckily this works as expected because in MethodGetAndSet.findSetter only methods with same (or superclass) type as getter are returned.", "A_clean_title": ["methodgetandset", "setvalu", "method", "get", "set", "set", "valu", "use", "wrong", "sourc", "determin", "which", "type", "convert", "when", "there", "no", "settermethodgetandset", "setvalu", "setter", "method", "get", "set", "set", "valu", "use", "wrong", "sourc", "determin", "which", "type", "convert", "when", "there", "no", "setter", "result", "except", "like", "thi", "org", "apach", "wicket", "wicketruntimeexcept", "wicket", "runtim", "except", "error", "set", "field", "privat", "int", "propertyresolvertest", "properti", "resolv", "test", "directfieldsetwithdifferenttypethangett", "valu", "direct", "field", "set", "differ", "type", "than", "getter", "object", "propertyresolvertest", "properti", "resolv", "test", "directfieldsetwithdifferenttypethangett", "direct", "field", "set", "differ", "type", "than", "getter", "396477d9", "at", "org", "apach", "wicket", "util", "lang", "propertyresolv", "properti", "resolv", "methodgetandset", "setvalu", "method", "get", "set", "set", "valu", "propertyresolv", "java:1150", "properti", "resolv", "at", "org", "apach", "wicket", "util", "lang", "propertyresolv", "properti", "resolv", "objectandgetsett", "setvalu", "object", "get", "setter", "set", "valu", "propertyresolv", "java:588", "properti", "resolv", "at", "org", "apach", "wicket", "util", "lang", "propertyresolv", "setvalu", "properti", "resolv", "set", "valu", "propertyresolv", "java:136", "properti", "resolv", "at", "propertyresolvertest", "testdirectfieldsetwithdifferenttypethangett", "properti", "resolv", "test", "test", "direct", "field", "set", "differ", "type", "than", "getter", "propertyresolvertest", "java:12", "properti", "resolv", "test", "bug", "locat", "convert", "convert", "convert", "valu", "getmethod", "getreturntyp", "get", "method", "get", "return", "type", "instead", "it", "read", "convert", "convert", "convert", "valu", "type", "testcas", "attach", "addit", "thought", "setmethod", "set", "method", "null", "type", "getmethod", "getreturntyp", "get", "method", "get", "return", "type", "thi", "realli", "confus", "we", "check", "setmethod", "set", "method", "presenc", "but", "get", "type", "getmethod", "get", "method", "luckili", "thi", "work", "as", "expect", "becaus", "methodgetandset", "findsett", "method", "get", "set", "find", "setter", "onli", "method", "same", "or", "superclass", "type", "as", "getter", "are", "return"], "B_title": "fixed MethodGetAndSet.setValue uses wrong source to determine which type to convert to when theres no setter Issue: WICKET-2624", "B_clean_title": ["fix", "methodgetandset", "setvalu", "method", "get", "set", "set", "valu", "use", "wrong", "sourc", "determin", "which", "type", "convert", "when", "there", "no", "setter", "issu", "wicket", "2624"]},
{"A_title": "calling MiniAccumuloCluster.stop multiple times fails with NPEOn the mailing list ~ctubbsii mentioned seeing some NPEs in the stderr for mvn verify.  I see one here when running mvn verify with either hadoop profile:  quote Exception in thread Thread-0 java.lang.NullPointerException at org.apache.accumulo.minicluster.MiniAccumuloCluster.stopProcessWithTimeout(MiniAccumuloCluster.java:449) at org.apache.accumulo.minicluster.MiniAccumuloCluster.stop(MiniAccumuloCluster.java:376) at org.apache.accumulo.minicluster.MiniAccumuloCluster 1.run(MiniAccumuloCluster.java:318) quote  The relevant piece of code (in 1.5.2-SNAP) is the executor.execute below  code   private int stopProcessWithTimeout(final Process proc long timeout TimeUnit unit) throws InterruptedException ExecutionException TimeoutException      FutureTask<Integer> future = new FutureTask<Integer>(new Callable<Integer>()          @Override         public Integer call() throws InterruptedException            proc.destroy();           return proc.waitFor();              );      executor.execute(future);      return future.get(timeout unit);    code  Reading through the code for stop it nulls out executor when its done. So the easy way to get an NPE is calling stop() multiple times on a MAC instance. Since we have a shutdown hook that calls stop that means that a single user invocation of stop should result in a NPE later.  Since start() doesnt allow multiple starts we probably shouldnt allow multiple stops. That would mean adding logic to the shutdown hook to check if were already stopped or making a private unguarded version of stop that allows multiple calls and using that from the hook.  criteria for closing this issue:  * MAC should document wether calling stop() multiple times is allowed * fix MAC.stop to either guard against multiple calls or handle them gracefully * find out why this only gets an NPE in one place. Do we rely on the shutdown hook everywhere?", "A_clean_title": ["call", "miniaccumuloclust", "stop", "mini", "accumulo", "cluster", "multipl", "time", "fail", "npeon", "npe", "mail", "list", "~ctubbsii", "mention", "see", "some", "npe", "np", "es", "stderr", "mvn", "verifi", "see", "one", "here", "when", "run", "mvn", "verifi", "either", "hadoop", "profil", "quot", "except", "thread", "thread", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "accumulo", "miniclust", "miniaccumuloclust", "stopprocesswithtimeout", "mini", "accumulo", "cluster", "stop", "process", "timeout", "miniaccumuloclust", "java:449", "mini", "accumulo", "cluster", "at", "org", "apach", "accumulo", "miniclust", "miniaccumuloclust", "stop", "mini", "accumulo", "cluster", "miniaccumuloclust", "java:376", "mini", "accumulo", "cluster", "at", "org", "apach", "accumulo", "miniclust", "miniaccumuloclust", "mini", "accumulo", "cluster", "run", "miniaccumuloclust", "java:318", "mini", "accumulo", "cluster", "quot", "relev", "piec", "code", "snap", "executor", "execut", "below", "code", "privat", "int", "stopprocesswithtimeout", "stop", "process", "timeout", "final", "process", "proc", "long", "timeout", "timeunit", "time", "unit", "unit", "throw", "interruptedexcept", "interrupt", "except", "executionexcept", "execut", "except", "timeoutexcept", "timeout", "except", "futuretask", "futur", "task", "integ", "futur", "new", "futuretask", "futur", "task", "integ", "new", "callabl", "integ", "overrid", "public", "integ", "call", "throw", "interruptedexcept", "interrupt", "except", "proc", "destroy", "return", "proc", "waitfor", "wait", "executor", "execut", "futur", "return", "futur", "get", "timeout", "unit", "code", "read", "through", "code", "stop", "it", "null", "out", "executor", "when", "it", "done", "so", "easi", "way", "get", "npe", "call", "stop", "multipl", "time", "mac", "instanc", "sinc", "we", "have", "shutdown", "hook", "that", "call", "stop", "that", "mean", "that", "singl", "user", "invoc", "stop", "result", "npe", "later", "sinc", "start", "doesnt", "allow", "multipl", "start", "we", "probabl", "shouldnt", "allow", "multipl", "stop", "that", "would", "mean", "ad", "logic", "shutdown", "hook", "check", "were", "alreadi", "stop", "or", "make", "privat", "unguard", "version", "stop", "that", "allow", "multipl", "call", "that", "hook", "criteria", "close", "thi", "issu", "mac", "document", "wether", "call", "stop", "multipl", "time", "allow", "fix", "mac", "stop", "either", "guard", "against", "multipl", "call", "or", "handl", "them", "grace", "find", "out", "whi", "thi", "onli", "get", "npe", "one", "place", "we", "reli", "shutdown", "hook", "everywher"], "B_title": "Guard against failure due to multiple invocations of MAC.stop", "B_clean_title": ["guard", "against", "failur", "due", "multipl", "invoc", "mac", "stop"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Early detection of Regula Falsi algorithm being stuck due to finite precision. Javadoc makes it clear that either the Pegasus or the Illinois solver should be preferred over the Regula Falsi one (due to D. Hendriks).", "B_clean_title": ["earli", "detect", "regula", "falsi", "algorithm", "be", "stuck", "due", "finit", "precis", "javadoc", "make", "it", "clear", "that", "either", "pegasu", "or", "illinoi", "solver", "prefer", "over", "regula", "falsi", "one", "due", "hendrik"]},
{"A_title": "Default sync handler property mapping does not allow constant propertiesit would be useful if the default sync handler user (and group) mapping could also handle constant properties and use given primary type and mixin type information. eg:  noformat profile/nt:primaryType=sling:Folder profile/sling:resourceType=sling/security/profile noformat", "A_clean_title": ["default", "sync", "handler", "properti", "map", "not", "allow", "constant", "propertiesit", "would", "use", "default", "sync", "handler", "user", "group", "map", "could", "also", "handl", "constant", "properti", "use", "given", "primari", "type", "mixin", "type", "inform", "eg", "noformat", "profil", "nt", "primarytype=sl", "primari", "type=sl", "folder", "profil", "sling", "resourcetype=sl", "secur", "profil", "resourc", "type=sl", "noformat"], "B_title": "Default sync handler property mapping does not allow constant properties", "B_clean_title": ["default", "sync", "handler", "properti", "map", "not", "allow", "constant", "properti"]},
{"A_title": "Exception when emitting code containing gettersNone", "A_clean_title": ["except", "when", "emit", "code", "contain", "gettersnon", "getter", "none"], "B_title": "Dont attempt to rewrite object literal get/set definitions. Fixes issue 538.", "B_clean_title": ["dont", "attempt", "rewrit", "object", "liter", "get", "set", "definit", "fix", "issu", "538"]},
{"A_title": "AbstractNumberConverter issue when used with NumberFormat#getCurrencyInstanceSummary of the discussion on users@:  There is an issue when using AbstractNumberConverter when #getNumberFormat returns NumberFormat#getCurrencyInstance() I think the problem is due to AbstractNumberConverter#parse(Object double double Locale):  if (value instanceof String)          // Convert spaces to no-break space (U+00A0) to fix problems with         // browser conversions.         // Space is not valid thousands-separator but no-br space is.         value = ((String)value).replace(  u00A0);   Which replace spaces so a string like 15 € is invalid while being parsed.  public class CurrencyConverter extends AbstractNumberConverter<Double>      private static final long serialVersionUID = 1L;      public CurrencyConverter()                @Override     protected Class<Double> getTargetType()              return Double.class;           @Override     public NumberFormat getNumberFormat(Locale locale)              return NumberFormat.getCurrencyInstance(locale);           @Override     public Double convertToObject(String value Locale locale)              locale = Locale.FRANCE;          return this.parse(value Double.MIN_VALUE Double.MAX_VALUE locale);  //        This does work: //        final NumberFormat format = this.getNumberFormat(locale); //        return this.parse(format value locale);        As Sven indicates there is (yet another) issue in Java currency formating (space as thousand separator) http://matthiaswessendorf.wordpress.com/2007/12/03/javas-numberformat-bug/ http://bugs.sun.com/view_bug.do?bug_id=4510618  So will I let you decide whether or not you wish to fix it (the space before the currency symbol).  Thanks & best regards Sebastien.", "A_clean_title": ["abstractnumberconvert", "abstract", "number", "convert", "issu", "when", "use", "numberformat", "number", "format", "getcurrencyinstancesummari", "get", "currenc", "instanc", "summari", "discuss", "user", "there", "issu", "when", "abstractnumberconvert", "abstract", "number", "convert", "when", "getnumberformat", "get", "number", "format", "return", "numberformat", "number", "format", "getcurrencyinst", "get", "currenc", "instanc", "think", "problem", "due", "abstractnumberconvert", "abstract", "number", "convert", "pars", "object", "doubl", "doubl", "local", "valu", "instanceof", "string", "convert", "space", "no", "break", "space", "u+00a0", "fix", "problem", "browser", "convers", "space", "not", "valid", "thousand", "separ", "but", "no", "br", "space", "valu", "string", "valu", "replac", "u00a0", "which", "replac", "space", "so", "string", "like", "15", "invalid", "while", "be", "pars", "public", "class", "currencyconvert", "currenc", "convert", "extend", "abstractnumberconvert", "abstract", "number", "convert", "doubl", "privat", "static", "final", "long", "serialversionuid", "serial", "version", "uid", "1l", "public", "currencyconvert", "currenc", "convert", "overrid", "protect", "class", "doubl", "gettargettyp", "get", "target", "type", "return", "doubl", "class", "overrid", "public", "numberformat", "number", "format", "getnumberformat", "get", "number", "format", "local", "local", "return", "numberformat", "getcurrencyinst", "number", "format", "get", "currenc", "instanc", "local", "overrid", "public", "doubl", "converttoobject", "convert", "object", "string", "valu", "local", "local", "local", "local", "franc", "return", "thi", "pars", "valu", "doubl", "min", "valu", "doubl", "max", "valu", "local", "thi", "work", "final", "numberformat", "number", "format", "format", "thi", "getnumberformat", "get", "number", "format", "local", "return", "thi", "pars", "format", "valu", "local", "as", "sven", "indic", "there", "yet", "anoth", "issu", "java", "currenc", "format", "space", "as", "thousand", "separ", "http", "numberformat", "wordpress", "bug", "matthiaswessendorf", "com", "2007", "12", "03", "java", "http", "sun", "bug", "bug", "com", "view", "bug", "id=4510618", "so", "will", "let", "you", "decid", "whether", "or", "not", "you", "wish", "fix", "it", "space", "befor", "currenc", "symbol", "thank", "best", "regard", "sebastien"], "B_title": "replace space with non-breaking space between digits only", "B_clean_title": ["replac", "space", "non", "break", "space", "between", "digit", "onli"]},
{"A_title": "Dont cache credentials in client-side ConnectorAuthenticationToken objects are Destroyable. However this cannot be exercised properly in the client code because the Connector immediately serializes the credentials and stores them as long as the Connector lives.  It should be possible to destroy a token after creating a Connector and thereby forcing any further RPC calls initiated by that Connector to fail to authenticate. This means that serialization on the client side to a TCredentials object needs to occur just before the RPC call.", "A_clean_title": ["dont", "cach", "credenti", "client", "side", "connectorauthenticationtoken", "connector", "authent", "token", "object", "are", "destroy", "howev", "thi", "not", "exercis", "properli", "client", "code", "becaus", "connector", "immedi", "serial", "credenti", "store", "them", "as", "long", "as", "connector", "live", "it", "possibl", "destroy", "token", "after", "creat", "connector", "therebi", "forc", "ani", "further", "rpc", "call", "initi", "by", "that", "connector", "fail", "authent", "thi", "mean", "that", "serial", "client", "side", "tcredenti", "credenti", "object", "need", "occur", "just", "befor", "rpc", "call"], "B_title": "Test Connectors and serialization with destroyed tokens", "B_clean_title": ["test", "connector", "serial", "destroy", "token"]},
{"A_title": "QueryEngine adding invalid property restriction for fulltext queryQueryEngine inserts a property restriction of is not null for any property used in fulltext constraint. For e.g. for query  noformat select * from nt:unstructured where CONTAINS(jcr:content/metadata/comment december) noformat  A property restriction would be added for jcr:content/metadata/comment. However currently due to bug in FulltextSearchImpl 1 the property name generated is comment/jcr:content/metadata.  code @Override     public void restrict(FilterImpl f)          if (propertyName != null)              if (f.getSelector().equals(selector))                  String p = propertyName;                 if (relativePath != null)                      p = PathUtils.concat(p relativePath);                                                  p = normalizePropertyName(p);                 restrictPropertyOnFilter(p f);                               f.restrictFulltextCondition(fullTextSearchExpression.currentValue().getValue(Type.STRING));      code  This happens because relativePath is passed as second param to PathUtils.concat. It should be first param  1 https://github.com/apache/jackrabbit-oak/blob/1.4/oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/FullTextSearchImpl.java#L275-L286", "A_clean_title": ["queryengin", "queri", "engin", "ad", "invalid", "properti", "restrict", "fulltext", "queryqueryengin", "queri", "queri", "engin", "insert", "properti", "restrict", "not", "null", "ani", "properti", "use", "fulltext", "constraint", "queri", "noformat", "select", "nt", "unstructur", "where", "contain", "jcr", "content", "metadata", "comment", "decemb", "noformat", "properti", "restrict", "would", "ad", "jcr", "content", "metadata", "comment", "howev", "current", "due", "bug", "fulltextsearchimpl", "fulltext", "search", "impl", "properti", "name", "gener", "comment", "jcr", "content", "metadata", "code", "overrid", "public", "void", "restrict", "filterimpl", "filter", "impl", "propertynam", "properti", "name", "null", "getselector", "get", "selector", "equal", "selector", "string", "propertynam", "properti", "name", "relativepath", "rel", "path", "null", "pathutil", "concat", "path", "util", "relativepath", "rel", "path", "normalizepropertynam", "normal", "properti", "name", "restrictpropertyonfilt", "restrict", "properti", "filter", "restrictfulltextcondit", "restrict", "fulltext", "condit", "fulltextsearchexpress", "currentvalu", "full", "text", "search", "express", "current", "valu", "getvalu", "get", "valu", "type", "string", "code", "thi", "happen", "becaus", "relativepath", "rel", "path", "pass", "as", "second", "param", "pathutil", "concat", "path", "util", "it", "first", "param", "http", "java", "github", "com", "apach", "jackrabbit", "oak", "blob", "oak", "core", "src", "main", "java", "org", "apach", "jackrabbit", "oak", "queri", "ast", "fulltextsearchimpl", "full", "text", "search", "impl", "l275", "l286"], "B_title": "QueryEngine adding invalid property restriction for fulltext query", "B_clean_title": ["queryengin", "queri", "engin", "ad", "invalid", "properti", "restrict", "fulltext", "queri"]},
{"A_title": "Method Strings.join doesnt work correctly if separator is empty.If we use an empty separator () to join strings the first character of any fragment is truncated. Es foo bar baz became ooaraz.", "A_clean_title": ["method", "string", "join", "doesnt", "work", "correctli", "separ", "empti", "we", "use", "empti", "separ", "join", "string", "first", "charact", "ani", "fragment", "truncat", "es", "foo", "bar", "baz", "becam", "ooaraz"], "B_title": "Method Strings.join doesnt work correctly if separator is empty.", "B_clean_title": ["method", "string", "join", "doesnt", "work", "correctli", "separ", "empti"]},
{"A_title": "Bug in MonotoneChain: a collinear point landing on the existing boundary should be dropped (patch)The is a bug on the code in MonotoneChain.java that attempts to handle the case of a point on the line formed by the previous last points and the last point of the chain being constructed. When `includeCollinearPoints` is false the point should be dropped entirely. In common-math 33 the point is added which in some cases can cause a `ConvergenceException` to be thrown.  In the patch below the data points are from a case that showed up in testing before we went to production.  code:java Index: src/main/java/org/apache/commons/math3/geometry/euclidean/twod/hull/MonotoneChain.java =================================================================== --- src/main/java/org/apache/commons/math3/geometry/euclidean/twod/hull/MonotoneChain.java(revision 1609491) +++ src/main/java/org/apache/commons/math3/geometry/euclidean/twod/hull/MonotoneChain.java(working copy) @@ -1608 +1608 @@                   else                       if (distanceToCurrent > distanceToLast)                           hull.remove(size - 1); +                        hull.add(point);                       -                    hull.add(point);                                    return;               else if (offset > 0)  Index: src/test/java/org/apache/commons/math3/geometry/euclidean/twod/hull/ConvexHullGenerator2DAbstractTest.java =================================================================== --- src/test/java/org/apache/commons/math3/geometry/euclidean/twod/hull/ConvexHullGenerator2DAbstractTest.java(revision 1609491) +++ src/test/java/org/apache/commons/math3/geometry/euclidean/twod/hull/ConvexHullGenerator2DAbstractTest.java(working copy) @@ -2046 +20424 @@              @Test +    public void testCollinnearPointOnExistingBoundary()  +        final Collection<Vector2D> points = new ArrayList<Vector2D>(); +        points.add(new Vector2D(7.3152 34.7472)); +        points.add(new Vector2D(6.400799999999997 34.747199999999985)); +        points.add(new Vector2D(5.486399999999997 34.7472)); +        points.add(new Vector2D(4.876799999999999 34.7472)); +        points.add(new Vector2D(4.876799999999999 34.1376)); +        points.add(new Vector2D(4.876799999999999 30.48)); +        points.add(new Vector2D(6.0959999999999965 30.48)); +        points.add(new Vector2D(6.0959999999999965 34.1376)); +        points.add(new Vector2D(7.315199999999996 34.1376)); +        points.add(new Vector2D(7.3152 30.48)); + +        final ConvexHull2D hull = generator.generate(points); +        checkConvexHull(points hull); +     + +    @Test      public void testIssue1123()             List<Vector2D> points = new ArrayList<Vector2D>(); code", "A_clean_title": ["bug", "monotonechain", "monoton", "chain", "collinear", "point", "land", "exist", "boundari", "drop", "patch", "bug", "code", "monotonechain", "java", "monoton", "chain", "that", "attempt", "handl", "case", "point", "line", "form", "by", "previou", "last", "point", "last", "point", "chain", "be", "construct", "when", "includecollinearpoint", "includ", "collinear", "point", "fals", "point", "drop", "entir", "common", "math", "33", "point", "ad", "which", "some", "case", "caus", "convergenceexcept", "converg", "except", "thrown", "patch", "below", "data", "point", "are", "case", "that", "show", "up", "test", "befor", "we", "went", "product", "code", "java", "index", "java", "src", "main", "java", "org", "apach", "common", "math3", "geometri", "euclidean", "twod", "hull", "monotonechain", "monoton", "chain", "java", "src", "main", "java", "org", "apach", "common", "math3", "geometri", "euclidean", "twod", "hull", "monotonechain", "monoton", "chain", "revis", "1609491", "java", "src", "main", "java", "org", "apach", "common", "math3", "geometri", "euclidean", "twod", "hull", "monotonechain", "monoton", "chain", "work", "copi", "1608", "+1608", "distancetocurr", "distanc", "current", "distancetolast", "distanc", "last", "hull", "remov", "size", "hull", "add", "point", "hull", "add", "point", "return", "offset", "index", "java", "src", "test", "java", "org", "apach", "common", "math3", "geometri", "euclidean", "twod", "hull", "convexhullgenerator2dabstracttest", "convex", "hull", "generator2d", "abstract", "test", "java", "src", "test", "java", "org", "apach", "common", "math3", "geometri", "euclidean", "twod", "hull", "convexhullgenerator2dabstracttest", "convex", "hull", "generator2d", "abstract", "test", "revis", "1609491", "java", "src", "test", "java", "org", "apach", "common", "math3", "geometri", "euclidean", "twod", "hull", "convexhullgenerator2dabstracttest", "convex", "hull", "generator2d", "abstract", "test", "work", "copi", "2046", "+20424", "test", "public", "void", "testcollinnearpointonexistingboundari", "test", "collinnear", "point", "exist", "boundari", "final", "collect", "vector2d", "point", "new", "arraylist", "array", "list", "vector2d", "point", "add", "new", "vector2d", "3152", "34", "7472", "point", "add", "new", "vector2d", "400799999999997", "34", "747199999999985", "point", "add", "new", "vector2d", "486399999999997", "34", "7472", "point", "add", "new", "vector2d", "876799999999999", "34", "7472", "point", "add", "new", "vector2d", "876799999999999", "34", "1376", "point", "add", "new", "vector2d", "876799999999999", "30", "48", "point", "add", "new", "vector2d", "0959999999999965", "30", "48", "point", "add", "new", "vector2d", "0959999999999965", "34", "1376", "point", "add", "new", "vector2d", "315199999999996", "34", "1376", "point", "add", "new", "vector2d", "3152", "30", "48", "final", "convexhull2d", "convex", "hull2d", "hull", "gener", "gener", "point", "checkconvexhul", "check", "convex", "hull", "point", "hull", "test", "public", "void", "testissue1123", "test", "issue1123", "list", "vector2d", "point", "new", "arraylist", "array", "list", "vector2d", "code"], "B_title": "Fix MonotoneChain algorithm in case of collinear hull points. Thanks to Guillaume Marceau.", "B_clean_title": ["fix", "monotonechain", "monoton", "chain", "algorithm", "case", "collinear", "hull", "point", "thank", "guillaum", "marceau"]},
{"A_title": "Bug on withLaterOffsetAtOverlap methodOn the last two brackets we can see that withLaterOffsetAtOverlap is not undoing withEarlierOffsetAtOverlap as it should ( and not even working at all ).", "A_clean_title": ["bug", "withlateroffsetatoverlap", "later", "offset", "at", "overlap", "methodon", "method", "last", "two", "bracket", "we", "see", "that", "withlateroffsetatoverlap", "later", "offset", "at", "overlap", "not", "undo", "withearlieroffsetatoverlap", "earlier", "offset", "at", "overlap", "as", "it", "not", "even", "work", "at", "all"], "B_title": "Fix time zone later/earlier offset methods in Western hemisphere 3476684", "B_clean_title": ["fix", "time", "zone", "later", "earlier", "offset", "method", "western", "hemispher", "3476684"]},
{"A_title": "Jackson Deserializer security vulnerability via default typing (CVE-2017-7525)I have send email to  info@fasterxml.com", "A_clean_title": ["jackson", "deseri", "secur", "vulner", "via", "default", "type", "cve", "2017", "7525", "have", "send", "email", "info", "fasterxml", "com"], "B_title": "Fix #1599 for 2.7(.10)", "B_clean_title": ["fix", "1599", "10"]},
{"A_title": "Brent solver doesnt throw IllegalArgumentException when initial guess has the wrong signJavadoc for public double solve(final UnivariateRealFunction f final double min final double max final double initial) claims that if the values of the function at the three points have the same sign an IllegalArgumentException is thrown. This case isnt even checked.", "A_clean_title": ["brent", "solver", "doesnt", "throw", "illegalargumentexcept", "illeg", "argument", "except", "when", "initi", "guess", "ha", "wrong", "signjavadoc", "sign", "javadoc", "public", "doubl", "solv", "final", "univariaterealfunct", "univari", "real", "function", "final", "doubl", "min", "final", "doubl", "max", "final", "doubl", "initi", "claim", "that", "valu", "function", "at", "three", "point", "have", "same", "sign", "illegalargumentexcept", "illeg", "argument", "except", "thrown", "thi", "case", "isnt", "even", "check"], "B_title": "Fixed a missing bracketing check of initial interval in Brent solver JIRA: MATH-343", "B_clean_title": ["fix", "miss", "bracket", "check", "initi", "interv", "brent", "solver", "jira", "math", "343"]},
{"A_title": "importdirectory failing on split tablebulk import for the wikisearch example isnt working properly: files are not being assigned to partitions if there are splits.", "A_clean_title": ["importdirectori", "fail", "split", "tablebulk", "import", "wikisearch", "exampl", "isnt", "work", "properli", "file", "are", "not", "be", "assign", "partit", "there", "are", "split"], "B_title": "fix index search", "B_clean_title": ["fix", "index", "search"]},
{"A_title": "EntityInstantiators deallocate params required for instantiation of parent object DATACMNS-1175opened and commented Fetching nested document from MongoDB into Kotlin data class structure will sometimes result in NullPointerException. This is caused by  DefaultingKotlinClassInstantiatorAdapter.createInstance(..) calling ClassGeneratingEntityInstantiator.deallocateArguments(..) method cleaning up the shared params array. Doing this while instantiating a child object will clean up all previously prepared arguments for parents constructor and thus causing NPEs on non-null parameters. Note that everything was fine while using version of Spring Data bundled with Spring Boot 2.0.0.M3    Affects: 2.0 RC3 (Kay)  Referenced from: pull request #247  and commits", "A_clean_title": ["entityinstanti", "entiti", "instanti", "dealloc", "param", "requir", "instanti", "parent", "object", "datacmn", "1175open", "comment", "fetch", "nest", "document", "mongodb", "mongo", "db", "into", "kotlin", "data", "class", "structur", "will", "sometim", "result", "nullpointerexcept", "null", "pointer", "except", "thi", "caus", "by", "defaultingkotlinclassinstantiatoradapt", "createinst", "default", "kotlin", "class", "instanti", "adapt", "creat", "instanc", "call", "classgeneratingentityinstanti", "deallocateargu", "class", "gener", "entiti", "instanti", "dealloc", "argument", "method", "clean", "up", "share", "param", "array", "do", "thi", "while", "instanti", "child", "object", "will", "clean", "up", "all", "previous", "prepar", "argument", "parent", "constructor", "thu", "caus", "npe", "np", "es", "non", "null", "paramet", "note", "that", "everyth", "wa", "fine", "while", "version", "spring", "data", "bundl", "spring", "boot", "m3", "affect", "rc3", "kay", "referenc", "pull", "request", "247", "commit"], "B_title": "DATACMNS-1175 - Remove argument array caching from EntityInstantiators.  We no longer cache argument arrays in our EntityInstantiators to prevent changes to shared mutable state caused by reentrant calls.  Previously a re-entrant call requesting an argument array of the same size as a previous call in the call stack reused the same array instance. Changes to this shared mutable state by multiple invocations caused an invalid state rendering wrong parameters for object instantiation. Removing the caching and only reusing an empty array for zero-arg constructors is the only safe approach for now.  Re-instantiation of object allocations results in a higher GC pressure but guarantee side effect-free instantiation and should be on-par with previous versions performance profile.  Original pull request: #247.", "B_clean_title": ["datacmn", "1175", "remov", "argument", "array", "cach", "entityinstanti", "entiti", "instanti", "we", "no", "longer", "cach", "argument", "array", "our", "entityinstanti", "entiti", "instanti", "prevent", "chang", "share", "mutabl", "state", "caus", "by", "reentrant", "call", "previous", "re", "entrant", "call", "request", "argument", "array", "same", "size", "as", "previou", "call", "call", "stack", "reus", "same", "array", "instanc", "chang", "thi", "share", "mutabl", "state", "by", "multipl", "invoc", "caus", "invalid", "state", "render", "wrong", "paramet", "object", "instanti", "remov", "cach", "onli", "reus", "empti", "array", "zero", "arg", "constructor", "onli", "safe", "approach", "now", "re", "instanti", "object", "alloc", "result", "higher", "gc", "pressur", "but", "guarante", "side", "effect", "free", "instanti", "par", "previou", "version", "perform", "profil", "origin", "pull", "request", "247"]},
{"A_title": "Persist fails on entity without id and version field if @EnableAuditing DATACMNS-957opened and commented Follow domain should be persist:   It works as long as auditing is turned off. After putting  @EnableAuditing to application follows exception is thrown:   Description: If auditing is enabled those steps are executed:    Determine strategy to fill auditing fields  Find fields that should be filled via auditing  Fill found fields  If strategy cant be determined (because id and version is not available in domain) exception is thrown and object isnt persisted.  This exception is also thrown if you dont have any fields in model that are filled via auditing.  There is no need to throw this exception if no fields are filled via auditing. Some code to make it clear:     Ive patch for this ticket.  PR: #189   Issue Links:     Referenced from: pull request #189  Backported to:  1.13 GA (Ingalls)  1.12.7 (Hopper SR7)  1.11.7 (Gosling SR7)", "A_clean_title": ["persist", "fail", "entiti", "without", "id", "version", "field", "enableaudit", "enabl", "audit", "datacmn", "957open", "comment", "follow", "domain", "persist", "it", "work", "as", "long", "as", "audit", "turn", "off", "after", "put", "enableaudit", "enabl", "audit", "applic", "follow", "except", "thrown", "descript", "audit", "enabl", "those", "step", "are", "execut", "determin", "strategi", "fill", "audit", "field", "find", "field", "that", "fill", "via", "audit", "fill", "found", "field", "strategi", "cant", "determin", "becaus", "id", "version", "not", "avail", "domain", "except", "thrown", "object", "isnt", "persist", "thi", "except", "also", "thrown", "you", "dont", "have", "ani", "field", "model", "that", "are", "fill", "via", "audit", "there", "no", "need", "throw", "thi", "except", "no", "field", "are", "fill", "via", "audit", "some", "code", "make", "it", "clear", "ive", "patch", "thi", "ticket", "pr", "189", "issu", "link", "referenc", "pull", "request", "189", "backport", "13", "ga", "ingal", "12", "hopper", "sr7", "11", "gosl", "sr7"], "B_title": "DATACMNS-957 - AuditingHandler now works with entities without an identifier.  Entities without an identifier previously an exception because the IsNewStrategyFactory wasnt able to determine a strategy even if there was no auditing to be applied in the first place.  We now eagerly check for auditability and skip the lookup for an IsNewStrategy completely in case that check returns false.  Related pull request: #189.", "B_clean_title": ["datacmn", "957", "auditinghandl", "audit", "handler", "now", "work", "entiti", "without", "identifi", "entiti", "without", "identifi", "previous", "except", "becaus", "isnewstrategyfactori", "new", "strategi", "factori", "wasnt", "abl", "determin", "strategi", "even", "there", "wa", "no", "audit", "appli", "first", "place", "we", "now", "eagerli", "check", "audit", "skip", "lookup", "isnewstrategi", "new", "strategi", "complet", "case", "that", "check", "return", "fals", "relat", "pull", "request", "189"]},
{"A_title": "TreeImpl#*Location: unable retrieve child location if access to parent is deniedas a consequence of OAK-709 we now have an issue with the way SessionDelegate and Root#getLocation access a node in the hierarchy which has an ancestor which is not accessible.  specifically RootImpl#getLocation will be served a NullLocation for the first ancestor which is not accessible and consequently any accessible child node cannot be accessed.  in order to reproduce the issue you may:  - change AccessControlConfigurationImpl to use PermissionProviderImpl instead   of the tmp solution - and run o.a.j.oak.jcr.security.authorization.ReadTest#testReadDenied", "A_clean_title": ["treeimpl", "tree", "impl", "locat", "unabl", "retriev", "child", "locat", "access", "parent", "denieda", "consequ", "oak", "709", "we", "now", "have", "issu", "way", "sessiondeleg", "session", "deleg", "root", "getloc", "get", "locat", "access", "node", "hierarchi", "which", "ha", "ancestor", "which", "not", "access", "specif", "rootimpl", "root", "impl", "getloc", "get", "locat", "will", "serv", "nullloc", "null", "locat", "first", "ancestor", "which", "not", "access", "consequ", "ani", "access", "child", "node", "not", "access", "order", "reproduc", "issu", "you", "may", "chang", "accesscontrolconfigurationimpl", "access", "control", "configur", "impl", "use", "permissionproviderimpl", "permiss", "provid", "impl", "instead", "tmp", "solut", "run", "oak", "jcr", "secur", "author", "readtest", "read", "test", "testreaddeni", "test", "read", "deni"], "B_title": "TreeImpl#*Location: unable retrieve child location if access to parent is denied tentative fix", "B_clean_title": ["treeimpl", "tree", "impl", "locat", "unabl", "retriev", "child", "locat", "access", "parent", "deni", "tent", "fix"]},
{"A_title": "Behaviors#internalAdd(Behavior) erroneously gets id for stateless behaviorssee http://markmail.org/thread/jtd4zn527r343jbm", "A_clean_title": ["behavior", "internaladd", "intern", "add", "behavior", "erron", "get", "id", "stateless", "behaviorsse", "http", "markmail", "org", "thread", "jtd4zn527r343jbm"], "B_title": "Behaviors#internalAdd(Behavior) erroneously gets id for stateless behaviors", "B_clean_title": ["behavior", "internaladd", "intern", "add", "behavior", "erron", "get", "id", "stateless", "behavior"]},
{"A_title": "Cannot cancel failing/restarting streaming job from the command lineI cannot seem to be able to cancel a failing/restarting job from the command line client. The job cannot be rescheduled so it keeps failing:  The exception I get: 13:58:11240 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Status of job 0c895d22c632de5dfe16c42a9ba818d5 (player-id) changed to RESTARTING. 13:58:25234 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Trying to cancel job with ID 0c895d22c632de5dfe16c42a9ba818d5. 13:58:25561 WARN  akka.remote.ReliableDeliverySupervisor                        - Association with remote system akka.tcp://flink@127.0.0.1:42012 has failed address is now gated for 5000 ms. Reason is: Disassociated.", "A_clean_title": ["not", "cancel", "fail", "restart", "stream", "job", "command", "linei", "line", "not", "seem", "abl", "cancel", "fail", "restart", "job", "command", "line", "client", "job", "not", "reschedul", "so", "it", "keep", "fail", "except", "get", "13:58:11240", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "statu", "job", "0c895d22c632de5dfe16c42a9ba818d5", "player", "id", "chang", "restart", "13:58:25234", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "tri", "cancel", "job", "id", "0c895d22c632de5dfe16c42a9ba818d5", "13:58:25561", "warn", "akka", "remot", "reliabledeliverysupervisor", "reliabl", "deliveri", "supervisor", "associ", "remot", "system", "akka", "tcp", "flink", "127", "1:42012", "ha", "fail", "address", "now", "gate", "5000", "ms", "reason", "disassoci"], "B_title": "runtime Fix cancel during restart", "B_clean_title": ["runtim", "fix", "cancel", "dure", "restart"]},
{"A_title": "IndexPlanner returning plan for queries involving jcr:scoreConsider a query like   noformat /jcr:root//element(* cq:Taggable) (@cq:tags = geometrixx-outdoors:activity/biking or @cq:tags = /etc/tags/geometrixx-outdoors/activity/biking)  order by @jcr:score descending  noformat  And a seemingly non related index like  noformat /oak:index/assetType   ...   - type = lucene   + indexRules     + nt:base       + properties         + assetType           - propertyIndex = true           - name = assetType noformat  Then currently IndexPlanner would return a plan because even when it cannot evaluate any of property restrictions because it thinks it can sort on jcr:score. This later results in an exception like  noformat 14.01.2015 16:16:35.866 *ERROR* 0:0:0:0:0:0:0:1 1421248595863 POST /bin/tagcommand HTTP/1.1 org.apache.sling.engine.impl.SlingRequestProcessorImpl service: Uncaught Throwable java.lang.IllegalStateException: No query created for filter Filter(query=select jcr:path jcr:score * from cq:Taggable as a where cq:tags in(geometrixx-outdoors:activity/swimming /etc/tags/geometrixx-outdoors/activity/swimming) and isdescendantnode(a /) order by jcr:score desc /* xpath: /jcr:root//element(* cq:Taggable) (@cq:tags = geometrixx-outdoors:activity/swimming or @cq:tags = /etc/tags/geometrixx-outdoors/activity/swimming)  order by @jcr:score descending */ path=//* property=cq:tags=in(geometrixx-outdoors:activity/swimming /etc/tags/geometrixx-outdoors/activity/swimming)) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex.getQuery(LucenePropertyIndex.java:505) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex.access 200(LucenePropertyIndex.java:158) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex 1.loadDocs(LucenePropertyIndex.java:303) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex 1.computeNext(LucenePropertyIndex.java:261) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex 1.computeNext(LucenePropertyIndex.java:253) at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143) noformat", "A_clean_title": ["indexplann", "index", "planner", "return", "plan", "queri", "involv", "jcr", "scoreconsid", "score", "consid", "queri", "like", "noformat", "jcr", "root", "element", "cq", "taggabl", "cq", "tag", "geometrixx", "outdoor", "activ", "bike", "or", "cq", "tag", "etc", "tag", "geometrixx", "outdoor", "activ", "bike", "order", "by", "jcr", "score", "descend", "noformat", "seemingli", "non", "relat", "index", "like", "noformat", "oak", "index", "assettyp", "asset", "type", "type", "lucen", "indexrul", "index", "rule", "nt", "base", "properti", "assettyp", "asset", "type", "propertyindex", "properti", "index", "true", "name", "assettyp", "asset", "type", "noformat", "then", "current", "indexplann", "index", "planner", "would", "return", "plan", "becaus", "even", "when", "it", "not", "evalu", "ani", "properti", "restrict", "becaus", "it", "think", "it", "sort", "jcr", "score", "thi", "later", "result", "except", "like", "noformat", "14", "01", "2015", "16:16:35", "866", "error", "0:0:0:0:0:0:0:1", "1421248595863", "post", "bin", "tagcommand", "http", "org", "apach", "sling", "engin", "impl", "slingrequestprocessorimpl", "sling", "request", "processor", "impl", "servic", "uncaught", "throwabl", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "no", "queri", "creat", "filter", "filter", "query=select", "jcr", "path", "jcr", "score", "cq", "taggabl", "as", "where", "cq", "tag", "geometrixx", "outdoor", "activ", "swim", "etc", "tag", "geometrixx", "outdoor", "activ", "swim", "isdescendantnod", "order", "by", "jcr", "score", "desc", "xpath", "jcr", "root", "element", "cq", "taggabl", "cq", "tag", "geometrixx", "outdoor", "activ", "swim", "or", "cq", "tag", "etc", "tag", "geometrixx", "outdoor", "activ", "swim", "order", "by", "jcr", "score", "descend", "path=", "property=cq", "tags=in", "geometrixx", "outdoor", "activ", "swim", "etc", "tag", "geometrixx", "outdoor", "activ", "swim", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "getqueri", "lucen", "properti", "index", "get", "queri", "lucenepropertyindex", "java:505", "lucen", "properti", "index", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "access", "lucen", "properti", "index", "200", "lucenepropertyindex", "java:158", "lucen", "properti", "index", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "lucen", "properti", "index", "loaddoc", "load", "doc", "lucenepropertyindex", "java:303", "lucen", "properti", "index", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "lucen", "properti", "index", "computenext", "comput", "next", "lucenepropertyindex", "java:261", "lucen", "properti", "index", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "lucen", "properti", "index", "computenext", "comput", "next", "lucenepropertyindex", "java:253", "lucen", "properti", "index", "at", "com", "googl", "common", "collect", "abstractiter", "trytocomputenext", "abstract", "iter", "tri", "comput", "next", "abstractiter", "java:143", "abstract", "iter", "noformat"], "B_title": "- IndexPlanner returning plan for queries involving jcr:score", "B_clean_title": ["indexplann", "index", "planner", "return", "plan", "queri", "involv", "jcr", "score"]},
{"A_title": "ConstraintViolationException seen with multiple Oak/Mongo with ConcurrentCreateNodesTestWhile running ConcurrentCreateNodesTest with 5 instances writing to same Mongo instance following exception is seen  noformat Exception in thread Background job org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest Writer@3f56e5ed java.lang.RuntimeException: javax.jcr.nodetype.ConstraintViolationException: OakConstraint0001: /: The primary type rep:root does not exist     at org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest Writer.run(ConcurrentCreateNodesTest.java:111)     at org.apache.jackrabbit.oak.benchmark.AbstractTest 1.run(AbstractTest.java:481) Caused by: javax.jcr.nodetype.ConstraintViolationException: OakConstraint0001: /: The primary type rep:root does not exist     at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:225)     at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:212)     at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.newRepositoryException(SessionDelegate.java:679)     at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:553)     at org.apache.jackrabbit.oak.jcr.session.SessionImpl 8.perform(SessionImpl.java:417)     at org.apache.jackrabbit.oak.jcr.session.SessionImpl 8.perform(SessionImpl.java:414)     at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:308)     at org.apache.jackrabbit.oak.jcr.session.SessionImpl.perform(SessionImpl.java:127)     at org.apache.jackrabbit.oak.jcr.session.SessionImpl.save(SessionImpl.java:414)     at org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest Writer.run(ConcurrentCreateNodesTest.java:100)     ... 1 more Caused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakConstraint0001: /: The primary type rep:root does not exist     at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.constraintViolation(TypeEditor.java:150)     at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.getEffectiveType(TypeEditor.java:286)     at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.<init>(TypeEditor.java:101)     at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditorProvider.getRootEditor(TypeEditorProvider.java:85)     at org.apache.jackrabbit.oak.spi.commit.CompositeEditorProvider.getRootEditor(CompositeEditorProvider.java:80)     at org.apache.jackrabbit.oak.spi.commit.EditorHook.processCommit(EditorHook.java:53)     at org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:60)     at org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:60)     at org.apache.jackrabbit.oak.spi.state.AbstractNodeStoreBranch InMemory.merge(AbstractNodeStoreBranch.java:498)     at org.apache.jackrabbit.oak.spi.state.AbstractNodeStoreBranch.merge(AbstractNodeStoreBranch.java:300)     at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge(DocumentNodeStoreBranch.java:129)     at org.apache.jackrabbit.oak.plugins.document.DocumentRootBuilder.merge(DocumentRootBuilder.java:159)     at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.merge(DocumentNodeStore.java:1275)     at org.apache.jackrabbit.oak.core.MutableRoot.commit(MutableRoot.java:247)     at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.commit(SessionDelegate.java:405)     at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:551)     ... 7 more noformat  This has been reported by ~rogoz", "A_clean_title": ["constraintviolationexcept", "constraint", "violat", "except", "seen", "multipl", "oak", "mongo", "concurrentcreatenodestestwhil", "concurr", "creat", "node", "test", "while", "run", "concurrentcreatenodestest", "concurr", "creat", "node", "test", "instanc", "write", "same", "mongo", "instanc", "follow", "except", "seen", "noformat", "except", "thread", "background", "job", "org", "apach", "jackrabbit", "oak", "benchmark", "concurrentcreatenodestest", "concurr", "creat", "node", "test", "writer", "3f56e5e", "java", "lang", "runtimeexcept", "runtim", "except", "javax", "jcr", "nodetyp", "constraintviolationexcept", "constraint", "violat", "except", "oakconstraint0001", "oak", "constraint0001", "primari", "type", "rep", "root", "not", "exist", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "concurrentcreatenodestest", "concurr", "creat", "node", "test", "writer", "run", "concurrentcreatenodestest", "java:111", "concurr", "creat", "node", "test", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "abstracttest", "abstract", "test", "run", "abstracttest", "java:481", "abstract", "test", "caus", "by", "javax", "jcr", "nodetyp", "constraintviolationexcept", "constraint", "violat", "except", "oakconstraint0001", "oak", "constraint0001", "primari", "type", "rep", "root", "not", "exist", "at", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "asrepositoryexcept", "commit", "fail", "except", "as", "repositori", "except", "commitfailedexcept", "java:225", "commit", "fail", "except", "at", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "asrepositoryexcept", "commit", "fail", "except", "as", "repositori", "except", "commitfailedexcept", "java:212", "commit", "fail", "except", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "newrepositoryexcept", "session", "deleg", "new", "repositori", "except", "sessiondeleg", "java:679", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:553", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "session", "impl", "perform", "sessionimpl", "java:417", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "session", "impl", "perform", "sessionimpl", "java:414", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "perform", "session", "deleg", "sessiondeleg", "java:308", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "perform", "session", "impl", "sessionimpl", "java:127", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "save", "session", "impl", "sessionimpl", "java:414", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "concurrentcreatenodestest", "concurr", "creat", "node", "test", "writer", "run", "concurrentcreatenodestest", "java:100", "concurr", "creat", "node", "test", "more", "caus", "by", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "commit", "fail", "except", "oakconstraint0001", "oak", "constraint0001", "primari", "type", "rep", "root", "not", "exist", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typeeditor", "constraintviol", "type", "editor", "constraint", "violat", "typeeditor", "java:150", "type", "editor", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typeeditor", "geteffectivetyp", "type", "editor", "get", "effect", "type", "typeeditor", "java:286", "type", "editor", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typeeditor", "type", "editor", "init", "typeeditor", "java:101", "type", "editor", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typeeditorprovid", "getrooteditor", "type", "editor", "provid", "get", "root", "editor", "typeeditorprovid", "java:85", "type", "editor", "provid", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositeeditorprovid", "getrooteditor", "composit", "editor", "provid", "get", "root", "editor", "compositeeditorprovid", "java:80", "composit", "editor", "provid", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "editorhook", "processcommit", "editor", "hook", "process", "commit", "editorhook", "java:53", "editor", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositehook", "processcommit", "composit", "hook", "process", "commit", "compositehook", "java:60", "composit", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositehook", "processcommit", "composit", "hook", "process", "commit", "compositehook", "java:60", "composit", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "abstractnodestorebranch", "abstract", "node", "store", "branch", "inmemori", "merg", "memori", "abstractnodestorebranch", "java:498", "abstract", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "abstractnodestorebranch", "merg", "abstract", "node", "store", "branch", "abstractnodestorebranch", "java:300", "abstract", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "merg", "document", "node", "store", "branch", "documentnodestorebranch", "java:129", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentrootbuild", "merg", "document", "root", "builder", "documentrootbuild", "java:159", "document", "root", "builder", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "merg", "document", "node", "store", "documentnodestor", "java:1275", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "core", "mutableroot", "commit", "mutabl", "root", "mutableroot", "java:247", "mutabl", "root", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "commit", "session", "deleg", "sessiondeleg", "java:405", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:551", "session", "deleg", "more", "noformat", "thi", "ha", "been", "report", "by", "~rogoz"], "B_title": "ConstraintViolationException seen with multiple Oak/Mongo with ConcurrentCreateNodesTest", "B_clean_title": ["constraintviolationexcept", "constraint", "violat", "except", "seen", "multipl", "oak", "mongo", "concurrentcreatenodestest", "concurr", "creat", "node", "test"]},
{"A_title": "Any empty url-parameter will make wicket 1.5 crashAdding an empty parameter to the query string will make wicket crash.  http://www.example.com/?oneParam&   How to reproduce in test:  PageParameters params = new PageParameters(); params.set(); params.getAllNamed();   Cause: Wicket accepts empty parameters but when encoding the url for a rendered page it will call params.getAllNamed().  params.getAllNamed() instantiates new NamedPairs which calls Args.notEmpty() on the key during instantiation causing the application to crash.   The NamedPair constructor should probably allow empty string as a key and call Args.notNull() on the key in stead.", "A_clean_title": ["ani", "empti", "url", "paramet", "will", "make", "wicket", "crashad", "crash", "ad", "empti", "paramet", "queri", "string", "will", "make", "wicket", "crash", "http", "exampl", "www", "com", "oneparam", "one", "param", "how", "reproduc", "test", "pageparamet", "page", "paramet", "param", "new", "pageparamet", "page", "paramet", "param", "set", "param", "getallnam", "get", "all", "name", "caus", "wicket", "accept", "empti", "paramet", "but", "when", "encod", "url", "render", "page", "it", "will", "call", "param", "getallnam", "get", "all", "name", "param", "getallnam", "get", "all", "name", "instanti", "new", "namedpair", "name", "pair", "which", "call", "arg", "notempti", "not", "empti", "key", "dure", "instanti", "caus", "applic", "crash", "namedpair", "name", "pair", "constructor", "probabl", "allow", "empti", "string", "as", "key", "call", "arg", "notnul", "not", "null", "key", "stead"], "B_title": "Any empty url-parameter will make wicket 1.5 crash", "B_clean_title": ["ani", "empti", "url", "paramet", "will", "make", "wicket", "crash"]},
{"A_title": "YamlGenerator closes the target stream when configured not toBug description  YamlGenerator closes the target stream when configured not to.  Versions used  jackson-dataformat-yaml 2.9.2  jackson-databind 2.9.6 Expected result  The target stream not closed when writing a value. No output when running reproduction script/program.  Actual result  The target stream is closed when using the YamlGenerator with the following output when running the reproduction script/program.   Steps to reproduce", "A_clean_title": ["yamlgener", "yaml", "gener", "close", "target", "stream", "when", "configur", "not", "tobug", "bug", "descript", "yamlgener", "yaml", "gener", "close", "target", "stream", "when", "configur", "not", "version", "use", "jackson", "dataformat", "yaml", "jackson", "databind", "expect", "result", "target", "stream", "not", "close", "when", "write", "valu", "no", "output", "when", "run", "reproduct", "script", "program", "actual", "result", "target", "stream", "close", "when", "yamlgener", "yaml", "gener", "follow", "output", "when", "run", "reproduct", "script", "program", "step", "reproduc"], "B_title": "Merge pull request #112 from vboulaye/closed-stream-when-autoclose-disabled  fix #99 do not close stream when autoclose is disabled in yaml generator/parser", "B_clean_title": ["merg", "pull", "request", "112", "stream", "when", "autoclos", "disabl", "vboulay", "close", "fix", "99", "not", "close", "stream", "when", "autoclos", "disabl", "yaml", "gener", "parser"]},
{"A_title": "Wicket doesnt encrypt links and Ajax URLs for mounted pages when CryptoMapper is usedURL encryption does not work in Wicket links and Ajax URLs.  For links the URL appears unencrypted in the href attribute value and is only later forwarded to the encrypted URL using a 302 response.  I am uploading a quickstart.", "A_clean_title": ["wicket", "doesnt", "encrypt", "link", "ajax", "url", "ur", "ls", "mount", "page", "when", "cryptomapp", "crypto", "mapper", "usedurl", "use", "url", "encrypt", "not", "work", "wicket", "link", "ajax", "url", "ur", "ls", "link", "url", "appear", "unencrypt", "href", "attribut", "valu", "onli", "later", "forward", "encrypt", "url", "302", "respons", "am", "upload", "quickstart"], "B_title": "Wicket doesnt encrypt links and Ajax URLs when CryptoMapper is used", "B_clean_title": ["wicket", "doesnt", "encrypt", "link", "ajax", "url", "ur", "ls", "when", "cryptomapp", "crypto", "mapper", "use"]},
{"A_title": "NodeDocument _modified may go back in timeIn a cluster with multiple DocumentMK instances the _modified field of a NodeDocument may go back in time. This will result in incorrect diff calculations when the DocumentNodeStore uses the _modified field to find changed nodes for a given revision range.", "A_clean_title": ["nodedocu", "node", "document", "modifi", "may", "go", "back", "timein", "time", "cluster", "multipl", "documentmk", "document", "mk", "instanc", "modifi", "field", "nodedocu", "node", "document", "may", "go", "back", "time", "thi", "will", "result", "incorrect", "diff", "calcul", "when", "documentnodestor", "document", "node", "store", "use", "modifi", "field", "find", "chang", "node", "given", "revis", "rang"], "B_title": "NodeDocument _modified may go back in time", "B_clean_title": ["nodedocu", "node", "document", "modifi", "may", "go", "back", "time"]},
{"A_title": "Watermark triggered operators cannot progress with cyclic flowsThe problem is that we can easily create a cyclic watermark (time) dependency in the stream graph which will result in a deadlock for watermark triggered operators such as  the `WindowOperator`.  A solution to this could be to emit a Long.MAX_VALUE watermark from the iteration sources.", "A_clean_title": ["watermark", "trigger", "oper", "not", "progress", "cyclic", "flowsth", "flow", "problem", "that", "we", "easili", "creat", "cyclic", "watermark", "time", "depend", "stream", "graph", "which", "will", "result", "deadlock", "watermark", "trigger", "oper", "such", "as", "windowoper", "window", "oper", "solut", "thi", "could", "emit", "long", "max", "valu", "watermark", "iter", "sourc"], "B_title": "streaming Remove cyclic watermark dependencies for iterations", "B_clean_title": ["stream", "remov", "cyclic", "watermark", "depend", "iter"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test: code @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);  code fails with noformat illegal state: maximal count (100) exceeded: evaluations noformat  Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "code", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "code", "fail", "noformat", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "noformat", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Early detection of Regula Falsi algorithm being stuck due to finite precision. Javadoc makes it clear that either the Pegasus or the Illinois solver should be preferred over the Regula Falsi one (due to D. Hendriks).", "B_clean_title": ["earli", "detect", "regula", "falsi", "algorithm", "be", "stuck", "due", "finit", "precis", "javadoc", "make", "it", "clear", "that", "either", "pegasu", "or", "illinoi", "solver", "prefer", "over", "regula", "falsi", "one", "due", "hendrik"]},
{"A_title": "Property value converion ignores reisdual property definitionAssume following node type which a property defined with type and a residual unnamed property also defined  noformat oak:foo  - stringProp (String)  - * (undefined) noformat  For such node type if a property stringProp is being set with a binary value then Oak converts it into a String property thereby causing binary stream to change. In JR2 conversion would not happen as conversion logic treats setting (stringPropBINARY) as a residual property", "A_clean_title": ["properti", "valu", "converion", "ignor", "reisdual", "properti", "definitionassum", "definit", "assum", "follow", "node", "type", "which", "properti", "defin", "type", "residu", "unnam", "properti", "also", "defin", "noformat", "oak", "foo", "stringprop", "string", "prop", "string", "undefin", "noformat", "such", "node", "type", "properti", "stringprop", "string", "prop", "be", "set", "binari", "valu", "then", "oak", "convert", "it", "into", "string", "properti", "therebi", "caus", "binari", "stream", "chang", "jr2", "convers", "would", "not", "happen", "as", "convers", "logic", "treat", "set", "stringpropbinari", "string", "prop", "binari", "as", "residu", "properti"], "B_title": "Property value converion ignores reisdual property definition", "B_clean_title": ["properti", "valu", "converion", "ignor", "reisdual", "properti", "definit"]},
{"A_title": "nextExponential parameter check bug - patch suppliedIndex: src/main/java/org/apache/commons/math/random/RandomDataImpl.java =================================================================== --- src/main/java/org/apache/commons/math/random/RandomDataImpl.java(revision 830102) +++ src/main/java/org/apache/commons/math/random/RandomDataImpl.java(working copy) @@ -4627 +4627 @@       * @return the random Exponential value       */      public double nextExponential(double mean)  -        if (mean < 0.0)  +        if (mean <= 0.0)               throw MathRuntimeException.createIllegalArgumentException(                    mean must be positive (0) mean);", "A_clean_title": ["nextexponenti", "next", "exponenti", "paramet", "check", "bug", "patch", "suppliedindex", "suppli", "index", "java", "src", "main", "java", "org", "apach", "common", "math", "random", "randomdataimpl", "random", "data", "impl", "java", "src", "main", "java", "org", "apach", "common", "math", "random", "randomdataimpl", "random", "data", "impl", "revis", "830102", "java", "src", "main", "java", "org", "apach", "common", "math", "random", "randomdataimpl", "random", "data", "impl", "work", "copi", "4627", "+4627", "return", "random", "exponenti", "valu", "public", "doubl", "nextexponenti", "next", "exponenti", "doubl", "mean", "mean", "mean", "throw", "mathruntimeexcept", "createillegalargumentexcept", "math", "runtim", "except", "creat", "illeg", "argument", "except", "mean", "must", "posit", "mean"], "B_title": "Fixed parameter test in RandomDataImpl#nextExponential. JIRA: MATH-309.", "B_clean_title": ["fix", "paramet", "test", "randomdataimpl", "random", "data", "impl", "nextexponenti", "next", "exponenti", "jira", "math", "309"]},
{"A_title": "Crash on the web closure compilerNone", "A_clean_title": ["crash", "web", "closur", "compilernon", "compil", "none"], "B_title": "SmartNamePass shouldnt record assignment dependencies if the rhs is a call. The rhs is used by the context so we dont want it removed if the lhs isnt used.", "B_clean_title": ["smartnamepass", "smart", "name", "pass", "shouldnt", "record", "assign", "depend", "rh", "call", "rh", "use", "by", "context", "so", "we", "dont", "want", "it", "remov", "lh", "isnt", "use"]},
{"A_title": "NodeDocument.getNodeAtRevision() may read too many revisionsThis is a regression introduced by OAK-1972.  The revision returned with the value may be different from the revision of the change when the change was first committed to a branch and later merged. In this case the value will return the merge revision. The check in getNodeAtRevision() introduced with OAK-1972 then assumes there may be more recent changes in a previous document and starts to scan the revision history. This scan depends on the number of changes that have been applied on the document since the most recent change on the property in question.", "A_clean_title": ["nodedocu", "getnodeatrevis", "node", "document", "get", "node", "at", "revis", "may", "read", "too", "mani", "revisionsthi", "revis", "thi", "regress", "introduc", "by", "oak", "1972", "revis", "return", "valu", "may", "differ", "revis", "chang", "when", "chang", "wa", "first", "commit", "branch", "later", "merg", "thi", "case", "valu", "will", "return", "merg", "revis", "check", "getnodeatrevis", "get", "node", "at", "revis", "introduc", "oak", "1972", "then", "assum", "there", "may", "more", "recent", "chang", "previou", "document", "start", "scan", "revis", "histori", "thi", "scan", "depend", "number", "chang", "that", "have", "been", "appli", "document", "sinc", "most", "recent", "chang", "properti", "question"], "B_title": "NodeDocument.getNodeAtRevision() may read too many revisions", "B_clean_title": ["nodedocu", "getnodeatrevis", "node", "document", "get", "node", "at", "revis", "may", "read", "too", "mani", "revis"]},
{"A_title": "SystemUtils.getJavaVersionAsFloat throws StringIndexOutOfBoundsException on Android runtime/Dalvik VMCan be replicated in the Android emulator quite easily. Stack trace:   at org.apache.commons.lang.builder.ToStringBuilder.<clinit>(ToStringBuilder.java:98) E/AndroidRuntime( 1681): ... 17 more E/AndroidRuntime( 1681): Caused by: java.lang.ExceptionInInitializerError E/AndroidRuntime( 1681): at org.apache.commons.lang.builder.ToStringStyle MultiLineToStringStyle.<init>(ToStringStyle.java:2276) E/AndroidRuntime( 1681): at org.apache.commons.lang.builder.ToStringStyle.<clinit>(ToStringStyle.java:94) E/AndroidRuntime( 1681): ... 18 more E/AndroidRuntime( 1681): Caused by: java.lang.StringIndexOutOfBoundsException E/AndroidRuntime( 1681): at java.lang.String.substring(String.java:1571) E/AndroidRuntime( 1681): at org.apache.commons.lang.SystemUtils.getJavaVersionAsFloat(SystemUtils.java:1153) E/AndroidRuntime( 1681): at org.apache.commons.lang.SystemUtils.<clinit>(SystemUtils.java:818)", "A_clean_title": ["systemutil", "getjavaversionasfloat", "system", "util", "get", "java", "version", "as", "float", "throw", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "android", "runtim", "dalvik", "vmcan", "vm", "replic", "android", "emul", "quit", "easili", "stack", "trace", "at", "org", "apach", "common", "lang", "builder", "tostringbuild", "string", "builder", "clinit", "tostringbuild", "java:98", "string", "builder", "androidruntim", "android", "runtim", "1681", "17", "more", "androidruntim", "android", "runtim", "1681", "caus", "by", "java", "lang", "exceptionininitializererror", "except", "initi", "error", "androidruntim", "android", "runtim", "1681", "at", "org", "apach", "common", "lang", "builder", "tostringstyl", "string", "style", "multilinetostringstyl", "multi", "line", "string", "style", "init", "tostringstyl", "java:2276", "string", "style", "androidruntim", "android", "runtim", "1681", "at", "org", "apach", "common", "lang", "builder", "tostringstyl", "string", "style", "clinit", "tostringstyl", "java:94", "string", "style", "androidruntim", "android", "runtim", "1681", "18", "more", "androidruntim", "android", "runtim", "1681", "caus", "by", "java", "lang", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "androidruntim", "android", "runtim", "1681", "at", "java", "lang", "string", "substr", "string", "java:1571", "androidruntim", "android", "runtim", "1681", "at", "org", "apach", "common", "lang", "systemutil", "getjavaversionasfloat", "system", "util", "get", "java", "version", "as", "float", "systemutil", "java:1153", "system", "util", "androidruntim", "android", "runtim", "1681", "at", "org", "apach", "common", "lang", "systemutil", "system", "util", "clinit", "systemutil", "java:818", "system", "util"], "B_title": "SystemUtils.getJavaVersionAsFloat throws StringIndexOutOfBoundsException on Android runtime/Dalvik VM. Oops fix return type.", "B_clean_title": ["systemutil", "getjavaversionasfloat", "system", "util", "get", "java", "version", "as", "float", "throw", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "android", "runtim", "dalvik", "vm", "oop", "fix", "return", "type"]},
{"A_title": "CMAESOptimizer does not enforce boundsThe CMAESOptimizer can exceed the bounds passed to optimize.  Looking at the generationLoop in doOptimize() it does a bounds check by calling isFeasible() but if checkFeasableCount is zero (the default) then isFeasible() is never even called.  Also even with non-zero checkFeasableCount it may give up before finding an in-bounds offspring and go forward with an out-of-bounds offspring.  This is against svn revision 1387637.  I can provide an example program where the optimizer ends up with a fit outside the prescribed bounds if that would help.", "A_clean_title": ["cmaesoptim", "cmae", "optim", "not", "enforc", "boundsth", "bound", "cmaesoptim", "cmae", "optim", "exceed", "bound", "pass", "optim", "look", "at", "generationloop", "gener", "loop", "dooptim", "optim", "it", "bound", "check", "by", "call", "isfeas", "feasibl", "but", "checkfeasablecount", "check", "feasabl", "count", "zero", "default", "then", "isfeas", "feasibl", "never", "even", "call", "also", "even", "non", "zero", "checkfeasablecount", "check", "feasabl", "count", "it", "may", "give", "up", "befor", "find", "bound", "offspr", "go", "forward", "out", "bound", "offspr", "thi", "against", "svn", "revis", "1387637", "provid", "exampl", "program", "where", "optim", "end", "up", "fit", "outsid", "prescrib", "bound", "that", "would", "help"], "B_title": "Fixed missing repair of a point that lies outside the boundaries. Thanks to Frank Hessen for the report and for pinpointing the cause of the problem.", "B_clean_title": ["fix", "miss", "repair", "point", "that", "lie", "outsid", "boundari", "thank", "frank", "hessen", "report", "pinpoint", "caus", "problem"]},
{"A_title": "LucenePropertyIndex full-text search on first level relative node returns no resultFollowing query does not return any result even with a proper index defined 1. noformat//element(* test:Page)  +             jcr:contains(jcr:content summer)  noformat  1 code    jcr:primaryType: oak:QueryIndexDefinition   compatVersion: 2   name: pageIndex   type: lucene   async: async   reindex: true   aggregates:      jcr:primaryType: nt:unstructured     test:Page:        jcr:primaryType: nt:unstructured       include0:          jcr:primaryType: nt:unstructured         relativeNode: true         path: jcr:content                  indexRules:      jcr:primaryType: nt:unstructured     test:Page:        jcr:primaryType: nt:unstructured       properties:          jcr:primaryType: nt:unstructured         jcr:lastModified:            jcr:primaryType: nt:unstructured           ordered: true           propertyIndex: true           name: jcr:content/jcr:lastModified           type: Date                          code", "A_clean_title": ["lucenepropertyindex", "lucen", "properti", "index", "full", "text", "search", "first", "level", "rel", "node", "return", "no", "resultfollow", "result", "follow", "queri", "not", "return", "ani", "result", "even", "proper", "index", "defin", "noformat", "element", "test", "page", "jcr", "contain", "jcr", "content", "summer", "noformat", "code", "jcr", "primarytyp", "primari", "type", "oak", "queryindexdefinit", "queri", "index", "definit", "compatvers", "compat", "version", "name", "pageindex", "page", "index", "type", "lucen", "async", "async", "reindex", "true", "aggreg", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "test", "page", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "include0", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "relativenod", "rel", "node", "true", "path", "jcr", "content", "indexrul", "index", "rule", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "test", "page", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "properti", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "jcr", "lastmodifi", "last", "modifi", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "order", "true", "propertyindex", "properti", "index", "true", "name", "jcr", "content", "jcr", "lastmodifi", "last", "modifi", "type", "date", "code"], "B_title": "- LucenePropertyIndex full-text search on first level relative node returns no result", "B_clean_title": ["lucenepropertyindex", "lucen", "properti", "index", "full", "text", "search", "first", "level", "rel", "node", "return", "no", "result"]},
{"A_title": "Exception when stubbing more than once with when...thenThrowIf I create a mock and stub a method so it throws an exception and do that twice the first exception will be thrown upon invoking the second stub instruction.", "A_clean_title": ["except", "when", "stub", "more", "than", "onc", "when", "thenthrowif", "then", "throw", "creat", "mock", "stub", "method", "so", "it", "throw", "except", "that", "twice", "first", "except", "will", "thrown", "upon", "invok", "second", "stub", "instruct"], "B_title": "issue 282 : mock invocation listeners were removed on reset(mock)", "B_clean_title": ["issu", "282", "mock", "invoc", "listen", "were", "remov", "reset", "mock"]},
{"A_title": "Wide bounds to CMAESOptimizer result in NaN parameters passed to fitness functionIf you give large values as lower/upper bounds (for example -Double.MAX_VALUE as a lower bound) the optimizer can call the fitness function with parameters set to NaN.  My guess is this is due to FitnessFunction.encode/decode generating NaN when normalizing/denormalizing parameters.  For example if the difference between the lower and upper bound is greater than Double.MAX_VALUE encode could divide infinity by infinity.", "A_clean_title": ["wide", "bound", "cmaesoptim", "cmae", "optim", "result", "nan", "na", "paramet", "pass", "fit", "functionif", "function", "you", "give", "larg", "valu", "as", "lower", "upper", "bound", "exampl", "doubl", "max", "valu", "as", "lower", "bound", "optim", "call", "fit", "function", "paramet", "set", "nan", "na", "my", "guess", "thi", "due", "fitnessfunct", "fit", "function", "encod", "decod", "gener", "nan", "na", "when", "normal", "denorm", "paramet", "exampl", "differ", "between", "lower", "upper", "bound", "greater", "than", "doubl", "max", "valu", "encod", "could", "divid", "infin", "by", "infin"], "B_title": "Early detection that overflow will occur in the variables normalization procedure (encode method). Warning mentioned in the documentation.", "B_clean_title": ["earli", "detect", "that", "overflow", "will", "occur", "variabl", "normal", "procedur", "encod", "method", "warn", "mention", "document"]},
{"A_title": "Incomplete reinitialization with some events handlingI get a bug with event handling: I track 2 events that occur in the same step when the first one is accepted it resets the state but the reinitialization is not complete and the second one becomes unable to find its way. I cant give my context which is rather large but I tried a patch that works for me unfortunately it breaks the unit tests.", "A_clean_title": ["incomplet", "reiniti", "some", "event", "handlingi", "handl", "get", "bug", "event", "handl", "track", "event", "that", "occur", "same", "step", "when", "first", "one", "accept", "it", "reset", "state", "but", "reiniti", "not", "complet", "second", "one", "becom", "unabl", "find", "it", "way", "cant", "give", "my", "context", "which", "rather", "larg", "but", "tri", "patch", "that", "work", "me", "unfortun", "it", "break", "unit", "test"], "B_title": "Fixed an event resetting issue in ODE.", "B_clean_title": ["fix", "event", "reset", "issu", "ode"]},
{"A_title": "InputTableConfig missing isOfflineScan field in SerializerInputTableConfig write(DataOutput dataOutput) forgets to write out the isOfflineScan field which makes it always false when it gets unserialized.", "A_clean_title": ["inputtableconfig", "input", "tabl", "config", "miss", "isofflinescan", "offlin", "scan", "field", "serializerinputtableconfig", "serial", "input", "tabl", "config", "write", "dataoutput", "data", "output", "dataoutput", "data", "output", "forget", "write", "out", "isofflinescan", "offlin", "scan", "field", "which", "make", "it", "alway", "fals", "when", "it", "get", "unseri"], "B_title": "Offline scan property is now being properly serialized. Added verification that all other booleans are being serialized.", "B_clean_title": ["offlin", "scan", "properti", "now", "be", "properli", "serial", "ad", "verif", "that", "all", "other", "boolean", "are", "be", "serial"]},
{"A_title": "Typos in externs/html5.jsNone", "A_clean_title": ["typo", "jsnone", "extern", "html5", "js", "none"], "B_title": "Fixes a bug in getGreatestSubtype (Andrew)", "B_clean_title": ["fix", "bug", "getgreatestsubtyp", "get", "greatest", "subtyp", "andrew"]},
{"A_title": "Branch reset does not revert all changesThis is caused by recent changes done for OAK-3646.", "A_clean_title": ["branch", "reset", "not", "revert", "all", "changesthi", "chang", "thi", "caus", "by", "recent", "chang", "done", "oak", "3646"], "B_title": "Branch reset does not revert all changes", "B_clean_title": ["branch", "reset", "not", "revert", "all", "chang"]},
{"A_title": "In RealVector dotProduct and outerProduct return wrong results due to misuse of sparse iteratorsIn class RealVector the default implementation of RealMatrix outerProduct(RealVector) uses sparse iterators on the entries of the two vectors. The rationale behind this is that 0d * x == 0d is true for all double x. This assumption is in fact false since 0d * NaN == NaN.  Proposed fix is to loop through *all* entries of both vectors. This can have a significant impact on the CPU cost but robustness should probably be preferred over speed in default implementations.  Same issue occurs with double dotProduct(RealVector) which uses sparse iterators for this only.  Another option would be to through an exception if isNaN() is true in which case caching could be used for both isNaN() and isInfinite().", "A_clean_title": ["realvector", "real", "vector", "dotproduct", "dot", "product", "outerproduct", "outer", "product", "return", "wrong", "result", "due", "misus", "spars", "iteratorsin", "iter", "class", "realvector", "real", "vector", "default", "implement", "realmatrix", "real", "matrix", "outerproduct", "outer", "product", "realvector", "real", "vector", "use", "spars", "iter", "entri", "two", "vector", "rational", "behind", "thi", "that", "0d", "0d", "true", "all", "doubl", "thi", "assumpt", "fact", "fals", "sinc", "0d", "nan", "na", "nan", "na", "propos", "fix", "loop", "through", "all", "entri", "both", "vector", "thi", "have", "signific", "impact", "cpu", "cost", "but", "robust", "probabl", "prefer", "over", "speed", "default", "implement", "same", "issu", "occur", "doubl", "dotproduct", "dot", "product", "realvector", "real", "vector", "which", "use", "spars", "iter", "thi", "onli", "anoth", "option", "would", "through", "except", "isnan", "na", "true", "which", "case", "cach", "could", "use", "both", "isnan", "na", "isinfinit", "infinit"], "B_title": "fixed a bug in RealVector.outerProduct(RealVector). Now loops through *all* entries of the vectors.", "B_clean_title": ["fix", "bug", "realvector", "outerproduct", "real", "vector", "outer", "product", "realvector", "real", "vector", "now", "loop", "through", "all", "entri", "vector"]},
{"A_title": "SerializationUtils throws ClassNotFoundException when cloning primitive classesIf a serializable object contains a reference to a primitive class e.g. int.class or int.class the SerializationUtils throw a ClassNotFoundException when trying to clone that object.  import org.apache.commons.lang3.SerializationUtils; import org.junit.Test;   public class SerializationUtilsTest    @Test public void primitiveTypeClassSerialization() Class<?> primitiveType = int.class;  Class<?> clone = SerializationUtils.clone(primitiveType); assertEquals(primitiveType clone);     The problem was already reported as a java bug http://bugs.sun.com/view_bug.do?bug_id=4171142 and ObjectInputStream is fixed since java version 1.4. The SerializationUtils problem arises because the SerializationUtils internally use the ClassLoaderAwareObjectInputStream that overrides the ObjectInputStreams resoleClass method without delegating to the super method in case of a ClassNotFoundException. I understand the intention of the ClassLoaderAwareObjectInputStream but this implementation should also implement a fallback to the original implementation. For example:          protected Class<?> resolveClass(ObjectStreamClass desc) throws IOException ClassNotFoundException              String name = desc.getName();             try                  return Class.forName(name false classLoader);              catch (ClassNotFoundException ex)              try                   return Class.forName(name false Thread.currentThread().getContextClassLoader());              catch (Exception e)       return super.resolveClass(desc);                          Here is the code in ObjectInputStream that fixed the java bug.      protected Class<?> resolveClass(ObjectStreamClass desc) throws IOException ClassNotFoundException      String name = desc.getName(); try      return Class.forName(name false latestUserDefinedLoader());  catch (ClassNotFoundException ex)      Class cl = (Class) primClasses.get(name);     if (cl != null)  return cl;      else  throw ex;", "A_clean_title": ["serializationutil", "serial", "util", "throw", "classnotfoundexcept", "class", "not", "found", "except", "when", "clone", "primit", "classesif", "class", "serializ", "object", "contain", "refer", "primit", "class", "int", "class", "or", "int", "class", "serializationutil", "serial", "util", "throw", "classnotfoundexcept", "class", "not", "found", "except", "when", "tri", "clone", "that", "object", "import", "org", "apach", "common", "lang3", "serializationutil", "serial", "util", "import", "org", "junit", "test", "public", "class", "serializationutilstest", "serial", "util", "test", "test", "public", "void", "primitivetypeclassseri", "primit", "type", "class", "serial", "class", "primitivetyp", "primit", "type", "int", "class", "class", "clone", "serializationutil", "clone", "serial", "util", "primitivetyp", "primit", "type", "assertequ", "assert", "equal", "primitivetyp", "primit", "type", "clone", "problem", "wa", "alreadi", "report", "as", "java", "bug", "http", "sun", "bug", "bug", "com", "view", "bug", "id=4171142", "objectinputstream", "object", "input", "stream", "fix", "sinc", "java", "version", "serializationutil", "serial", "util", "problem", "aris", "becaus", "serializationutil", "serial", "util", "intern", "use", "classloaderawareobjectinputstream", "class", "loader", "awar", "object", "input", "stream", "that", "overrid", "objectinputstream", "object", "input", "stream", "resoleclass", "resol", "class", "method", "without", "deleg", "super", "method", "case", "classnotfoundexcept", "class", "not", "found", "except", "understand", "intent", "classloaderawareobjectinputstream", "class", "loader", "awar", "object", "input", "stream", "but", "thi", "implement", "also", "implement", "fallback", "origin", "implement", "exampl", "protect", "class", "resolveclass", "resolv", "class", "objectstreamclass", "object", "stream", "class", "desc", "throw", "ioexcept", "io", "except", "classnotfoundexcept", "class", "not", "found", "except", "string", "name", "desc", "getnam", "get", "name", "tri", "return", "class", "fornam", "name", "name", "fals", "classload", "class", "loader", "catch", "classnotfoundexcept", "class", "not", "found", "except", "ex", "tri", "return", "class", "fornam", "name", "name", "fals", "thread", "currentthread", "current", "thread", "getcontextclassload", "get", "context", "class", "loader", "catch", "except", "return", "super", "resolveclass", "resolv", "class", "desc", "here", "code", "objectinputstream", "object", "input", "stream", "that", "fix", "java", "bug", "protect", "class", "resolveclass", "resolv", "class", "objectstreamclass", "object", "stream", "class", "desc", "throw", "ioexcept", "io", "except", "classnotfoundexcept", "class", "not", "found", "except", "string", "name", "desc", "getnam", "get", "name", "tri", "return", "class", "fornam", "name", "name", "fals", "latestuserdefinedload", "latest", "user", "defin", "loader", "catch", "classnotfoundexcept", "class", "not", "found", "except", "ex", "class", "cl", "class", "primclass", "get", "prim", "class", "name", "cl", "null", "return", "cl", "throw", "ex"], "B_title": "SerializationUtils throws ClassNotFoundException when cloning primitive classes", "B_clean_title": ["serializationutil", "serial", "util", "throw", "classnotfoundexcept", "class", "not", "found", "except", "when", "clone", "primit", "class"]},
{"A_title": "MU-201 v3.xx doesnt work?Hi  ive tried to install my tracker in Traccar but it doesnt work. The Logfile was generated and everything is running but not the tracker...  HEX is translatet to:   Port 5051  How can i add the device?  Kind regards  Daniel", "A_clean_title": ["mu", "201", "v3", "xx", "doesnt", "work", "hi", "ive", "tri", "instal", "my", "tracker", "traccar", "but", "it", "doesnt", "work", "logfil", "wa", "gener", "everyth", "run", "but", "not", "tracker", "hex", "translatet", "port", "5051", "how", "add", "devic", "kind", "regard", "daniel"], "B_title": "Fix MU-201 message decoding (fix #3220)", "B_clean_title": ["fix", "mu", "201", "messag", "decod", "fix", "3220"]},
{"A_title": "IResponseFilter cannot change buffer contentsChanges to the responseBuffer passed to an IResponseFilter are not picked up nor are newly created AppendingStringBuffer (return value of the method). Both callers of the method invoke it with a copy of the buffer and ignore return values (BufferedWebResponse line 145 and AjaxRequestTarget line 687).", "A_clean_title": ["iresponsefilt", "respons", "filter", "not", "chang", "buffer", "contentschang", "content", "chang", "responsebuff", "respons", "buffer", "pass", "iresponsefilt", "respons", "filter", "are", "not", "pick", "up", "nor", "are", "newli", "creat", "appendingstringbuff", "append", "string", "buffer", "return", "valu", "method", "both", "caller", "method", "invok", "it", "copi", "buffer", "ignor", "return", "valu", "bufferedwebrespons", "buffer", "web", "respons", "line", "145", "ajaxrequesttarget", "ajax", "request", "target", "line", "687"], "B_title": "Changing AjaxRequestTarget and BufferedWebResponse to dont discard the filtered AppendingStringBuffer response if the filter returns a new instance. Issue: WICKET-3620", "B_clean_title": ["chang", "ajaxrequesttarget", "ajax", "request", "target", "bufferedwebrespons", "buffer", "web", "respons", "dont", "discard", "filter", "appendingstringbuff", "append", "string", "buffer", "respons", "filter", "return", "new", "instanc", "issu", "wicket", "3620"]},
{"A_title": "support @lends annotationNone", "A_clean_title": ["support", "lend", "annotationnon", "annot", "none"], "B_title": "dont emit unsafe global this warnings when the @lends annotation is used correctly. fixes issue 248", "B_clean_title": ["dont", "emit", "unsaf", "global", "thi", "warn", "when", "lend", "annot", "use", "correctli", "fix", "issu", "248"]},
{"A_title": "Failure in one of the batch in VersionGC might lead to orphaned nodesVersionGC logic currently performs deletion of nodes in batches. For GC to work properly NodeDocument should always be removed in bottom-up mode i.e. parent node should be removed *after* child has been removed  Currently the GC logic deletes the NodeDocument in undefined order. In such mode if one of the batch fails then its possible that parent might have got deleted but the child was not deleted.   Now in next run the child node would not be recognized as a deleted node because the commit root would not be found.", "A_clean_title": ["failur", "one", "batch", "versiongc", "version", "gc", "might", "lead", "orphan", "nodesversiongc", "node", "version", "gc", "logic", "current", "perform", "delet", "node", "batch", "gc", "work", "properli", "nodedocu", "node", "document", "alway", "remov", "bottom", "up", "mode", "parent", "node", "remov", "after", "child", "ha", "been", "remov", "current", "gc", "logic", "delet", "nodedocu", "node", "document", "undefin", "order", "such", "mode", "one", "batch", "fail", "then", "it", "possibl", "that", "parent", "might", "have", "got", "delet", "but", "child", "wa", "not", "delet", "now", "next", "run", "child", "node", "would", "not", "recogn", "as", "delet", "node", "becaus", "commit", "root", "would", "not", "found"], "B_title": "- Failure in one of the batch in VersionGC might lead to orphaned nodes", "B_clean_title": ["failur", "one", "batch", "versiongc", "version", "gc", "might", "lead", "orphan", "node"]},
{"A_title": "AccessDenied when modifying transiently moved item with too many ACEsIf at least the following preconditions are fulfilled saving a moved item fails with access denied:  1. there are more PermissionEntries in the PermissionEntryCache than the configured EagerCacheSize 2. an node is moved to a location where the user has write access through a group membership 3. a property is added to the transiently moved item  For example: 1. set the *eagerCacheSize* to 0 2. create new group *testgroup* and user *testuser* 3. make *testuser* member of *testgroup* 4. create nodes /testroot/a and /testroot/a/b and /testroot/a/c 5. allow *testgroup* rep:write on /testroot/a 6. as *testuser* create /testroot/a/b/item (to verify that the user has write access) 7. as *testuser* move /testroot/a/b/item to /testroot/a/c/item 8. save() -> works 9. as *testuser* move /testroot/a/c/item back to /testroot/a/b/item AND add new property to the transient /testroot/a/b/item 10. save() -> access denied", "A_clean_title": ["accessdeni", "access", "deni", "when", "modifi", "transient", "move", "item", "too", "mani", "acesif", "ac", "es", "at", "least", "follow", "precondit", "are", "fulfil", "save", "move", "item", "fail", "access", "deni", "there", "are", "more", "permissionentri", "permiss", "entri", "permissionentrycach", "permiss", "entri", "cach", "than", "configur", "eagercaches", "eager", "cach", "size", "node", "move", "locat", "where", "user", "ha", "write", "access", "through", "group", "membership", "properti", "ad", "transient", "move", "item", "exampl", "set", "eagercaches", "eager", "cach", "size", "creat", "new", "group", "testgroup", "user", "testus", "make", "testus", "member", "testgroup", "creat", "node", "testroot", "testroot", "testroot", "allow", "testgroup", "rep", "write", "testroot", "as", "testus", "creat", "testroot", "item", "verifi", "that", "user", "ha", "write", "access", "as", "testus", "move", "testroot", "item", "testroot", "item", "save", "work", "as", "testus", "move", "testroot", "item", "back", "testroot", "item", "add", "new", "properti", "transient", "testroot", "item", "10", "save", "access", "deni"], "B_title": "AccessDenied when modifying transiently moved item with too many ACEs", "B_clean_title": ["accessdeni", "access", "deni", "when", "modifi", "transient", "move", "item", "too", "mani", "ace", "ac", "es"]},
{"A_title": "XYSeries.addOrUpdate() should add if duplicates are allowedIve found a bug in jfreechart-1.0.9 code for org.jfree.data.xy.XYSeries. There was a change some time ago which introduced the notion of allowing duplicate X values in XYSeries data. The method addOrUpdate(Number x Number y) was never modified to support this and therefore duplicate data were overwriting existing data.", "A_clean_title": ["xyseri", "addorupd", "xy", "seri", "add", "or", "updat", "add", "duplic", "are", "allowed", "allow", "ive", "found", "bug", "jfreechart", "code", "org", "jfree", "data", "xy", "xyseri", "xy", "seri", "there", "wa", "chang", "some", "time", "ago", "which", "introduc", "notion", "allow", "duplic", "valu", "xyseri", "xy", "seri", "data", "method", "addorupd", "add", "or", "updat", "number", "number", "wa", "never", "modifi", "support", "thi", "therefor", "duplic", "data", "were", "overwrit", "exist", "data"], "B_title": "Fix for bug 1955483.", "B_clean_title": ["fix", "bug", "1955483"]},
{"A_title": "URL with a previous page version ignores requested page based on mount pathSee discussion on http://mail-archives.apache.org/mod_mbox/wicket-users/201203.mbox/browser  With 2 mounts /page1 and /page2 to stateful pages and the following sequence: 1-With a new session user visits /page1. Displayed URL is /page1?0 2-Whatever without expiring session 3-User requests URL /page2?0 because it was bookmarked received via email etc. 4-Rendered page is /page1?0 which was stored in the page map. The actual URL displayed is /wicket/bookmarkable/com.mycompany.Page1?0  If a requested page id exists but does not match the page class mounted on the actual requested url Wicket should not use the old page version. This is very counter-intuitive for users having bookmarks to stateful pages or exchanging links.", "A_clean_title": ["url", "previou", "page", "version", "ignor", "request", "page", "base", "mount", "pathse", "path", "see", "discuss", "http", "mail", "archiv", "apach", "user", "201203", "mbox", "browser", "org", "mod", "mbox", "wicket", "mount", "page1", "page2", "state", "page", "follow", "sequenc", "new", "session", "user", "visit", "page1", "display", "url", "page1", "whatev", "without", "expir", "session", "user", "request", "url", "page2", "becaus", "it", "wa", "bookmark", "receiv", "via", "email", "etc", "render", "page", "page1", "which", "wa", "store", "page", "map", "actual", "url", "display", "mycompani", "page1", "wicket", "bookmark", "com", "request", "page", "id", "exist", "but", "not", "match", "page", "class", "mount", "actual", "request", "url", "wicket", "not", "use", "old", "page", "version", "thi", "veri", "counter", "intuit", "user", "have", "bookmark", "state", "page", "or", "exchang", "link"], "B_title": "URL with a previous page version ignores requested page based on mount path", "B_clean_title": ["url", "previou", "page", "version", "ignor", "request", "page", "base", "mount", "path"]},
{"A_title": "testing for symmetric positive definite matrix in CholeskyDecompositionI used this matrix:         double cv =   0.40434286 0.09376327 0.30328980 0.04909388   0.09376327 0.10400408 0.07137959 0.04762857   0.30328980 0.07137959 0.30458776 0.04882449             0.04909388 0.04762857 0.04882449 0.07543265         ;  And it works fine because it is symmetric positive definite  I tried this matrix:          double cv =              0.40434286 -0.09376327 0.30328980 0.04909388             -0.09376327 0.10400408 0.07137959 0.04762857             0.30328980 0.07137959 0.30458776 0.04882449              0.04909388 0.04762857 0.04882449 0.07543265         ; And it should throw an exception but it does not.  I tested the matrix in R and Rs cholesky decomposition method returns that the matrix is not symmetric positive definite. Obviously your code is not catching this appropriately. By the way (in my opinion) the use of exceptions to check these conditions is not the best design or use for exceptions.  If you are going to force the use to try and catch these exceptions at least provide methods  to test the conditions prior to the possibility of the exception.", "A_clean_title": ["test", "symmetr", "posit", "definit", "matrix", "choleskydecompositioni", "choleski", "decomposit", "use", "thi", "matrix", "doubl", "cv", "40434286", "09376327", "30328980", "04909388", "09376327", "10400408", "07137959", "04762857", "30328980", "07137959", "30458776", "04882449", "04909388", "04762857", "04882449", "07543265", "it", "work", "fine", "becaus", "it", "symmetr", "posit", "definit", "tri", "thi", "matrix", "doubl", "cv", "40434286", "09376327", "30328980", "04909388", "09376327", "10400408", "07137959", "04762857", "30328980", "07137959", "30458776", "04882449", "04909388", "04762857", "04882449", "07543265", "it", "throw", "except", "but", "it", "not", "test", "matrix", "rs", "choleski", "decomposit", "method", "return", "that", "matrix", "not", "symmetr", "posit", "definit", "obvious", "your", "code", "not", "catch", "thi", "appropri", "by", "way", "my", "opinion", "use", "except", "check", "these", "condit", "not", "best", "design", "or", "use", "except", "you", "are", "go", "forc", "use", "tri", "catch", "these", "except", "at", "least", "provid", "method", "test", "condit", "prior", "possibl", "except"], "B_title": "fixed detection of not positive definite matrices JIRA: MATH-274", "B_clean_title": ["fix", "detect", "not", "posit", "definit", "matric", "jira", "math", "274"]},
{"A_title": "InstanceConnectionInfo returns wrong hostname when no DNS entry existsIf there is no DNS entry for an address (like 10.4.122.43) then the InstanceConnectionInfo returns the first octet (10) as the hostame.", "A_clean_title": ["instanceconnectioninfo", "instanc", "connect", "info", "return", "wrong", "hostnam", "when", "no", "dn", "entri", "existsif", "exist", "there", "no", "dn", "entri", "address", "like", "10", "122", "43", "then", "instanceconnectioninfo", "instanc", "connect", "info", "return", "first", "octet", "10", "as", "hostam"], "B_title": "taskmanager Fix hostname lookup.", "B_clean_title": ["taskmanag", "fix", "hostnam", "lookup"]},
{"A_title": "EnumChoiceRenderer misbehaves with anonymous enum classesPlease find attached testcase reproducing the problem.  Proper fix is to do return object.getDeclaringClass().getSimpleName() + . + object.name()  instead of return object.getClass().getSimpleName() + . + object.name()  in EnumChoiceRenderer.resourceKey", "A_clean_title": ["enumchoicerender", "enum", "choic", "render", "misbehav", "anonym", "enum", "classespleas", "class", "pleas", "find", "attach", "testcas", "reproduc", "problem", "proper", "fix", "return", "object", "getdeclaringclass", "get", "declar", "class", "getsimplenam", "get", "simpl", "name", "object", "name", "instead", "return", "object", "getclass", "get", "class", "getsimplenam", "get", "simpl", "name", "object", "name", "enumchoicerender", "resourcekey", "enum", "choic", "render", "resourc", "key"], "B_title": "EnumChoiceRenderer fix Issue: WICKET-2609", "B_clean_title": ["enumchoicerender", "enum", "choic", "render", "fix", "issu", "wicket", "2609"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Fixed Complex.reciprocal() for zero argument.", "B_clean_title": ["fix", "complex", "reciproc", "zero", "argument"]},
{"A_title": "Mapping ResourceReferences to Urls is slowPackageResourceReference is often used for stylesheets and JavaScript resources many of which can appear on a typical page (WicketAjaxReference is one common example). Every time the page is rendered these resources are mapped to urls in order to build the appropriate <link href=...> or <script src=...> tags.  The trouble is that this mapping process is extremely inefficient. To map a ResourceReference to a url ResourceReference#getLastModified() must be consulted for FilenameWithTimestampResourceCachingStrategy and ResourceReference#getUrlAttributes() is called to append appropriate query parameters.  In PackageResourceReference both of these methods delegate to the very expensive PackageResourceReference#lookupStream() which makes several attempts to locate the underlying file or classpath item using various permutations of locale style and variation. Each of these attempts involves I/O. The default ResourceStreamLocator which does the actual file and classpath queries does no caching whatsoever.  On a trivial Wicket page containing 7 total PackageResourceReferences for images stylesheets and JavaScript files the average response time in my tests was 211 ms. The vast majority of that time was spent in ResourceStreamLocator due to the expensive steps described above.  It seems that putting caching at the ResourceStreamLocator would be extremely beneficial. I am attaching a simple implementation. With caching enabled in ResourceStreamLocator the response time of my test page dropped from 211 ms to 49 ms.", "A_clean_title": ["map", "resourcerefer", "resourc", "refer", "url", "slowpackageresourcerefer", "slow", "packag", "resourc", "refer", "often", "use", "stylesheet", "javascript", "java", "script", "resourc", "mani", "which", "appear", "typic", "page", "wicketajaxrefer", "wicket", "ajax", "refer", "one", "common", "exampl", "everi", "time", "page", "render", "these", "resourc", "are", "map", "url", "order", "build", "appropri", "link", "href=", "or", "script", "src=", "tag", "troubl", "that", "thi", "map", "process", "extrem", "ineffici", "map", "resourcerefer", "resourc", "refer", "url", "resourcerefer", "resourc", "refer", "getlastmodifi", "get", "last", "modifi", "must", "consult", "filenamewithtimestampresourcecachingstrategi", "filenam", "timestamp", "resourc", "cach", "strategi", "resourcerefer", "resourc", "refer", "geturlattribut", "get", "url", "attribut", "call", "append", "appropri", "queri", "paramet", "packageresourcerefer", "packag", "resourc", "refer", "both", "these", "method", "deleg", "veri", "expens", "packageresourcerefer", "packag", "resourc", "refer", "lookupstream", "lookup", "stream", "which", "make", "sever", "attempt", "locat", "underli", "file", "or", "classpath", "item", "variou", "permut", "local", "style", "variat", "each", "these", "attempt", "involv", "default", "resourcestreamloc", "resourc", "stream", "locat", "which", "actual", "file", "classpath", "queri", "no", "cach", "whatsoev", "trivial", "wicket", "page", "contain", "total", "packageresourcerefer", "packag", "resourc", "refer", "imag", "stylesheet", "javascript", "java", "script", "file", "averag", "respons", "time", "my", "test", "wa", "211", "ms", "vast", "major", "that", "time", "wa", "spent", "resourcestreamloc", "resourc", "stream", "locat", "due", "expens", "step", "describ", "abov", "it", "seem", "that", "put", "cach", "at", "resourcestreamloc", "resourc", "stream", "locat", "would", "extrem", "benefici", "am", "attach", "simpl", "implement", "cach", "enabl", "resourcestreamloc", "resourc", "stream", "locat", "respons", "time", "my", "test", "page", "drop", "211", "ms", "49", "ms"], "B_title": "Mapping ResourceReferences to Urls is slow", "B_clean_title": ["map", "resourcerefer", "resourc", "refer", "url", "slow"]},
{"A_title": "NullPointerException in DeltaIteration when no ForwardedFiledsThe following exception is thrown by the Connected Components example if the @ForwardedFieldsFirst(*) annotation from the ComponentIdFilter join is removed:  Caused by: java.lang.NullPointerException at org.apache.flink.examples.java.graph.ConnectedComponents ComponentIdFilter.join(ConnectedComponents.java:186) at org.apache.flink.examples.java.graph.ConnectedComponents ComponentIdFilter.join(ConnectedComponents.java:1) at org.apache.flink.runtime.operators.JoinWithSolutionSetSecondDriver.run(JoinWithSolutionSetSecondDriver.java:198) at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:496) at org.apache.flink.runtime.iterative.task.AbstractIterativePactTask.run(AbstractIterativePactTask.java:139) at org.apache.flink.runtime.iterative.task.IterationIntermediatePactTask.run(IterationIntermediatePactTask.java:92) at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:362) at org.apache.flink.runtime.execution.RuntimeEnvironment.run(RuntimeEnvironment.java:217) at java.lang.Thread.run(Thread.java:745)  Code | https://github.com/vasia/flink/tree/cc-test and dataset | http://snap.stanford.edu/data/com-DBLP.html to reproduce.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "deltaiter", "delta", "iter", "when", "no", "forwardedfiledsth", "forward", "file", "follow", "except", "thrown", "by", "connect", "compon", "exampl", "forwardedfieldsfirst", "forward", "field", "first", "annot", "componentidfilt", "compon", "id", "filter", "join", "remov", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "flink", "exampl", "java", "graph", "connectedcompon", "connect", "compon", "componentidfilt", "join", "compon", "id", "filter", "connectedcompon", "java:186", "connect", "compon", "at", "org", "apach", "flink", "exampl", "java", "graph", "connectedcompon", "connect", "compon", "componentidfilt", "join", "compon", "id", "filter", "connectedcompon", "java:1", "connect", "compon", "at", "org", "apach", "flink", "runtim", "oper", "joinwithsolutionsetseconddriv", "run", "join", "solut", "set", "second", "driver", "joinwithsolutionsetseconddriv", "java:198", "join", "solut", "set", "second", "driver", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "run", "regular", "pact", "task", "regularpacttask", "java:496", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "iter", "task", "abstractiterativepacttask", "run", "abstract", "iter", "pact", "task", "abstractiterativepacttask", "java:139", "abstract", "iter", "pact", "task", "at", "org", "apach", "flink", "runtim", "iter", "task", "iterationintermediatepacttask", "run", "iter", "intermedi", "pact", "task", "iterationintermediatepacttask", "java:92", "iter", "intermedi", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "invok", "regular", "pact", "task", "regularpacttask", "java:362", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "run", "runtim", "environ", "runtimeenviron", "java:217", "runtim", "environ", "at", "java", "lang", "thread", "run", "thread", "java:745", "code", "http", "test", "github", "com", "vasia", "flink", "tree", "cc", "dataset", "http", "stanford", "dblp", "html", "snap", "edu", "data", "com", "reproduc"], "B_title": "Fix NullPointerException in delta iteration due to missing temp", "B_clean_title": ["fix", "nullpointerexcept", "null", "pointer", "except", "delta", "iter", "due", "miss", "temp"]},
{"A_title": "XmlPullParser fails to properly parse from String with encoding declarationWhen parsing from a string XmlPullParser fails if the encoding from the XML declaration is different than the systems file encoding.  Examples:    -Dfile.encoding=ISO-8859-1    parser.parse(<?xml encoding=UTF-8 ?><span id=umlaut-äöü></span>);     -Dfile.encoding=UTF-8    parser.parse(<?xml encoding=ISO-8859-1 ?><span id=umlaut-äöü></span>);  Both fail because the string is read with the systems file encoding while the parser expects the stream to be encoded in the declarated encoding.", "A_clean_title": ["xmlpullpars", "xml", "pull", "parser", "fail", "properli", "pars", "string", "encod", "declarationwhen", "declar", "when", "pars", "string", "xmlpullpars", "xml", "pull", "parser", "fail", "encod", "xml", "declar", "differ", "than", "system", "file", "encod", "exampl", "8859", "dfile", "encoding=iso", "parser", "pars", "xml", "encoding=utf", "span", "id=umlaut", "span", "dfile", "encoding=utf", "parser", "pars", "xml", "encoding=iso", "8859", "span", "id=umlaut", "span", "both", "fail", "becaus", "string", "read", "system", "file", "encod", "while", "parser", "expect", "stream", "encod", "declar", "encod"], "B_title": "dont use possibly conflicting encoding from XML declaration when parsing a String", "B_clean_title": ["dont", "use", "possibl", "conflict", "encod", "xml", "declar", "when", "pars", "string"]},
{"A_title": "Rescheduling the same ajax timer behavior causes memory leak in the browserAbstractAjaxTimerBehavior uses JavaScript setTimeout() function to do its job. It has a #stop() method that clears the timeout but if the timeout is re-scheduled without being cleared a memory leak is observed in the browser.", "A_clean_title": ["reschedul", "same", "ajax", "timer", "behavior", "caus", "memori", "leak", "browserabstractajaxtimerbehavior", "browser", "abstract", "ajax", "timer", "behavior", "use", "javascript", "java", "script", "settimeout", "set", "timeout", "function", "it", "job", "it", "ha", "stop", "method", "that", "clear", "timeout", "but", "timeout", "re", "schedul", "without", "be", "clear", "memori", "leak", "observ", "browser"], "B_title": "Rescheduling the same ajax timer behavior causes memory leak in the browser", "B_clean_title": ["reschedul", "same", "ajax", "timer", "behavior", "caus", "memori", "leak", "browser"]},
{"A_title": "Exception thrown in ode for a pair of close eventsWhen two discrete events occur closer to each other than the convergence threshold used for locating them this sometimes triggers a NumberIsTooLargeException.  The exception happens because the EventState class think the second event is simply a numerical artifact (a repetition of the already triggerred first event) and tries to skip past it. If there are no other event in the same step later on one interval boundary finally reach step end and the interval bounds are reversed.", "A_clean_title": ["except", "thrown", "ode", "pair", "close", "eventswhen", "event", "when", "two", "discret", "event", "occur", "closer", "each", "other", "than", "converg", "threshold", "use", "locat", "them", "thi", "sometim", "trigger", "numberistoolargeexcept", "number", "too", "larg", "except", "except", "happen", "becaus", "eventst", "event", "state", "class", "think", "second", "event", "simpli", "numer", "artifact", "repetit", "alreadi", "trigger", "first", "event", "tri", "skip", "past", "it", "there", "are", "no", "other", "event", "same", "step", "later", "one", "interv", "boundari", "final", "reach", "step", "end", "interv", "bound", "are", "revers"], "B_title": "Fixed wrong event detection in case of close events pairs.", "B_clean_title": ["fix", "wrong", "event", "detect", "case", "close", "event", "pair"]},
{"A_title": "constant functions not inlined aggressively enoughNone", "A_clean_title": ["constant", "function", "not", "inlin", "aggress", "enoughnon", "enough", "none"], "B_title": "Lower the cost of true/false/null. Fixes issue 728", "B_clean_title": ["lower", "cost", "true", "fals", "null", "fix", "issu", "728"]},
{"A_title": "Upgraded version history has UUIDs as jcr:frozenUuid of non-referenceable nodesIn Jackrabbit Classic each node even non-referenceable ones has a UUID as its identifier and thus the jcr:frozenUuid properties of frozen nodes are always UUIDs. In contrast Oak uses path identifiers for non-referenceable frozen nodes (see OAK-1009) which presents a problem when dealing with version histories migrated from Jackrabbit Classic.  To avoid this mismatch the upgrade code should check each frozen node for referenceability and replace the frozen UUID with a path identifier if needed.", "A_clean_title": ["upgrad", "version", "histori", "ha", "uuid", "uui", "ds", "as", "jcr", "frozenuuid", "frozen", "uuid", "non", "referenc", "nodesin", "node", "jackrabbit", "classic", "each", "node", "even", "non", "referenc", "one", "ha", "uuid", "as", "it", "identifi", "thu", "jcr", "frozenuuid", "frozen", "uuid", "properti", "frozen", "node", "are", "alway", "uuid", "uui", "ds", "contrast", "oak", "use", "path", "identifi", "non", "referenc", "frozen", "node", "see", "oak", "1009", "which", "present", "problem", "when", "deal", "version", "histori", "migrat", "jackrabbit", "classic", "avoid", "thi", "mismatch", "upgrad", "code", "check", "each", "frozen", "node", "referenc", "replac", "frozen", "uuid", "path", "identifi", "need"], "B_title": "Upgraded version history has UUIDs as jcr:frozenUuid of non-referenceable nodes", "B_clean_title": ["upgrad", "version", "histori", "ha", "uuid", "uui", "ds", "as", "jcr", "frozenuuid", "frozen", "uuid", "non", "referenc", "node"]},
{"A_title": "Wrong compareTo in micro-kernel Id classCompareTo method in Id class fails in some cases.  code  // this works final Id id1 = Id.fromString( 0000000000000007 ); final Id id2 = Id.fromString( 000000000000000c );  assertTrue( id1 +  should be less than  + id2 id1.compareTo( id2 ) < 0 );  // but this doesnt final Id id1 = Id.fromString( 0000000000000070 ); final Id id2 = Id.fromString( 00000000000000c0 );  assertTrue( id1 +  should be less than  + id2 id1.compareTo( id2 ) < 0 ); code", "A_clean_title": ["wrong", "compareto", "compar", "micro", "kernel", "id", "classcompareto", "class", "compar", "method", "id", "class", "fail", "some", "case", "code", "thi", "work", "final", "id", "id1", "id", "fromstr", "string", "0000000000000007", "final", "id", "id2", "id", "fromstr", "string", "000000000000000c", "asserttru", "assert", "true", "id1", "less", "than", "id2", "id1", "compareto", "compar", "id2", "but", "thi", "doesnt", "final", "id", "id1", "id", "fromstr", "string", "0000000000000070", "final", "id", "id2", "id", "fromstr", "string", "00000000000000c0", "asserttru", "assert", "true", "id1", "less", "than", "id2", "id1", "compareto", "compar", "id2", "code"], "B_title": "Wrong compareTo in micro-kernel Id class", "B_clean_title": ["wrong", "compareto", "compar", "micro", "kernel", "id", "class"]},
{"A_title": "UserValidator and AccessControlValidator must not process hidden nodesThis is similar to OAK-3019 but for UserValidator and AccessControlValidator.", "A_clean_title": ["uservalid", "user", "valid", "accesscontrolvalid", "access", "control", "valid", "must", "not", "process", "hidden", "nodesthi", "node", "thi", "similar", "oak", "3019", "but", "uservalid", "user", "valid", "accesscontrolvalid", "access", "control", "valid"], "B_title": "UserValidator and AccessControlValidator must not process hidden nodes", "B_clean_title": ["uservalid", "user", "valid", "accesscontrolvalid", "access", "control", "valid", "must", "not", "process", "hidden", "node"]},
{"A_title": "Bug in require calls processingNone", "A_clean_title": ["bug", "requir", "call", "processingnon", "process", "none"], "B_title": "This change had to be rolled-back since it breaks some users of the Java API. See the updated comment and new test case for reasoning.", "B_clean_title": ["thi", "chang", "had", "roll", "back", "sinc", "it", "break", "some", "user", "java", "api", "see", "updat", "comment", "new", "test", "case", "reason"]},
{"A_title": "Mockito.after() method accepts negative timeperiods and subsequent verifications always passNone", "A_clean_title": ["mockito", "after", "method", "accept", "neg", "timeperiod", "subsequ", "verif", "alway", "passnon", "pass", "none"], "B_title": "Fixes #197 : Blocks ability to use negative value for timeout() and after() method.", "B_clean_title": ["fix", "197", "block", "abil", "use", "neg", "valu", "timeout", "after", "method"]},
{"A_title": "Error while parsing job arguments passed by CLIFlink CLI treats job arguments provided in format -<char> as its own parameters which results in errors in execution.  Example 1: call: >bin/flink info myJarFile.jar -f flink -i <filepath> -m 1 error: Unrecognized option: -f  Example 2: Job myJarFile.jar is uploaded to web submission client flink parameter box is empty program arguments box: -f flink -i <filepath> -m 1 error:  An unexpected error occurred: Unrecognized option: -f org.apache.flink.client.cli.CliArgsException: Unrecognized option: -f at org.apache.flink.client.cli.CliFrontendParser.parseInfoCommand(CliFrontendParser.java:296) at org.apache.flink.client.CliFrontend.info(CliFrontend.java:376) at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:983) at org.apache.flink.client.web.JobSubmissionServlet.doGet(JobSubmissionServlet.java:171) at javax.servlet.http.HttpServlet.service(HttpServlet.java:734) at javax.servlet.http.HttpServlet.service(HttpServlet.java:847) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:532) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:453) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:227) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:965) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:388) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:187) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:901) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:117) at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:47) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:113) at org.eclipse.jetty.server.Server.handle(Server.java:348) at org.eclipse.jetty.server.HttpConnection.handleRequest(HttpConnection.java:596) at org.eclipse.jetty.server.HttpConnection RequestHandler.headerComplete(HttpConnection.java:1048) at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:549) at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:211) at org.eclipse.jetty.server.HttpConnection.handle(HttpConnection.java:425) at org.eclipse.jetty.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:489) at org.eclipse.jetty.util.thread.QueuedThreadPool 2.run(QueuedThreadPool.java:436) at java.lang.Thread.run(Thread.java:745)  Execution of  >bin/flink run myJarFile.jar -f flink -i <filepath> -m 1   works perfectly fine", "A_clean_title": ["error", "while", "pars", "job", "argument", "pass", "by", "cliflink", "cli", "flink", "cli", "treat", "job", "argument", "provid", "format", "char", "as", "it", "own", "paramet", "which", "result", "error", "execut", "exampl", "call", "bin", "flink", "info", "myjarfil", "jar", "my", "jar", "file", "flink", "filepath", "error", "unrecogn", "option", "exampl", "job", "myjarfil", "jar", "my", "jar", "file", "upload", "web", "submiss", "client", "flink", "paramet", "box", "empti", "program", "argument", "box", "flink", "filepath", "error", "unexpect", "error", "occur", "unrecogn", "option", "org", "apach", "flink", "client", "cli", "cliargsexcept", "cli", "arg", "except", "unrecogn", "option", "at", "org", "apach", "flink", "client", "cli", "clifrontendpars", "parseinfocommand", "cli", "frontend", "parser", "pars", "info", "command", "clifrontendpars", "java:296", "cli", "frontend", "parser", "at", "org", "apach", "flink", "client", "clifrontend", "info", "cli", "frontend", "clifrontend", "java:376", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "parseparamet", "cli", "frontend", "pars", "paramet", "clifrontend", "java:983", "cli", "frontend", "at", "org", "apach", "flink", "client", "web", "jobsubmissionservlet", "doget", "job", "submiss", "servlet", "get", "jobsubmissionservlet", "java:171", "job", "submiss", "servlet", "at", "javax", "servlet", "http", "httpservlet", "servic", "http", "servlet", "httpservlet", "java:734", "http", "servlet", "at", "javax", "servlet", "http", "httpservlet", "servic", "http", "servlet", "httpservlet", "java:847", "http", "servlet", "at", "org", "eclips", "jetti", "servlet", "servlethold", "handl", "servlet", "holder", "servlethold", "java:532", "servlet", "holder", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "dohandl", "servlet", "handler", "handl", "servlethandl", "java:453", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "dohandl", "session", "handler", "handl", "sessionhandl", "java:227", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "dohandl", "context", "handler", "handl", "contexthandl", "java:965", "context", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "doscop", "servlet", "handler", "scope", "servlethandl", "java:388", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "doscop", "session", "handler", "scope", "sessionhandl", "java:187", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "doscop", "context", "handler", "scope", "contexthandl", "java:901", "context", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:117", "scope", "handler", "at", "org", "eclips", "jetti", "server", "handler", "handlerlist", "handl", "handler", "list", "handlerlist", "java:47", "handler", "list", "at", "org", "eclips", "jetti", "server", "handler", "handlerwrapp", "handl", "handler", "wrapper", "handlerwrapp", "java:113", "handler", "wrapper", "at", "org", "eclips", "jetti", "server", "server", "handl", "server", "java:348", "at", "org", "eclips", "jetti", "server", "httpconnect", "handlerequest", "http", "connect", "handl", "request", "httpconnect", "java:596", "http", "connect", "at", "org", "eclips", "jetti", "server", "httpconnect", "http", "connect", "requesthandl", "headercomplet", "request", "handler", "header", "complet", "httpconnect", "java:1048", "http", "connect", "at", "org", "eclips", "jetti", "http", "httpparser", "parsenext", "http", "parser", "pars", "next", "httpparser", "java:549", "http", "parser", "at", "org", "eclips", "jetti", "http", "httpparser", "parseavail", "http", "parser", "pars", "avail", "httpparser", "java:211", "http", "parser", "at", "org", "eclips", "jetti", "server", "httpconnect", "handl", "http", "connect", "httpconnect", "java:425", "http", "connect", "at", "org", "eclips", "jetti", "io", "nio", "selectchannelendpoint", "run", "select", "channel", "end", "point", "selectchannelendpoint", "java:489", "select", "channel", "end", "point", "at", "org", "eclips", "jetti", "util", "thread", "queuedthreadpool", "queu", "thread", "pool", "run", "queuedthreadpool", "java:436", "queu", "thread", "pool", "at", "java", "lang", "thread", "run", "thread", "java:745", "execut", "bin", "flink", "run", "myjarfil", "jar", "my", "jar", "file", "flink", "filepath", "work", "perfectli", "fine"], "B_title": "Fix argument parsing of CLI client INFO action", "B_clean_title": ["fix", "argument", "pars", "cli", "client", "info", "action"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Automated g4 rollback of changelist 53511956.", "B_clean_title": ["autom", "g4", "rollback", "changelist", "53511956"]},
{"A_title": "Statistics.setVarianceImpl makes getStandardDeviation produce NaNInvoking SummaryStatistics.setVarianceImpl(new Variance(true/false) makes getStandardDeviation produce NaN. The code to reproduce it:  int scores = 1 2 3 4; SummaryStatistics stats = new SummaryStatistics(); stats.setVarianceImpl(new Variance(false)); //use population variance for(int i : scores)    stats.addValue(i);  double sd = stats.getStandardDeviation(); System.out.println(sd);   A workaround suggested by Mikkel is:    double sd = FastMath.sqrt(stats.getSecondMoment() / stats.getN());", "A_clean_title": ["statist", "setvarianceimpl", "set", "varianc", "impl", "make", "getstandarddevi", "get", "standard", "deviat", "produc", "naninvok", "na", "invok", "summarystatist", "setvarianceimpl", "summari", "statist", "set", "varianc", "impl", "new", "varianc", "true", "fals", "make", "getstandarddevi", "get", "standard", "deviat", "produc", "nan", "na", "code", "reproduc", "it", "int", "score", "summarystatist", "summari", "statist", "stat", "new", "summarystatist", "summari", "statist", "stat", "setvarianceimpl", "set", "varianc", "impl", "new", "varianc", "fals", "use", "popul", "varianc", "int", "score", "stat", "addvalu", "add", "valu", "doubl", "sd", "stat", "getstandarddevi", "get", "standard", "deviat", "system", "out", "println", "sd", "workaround", "suggest", "by", "mikkel", "doubl", "sd", "fastmath", "sqrt", "fast", "math", "stat", "getsecondmo", "get", "second", "moment", "stat", "getn", "get"], "B_title": "Fixed errors in SummaryStatistics causing overriden statistics not to be updated if the supplied impls are commons-math classes.  JIRA: MATH-691.", "B_clean_title": ["fix", "error", "summarystatist", "summari", "statist", "caus", "overriden", "statist", "not", "updat", "suppli", "impl", "are", "common", "math", "class", "jira", "math", "691"]},
{"A_title": "NumberUtils does not handle Long Hex numbersNumberUtils.createLong() does not handle hex numbers but createInteger() handles hex and octal. This seems odd. NumberUtils.createNumber() assumes that hex numbers can only be Integer. Again why not handle bigger Hex numbers? == It is trivial to fix createLong() - just use Long.decode() instead of valueOf(). Its not clear why this was not done originally - the decode() method was added to both Integer and Long in Java 1.2. Fixing createNumber() is also fairly easy - if the hex string has more than 8 digits use Long. Should we allow for leading zeros in an Integer?  If not the length check is trivial.", "A_clean_title": ["numberutil", "number", "util", "not", "handl", "long", "hex", "numbersnumberutil", "createlong", "number", "number", "util", "creat", "long", "not", "handl", "hex", "number", "but", "createinteg", "creat", "integ", "handl", "hex", "octal", "thi", "seem", "odd", "numberutil", "createnumb", "number", "util", "creat", "number", "assum", "that", "hex", "number", "onli", "integ", "again", "whi", "not", "handl", "bigger", "hex", "number", "it", "trivial", "fix", "createlong", "creat", "long", "just", "use", "long", "decod", "instead", "valueof", "valu", "it", "not", "clear", "whi", "thi", "wa", "not", "done", "origin", "decod", "method", "wa", "ad", "both", "integ", "long", "java", "fix", "createnumb", "creat", "number", "also", "fairli", "easi", "hex", "string", "ha", "more", "than", "digit", "use", "long", "we", "allow", "lead", "zero", "integ", "not", "length", "check", "trivial"], "B_title": "NumberUtils does not handle Long Hex numbers", "B_clean_title": ["numberutil", "number", "util", "not", "handl", "long", "hex", "number"]},
{"A_title": "StrBuilder contains usages of thisBuf.length when they should use sizeWhile fixing LANG-294 I noticed that there are two other places in StrBuilder that reference thisBuf.length and unless Im mistaken they shouldnt.", "A_clean_title": ["strbuilder", "str", "builder", "contain", "usag", "thisbuf", "length", "thi", "buf", "when", "they", "use", "sizewhil", "size", "while", "fix", "lang", "294", "notic", "that", "there", "are", "two", "other", "place", "strbuilder", "str", "builder", "that", "refer", "thisbuf", "length", "thi", "buf", "unless", "im", "mistaken", "they", "shouldnt"], "B_title": "Fixng LANG-295 - thisBuf.length calls. There were two of the calls so Ive committed a unit test showing things are broken and a fix in both cases.", "B_clean_title": ["fixng", "lang", "295", "thisbuf", "length", "thi", "buf", "call", "there", "were", "two", "call", "so", "ive", "commit", "unit", "test", "show", "thing", "are", "broken", "fix", "both", "case"]},
{"A_title": "GammaDistribution cloning brokenSerializing a GammaDistribution and deserializing it does not result in a cloned distribution that produces the same samples. Cause: GammaDistribution inherits from AbstractRealDistribution which implements Serializable. AbstractRealDistribution has random in which we have a Well19937c instance which inherits from AbstractWell. AbstractWell implements Serializable. AbstractWell inherits from BitsStreamGenerator which is not Serializable but does have a private field nextGaussian. Solution: Make BitStreamGenerator implement Serializable as well. This probably affects other distributions as well.", "A_clean_title": ["gammadistribut", "gamma", "distribut", "clone", "brokenseri", "broken", "serial", "gammadistribut", "gamma", "distribut", "deseri", "it", "not", "result", "clone", "distribut", "that", "produc", "same", "sampl", "caus", "gammadistribut", "gamma", "distribut", "inherit", "abstractrealdistribut", "abstract", "real", "distribut", "which", "implement", "serializ", "abstractrealdistribut", "abstract", "real", "distribut", "ha", "random", "which", "we", "have", "well19937c", "instanc", "which", "inherit", "abstractwel", "abstract", "well", "abstractwel", "abstract", "well", "implement", "serializ", "abstractwel", "abstract", "well", "inherit", "bitsstreamgener", "bit", "stream", "gener", "which", "not", "serializ", "but", "have", "privat", "field", "nextgaussian", "next", "gaussian", "solut", "make", "bitstreamgener", "bit", "stream", "gener", "implement", "serializ", "as", "well", "thi", "probabl", "affect", "other", "distribut", "as", "well"], "B_title": "Made BitsStreamGenerator class Serializable to allow cloning of subclasses. Added cloning test for all RealDistribution classes. Thanks to Dennis Hendriks.", "B_clean_title": ["made", "bitsstreamgener", "bit", "stream", "gener", "class", "serializ", "allow", "clone", "subclass", "ad", "clone", "test", "all", "realdistribut", "real", "distribut", "class", "thank", "denni", "hendrik"]},
{"A_title": "CryptoMapper does not work for applications having a home page that needs query parametersCryptoMapper.decryptUrl() should not return null for requests like http://myhost/MyApplication/app/?param=xx   As a possible fix one can replace  if (encryptedUrl.getSegments().isEmpty() && encryptedUrl.getQueryParameters().isEmpty())             return encryptedUrl;   with   if (encryptedUrl.getSegments().isEmpty())             return encryptedUrl;   but I suspect that the original test is intended to answer to another use case...", "A_clean_title": ["cryptomapp", "crypto", "mapper", "not", "work", "applic", "have", "home", "page", "that", "need", "queri", "parameterscryptomapp", "decrypturl", "paramet", "crypto", "mapper", "decrypt", "url", "not", "return", "null", "request", "like", "http", "myhost", "myapplic", "app", "my", "applic", "param=xx", "as", "possibl", "fix", "one", "replac", "encryptedurl", "getseg", "encrypt", "url", "get", "segment", "isempti", "empti", "encryptedurl", "getqueryparamet", "encrypt", "url", "get", "queri", "paramet", "isempti", "empti", "return", "encryptedurl", "encrypt", "url", "encryptedurl", "getseg", "encrypt", "url", "get", "segment", "isempti", "empti", "return", "encryptedurl", "encrypt", "url", "but", "suspect", "that", "origin", "test", "intend", "answer", "anoth", "use", "case"], "B_title": "CryptoMapper does not work for applications having a home page that needs query parameters", "B_clean_title": ["cryptomapp", "crypto", "mapper", "not", "work", "applic", "have", "home", "page", "that", "need", "queri", "paramet"]},
{"A_title": "PropertyIndex only considers the cost of a single indexed propertyThe existing PropertyIndex loops through the PropertyRestriction objects in the Filter and essentially only calculates the cost of the first indexed property. This isnt actually the first property in the query and Filter.propertyRestrictions is a HashMap.  More confusingly the plan for a query with multiple indexed properties outputs *all* indexed properties even though only the first one is used.  For queries with multiple indexed properties the cheapest property index should be used in all three relevant places: when calculating the cost when executing the query and when producing the plan.", "A_clean_title": ["propertyindex", "properti", "index", "onli", "consid", "cost", "singl", "index", "propertyth", "properti", "exist", "propertyindex", "properti", "index", "loop", "through", "propertyrestrict", "properti", "restrict", "object", "filter", "essenti", "onli", "calcul", "cost", "first", "index", "properti", "thi", "isnt", "actual", "first", "properti", "queri", "filter", "propertyrestrict", "properti", "restrict", "hashmap", "hash", "map", "more", "confusingli", "plan", "queri", "multipl", "index", "properti", "output", "all", "index", "properti", "even", "though", "onli", "first", "one", "use", "queri", "multipl", "index", "properti", "cheapest", "properti", "index", "use", "all", "three", "relev", "place", "when", "calcul", "cost", "when", "execut", "queri", "when", "produc", "plan"], "B_title": "PropertyIndex only considers the cost of a single indexed property", "B_clean_title": ["propertyindex", "properti", "index", "onli", "consid", "cost", "singl", "index", "properti"]},
{"A_title": "XPath failures for typed propertiesIt looks like there are some failures in xpath queries that expect a match only on properties of a certain type (which is to be inferred from the query)", "A_clean_title": ["xpath", "path", "failur", "type", "propertiesit", "properti", "it", "look", "like", "there", "are", "some", "failur", "xpath", "queri", "that", "expect", "match", "onli", "properti", "certain", "type", "which", "infer", "queri"], "B_title": "XPath failures for typed properties", "B_clean_title": ["xpath", "path", "failur", "type", "properti"]},
{"A_title": "PageParameters construced with keyValuePairs does not handle array valuesThe PageParameters constructor that takes a keyValuePairs argument does not convert repeated keys into an array of values.  For example:  code // specify three comma delimited values for the a parameters PageParameters parameters = new PageParameters(a=1a=2a=3); String a = parameters.getStringArray(a); assertEquals(3 a.length); // fails because a.length == 1 code  Issue first described on the users list: http://www.nabble.com/PageParameters-with-String-array-question-to22540294.html", "A_clean_title": ["pageparamet", "page", "paramet", "construc", "keyvaluepair", "key", "valu", "pair", "not", "handl", "array", "valuesth", "valu", "pageparamet", "page", "paramet", "constructor", "that", "take", "keyvaluepair", "key", "valu", "pair", "argument", "not", "convert", "repeat", "key", "into", "array", "valu", "exampl", "code", "specifi", "three", "comma", "delimit", "valu", "paramet", "pageparamet", "page", "paramet", "paramet", "new", "pageparamet", "page", "paramet", "a=1a=2a=3", "string", "paramet", "getstringarray", "get", "string", "array", "assertequ", "assert", "equal", "length", "fail", "becaus", "length", "code", "issu", "first", "describ", "user", "list", "http", "string", "array", "question", "nabbl", "to22540294", "html", "www", "com", "pageparamet", "page", "paramet"], "B_title": "fixed WICKET-2172 PageParameters construced with keyValuePairs does not handle array values Issue: WICKET-2172", "B_clean_title": ["fix", "wicket", "2172", "pageparamet", "page", "paramet", "construc", "keyvaluepair", "key", "valu", "pair", "not", "handl", "array", "valu", "issu", "wicket", "2172"]},
{"A_title": "Only assignment to this issues a dangerous use of the global this object warning.None", "A_clean_title": ["onli", "assign", "thi", "issu", "danger", "use", "global", "thi", "object", "warn", "none"], "B_title": "Change on 2010/05/27 by johnlenz", "B_clean_title": ["chang", "2010", "05", "27", "by", "johnlenz"]},
{"A_title": "Full-text search on the traversing index fails if the condition contains a slashA full-text search on the traversing index falls back to a sort of manual evaluation of results.  This is handled by the _FullTextTerm_ class and it appears that it passes the constraint text through a cleanup process where it strips most of the characters that are neither _Character.isLetterOrDigit(c)_ not in the list _+-:&_  Im not exactly sure where this list comes from but I see the / character is missing which causes a certain type of query to fail.  Example: code //*jcr:contains(. text/plain) code", "A_clean_title": ["full", "text", "search", "travers", "index", "fail", "condit", "contain", "slasha", "slash", "full", "text", "search", "travers", "index", "fall", "back", "sort", "manual", "evalu", "result", "thi", "handl", "by", "fulltextterm", "full", "text", "term", "class", "it", "appear", "that", "it", "pass", "constraint", "text", "through", "cleanup", "process", "where", "it", "strip", "most", "charact", "that", "are", "neither", "isletterordigit", "charact", "letter", "or", "digit", "not", "list", "im", "not", "exactli", "sure", "where", "thi", "list", "come", "but", "see", "charact", "miss", "which", "caus", "certain", "type", "queri", "fail", "exampl", "code", "jcr", "contain", "text", "plain", "code"], "B_title": "Full-text search on the traversing index fails if the condition contains a slash", "B_clean_title": ["full", "text", "search", "travers", "index", "fail", "condit", "contain", "slash"]},
{"A_title": "Correlated random vector generator fails (silently) when faced with zero rows in covariance matrixThe following three matrices (which are basically permutations of each other) produce different results when sampling a multi-variate Gaussian with the help of CorrelatedRandomVectorGenerator (sample covariances calculated in R based on 10000 samples): Array2DRowRealMatrix  0.00.00.00.00.0  0.00.0134455320.010394690.0098811560.010499559  0.00.010394690.0230066160.0081968560.010732709  0.00.0098811560.0081968560.0190238660.009210099  0.00.0104995590.0107327090.0092100990.019107243 > cov(data1)    V1 V2 V3 V4 V5 V1 0 0.000000000 0.00000000 0.000000000 0.000000000 V2 0 0.013383931 0.01034401 0.009913271 0.010506733 V3 0 0.010344006 0.02309479 0.008374730 0.010759306 V4 0 0.009913271 0.00837473 0.019005488 0.009187287 V5 0 0.010506733 0.01075931 0.009187287 0.019021483 Array2DRowRealMatrix  0.0134455320.010394690.00.0098811560.010499559  0.010394690.0230066160.00.0081968560.010732709  0.00.00.00.00.0 0.0098811560.0081968560.00.0190238660.009210099 0.0104995590.0107327090.00.0092100990.019107243  > cov(data2)             V1 V2 V3 V4 V5 V1 0.006922905 0.010507692 0 0.005817399 0.010330529 V2 0.010507692 0.023428918 0 0.008273152 0.010735568 V3 0.000000000 0.000000000 0 0.000000000 0.000000000 V4 0.005817399 0.008273152 0 0.004929843 0.009048759 V5 0.010330529 0.010735568 0 0.009048759 0.018683544   Array2DRowRealMatrix 0.0134455320.010394690.0098811560.010499559 0.010394690.0230066160.0081968560.010732709 0.0098811560.0081968560.0190238660.009210099 0.0104995590.0107327090.0092100990.019107243  > cov(data3)             V1          V2          V3          V4 V1 0.013445047 0.010478862 0.009955904 0.010529542 V2 0.010478862 0.022910522 0.008610113 0.011046353 V3 0.009955904 0.008610113 0.019250975 0.009464442 V4 0.010529542 0.011046353 0.009464442 0.019260317   Ive traced this back to the RectangularCholeskyDecomposition which does not seem to handle the second matrix very well (decompositions in the same order as the matrices above):  CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.00.00.00.00.0  0.07595774181220630.08761251884742390.00.00.0  0.077644436225135050.051328212214607520.119763818217912350.00.0  0.066629305279094040.055016617441145850.00166625065193079970.107493242076536320.0 0.138228951381394770.00.00.00.0 CorrelatedRandomVectorGenerator.getRank() = 5 CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.07595774181220630.0345127513794487240.0 0.077644436225135050.130299491646287460.0  0.00.00.0  0.066629305279094040.0232039366948556740.0 0.138228951381394770.00.0 CorrelatedRandomVectorGenerator.getRank() = 3 CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.07595774181220630.0345127513794487240.0339137482263482250.07303890149947785 0.077644436225135050.130299491646287460.00.0  0.066629305279094040.0232039366948556740.118515733132299450.0 0.138228951381394770.00.00.0 CorrelatedRandomVectorGenerator.getRank() = 4 Clearly the rank of each of these matrices should be 4. The first matrix does not lead to incorrect results but the second one does. Unfortunately I dont know enough about the Cholesky decomposition to find the flaw in the implementation and I could not find documentation for the rectangular variant (also not at the links provided in the javadoc).", "A_clean_title": ["correl", "random", "vector", "gener", "fail", "silent", "when", "face", "zero", "row", "covari", "matrixth", "matrix", "follow", "three", "matric", "which", "are", "basic", "permut", "each", "other", "produc", "differ", "result", "when", "sampl", "multi", "variat", "gaussian", "help", "correlatedrandomvectorgener", "correl", "random", "vector", "gener", "sampl", "covari", "calcul", "base", "10000", "sampl", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "00", "00", "00", "00", "00", "0134455320", "010394690", "0098811560", "010499559", "00", "010394690", "0230066160", "0081968560", "010732709", "00", "0098811560", "0081968560", "0190238660", "009210099", "00", "0104995590", "0107327090", "0092100990", "019107243", "cov", "data1", "v1", "v2", "v3", "v4", "v5", "v1", "000000000", "00000000", "000000000", "000000000", "v2", "013383931", "01034401", "009913271", "010506733", "v3", "010344006", "02309479", "008374730", "010759306", "v4", "009913271", "00837473", "019005488", "009187287", "v5", "010506733", "01075931", "009187287", "019021483", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "0134455320", "010394690", "00", "0098811560", "010499559", "010394690", "0230066160", "00", "0081968560", "010732709", "00", "00", "00", "00", "0098811560", "0081968560", "00", "0190238660", "009210099", "0104995590", "0107327090", "00", "0092100990", "019107243", "cov", "data2", "v1", "v2", "v3", "v4", "v5", "v1", "006922905", "010507692", "005817399", "010330529", "v2", "010507692", "023428918", "008273152", "010735568", "v3", "000000000", "000000000", "000000000", "000000000", "v4", "005817399", "008273152", "004929843", "009048759", "v5", "010330529", "010735568", "009048759", "018683544", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "0134455320", "010394690", "0098811560", "010499559", "010394690", "0230066160", "0081968560", "010732709", "0098811560", "0081968560", "0190238660", "009210099", "0104995590", "0107327090", "0092100990", "019107243", "cov", "data3", "v1", "v2", "v3", "v4", "v1", "013445047", "010478862", "009955904", "010529542", "v2", "010478862", "022910522", "008610113", "011046353", "v3", "009955904", "008610113", "019250975", "009464442", "v4", "010529542", "011046353", "009464442", "019260317", "ive", "trace", "thi", "back", "rectangularcholeskydecomposit", "rectangular", "choleski", "decomposit", "which", "not", "seem", "handl", "second", "matrix", "veri", "well", "decomposit", "same", "order", "as", "matric", "abov", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "00", "00", "00", "00", "array2d", "row", "real", "matrix0", "07595774181220630", "08761251884742390", "00", "00", "077644436225135050", "051328212214607520", "119763818217912350", "00", "066629305279094040", "055016617441145850", "00166625065193079970", "107493242076536320", "138228951381394770", "00", "00", "00", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "07595774181220630", "0345127513794487240", "array2d", "row", "real", "matrix0", "077644436225135050", "130299491646287460", "00", "00", "066629305279094040", "0232039366948556740", "138228951381394770", "00", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "07595774181220630", "0345127513794487240", "0339137482263482250", "07303890149947785", "array2d", "row", "real", "matrix0", "077644436225135050", "130299491646287460", "00", "066629305279094040", "0232039366948556740", "118515733132299450", "138228951381394770", "00", "00", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "clearli", "rank", "each", "these", "matric", "first", "matrix", "not", "lead", "incorrect", "result", "but", "second", "one", "unfortun", "dont", "know", "enough", "about", "choleski", "decomposit", "find", "flaw", "implement", "could", "not", "find", "document", "rectangular", "variant", "also", "not", "at", "link", "provid", "javadoc"], "B_title": "Fixed an error in rectangular Cholesky decomposition.", "B_clean_title": ["fix", "error", "rectangular", "choleski", "decomposit"]},
{"A_title": "POJO Type extractor bug with type variablesThe following program incorrectly states that there are duplicate getters/setters.  code public static class Vertex<K V>   private K key1; private K key2; private V value;  public Vertex()   public Vertex(K key V value)  this.key1 = key; this.key2 = key; this.value = value;   public Vertex(K key1 K key2 V value)  this.key1 = key1; this.key2 = key2; this.value = value;   public void setKey1(K key1)  this.key1 = key1;   public void setKey2(K key2)  this.key2 = key2;   public K getKey1()  return key1;   public K getKey2()  return key2;   public void setValue(V value)  this.value = value;   public V getValue()  return value;    public static void main(String args) throws Exception  ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();  DataSet<Vertex<Long Double>> set = env.fromElements(new Vertex<Long Double>(0L 3.0) new Vertex<Long Double>(1L 1.0));  set.print();  env.execute();  code  The exception is code Exception in thread main java.lang.IllegalStateException: Detected more than one getters at org.apache.flink.api.java.typeutils.TypeExtractor.isValidPojoField(TypeExtractor.java:981) at org.apache.flink.api.java.typeutils.TypeExtractor.analyzePojo(TypeExtractor.java:1025) at org.apache.flink.api.java.typeutils.TypeExtractor.privateGetForClass(TypeExtractor.java:937) at org.apache.flink.api.java.typeutils.TypeExtractor.privateGetForClass(TypeExtractor.java:863) at org.apache.flink.api.java.typeutils.TypeExtractor.privateGetForObject(TypeExtractor.java:1146) at org.apache.flink.api.java.typeutils.TypeExtractor.getForObject(TypeExtractor.java:1116) at org.apache.flink.api.java.ExecutionEnvironment.fromElements(ExecutionEnvironment.java:466) at test.Test.main(Test.java:74)  code", "A_clean_title": ["pojo", "type", "extractor", "bug", "type", "variablesth", "variabl", "follow", "program", "incorrectli", "state", "that", "there", "are", "duplic", "getter", "setter", "code", "public", "static", "class", "vertex", "privat", "key1", "privat", "key2", "privat", "valu", "public", "vertex", "public", "vertex", "key", "valu", "thi", "key1", "key", "thi", "key2", "key", "thi", "valu", "valu", "public", "vertex", "key1", "key2", "valu", "thi", "key1", "key1", "thi", "key2", "key2", "thi", "valu", "valu", "public", "void", "setkey1", "set", "key1", "key1", "thi", "key1", "key1", "public", "void", "setkey2", "set", "key2", "key2", "thi", "key2", "key2", "public", "getkey1", "get", "key1", "return", "key1", "public", "getkey2", "get", "key2", "return", "key2", "public", "void", "setvalu", "set", "valu", "valu", "thi", "valu", "valu", "public", "getvalu", "get", "valu", "return", "valu", "public", "static", "void", "main", "string", "arg", "throw", "except", "executionenviron", "execut", "environ", "env", "executionenviron", "getexecutionenviron", "execut", "environ", "get", "execut", "environ", "dataset", "data", "set", "vertex", "long", "doubl", "set", "env", "fromel", "element", "new", "vertex", "long", "doubl", "0l", "new", "vertex", "long", "doubl", "1l", "set", "print", "env", "execut", "code", "except", "code", "except", "thread", "main", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "detect", "more", "than", "one", "getter", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "isvalidpojofield", "type", "extractor", "valid", "pojo", "field", "typeextractor", "java:981", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "analyzepojo", "type", "extractor", "analyz", "pojo", "typeextractor", "java:1025", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "privategetforclass", "type", "extractor", "privat", "get", "class", "typeextractor", "java:937", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "privategetforclass", "type", "extractor", "privat", "get", "class", "typeextractor", "java:863", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "privategetforobject", "type", "extractor", "privat", "get", "object", "typeextractor", "java:1146", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "getforobject", "type", "extractor", "get", "object", "typeextractor", "java:1116", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "executionenviron", "fromel", "execut", "environ", "element", "executionenviron", "java:466", "execut", "environ", "at", "test", "test", "main", "test", "java:74", "code"], "B_title": "Fix incorrect getter / setter detection", "B_clean_title": ["fix", "incorrect", "getter", "setter", "detect"]},
{"A_title": "HomePageMapper ignores request to / with query string parametersIssue a request to http://host:port/contextpath/?something Wicket will log an error message like: ERROR - RequestCycle               - Unable to execute request. No suitable RequestHandler found. URL=?something  I think the reason is in HomePageMapper which maps to the configured home page only if there are no query parameters.  HomePageMapper.java: code public IRequestHandler mapRequest(Request request)  if (request.getUrl().getSegments().size() == 0 && request.getUrl().getQueryParameters().size() == 0)  return new RenderPageRequestHandler(new PageProvider(getContext().getHomePageClass()));  else  return null;   code", "A_clean_title": ["homepagemapp", "home", "page", "mapper", "ignor", "request", "queri", "string", "parametersissu", "paramet", "issu", "request", "http", "host", "port", "contextpath", "someth", "wicket", "will", "log", "error", "messag", "like", "error", "requestcycl", "request", "cycl", "unabl", "execut", "request", "no", "suitabl", "requesthandl", "request", "handler", "found", "url=", "someth", "think", "reason", "homepagemapp", "home", "page", "mapper", "which", "map", "configur", "home", "page", "onli", "there", "are", "no", "queri", "paramet", "homepagemapp", "java", "home", "page", "mapper", "code", "public", "irequesthandl", "request", "handler", "maprequest", "map", "request", "request", "request", "request", "geturl", "get", "url", "getseg", "get", "segment", "size", "request", "geturl", "get", "url", "getqueryparamet", "get", "queri", "paramet", "size", "return", "new", "renderpagerequesthandl", "render", "page", "request", "handler", "new", "pageprovid", "page", "provid", "getcontext", "get", "context", "gethomepageclass", "get", "home", "page", "class", "return", "null", "code"], "B_title": "HomePageMapper ignores request to / with query string parameters", "B_clean_title": ["homepagemapp", "home", "page", "mapper", "ignor", "request", "queri", "string", "paramet"]},
{"A_title": "Switched order of delete key and key in statements changes semanticNone", "A_clean_title": ["switch", "order", "delet", "key", "key", "statement", "chang", "semanticnon", "semant", "none"], "B_title": "Dont inline values over a delete. Fixes issue 773", "B_clean_title": ["dont", "inlin", "valu", "over", "delet", "fix", "issu", "773"]},
{"A_title": "Repository.findOne method fails to return row for row level secured entity type if first row isnt readableCode inspection  FindOne shouldnt check if first row of delegate is readable but find first readable row.", "A_clean_title": ["repositori", "findon", "find", "one", "method", "fail", "return", "row", "row", "level", "secur", "entiti", "type", "first", "row", "isnt", "readablecod", "readabl", "code", "inspect", "findon", "find", "one", "shouldnt", "check", "first", "row", "deleg", "readabl", "but", "find", "first", "readabl", "row"], "B_title": "Fix #7263 Row-level secured findOne: return first readable entity", "B_clean_title": ["fix", "7263", "row", "level", "secur", "findon", "find", "one", "return", "first", "readabl", "entiti"]},
{"A_title": "unexpected typed coverage of less than 100%None", "A_clean_title": ["unexpect", "type", "coverag", "less", "than", "100", "none"], "B_title": "Parameter types should be declared rather than inferred. This means that if the programmer re-assignes the argument to a different type they will get a type warning. Fixes issue 433.", "B_clean_title": ["paramet", "type", "declar", "rather", "than", "infer", "thi", "mean", "that", "programm", "re", "assign", "argument", "differ", "type", "they", "will", "get", "type", "warn", "fix", "issu", "433"]},
{"A_title": "Bugs in BrentOptimizerI apologize for having provided a buggy implementation of Brents optimization algorithm (class BrentOptimizer in package optimization.univariate). The unit tests didnt show that there was something wrong although (from the changes.xml file) I discovered that at the time Luc had noticed something weird in the implementations behaviour. Comparing with an implementation in Python I could figure out the fixes. Ill modify BrentOptimizer and add a test. I also propose to change the name of the unit test class from BrentMinimizerTest to BrentOptimizerTest.", "A_clean_title": ["bug", "brentoptimizeri", "brent", "optim", "apolog", "have", "provid", "buggi", "implement", "brent", "optim", "algorithm", "class", "brentoptim", "brent", "optim", "packag", "optim", "univari", "unit", "test", "didnt", "show", "that", "there", "wa", "someth", "wrong", "although", "chang", "xml", "file", "discov", "that", "at", "time", "luc", "had", "notic", "someth", "weird", "implement", "behaviour", "compar", "implement", "python", "could", "figur", "out", "fix", "ill", "modifi", "brentoptim", "brent", "optim", "add", "test", "also", "propos", "chang", "name", "unit", "test", "class", "brentminimizertest", "brent", "minim", "test", "brentoptimizertest", "brent", "optim", "test"], "B_title": "Another bug uncovered; all things being equal the code now behaves like the Puthon implementation. MATH-397: Modified BrentOptimizer following the changes in AbstractUnivariateRealOptimizer.", "B_clean_title": ["anoth", "bug", "uncov", "all", "thing", "be", "equal", "code", "now", "behav", "like", "puthon", "implement", "math", "397", "modifi", "brentoptim", "brent", "optim", "follow", "chang", "abstractunivariaterealoptim", "abstract", "univari", "real", "optim"]},
{"A_title": "Variable names prefixed with MSG_ cause error with advanced optimizationsNone", "A_clean_title": ["variabl", "name", "prefix", "msg", "caus", "error", "advanc", "optimizationsnon", "optim", "none"], "B_title": "Shut off i18n warnings if the user didnt ask for i18n. Fixes issue 1135 R=blickly", "B_clean_title": ["shut", "off", "i18n", "warn", "user", "didnt", "ask", "i18n", "fix", "issu", "1135", "r=blickli"]},
{"A_title": "feat: add support for $java.version in pom.xmlHi !  I have an issue creating a MavenLauncher for projects that have $java.version in their POM.xml .  Replacing it with  1.8 for example seems to work around. Thank you for your help !", "A_clean_title": ["feat", "add", "support", "java", "version", "pom", "xmlhi", "xml", "hi", "have", "issu", "creat", "mavenlaunch", "maven", "launcher", "project", "that", "have", "java", "version", "their", "pom", "xml", "replac", "it", "exampl", "seem", "work", "around", "thank", "you", "your", "help"], "B_title": "fix: parsing of java version not starting with 1. in pom.xml (#2729)  * Check if java.version contains a dot in pom.xml    * cover all cases and added an Assert in MavenLauncherTest    * (style) added a missing whitespace    fix #2714", "B_clean_title": ["fix", "pars", "java", "version", "not", "start", "pom", "xml", "2729", "check", "java", "version", "contain", "dot", "pom", "xml", "cover", "all", "case", "ad", "assert", "mavenlaunchertest", "maven", "launcher", "test", "style", "ad", "miss", "whitespac", "fix", "2714"]},
{"A_title": "RepositorySidegrade: oak-segment to oak-segment-tar should migrate checkpoint infoThe sidegrade from oak-segment to oak-segment-tar should also take care of moving the checkpoint data and meta. This will save a very expensive full-reindex.", "A_clean_title": ["repositorysidegrad", "repositori", "sidegrad", "oak", "segment", "oak", "segment", "tar", "migrat", "checkpoint", "infoth", "info", "sidegrad", "oak", "segment", "oak", "segment", "tar", "also", "take", "care", "move", "checkpoint", "data", "meta", "thi", "will", "save", "veri", "expens", "full", "reindex"], "B_title": "segment to segment-tar should migrate checkpoint info", "B_clean_title": ["segment", "segment", "tar", "migrat", "checkpoint", "info"]},
{"A_title": "AnnotationRevisionMetadata throws ClassCastException DATACMNS-1173opened and commented  AnnotationRevisionMetadata throws ClassCastException at line 90 :  Most likely leftovers during migration to  java.util.Optional   Affects: 2.0 RC3 (Kay)", "A_clean_title": ["annotationrevisionmetadata", "annot", "revis", "metadata", "throw", "classcastexcept", "class", "cast", "except", "datacmn", "1173open", "comment", "annotationrevisionmetadata", "annot", "revis", "metadata", "throw", "classcastexcept", "class", "cast", "except", "at", "line", "90", "most", "like", "leftov", "dure", "migrat", "java", "util", "option", "affect", "rc3", "kay"], "B_title": "DATACMNS-1173 - Fixed value lookup of AnnotationRevisionMetadata.  Fixed handling of absent values. Minor refactorings. More unit tests.", "B_clean_title": ["datacmn", "1173", "fix", "valu", "lookup", "annotationrevisionmetadata", "annot", "revis", "metadata", "fix", "handl", "absent", "valu", "minor", "refactor", "more", "unit", "test"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "source/org/jfree/data/time/TimeSeries.java (createCopy(RegularTimePeriod RegularTimePeriod)): Handle empty range.", "B_clean_title": ["java", "sourc", "org", "jfree", "data", "time", "timeseri", "time", "seri", "createcopi", "creat", "copi", "regulartimeperiod", "regular", "time", "period", "regulartimeperiod", "regular", "time", "period", "handl", "empti", "rang"]},
{"A_title": "GaussianFitter Unexpectedly Throws NotStrictlyPositiveExceptionRunning the following:      double observations =            1.1143831578403364E-29       4.95281403484594E-28       1.1171347211930288E-26       1.7044813962636277E-25       1.9784716574832164E-24       1.8630236407866774E-23       1.4820532905097742E-22       1.0241963854632831E-21       6.275077366673128E-21       3.461808994532493E-20       1.7407124684715706E-19       8.056687953553974E-19       3.460193945992071E-18       1.3883326374011525E-17       5.233894983671116E-17       1.8630791465263745E-16       6.288759227922111E-16       2.0204433920597856E-15       6.198768938576155E-15       1.821419346860626E-14       5.139176445538471E-14       1.3956427429045787E-13       3.655705706448139E-13       9.253753324779779E-13       2.267636001476696E-12       5.3880460095836855E-12       1.2431632654852931E-11      ;        GaussianFitter g =      new GaussianFitter(new LevenbergMarquardtOptimizer());          for (int index = 0; index < 27; index++)          g.addObservedPoint(index observationsindex);             g.fit();  Results in:  org.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than or equal to the minimum (0) at org.apache.commons.math.analysis.function.Gaussian Parametric.validateParameters(Gaussian.java:184) at org.apache.commons.math.analysis.function.Gaussian Parametric.value(Gaussian.java:129)   Im guessing the initial guess for sigma is off.", "A_clean_title": ["gaussianfitt", "gaussian", "fitter", "unexpectedli", "throw", "notstrictlypositiveexceptionrun", "not", "strictli", "posit", "except", "run", "follow", "doubl", "observ", "29", "1143831578403364e", "28", "95281403484594e", "26", "1171347211930288e", "25", "7044813962636277e", "24", "9784716574832164e", "23", "8630236407866774e", "22", "4820532905097742e", "21", "0241963854632831e", "21", "275077366673128e", "20", "461808994532493e", "19", "7407124684715706e", "19", "056687953553974e", "18", "460193945992071e", "17", "3883326374011525e", "17", "233894983671116e", "16", "8630791465263745e", "16", "288759227922111e", "15", "0204433920597856e", "15", "198768938576155e", "14", "821419346860626e", "14", "139176445538471e", "13", "3956427429045787e", "13", "655705706448139e", "13", "253753324779779e", "12", "267636001476696e", "12", "3880460095836855e", "11", "2431632654852931e", "gaussianfitt", "gaussian", "fitter", "new", "gaussianfitt", "gaussian", "fitter", "new", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "int", "index", "index", "27", "index++", "addobservedpoint", "add", "observ", "point", "index", "observationsindex", "fit", "result", "org", "apach", "common", "math", "except", "notstrictlypositiveexcept", "not", "strictli", "posit", "except", "277", "smaller", "than", "or", "equal", "minimum", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "validateparamet", "valid", "paramet", "gaussian", "java:184", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "valu", "gaussian", "java:129", "im", "guess", "initi", "guess", "sigma", "off"], "B_title": "Workaround exception generated when the optimizer tries invalid values for the sigma parameter. Added a method to allow the user to pass his own initial guess.", "B_clean_title": ["workaround", "except", "gener", "when", "optim", "tri", "invalid", "valu", "sigma", "paramet", "ad", "method", "allow", "user", "pass", "hi", "own", "initi", "guess"]},
{"A_title": "Return empty value for Iterables.I expect an Iterable to be mocked by default with an empty Iterable. I understand from the initial issue this behavior would be introduced in Mockito 2 but beta-8 still returns null. Could we return null for Iterables ?", "A_clean_title": ["return", "empti", "valu", "iter", "expect", "iter", "mock", "by", "default", "empti", "iter", "understand", "initi", "issu", "thi", "behavior", "would", "introduc", "mockito", "but", "beta", "still", "return", "null", "could", "we", "return", "null", "iter"], "B_title": "Adds empty iterable as a new empty value #210", "B_clean_title": ["add", "empti", "iter", "as", "new", "empti", "valu", "210"]},
{"A_title": "PageParameters#mergeWith may loose values of the other PPThe code at org.apache.wicket.request.mapper.parameter.PageParameters#mergeWith() looks like:  for (NamedPair curNamed : other.getAllNamed()) set(curNamed.getKey() curNamed.getValue());  may loose some values if other has a named parameter with several values.With the current code only the last name/value pair is preserved.", "A_clean_title": ["pageparamet", "page", "paramet", "mergewith", "merg", "may", "loos", "valu", "other", "ppthe", "pp", "code", "at", "org", "apach", "wicket", "request", "mapper", "paramet", "pageparamet", "page", "paramet", "mergewith", "merg", "look", "like", "namedpair", "name", "pair", "curnam", "cur", "name", "other", "getallnam", "get", "all", "name", "set", "curnam", "getkey", "cur", "name", "get", "key", "curnam", "getvalu", "cur", "name", "get", "valu", "may", "loos", "some", "valu", "other", "ha", "name", "paramet", "sever", "valu", "current", "code", "onli", "last", "name", "valu", "pair", "preserv"], "B_title": "keep multiple named values and absent indexed values", "B_clean_title": ["keep", "multipl", "name", "valu", "absent", "index", "valu"]},
{"A_title": "One of Variance.evaluate() methods does not work correctlyThe method org.apache.commons.math.stat.descriptive.moment.Variance.evaluate(double values double weights double mean int begin int length) does not work properly. Looks loke it ignores the length parameter and grabs the whole dataset. Similar method in Mean class seems to work. I did not check other methods taking the part of the array; they may have the same problem. Workaround: I had to shrink my arrays and use the method without the length.", "A_clean_title": ["one", "varianc", "evalu", "method", "not", "work", "correctlyth", "correctli", "method", "org", "apach", "common", "math", "stat", "descript", "moment", "varianc", "evalu", "doubl", "valu", "doubl", "weight", "doubl", "mean", "int", "begin", "int", "length", "not", "work", "properli", "look", "loke", "it", "ignor", "length", "paramet", "grab", "whole", "dataset", "similar", "method", "mean", "class", "seem", "work", "did", "not", "check", "other", "method", "take", "part", "array", "they", "may", "have", "same", "problem", "workaround", "had", "shrink", "my", "array", "use", "method", "without", "length"], "B_title": "Fixed array indexing error in Variance evaluate method for computing the weighted variance of an array segment.", "B_clean_title": ["fix", "array", "index", "error", "varianc", "evalu", "method", "comput", "weight", "varianc", "array", "segment"]},
{"A_title": "StringUtils replaceEach - Bug or Missing DocumentationThe following Test Case for replaceEach fails with a null pointer exception. I have expected that all StringUtils methods are null-friendly The use case is that i will stuff Values into the replacementList of which I do not want to check whether they are null. I admit the use case is not perfect because it is unclear what happens on the replace. I outlined three expectations in the test case of course only one should be met. If it is decided that none of them should be possible I propose to update the documentation with what happens when null is passed as replacement string  import static org.junit.Assert.assertEquals;  import org.apache.commons.lang.StringUtils; import org.junit.Test;   public class StringUtilsTest   @Test public void replaceEach() String original = Hello World!; String searchList = Hello World; String replacementList = Greetings null; String result = StringUtils.replaceEach(original searchList replacementList); assertEquals(Greetings ! result); //perhaps this is ok as well                 //assertEquals(Greetings World! result);                 //or even //assertEquals(Greetings null! result);", "A_clean_title": ["stringutil", "string", "util", "replaceeach", "replac", "each", "bug", "or", "miss", "documentationth", "document", "follow", "test", "case", "replaceeach", "replac", "each", "fail", "null", "pointer", "except", "have", "expect", "that", "all", "stringutil", "string", "util", "method", "are", "null", "friendli", "use", "case", "that", "will", "stuff", "valu", "into", "replacementlist", "replac", "list", "which", "not", "want", "check", "whether", "they", "are", "null", "admit", "use", "case", "not", "perfect", "becaus", "it", "unclear", "what", "happen", "replac", "outlin", "three", "expect", "test", "case", "cours", "onli", "one", "met", "it", "decid", "that", "none", "them", "possibl", "propos", "updat", "document", "what", "happen", "when", "null", "pass", "as", "replac", "string", "import", "static", "org", "junit", "assert", "assertequ", "assert", "equal", "import", "org", "apach", "common", "lang", "stringutil", "string", "util", "import", "org", "junit", "test", "public", "class", "stringutilstest", "string", "util", "test", "test", "public", "void", "replaceeach", "replac", "each", "string", "origin", "hello", "world", "string", "searchlist", "search", "list", "hello", "world", "string", "replacementlist", "replac", "list", "greet", "null", "string", "result", "stringutil", "replaceeach", "string", "util", "replac", "each", "origin", "searchlist", "search", "list", "replacementlist", "replac", "list", "assertequ", "assert", "equal", "greet", "result", "perhap", "thi", "ok", "as", "well", "assertequ", "assert", "equal", "greet", "world", "result", "or", "even", "assertequ", "assert", "equal", "greet", "null", "result"], "B_title": "Applying fix for LANG-552. StringUtils.replaceEach(String String String) no longer NPEs when null appears in the last String", "B_clean_title": ["appli", "fix", "lang", "552", "stringutil", "replaceeach", "string", "util", "replac", "each", "string", "string", "string", "no", "longer", "npe", "np", "es", "when", "null", "appear", "last", "string"]},
{"A_title": "DocumentNodeStore.dispatch() may pass null to NodeStateDiffThis is a regression introduced by OAK-2562. The dispatch method passes a null state if the node does not exist at a given revision.", "A_clean_title": ["documentnodestor", "dispatch", "document", "node", "store", "may", "pass", "null", "nodestatediffthi", "node", "state", "diff", "thi", "regress", "introduc", "by", "oak", "2562", "dispatch", "method", "pass", "null", "state", "node", "not", "exist", "at", "given", "revis"], "B_title": "DocumentNodeStore.dispatch() may pass null to NodeStateDiff", "B_clean_title": ["documentnodestor", "dispatch", "document", "node", "store", "may", "pass", "null", "nodestatediff", "node", "state", "diff"]},
{"A_title": "twod.PolygonsSet.getSize produces NullPointerException if BSPTree has no nodesorg.apache.commons.math3.geometry.euclidean.twod.PolygonsSet.getSize() uses a tree internally:  final BSPTree<Euclidean2D> tree = getTree(false);  However if that tree contains no data it seems that the reference returned is null which causes a subsequent NullPointerException.  Probably an exception with a message (tree has no data) would clarify that this is an API usage error.", "A_clean_title": ["twod", "polygonsset", "getsiz", "polygon", "set", "get", "size", "produc", "nullpointerexcept", "null", "pointer", "except", "bsptree", "bsp", "tree", "ha", "no", "nodesorg", "apach", "common", "math3", "geometri", "euclidean", "twod", "polygonsset", "getsiz", "polygon", "set", "get", "size", "use", "tree", "intern", "final", "bsptree", "bsp", "tree", "euclidean2d", "tree", "gettre", "get", "tree", "fals", "howev", "that", "tree", "contain", "no", "data", "it", "seem", "that", "refer", "return", "null", "which", "caus", "subsequ", "nullpointerexcept", "null", "pointer", "except", "probabl", "except", "messag", "tree", "ha", "no", "data", "would", "clarifi", "that", "thi", "api", "usag", "error"], "B_title": "Build properly empty polygons for equal min/max box.", "B_clean_title": ["build", "properli", "empti", "polygon", "equal", "min", "max", "box"]},
{"A_title": "Range check fails with IllegalArgumentExceptionRange.includes() fails with IllegalArgumentException when provided revision is from another cluster node:  noformat java.lang.IllegalArgumentException: Trying to compare revisions of different cluster ids: r142f43d2f0f-0-2 and r142f43d46fb-0-1 at org.apache.jackrabbit.oak.plugins.mongomk.Revision.compareRevisionTime(Revision.java:84) at org.apache.jackrabbit.oak.plugins.mongomk.Range.includes(Range.java:55) noformat  The IllegalArgumentException was introduced with OAK-1274.", "A_clean_title": ["rang", "check", "fail", "illegalargumentexceptionrang", "includ", "illeg", "argument", "except", "rang", "fail", "illegalargumentexcept", "illeg", "argument", "except", "when", "provid", "revis", "anoth", "cluster", "node", "noformat", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "tri", "compar", "revis", "differ", "cluster", "id", "r142f43d2f0f", "r142f43d46fb", "at", "org", "apach", "jackrabbit", "oak", "plugin", "mongomk", "revis", "comparerevisiontim", "compar", "revis", "time", "revis", "java:84", "at", "org", "apach", "jackrabbit", "oak", "plugin", "mongomk", "rang", "includ", "rang", "java:55", "noformat", "illegalargumentexcept", "illeg", "argument", "except", "wa", "introduc", "oak", "1274"], "B_title": "Range check fails with IllegalArgumentException", "B_clean_title": ["rang", "check", "fail", "illegalargumentexcept", "illeg", "argument", "except"]},
{"A_title": "Fix incorrect usage of ByteBufferWhile working on ACCUMULO-4098 I found one place where ByteBuffer was being used incorrectly.   Looking around the code I have found other places that are using ByteBuffer incorrectly.  Some of the problems I found are as follows :   * Calling ByteBuffer.array() without calling ByteBuffer.hasArray().  * Using ByteBuffer.position() or ByteBuffer.limit() without adding ByteBuffer.arrayOffset() when dealing with an array returned by ByteBuffer.array().  * Using ByteBuffer.arrayOffset() without adding ByteBuffer.position() when dealing with an array returned by ByteBuffer.array().", "A_clean_title": ["fix", "incorrect", "usag", "bytebufferwhil", "byte", "buffer", "while", "work", "accumulo", "4098", "found", "one", "place", "where", "bytebuff", "byte", "buffer", "wa", "be", "use", "incorrectli", "look", "around", "code", "have", "found", "other", "place", "that", "are", "bytebuff", "byte", "buffer", "incorrectli", "some", "problem", "found", "are", "as", "follow", "call", "bytebuff", "array", "byte", "buffer", "without", "call", "bytebuff", "hasarray", "byte", "buffer", "ha", "array", "bytebuff", "posit", "byte", "buffer", "or", "bytebuff", "limit", "byte", "buffer", "without", "ad", "bytebuff", "arrayoffset", "byte", "buffer", "array", "offset", "when", "deal", "array", "return", "by", "bytebuff", "array", "byte", "buffer", "bytebuff", "arrayoffset", "byte", "buffer", "array", "offset", "without", "ad", "bytebuff", "posit", "byte", "buffer", "when", "deal", "array", "return", "by", "bytebuff", "array", "byte", "buffer"], "B_title": "Fix incorrect usage of ByteBuffer", "B_clean_title": ["fix", "incorrect", "usag", "bytebuff", "byte", "buffer"]},
{"A_title": "fix some rawtype warnings in tests.None", "A_clean_title": ["fix", "some", "rawtyp", "warn", "test", "none"], "B_title": "Merge pull request #32 from alberskib/master", "B_clean_title": ["merg", "pull", "request", "32", "alberskib", "master"]},
{"A_title": "2.0 equal to -2.0The following test fails:  code     @Test     public void testMath1127()          Assert.assertFalse(Precision.equals(2.0 -2.0 1));      code", "A_clean_title": ["equal", "0the", "follow", "test", "fail", "code", "test", "public", "void", "testmath1127", "test", "math1127", "assert", "assertfals", "assert", "fals", "precis", "equal", "code"], "B_title": "Fixed overflow in Precision.equals with ulps.", "B_clean_title": ["fix", "overflow", "precis", "equal", "ulp"]},
{"A_title": "Incorrect rounding of floatpackage org.apache.commons.math3.util  example of usage of round functions of Precision class:  Precision.round(0.0f 2 BigDecimal.ROUND_UP) = 0.01 Precision.round((float)0.0 2 BigDecimal.ROUND_UP) = 0.01 Precision.round((float) 0.0 2) = 0.0 Precision.round(0.0 2 BigDecimal.ROUND_UP) = 0.0  Seems the reason is usage of extending float to double inside round functions and getting influence of memory trash as value.  I think same problem will be found at usage of other round modes.", "A_clean_title": ["incorrect", "round", "floatpackag", "org", "apach", "common", "math3", "util", "exampl", "usag", "round", "function", "precis", "class", "precis", "round", "0f", "bigdecim", "big", "decim", "round", "up", "01", "precis", "round", "float", "bigdecim", "big", "decim", "round", "up", "01", "precis", "round", "float", "precis", "round", "bigdecim", "big", "decim", "round", "up", "seem", "reason", "usag", "extend", "float", "doubl", "insid", "round", "function", "get", "influenc", "memori", "trash", "as", "valu", "think", "same", "problem", "will", "found", "at", "usag", "other", "round", "mode"], "B_title": "Fix Precision.round(float int int) for RoundingMode ROUND_UP. Thanks to  Oleksandr Muliarevych.", "B_clean_title": ["fix", "precis", "round", "float", "int", "int", "roundingmod", "round", "mode", "round", "up", "thank", "oleksandr", "muliarevych"]},
{"A_title": "ArgumentCaptor no longer working for varargsWhen upgrading 1.10.8 the verify passes but the getValue() fails with this error. One other piece of info came to light as a result of creating the MCVE - the test works fine if the Date is the only element passed for bindVariables. That is remove var1 from target and test code then the test runs fine under 1.9.5 and 1.10.8. Also it doesnt matter that the captor is for a Date. The same issue occurs if the parameter is of another type such as Integer.", "A_clean_title": ["argumentcaptor", "argument", "captor", "no", "longer", "work", "varargswhen", "vararg", "when", "upgrad", "10", "verifi", "pass", "but", "getvalu", "get", "valu", "fail", "thi", "error", "one", "other", "piec", "info", "came", "light", "as", "result", "creat", "mcve", "test", "work", "fine", "date", "onli", "element", "pass", "bindvari", "bind", "variabl", "that", "remov", "var1", "target", "test", "code", "then", "test", "run", "fine", "under", "10", "also", "it", "doesnt", "matter", "that", "captor", "date", "same", "issu", "occur", "paramet", "anoth", "type", "such", "as", "integ"], "B_title": "Fixes #188 : attempt to implement logic for varargs capture", "B_clean_title": ["fix", "188", "attempt", "implement", "logic", "vararg", "captur"]},
{"A_title": "MockAccumulo doesnt throw informative errorsUsers are unable to tell if an error has occurred and whether it is due to unimplemented features in MockAccumulo.", "A_clean_title": ["mockaccumulo", "mock", "accumulo", "doesnt", "throw", "inform", "errorsus", "error", "user", "are", "unabl", "tell", "error", "ha", "occur", "whether", "it", "due", "unimpl", "featur", "mockaccumulo", "mock", "accumulo"], "B_title": "employed more TableNotFound / TableExists Exceptions in TableOperations", "B_clean_title": ["employ", "more", "tablenotfound", "tabl", "not", "found", "tableexist", "tabl", "exist", "except", "tableoper", "tabl", "oper"]},
{"A_title": "Integer overflow in OpenMapRealMatrixcomputeKey() has an integer overflow. Since it is a sparse matrix this is quite easily encountered long before heap space is exhausted. The attached code demonstrates the problem which could potentially be a security vulnerability (for example if one was to use this matrix to store access control information).  Workaround: never create an OpenMapRealMatrix with more cells than are addressable with an int.", "A_clean_title": ["integ", "overflow", "openmaprealmatrixcomputekey", "open", "map", "real", "matrixcomput", "key", "ha", "integ", "overflow", "sinc", "it", "spars", "matrix", "thi", "quit", "easili", "encount", "long", "befor", "heap", "space", "exhaust", "attach", "code", "demonstr", "problem", "which", "could", "potenti", "secur", "vulner", "exampl", "one", "wa", "use", "thi", "matrix", "store", "access", "control", "inform", "workaround", "never", "creat", "openmaprealmatrix", "open", "map", "real", "matrix", "more", "cell", "than", "are", "address", "int"], "B_title": "Fixed an integer overflow in OpenMapRealMatrix.", "B_clean_title": ["fix", "integ", "overflow", "openmaprealmatrix", "open", "map", "real", "matrix"]},
{"A_title": "Use analytical function for UniformRealDistribution.inverseCumulativeProbabilityThe inverse CDF is currently solved by a root finding function. It would be much simpler (and faster) to use the analytical expression. This would save the user from having to set the inverseCumAccuracy correctly.  Ive attached a patch that implements this.", "A_clean_title": ["use", "analyt", "function", "uniformrealdistribut", "inversecumulativeprobabilityth", "uniform", "real", "distribut", "invers", "cumul", "probabl", "invers", "cdf", "current", "solv", "by", "root", "find", "function", "it", "would", "much", "simpler", "faster", "use", "analyt", "express", "thi", "would", "save", "user", "have", "set", "inversecumaccuraci", "invers", "cum", "accuraci", "correctli", "ive", "attach", "patch", "that", "implement", "thi"], "B_title": "Fixed inverse cumulative probability for uniform distribution.", "B_clean_title": ["fix", "invers", "cumul", "probabl", "uniform", "distribut"]},
{"A_title": "onBeforeRender() is called on components that are not allowed to renderpasted from the list:  Hi  I ran into an odd problem this week. A model fed to a ListView was calling service methods the current user wasnt allowed to use and I was wondering how that could happen. A panel far above this ListView in the hierarchy had been secured (using Shiro annotations but that turns out to not matter at all) and was not supposed to be rendered for this user. From this I had expected the ListView not to be rendered either but here it was trying to assemble itself in onBeforeRender and thus calling the forbidden service methods.  I investigated Component and friends for a bit and have found a potential problem.  internalBeforeRender() checks determineVisibility() before doing anything. So far so good. determineVisibility() then checks isRenderAllowed() so the applications IAuthorizationStrategy can block certain components. This is where it goes wrong though: isRenderAllowed() only looks at FLAG_IS_RENDER_ALLOWED for performance reasons and that flag hasnt been set yet! internalPrepareForRender() only calls setRenderAllowed() *after* beforeRender().  Due to this the supposedly secure panel was going through its own beforeRender and thus calling that ListViews beforeRender.  I think this can be a serious problem such as in my case described above. Id expect that if isActionAuthorized(RENDER) is false the secured component should basically never get to the beforeRender phase. My questions are now:  - Is this intentional? If yes please explain the reasoning behind it  because it isnt obvious to me.  - If not can we fix it? My intuitive suggestion would be to simply  move the call to setRenderAllowed() from the end of  internalBeforeRender() (prepareForRender in 1.4) to the beginning of  that method so beforeRender() can reliably look at that flag.  - If we can fix it when and where do we fix it? This hit me in 1.4  and looking at the code its still there in 1.5. Id *really* like it  fixed in the last 1.4 release and certainly in 1.5 given that this  has the potential to impact security.   Its not an API break but Im not sure whether the implications for  application behavior are tolerable for all existing applications. On  the other hand it seems to be a real security problem so maybe the  change is justified. Id like some core dev opinions please :-)  If this is in fact a bug Im of course willing to provide a ticket and a patch :-)  Thanks!  Carl-Eric www.wicketbuch.de", "A_clean_title": ["onbeforerend", "befor", "render", "call", "compon", "that", "are", "not", "allow", "renderpast", "list", "hi", "ran", "into", "odd", "problem", "thi", "week", "model", "fed", "listview", "list", "view", "wa", "call", "servic", "method", "current", "user", "wasnt", "allow", "use", "wa", "wonder", "how", "that", "could", "happen", "panel", "far", "abov", "thi", "listview", "list", "view", "hierarchi", "had", "been", "secur", "shiro", "annot", "but", "that", "turn", "out", "not", "matter", "at", "all", "wa", "not", "suppos", "render", "thi", "user", "thi", "had", "expect", "listview", "list", "view", "not", "render", "either", "but", "here", "it", "wa", "tri", "assembl", "itself", "onbeforerend", "befor", "render", "thu", "call", "forbidden", "servic", "method", "investig", "compon", "friend", "bit", "have", "found", "potenti", "problem", "internalbeforerend", "intern", "befor", "render", "check", "determinevis", "determin", "visibl", "befor", "do", "anyth", "so", "far", "so", "good", "determinevis", "determin", "visibl", "then", "check", "isrenderallow", "render", "allow", "so", "applic", "iauthorizationstrategi", "author", "strategi", "block", "certain", "compon", "thi", "where", "it", "goe", "wrong", "though", "isrenderallow", "render", "allow", "onli", "look", "at", "flag", "render", "allow", "perform", "reason", "that", "flag", "hasnt", "been", "set", "yet", "internalprepareforrend", "intern", "prepar", "render", "onli", "call", "setrenderallow", "set", "render", "allow", "after", "beforerend", "befor", "render", "due", "thi", "supposedli", "secur", "panel", "wa", "go", "through", "it", "own", "beforerend", "befor", "render", "thu", "call", "that", "listview", "list", "view", "beforerend", "befor", "render", "think", "thi", "seriou", "problem", "such", "as", "my", "case", "describ", "abov", "id", "expect", "that", "isactionauthor", "action", "author", "render", "fals", "secur", "compon", "basic", "never", "get", "beforerend", "befor", "render", "phase", "my", "question", "are", "now", "thi", "intent", "ye", "pleas", "explain", "reason", "behind", "it", "becaus", "it", "isnt", "obviou", "me", "not", "we", "fix", "it", "my", "intuit", "suggest", "would", "simpli", "move", "call", "setrenderallow", "set", "render", "allow", "end", "internalbeforerend", "intern", "befor", "render", "prepareforrend", "prepar", "render", "begin", "that", "method", "so", "beforerend", "befor", "render", "reliabl", "look", "at", "that", "flag", "we", "fix", "it", "when", "where", "we", "fix", "it", "thi", "hit", "me", "look", "at", "code", "it", "still", "there", "id", "realli", "like", "it", "fix", "last", "releas", "certainli", "given", "that", "thi", "ha", "potenti", "impact", "secur", "it", "not", "api", "break", "but", "im", "not", "sure", "whether", "implic", "applic", "behavior", "are", "toler", "all", "exist", "applic", "other", "hand", "it", "seem", "real", "secur", "problem", "so", "mayb", "chang", "justifi", "id", "like", "some", "core", "dev", "opinion", "pleas", "thi", "fact", "bug", "im", "cours", "will", "provid", "ticket", "patch", "thank", "carl", "eric", "www", "wicketbuch", "de"], "B_title": "block onbeforerender() from being called if auth strategy vetoes render action Issue: WICKET-4256", "B_clean_title": ["block", "onbeforerend", "be", "call", "auth", "strategi", "veto", "render", "action", "issu", "wicket", "4256"]},
{"A_title": "MockHttpServletResponse.addCookie(Cookie) adds duplicate cookiesorg.apache.wicket.protocol.http.mock.MockHttpServletResponse.addCookie(Cookie) makes a bad check whether the cookie to be added is already in the list of cookies. Since javax.servlet.http.Cookie doesnt implement #equals() cookies.remove(cookie) wont remove the previous cookie because the identity is different.  According to http://www.ietf.org/rfc/rfc2109.txt p.4.3.3 :   If a user agent receives a Set-Cookie response header whose NAME is    the same as a pre-existing cookie and whose Domain and Path    attribute values exactly (string) match those of a pre-existing    cookie the new cookie supersedes the old.  However if the Set-    Cookie has a value for Max-Age of zero the (old and new) cookie is    discarded.  Otherwise cookies accumulate until they expire (resources    permitting) at which time they are discarded.  I.e. the equality is on the name path and domain.", "A_clean_title": ["mockhttpservletrespons", "addcooki", "mock", "http", "servlet", "respons", "add", "cooki", "cooki", "add", "duplic", "cookiesorg", "apach", "wicket", "protocol", "http", "mock", "mockhttpservletrespons", "addcooki", "mock", "http", "servlet", "respons", "add", "cooki", "cooki", "make", "bad", "check", "whether", "cooki", "ad", "alreadi", "list", "cooki", "sinc", "javax", "servlet", "http", "cooki", "doesnt", "implement", "equal", "cooki", "remov", "cooki", "wont", "remov", "previou", "cooki", "becaus", "ident", "differ", "accord", "http", "ietf", "txt", "www", "org", "rfc", "rfc2109", "user", "agent", "receiv", "set", "cooki", "respons", "header", "whose", "name", "same", "as", "pre", "exist", "cooki", "whose", "domain", "path", "attribut", "valu", "exactli", "string", "match", "those", "pre", "exist", "cooki", "new", "cooki", "supersed", "old", "howev", "set", "cooki", "ha", "valu", "max", "age", "zero", "old", "new", "cooki", "discard", "otherwis", "cooki", "accumul", "until", "they", "expir", "resourc", "permit", "at", "which", "time", "they", "are", "discard", "equal", "name", "path", "domain"], "B_title": "MockHttpServletResponse.addCookie(Cookie) adds duplicate cookies", "B_clean_title": ["mockhttpservletrespons", "addcooki", "mock", "http", "servlet", "respons", "add", "cooki", "cooki", "add", "duplic", "cooki"]},
{"A_title": "SQL-2 query parser doesnt detect some illegal statementsThe SQL-2 query parser doesnt detect some illegal statements for example  code select * from nt:base where name =+ Hello select * from nt:base where name => Hello code  Both are currently interpreted as name = Hello which is wrong.", "A_clean_title": ["sql", "queri", "parser", "doesnt", "detect", "some", "illeg", "statementsth", "statement", "sql", "queri", "parser", "doesnt", "detect", "some", "illeg", "statement", "exampl", "code", "select", "nt", "base", "where", "name", "hello", "select", "nt", "base", "where", "name", "hello", "code", "both", "are", "current", "interpret", "as", "name", "hello", "which", "wrong"], "B_title": "SQL-2 query parser doesnt detect some illegal statements", "B_clean_title": ["sql", "queri", "parser", "doesnt", "detect", "some", "illeg", "statement"]},
{"A_title": "Exception when parsing erroneous jsdoc: /**@return @code foo bar   *    baz. */None", "A_clean_title": ["except", "when", "pars", "erron", "jsdoc", "return", "code", "foo", "bar", "baz", "none"], "B_title": "Fixes issue 919", "B_clean_title": ["fix", "issu", "919"]},
{"A_title": "Compiler should warn/error when instance methods are operated onNone", "A_clean_title": ["compil", "warn", "error", "when", "instanc", "method", "are", "oper", "onnon", "none"], "B_title": "Make sure that functions are called with a this type. Fixes issue 440", "B_clean_title": ["make", "sure", "that", "function", "are", "call", "thi", "type", "fix", "issu", "440"]},
{"A_title": "PutTokenImpl not thread safePutTokenImpl uses prefix increment on a static member to generate presumably unique identifiers. Prefix increment is not atomic though which might result in non unique ids being generated.", "A_clean_title": ["puttokenimpl", "put", "token", "impl", "not", "thread", "safeputtokenimpl", "safe", "put", "token", "impl", "use", "prefix", "increment", "static", "member", "gener", "presum", "uniqu", "identifi", "prefix", "increment", "not", "atom", "though", "which", "might", "result", "non", "uniqu", "id", "be", "gener"], "B_title": "PutTokenImpl not thread safe", "B_clean_title": ["puttokenimpl", "put", "token", "impl", "not", "thread", "safe"]},
{"A_title": "PathUtils#getDepth returns 1 for empty pathPathUtils#getDepths that the root path / has depth 0. however passing in a empty string is accepted and returns 1.  according to the API contract getDepth is counting the number of elements in the path which for  should IMO be zero.", "A_clean_title": ["pathutil", "path", "util", "getdepth", "get", "depth", "return", "empti", "pathpathutil", "path", "path", "util", "getdepth", "get", "depth", "that", "root", "path", "ha", "depth", "howev", "pass", "empti", "string", "accept", "return", "accord", "api", "contract", "getdepth", "get", "depth", "count", "number", "element", "path", "which", "imo", "zero"], "B_title": ": PathUtils#getDepth returns 1 for empty path", "B_clean_title": ["pathutil", "path", "util", "getdepth", "get", "depth", "return", "empti", "path"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Fix tests and code in UCE that do unsound optimizations in finally blocks.", "B_clean_title": ["fix", "test", "code", "uce", "that", "unsound", "optim", "final", "block"]},
{"A_title": "address-controller allows to create multiple addresses with the same spec.address valuereproducible via following steps:    create standard address space (reproducible with brokered as well)  deploy 3 addresses into this address space     all addresses were created successfully console shows only one of those addresses next address appears once previous one is removed.  And only first of multiple addresses has isReady attribute set to true in configMap  standard_anycast.json", "A_clean_title": ["address", "control", "allow", "creat", "multipl", "address", "same", "spec", "address", "valuereproduc", "via", "follow", "step", "creat", "standard", "address", "space", "reproduc", "broker", "as", "well", "deploy", "address", "into", "thi", "address", "space", "all", "address", "were", "creat", "success", "consol", "show", "onli", "one", "those", "address", "next", "address", "appear", "onc", "previou", "one", "remov", "onli", "first", "multipl", "address", "ha", "isreadi", "readi", "attribut", "set", "true", "configmap", "config", "map", "json", "standard", "anycast"], "B_title": "Enhance address validation in REST API  * Ensure no duplicate addresses within new addresses * Ensure no duplicate addresses in new addresses and existing addresses  This fixes #931", "B_clean_title": ["enhanc", "address", "valid", "rest", "api", "ensur", "no", "duplic", "address", "within", "new", "address", "ensur", "no", "duplic", "address", "new", "address", "exist", "address", "thi", "fix", "931"]},
{"A_title": "Inheritance layout excludes XML header from outputWhen using inheritance layout if the superclass (Layout class) has an ?xml header at the top its excluded from the rendering of subclasses if they have an associated html file. If the subclass has no .html file associated with it the ?xml header is preserved in the rendering output.  To reproduce: Create a SuperPage class extending WebPage. At the top of SuperPage.html put <?xml version=1.0 encoding=utf-8?> . Create two subclasses of SuperPage one with an HTML file and one without. View the sub pages. Notice when the one with an HTML file is rendered the xml header is excluded.  Expected: The ?xml header should always be preserved in the rendered output as its vital to the layout.", "A_clean_title": ["inherit", "layout", "exclud", "xml", "header", "outputwhen", "output", "when", "inherit", "layout", "superclass", "layout", "class", "ha", "xml", "header", "at", "top", "it", "exclud", "render", "subclass", "they", "have", "associ", "html", "file", "subclass", "ha", "no", "html", "file", "associ", "it", "xml", "header", "preserv", "render", "output", "reproduc", "creat", "superpag", "super", "page", "class", "extend", "webpag", "web", "page", "at", "top", "superpag", "html", "super", "page", "put", "xml", "version=1", "encoding=utf", "creat", "two", "subclass", "superpag", "super", "page", "one", "html", "file", "one", "without", "view", "sub", "page", "notic", "when", "one", "html", "file", "render", "xml", "header", "exclud", "expect", "xml", "header", "alway", "preserv", "render", "output", "as", "it", "vital", "layout"], "B_title": "fixed: Inheritance layout excludes XML header from output Issue: WICKET-2569", "B_clean_title": ["fix", "inherit", "layout", "exclud", "xml", "header", "output", "issu", "wicket", "2569"]},
{"A_title": "GaussianFitter Unexpectedly Throws NotStrictlyPositiveExceptionRunning the following:     double observations =         1.1143831578403364E-29       4.95281403484594E-28       1.1171347211930288E-26       1.7044813962636277E-25       1.9784716574832164E-24       1.8630236407866774E-23       1.4820532905097742E-22       1.0241963854632831E-21       6.275077366673128E-21       3.461808994532493E-20       1.7407124684715706E-19       8.056687953553974E-19       3.460193945992071E-18       1.3883326374011525E-17       5.233894983671116E-17       1.8630791465263745E-16       6.288759227922111E-16       2.0204433920597856E-15       6.198768938576155E-15       1.821419346860626E-14       5.139176445538471E-14       1.3956427429045787E-13       3.655705706448139E-13       9.253753324779779E-13       2.267636001476696E-12       5.3880460095836855E-12       1.2431632654852931E-11       ;     GaussianFitter g =      new GaussianFitter(new LevenbergMarquardtOptimizer());     for (int index = 0; index < 27; index++)          g.addObservedPoint(index observationsindex);             g.fit(); Results in: org.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than or equal to the minimum (0) at org.apache.commons.math.analysis.function.Gaussian Parametric.validateParameters(Gaussian.java:184) at org.apache.commons.math.analysis.function.Gaussian Parametric.value(Gaussian.java:129) Im guessing the initial guess for sigma is off.", "A_clean_title": ["gaussianfitt", "gaussian", "fitter", "unexpectedli", "throw", "notstrictlypositiveexceptionrun", "not", "strictli", "posit", "except", "run", "follow", "doubl", "observ", "29", "1143831578403364e", "28", "95281403484594e", "26", "1171347211930288e", "25", "7044813962636277e", "24", "9784716574832164e", "23", "8630236407866774e", "22", "4820532905097742e", "21", "0241963854632831e", "21", "275077366673128e", "20", "461808994532493e", "19", "7407124684715706e", "19", "056687953553974e", "18", "460193945992071e", "17", "3883326374011525e", "17", "233894983671116e", "16", "8630791465263745e", "16", "288759227922111e", "15", "0204433920597856e", "15", "198768938576155e", "14", "821419346860626e", "14", "139176445538471e", "13", "3956427429045787e", "13", "655705706448139e", "13", "253753324779779e", "12", "267636001476696e", "12", "3880460095836855e", "11", "2431632654852931e", "gaussianfitt", "gaussian", "fitter", "new", "gaussianfitt", "gaussian", "fitter", "new", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "int", "index", "index", "27", "index++", "addobservedpoint", "add", "observ", "point", "index", "observationsindex", "fit", "result", "org", "apach", "common", "math", "except", "notstrictlypositiveexcept", "not", "strictli", "posit", "except", "277", "smaller", "than", "or", "equal", "minimum", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "validateparamet", "valid", "paramet", "gaussian", "java:184", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "valu", "gaussian", "java:129", "im", "guess", "initi", "guess", "sigma", "off"], "B_title": "Workaround exception generated when the optimizer tries invalid values for the sigma parameter. Added a method to allow the user to pass his own initial guess.", "B_clean_title": ["workaround", "except", "gener", "when", "optim", "tri", "invalid", "valu", "sigma", "paramet", "ad", "method", "allow", "user", "pass", "hi", "own", "initi", "guess"]},
{"A_title": "Creating multiple checkpoint on same head revision overwrites previous entriesCurrently when a checkpoint is created in DocumentNodeStore then it is saved in form of currentHeadRev=>expiryTime. Now if multiple checkpoints are created where head revision has not changed then only the last one would be saved and previous entries would be overridden as revision is used as key  One fix would be to change the expiry time only if the new expiry time is greater than previous entry. However doing that safely in a cluster (check then save) is currently not possible with DocumentStore API as the modCount check if only supported for Nodes.", "A_clean_title": ["creat", "multipl", "checkpoint", "same", "head", "revis", "overwrit", "previou", "entriescurr", "entri", "current", "when", "checkpoint", "creat", "documentnodestor", "document", "node", "store", "then", "it", "save", "form", "currentheadrev=", "current", "head", "rev=", "expirytim", "expiri", "time", "now", "multipl", "checkpoint", "are", "creat", "where", "head", "revis", "ha", "not", "chang", "then", "onli", "last", "one", "would", "save", "previou", "entri", "would", "overridden", "as", "revis", "use", "as", "key", "one", "fix", "would", "chang", "expiri", "time", "onli", "new", "expiri", "time", "greater", "than", "previou", "entri", "howev", "do", "that", "safe", "cluster", "check", "then", "save", "current", "not", "possibl", "documentstor", "document", "store", "api", "as", "modcount", "mod", "count", "check", "onli", "support", "node"], "B_title": "Creating multiple checkpoint on same head revision overwrites previous entries", "B_clean_title": ["creat", "multipl", "checkpoint", "same", "head", "revis", "overwrit", "previou", "entri"]},
{"A_title": "goog.scope doesnt properly check declared functionsNone", "A_clean_title": ["goog", "scope", "doesnt", "properli", "check", "declar", "functionsnon", "function", "none"], "B_title": "Emit an error if there are dangling functions in the goog.scope fixes issue 737", "B_clean_title": ["emit", "error", "there", "are", "dangl", "function", "goog", "scope", "fix", "issu", "737"]},
{"A_title": "Overzealous optimization confuses variablesNone", "A_clean_title": ["overzeal", "optim", "confus", "variablesnon", "variabl", "none"], "B_title": "Fix inlining bug in https://code.google.com/p/closure-compiler/issues/detail?id=1053 Attempt 2 Fixes issue 1053 ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=50800167", "B_clean_title": ["fix", "inlin", "bug", "http", "googl", "compil", "issu", "detail", "code", "com", "closur", "id=1053", "attempt", "fix", "issu", "1053", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=50800167"]},
{"A_title": "Fix and then deprecate isSupportXxxInclusive in RealDistribution interfaceThe conclusion from 1 was never implemented. We should deprecate these properties from the RealDistribution interface but since removal will have to wait until 4.0 we should agree on a precise definition and fix the code to match it in the mean time.  The definition that I propose is that isSupportXxxInclusive means that when the density function is applied to the upper or lower bound of support returned by getSupportXxxBound a finite (i.e. not infinite) not NaN value is returned.  1 http://markmail.org/message/dxuxh7eybl7xejde", "A_clean_title": ["fix", "then", "deprec", "issupportxxxinclus", "support", "xxx", "inclus", "realdistribut", "real", "distribut", "interfaceth", "interfac", "conclus", "wa", "never", "implement", "we", "deprec", "these", "properti", "realdistribut", "real", "distribut", "interfac", "but", "sinc", "remov", "will", "have", "wait", "until", "we", "agre", "precis", "definit", "fix", "code", "match", "it", "mean", "time", "definit", "that", "propos", "that", "issupportxxxinclus", "support", "xxx", "inclus", "mean", "that", "when", "densiti", "function", "appli", "upper", "or", "lower", "bound", "support", "return", "by", "getsupportxxxbound", "get", "support", "xxx", "bound", "finit", "not", "infinit", "not", "nan", "na", "valu", "return", "http", "markmail", "org", "messag", "dxuxh7eybl7xejd"], "B_title": "Clarified definition of isSupportXxxBoundInclusive in RealDistribution interface made code consistent with the definition and deprecated these methods marking for removal in 4.0. JIRA: MATH-859", "B_clean_title": ["clarifi", "definit", "issupportxxxboundinclus", "support", "xxx", "bound", "inclus", "realdistribut", "real", "distribut", "interfac", "made", "code", "consist", "definit", "deprec", "these", "method", "mark", "remov", "jira", "math", "859"]},
{"A_title": "DefaultPropertyResolver does not respect JavaBean conventionsThe property name code should handle the isPropertyName pattern  if(getterName.startsWith(get))  name = getterName.substring(3 4).toLowerCase() + getterName.substring(4);  else  name = getterName.substring(2 3).toLowerCase() + getterName.substring(3);   Workaround: providing my own property resolver.", "A_clean_title": ["defaultpropertyresolv", "default", "properti", "resolv", "not", "respect", "javabean", "java", "bean", "conventionsth", "convent", "properti", "name", "code", "handl", "ispropertynam", "properti", "name", "pattern", "getternam", "startswith", "getter", "name", "start", "get", "name", "getternam", "substr", "getter", "name", "tolowercas", "lower", "case", "getternam", "substr", "getter", "name", "name", "getternam", "substr", "getter", "name", "tolowercas", "lower", "case", "getternam", "substr", "getter", "name", "workaround", "provid", "my", "own", "properti", "resolv"], "B_title": "DefaultPropertyResolver does not respect JavaBean conventions", "B_clean_title": ["defaultpropertyresolv", "default", "properti", "resolv", "not", "respect", "javabean", "java", "bean", "convent"]},
{"A_title": "multistep integrator start failure triggers NPEMultistep ODE integrators like Adams-Bashforth and Adams-Moulton require a starter procedure. If the starter integrator is not configured properly it will not create the necessary number of initial points and the multistep integrator will not be initialized correctly. This results in NullPointErException when the scaling array is referenced later on.  The following test case (with an intentionally wrong starter configuration) shows the problem.  code @Test public void testStartFailure()        TestProblem1 pb = new TestProblem1();       double minStep = 0.0001 * (pb.getFinalTime() - pb.getInitialTime());       double maxStep = pb.getFinalTime() - pb.getInitialTime();       double scalAbsoluteTolerance = 1.0e-6;       double scalRelativeTolerance = 1.0e-7;        MultistepIntegrator integ =           new AdamsBashforthIntegrator(4 minStep maxStep                                                             scalAbsoluteTolerance                                                             scalRelativeTolerance);       integ.setStarterIntegrator(new DormandPrince853Integrator(0.2 * (pb.getFinalTime() - pb.getInitialTime())                                                                 pb.getFinalTime() - pb.getInitialTime()                                                                 0.1 0.1));       TestProblemHandler handler = new TestProblemHandler(pb integ);       integ.addStepHandler(handler);       integ.integrate(pb                              pb.getInitialTime() pb.getInitialState()                              pb.getFinalTime() new doublepb.getDimension());       code  Failure to start the integrator should be detected and an appropriate exception should be triggered.", "A_clean_title": ["multistep", "integr", "start", "failur", "trigger", "npemultistep", "npe", "multistep", "ode", "integr", "like", "adam", "bashforth", "adam", "moulton", "requir", "starter", "procedur", "starter", "integr", "not", "configur", "properli", "it", "will", "not", "creat", "necessari", "number", "initi", "point", "multistep", "integr", "will", "not", "initi", "correctli", "thi", "result", "nullpointerexcept", "null", "point", "er", "except", "when", "scale", "array", "referenc", "later", "follow", "test", "case", "intent", "wrong", "starter", "configur", "show", "problem", "code", "test", "public", "void", "teststartfailur", "test", "start", "failur", "testproblem1", "test", "problem1", "pb", "new", "testproblem1", "test", "problem1", "doubl", "minstep", "min", "step", "0001", "pb", "getfinaltim", "get", "final", "time", "pb", "getinitialtim", "get", "initi", "time", "doubl", "maxstep", "max", "step", "pb", "getfinaltim", "get", "final", "time", "pb", "getinitialtim", "get", "initi", "time", "doubl", "scalabsolutetoler", "scal", "absolut", "toler", "0e", "doubl", "scalrelativetoler", "scal", "rel", "toler", "0e", "multistepintegr", "multistep", "integr", "integ", "new", "adamsbashforthintegr", "adam", "bashforth", "integr", "minstep", "min", "step", "maxstep", "max", "step", "scalabsolutetoler", "scal", "absolut", "toler", "scalrelativetoler", "scal", "rel", "toler", "integ", "setstarterintegr", "set", "starter", "integr", "new", "dormandprince853integr", "dormand", "prince853integr", "pb", "getfinaltim", "get", "final", "time", "pb", "getinitialtim", "get", "initi", "time", "pb", "getfinaltim", "get", "final", "time", "pb", "getinitialtim", "get", "initi", "time", "testproblemhandl", "test", "problem", "handler", "handler", "new", "testproblemhandl", "test", "problem", "handler", "pb", "integ", "integ", "addstephandl", "add", "step", "handler", "handler", "integ", "integr", "pb", "pb", "getinitialtim", "get", "initi", "time", "pb", "getinitialst", "get", "initi", "state", "pb", "getfinaltim", "get", "final", "time", "new", "doublepb", "getdimens", "get", "dimens", "code", "failur", "start", "integr", "detect", "appropri", "except", "trigger"], "B_title": "Detect start failures with multi-step ODE integrators.", "B_clean_title": ["detect", "start", "failur", "multi", "step", "ode", "integr"]},
{"A_title": "FileUpload writeToTempFile() method throws NPE for sessionless requestsI have created stateless page with stateless form containing FileUploadField however when I tried to post file to it NPE was thrown.  The issue is caused by method FileUpload#writeToTempFile() method trying to use session id as temp file prefix.   Workaround: create temp file manually and use method FileUpload#writeToFile( myTempFile)", "A_clean_title": ["fileupload", "file", "upload", "writetotempfil", "write", "temp", "file", "method", "throw", "npe", "sessionless", "requestsi", "request", "have", "creat", "stateless", "page", "stateless", "form", "contain", "fileuploadfield", "file", "upload", "field", "howev", "when", "tri", "post", "file", "it", "npe", "wa", "thrown", "issu", "caus", "by", "method", "fileupload", "file", "upload", "writetotempfil", "write", "temp", "file", "method", "tri", "use", "session", "id", "as", "temp", "file", "prefix", "workaround", "creat", "temp", "file", "manual", "use", "method", "fileupload", "file", "upload", "writetofil", "write", "file", "mytempfil", "my", "temp", "file"], "B_title": "Improving the FileUpload#writeToFile method to not rely on HTTP session existence Issue: WICKET-3715", "B_clean_title": ["improv", "fileupload", "file", "upload", "writetofil", "write", "file", "method", "not", "reli", "http", "session", "exist", "issu", "wicket", "3715"]},
{"A_title": "onremove() in RefreshingView.onPopulatefile a bug with a quickstart. onremove() should be called on all removed components.  -igor  On Fri Feb 18 2011 at 5:38 AM Benedikt Rothe <benedikt.rothe@qleo.de> wrote: > > Hi > > > > Are the existing children of a RepeatingView/RefreshingView being informed > > when > > the View is newly populated (RefreshingView.onPopulate). > > > > Id like to clean some internal references in this case. > > I tried: > > - aChild.onRemove is not called in this situation > > - aChild.setParent(null) is called. I treid to override setParent it. But > > setParent is private. > > > > Any suggestions? > > Benedikt", "A_clean_title": ["onremov", "refreshingview", "onpopulatefil", "refresh", "view", "populatefil", "bug", "quickstart", "onremov", "call", "all", "remov", "compon", "igor", "fri", "feb", "18", "2011", "at", "5:38", "am", "benedikt", "roth", "benedikt", "roth", "qleo", "de", "wrote", "hi", "are", "exist", "children", "repeatingview", "refreshingview", "repeat", "view", "refresh", "view", "be", "inform", "when", "view", "newli", "popul", "refreshingview", "onpopul", "refresh", "view", "popul", "id", "like", "clean", "some", "intern", "refer", "thi", "case", "tri", "achild", "onremov", "child", "remov", "not", "call", "thi", "situat", "achild", "setpar", "child", "set", "parent", "null", "call", "treid", "overrid", "setpar", "set", "parent", "it", "but", "setpar", "set", "parent", "privat", "ani", "suggest", "benedikt"], "B_title": "Issue: WICKET-3455", "B_clean_title": ["issu", "wicket", "3455"]},
{"A_title": "WebPage#onAfterRender erroneously reports missing headerIn WebPage#onAfterRender() theres a check wether a header was missing on a page and header contributions would be lost.  In the following case this check erroneously barks: - page A was requested - in As onBeforeRender() a RestartResponseAtInterceptPageException to page B is thrown - page As onAfterRender() is invoked in a finally block - processing continues with page B  Page As onAfterRender() complains about the missing header althought his page was never completely rendered.  IMHO theres a check missing in WebPage#onAfterRender():      if (getRequestCycle().getResponsePage() == this)  .....   Or is Page A not allowed to throw RestartResponseAtInterceptPageException in onBeforeRender() at all?", "A_clean_title": ["webpag", "web", "page", "onafterrend", "after", "render", "erron", "report", "miss", "headerin", "header", "webpag", "web", "page", "onafterrend", "after", "render", "there", "check", "wether", "header", "wa", "miss", "page", "header", "contribut", "would", "lost", "follow", "case", "thi", "check", "erron", "bark", "page", "wa", "request", "as", "onbeforerend", "befor", "render", "restartresponseatinterceptpageexcept", "restart", "respons", "at", "intercept", "page", "except", "page", "thrown", "page", "as", "onafterrend", "after", "render", "invok", "final", "block", "process", "continu", "page", "page", "as", "onafterrend", "after", "render", "complain", "about", "miss", "header", "althought", "hi", "page", "wa", "never", "complet", "render", "imho", "there", "check", "miss", "webpag", "web", "page", "onafterrend", "after", "render", "getrequestcycl", "get", "request", "cycl", "getresponsepag", "get", "respons", "page", "thi", "or", "page", "not", "allow", "throw", "restartresponseatinterceptpageexcept", "restart", "respons", "at", "intercept", "page", "except", "onbeforerend", "befor", "render", "at", "all"], "B_title": "check successful rendering of page before validating headers", "B_clean_title": ["check", "success", "render", "page", "befor", "valid", "header"]},
{"A_title": "When true setOneIndexedParameters still behaves as false in the links of the json response DATACMNS-563opened and commented When setting this to true the argument 1 accepted from the HTTP request is indeed considered to be the index of the first page but the json response still displays links as if the first page is indexed 0. For example requesting the page 3 gets the page 3 but the links are described ignoring the index start at 1. The prev link should show 2 and the next link should show 4. As it stands now the next page link has the same index as the current page in the request.     Affects: 1.8.2 (Dijkstra SR2)  Referenced from: pull request #267  Backported to:  2.0.3 (Kay SR3)  1.13.10 (Ingalls SR10)", "A_clean_title": ["when", "true", "setoneindexedparamet", "set", "one", "index", "paramet", "still", "behav", "as", "fals", "link", "json", "respons", "datacmn", "563open", "comment", "when", "set", "thi", "true", "argument", "accept", "http", "request", "inde", "consid", "index", "first", "page", "but", "json", "respons", "still", "display", "link", "as", "first", "page", "index", "exampl", "request", "page", "get", "page", "but", "link", "are", "describ", "ignor", "index", "start", "at", "prev", "link", "show", "next", "link", "show", "as", "it", "stand", "now", "next", "page", "link", "ha", "same", "index", "as", "current", "page", "request", "affect", "dijkstra", "sr2", "referenc", "pull", "request", "267", "backport", "kay", "sr3", "13", "10", "ingal", "sr10"], "B_title": "DATACMNS-563 - PagedResourcesAssembler now correctly forwards one-index settings to PageMetadata.  Original pull request: #267.", "B_clean_title": ["datacmn", "563", "pagedresourcesassembl", "page", "resourc", "assembl", "now", "correctli", "forward", "one", "index", "set", "pagemetadata", "page", "metadata", "origin", "pull", "request", "267"]},
{"A_title": "no warnings when @private prop is redeclared on subclassNone", "A_clean_title": ["no", "warn", "when", "privat", "prop", "redeclar", "subclassnon", "subclass", "none"], "B_title": "Emit a warning when a private property overrides another private property with both defined in the ctor. Fixes issue 254", "B_clean_title": ["emit", "warn", "when", "privat", "properti", "overrid", "anoth", "privat", "properti", "both", "defin", "ctor", "fix", "issu", "254"]},
{"A_title": "Missing toString hashCode and equals methods on BatchWriterConfigTried to test equality of two BatchWriterConfig objects found theyre missing all of the methods from Object that they should be implementing.", "A_clean_title": ["miss", "tostr", "string", "hashcod", "hash", "code", "equal", "method", "batchwriterconfigtri", "batch", "writer", "config", "tri", "test", "equal", "two", "batchwriterconfig", "batch", "writer", "config", "object", "found", "theyr", "miss", "all", "method", "object", "that", "they", "implement"], "B_title": "Add equals hashCode and toString to batchwriterconfig.", "B_clean_title": ["add", "equal", "hashcod", "hash", "code", "tostr", "string", "batchwriterconfig"]},
{"A_title": "DocumentNodeStore.dispose() may leave repository in an inconsistent stateThe repository may become inconsistent when a commit happens while the DocumentNodeStore is disposed.   The node store writes back pending _lastRevs and then unset the active flag in the clusterNodes collection. It is possible a commit gets through even after the _lastRevs had been updated and the active flag is cleared. This means the missing _lastRev updates will not be recovered on a restart or by another cluster node.", "A_clean_title": ["documentnodestor", "dispos", "document", "node", "store", "may", "leav", "repositori", "inconsist", "stateth", "state", "repositori", "may", "becom", "inconsist", "when", "commit", "happen", "while", "documentnodestor", "document", "node", "store", "dispos", "node", "store", "write", "back", "pend", "lastrev", "last", "rev", "then", "unset", "activ", "flag", "clusternod", "cluster", "node", "collect", "it", "possibl", "commit", "get", "through", "even", "after", "lastrev", "last", "rev", "had", "been", "updat", "activ", "flag", "clear", "thi", "mean", "miss", "lastrev", "last", "rev", "updat", "will", "not", "recov", "restart", "or", "by", "anoth", "cluster", "node"], "B_title": "DocumentNodeStore.dispose() may leave repository in an inconsistent state", "B_clean_title": ["documentnodestor", "dispos", "document", "node", "store", "may", "leav", "repositori", "inconsist", "state"]},
{"A_title": "Need range checks for elitismRate in ElitisticListPopulation constructors.There is a range check for setting the elitismRate via ElitisticListPopulations setElitismRate method but not via the constructors.", "A_clean_title": ["need", "rang", "check", "elitismr", "elit", "rate", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "there", "rang", "check", "set", "elitismr", "elit", "rate", "via", "elitisticlistpopul", "elitist", "list", "popul", "setelitismr", "set", "elit", "rate", "method", "but", "not", "via", "constructor"], "B_title": "Use same range check in ctor as in setter for ElitisticListPopulation. Thanks to Reid Hochstedler", "B_clean_title": ["use", "same", "rang", "check", "ctor", "as", "setter", "elitisticlistpopul", "elitist", "list", "popul", "thank", "reid", "hochstedl"]},
{"A_title": "Minified css/js gets compressedGiven an application with a resource reference to a minified script i.e. html5.js and html5.min.js.  When the ResourceRequestHandler responds  it will set compress to false if the resource reference was PackageResourceReference but it will not change compression if the resource reference was JavaScriptResourceReference.   PackageResourceReference handles minified resources more or less correctly (if they are minified they should not be further compressed) but this behavior is overwritten in its subclasses.", "A_clean_title": ["minifi", "css", "js", "get", "compressedgiven", "compress", "given", "applic", "resourc", "refer", "minifi", "script", "html5", "js", "html5", "min", "js", "when", "resourcerequesthandl", "resourc", "request", "handler", "respond", "it", "will", "set", "compress", "fals", "resourc", "refer", "wa", "packageresourcerefer", "packag", "resourc", "refer", "but", "it", "will", "not", "chang", "compress", "resourc", "refer", "wa", "javascriptresourcerefer", "java", "script", "resourc", "refer", "packageresourcerefer", "packag", "resourc", "refer", "handl", "minifi", "resourc", "more", "or", "less", "correctli", "they", "are", "minifi", "they", "not", "further", "compress", "but", "thi", "behavior", "overwritten", "it", "subclass"], "B_title": "", "B_clean_title": []},
{"A_title": "Overflow checks in Fraction multiply(int) / divide(int)The member methods multiply(int) / divide(int) in the class org.apache.commons.math3.fraction.Fraction do not have overflow checks.  code:java return new Fraction(numerator * i denominator); code  should be  code:java return new Fraction(ArithmeticUtils.mulAndCheck(numerator i) denominator); code  or considering the case gcd(i denominator) > 1  code:java return multiply(new Fraction(i)); code", "A_clean_title": ["overflow", "check", "fraction", "multipli", "int", "divid", "int", "member", "method", "multipli", "int", "divid", "int", "class", "org", "apach", "common", "math3", "fraction", "fraction", "not", "have", "overflow", "check", "code", "java", "return", "new", "fraction", "numer", "denomin", "code", "code", "java", "return", "new", "fraction", "arithmeticutil", "mulandcheck", "arithmet", "util", "mul", "check", "numer", "denomin", "code", "or", "consid", "case", "gcd", "denomin", "code", "java", "return", "multipli", "new", "fraction", "code"], "B_title": "", "B_clean_title": []},
{"A_title": "Node isNew() is false in case the node is removed and added in same commitWhen you remove a Node /path/a transiently and add one add /path/a again. The transiently added Node isNew() check will be false. code root.getNode(name).remove(); Node newNode = root.addNode(name); nowNode.isNew() => false code  The API says quote Returns true if this is a new item meaning that it exists only in transient storage on the Session and has not yet been saved. Within a transaction isNew on an Item may return false (because the item has been saved) even if that Item is not in persistent storage (because the transaction has not yet been committed).... quote", "A_clean_title": ["node", "isnew", "new", "fals", "case", "node", "remov", "ad", "same", "commitwhen", "commit", "when", "you", "remov", "node", "path", "transient", "add", "one", "add", "path", "again", "transient", "ad", "node", "isnew", "new", "check", "will", "fals", "code", "root", "getnod", "get", "node", "name", "remov", "node", "newnod", "new", "node", "root", "addnod", "add", "node", "name", "nownod", "isnew", "now", "node", "new", "fals", "code", "api", "say", "quot", "return", "true", "thi", "new", "item", "mean", "that", "it", "exist", "onli", "transient", "storag", "session", "ha", "not", "yet", "been", "save", "within", "transact", "isnew", "new", "item", "may", "return", "fals", "becaus", "item", "ha", "been", "save", "even", "that", "item", "not", "persist", "storag", "becaus", "transact", "ha", "not", "yet", "been", "commit", "quot"], "B_title": "Node isNew() is false in case the node is removed and added in same commit Treat a replaced builder as new enable test cases", "B_clean_title": ["node", "isnew", "new", "fals", "case", "node", "remov", "ad", "same", "commit", "treat", "replac", "builder", "as", "new", "enabl", "test", "case"]},
{"A_title": "POJO serialization NPENullPointer on serialization of a Date field:  Caused by: java.lang.RuntimeException: Error obtaining the sorted input: Thread SortMerger Reading Thread terminated due to an exception: null at org.apache.flink.runtime.operators.sort.UnilateralSortMerger.getIterator(UnilateralSortMerger.java:607) at org.apache.flink.runtime.operators.RegularPactTask.getInput(RegularPactTask.java:1132) at org.apache.flink.runtime.operators.CoGroupDriver.prepare(CoGroupDriver.java:98) at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:464) ... 3 more Caused by: java.io.IOException: Thread SortMerger Reading Thread terminated due to an exception: null at org.apache.flink.runtime.operators.sort.UnilateralSortMerger ThreadBase.run(UnilateralSortMerger.java:784) Caused by: java.lang.NullPointerException at org.apache.flink.api.common.typeutils.base.DateSerializer.deserialize(DateSerializer.java:72) at org.apache.flink.api.common.typeutils.base.DateSerializer.deserialize(DateSerializer.java:1) at org.apache.flink.api.java.typeutils.runtime.PojoSerializer.deserialize(PojoSerializer.java:487) at org.apache.flink.api.java.typeutils.runtime.TupleSerializer.deserialize(TupleSerializer.java:136) at org.apache.flink.api.java.typeutils.runtime.TupleSerializer.deserialize(TupleSerializer.java:30) at org.apache.flink.runtime.plugable.ReusingDeserializationDelegate.read(ReusingDeserializationDelegate.java:57) at org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer.getNextRecord(SpillingAdaptiveSpanningRecordDeserializer.java:111) at org.apache.flink.runtime.io.network.api.reader.AbstractRecordReader.getNextRecord(AbstractRecordReader.java:64) at org.apache.flink.runtime.io.network.api.reader.MutableRecordReader.next(MutableRecordReader.java:34) at org.apache.flink.runtime.operators.util.ReaderIterator.next(ReaderIterator.java:59) at org.apache.flink.runtime.operators.sort.UnilateralSortMerger ReadingThread.go(UnilateralSortMerger.java:958) at org.apache.flink.runtime.operators.sort.UnilateralSortMerger ThreadBase.run(UnilateralSortMerger.java:781)", "A_clean_title": ["pojo", "serial", "npenullpoint", "npe", "null", "pointer", "serial", "date", "field", "caus", "by", "java", "lang", "runtimeexcept", "runtim", "except", "error", "obtain", "sort", "input", "thread", "sortmerg", "sort", "merger", "read", "thread", "termin", "due", "except", "null", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "getiter", "unilater", "sort", "merger", "get", "iter", "unilateralsortmerg", "java:607", "unilater", "sort", "merger", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "getinput", "regular", "pact", "task", "get", "input", "regularpacttask", "java:1132", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "cogroupdriv", "prepar", "co", "group", "driver", "cogroupdriv", "java:98", "co", "group", "driver", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "run", "regular", "pact", "task", "regularpacttask", "java:464", "regular", "pact", "task", "more", "caus", "by", "java", "io", "ioexcept", "io", "except", "thread", "sortmerg", "sort", "merger", "read", "thread", "termin", "due", "except", "null", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "unilater", "sort", "merger", "threadbas", "run", "thread", "base", "unilateralsortmerg", "java:784", "unilater", "sort", "merger", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "flink", "api", "common", "typeutil", "base", "dateseri", "deseri", "date", "serial", "dateseri", "java:72", "date", "serial", "at", "org", "apach", "flink", "api", "common", "typeutil", "base", "dateseri", "deseri", "date", "serial", "dateseri", "java:1", "date", "serial", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "pojoseri", "deseri", "pojo", "serial", "pojoseri", "java:487", "pojo", "serial", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "tupleseri", "deseri", "tupl", "serial", "tupleseri", "java:136", "tupl", "serial", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "tupleseri", "deseri", "tupl", "serial", "tupleseri", "java:30", "tupl", "serial", "at", "org", "apach", "flink", "runtim", "plugabl", "reusingdeserializationdeleg", "read", "reus", "deseri", "deleg", "reusingdeserializationdeleg", "java:57", "reus", "deseri", "deleg", "at", "org", "apach", "flink", "runtim", "io", "network", "api", "serial", "spillingadaptivespanningrecorddeseri", "getnextrecord", "spill", "adapt", "span", "record", "deseri", "get", "next", "record", "spillingadaptivespanningrecorddeseri", "java:111", "spill", "adapt", "span", "record", "deseri", "at", "org", "apach", "flink", "runtim", "io", "network", "api", "reader", "abstractrecordread", "getnextrecord", "abstract", "record", "reader", "get", "next", "record", "abstractrecordread", "java:64", "abstract", "record", "reader", "at", "org", "apach", "flink", "runtim", "io", "network", "api", "reader", "mutablerecordread", "next", "mutabl", "record", "reader", "mutablerecordread", "java:34", "mutabl", "record", "reader", "at", "org", "apach", "flink", "runtim", "oper", "util", "readeriter", "next", "reader", "iter", "readeriter", "java:59", "reader", "iter", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "unilater", "sort", "merger", "readingthread", "go", "read", "thread", "unilateralsortmerg", "java:958", "unilater", "sort", "merger", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "unilater", "sort", "merger", "threadbas", "run", "thread", "base", "unilateralsortmerg", "java:781", "unilater", "sort", "merger"], "B_title": "Fix POJO deserialization for reuse objects with NULL fields", "B_clean_title": ["fix", "pojo", "deseri", "reus", "object", "null", "field"]},
{"A_title": "MathUtils.factorial(n) fails for n >= 17The result of MathUtils.factorial( n ) for n = 17 18 19 is wrong probably because of rounding errors in the double calculations. Replace the first line of MathUtilsTest.testFactorial() by         for (int i = 1; i <= 20; i++)  to check all valid arguments for the long result and see the failure. I suggest implementing a simple loop to multiply the long result - or even using a precomputed long - instead of adding logarithms.", "A_clean_title": ["mathutil", "factori", "math", "util", "fail", "17the", "result", "mathutil", "factori", "math", "util", "17", "18", "19", "wrong", "probabl", "becaus", "round", "error", "doubl", "calcul", "replac", "first", "line", "mathutilstest", "testfactori", "math", "util", "test", "test", "factori", "by", "int", "20", "i++", "check", "all", "valid", "argument", "long", "result", "see", "failur", "suggest", "implement", "simpl", "loop", "multipli", "long", "result", "or", "even", "precomput", "long", "instead", "ad", "logarithm"], "B_title": "Fixed error in factorial accuracy.  JIRA: MATH-240.", "B_clean_title": ["fix", "error", "factori", "accuraci", "jira", "math", "240"]},
{"A_title": "too large first step with embedded Runge-Kutta integrators (Dormand-Prince 8(53) ...)Adaptive step size integrators compute the first step size by themselves if it is not provided. For embedded Runge-Kutta type this step size is not checked against the integration range so if the integration range is extremely short this step size may evaluate the function out of the range (and in fact it tries afterward to go back and fails to stop). Gragg-Bulirsch-Stoer integrators do not have this problem the step size is checked and truncated if needed.", "A_clean_title": ["too", "larg", "first", "step", "embed", "rung", "kutta", "integr", "dormand", "princ", "53", "adapt", "step", "size", "integr", "comput", "first", "step", "size", "by", "themselv", "it", "not", "provid", "embed", "rung", "kutta", "type", "thi", "step", "size", "not", "check", "against", "integr", "rang", "so", "integr", "rang", "extrem", "short", "thi", "step", "size", "may", "evalu", "function", "out", "rang", "fact", "it", "tri", "afterward", "go", "back", "fail", "stop", "gragg", "bulirsch", "stoer", "integr", "not", "have", "thi", "problem", "step", "size", "check", "truncat", "need"], "B_title": "fixed too long first step in fixed Runge-Kutta integrators.", "B_clean_title": ["fix", "too", "long", "first", "step", "fix", "rung", "kutta", "integr"]},
{"A_title": "none standard PeriodType without year throws exceptionI tried to get a Period only for months and weeks with following code:  This throws following exception:  Even removing the year component with .withYearsRemoved() throws the same exception:", "A_clean_title": ["none", "standard", "periodtyp", "period", "type", "without", "year", "throw", "exceptioni", "except", "tri", "get", "period", "onli", "month", "week", "follow", "code", "thi", "throw", "follow", "except", "even", "remov", "year", "compon", "withyearsremov", "year", "remov", "throw", "same", "except"], "B_title": "Fix handling of PeriodType when either years or months missing", "B_clean_title": ["fix", "handl", "periodtyp", "period", "type", "when", "either", "year", "or", "month", "miss"]},
{"A_title": "VisibilityFilter does not catch BadArgumentExceptionIf an invalid column visibility makes it into the system then the VisibilityFilter may not handle it properly.   The accept method handles VisibilityParseException but some of the parse code throws a BadArgumentException which is not handled.", "A_clean_title": ["visibilityfilt", "visibl", "filter", "not", "catch", "badargumentexceptionif", "bad", "argument", "except", "invalid", "column", "visibl", "make", "it", "into", "system", "then", "visibilityfilt", "visibl", "filter", "may", "not", "handl", "it", "properli", "accept", "method", "handl", "visibilityparseexcept", "visibl", "pars", "except", "but", "some", "pars", "code", "throw", "badargumentexcept", "bad", "argument", "except", "which", "not", "handl"], "B_title": "made visibilityfilter catch badargument exception", "B_clean_title": ["made", "visibilityfilt", "catch", "badargu", "except"]},
{"A_title": "Blank map and no pointer when tracker is sending vibration alarmHello  Im very happy with the traccar platform but got a strange issue.  I got about 40 trackers connected but 2 is missing map and pointers. I noticed those 2 trackers is marked with ´vibration´ alarm and ignition OFF. Is it a bug or am I doing something wrong ? trackers is running on h02 protocol.  Thanks", "A_clean_title": ["blank", "map", "no", "pointer", "when", "tracker", "send", "vibrat", "alarmhello", "alarm", "hello", "im", "veri", "happi", "traccar", "platform", "but", "got", "strang", "issu", "got", "about", "40", "tracker", "connect", "but", "miss", "map", "pointer", "notic", "those", "tracker", "mark", "´vibration´", "alarm", "ignit", "off", "it", "bug", "or", "am", "do", "someth", "wrong", "tracker", "run", "h02", "protocol", "thank"], "B_title": "Better handle H02 X mode (fix #2780)", "B_clean_title": ["better", "handl", "h02", "mode", "fix", "2780"]},
{"A_title": "should use provided pullRequestTitle when creating the PRSummary  Related to  societe-generale/ci-droid#6 : new pullRequestTitle field needs to be taken into account when creating the PR Type of Issue  It is a :       Motivation  Current Behavior  the PR is created but takes the commitMessage as title : now that a dedicated field (pullRequestTitle) has been introduced in the model we should use it  Expected Behavior  use pullRequestTitle if provided - otherwise use the branch name as PR title  Steps to Reproduce (for bugs)  Your Environment    Version used: 1.0.5  OS and version:  Version of libs used:", "A_clean_title": ["use", "provid", "pullrequesttitl", "pull", "request", "titl", "when", "creat", "prsummari", "pr", "summari", "relat", "societ", "droid", "general", "ci", "new", "pullrequesttitl", "pull", "request", "titl", "field", "need", "taken", "into", "account", "when", "creat", "pr", "type", "issu", "it", "motiv", "current", "behavior", "pr", "creat", "but", "take", "commitmessag", "commit", "messag", "as", "titl", "now", "that", "dedic", "field", "pullrequesttitl", "pull", "request", "titl", "ha", "been", "introduc", "model", "we", "use", "it", "expect", "behavior", "use", "pullrequesttitl", "pull", "request", "titl", "provid", "otherwis", "use", "branch", "name", "as", "pr", "titl", "step", "reproduc", "bug", "your", "environ", "version", "use", "os", "version", "version", "lib", "use"], "B_title": "Issue15 - handle pull request title (#16)  * upgrading to ci-droid-api.version 1.0.4    * fixes https://github.com/societe-generale/ci-droid-tasks-consumer/issues/15", "B_clean_title": ["issue15", "handl", "pull", "request", "titl", "16", "upgrad", "ci", "droid", "api", "version", "fix", "http", "droid", "task", "general", "ci", "consum", "issu", "15", "github", "com", "societ"]},
{"A_title": "Stop receiving records with error  Last request was dispatched at...but no response as of ...Cancelling subscription and restarting. (KCL 2.0)I have a Kinesis stream of 2 shards with data published to it continuously. I use KCL 2.0.1 java to connect to the stream with polling (by populating retrievalConfig.retrievalSpecificConfig with a PollingConfig object). It works completely fine and keeps receiving messages from both shards for the first 10 minutes. After that it stops receiving any message even there is data continuously published to the stream. I leave the process running for 5 more minutes and issue persists. After that I restart the process and it starts receiving messages again from both shards but stops receiving messages again after running for 10 minutes. Issue happens repeatedly.  No throttling error is seen in logs. Instead following errors are seen in logs:   2018-10-19 14:12:43531 ERROR main shardId-000000000000: Last request was dispatched at 2018-10-19T03:12:07.772Z but no response as of 2018-10-19T03:12:43.531Z (PT35.759S).  Cancelling subscription and restarting. This kind of logs appear once for every 35 seconds for each shard. When it first appeared it happened to shardId-000000000000 and no more messages are received from this shard. Then it appeared for shardId-000000000001 as well and no more message is received from this shard.  To isolate the publishing factor Ive done another test where I first published lots of data to the stream without consuming. Then I stop publishing and start the consumer application. Same behaviours are observed.  Same behaviours are observed with KCL 2.0.3.  Ive extracted and attached the relevant application logs and error logs for reference.   app.log  error.log Any idea?", "A_clean_title": ["stop", "receiv", "record", "error", "last", "request", "wa", "dispatch", "at", "but", "no", "respons", "as", "cancel", "subscript", "restart", "kcl", "have", "kinesi", "stream", "shard", "data", "publish", "it", "continu", "use", "kcl", "java", "connect", "stream", "poll", "by", "popul", "retrievalconfig", "retrievalspecificconfig", "retriev", "config", "retriev", "specif", "config", "pollingconfig", "poll", "config", "object", "it", "work", "complet", "fine", "keep", "receiv", "messag", "both", "shard", "first", "10", "minut", "after", "that", "it", "stop", "receiv", "ani", "messag", "even", "there", "data", "continu", "publish", "stream", "leav", "process", "run", "more", "minut", "issu", "persist", "after", "that", "restart", "process", "it", "start", "receiv", "messag", "again", "both", "shard", "but", "stop", "receiv", "messag", "again", "after", "run", "10", "minut", "issu", "happen", "repeatedli", "no", "throttl", "error", "seen", "log", "instead", "follow", "error", "are", "seen", "log", "2018", "10", "19", "14:12:43531", "error", "main", "shardid", "000000000000", "shard", "id", "last", "request", "wa", "dispatch", "at", "2018", "10", "19t03:12:07", "772z", "but", "no", "respons", "as", "2018", "10", "19t03:12:43", "531z", "pt35", "759", "cancel", "subscript", "restart", "thi", "kind", "log", "appear", "onc", "everi", "35", "second", "each", "shard", "when", "it", "first", "appear", "it", "happen", "shardid", "000000000000", "shard", "id", "no", "more", "messag", "are", "receiv", "thi", "shard", "then", "it", "appear", "shardid", "000000000001", "shard", "id", "as", "well", "no", "more", "messag", "receiv", "thi", "shard", "isol", "publish", "factor", "ive", "done", "anoth", "test", "where", "first", "publish", "lot", "data", "stream", "without", "consum", "then", "stop", "publish", "start", "consum", "applic", "same", "behaviour", "are", "observ", "same", "behaviour", "are", "observ", "kcl", "ive", "extract", "attach", "relev", "applic", "log", "error", "log", "refer", "app", "log", "error", "log", "ani", "idea"], "B_title": "Remove a possible deadlock on polling queue fill (#462)  * Remove a possible deadlock on polling queue fill    Adding new items to the receive queue for the PrefetchRecordsPublisher  when at capacity would deadlock retrievals as it was already holding  a lock on this.    The method addArrivedRecordsInput did not need to be synchronized on  this as it didnt change any of the protected  state (requestedResponses).  There is a call to drainQueueForRequests  immediately after the addArrivedRecordsInput that will ensure newly  arrived data is dispatched.    This fixes #448    * Small fix on the reasoning comment    * Adjust the test to act more like the ShardConsumer    The ShardConsuemr which is the principal user of the  PrefetchRecordsPublisher uses RxJava to consume from publisher. This  test uses RxJava to consume and notifies the test thread once  MAX_ITEMS * 3 have been received. This ensures that we cycle through  the queue at least 3 times.    * Removed the upper limit on the retrievals    The way RxJavas request management makes it possible that more  requests than we might expect can happen.", "B_clean_title": ["remov", "possibl", "deadlock", "poll", "queue", "fill", "462", "remov", "possibl", "deadlock", "poll", "queue", "fill", "ad", "new", "item", "receiv", "queue", "prefetchrecordspublish", "prefetch", "record", "publish", "when", "at", "capac", "would", "deadlock", "retriev", "as", "it", "wa", "alreadi", "hold", "lock", "thi", "method", "addarrivedrecordsinput", "add", "arriv", "record", "input", "did", "not", "need", "synchron", "thi", "as", "it", "didnt", "chang", "ani", "protect", "state", "requestedrespons", "request", "respons", "there", "call", "drainqueueforrequest", "drain", "queue", "request", "immedi", "after", "addarrivedrecordsinput", "add", "arriv", "record", "input", "that", "will", "ensur", "newli", "arriv", "data", "dispatch", "thi", "fix", "448", "small", "fix", "reason", "comment", "adjust", "test", "act", "more", "like", "shardconsum", "shard", "consum", "shardconsuemr", "shard", "consuemr", "which", "princip", "user", "prefetchrecordspublish", "prefetch", "record", "publish", "use", "rxjava", "rx", "java", "consum", "publish", "thi", "test", "use", "rxjava", "rx", "java", "consum", "notifi", "test", "thread", "onc", "max", "item", "have", "been", "receiv", "thi", "ensur", "that", "we", "cycl", "through", "queue", "at", "least", "time", "remov", "upper", "limit", "retriev", "way", "rxjava", "rx", "java", "request", "manag", "make", "it", "possibl", "that", "more", "request", "than", "we", "might", "expect", "happen"]},
{"A_title": "PackageMapper - Could not resolve classIt seems that the PackageMapper try to resolve much more than it is supposed to do for instance if Ive 2 pages test1/TestPage1 and test2/TestPage2 then it tries to resolve test2/TestPage1 when I reach the page1...   WARN  - WicketObjects              - Could not resolve class com.mycompany.test2.TestPage1 java.lang.ClassNotFoundException: com.mycompany.test2.TestPage1     at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1714)     at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1559)     at java.lang.Class.forName0(Native Method)     at java.lang.Class.forName(Class.java:270)     at org.apache.wicket.application.AbstractClassResolver.resolveClass(AbstractClassResolver.java:108)     at org.apache.wicket.core.util.lang.WicketObjects.resolveClass(WicketObjects.java:71)     at org.apache.wicket.core.request.mapper.AbstractComponentMapper.getPageClass(AbstractComponentMapper.java:134)     at org.apache.wicket.core.request.mapper.PackageMapper.parseRequest(PackageMapper.java:152)     at org.apache.wicket.core.request.mapper.AbstractBookmarkableMapper.mapRequest(AbstractBookmarkableMapper.java:322)     at org.apache.wicket.request.mapper.CompoundRequestMapper.mapRequest(CompoundRequestMapper.java:152)     at org.apache.wicket.request.cycle.RequestCycle.resolveRequestHandler(RequestCycle.java:189)     at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:219)     at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:293)     at org.apache.wicket.protocol.http.WicketFilter.processRequestCycle(WicketFilter.java:261)     at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:203)     at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:284)", "A_clean_title": ["packagemapp", "packag", "mapper", "could", "not", "resolv", "classit", "class", "it", "seem", "that", "packagemapp", "packag", "mapper", "tri", "resolv", "much", "more", "than", "it", "suppos", "instanc", "ive", "page", "test1", "testpage1", "test", "page1", "test2", "testpage2", "test", "page2", "then", "it", "tri", "resolv", "test2", "testpage1", "test", "page1", "when", "reach", "page1", "warn", "wicketobject", "wicket", "object", "could", "not", "resolv", "class", "com", "mycompani", "test2", "testpage1", "test", "page1", "java", "lang", "classnotfoundexcept", "class", "not", "found", "except", "com", "mycompani", "test2", "testpage1", "test", "page1", "at", "org", "apach", "catalina", "loader", "webappclassload", "loadclass", "webapp", "class", "loader", "load", "class", "webappclassload", "java:1714", "webapp", "class", "loader", "at", "org", "apach", "catalina", "loader", "webappclassload", "loadclass", "webapp", "class", "loader", "load", "class", "webappclassload", "java:1559", "webapp", "class", "loader", "at", "java", "lang", "class", "forname0", "name0", "nativ", "method", "at", "java", "lang", "class", "fornam", "name", "class", "java:270", "at", "org", "apach", "wicket", "applic", "abstractclassresolv", "resolveclass", "abstract", "class", "resolv", "resolv", "class", "abstractclassresolv", "java:108", "abstract", "class", "resolv", "at", "org", "apach", "wicket", "core", "util", "lang", "wicketobject", "resolveclass", "wicket", "object", "resolv", "class", "wicketobject", "java:71", "wicket", "object", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractcomponentmapp", "getpageclass", "abstract", "compon", "mapper", "get", "page", "class", "abstractcomponentmapp", "java:134", "abstract", "compon", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "packagemapp", "parserequest", "packag", "mapper", "pars", "request", "packagemapp", "java:152", "packag", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractbookmarkablemapp", "maprequest", "abstract", "bookmark", "mapper", "map", "request", "abstractbookmarkablemapp", "java:322", "abstract", "bookmark", "mapper", "at", "org", "apach", "wicket", "request", "mapper", "compoundrequestmapp", "maprequest", "compound", "request", "mapper", "map", "request", "compoundrequestmapp", "java:152", "compound", "request", "mapper", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "resolverequesthandl", "request", "cycl", "resolv", "request", "handler", "requestcycl", "java:189", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:219", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:293", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequestcycl", "wicket", "filter", "process", "request", "cycl", "wicketfilt", "java:261", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:203", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:284", "wicket", "filter"], "B_title": "PackageMapper - Could not resolve class", "B_clean_title": ["packagemapp", "packag", "mapper", "could", "not", "resolv", "class"]},
{"A_title": "NEW VALUE is not a valid Serializable error during ajax form submissionI attached a quickstart with a test in TestHomePage#formSubmitsSuccessfully.  The test throws NEW VALUE is not a valid Serializable error when NEW VALUE string in value textField is submitted as a part of myForm ajax submission.  The problem is that a call to Objects#convertValue(nonNullNonArrayValue Object.class) will always return null if nonNullNonArrayValue is a value that is not null and not an array! Shouldnt it always return the first parameter when the second parameter is Object.class?  Sven on Wicket forum suggested to fix this as by adding another if-statement in Objects#convertValue() if (toType.isInstance(value))    result = toType.cast(value);   See the following forum thread for more information http://apache-wicket.1842946.n4.nabble.com/Issues-with-default-type-conversion-in-1-5-td4651857.html", "A_clean_title": ["new", "valu", "not", "valid", "serializ", "error", "dure", "ajax", "form", "submissioni", "submiss", "attach", "quickstart", "test", "testhomepag", "test", "home", "page", "formsubmitssuccess", "form", "submit", "success", "test", "throw", "new", "valu", "not", "valid", "serializ", "error", "when", "new", "valu", "string", "valu", "textfield", "text", "field", "submit", "as", "part", "myform", "my", "form", "ajax", "submiss", "problem", "that", "call", "object", "convertvalu", "convert", "valu", "nonnullnonarrayvalu", "non", "null", "non", "array", "valu", "object", "class", "will", "alway", "return", "null", "nonnullnonarrayvalu", "non", "null", "non", "array", "valu", "valu", "that", "not", "null", "not", "array", "shouldnt", "it", "alway", "return", "first", "paramet", "when", "second", "paramet", "object", "class", "sven", "wicket", "forum", "suggest", "fix", "thi", "as", "by", "ad", "anoth", "statement", "object", "convertvalu", "convert", "valu", "totyp", "isinst", "type", "instanc", "valu", "result", "totyp", "cast", "type", "valu", "see", "follow", "forum", "thread", "more", "inform", "http", "default", "type", "convers", "apach", "wicket", "1842946", "n4", "nabbl", "td4651857", "html", "com", "issu"], "B_title": "cast if possible", "B_clean_title": ["cast", "possibl"]},
{"A_title": "TraceProxy.trace should not throw InvocationTargetExceptionIn TraceProxy.trace there is the following code snippet: code         try            return method.invoke(instance args);          catch (Throwable ex)            ex.printStackTrace();           throw ex;          code When this is an InvocationTargetException it can really mess with the calling codes exception handling logic.", "A_clean_title": ["traceproxi", "trace", "trace", "proxi", "not", "throw", "invocationtargetexceptionin", "invoc", "target", "except", "traceproxi", "trace", "trace", "proxi", "there", "follow", "code", "snippet", "code", "tri", "return", "method", "invok", "instanc", "arg", "catch", "throwabl", "ex", "ex", "printstacktrac", "print", "stack", "trace", "throw", "ex", "code", "when", "thi", "invocationtargetexcept", "invoc", "target", "except", "it", "realli", "mess", "call", "code", "except", "handl", "logic"], "B_title": "InvocationTargetEx in TraceProxy", "B_clean_title": ["invocationtargetex", "invoc", "target", "ex", "traceproxi", "trace", "proxi"]},
{"A_title": "DataStoreBlobStore does not take into maxLastModifiedTime when fetching all chunksCurrently the DataStoreBlobStore has a pending TODO  code  @Override     public Iterator<String> getAllChunkIds(long maxLastModifiedTime) throws Exception          //TODO Ignores the maxLastModifiedTime currently.         return Iterators.transform(delegate.getAllIdentifiers() new Function<DataIdentifier String>()              @Nullable             @Override             public String apply(@Nullable DataIdentifier input)                  return input.toString();                      );      code  Due to this it currently returns all blobId. This would issue when new binary gets created while a blob gc is running as such binaries might be considered orphan and deleted", "A_clean_title": ["datastoreblobstor", "data", "store", "blob", "store", "not", "take", "into", "maxlastmodifiedtim", "max", "last", "modifi", "time", "when", "fetch", "all", "chunkscurr", "chunk", "current", "datastoreblobstor", "data", "store", "blob", "store", "ha", "pend", "todo", "code", "overrid", "public", "iter", "string", "getallchunkid", "get", "all", "chunk", "id", "long", "maxlastmodifiedtim", "max", "last", "modifi", "time", "throw", "except", "todo", "ignor", "maxlastmodifiedtim", "max", "last", "modifi", "time", "current", "return", "iter", "transform", "deleg", "getallidentifi", "get", "all", "identifi", "new", "function", "dataidentifi", "data", "identifi", "string", "nullabl", "overrid", "public", "string", "appli", "nullabl", "dataidentifi", "data", "identifi", "input", "return", "input", "tostr", "string", "code", "due", "thi", "it", "current", "return", "all", "blobid", "blob", "id", "thi", "would", "issu", "when", "new", "binari", "get", "creat", "while", "blob", "gc", "run", "as", "such", "binari", "might", "consid", "orphan", "delet"], "B_title": "- DataStoreBlobStore does not take into maxLastModifiedTime when fetching all chunks", "B_clean_title": ["datastoreblobstor", "data", "store", "blob", "store", "not", "take", "into", "maxlastmodifiedtim", "max", "last", "modifi", "time", "when", "fetch", "all", "chunk"]},
{"A_title": "Streaming iteration heads cannot be instantiatedIt looks that streaming jobs with iterations and dop > 1 do not work currently. From what I see when the TaskManager tries to instantiate a new RuntimeEnvironment for the iteration head tasks it fails since the following exception is being thrown:  java.lang.Exception: Failed to deploy the task Map (2/8) - execution #0 to slot SimpleSlot (0)(1) - 0e39fcabcab3e8543cc2d8320f9de783 - ALLOCATED/ALIVE: java.lang.Exception: Error setting up runtime environment: java.lang.RuntimeException: Could not register the given element broker slot is already occupied. at org.apache.flink.runtime.execution.RuntimeEnvironment.<init>(RuntimeEnvironment.java:174) at org.apache.flink.runtime.taskmanager.TaskManager.org apache flink runtime taskmanager TaskManager  submitTask(TaskManager.scala:432) ..... ..... Caused by: java.lang.RuntimeException: java.lang.RuntimeException: Could not register the given element broker slot is already occupied. at org.apache.flink.streaming.api.streamvertex.StreamIterationHead.setInputsOutputs(StreamIterationHead.java:64) at org.apache.flink.streaming.api.streamvertex.StreamVertex.registerInputOutput(StreamVertex.java:86) at org.apache.flink.runtime.execution.RuntimeEnvironment.<init>(RuntimeEnvironment.java:171) ... 20 more Caused by: java.lang.RuntimeException: Could not register the given element broker slot is already occupied. at org.apache.flink.runtime.iterative.concurrent.Broker.handIn(Broker.java:39) at org.apache.flink.streaming.api.streamvertex.StreamIterationHead.setInputsOutputs(StreamIterationHead.java:62)  The IterateTest passed since it is using a dop of 1 but for higher parallelism it fails. Also the IterateExample fails as well if you try to run it.   I will debug this once I find some time so any ideas of what could possible cause this are more than welcome.", "A_clean_title": ["stream", "iter", "head", "not", "instantiatedit", "instanti", "it", "look", "that", "stream", "job", "iter", "dop", "not", "work", "current", "what", "see", "when", "taskmanag", "task", "manag", "tri", "instanti", "new", "runtimeenviron", "runtim", "environ", "iter", "head", "task", "it", "fail", "sinc", "follow", "except", "be", "thrown", "java", "lang", "except", "fail", "deploy", "task", "map", "execut", "slot", "simpleslot", "simpl", "slot", "0e39fcabcab3e8543cc2d8320f9de783", "alloc", "aliv", "java", "lang", "except", "error", "set", "up", "runtim", "environ", "java", "lang", "runtimeexcept", "runtim", "except", "could", "not", "regist", "given", "element", "broker", "slot", "alreadi", "occupi", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "runtim", "environ", "init", "runtimeenviron", "java:174", "runtim", "environ", "at", "org", "apach", "flink", "runtim", "taskmanag", "taskmanag", "org", "task", "manag", "apach", "flink", "runtim", "taskmanag", "taskmanag", "task", "manag", "submittask", "submit", "task", "taskmanag", "scala:432", "task", "manag", "caus", "by", "java", "lang", "runtimeexcept", "runtim", "except", "java", "lang", "runtimeexcept", "runtim", "except", "could", "not", "regist", "given", "element", "broker", "slot", "alreadi", "occupi", "at", "org", "apach", "flink", "stream", "api", "streamvertex", "streamiterationhead", "setinputsoutput", "stream", "iter", "head", "set", "input", "output", "streamiterationhead", "java:64", "stream", "iter", "head", "at", "org", "apach", "flink", "stream", "api", "streamvertex", "streamvertex", "registerinputoutput", "stream", "vertex", "regist", "input", "output", "streamvertex", "java:86", "stream", "vertex", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "runtim", "environ", "init", "runtimeenviron", "java:171", "runtim", "environ", "20", "more", "caus", "by", "java", "lang", "runtimeexcept", "runtim", "except", "could", "not", "regist", "given", "element", "broker", "slot", "alreadi", "occupi", "at", "org", "apach", "flink", "runtim", "iter", "concurr", "broker", "handin", "hand", "broker", "java:39", "at", "org", "apach", "flink", "stream", "api", "streamvertex", "streamiterationhead", "setinputsoutput", "stream", "iter", "head", "set", "input", "output", "streamiterationhead", "java:62", "stream", "iter", "head", "iteratetest", "iter", "test", "pass", "sinc", "it", "dop", "but", "higher", "parallel", "it", "fail", "also", "iterateexampl", "iter", "exampl", "fail", "as", "well", "you", "tri", "run", "it", "will", "debug", "thi", "onc", "find", "some", "time", "so", "ani", "idea", "what", "could", "possibl", "caus", "thi", "are", "more", "than", "welcom"], "B_title": "streaming add parallel iteration test", "B_clean_title": ["stream", "add", "parallel", "iter", "test"]},
{"A_title": "UUID collision check is not does not work in transient spaceI think OAK-1037 broke the system view import.  test case: 1. create a new node with a uuid (referenceable or new user) 2. import systemview with IMPORT_UUID_COLLISION_REPLACE_EXISTING 3. save()  result: noformat javax.jcr.nodetype.ConstraintViolationException: OakConstraint0030: Uniqueness constraint violated at path / for one of the property in jcr:uuid having value e358efa4-89f5-3062-b10d-d7316b65649e noformat  expected: * imported content should replace the existing node - even in transient space.  note: * if you perform a save() after step 1 everything works.", "A_clean_title": ["uuid", "collis", "check", "not", "not", "work", "transient", "spacei", "space", "think", "oak", "1037", "broke", "system", "view", "import", "test", "case", "creat", "new", "node", "uuid", "referenc", "or", "new", "user", "import", "systemview", "import", "uuid", "collis", "replac", "exist", "save", "result", "noformat", "javax", "jcr", "nodetyp", "constraintviolationexcept", "constraint", "violat", "except", "oakconstraint0030", "oak", "constraint0030", "uniqu", "constraint", "violat", "at", "path", "one", "properti", "jcr", "uuid", "have", "valu", "e358efa4", "89f5", "3062", "b10d", "d7316b65649e", "noformat", "expect", "import", "content", "replac", "exist", "node", "even", "transient", "space", "note", "you", "perform", "save", "after", "step", "everyth", "work"], "B_title": ": UUID collision check is not does not work in transient space", "B_clean_title": ["uuid", "collis", "check", "not", "not", "work", "transient", "space"]},
{"A_title": "DiscreteDistribution.sample(int) may throw an exception if first element of singletons of sub-class typeCreating an array with Array.newInstance(singletons.get(0).getClass() sampleSize) in DiscreteDistribution.sample(int) is risky. An exception will be thrown if: * singleons.get(0) is of type T1 an sub-class of T and * DiscreteDistribution.sample() returns an object which is of type T but not of type T1.  To reproduce: code List<Pair<ObjectDouble>> list = new ArrayList<Pair<Object Double>>(); list.add(new Pair<Object Double>(new Object()  new Double(0))); list.add(new Pair<Object Double>(new Object()  new Double(1))); new DiscreteDistribution<Object>(list).sample(1); code  Attaching a patch.", "A_clean_title": ["discretedistribut", "sampl", "discret", "distribut", "int", "may", "throw", "except", "first", "element", "singleton", "sub", "class", "typecr", "type", "creat", "array", "array", "newinst", "new", "instanc", "singleton", "get", "getclass", "get", "class", "samples", "sampl", "size", "discretedistribut", "sampl", "discret", "distribut", "int", "riski", "except", "will", "thrown", "singleon", "get", "type", "t1", "sub", "class", "discretedistribut", "sampl", "discret", "distribut", "return", "object", "which", "type", "but", "not", "type", "t1", "reproduc", "code", "list", "pair", "objectdoubl", "object", "doubl", "list", "new", "arraylist", "array", "list", "pair", "object", "doubl", "list", "add", "new", "pair", "object", "doubl", "new", "object", "new", "doubl", "list", "add", "new", "pair", "object", "doubl", "new", "object", "new", "doubl", "new", "discretedistribut", "discret", "distribut", "object", "list", "sampl", "code", "attach", "patch"], "B_title": "Fixed creation of generic array.", "B_clean_title": ["fix", "creation", "gener", "array"]},
{"A_title": "StackOverflowError after form submit with a validation errorI was not able to find a cause or make a small quickstart but it has something to do with a form validation my workaround was to setDefaultFormProcessing(false) or not use required TextFields.  It can be reproduced on https://github.com/krasa/DevSupportApp/tree/stackOverflow  1) run StartVojtitkoDummy 2) go to http://localhost:8765/wicket/bookmarkable/krasa.release.frontend.TokenizationPage 3) click on Generate Release json button  - instead of SOE it should give a validation error probably even on fields which I would not want to validate but thats just because Ive made the page badly...     code java.lang.StackOverflowError: null ... at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.Component.internalRender(Component.java:2344) at org.apache.wicket.Component.render(Component.java:2307) at org.apache.wicket.ajax.XmlAjaxResponse.writeComponent(XmlAjaxResponse.java:128) at org.apache.wicket.ajax.AbstractAjaxResponse.writeComponents(AbstractAjaxResponse.java:218) at org.apache.wicket.ajax.AbstractAjaxResponse.writeTo(AbstractAjaxResponse.java:150) at org.apache.wicket.ajax.AjaxRequestHandler.respond(AjaxRequestHandler.java:359) at org.apache.wicket.request.cycle.RequestCycle HandlerExecutor.respond(RequestCycle.java:865) at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:64) at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:97) at org.apache.wicket.request.cycle.RequestCycle.execute(RequestCycle.java:265) at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:222) at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:293) at org.apache.wicket.protocol.ws.AbstractUpgradeFilter.processRequestCycle(AbstractUpgradeFilter.java:59) at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:203) at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:284) at org.eclipse.jetty.servlet.ServletHandler CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1125) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1059) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:497) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:248) at org.eclipse.jetty.io.AbstractConnection 2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:620) at org.eclipse.jetty.util.thread.QueuedThreadPool 3.ru code", "A_clean_title": ["stackoverflowerror", "stack", "overflow", "error", "after", "form", "submit", "valid", "errori", "error", "wa", "not", "abl", "find", "caus", "or", "make", "small", "quickstart", "but", "it", "ha", "someth", "form", "valid", "my", "workaround", "wa", "setdefaultformprocess", "set", "default", "form", "process", "fals", "or", "not", "use", "requir", "textfield", "text", "field", "it", "reproduc", "http", "github", "com", "krasa", "devsupportapp", "tree", "stackoverflow", "dev", "support", "app", "stack", "overflow", "run", "startvojtitkodummi", "start", "vojtitko", "dummi", "go", "http", "releas", "frontend", "tokenizationpag", "localhost:8765", "wicket", "bookmark", "krasa", "token", "page", "click", "gener", "releas", "json", "button", "instead", "soe", "it", "give", "valid", "error", "probabl", "even", "field", "which", "would", "not", "want", "valid", "but", "that", "just", "becaus", "ive", "made", "page", "badli", "code", "java", "lang", "stackoverflowerror", "stack", "overflow", "error", "null", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "compon", "internalrend", "intern", "render", "compon", "java:2344", "at", "org", "apach", "wicket", "compon", "render", "compon", "java:2307", "at", "org", "apach", "wicket", "ajax", "xmlajaxrespons", "writecompon", "xml", "ajax", "respons", "write", "compon", "xmlajaxrespons", "java:128", "xml", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "abstractajaxrespons", "writecompon", "abstract", "ajax", "respons", "write", "compon", "abstractajaxrespons", "java:218", "abstract", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "abstractajaxrespons", "writeto", "abstract", "ajax", "respons", "write", "abstractajaxrespons", "java:150", "abstract", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "ajaxrequesthandl", "respond", "ajax", "request", "handler", "ajaxrequesthandl", "java:359", "ajax", "request", "handler", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "request", "cycl", "handlerexecutor", "respond", "handler", "executor", "requestcycl", "java:865", "request", "cycl", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:64", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:97", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "execut", "request", "cycl", "requestcycl", "java:265", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:222", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:293", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "ws", "abstractupgradefilt", "processrequestcycl", "abstract", "upgrad", "filter", "process", "request", "cycl", "abstractupgradefilt", "java:59", "abstract", "upgrad", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:203", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:284", "wicket", "filter", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "servlet", "handler", "cachedchain", "dofilt", "cach", "chain", "filter", "servlethandl", "java:1652", "servlet", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "dohandl", "servlet", "handler", "handl", "servlethandl", "java:585", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:143", "scope", "handler", "at", "org", "eclips", "jetti", "secur", "securityhandl", "handl", "secur", "handler", "securityhandl", "java:577", "secur", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "dohandl", "session", "handler", "handl", "sessionhandl", "java:223", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "dohandl", "context", "handler", "handl", "contexthandl", "java:1125", "context", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "doscop", "servlet", "handler", "scope", "servlethandl", "java:515", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "doscop", "session", "handler", "scope", "sessionhandl", "java:185", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "doscop", "context", "handler", "scope", "contexthandl", "java:1059", "context", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:141", "scope", "handler", "at", "org", "eclips", "jetti", "server", "handler", "handlerwrapp", "handl", "handler", "wrapper", "handlerwrapp", "java:97", "handler", "wrapper", "at", "org", "eclips", "jetti", "server", "server", "handl", "server", "java:497", "at", "org", "eclips", "jetti", "server", "httpchannel", "handl", "http", "channel", "httpchannel", "java:310", "http", "channel", "at", "org", "eclips", "jetti", "server", "httpconnect", "onfil", "http", "connect", "fillabl", "httpconnect", "java:248", "http", "connect", "at", "org", "eclips", "jetti", "io", "abstractconnect", "abstract", "connect", "run", "abstractconnect", "java:540", "abstract", "connect", "at", "org", "eclips", "jetti", "util", "thread", "queuedthreadpool", "runjob", "queu", "thread", "pool", "run", "job", "queuedthreadpool", "java:620", "queu", "thread", "pool", "at", "org", "eclips", "jetti", "util", "thread", "queuedthreadpool", "queu", "thread", "pool", "ru", "code"], "B_title": "avoid to search component resolvers inside transparent containers", "B_clean_title": ["avoid", "search", "compon", "resolv", "insid", "transpar", "contain"]},
{"A_title": "Component queuing breaks with html tags that dont require close tag.Component queuing try to skip to close tag also for those tags that dont have one. This leads to a EmptyStackException (see ArrayListStack#peek).", "A_clean_title": ["compon", "queu", "break", "html", "tag", "that", "dont", "requir", "close", "tag", "compon", "queu", "tri", "skip", "close", "tag", "also", "those", "tag", "that", "dont", "have", "one", "thi", "lead", "emptystackexcept", "empti", "stack", "except", "see", "arrayliststack", "array", "list", "stack", "peek"], "B_title": "Component queuing breaks with html tags that dont require close tag.", "B_clean_title": ["compon", "queu", "break", "html", "tag", "that", "dont", "requir", "close", "tag"]},
{"A_title": "SimplexSolver not working as expected?I guess (but I could be wrong) that SimplexSolver does not always return the optimal solution nor satisfies all the constraints... Consider this LP: max: 0.8 x0 + 0.2 x1 + 0.7 x2 + 0.3 x3 + 0.6 x4 + 0.4 x5; r1: x0 + x2 + x4 = 23.0; r2: x1 + x3 + x5 = 23.0; r3: x0 >= 10.0; r4: x2 >= 8.0; r5: x4 >= 5.0; LPSolve returns 25.8 with x0 = 10.0 x1 = 0.0 x2 = 8.0 x3 = 0.0 x4 = 5.0 x5 = 23.0; The same LP expressed in Apache commons math is: LinearObjectiveFunction f = new LinearObjectiveFunction(new double   0.8 0.2 0.7 0.3 0.6 0.4   0 ); Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>(); constraints.add(new LinearConstraint(new double   1 0 1 0 1 0   Relationship.EQ 23.0)); constraints.add(new LinearConstraint(new double   0 1 0 1 0 1   Relationship.EQ 23.0)); constraints.add(new LinearConstraint(new double   1 0 0 0 0 0   Relationship.GEQ 10.0)); constraints.add(new LinearConstraint(new double   0 0 1 0 0 0   Relationship.GEQ 8.0)); constraints.add(new LinearConstraint(new double   0 0 0 0 1 0   Relationship.GEQ 5.0)); RealPointValuePair solution = new SimplexSolver().optimize(f constraints GoalType.MAXIMIZE true); that returns 22.20 with x0 = 15.0 x1 = 23.0 x2 = 8.0 x3 = 0.0 x4 = 0.0 x5 = 0.0; Is it possible SimplexSolver is buggy that way? The returned value is 22.20 instead of 25.8 and the last constraint (x4 >= 5.0) is not satisfied... Am I using the interface wrongly?", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "guess", "but", "could", "wrong", "that", "simplexsolv", "simplex", "solver", "not", "alway", "return", "optim", "solut", "nor", "satisfi", "all", "constraint", "consid", "thi", "lp", "max", "x0", "x1", "x2", "x3", "x4", "x5", "r1", "x0", "x2", "x4", "23", "r2", "x1", "x3", "x5", "23", "r3", "x0", "10", "r4", "x2", "r5", "x4", "lpsolv", "lp", "solv", "return", "25", "x0", "10", "x1", "x2", "x3", "x4", "x5", "23", "same", "lp", "express", "apach", "common", "math", "linearobjectivefunct", "linear", "object", "function", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "constraint", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "23", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "23", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "10", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "realpointvaluepair", "real", "point", "valu", "pair", "solut", "new", "simplexsolv", "simplex", "solver", "optim", "constraint", "goaltyp", "maxim", "goal", "type", "true", "that", "return", "22", "20", "x0", "15", "x1", "23", "x2", "x3", "x4", "x5", "it", "possibl", "simplexsolv", "simplex", "solver", "buggi", "that", "way", "return", "valu", "22", "20", "instead", "25", "last", "constraint", "x4", "not", "satisfi", "am", "interfac", "wrongli"], "B_title": "fixed an error leading the simplex solver to compute the right solution but return another one JIRA: MATH-286", "B_clean_title": ["fix", "error", "lead", "simplex", "solver", "comput", "right", "solut", "but", "return", "anoth", "one", "jira", "math", "286"]},
{"A_title": "ArgumentCaptor.fromClasss return type should match a parameterized typeArgumentCaptor.fromClasss return type should match a parameterized type. I.e. the expression ArgumentCaptor.fromClass(Class<S>) should be of type ArgumentCaptor<U> where S is a subtype of U. It should type check.", "A_clean_title": ["argumentcaptor", "fromclasss", "argument", "captor", "classs", "return", "type", "match", "parameter", "typeargumentcaptor", "fromclasss", "type", "argument", "captor", "classs", "return", "type", "match", "parameter", "type", "express", "argumentcaptor", "fromclass", "argument", "captor", "class", "class", "type", "argumentcaptor", "argument", "captor", "where", "subtyp", "it", "type", "check"], "B_title": "Fixed issue 200 For some weird reason when we had inherited generics sometimes the cglib proxy does not behave like java proxy would. Fixed in Mockito code.", "B_clean_title": ["fix", "issu", "200", "some", "weird", "reason", "when", "we", "had", "inherit", "gener", "sometim", "cglib", "proxi", "not", "behav", "like", "java", "proxi", "would", "fix", "mockito", "code"]},
{"A_title": "Url cant parse urls with username and passwordUrl tries to parse the password as the portnumber because its after the : resulting in the following exception: java.lang.NumberFormatException: For input string: 23dc429c-4ffa-4e99-8e24-984571f4c3b6@digdag-rest-dev2.topicusonderwijs.nl java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) java.lang.Integer.parseInt(Integer.java:492) java.lang.Integer.parseInt(Integer.java:527) org.apache.wicket.request.Url.parse(Url.java:276) org.apache.wicket.request.Url.parse(Url.java:192) org.apache.wicket.protocol.http.servlet.ServletWebResponse.encodeRedirectURL(ServletWebResponse.java:212) org.apache.wicket.protocol.http.servlet.ServletWebResponse.sendRedirect(ServletWebResponse.java:236) org.apache.wicket.protocol.http.BufferedWebResponse SendRedirectAction.invoke(BufferedWebResponse.java:400) org.apache.wicket.protocol.http.BufferedWebResponse.writeTo(BufferedWebResponse.java:588) org.apache.wicket.protocol.http.HeaderBufferingWebResponse.stopBuffering(HeaderBufferingWebResponse.java:60) org.apache.wicket.protocol.http.HeaderBufferingWebResponse.flush(HeaderBufferingWebResponse.java:97) org.apache.wicket.protocol.http.WicketFilter.processRequestCycle(WicketFilter.java:269) org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:201) org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:282)", "A_clean_title": ["url", "cant", "pars", "url", "usernam", "passwordurl", "password", "url", "tri", "pars", "password", "as", "portnumb", "becaus", "it", "after", "result", "follow", "except", "java", "lang", "numberformatexcept", "number", "format", "except", "input", "string", "23dc429c", "4ffa", "4e99", "8e24", "984571f4c3b6", "digdag", "rest", "dev2", "topicusonderwij", "nl", "java", "lang", "numberformatexcept", "forinputstr", "number", "format", "except", "input", "string", "numberformatexcept", "java:65", "number", "format", "except", "java", "lang", "integ", "parseint", "pars", "int", "integ", "java:492", "java", "lang", "integ", "parseint", "pars", "int", "integ", "java:527", "org", "apach", "wicket", "request", "url", "pars", "url", "java:276", "org", "apach", "wicket", "request", "url", "pars", "url", "java:192", "org", "apach", "wicket", "protocol", "http", "servlet", "servletwebrespons", "encoderedirecturl", "servlet", "web", "respons", "encod", "redirect", "url", "servletwebrespons", "java:212", "servlet", "web", "respons", "org", "apach", "wicket", "protocol", "http", "servlet", "servletwebrespons", "sendredirect", "servlet", "web", "respons", "send", "redirect", "servletwebrespons", "java:236", "servlet", "web", "respons", "org", "apach", "wicket", "protocol", "http", "bufferedwebrespons", "buffer", "web", "respons", "sendredirectact", "invok", "send", "redirect", "action", "bufferedwebrespons", "java:400", "buffer", "web", "respons", "org", "apach", "wicket", "protocol", "http", "bufferedwebrespons", "writeto", "buffer", "web", "respons", "write", "bufferedwebrespons", "java:588", "buffer", "web", "respons", "org", "apach", "wicket", "protocol", "http", "headerbufferingwebrespons", "stopbuff", "header", "buffer", "web", "respons", "stop", "buffer", "headerbufferingwebrespons", "java:60", "header", "buffer", "web", "respons", "org", "apach", "wicket", "protocol", "http", "headerbufferingwebrespons", "flush", "header", "buffer", "web", "respons", "headerbufferingwebrespons", "java:97", "header", "buffer", "web", "respons", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequestcycl", "wicket", "filter", "process", "request", "cycl", "wicketfilt", "java:269", "wicket", "filter", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:201", "wicket", "filter", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:282", "wicket", "filter"], "B_title": "Fix WICKET-5259: skip username+password when searching for portnumber", "B_clean_title": ["fix", "wicket", "5259", "skip", "username+password", "when", "search", "portnumb"]},
{"A_title": "IllegalStateException when using lowerCase/lower on a array propertyif query contain lowerCase on array property then QueryResult.getRows() throwing  IllegalStateException.  Query which causing issue   select selector_1.* from nt:unstructured AS selector_1 where ((selector_1.lcc:className = com.adobe.icc.dbforms.obj.ConditionalDataModule)) AND (LOWER(selector_1.dataDictionaryRefs) = employeedd)  If we remove LOWER function then it is working    select selector_1.* from nt:unstructured AS selector_1 where ((selector_1.lcc:className = com.adobe.icc.dbforms.obj.ConditionalDataModule)) AND (selector_1.dataDictionaryRefs = EmployeeDD)", "A_clean_title": ["illegalstateexcept", "illeg", "state", "except", "when", "lowercas", "lower", "lower", "case", "array", "propertyif", "queri", "contain", "lowercas", "lower", "case", "array", "properti", "then", "queryresult", "getrow", "queri", "result", "get", "row", "throw", "illegalstateexcept", "illeg", "state", "except", "queri", "which", "caus", "issu", "select", "selector", "nt", "unstructur", "as", "selector", "where", "lcc", "selector", "classnam", "class", "name", "com", "adob", "icc", "dbform", "obj", "conditionaldatamodul", "condit", "data", "modul", "lower", "datadictionaryref", "selector", "data", "dictionari", "ref", "employeedd", "we", "remov", "lower", "function", "then", "it", "work", "select", "selector", "nt", "unstructur", "as", "selector", "where", "lcc", "selector", "classnam", "class", "name", "com", "adob", "icc", "dbform", "obj", "conditionaldatamodul", "condit", "data", "modul", "datadictionaryref", "selector", "data", "dictionari", "ref", "employeedd", "employe", "dd"], "B_title": "IllegalStateException while trying retrieve rows information from QueryResult", "B_clean_title": ["illegalstateexcept", "illeg", "state", "except", "while", "tri", "retriev", "row", "inform", "queryresult", "queri", "result"]},
{"A_title": "missing base64/ URL encodingyesterday i showed the concept of omponents to a friend and stumled into something i dont understand and think it might be a bug.    I have a small panelcompoment that holds a searchform (textfield + submit) nothing special here the code behind looks like:     @Override         public void onSubmit()                       String suchFeld = getSuchfeld();             if(suchFeld.length()>0)                              PageParameters params = new PageParameters();                 params.add(findesuchFeld);                 setResponsePage(Suche.classparams);                          else                              setResponsePage(getPage().getClass());                         the component is put into a BasePage:    public BasePage()          ....             add(bar);         add(new SuchPanel(SuchPanel));         .....    wich is then extended by the real page:   public class Foo extends BasePage          /** Creates a new instance of Zigarren */     public Foo()             wich works all fine however if the class name contains non ascii letters (e.g: ö ä ü etc.) it gives me a bug if nothing is entered into the search and the part   public class Zubehör extends BasePage          /** Creates a new instance of Zubehör */     public Zubehör()         setResponsePage(getPage().getClass()); comes to action the trouble is that the page might have the URL: ?wicket:bookmarkablePage=:de.pages.Zubeh%C3%B6r but the form tries to go to :  wicket:bookmarkablePage=:de.pages.Zubeh%F6r   wich results in a CODE 404 in the App Server", "A_clean_title": ["miss", "base64", "url", "encodingyesterday", "show", "concept", "ompon", "friend", "stuml", "into", "someth", "dont", "understand", "think", "it", "might", "bug", "have", "small", "panelcompo", "that", "hold", "searchform", "textfield", "submit", "noth", "special", "here", "code", "behind", "look", "like", "overrid", "public", "void", "onsubmit", "submit", "string", "suchfeld", "such", "feld", "getsuchfeld", "get", "suchfeld", "suchfeld", "length", "such", "feld", "pageparamet", "page", "paramet", "param", "new", "pageparamet", "page", "paramet", "param", "add", "findesuchfeld", "findesuch", "feld", "setresponsepag", "set", "respons", "page", "such", "classparam", "setresponsepag", "set", "respons", "page", "getpag", "get", "page", "getclass", "get", "class", "compon", "put", "into", "basepag", "base", "page", "public", "basepag", "base", "page", "add", "bar", "add", "new", "suchpanel", "such", "panel", "suchpanel", "such", "panel", "wich", "then", "extend", "by", "real", "page", "public", "class", "foo", "extend", "basepag", "base", "page", "creat", "new", "instanc", "zigarren", "public", "foo", "wich", "work", "all", "fine", "howev", "class", "name", "contain", "non", "ascii", "letter", "etc", "it", "give", "me", "bug", "noth", "enter", "into", "search", "part", "public", "class", "zubehör", "extend", "basepag", "base", "page", "creat", "new", "instanc", "zubehör", "public", "zubehör", "setresponsepag", "set", "respons", "page", "getpag", "get", "page", "getclass", "get", "class", "come", "action", "troubl", "that", "page", "might", "have", "url", "wicket", "bookmarkablepage=", "bookmark", "page=", "de", "page", "zubeh", "c3", "b6r", "but", "form", "tri", "go", "wicket", "bookmarkablepage=", "bookmark", "page=", "de", "page", "zubeh", "f6r", "wich", "result", "code", "404", "app", "server"], "B_title": "Make sure that bookmarkable urls for classes containing non-ascii characters is encoded properly.", "B_clean_title": ["make", "sure", "that", "bookmark", "url", "class", "contain", "non", "ascii", "charact", "encod", "properli"]},
{"A_title": "The LinearConstraintSet shall return its constraints in a deterministic wayAs previously discussed on the mailinglist the LinearConstraintSet should return its internally stored LinearConstraints in the same iteration order as they have been provided via its constructor.  This ensures that the execution of the same linear problem results in the same results each time it is executed. This is especially important when linear problems are loaded from a file e.g. mps format and makes it simpler to debug problems and compare with other solvers which do the same thing.", "A_clean_title": ["linearconstraintset", "linear", "constraint", "set", "shall", "return", "it", "constraint", "determinist", "waya", "way", "as", "previous", "discuss", "mailinglist", "linearconstraintset", "linear", "constraint", "set", "return", "it", "intern", "store", "linearconstraint", "linear", "constraint", "same", "iter", "order", "as", "they", "have", "been", "provid", "via", "it", "constructor", "thi", "ensur", "that", "execut", "same", "linear", "problem", "result", "same", "result", "each", "time", "it", "execut", "thi", "especi", "import", "when", "linear", "problem", "are", "load", "file", "mp", "format", "make", "it", "simpler", "debug", "problem", "compar", "other", "solver", "which", "same", "thing"], "B_title": "LinearConstraintSet returns now the LinearConstraints in the same order as they have been added.", "B_clean_title": ["linearconstraintset", "linear", "constraint", "set", "return", "now", "linearconstraint", "linear", "constraint", "same", "order", "as", "they", "have", "been", "ad"]},
{"A_title": "Sysview import of single valued mv property creates sv propertySee test in filevault 0.  it imports a multivalue property that only has 1 value via 1. the same test succeeds in jackrabbit 2.0 but fails in oak 1.3.14  0 https://github.com/apache/jackrabbit-filevault/blob/jackrabbit-filevault-3.1.26/vault-core/src/test/java/org/apache/jackrabbit/vault/packaging/integration/TestUserContentPackage.java#L297-L326 1 https://github.com/apache/jackrabbit-filevault/blob/jackrabbit-filevault-3.1.26/vault-core/src/main/java/org/apache/jackrabbit/vault/fs/impl/io/JcrSysViewTransformer.java#L146-L148", "A_clean_title": ["sysview", "import", "singl", "valu", "mv", "properti", "creat", "sv", "propertyse", "properti", "see", "test", "filevault", "it", "import", "multivalu", "properti", "that", "onli", "ha", "valu", "via", "same", "test", "succe", "jackrabbit", "but", "fail", "oak", "14", "http", "filevault", "filevault", "blob", "jackrabbit", "java", "github", "com", "apach", "jackrabbit", "26", "vault", "core", "src", "test", "java", "org", "apach", "jackrabbit", "vault", "packag", "integr", "testusercontentpackag", "test", "user", "content", "packag", "l297", "l326", "http", "filevault", "filevault", "blob", "jackrabbit", "java", "github", "com", "apach", "jackrabbit", "26", "vault", "core", "src", "main", "java", "org", "apach", "jackrabbit", "vault", "fs", "impl", "io", "jcrsysviewtransform", "jcr", "sy", "view", "transform", "l146", "l148"], "B_title": ": Sysview import of single valued mv property creates sv property", "B_clean_title": ["sysview", "import", "singl", "valu", "mv", "properti", "creat", "sv", "properti"]},
{"A_title": "ODE integrator goes past specified end of integration rangeEnd of integration range in ODE solving is handled as an event. In some cases numerical accuracy in events detection leads to error in events location. The following test case shows the end event is not handled properly and an integration that should cover a 60s range in fact covers a 160s range more than twice the specified range.    public void testMissedEvent() throws IntegratorException DerivativeException            final double t0 = 1878250320.0000029;           final double t =  1878250379.9999986;           FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations()                           public int getDimension()                  return 1;                                       public void computeDerivatives(double t double y double yDot)                 throws DerivativeException                  yDot0 = y0 * 1.0e-6;                      ;          DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0 100.0                                                                                1.0e-10 1.0e-10);          double y =  1.0 ;         integrator.setInitialStepSize(60.0);         double finalT = integrator.integrate(ode t0 y t y);         Assert.assertEquals(t finalT 1.0e-6);", "A_clean_title": ["ode", "integr", "goe", "past", "specifi", "end", "integr", "rangeend", "rang", "end", "integr", "rang", "ode", "solv", "handl", "as", "event", "some", "case", "numer", "accuraci", "event", "detect", "lead", "error", "event", "locat", "follow", "test", "case", "show", "end", "event", "not", "handl", "properli", "integr", "that", "cover", "60", "rang", "fact", "cover", "160", "rang", "more", "than", "twice", "specifi", "rang", "public", "void", "testmissedev", "test", "miss", "event", "throw", "integratorexcept", "integr", "except", "derivativeexcept", "deriv", "except", "final", "doubl", "t0", "1878250320", "0000029", "final", "doubl", "1878250379", "9999986", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "ode", "new", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "public", "int", "getdimens", "get", "dimens", "return", "public", "void", "computederiv", "comput", "deriv", "doubl", "doubl", "doubl", "ydot", "dot", "throw", "derivativeexcept", "deriv", "except", "ydot0", "dot0", "y0", "0e", "dormandprince853integr", "dormand", "prince853integr", "integr", "new", "dormandprince853integr", "dormand", "prince853integr", "100", "10", "0e", "10", "0e", "doubl", "integr", "setinitialsteps", "set", "initi", "step", "size", "60", "doubl", "finalt", "final", "integr", "integr", "ode", "t0", "assert", "assertequ", "assert", "equal", "finalt", "final", "0e"], "B_title": "Fixed an error in events handling in ODE solvers. In some rare cases events occurring close to a step start were handled without truncating the step making them appear as is they occurred close to the step end JIRA: MATH-358", "B_clean_title": ["fix", "error", "event", "handl", "ode", "solver", "some", "rare", "case", "event", "occur", "close", "step", "start", "were", "handl", "without", "truncat", "step", "make", "them", "appear", "as", "they", "occur", "close", "step", "end", "jira", "math", "358"]},
{"A_title": "XsltOutputTransformerContainer incorrectly claims markup type xslXsltOutputTransformerContainer return xsl from getMarkupType() forcing is on all contained components.  If the components in org.apache.wicket.markup.outputTransformer.Page_1 are reordered (XsltOutputTransformerContainer coming first) the test fails because no markup for SimpleBorder can be found.", "A_clean_title": ["xsltoutputtransformercontain", "xslt", "output", "transform", "contain", "incorrectli", "claim", "markup", "type", "xslxsltoutputtransformercontain", "xsl", "xslt", "output", "transform", "contain", "return", "xsl", "getmarkuptyp", "get", "markup", "type", "forc", "all", "contain", "compon", "compon", "org", "apach", "wicket", "markup", "outputtransform", "output", "transform", "page", "are", "reorder", "xsltoutputtransformercontain", "xslt", "output", "transform", "contain", "come", "first", "test", "fail", "becaus", "no", "markup", "simplebord", "simpl", "border", "found"], "B_title": "XsltOutputTransformerContainer not necessarily has xsl markup type", "B_clean_title": ["xsltoutputtransformercontain", "xslt", "output", "transform", "contain", "not", "necessarili", "ha", "xsl", "markup", "type"]},
{"A_title": "org.apache.wicket.util.string.StringValue#equals brokenThe #equals implementation for org.apache.wicket.util.string.StringValue is broken. The following throws an exception instead of just printing false:  StringValue val = StringValue.valueOf(bla Locale.FRANCE); StringValue val2 = StringValue.valueOf(bla Locale.CANADA); System.out.println(val.equals(val2));   This part of #equals Objects.isEqual(locale stringValue.locale)  should probably be replaced with something like (locale == stringValue.locale || (locale != null && locale.equals(stringValue.locale))  -> Objects.isEqual is not suitable to determine equality of Locale", "A_clean_title": ["org", "apach", "wicket", "util", "string", "stringvalu", "string", "valu", "equal", "brokenth", "broken", "equal", "implement", "org", "apach", "wicket", "util", "string", "stringvalu", "string", "valu", "broken", "follow", "throw", "except", "instead", "just", "print", "fals", "stringvalu", "string", "valu", "val", "stringvalu", "valueof", "string", "valu", "valu", "bla", "local", "franc", "stringvalu", "string", "valu", "val2", "stringvalu", "valueof", "string", "valu", "valu", "bla", "local", "canada", "system", "out", "println", "val", "equal", "val2", "thi", "part", "equal", "object", "isequ", "equal", "local", "stringvalu", "local", "string", "valu", "probabl", "replac", "someth", "like", "local", "stringvalu", "local", "string", "valu", "local", "null", "local", "equal", "stringvalu", "local", "string", "valu", "object", "isequ", "equal", "not", "suitabl", "determin", "equal", "local"], "B_title": "fixed equals for different locales", "B_clean_title": ["fix", "equal", "differ", "local"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Fixing LANG-538 - you need to call getTime() on a calendar sometimes to get it in the right state otherwise the timezone gets out of whack.", "B_clean_title": ["fix", "lang", "538", "you", "need", "call", "gettim", "get", "time", "calendar", "sometim", "get", "it", "right", "state", "otherwis", "timezon", "get", "out", "whack"]},
{"A_title": "MockTableOperations.deleteRow does not handle null for start or end keysThe deleteRow function does not check for null values for start or end keys. These null values are passed down into key constructor which will throw a NullPointerException: java.lang.NullPointerException at org.apache.accumulo.core.data.Key.<init>(Key.java:103) at org.apache.accumulo.core.client.mock.MockTableOperations.deleteRows(MockTableOperations.java:315)  The API semantics dictate: if (start == null ) then start == Text() if (end == null ) then end == maxKey()", "A_clean_title": ["mocktableoper", "deleterow", "mock", "tabl", "oper", "delet", "row", "not", "handl", "null", "start", "or", "end", "keysth", "key", "deleterow", "delet", "row", "function", "not", "check", "null", "valu", "start", "or", "end", "key", "these", "null", "valu", "are", "pass", "down", "into", "key", "constructor", "which", "will", "throw", "nullpointerexcept", "null", "pointer", "except", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "accumulo", "core", "data", "key", "init", "key", "java:103", "at", "org", "apach", "accumulo", "core", "client", "mock", "mocktableoper", "deleterow", "mock", "tabl", "oper", "delet", "row", "mocktableoper", "java:315", "mock", "tabl", "oper", "api", "semant", "dictat", "start", "null", "then", "start", "text", "end", "null", "then", "end", "maxkey", "max", "key"], "B_title": "added logic to handle null keys for MockTableOperations.deleteRow", "B_clean_title": ["ad", "logic", "handl", "null", "key", "mocktableoper", "deleterow", "mock", "tabl", "oper", "delet", "row"]},
{"A_title": "IE8 error: Object doesnt support this actionNone", "A_clean_title": ["ie8", "error", "object", "doesnt", "support", "thi", "actionnon", "action", "none"], "B_title": "a really terrible fix for issue 291 fixes issue 291", "B_clean_title": ["realli", "terribl", "fix", "issu", "291", "fix", "issu", "291"]},
{"A_title": "AsyncIndexUpdate unable to cope with missing checkpoint refThe async index uses a checkpoint reference stored under the _:async_ hidden node as a base for running the index diff. It might happen that this reference is stale (pointing to checkpoints that no longer exist) so the async indexer logs a warning that it will reindex everything and will start its work. The trouble is with the #mergeWithConcurrencyCheck which does not cope well with this scenario. Even if the ref checkpoint is null it will throw a concurrent update exception which will be logged as a misleading debug log _Concurrent update detected in the async index update_.  Overall the code looks stuck in an endless reindexing loop.  code *WARN* pool-9-thread-1 org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate Failed to retrieve previously indexed checkpoint 569d8847-ebb6-4832-a55f-2b0b1a32ae71; re-running the initial async index update *DEBUG* pool-9-thread-1 org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate Concurrent update detected in the async index update code", "A_clean_title": ["asyncindexupd", "async", "index", "updat", "unabl", "cope", "miss", "checkpoint", "refth", "ref", "async", "index", "use", "checkpoint", "refer", "store", "under", "async", "hidden", "node", "as", "base", "run", "index", "diff", "it", "might", "happen", "that", "thi", "refer", "stale", "point", "checkpoint", "that", "no", "longer", "exist", "so", "async", "index", "log", "warn", "that", "it", "will", "reindex", "everyth", "will", "start", "it", "work", "troubl", "mergewithconcurrencycheck", "merg", "concurr", "check", "which", "not", "cope", "well", "thi", "scenario", "even", "ref", "checkpoint", "null", "it", "will", "throw", "concurr", "updat", "except", "which", "will", "log", "as", "mislead", "debug", "log", "concurr", "updat", "detect", "async", "index", "updat", "overal", "code", "look", "stuck", "endless", "reindex", "loop", "code", "warn", "pool", "thread", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "async", "index", "updat", "fail", "retriev", "previous", "index", "checkpoint", "569d8847", "ebb6", "4832", "a55f", "2b0b1a32ae71", "re", "run", "initi", "async", "index", "updat", "debug", "pool", "thread", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "async", "index", "updat", "concurr", "updat", "detect", "async", "index", "updat", "code"], "B_title": "AsyncIndexUpdate unable to cope with missing checkpoint ref", "B_clean_title": ["asyncindexupd", "async", "index", "updat", "unabl", "cope", "miss", "checkpoint", "ref"]},
{"A_title": "Possibility of overflow in file length calculationIn OakDirectory the length of a file is calculated in following way  code:title=OakDirectory|linenumbers=true         public OakIndexFile(String name NodeBuilder file)              ...             this.blobSize = determineBlobSize(file);             this.blob = new byteblobSize;              PropertyState property = file.getProperty(JCR_DATA);             if (property != null && property.getType() == BINARIES)                  this.data = newArrayList(property.getValue(BINARIES));              else                  this.data = newArrayList();                           this.length = data.size() * blobSize;             if (!data.isEmpty())                  Blob last = data.get(data.size() - 1);                 this.length -= blobSize - last.length();              code  In above calculation its possible to have an overflow in  bq. this.length = data.size() * blobSize;  As multiplication of two integers result in an integer 1  1 http://stackoverflow.com/questions/12861893/casting-result-of-multiplication-two-positive-integers-to-long-is-negative-value", "A_clean_title": ["possibl", "overflow", "file", "length", "calculationin", "calcul", "oakdirectori", "oak", "directori", "length", "file", "calcul", "follow", "way", "code", "title=oakdirectory|linenumbers=tru", "title=oak", "directory|linenumbers=tru", "public", "oakindexfil", "oak", "index", "file", "string", "name", "nodebuild", "node", "builder", "file", "thi", "blobsiz", "blob", "size", "determineblobs", "determin", "blob", "size", "file", "thi", "blob", "new", "byteblobs", "byteblob", "size", "propertyst", "properti", "state", "properti", "file", "getproperti", "get", "properti", "jcr", "data", "properti", "null", "properti", "gettyp", "get", "type", "binari", "thi", "data", "newarraylist", "new", "array", "list", "properti", "getvalu", "get", "valu", "binari", "thi", "data", "newarraylist", "new", "array", "list", "thi", "length", "data", "size", "blobsiz", "blob", "size", "data", "isempti", "empti", "blob", "last", "data", "get", "data", "size", "thi", "length", "blobsiz", "blob", "size", "last", "length", "code", "abov", "calcul", "it", "possibl", "have", "overflow", "bq", "thi", "length", "data", "size", "blobsiz", "blob", "size", "as", "multipl", "two", "integ", "result", "integ", "http", "result", "multipl", "two", "posit", "integ", "long", "neg", "valu", "stackoverflow", "com", "question", "12861893", "cast"], "B_title": "- Possibility of overflow in file length calculation", "B_clean_title": ["possibl", "overflow", "file", "length", "calcul"]},
{"A_title": "address-controller: NPE when required parameters (address plan or type) are not setDescription:  When required parameter (addressplan or type) in address definition is not set then it cause NPE in address-controller.  https://github.com/EnMasseProject/enmasse/blob/master/address-model-lib/src/main/java/io/enmasse/address/model/v1/AddressV1Deserializer.java#L36 Steps to reproduce:    create brokered address-space brokered-space  create address without required parameter: brokered_incorrect_address.json    Automated test:  we have no automated test for that yet output from address-controller log:", "A_clean_title": ["address", "control", "npe", "when", "requir", "paramet", "address", "plan", "or", "type", "are", "not", "setdescript", "set", "descript", "when", "requir", "paramet", "addressplan", "or", "type", "address", "definit", "not", "set", "then", "it", "caus", "npe", "address", "control", "http", "model", "java", "github", "com", "enmasseproject", "enmass", "blob", "master", "address", "lib", "src", "main", "java", "io", "enmass", "address", "model", "v1", "addressv1deseri", "en", "mass", "project", "address", "v1deseri", "l36", "step", "reproduc", "creat", "broker", "address", "space", "broker", "space", "creat", "address", "without", "requir", "paramet", "json", "broker", "incorrect", "address", "autom", "test", "we", "have", "no", "autom", "test", "that", "yet", "output", "address", "control", "log"], "B_title": "Validate required fields and provide correct HTTP response on validation errors  Fixes #1082", "B_clean_title": ["valid", "requir", "field", "provid", "correct", "http", "respons", "valid", "error", "fix", "1082"]},
{"A_title": "issues with JsopBuilder.encode and .escape1) escape() escapes many characters that do not need to be escaped (>127)  2) encode() does not encode many control characters that would need to be escaped when read through a JSON parser.", "A_clean_title": ["issu", "jsopbuild", "encod", "jsop", "builder", "escape1", "escap", "escap", "mani", "charact", "that", "not", "need", "escap", "127", "encod", "not", "encod", "mani", "control", "charact", "that", "would", "need", "escap", "when", "read", "through", "json", "parser"], "B_title": "- add handling for broken surrogate pairs because they wont round-trip through UTF-8 (and some databases) otherwise", "B_clean_title": ["add", "handl", "broken", "surrog", "pair", "becaus", "they", "wont", "round", "trip", "through", "utf", "some", "databas", "otherwis"]},
{"A_title": "MockTableOperations.tableIdMap always returns tableName as IDNoticed and fixed this during ACCUMULO-378.  An exception was thrown unexpectedly when trying to use tableIdMap with a MockInstance. Lift fix from 93c8bddc71d1ee190649eeab263205185d75421c into main tree.", "A_clean_title": ["mocktableoper", "tableidmap", "mock", "tabl", "oper", "tabl", "id", "map", "alway", "return", "tablenam", "tabl", "name", "as", "idnot", "id", "notic", "fix", "thi", "dure", "accumulo", "378", "except", "wa", "thrown", "unexpectedli", "when", "tri", "use", "tableidmap", "tabl", "id", "map", "mockinst", "mock", "instanc", "lift", "fix", "93c8bddc71d1ee190649eeab263205185d75421c", "into", "main", "tree"], "B_title": "Return a more real tableID", "B_clean_title": ["return", "more", "real", "tableid", "tabl", "id"]},
{"A_title": "FromStringDeserializer ignores registered DeserializationProblemHandler for java.util.UUIDCulprit appears to be  lines 155-161 of FromStringDeserializer :  The above lines appear to show that the exception will be thrown regardless of any problem handling logic.  Test Case:   The handler handles the issue properly; but an exception is thrown anyway:", "A_clean_title": ["fromstringdeseri", "string", "deseri", "ignor", "regist", "deserializationproblemhandl", "deseri", "problem", "handler", "java", "util", "uuidculprit", "uuid", "culprit", "appear", "line", "155", "161", "fromstringdeseri", "string", "deseri", "abov", "line", "appear", "show", "that", "except", "will", "thrown", "regardless", "ani", "problem", "handl", "logic", "test", "case", "handler", "handl", "issu", "properli", "but", "except", "thrown", "anyway"], "B_title": "Fix #1629", "B_clean_title": ["fix", "1629"]},
{"A_title": "StackOverflowError in Dynamic StdKeySerializerThere seem to be a problem (checked and doesnt seem to be fixed in latest version) with the serialize method of the Dynamic static class of the StdKeySerializer.   The problem comes from the fact that when  ser is null  the new ser returned by _findAndAddDynamic is incorrectly filled.  So say we are in  ser#1  ser#1._dynamicSerializers now has the correct PropertySerializerMap$Single . However result.serializer._dynamicSerializers has PropertySerializerMap$Empty . Therefore a new call with that result ser#2 is made which ends up creating an infinite loop. Possible fix:    replace  If Im mistaken please let me know but It seems obvious when debugging that somethings is not working as intended", "A_clean_title": ["stackoverflowerror", "stack", "overflow", "error", "dynam", "stdkeyserializerther", "std", "key", "serial", "there", "seem", "problem", "check", "doesnt", "seem", "fix", "latest", "version", "serial", "method", "dynam", "static", "class", "stdkeyseri", "std", "key", "serial", "problem", "come", "fact", "that", "when", "ser", "null", "new", "ser", "return", "by", "findandadddynam", "find", "add", "dynam", "incorrectli", "fill", "so", "say", "we", "are", "ser", "ser", "dynamicseri", "dynam", "serial", "now", "ha", "correct", "propertyserializermap", "properti", "serial", "map", "singl", "howev", "result", "serial", "dynamicseri", "dynam", "serial", "ha", "propertyserializermap", "properti", "serial", "map", "empti", "therefor", "new", "call", "that", "result", "ser", "made", "which", "end", "up", "creat", "infinit", "loop", "possibl", "fix", "replac", "im", "mistaken", "pleas", "let", "me", "know", "but", "it", "seem", "obviou", "when", "debug", "that", "someth", "not", "work", "as", "intend"], "B_title": "Fix #1679", "B_clean_title": ["fix", "1679"]},
{"A_title": "MountedMapper.mapHandler ruins Links inside mounted pages appending parameters wicket-ajax and wicket-ajax-baseurlWith the last commit n° 1166194 method mapHandler has been added to MountedMapper class in order to solve WICKET-4014. Unfortunately this method seems to ruin Link url inside mounted page (for example home page) if this page uses AJAX. mapHandler modifies Link url appending parameters wicket-ajax and wicket-ajax-baseurl to it. In this way when we click Link we get an error from browser like this:          This XML file does not appear to have any style information associated with it. The document tree is shown below.       <ajax-response><redirect>wicket/page?41</redirect></ajax-response>   The error message is the same for Firefox and Chromium. See attached quickstart.  Warning: as Im writing this issue Wicket snapshot is not affected yet by this bug so you have to run quickstart with the last source from repository.", "A_clean_title": ["mountedmapp", "maphandl", "mount", "mapper", "map", "handler", "ruin", "link", "insid", "mount", "page", "append", "paramet", "wicket", "ajax", "wicket", "ajax", "baseurlwith", "baseurl", "last", "commit", "n°", "1166194", "method", "maphandl", "map", "handler", "ha", "been", "ad", "mountedmapp", "mount", "mapper", "class", "order", "solv", "wicket", "4014", "unfortun", "thi", "method", "seem", "ruin", "link", "url", "insid", "mount", "page", "exampl", "home", "page", "thi", "page", "use", "ajax", "maphandl", "map", "handler", "modifi", "link", "url", "append", "paramet", "wicket", "ajax", "wicket", "ajax", "baseurl", "it", "thi", "way", "when", "we", "click", "link", "we", "get", "error", "browser", "like", "thi", "thi", "xml", "file", "not", "appear", "have", "ani", "style", "inform", "associ", "it", "document", "tree", "shown", "below", "ajax", "respons", "redirect", "wicket", "page", "41", "redirect", "respons", "ajax", "error", "messag", "same", "firefox", "chromium", "see", "attach", "quickstart", "warn", "as", "im", "write", "thi", "issu", "wicket", "snapshot", "not", "affect", "yet", "by", "thi", "bug", "so", "you", "have", "run", "quickstart", "last", "sourc", "repositori"], "B_title": "Dont create an empty PageParameters if the original is null.", "B_clean_title": ["dont", "creat", "empti", "pageparamet", "page", "paramet", "origin", "null"]},
{"A_title": "during ODE integration the last event in a pair of very close event may not be detectedWhen an events follows a previous one very closely it may be ignored. The occurrence of the bug depends on the side of the bracketing interval that was selected. For example consider a switching function that is increasing around first event around t = 90 reaches its maximum and is decreasing around the second event around t = 135. If an integration step spans from 67.5 and 112.5 the switching function values at start and end of step will  have opposite signs so the first event will be detected. The solver will find the event really occurs at 90.0 and will therefore truncate the step at 90.0. The next step will start from where the first step ends i.e. it will start at 90.0. Lets say this step spans from 90.0 to 153.0. The switching function switches once again in this step. If the solver for the first event converged to a value slightly before 90.0 (say 89.9999999) then the switch will not be detected because g(89.9999999) and g(153.0) are both negative. This bug was introduced as of r781157 (2009-06-02) when special handling of events very close to step start was added.", "A_clean_title": ["dure", "ode", "integr", "last", "event", "pair", "veri", "close", "event", "may", "not", "detectedwhen", "detect", "when", "event", "follow", "previou", "one", "veri", "close", "it", "may", "ignor", "occurr", "bug", "depend", "side", "bracket", "interv", "that", "wa", "select", "exampl", "consid", "switch", "function", "that", "increas", "around", "first", "event", "around", "90", "reach", "it", "maximum", "decreas", "around", "second", "event", "around", "135", "integr", "step", "span", "67", "112", "switch", "function", "valu", "at", "start", "end", "step", "will", "have", "opposit", "sign", "so", "first", "event", "will", "detect", "solver", "will", "find", "event", "realli", "occur", "at", "90", "will", "therefor", "truncat", "step", "at", "90", "next", "step", "will", "start", "where", "first", "step", "end", "it", "will", "start", "at", "90", "let", "say", "thi", "step", "span", "90", "153", "switch", "function", "switch", "onc", "again", "thi", "step", "solver", "first", "event", "converg", "valu", "slightli", "befor", "90", "say", "89", "9999999", "then", "switch", "will", "not", "detect", "becaus", "89", "9999999", "153", "are", "both", "neg", "thi", "bug", "wa", "introduc", "as", "r781157", "2009", "06", "02", "when", "special", "handl", "event", "veri", "close", "step", "start", "wa", "ad"], "B_title": "Fixed an error in handling of very close events during ODE integration JIRA: MATH-322", "B_clean_title": ["fix", "error", "handl", "veri", "close", "event", "dure", "ode", "integr", "jira", "math", "322"]},
{"A_title": "ResizableDoubleArray is not thread-safe yet has some synch. methodsResizableDoubleArray has several synchronised methods but is not thread-safe because class variables are not always accessed using the lock.  Is the class supposed to be thread-safe?  If so all accesses (read and write) need to be synch.  If not the synch. qualifiers could be dropped.  In any case the protected fields need to be made private.", "A_clean_title": ["resizabledoublearray", "resiz", "doubl", "array", "not", "thread", "safe", "yet", "ha", "some", "synch", "methodsresizabledoublearray", "method", "resiz", "doubl", "array", "ha", "sever", "synchronis", "method", "but", "not", "thread", "safe", "becaus", "class", "variabl", "are", "not", "alway", "access", "lock", "class", "suppos", "thread", "safe", "so", "all", "access", "read", "write", "need", "synch", "not", "synch", "qualifi", "could", "drop", "ani", "case", "protect", "field", "need", "made", "privat"], "B_title": "Removed broken and deprecated synchronization support in ResizableDoubleArray.", "B_clean_title": ["remov", "broken", "deprec", "synchron", "support", "resizabledoublearray", "resiz", "doubl", "array"]},
{"A_title": "NPE in RecordIdMapRecordIdMap is not properly guarded against NPEs when calling accessors on an empty map (which is represented by keys == null.   noformat testRecordIdMap(org.apache.jackrabbit.oak.plugins.segment.RecordIdMapTest)  Time elapsed: 0.019 sec  <<< ERROR! java.lang.NullPointerException at org.apache.jackrabbit.oak.plugins.segment.RecordIdMap.size(RecordIdMap.java:100) at org.apache.jackrabbit.oak.plugins.segment.RecordIdMapTest.testRecordIdMap(RecordIdMapTest.java:64) noformat", "A_clean_title": ["npe", "recordidmaprecordidmap", "record", "id", "map", "record", "id", "map", "not", "properli", "guard", "against", "npe", "np", "es", "when", "call", "accessor", "empti", "map", "which", "repres", "by", "key", "null", "noformat", "testrecordidmap", "test", "record", "id", "map", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "recordidmaptest", "record", "id", "map", "test", "time", "elaps", "019", "sec", "error", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "recordidmap", "size", "record", "id", "map", "recordidmap", "java:100", "record", "id", "map", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "recordidmaptest", "testrecordidmap", "record", "id", "map", "test", "test", "record", "id", "map", "recordidmaptest", "java:64", "record", "id", "map", "test", "noformat"], "B_title": "NPE in RecordIdMap * Properly guard against NPE * Added test case for empty map", "B_clean_title": ["npe", "recordidmap", "record", "id", "map", "properli", "guard", "against", "npe", "ad", "test", "case", "empti", "map"]},
{"A_title": "Failing generic type resolution of generic types within nested generic fields DATACMNS-1196opened and commented It seems that the type resolution is not working properly when having nested object composition with generic type.  Example of model: constructors getters... ommited  And create instance of  Outer with  When we create an instance of  Outer which has reference to instance of Generic whose generic type is MyEnum then if we save Outer instance using MongoTemplate its persisted in db correctly converted to mongos document.   But when we try to read it from db it is mapped incorrectly back to  Outer . Field myList in instance of Inner contains a List which contains instances of String  but field elem in instance of Inner is mapped correctly and it really contains an instance of MyEnum . Seems that problem is in MongoConverter . Im attaching a simple project which is able to reproduce problem described above. In tests Im not actually storing an instance to mongo collection but rather using only MongoConverter to convert an instance to Document and than back to Outer . I dont know if workaround for this cold be writing a custom Converter . My workaround for this (in real project) was to manually convert a Document to some domain specific instance but that is really annoying.  I know that mapping from mongo types back can be tricky and sometimes type information is lost but that is not case here. For comparison Ive tried Jackson s ObjectMapper to do serialization of instance of Outer to JSON string and than de-serialize JSON on back to Outer and it seems that Jackson resolves  generic types correctly.   Affects: 1.13.8 (Ingalls SR8) 2.0 GA (Kay)  Attachments:     Backported to:  2.0.1 (Kay SR1)  1.13.9 (Ingalls SR9)", "A_clean_title": ["fail", "gener", "type", "resolut", "gener", "type", "within", "nest", "gener", "field", "datacmn", "1196open", "comment", "it", "seem", "that", "type", "resolut", "not", "work", "properli", "when", "have", "nest", "object", "composit", "gener", "type", "exampl", "model", "constructor", "getter", "ommit", "creat", "instanc", "outer", "when", "we", "creat", "instanc", "outer", "which", "ha", "refer", "instanc", "gener", "whose", "gener", "type", "myenum", "my", "enum", "then", "we", "save", "outer", "instanc", "mongotempl", "mongo", "templat", "it", "persist", "db", "correctli", "convert", "mongo", "document", "but", "when", "we", "tri", "read", "it", "db", "it", "map", "incorrectli", "back", "outer", "field", "mylist", "my", "list", "instanc", "inner", "contain", "list", "which", "contain", "instanc", "string", "but", "field", "elem", "instanc", "inner", "map", "correctli", "it", "realli", "contain", "instanc", "myenum", "my", "enum", "seem", "that", "problem", "mongoconvert", "mongo", "convert", "im", "attach", "simpl", "project", "which", "abl", "reproduc", "problem", "describ", "abov", "test", "im", "not", "actual", "store", "instanc", "mongo", "collect", "but", "rather", "onli", "mongoconvert", "mongo", "convert", "convert", "instanc", "document", "than", "back", "outer", "dont", "know", "workaround", "thi", "cold", "write", "custom", "convert", "my", "workaround", "thi", "real", "project", "wa", "manual", "convert", "document", "some", "domain", "specif", "instanc", "but", "that", "realli", "annoy", "know", "that", "map", "mongo", "type", "back", "tricki", "sometim", "type", "inform", "lost", "but", "that", "not", "case", "here", "comparison", "ive", "tri", "jackson", "objectmapp", "object", "mapper", "serial", "instanc", "outer", "json", "string", "than", "de", "serial", "json", "back", "outer", "it", "seem", "that", "jackson", "resolv", "gener", "type", "correctli", "affect", "13", "ingal", "sr8", "ga", "kay", "attach", "backport", "kay", "sr1", "13", "ingal", "sr9"], "B_title": "DATACMNS-1196 - Fixed generics lookup for nested generics in ParameterizedTypeInformation.  We now eagerly resolve a generics declaration chain which we previously - erroneously - expected GenericTypeResolver to do for us. Simplified TypeVariableTypeInformation implementation. Renamed ParameterizedTypeUnitTests to ParameterizedTypeInformationUnitTests.", "B_clean_title": ["datacmn", "1196", "fix", "gener", "lookup", "nest", "gener", "parameterizedtypeinform", "parameter", "type", "inform", "we", "now", "eagerli", "resolv", "gener", "declar", "chain", "which", "we", "previous", "erron", "expect", "generictyperesolv", "gener", "type", "resolv", "us", "simplifi", "typevariabletypeinform", "type", "variabl", "type", "inform", "implement", "renam", "parameterizedtypeunittest", "parameter", "type", "unit", "test", "parameterizedtypeinformationunittest", "parameter", "type", "inform", "unit", "test"]},
{"A_title": "StringUtils methods do not handle Unicode 2.0+ supplementary characters correctly.StringUtils.containsAny methods incorrectly matches Unicode 2.0+ supplementary characters. For example define a test fixture to be the Unicode character U+20000 where U+20000 is written in Java source as uD840uDC00 private static final String CharU20000 = uD840uDC00; private static final String CharU20001 = uD840uDC01; You can see Unicode supplementary characters correctly implemented in the JRE call: assertEquals(-1 CharU20000.indexOf(CharU20001)); But this is broken: assertEquals(false StringUtils.containsAny(CharU20000 CharU20001)); assertEquals(false StringUtils.containsAny(CharU20001 CharU20000)); This is fine: assertEquals(true StringUtils.contains(CharU20000 + CharU20001 CharU20000)); assertEquals(true StringUtils.contains(CharU20000 + CharU20001 CharU20001)); assertEquals(true StringUtils.contains(CharU20000 CharU20000)); assertEquals(false StringUtils.contains(CharU20000 CharU20001)); because the method calls the JRE to perform the match. More than you want to know:  http://java.sun.com/developer/technicalArticles/Intl/Supplementary/", "A_clean_title": ["stringutil", "string", "util", "method", "not", "handl", "unicod", "0+", "supplementari", "charact", "correctli", "stringutil", "containsani", "string", "util", "contain", "ani", "method", "incorrectli", "match", "unicod", "0+", "supplementari", "charact", "exampl", "defin", "test", "fixtur", "unicod", "charact", "u+20000", "where", "u+20000", "written", "java", "sourc", "as", "ud840udc00", "d840u", "dc00", "privat", "static", "final", "string", "charu20000", "char", "u20000", "ud840udc00", "d840u", "dc00", "privat", "static", "final", "string", "charu20001", "char", "u20001", "ud840udc01", "d840u", "dc01", "you", "see", "unicod", "supplementari", "charact", "correctli", "implement", "jre", "call", "assertequ", "assert", "equal", "charu20000", "indexof", "char", "u20000", "index", "charu20001", "char", "u20001", "but", "thi", "broken", "assertequ", "assert", "equal", "fals", "stringutil", "containsani", "string", "util", "contain", "ani", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "assertequ", "assert", "equal", "fals", "stringutil", "containsani", "string", "util", "contain", "ani", "charu20001", "char", "u20001", "charu20000", "char", "u20000", "thi", "fine", "assertequ", "assert", "equal", "true", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "charu20000", "char", "u20000", "assertequ", "assert", "equal", "true", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "charu20001", "char", "u20001", "assertequ", "assert", "equal", "true", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20000", "char", "u20000", "assertequ", "assert", "equal", "fals", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "becaus", "method", "call", "jre", "perform", "match", "more", "than", "you", "want", "know", "http", "sun", "java", "com", "develop", "technicalarticl", "intl", "supplementari", "technic", "articl"], "B_title": "StringUtils methods do not handle Unicode 2.0+ supplementary characters correctly.", "B_clean_title": ["stringutil", "string", "util", "method", "not", "handl", "unicod", "0+", "supplementari", "charact", "correctli"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "avoid NPE in ClassUtils.toClass(Object)", "B_clean_title": ["avoid", "npe", "classutil", "toclass", "class", "util", "class", "object"]},
{"A_title": "StringResourceModel doesnt detach model in some casesWe have come across an issue with StringResourceModel not detaching the model it holds under a certain condition.  The problem is the case where the StringResourceModel is created but it is not used - for example when it is on a tab that is not displayed.  StringResourceModel is a subclass of LoadableDetachableModel and it simply implements onDetach() letting the superclass decide whether it is attached or not. The problem is that when StringResourceModel is created LoadableDetachableModel.attached will be false.  If the StringResourceModel is never read (i.e. getObject() is not called) the LoadableDetachableModel will not be marked as attached and when detach() is called onDetach() will not be called.  Therefore StringResourceModel will not call detach() on the model that it holds.", "A_clean_title": ["stringresourcemodel", "string", "resourc", "model", "doesnt", "detach", "model", "some", "casesw", "case", "we", "have", "come", "across", "issu", "stringresourcemodel", "string", "resourc", "model", "not", "detach", "model", "it", "hold", "under", "certain", "condit", "problem", "case", "where", "stringresourcemodel", "string", "resourc", "model", "creat", "but", "it", "not", "use", "exampl", "when", "it", "tab", "that", "not", "display", "stringresourcemodel", "string", "resourc", "model", "subclass", "loadabledetachablemodel", "loadabl", "detach", "model", "it", "simpli", "implement", "ondetach", "detach", "let", "superclass", "decid", "whether", "it", "attach", "or", "not", "problem", "that", "when", "stringresourcemodel", "string", "resourc", "model", "creat", "loadabledetachablemodel", "attach", "loadabl", "detach", "model", "will", "fals", "stringresourcemodel", "string", "resourc", "model", "never", "read", "getobject", "get", "object", "not", "call", "loadabledetachablemodel", "loadabl", "detach", "model", "will", "not", "mark", "as", "attach", "when", "detach", "call", "ondetach", "detach", "will", "not", "call", "therefor", "stringresourcemodel", "string", "resourc", "model", "will", "not", "call", "detach", "model", "that", "it", "hold"], "B_title": "StringResourceModel doesnt detach model in some cases", "B_clean_title": ["stringresourcemodel", "string", "resourc", "model", "doesnt", "detach", "model", "some", "case"]},
{"A_title": "Prototypes declared with quotes produce a JSC_USED_GLOBAL_THIS warning.None", "A_clean_title": ["prototyp", "declar", "quot", "produc", "jsc", "use", "global", "thi", "warn", "none"], "B_title": "Change on 2010/06/03 by nicksantos", "B_clean_title": ["chang", "2010", "06", "03", "by", "nicksanto"]},
{"A_title": "ODE integrator goes past specified end of integration rangeEnd of integration range in ODE solving is handled as an event. In some cases numerical accuracy in events detection leads to error in events location. The following test case shows the end event is not handled properly and an integration that should cover a 60s range in fact covers a 160s range more than twice the specified range. code   public void testMissedEvent() throws IntegratorException DerivativeException            final double t0 = 1878250320.0000029;           final double t =  1878250379.9999986;           FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations()                           public int getDimension()                  return 1;                                       public void computeDerivatives(double t double y double yDot)                 throws DerivativeException                  yDot0 = y0 * 1.0e-6;                      ;          DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0 100.0                                                                                1.0e-10 1.0e-10);          double y =  1.0 ;         integrator.setInitialStepSize(60.0);         double finalT = integrator.integrate(ode t0 y t y);         Assert.assertEquals(t finalT 1.0e-6);       code", "A_clean_title": ["ode", "integr", "goe", "past", "specifi", "end", "integr", "rangeend", "rang", "end", "integr", "rang", "ode", "solv", "handl", "as", "event", "some", "case", "numer", "accuraci", "event", "detect", "lead", "error", "event", "locat", "follow", "test", "case", "show", "end", "event", "not", "handl", "properli", "integr", "that", "cover", "60", "rang", "fact", "cover", "160", "rang", "more", "than", "twice", "specifi", "rang", "code", "public", "void", "testmissedev", "test", "miss", "event", "throw", "integratorexcept", "integr", "except", "derivativeexcept", "deriv", "except", "final", "doubl", "t0", "1878250320", "0000029", "final", "doubl", "1878250379", "9999986", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "ode", "new", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "public", "int", "getdimens", "get", "dimens", "return", "public", "void", "computederiv", "comput", "deriv", "doubl", "doubl", "doubl", "ydot", "dot", "throw", "derivativeexcept", "deriv", "except", "ydot0", "dot0", "y0", "0e", "dormandprince853integr", "dormand", "prince853integr", "integr", "new", "dormandprince853integr", "dormand", "prince853integr", "100", "10", "0e", "10", "0e", "doubl", "integr", "setinitialsteps", "set", "initi", "step", "size", "60", "doubl", "finalt", "final", "integr", "integr", "ode", "t0", "assert", "assertequ", "assert", "equal", "finalt", "final", "0e", "code"], "B_title": "Fixed an error in events handling in ODE solvers. In some rare cases events occurring close to a step start were handled without truncating the step making them appear as is they occurred close to the step end JIRA: MATH-358", "B_clean_title": ["fix", "error", "event", "handl", "ode", "solver", "some", "rare", "case", "event", "occur", "close", "step", "start", "were", "handl", "without", "truncat", "step", "make", "them", "appear", "as", "they", "occur", "close", "step", "end", "jira", "math", "358"]},
{"A_title": "SimplexSolver not working as expected?I guess (but I could be wrong) that SimplexSolver does not always return the optimal solution nor satisfies all the constraints...  Consider this LP:  max: 0.8 x0 + 0.2 x1 + 0.7 x2 + 0.3 x3 + 0.6 x4 + 0.4 x5; r1: x0 + x2 + x4 = 23.0; r2: x1 + x3 + x5 = 23.0; r3: x0 >= 10.0; r4: x2 >= 8.0; r5: x4 >= 5.0;  LPSolve returns 25.8 with x0 = 10.0 x1 = 0.0 x2 = 8.0 x3 = 0.0 x4 = 5.0 x5 = 23.0;  The same LP expressed in Apache commons math is:  LinearObjectiveFunction f = new LinearObjectiveFunction(new double  0.8 0.2 0.7 0.3 0.6 0.4  0 ); Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>(); constraints.add(new LinearConstraint(new double  1 0 1 0 1 0  Relationship.EQ 23.0)); constraints.add(new LinearConstraint(new double  0 1 0 1 0 1  Relationship.EQ 23.0)); constraints.add(new LinearConstraint(new double  1 0 0 0 0 0  Relationship.GEQ 10.0)); constraints.add(new LinearConstraint(new double  0 0 1 0 0 0  Relationship.GEQ 8.0)); constraints.add(new LinearConstraint(new double  0 0 0 0 1 0  Relationship.GEQ 5.0));  RealPointValuePair solution = new SimplexSolver().optimize(f constraints GoalType.MAXIMIZE true);  that returns 22.20 with x0 = 15.0 x1 = 23.0 x2 = 8.0 x3 = 0.0 x4 = 0.0 x5 = 0.0;  Is it possible SimplexSolver is buggy that way? The returned value is 22.20 instead of 25.8 and the last constraint (x4 >= 5.0) is not satisfied...  Am I using the interface wrongly?", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "guess", "but", "could", "wrong", "that", "simplexsolv", "simplex", "solver", "not", "alway", "return", "optim", "solut", "nor", "satisfi", "all", "constraint", "consid", "thi", "lp", "max", "x0", "x1", "x2", "x3", "x4", "x5", "r1", "x0", "x2", "x4", "23", "r2", "x1", "x3", "x5", "23", "r3", "x0", "10", "r4", "x2", "r5", "x4", "lpsolv", "lp", "solv", "return", "25", "x0", "10", "x1", "x2", "x3", "x4", "x5", "23", "same", "lp", "express", "apach", "common", "math", "linearobjectivefunct", "linear", "object", "function", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "constraint", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "23", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "23", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "10", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "realpointvaluepair", "real", "point", "valu", "pair", "solut", "new", "simplexsolv", "simplex", "solver", "optim", "constraint", "goaltyp", "maxim", "goal", "type", "true", "that", "return", "22", "20", "x0", "15", "x1", "23", "x2", "x3", "x4", "x5", "it", "possibl", "simplexsolv", "simplex", "solver", "buggi", "that", "way", "return", "valu", "22", "20", "instead", "25", "last", "constraint", "x4", "not", "satisfi", "am", "interfac", "wrongli"], "B_title": "fixed an error leading the simplex solver to compute the right solution but return another one JIRA: MATH-286", "B_clean_title": ["fix", "error", "lead", "simplex", "solver", "comput", "right", "solut", "but", "return", "anoth", "one", "jira", "math", "286"]},
{"A_title": "ResourceMapper throws IllegalStateException when attempting to map a request to a URL ending in a empty segment (directory)ResourceMapper.mapRequest() calls ResourceMapper.removeCachingDecoration() which throws IllegalStateException if the URLs last segment is an empty string.  URLs like: path/to/my/non/wicket/directory/ end in a empty segment.   We must change the behaviour to not attempt to undecorate a URL ending in an empty segment.", "A_clean_title": ["resourcemapp", "resourc", "mapper", "throw", "illegalstateexcept", "illeg", "state", "except", "when", "attempt", "map", "request", "url", "end", "empti", "segment", "directori", "resourcemapp", "maprequest", "resourc", "mapper", "map", "request", "call", "resourcemapp", "removecachingdecor", "resourc", "mapper", "remov", "cach", "decor", "which", "throw", "illegalstateexcept", "illeg", "state", "except", "url", "ur", "ls", "last", "segment", "empti", "string", "url", "ur", "ls", "like", "path", "my", "non", "wicket", "directori", "end", "empti", "segment", "we", "must", "chang", "behaviour", "not", "attempt", "undecor", "url", "end", "empti", "segment"], "B_title": "ResourceMapper throws IllegalStateException when attempting to map a request to a URL ending in a empty segment (directory)", "B_clean_title": ["resourcemapp", "resourc", "mapper", "throw", "illegalstateexcept", "illeg", "state", "except", "when", "attempt", "map", "request", "url", "end", "empti", "segment", "directori"]},
{"A_title": "404 Error on Nested ModalWindows in IE7 and IE8When opening a ModalWindow inside a ModalWindow the inner ModalWindow generates a 404 error.  Both windows use a PageCreator for content.  To replicate you must use an actual IE 7 or IE 8 browser as this does not replicate using developer tools and setting the document and brower to IE 7.  The problem can be seen at http://www.wicket-library.com/wicket-examples/ajax/modal-window.  I will attach a Quickstart as well.", "A_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8when", "open", "modalwindow", "modal", "window", "insid", "modalwindow", "modal", "window", "inner", "modalwindow", "modal", "window", "gener", "404", "error", "both", "window", "use", "pagecr", "page", "creator", "content", "replic", "you", "must", "use", "actual", "ie", "or", "ie", "browser", "as", "thi", "not", "replic", "develop", "tool", "set", "document", "brower", "ie", "problem", "seen", "at", "http", "window", "wicket", "librari", "exampl", "ajax", "modal", "www", "com", "wicket", "will", "attach", "quickstart", "as", "well"], "B_title": "404 Error on Nested ModalWindows in IE7 and IE8", "B_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8"]},
{"A_title": "Ordered Index Indexing on large content is slowIndexing large number of ordered properties is quite slow.  Explore ways of making it faster. The current skip list implementation uses 4 lanes with a probability of 10%. It should be made configurable and the defaults changed.", "A_clean_title": ["order", "index", "index", "larg", "content", "slowindex", "slow", "index", "larg", "number", "order", "properti", "quit", "slow", "explor", "way", "make", "it", "faster", "current", "skip", "list", "implement", "use", "lane", "probabl", "10", "it", "made", "configur", "default", "chang"], "B_title": "Ordered Index Indexing on large content is slow", "B_clean_title": ["order", "index", "index", "larg", "content", "slow"]},
{"A_title": "side-effects analysis incorrectly removing function calls with side effectsNone", "A_clean_title": ["side", "effect", "analysi", "incorrectli", "remov", "function", "call", "side", "effectsnon", "effect", "none"], "B_title": "Fix improper analysis of NEW the bad way: by assuming NEW always returns a non-local result. Fixes issue 303.", "B_clean_title": ["fix", "improp", "analysi", "new", "bad", "way", "by", "assum", "new", "alway", "return", "non", "local", "result", "fix", "issu", "303"]},
{"A_title": "NormalDistribution.cumulativeProbability() suffers from cancellationI see the following around line 194: noformat         return 0.5 * (1 + Erf.erf(dev / (standardDeviation * SQRT2))); noformat  When erf() returns a very small value this cancels in the addition with the 1.0 which leads to poor precision in the results.  I would suggest changing this line to read more like: noformat return 0.5 * Erf.erfc( -dev / standardDeviation * SQRT2 ); noformat   Should you want some test cases for extreme values (one might argue that within 10 standard deviations isnt all that extreme) then you can check the following: http://www.jstatsoft.org/v52/i07/ then look in the v52i07-xls.zip at replication-01-distribution-standard-normal.xls  I think you will also find that evaluation of expressions such as noformatNormalDistribution( 0 1 ).cumulativeProbability( -10.0 );noformat are pretty far off.", "A_clean_title": ["normaldistribut", "cumulativeprob", "normal", "distribut", "cumul", "probabl", "suffer", "cancellationi", "cancel", "see", "follow", "around", "line", "194", "noformat", "return", "erf", "erf", "dev", "standarddevi", "standard", "deviat", "sqrt2", "noformat", "when", "erf", "return", "veri", "small", "valu", "thi", "cancel", "addit", "which", "lead", "poor", "precis", "result", "would", "suggest", "chang", "thi", "line", "read", "more", "like", "noformat", "return", "erf", "erfc", "dev", "standarddevi", "standard", "deviat", "sqrt2", "noformat", "you", "want", "some", "test", "case", "extrem", "valu", "one", "might", "argu", "that", "within", "10", "standard", "deviat", "isnt", "all", "that", "extrem", "then", "you", "check", "follow", "http", "jstatsoft", "www", "org", "v52", "i07", "then", "look", "v52i07", "xl", "zip", "at", "replic", "01", "distribut", "standard", "normal", "xl", "think", "you", "will", "also", "find", "that", "evalu", "express", "such", "as", "noformatnormaldistribut", "noformat", "normal", "distribut", "cumulativeprob", "cumul", "probabl", "10", "noformat", "are", "pretti", "far", "off"], "B_title": "", "B_clean_title": []},
{"A_title": "alert(/ / / / /)None", "A_clean_title": ["alert", "none"], "B_title": "Fix issue 620", "B_clean_title": ["fix", "issu", "620"]},
{"A_title": "Redundent entries in effective policies per principal-setwhen retrieving the effective policies for a given set of principals the resulting array of policies contains redundant entries if a given policy contains multiple ACEs for the given set of principals.", "A_clean_title": ["redund", "entri", "effect", "polici", "per", "princip", "setwhen", "retriev", "effect", "polici", "given", "set", "princip", "result", "array", "polici", "contain", "redund", "entri", "given", "polici", "contain", "multipl", "ace", "ac", "es", "given", "set", "princip"], "B_title": ": Redundent entries in effective policies per principal-set", "B_clean_title": ["redund", "entri", "effect", "polici", "per", "princip", "set"]},
{"A_title": "precondition crash: goog.scope local with aliased in the type declarationNone", "A_clean_title": ["precondit", "crash", "goog", "scope", "local", "alias", "type", "declarationnon", "declar", "none"], "B_title": "Dont try to process jsdoc nodes twice. Fixes issue 1144 R=blickly", "B_clean_title": ["dont", "tri", "process", "jsdoc", "node", "twice", "fix", "issu", "1144", "r=blickli"]},
{"A_title": "CsvParser: Quotes cannot be escaped inside quoted fieldsWe should allow users to escape the quote character inside a quoted field.  Quoting could be realized through the  character like in: This is an escaped quotation.  Mailing list thread: http://apache-flink-mailing-list-archive.1008284.n3.nabble.com/jira-Created-FLINK-2567-CsvParser-Quotes-cannot-be-escaped-inside-quoted-fields-td7654.html", "A_clean_title": ["csvparser", "csv", "parser", "quot", "not", "escap", "insid", "quot", "fieldsw", "field", "we", "allow", "user", "escap", "quot", "charact", "insid", "quot", "field", "quot", "could", "realiz", "through", "charact", "like", "thi", "escap", "quotat", "mail", "list", "thread", "http", "flink", "mail", "list", "creat", "flink", "2567", "csvparser", "quot", "apach", "archiv", "1008284", "n3", "nabbl", "csv", "parser", "com", "jira", "not", "escap", "insid", "quot", "field", "td7654", "html"], "B_title": "core Allow quoted strings in CSV fields to contain quotation character inside of the field as long as its escaped Ex: Hi my name is Flink", "B_clean_title": ["core", "allow", "quot", "string", "csv", "field", "contain", "quotat", "charact", "insid", "field", "as", "long", "as", "it", "escap", "ex", "hi", "my", "name", "flink"]},
{"A_title": "URL rendering regressionThe way URLs are encoded was changed (WICKET-4645) and now the first request (with ;jsessionid in path) generates invalid internal links: My page is mounted to /Home/ and I get redirected to /Home/;jsessionid=1234?0 (fine). Theres a Link  on the page and the generated URL for it is ../Home;jsessionid=1234?0-1.ILinkListener-link. Note the missing /. This results in a 404 and breaks basically all of my system tests.  Ill attach a simple quickstart which demonstrates the problem. Its important to delete the jsessionid cookie before accessing the page.", "A_clean_title": ["url", "render", "regressionth", "regress", "way", "url", "ur", "ls", "are", "encod", "wa", "chang", "wicket", "4645", "now", "first", "request", "jsessionid", "path", "gener", "invalid", "intern", "link", "my", "page", "mount", "home", "get", "redirect", "home", "jsessionid=1234", "fine", "there", "link", "page", "gener", "url", "it", "home", "jsessionid=1234", "link", "ilinklisten", "link", "listen", "note", "miss", "thi", "result", "404", "break", "basic", "all", "my", "system", "test", "ill", "attach", "simpl", "quickstart", "which", "demonstr", "problem", "it", "import", "delet", "jsessionid", "cooki", "befor", "access", "page"], "B_title": "url rendering regression: keep trailing empty segment if base still has segments but relative has not", "B_clean_title": ["url", "render", "regress", "keep", "trail", "empti", "segment", "base", "still", "ha", "segment", "but", "rel", "ha", "not"]},
{"A_title": "Redirect to HTTPS is using wrong port 80 if HttpsConfig with default ports 80/443 is usedHttpsMapper#mapHandler() doesnt set the Urls port if the desired protocol uses the standard port.  This leads to UrlRenderer choosing to the requests port as fallback (which is 80 before switching to https).", "A_clean_title": ["redirect", "http", "wrong", "port", "80", "httpsconfig", "http", "config", "default", "port", "80", "443", "usedhttpsmapp", "use", "http", "mapper", "maphandl", "map", "handler", "doesnt", "set", "url", "port", "desir", "protocol", "use", "standard", "port", "thi", "lead", "urlrender", "url", "render", "choos", "request", "port", "as", "fallback", "which", "80", "befor", "switch", "http"], "B_title": "set port explicitly it wont be rendered by UrlRenderer if not required", "B_clean_title": ["set", "port", "explicitli", "it", "wont", "render", "by", "urlrender", "url", "render", "not", "requir"]},
{"A_title": "PropertyValidator ignoring groups with the @NotNull annotation onlyWhen using groups in your JSR303 compliant classes Wicket does not honor the groups for the @NotNull annotation.", "A_clean_title": ["propertyvalid", "properti", "valid", "ignor", "group", "notnul", "not", "null", "annot", "onlywhen", "onli", "when", "group", "your", "jsr303", "compliant", "class", "wicket", "not", "honor", "group", "notnul", "not", "null", "annot"], "B_title": "properly handle groups in NonNull constraint", "B_clean_title": ["properli", "handl", "group", "nonnul", "non", "null", "constraint"]},
{"A_title": "XPath backwards compatibility issue with false() and true()In JR2 (actually CRX 2) both of the following queries for nodes with a boolean property can be parsed however only query (a) returns search results. noformat     (a) /jcr:root/test//*@foo = true()     (b) /jcr:root/test//*@foo = true noformat  On Oak 1.2 query (a) results in an exception0 and query (b) returns search results.  See discussion at http://markmail.org/thread/kpews55jpdwm62ds", "A_clean_title": ["xpath", "path", "backward", "compat", "issu", "fals", "true", "jr2", "actual", "crx", "both", "follow", "queri", "node", "boolean", "properti", "pars", "howev", "onli", "queri", "return", "search", "result", "noformat", "jcr", "root", "test", "foo", "true", "jcr", "root", "test", "foo", "true", "noformat", "oak", "queri", "result", "exception0", "queri", "return", "search", "result", "see", "discuss", "at", "http", "markmail", "org", "thread", "kpews55jpdwm62d"], "B_title": "XPath backwards compatibility issue with false() and true()", "B_clean_title": ["xpath", "path", "backward", "compat", "issu", "fals", "true"]},
{"A_title": "UrlAttributes are encoded incorrectly when style is null but variation is notAbstractResourceReferenceMapper.encodeResourceReferenceAttributes() method generates the same -foo output for these two different inputs: locale = null style = foo variation = null and locale = null style = null variation = foo. For the second input it should generate --foo (double dash prefix).", "A_clean_title": ["urlattribut", "url", "attribut", "are", "encod", "incorrectli", "when", "style", "null", "but", "variat", "notabstractresourcereferencemapp", "encoderesourcereferenceattribut", "not", "abstract", "resourc", "refer", "mapper", "encod", "resourc", "refer", "attribut", "method", "gener", "same", "foo", "output", "these", "two", "differ", "input", "local", "null", "style", "foo", "variat", "null", "local", "null", "style", "null", "variat", "foo", "second", "input", "it", "gener", "foo", "doubl", "dash", "prefix"], "B_title": "UrlAttributes are encoded incorrectly when style is null but variation is not", "B_clean_title": ["urlattribut", "url", "attribut", "are", "encod", "incorrectli", "when", "style", "null", "but", "variat", "not"]},
{"A_title": "Index updation fails on updating multivalued propertyOn emptying a multivalued property fulltext index updation fails and one can search on old values. Following test demonstrates the issue. Added below test in LuceneIndexQueryTest.java|https://github.com/apache/jackrabbit-oak/blob/trunk/oak-lucene/src/test/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexQueryTest.java which should pass -  code     @Test     public void testMultiValuedPropUpdate() throws Exception          Tree test = root.getTree(/).addChild(test);         String child = child;         String mulValuedProp = prop;         test.addChild(child).setProperty(mulValuedProp of(foobar) Type.STRINGS);         root.commit();         assertQuery(                 /jcr:root//*jcr:contains(@ + mulValuedProp +  foo)                 xpath ImmutableList.of(/test/ + child));         test.getChild(child).setProperty(mulValuedProp new ArrayList<String>() Type.STRINGS);         root.commit();         assertQuery(                 /jcr:root//*jcr:contains(@ + mulValuedProp +  foo)                 xpath new ArrayList<String>());          test.getChild(child).setProperty(mulValuedProp of(bar) Type.STRINGS);         root.commit();         assertQuery(                 /jcr:root//*jcr:contains(@ + mulValuedProp +  foo)                 xpath new ArrayList<String>());       code", "A_clean_title": ["index", "updat", "fail", "updat", "multivalu", "propertyon", "properti", "empti", "multivalu", "properti", "fulltext", "index", "updat", "fail", "one", "search", "old", "valu", "follow", "test", "demonstr", "issu", "ad", "below", "test", "luceneindexquerytest", "java|http", "lucen", "index", "queri", "test", "oak", "blob", "trunk", "oak", "java", "github", "com", "apach", "jackrabbit", "lucen", "src", "test", "java", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexquerytest", "lucen", "index", "queri", "test", "which", "pass", "code", "test", "public", "void", "testmultivaluedpropupd", "test", "multi", "valu", "prop", "updat", "throw", "except", "tree", "test", "root", "gettre", "get", "tree", "addchild", "add", "child", "test", "string", "child", "child", "string", "mulvaluedprop", "mul", "valu", "prop", "prop", "test", "addchild", "add", "child", "child", "setproperti", "set", "properti", "mulvaluedprop", "mul", "valu", "prop", "foobar", "type", "string", "root", "commit", "assertqueri", "assert", "queri", "jcr", "root", "jcr", "contain", "mulvaluedprop", "mul", "valu", "prop", "foo", "xpath", "immutablelist", "immut", "list", "test", "child", "test", "getchild", "get", "child", "child", "setproperti", "set", "properti", "mulvaluedprop", "mul", "valu", "prop", "new", "arraylist", "array", "list", "string", "type", "string", "root", "commit", "assertqueri", "assert", "queri", "jcr", "root", "jcr", "contain", "mulvaluedprop", "mul", "valu", "prop", "foo", "xpath", "new", "arraylist", "array", "list", "string", "test", "getchild", "get", "child", "child", "setproperti", "set", "properti", "mulvaluedprop", "mul", "valu", "prop", "bar", "type", "string", "root", "commit", "assertqueri", "assert", "queri", "jcr", "root", "jcr", "contain", "mulvaluedprop", "mul", "valu", "prop", "foo", "xpath", "new", "arraylist", "array", "list", "string", "code"], "B_title": "Index updation fails on updating multivalued property", "B_clean_title": ["index", "updat", "fail", "updat", "multivalu", "properti"]},
{"A_title": "Certain Avro generated getters/setters not recognizedFor Avro schemas where value null is not allowed the field is unboxed e.g. int but the getter/setter methods provide the boxed Integer as interface:  code   fields:        type: double     name: time      code  This results in Java  code   private double time;    public java.lang.Double getTime()      return time;       public void setTime(java.lang.Double value)      this.time = value;    code  There is also a problem when there is an underscore in the Avro schema e.g.:  code       default: null     type:      null      long         name: conn_id     code  This results in Java:  code private java.lang.Long conn_id;    public java.lang.Long getConnId()      return conn_id;       public void setConnId(java.lang.Long value)      this.conn_id = value;    code", "A_clean_title": ["certain", "avro", "gener", "getter", "setter", "not", "recognizedfor", "recogn", "avro", "schema", "where", "valu", "null", "not", "allow", "field", "unbox", "int", "but", "getter", "setter", "method", "provid", "box", "integ", "as", "interfac", "code", "field", "type", "doubl", "name", "time", "code", "thi", "result", "java", "code", "privat", "doubl", "time", "public", "java", "lang", "doubl", "gettim", "get", "time", "return", "time", "public", "void", "settim", "set", "time", "java", "lang", "doubl", "valu", "thi", "time", "valu", "code", "there", "also", "problem", "when", "there", "underscor", "avro", "schema", "code", "default", "null", "type", "null", "long", "name", "conn", "id", "code", "thi", "result", "java", "code", "privat", "java", "lang", "long", "conn", "id", "public", "java", "lang", "long", "getconnid", "get", "conn", "id", "return", "conn", "id", "public", "void", "setconnid", "set", "conn", "id", "java", "lang", "long", "valu", "thi", "conn", "id", "valu", "code"], "B_title": "Fix Avro getter/setter recognition", "B_clean_title": ["fix", "avro", "getter", "setter", "recognit"]},
{"A_title": "Upgraded version history has UUIDs as jcr:frozenUuid of non-referenceable nodesIn Jackrabbit Classic each node even non-referenceable ones has a UUID as its identifier and thus the jcr:frozenUuid properties of frozen nodes are always UUIDs. In contrast Oak uses path identifiers for non-referenceable frozen nodes (see OAK-1009) which presents a problem when dealing with version histories migrated from Jackrabbit Classic.  To avoid this mismatch the upgrade code should check each frozen node for referenceability and replace the frozen UUID with a path identifier if needed.", "A_clean_title": ["upgrad", "version", "histori", "ha", "uuid", "uui", "ds", "as", "jcr", "frozenuuid", "frozen", "uuid", "non", "referenc", "nodesin", "node", "jackrabbit", "classic", "each", "node", "even", "non", "referenc", "one", "ha", "uuid", "as", "it", "identifi", "thu", "jcr", "frozenuuid", "frozen", "uuid", "properti", "frozen", "node", "are", "alway", "uuid", "uui", "ds", "contrast", "oak", "use", "path", "identifi", "non", "referenc", "frozen", "node", "see", "oak", "1009", "which", "present", "problem", "when", "deal", "version", "histori", "migrat", "jackrabbit", "classic", "avoid", "thi", "mismatch", "upgrad", "code", "check", "each", "frozen", "node", "referenc", "replac", "frozen", "uuid", "path", "identifi", "need"], "B_title": "Upgraded version history has UUIDs as jcr:frozenUuid of non-referenceable nodes", "B_clean_title": ["upgrad", "version", "histori", "ha", "uuid", "uui", "ds", "as", "jcr", "frozenuuid", "frozen", "uuid", "non", "referenc", "node"]},
{"A_title": "ConvergenceException in normal CDFNormalDistributionImpl::cumulativeProbability(double x) throws ConvergenceException if x deviates too much from the mean. For example when x=+/-100 mean=0 sd=1. Of course the value of the CDF is hard to evaluate in these cases but effectively it should be either zero or one.", "A_clean_title": ["convergenceexcept", "converg", "except", "normal", "cdfnormaldistributionimpl", "cdf", "normal", "distribut", "impl", ":cumulativeprob", ":cumul", "probabl", "doubl", "throw", "convergenceexcept", "converg", "except", "deviat", "too", "much", "mean", "exampl", "when", "100", "x=+", "mean=0", "sd=1", "cours", "valu", "cdf", "hard", "evalu", "these", "case", "but", "effect", "it", "either", "zero", "or", "one"], "B_title": "Modified NormalDistributionImpl.cumulativeProbablity to catch MaxIterationsExceededException and return 0 or 1 resp. if the argument is more than 20 standard deviations from the mean.", "B_clean_title": ["modifi", "normaldistributionimpl", "cumulativeprobabl", "normal", "distribut", "impl", "cumul", "probabl", "catch", "maxiterationsexceededexcept", "max", "iter", "exceed", "except", "return", "or", "resp", "argument", "more", "than", "20", "standard", "deviat", "mean"]},
{"A_title": "Url#getQueryString(charset) method returns quesrystring with ? prefixed to iti have just pointed out 6.0.0-beta3/6.x but it must be same in 1.5.x too afaik ? is not considered part of querystring ? is considered separator see http://tools.ietf.org/html/rfc3986#section-3 this method is used in Url#toString() too which can be easily fixed but it may be used at other places too so i dont know if removing ? will break things now.  so how things break currently RequestUtils.decodeParameters(url.getQueryString()parameters); decodeparameters will considered first key to be ?key  so may be requestutils#decodeparameters method should strip away ? if its present in the query string before populating pageparameters  thanks!", "A_clean_title": ["url", "getquerystr", "get", "queri", "string", "charset", "method", "return", "quesrystr", "prefix", "iti", "have", "just", "point", "out", "beta3", "but", "it", "must", "same", "too", "afaik", "not", "consid", "part", "querystr", "consid", "separ", "see", "http", "ietf", "tool", "org", "html", "rfc3986", "section", "thi", "method", "use", "url", "tostr", "string", "too", "which", "easili", "fix", "but", "it", "may", "use", "at", "other", "place", "too", "so", "dont", "know", "remov", "will", "break", "thing", "now", "so", "how", "thing", "break", "current", "requestutil", "decodeparamet", "request", "util", "decod", "paramet", "url", "getquerystr", "get", "queri", "string", "paramet", "decodeparamet", "will", "consid", "first", "key", "key", "so", "may", "requestutil", "decodeparamet", "method", "strip", "away", "it", "present", "queri", "string", "befor", "popul", "pageparamet", "thank"], "B_title": "Complement for WICKET-4664", "B_clean_title": ["complement", "wicket", "4664"]},
{"A_title": "delete mutations not working through the ProxyAru Sahni writes:  quote Im new to Accumulo and am still trying to wrap my head around its ways. To further that challenge Im using Pyaccumulo which doesnt present much in terms of available reference material.  Right now Im trying to understand how Accumulo manages record (key-value pair) deletions.  conn = Accumulo(host port user password) table = test_table conn.create_table(table) writer = conn.create_batch_writer(table) mut = Mutation(mut_01) mut.put(cf=item cq=name value=car) writer.add_mutation(mut) writer.close() conn.close()  Will generate a record (found via a shell scan):  mut_01 item:name     car  However the subsequent mutation...  writer = conn.create_batch_writer(table) mut = Mutation(mut_01) mut.put(cf=item cq=name is_delete=True) writer.add_mutation(mut) writer.close()  Results in:  mut_01 item:name   How should one expect the deleted row to be represented? That record sticks around even after I force a compaction of the table.  I was expecting it to not show up in any iterators or at least provide an easy way to see if the cell has been deleted. quote  ~ecn has confirmed the problem.", "A_clean_title": ["delet", "mutat", "not", "work", "through", "proxyaru", "proxi", "aru", "sahni", "write", "quot", "im", "new", "accumulo", "am", "still", "tri", "wrap", "my", "head", "around", "it", "way", "further", "that", "challeng", "im", "pyaccumulo", "which", "doesnt", "present", "much", "term", "avail", "refer", "materi", "right", "now", "im", "tri", "understand", "how", "accumulo", "manag", "record", "key", "valu", "pair", "delet", "conn", "accumulo", "host", "port", "user", "password", "tabl", "test", "tabl", "conn", "creat", "tabl", "tabl", "writer", "conn", "creat", "batch", "writer", "tabl", "mut", "mutat", "mut", "01", "mut", "put", "cf=item", "cq=name", "value=car", "writer", "add", "mutat", "mut", "writer", "close", "conn", "close", "will", "gener", "record", "found", "via", "shell", "scan", "mut", "01", "item", "name", "car", "howev", "subsequ", "mutat", "writer", "conn", "creat", "batch", "writer", "tabl", "mut", "mutat", "mut", "01", "mut", "put", "cf=item", "cq=name", "delete=tru", "writer", "add", "mutat", "mut", "writer", "close", "result", "mut", "01", "item", "name", "how", "one", "expect", "delet", "row", "repres", "that", "record", "stick", "around", "even", "after", "forc", "compact", "tabl", "wa", "expect", "it", "not", "show", "up", "ani", "iter", "or", "at", "least", "provid", "easi", "way", "see", "cell", "ha", "been", "delet", "quot", "~ecn", "ha", "confirm", "problem"], "B_title": "fix deletes added test", "B_clean_title": ["fix", "delet", "ad", "test"]},
{"A_title": "Queuing a component in headQueuing a component which is in the head section doesnt work : <head> <meta charset=utf-8 /> <title wicket:id=titre>Test</title> </head>", "A_clean_title": ["queu", "compon", "headqueu", "head", "queu", "compon", "which", "head", "section", "doesnt", "work", "head", "meta", "charset=utf", "titl", "wicket", "id=titr", "test", "titl", "head"], "B_title": "Queuing a component in head", "B_clean_title": ["queu", "compon", "head"]},
{"A_title": "Duration.toPeriod with fixed time zones.I have a question concerning the conversion of a Duration to Period. Im not sure if this is a bug or if there is a different way to do this.  The basis of the problem is that using Duration.toPeriod() uses the chronology of the default time zone to do the conversion. This can cause different results from a timezone with DST and one without. This can be reproduced easily with this test. In the joda code Duration.toPeriod() uses a period constructor that takes the chronology but null is passed in so the chronology of the default time zone is used which leads to this behavior.  The javadoc of toPeriod() states that only precise fields of hours minutes seconds and millis will be converted. But for a fixed timezone days and weeks are also precise which is stated in the javadoc for toPeriod(Chronology chrono). In our app we need consistent behavior regardless of the default time zone which is to have all the extra hours put into the hours bucket. Since Duration is supposed to be a time zone independent length of time I dont think we should have to do any chronology manipulation to get this to work.", "A_clean_title": ["durat", "toperiod", "period", "fix", "time", "zone", "have", "question", "concern", "convers", "durat", "period", "im", "not", "sure", "thi", "bug", "or", "there", "differ", "way", "thi", "basi", "problem", "that", "durat", "toperiod", "period", "use", "chronolog", "default", "time", "zone", "convers", "thi", "caus", "differ", "result", "timezon", "dst", "one", "without", "thi", "reproduc", "easili", "thi", "test", "joda", "code", "durat", "toperiod", "period", "use", "period", "constructor", "that", "take", "chronolog", "but", "null", "pass", "so", "chronolog", "default", "time", "zone", "use", "which", "lead", "thi", "behavior", "javadoc", "toperiod", "period", "state", "that", "onli", "precis", "field", "hour", "minut", "second", "milli", "will", "convert", "but", "fix", "timezon", "day", "week", "are", "also", "precis", "which", "state", "javadoc", "toperiod", "period", "chronolog", "chrono", "our", "app", "we", "need", "consist", "behavior", "regardless", "default", "time", "zone", "which", "have", "all", "extra", "hour", "put", "into", "hour", "bucket", "sinc", "durat", "suppos", "time", "zone", "independ", "length", "time", "dont", "think", "we", "have", "ani", "chronolog", "manipul", "get", "thi", "work"], "B_title": "Duraton.toPeriod() new Period(long) new MutablePeriod(long) 3264409 Fixed to obey Javadoc. Previously they didnt obey the Javadoc if the default time-zone had no daylight savings.", "B_clean_title": ["duraton", "toperiod", "period", "new", "period", "long", "new", "mutableperiod", "mutabl", "period", "long", "3264409", "fix", "obey", "javadoc", "previous", "they", "didnt", "obey", "javadoc", "default", "time", "zone", "had", "no", "daylight", "save"]},
{"A_title": "Failing tests on Windows machineNone", "A_clean_title": ["fail", "test", "window", "machinenon", "machin", "none"], "B_title": "printing args on smart nulls toString (Issue #225)", "B_clean_title": ["print", "arg", "smart", "null", "tostr", "string", "issu", "225"]},
{"A_title": "Nested Redirects and REDIRECT_TO_BUFFERWhen the render strategy is REDIRECT_TO_BUFFER redirects cannot be nested. After the second redirect Wicket renders the buffered first page in preference to the second page. The relevant code is in WebPageRenderer.respond:  noformat if (bufferedResponse != null)  logger.warn(The Buffered response should be handled by BufferedResponseRequestHandler); // if there is saved response for this URL render it bufferedResponse.writeTo((WebResponse)requestCycle.getResponse());  noformat  The attached quickstart demonstrates the issue. Simply navigate to the home page. The observed behavior is that Page1 is displayed but I expect Page2 to be displayed.  I can work around the issue by calling WebApplication.getAndRemoveBufferedResponse() to clear the render buffer but I am uneasy with this solution since it seems like I am playing with Wicket internals; albeit the function is public.", "A_clean_title": ["nest", "redirect", "redirect", "bufferwhen", "buffer", "when", "render", "strategi", "redirect", "buffer", "redirect", "not", "nest", "after", "second", "redirect", "wicket", "render", "buffer", "first", "page", "prefer", "second", "page", "relev", "code", "webpagerender", "respond", "web", "page", "render", "noformat", "bufferedrespons", "buffer", "respons", "null", "logger", "warn", "buffer", "respons", "handl", "by", "bufferedresponserequesthandl", "buffer", "respons", "request", "handler", "there", "save", "respons", "thi", "url", "render", "it", "bufferedrespons", "writeto", "buffer", "respons", "write", "webrespons", "web", "respons", "requestcycl", "getrespons", "request", "cycl", "get", "respons", "noformat", "attach", "quickstart", "demonstr", "issu", "simpli", "navig", "home", "page", "observ", "behavior", "that", "page1", "display", "but", "expect", "page2", "display", "work", "around", "issu", "by", "call", "webappl", "getandremovebufferedrespons", "web", "applic", "get", "remov", "buffer", "respons", "clear", "render", "buffer", "but", "am", "uneasi", "thi", "solut", "sinc", "it", "seem", "like", "am", "play", "wicket", "intern", "albeit", "function", "public"], "B_title": "Nested Redirects and REDIRECT_TO_BUFFER", "B_clean_title": ["nest", "redirect", "redirect", "buffer"]},
{"A_title": "Incorrect assignment removal from expression in simple mode.None", "A_clean_title": ["incorrect", "assign", "remov", "express", "simpl", "mode", "none"], "B_title": "Fix checks for variable reads in expressions with assignments. Fixes issue 297.", "B_clean_title": ["fix", "check", "variabl", "read", "express", "assign", "fix", "issu", "297"]},
{"A_title": "Correlated random vector generator fails (silently) when faced with zero rows in covariance matrixThe following three matrices (which are basically permutations of each other) produce different results when sampling a multi-variate Gaussian with the help of CorrelatedRandomVectorGenerator (sample covariances calculated in R based on 10000 samples):  Array2DRowRealMatrix 0.00.00.00.00.0 0.00.0134455320.010394690.0098811560.010499559 0.00.010394690.0230066160.0081968560.010732709 0.00.0098811560.0081968560.0190238660.009210099 0.00.0104995590.0107327090.0092100990.019107243  > cov(data1)    V1 V2 V3 V4 V5 V1 0 0.000000000 0.00000000 0.000000000 0.000000000 V2 0 0.013383931 0.01034401 0.009913271 0.010506733 V3 0 0.010344006 0.02309479 0.008374730 0.010759306 V4 0 0.009913271 0.00837473 0.019005488 0.009187287 V5 0 0.010506733 0.01075931 0.009187287 0.019021483  Array2DRowRealMatrix 0.0134455320.010394690.00.0098811560.010499559 0.010394690.0230066160.00.0081968560.010732709 0.00.00.00.00.0 0.0098811560.0081968560.00.0190238660.009210099 0.0104995590.0107327090.00.0092100990.019107243  > cov(data2)             V1 V2 V3 V4 V5 V1 0.006922905 0.010507692 0 0.005817399 0.010330529 V2 0.010507692 0.023428918 0 0.008273152 0.010735568 V3 0.000000000 0.000000000 0 0.000000000 0.000000000 V4 0.005817399 0.008273152 0 0.004929843 0.009048759 V5 0.010330529 0.010735568 0 0.009048759 0.018683544   Array2DRowRealMatrix 0.0134455320.010394690.0098811560.010499559 0.010394690.0230066160.0081968560.010732709 0.0098811560.0081968560.0190238660.009210099 0.0104995590.0107327090.0092100990.019107243  > cov(data3)             V1          V2          V3          V4 V1 0.013445047 0.010478862 0.009955904 0.010529542 V2 0.010478862 0.022910522 0.008610113 0.011046353 V3 0.009955904 0.008610113 0.019250975 0.009464442 V4 0.010529542 0.011046353 0.009464442 0.019260317   Ive traced this back to the RectangularCholeskyDecomposition which does not seem to handle the second matrix very well (decompositions in the same order as the matrices above):  CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.00.00.00.00.00.07595774181220630.08761251884742390.00.00.00.077644436225135050.051328212214607520.119763818217912350.00.00.066629305279094040.055016617441145850.00166625065193079970.107493242076536320.00.138228951381394770.00.00.00.0 CorrelatedRandomVectorGenerator.getRank() = 5  CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.07595774181220630.0345127513794487240.00.077644436225135050.130299491646287460.00.00.00.00.066629305279094040.0232039366948556740.00.138228951381394770.00.0 CorrelatedRandomVectorGenerator.getRank() = 3  CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.07595774181220630.0345127513794487240.0339137482263482250.073038901499477850.077644436225135050.130299491646287460.00.00.066629305279094040.0232039366948556740.118515733132299450.00.138228951381394770.00.00.0 CorrelatedRandomVectorGenerator.getRank() = 4  Clearly the rank of each of these matrices should be 4. The first matrix does not lead to incorrect results but the second one does. Unfortunately I dont know enough about the Cholesky decomposition to find the flaw in the implementation and I could not find documentation for the rectangular variant (also not at the links provided in the javadoc).", "A_clean_title": ["correl", "random", "vector", "gener", "fail", "silent", "when", "face", "zero", "row", "covari", "matrixth", "matrix", "follow", "three", "matric", "which", "are", "basic", "permut", "each", "other", "produc", "differ", "result", "when", "sampl", "multi", "variat", "gaussian", "help", "correlatedrandomvectorgener", "correl", "random", "vector", "gener", "sampl", "covari", "calcul", "base", "10000", "sampl", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "00", "00", "00", "00", "00", "0134455320", "010394690", "0098811560", "010499559", "00", "010394690", "0230066160", "0081968560", "010732709", "00", "0098811560", "0081968560", "0190238660", "009210099", "00", "0104995590", "0107327090", "0092100990", "019107243", "cov", "data1", "v1", "v2", "v3", "v4", "v5", "v1", "000000000", "00000000", "000000000", "000000000", "v2", "013383931", "01034401", "009913271", "010506733", "v3", "010344006", "02309479", "008374730", "010759306", "v4", "009913271", "00837473", "019005488", "009187287", "v5", "010506733", "01075931", "009187287", "019021483", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "0134455320", "010394690", "00", "0098811560", "010499559", "010394690", "0230066160", "00", "0081968560", "010732709", "00", "00", "00", "00", "0098811560", "0081968560", "00", "0190238660", "009210099", "0104995590", "0107327090", "00", "0092100990", "019107243", "cov", "data2", "v1", "v2", "v3", "v4", "v5", "v1", "006922905", "010507692", "005817399", "010330529", "v2", "010507692", "023428918", "008273152", "010735568", "v3", "000000000", "000000000", "000000000", "000000000", "v4", "005817399", "008273152", "004929843", "009048759", "v5", "010330529", "010735568", "009048759", "018683544", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "0134455320", "010394690", "0098811560", "010499559", "010394690", "0230066160", "0081968560", "010732709", "0098811560", "0081968560", "0190238660", "009210099", "0104995590", "0107327090", "0092100990", "019107243", "cov", "data3", "v1", "v2", "v3", "v4", "v1", "013445047", "010478862", "009955904", "010529542", "v2", "010478862", "022910522", "008610113", "011046353", "v3", "009955904", "008610113", "019250975", "009464442", "v4", "010529542", "011046353", "009464442", "019260317", "ive", "trace", "thi", "back", "rectangularcholeskydecomposit", "rectangular", "choleski", "decomposit", "which", "not", "seem", "handl", "second", "matrix", "veri", "well", "decomposit", "same", "order", "as", "matric", "abov", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "00", "00", "00", "00", "00", "07595774181220630", "08761251884742390", "00", "00", "00", "077644436225135050", "051328212214607520", "119763818217912350", "00", "00", "066629305279094040", "055016617441145850", "00166625065193079970", "107493242076536320", "00", "138228951381394770", "00", "00", "00", "array2d", "row", "real", "matrix0", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "07595774181220630", "0345127513794487240", "00", "077644436225135050", "130299491646287460", "00", "00", "00", "00", "066629305279094040", "0232039366948556740", "00", "138228951381394770", "00", "array2d", "row", "real", "matrix0", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "07595774181220630", "0345127513794487240", "0339137482263482250", "073038901499477850", "077644436225135050", "130299491646287460", "00", "00", "066629305279094040", "0232039366948556740", "118515733132299450", "00", "138228951381394770", "00", "00", "array2d", "row", "real", "matrix0", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "clearli", "rank", "each", "these", "matric", "first", "matrix", "not", "lead", "incorrect", "result", "but", "second", "one", "unfortun", "dont", "know", "enough", "about", "choleski", "decomposit", "find", "flaw", "implement", "could", "not", "find", "document", "rectangular", "variant", "also", "not", "at", "link", "provid", "javadoc"], "B_title": "Fixed an error in rectangular Cholesky decomposition.", "B_clean_title": ["fix", "error", "rectangular", "choleski", "decomposit"]},
{"A_title": "FormComponents remain invalid forever if there is no feedback panelif there is no feedback panel the error messages are not removed in ondetach and form component re-validation is skipped so the form component once marked as invalid will remain invalid forever or at least until its error messages are rendered.  the error messages should be dropped and the form component should be re-validated on every form submit.", "A_clean_title": ["formcompon", "form", "compon", "remain", "invalid", "forev", "there", "no", "feedback", "panelif", "there", "no", "feedback", "panel", "error", "messag", "are", "not", "remov", "ondetach", "form", "compon", "re", "valid", "skip", "so", "form", "compon", "onc", "mark", "as", "invalid", "will", "remain", "invalid", "forev", "or", "at", "least", "until", "it", "error", "messag", "are", "render", "error", "messag", "drop", "form", "compon", "re", "valid", "everi", "form", "submit"], "B_title": "fix form validation bug where form components would remain invalid until their error messages were rendered", "B_clean_title": ["fix", "form", "valid", "bug", "where", "form", "compon", "would", "remain", "invalid", "until", "their", "error", "messag", "were", "render"]},
{"A_title": "ISecuritySettings#getEnforceMounts(true) prevents access to *all* non-mounted bookmarkable pagesISecuritySettings#setEnforceMounts(true) is meant to be used to prevent access to mounted-pages via BookmarkableMapper e.g. when Page1.class is mounted:     http://localhost:8080/niceurl/a/nice/path/to/the/first/page  ... then the following url will not be accepted:     http://localhost:8080/niceurl/wicket/bookmarkable/org.apache.wicket.examples.niceurl.Page1  But starting with Wicket 1.5.x access to *all* non-mounted pages via BookmarkableMapper is prevented i.e. no url http://localhost:8080/niceurl/wicket/bookmarkable/* is matched.", "A_clean_title": ["isecurityset", "secur", "set", "getenforcemount", "get", "enforc", "mount", "true", "prevent", "access", "all", "non", "mount", "bookmark", "pagesisecurityset", "page", "secur", "set", "setenforcemount", "set", "enforc", "mount", "true", "meant", "use", "prevent", "access", "mount", "page", "via", "bookmarkablemapp", "bookmark", "mapper", "when", "page1", "class", "mount", "http", "localhost:8080", "niceurl", "nice", "path", "first", "page", "then", "follow", "url", "will", "not", "accept", "http", "apach", "wicket", "exampl", "niceurl", "page1", "localhost:8080", "niceurl", "wicket", "bookmark", "org", "but", "start", "wicket", "access", "all", "non", "mount", "page", "via", "bookmarkablemapp", "bookmark", "mapper", "prevent", "no", "url", "http", "localhost:8080", "niceurl", "wicket", "bookmark", "match"], "B_title": "enforce mount for mounted pages only", "B_clean_title": ["enforc", "mount", "mount", "page", "onli"]},
{"A_title": "Instance secret written out with other configuration items to RFiles and WALogs when encryption is turned onThe encryption at rest feature records configuration information in order to encrypted RFiles and WALogs so that if the configuration changes the files can be read back.  The code that does this recording hovers up all the instance.* entries and does not pick out the instance.secret as a special one not to write.  Thus the instance secret goes into each file in the clear which is non-ideal to say the least.  Patch forthcoming.", "A_clean_title": ["instanc", "secret", "written", "out", "other", "configur", "item", "rfile", "file", "walog", "wa", "log", "when", "encrypt", "turn", "onth", "encrypt", "at", "rest", "featur", "record", "configur", "inform", "order", "encrypt", "rfile", "file", "walog", "wa", "log", "so", "that", "configur", "chang", "file", "read", "back", "code", "that", "thi", "record", "hover", "up", "all", "instanc", "entri", "not", "pick", "out", "instanc", "secret", "as", "special", "one", "not", "write", "thu", "instanc", "secret", "goe", "into", "each", "file", "clear", "which", "non", "ideal", "say", "least", "patch", "forthcom"], "B_title": "fixing Michael Allens patch and adding test", "B_clean_title": ["fix", "michael", "allen", "patch", "ad", "test"]},
{"A_title": "Sometimes hierarchy conflict between concurrent add/delete isnt detectedIm not sure of exact set of event that led to an incident on one of our test clusters. The cluster is running 3 AEM instances based on oak build at 1.3.10.r1713699 backed by a single mongo 3 instance.  Unfortunately we found the issue too late and logs had rolled over. Heres the exception that showed over and over as workflow jobs were (trying to) being processed: noformat ....         at java.lang.Thread.run(Thread.java:745) Caused by: javax.jcr.InvalidItemStateException: OakMerge0004: OakMerge0004: The node 8:/oak:index/event.job.topic/:index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel/var/eventing/jobs/assigned was already added in revision r151233e54e1-0-4 before r15166378b6a-0-2 (retries 5 6830 ms)         at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:239)         at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:212)         at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.newRepositoryException(SessionDelegate.java:669)         at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:495)         at org.apache.jackrabbit.oak.jcr.session.SessionImpl 8.performVoid(SessionImpl.java:419)         at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.performVoid(SessionDelegate.java:273)         at org.apache.jackrabbit.oak.jcr.session.SessionImpl.save(SessionImpl.java:416)         at org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProvider.commit(JcrResourceProvider.java:634)         ... 16 common frames omitted Caused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakMerge0004: OakMerge0004: The node 8:/oak:index/event.job.topic/:index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel/var/eventing/jobs/assigned was already added in revision r151233e54e1-0-4 before r15166378b6a-0-2 (retries 5 6830 ms)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge0(DocumentNodeStoreBranch.java:200)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge(DocumentNodeStoreBranch.java:123)         at org.apache.jackrabbit.oak.plugins.document.DocumentRootBuilder.merge(DocumentRootBuilder.java:158)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.merge(DocumentNodeStore.java:1497)         at org.apache.jackrabbit.oak.core.MutableRoot.commit(MutableRoot.java:247)         at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.commit(SessionDelegate.java:346)         at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:493)         ... 20 common frames omitted Caused by: org.apache.jackrabbit.oak.plugins.document.ConflictException: The node 8:/oak:index/event.job.topic/:index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel/var/eventing/jobs/assigned was already added in revision r151233e54e1-0-4 before r15166378b6a-0-2         at org.apache.jackrabbit.oak.plugins.document.Commit.checkConflicts(Commit.java:582)         at org.apache.jackrabbit.oak.plugins.document.Commit.createOrUpdateNode(Commit.java:487)         at org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:371)         at org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:265)         at org.apache.jackrabbit.oak.plugins.document.Commit.applyInternal(Commit.java:234)         at org.apache.jackrabbit.oak.plugins.document.Commit.apply(Commit.java:219)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:290)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:260)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.access 300(DocumentNodeStoreBranch.java:54)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch InMemory.merge(DocumentNodeStoreBranch.java:498)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge0(DocumentNodeStoreBranch.java:180)         ... 26 common frames omitted .... noformat  Doing following removed repo corruption and restored w/f processing: noformat oak.removeDescendantsAndSelf(/oak:index/event.job.topic/:index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel/var/eventing/jobs/assigned) noformat  Attaching mongoexport output|^mongoexport.zip for /oak:index/event.job.topic/:index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel/var/eventing/jobs/assigned/6a389a6a-a8bf-4038-b57b-cb441c6ac557/com.adobe.granite.workflow.transient.job.etc.workflow.models.dam-xmp-writeback.jcr_content.model/2015/11/19/23/54/6a389a6a-a8bf-4038-b57b-cb441c6ac557_10 (the hierarchy created at r151233e54e1-0-4). Ive renamed a few path elements to make it more reable though (e.g. :index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel -> enc_value).  ~mreutegg Im assigning it to myself for now but I think this would require your expertise all the way :).", "A_clean_title": ["sometim", "hierarchi", "conflict", "between", "concurr", "add", "delet", "isnt", "detectedim", "detect", "im", "not", "sure", "exact", "set", "event", "that", "led", "incid", "one", "our", "test", "cluster", "cluster", "run", "aem", "instanc", "base", "oak", "build", "at", "10", "r1713699", "back", "by", "singl", "mongo", "instanc", "unfortun", "we", "found", "issu", "too", "late", "log", "had", "roll", "over", "here", "except", "that", "show", "over", "over", "as", "workflow", "job", "were", "tri", "be", "process", "noformat", "at", "java", "lang", "thread", "run", "thread", "java:745", "caus", "by", "javax", "jcr", "invaliditemstateexcept", "invalid", "item", "state", "except", "oakmerge0004", "oak", "merge0004", "oakmerge0004", "oak", "merge0004", "node", "oak", "job", "index", "event", "topic", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "2fmodel", "var", "event", "job", "assign", "wa", "alreadi", "ad", "revis", "r151233e54e1", "befor", "r15166378b6a", "retri", "6830", "ms", "at", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "asrepositoryexcept", "commit", "fail", "except", "as", "repositori", "except", "commitfailedexcept", "java:239", "commit", "fail", "except", "at", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "asrepositoryexcept", "commit", "fail", "except", "as", "repositori", "except", "commitfailedexcept", "java:212", "commit", "fail", "except", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "newrepositoryexcept", "session", "deleg", "new", "repositori", "except", "sessiondeleg", "java:669", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:495", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "session", "impl", "performvoid", "perform", "void", "sessionimpl", "java:419", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "performvoid", "session", "deleg", "perform", "void", "sessiondeleg", "java:273", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "save", "session", "impl", "sessionimpl", "java:416", "session", "impl", "at", "org", "apach", "sling", "jcr", "resourc", "intern", "helper", "jcr", "jcrresourceprovid", "commit", "jcr", "resourc", "provid", "jcrresourceprovid", "java:634", "jcr", "resourc", "provid", "16", "common", "frame", "omit", "caus", "by", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "commit", "fail", "except", "oakmerge0004", "oak", "merge0004", "oakmerge0004", "oak", "merge0004", "node", "oak", "job", "index", "event", "topic", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "2fmodel", "var", "event", "job", "assign", "wa", "alreadi", "ad", "revis", "r151233e54e1", "befor", "r15166378b6a", "retri", "6830", "ms", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "merge0", "document", "node", "store", "branch", "documentnodestorebranch", "java:200", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "merg", "document", "node", "store", "branch", "documentnodestorebranch", "java:123", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentrootbuild", "merg", "document", "root", "builder", "documentrootbuild", "java:158", "document", "root", "builder", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "merg", "document", "node", "store", "documentnodestor", "java:1497", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "core", "mutableroot", "commit", "mutabl", "root", "mutableroot", "java:247", "mutabl", "root", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "commit", "session", "deleg", "sessiondeleg", "java:346", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:493", "session", "deleg", "20", "common", "frame", "omit", "caus", "by", "org", "apach", "jackrabbit", "oak", "plugin", "document", "conflictexcept", "conflict", "except", "node", "oak", "job", "index", "event", "topic", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "2fmodel", "var", "event", "job", "assign", "wa", "alreadi", "ad", "revis", "r151233e54e1", "befor", "r15166378b6a", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "checkconflict", "check", "conflict", "commit", "java:582", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "createorupdatenod", "creat", "or", "updat", "node", "commit", "java:487", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "applytodocumentstor", "appli", "document", "store", "commit", "java:371", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "applytodocumentstor", "appli", "document", "store", "commit", "java:265", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "applyintern", "appli", "intern", "commit", "java:234", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "appli", "commit", "java:219", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "persist", "document", "node", "store", "branch", "documentnodestorebranch", "java:290", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "persist", "document", "node", "store", "branch", "documentnodestorebranch", "java:260", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "access", "document", "node", "store", "branch", "300", "documentnodestorebranch", "java:54", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "document", "node", "store", "branch", "inmemori", "merg", "memori", "documentnodestorebranch", "java:498", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "merge0", "document", "node", "store", "branch", "documentnodestorebranch", "java:180", "document", "node", "store", "branch", "26", "common", "frame", "omit", "noformat", "do", "follow", "remov", "repo", "corrupt", "restor", "process", "noformat", "oak", "removedescendantsandself", "remov", "descend", "self", "oak", "job", "index", "event", "topic", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "2fmodel", "var", "event", "job", "assign", "noformat", "attach", "mongoexport", "output|^mongoexport", "zip", "oak", "job", "index", "event", "topic", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "a8bf", "4038", "b57b", "xmp", "a8bf", "4038", "b57b", "2fmodel", "var", "event", "job", "assign", "6a389a6a", "adob", "granit", "workflow", "transient", "job", "etc", "workflow", "model", "dam", "writeback", "cb441c6ac557", "10", "cb441c6ac557", "com", "jcr", "content", "model", "2015", "11", "19", "23", "54", "6a389a6a", "hierarchi", "creat", "at", "r151233e54e1", "ive", "renam", "few", "path", "element", "make", "it", "more", "reabl", "though", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "2fmodel", "enc", "valu", "~mreutegg", "im", "assign", "it", "myself", "now", "but", "think", "thi", "would", "requir", "your", "expertis", "all", "way"], "B_title": "Sometimes hierarchy conflict between concurrent add/delete isnt detected", "B_clean_title": ["sometim", "hierarchi", "conflict", "between", "concurr", "add", "delet", "isnt", "detect"]},
{"A_title": "Shells setiter is not informative when using a bad class nameIn the shell I did setiter using a class that wasnt found. Rather then a message about it not being found I just get told that I have an invalid argument. Even turning on debug I had to use the stack trace to figure out why it was erroring.", "A_clean_title": ["shell", "setit", "not", "inform", "when", "bad", "class", "namein", "name", "shell", "did", "setit", "class", "that", "wasnt", "found", "rather", "then", "messag", "about", "it", "not", "be", "found", "just", "get", "told", "that", "have", "invalid", "argument", "even", "turn", "debug", "had", "use", "stack", "trace", "figur", "out", "whi", "it", "wa", "error"], "B_title": "Appled patch from Mike Drob with modification to delete table in unit test.", "B_clean_title": ["appl", "patch", "mike", "drob", "modif", "delet", "tabl", "unit", "test"]},
{"A_title": "Wicket example forminput is broken due to bad url for IOnChangeListenerhttp://localhost:8080/forminput (wicket-examples) doesnt change the locale of the labels when the locale select is changed. The reason seems to be the produced url: ./.?5-1.IOnChangeListener-inputForm-localeSelect  This is parsed to a Url with one empty segment and thus HomePageMapper doesnt match it and doesnt handle it.", "A_clean_title": ["wicket", "exampl", "forminput", "broken", "due", "bad", "url", "ionchangelistenerhttp", "chang", "listenerhttp", "localhost:8080", "forminput", "wicket", "exampl", "doesnt", "chang", "local", "label", "when", "local", "select", "chang", "reason", "seem", "produc", "url", "inputform", "localeselect", "ionchangelisten", "input", "form", "local", "select", "chang", "listen", "thi", "pars", "url", "one", "empti", "segment", "thu", "homepagemapp", "home", "page", "mapper", "doesnt", "match", "it", "doesnt", "handl", "it"], "B_title": "remove empty segments when resolving relative url", "B_clean_title": ["remov", "empti", "segment", "when", "resolv", "rel", "url"]},
{"A_title": "CtFieldReference.getDefaultExpression() returns initializer from a field of another classHi Im trying to collect and evaluate certain strings in the source repository.  I tried VisitorPartialEvaluator but it runs into an infinite loop. The reason of this is that fields get mixed up. The code setup is like this:   Now if you try to read the return value of the  getKey() method the CtFieldReference object will return the default value of ClassB.PREFIX  not BaseClass.PREFIX .", "A_clean_title": ["ctfieldrefer", "getdefaultexpress", "ct", "field", "refer", "get", "default", "express", "return", "initi", "field", "anoth", "classhi", "class", "hi", "im", "tri", "collect", "evalu", "certain", "string", "sourc", "repositori", "tri", "visitorpartialevalu", "visitor", "partial", "evalu", "but", "it", "run", "into", "infinit", "loop", "reason", "thi", "that", "field", "get", "mix", "up", "code", "setup", "like", "thi", "now", "you", "tri", "read", "return", "valu", "getkey", "get", "key", "method", "ctfieldrefer", "ct", "field", "refer", "object", "will", "return", "default", "valu", "classb", "prefix", "class", "not", "baseclass", "prefix", "base", "class"], "B_title": "fix: fix bug in getDeclaration(). Closes #1213. (PR #1215)  This change impacts declaration lookup of field references after clone.", "B_clean_title": ["fix", "fix", "bug", "getdeclar", "get", "declar", "close", "1213", "pr", "1215", "thi", "chang", "impact", "declar", "lookup", "field", "refer", "after", "clone"]},
{"A_title": "Slow event listeners do not scale as expectedorg.apache.jackrabbit.oak.jcr.LargeOperationIT#slowListener does not scale to O n log n on the document node store.", "A_clean_title": ["slow", "event", "listen", "not", "scale", "as", "expectedorg", "apach", "jackrabbit", "oak", "jcr", "largeoperationit", "larg", "oper", "it", "slowlisten", "slow", "listen", "not", "scale", "log", "document", "node", "store"], "B_title": "Slow event listeners do not scale as expected", "B_clean_title": ["slow", "event", "listen", "not", "scale", "as", "expect"]},
{"A_title": "Internal Compiler Error on BulletNone", "A_clean_title": ["intern", "compil", "error", "bulletnon", "bullet", "none"], "B_title": "Label names must be made unique when inlining a function. Fixes issue 435", "B_clean_title": ["label", "name", "must", "made", "uniqu", "when", "inlin", "function", "fix", "issu", "435"]},
{"A_title": "RandomDataImpl.nextPoisson fails for means in range 6.0 - 19.99math.random.RandomDataImpl.nextPoisson(double mean) fails frequently (but not always) for values of mean between 6.0 and 19.99 inclusive. For values below 6.0 (where I see there is a branch in the logic) and above 20.0 it seems to be okay (though Ive only randomly sampled the space and run a million trials for the values Ive tried)  When it fails the exception is as follows (this for a mean of 6.0)  org.apache.commons.math.MathRuntimeException 4: must have n >= 0 for n! got n = -2 at org.apache.commons.math.MathRuntimeException.createIllegalArgumentException(MathRuntimeException.java:282) at org.apache.commons.math.util.MathUtils.factorialLog(MathUtils.java:561) at org.apache.commons.math.random.RandomDataImpl.nextPoisson(RandomDataImpl.java:434)   ie MathUtils.factorialLog is being called with a negative input  To reproduce:      JDKRandomGenerator random = new JDKRandomGenerator();     random.setSeed(123456);     RandomData randomData = new RandomDataImpl(random);      for (int i=0; i< 1000000; i++)         randomData.nextPoisson(6.0);", "A_clean_title": ["randomdataimpl", "nextpoisson", "random", "data", "impl", "next", "poisson", "fail", "mean", "rang", "19", "99math", "random", "randomdataimpl", "nextpoisson", "random", "data", "impl", "next", "poisson", "doubl", "mean", "fail", "frequent", "but", "not", "alway", "valu", "mean", "between", "19", "99", "inclus", "valu", "below", "where", "see", "there", "branch", "logic", "abov", "20", "it", "seem", "okay", "though", "ive", "onli", "randomli", "sampl", "space", "run", "million", "trial", "valu", "ive", "tri", "when", "it", "fail", "except", "as", "follow", "thi", "mean", "org", "apach", "common", "math", "mathruntimeexcept", "math", "runtim", "except", "must", "have", "got", "at", "org", "apach", "common", "math", "mathruntimeexcept", "createillegalargumentexcept", "math", "runtim", "except", "creat", "illeg", "argument", "except", "mathruntimeexcept", "java:282", "math", "runtim", "except", "at", "org", "apach", "common", "math", "util", "mathutil", "factoriallog", "math", "util", "factori", "log", "mathutil", "java:561", "math", "util", "at", "org", "apach", "common", "math", "random", "randomdataimpl", "nextpoisson", "random", "data", "impl", "next", "poisson", "randomdataimpl", "java:434", "random", "data", "impl", "ie", "mathutil", "factoriallog", "math", "util", "factori", "log", "be", "call", "neg", "input", "reproduc", "jdkrandomgener", "jdk", "random", "gener", "random", "new", "jdkrandomgener", "jdk", "random", "gener", "random", "setse", "set", "seed", "123456", "randomdata", "random", "data", "randomdata", "random", "data", "new", "randomdataimpl", "random", "data", "impl", "random", "int", "i=0", "1000000", "i++", "randomdata", "nextpoisson", "random", "data", "next", "poisson"], "B_title": "Implemented alternative algorithm for generating poisson deviates when the mean is large. JIRA: MATH-294.", "B_clean_title": ["implement", "altern", "algorithm", "gener", "poisson", "deviat", "when", "mean", "larg", "jira", "math", "294"]},
{"A_title": "NPE in DocumentNodeStore#retrieve for non existing checkpointSaid method throws a NPE when passing it a valid revision identifier from a non existing checkpoint.", "A_clean_title": ["npe", "documentnodestor", "document", "node", "store", "retriev", "non", "exist", "checkpointsaid", "checkpoint", "said", "method", "throw", "npe", "when", "pass", "it", "valid", "revis", "identifi", "non", "exist", "checkpoint"], "B_title": "NPE in DocumentNodeStore#retrieve for non existing checkpoint Add null check and test case", "B_clean_title": ["npe", "documentnodestor", "document", "node", "store", "retriev", "non", "exist", "checkpoint", "add", "null", "check", "test", "case"]},
{"A_title": "MockBatchScanner inappropriately filters on rangesI believe I have a legitimate case where an iterator will return something outside of the seeked-to range.  This appears to work in a live system but fails to work in test cases using the MockBatchScanner.  I believe this is because the MockBatchScanner filters on the supplied ranges in addition to seeking the iterators to each range.  Either we need to remove this range filter or fix the real system to do the same thing.  I prefer the former of course.", "A_clean_title": ["mockbatchscann", "mock", "batch", "scanner", "inappropri", "filter", "rangesi", "rang", "believ", "have", "legitim", "case", "where", "iter", "will", "return", "someth", "outsid", "seek", "rang", "thi", "appear", "work", "live", "system", "but", "fail", "work", "test", "case", "mockbatchscann", "mock", "batch", "scanner", "believ", "thi", "becaus", "mockbatchscann", "mock", "batch", "scanner", "filter", "suppli", "rang", "addit", "seek", "iter", "each", "rang", "either", "we", "need", "remov", "thi", "rang", "filter", "or", "fix", "real", "system", "same", "thing", "prefer", "former", "cours"], "B_title": "unit test out-of-range keys returned from an iterator stack", "B_clean_title": ["unit", "test", "out", "rang", "key", "return", "iter", "stack"]},
{"A_title": "The DateTimeField.onBeforeRender() method does not format the fields correctly.The current implementation relies on the org.joda.time.MutableDateTime instance to format the date hours amOrPm and minutes fields. Unfortunately the MutableDateTime constructor is not provided with the clients TimeZone value (assuming it is set). As a result the joda library uses the JVMs default timezone. If the defaul timezone differs from the clients timezone the formatted fields may turn out to be incorrect.", "A_clean_title": ["datetimefield", "onbeforerend", "date", "time", "field", "befor", "render", "method", "not", "format", "field", "correctli", "current", "implement", "reli", "org", "joda", "time", "mutabledatetim", "mutabl", "date", "time", "instanc", "format", "date", "hour", "amorpm", "am", "or", "pm", "minut", "field", "unfortun", "mutabledatetim", "mutabl", "date", "time", "constructor", "not", "provid", "client", "timezon", "time", "zone", "valu", "assum", "it", "set", "as", "result", "joda", "librari", "use", "jvm", "jv", "ms", "default", "timezon", "defaul", "timezon", "differ", "client", "timezon", "format", "field", "may", "turn", "out", "incorrect"], "B_title": "The DateTimeField.onBeforeRender() method does not format the fields correctly.", "B_clean_title": ["datetimefield", "onbeforerend", "date", "time", "field", "befor", "render", "method", "not", "format", "field", "correctli"]},
{"A_title": "Item names with trailing spaces should not be allowedthe following should fail:  code         Node hello = session.getRootNode().addNode(hello);         session.save();          Node illegal = hello.addNode(test ); <-- here         session.save();          assertEquals(/hello/test  illegal.getPath()); <-- and here          Node other = session.getNode(/hello/test ); <-- and here         assertTrue(other.isSame(illegal));         assertTrue(session.nodeExists(/hello/test )); <-- and here code", "A_clean_title": ["item", "name", "trail", "space", "not", "allowedth", "follow", "fail", "code", "node", "hello", "session", "getrootnod", "get", "root", "node", "addnod", "add", "node", "hello", "session", "save", "node", "illeg", "hello", "addnod", "add", "node", "test", "here", "session", "save", "assertequ", "assert", "equal", "hello", "test", "illeg", "getpath", "get", "path", "here", "node", "other", "session", "getnod", "get", "node", "hello", "test", "here", "asserttru", "assert", "true", "other", "issam", "same", "illeg", "asserttru", "assert", "true", "session", "nodeexist", "node", "exist", "hello", "test", "here", "code"], "B_title": "Item names with trailing spaces should not be allowed", "B_clean_title": ["item", "name", "trail", "space", "not", "allow"]},
{"A_title": "IllegalStateException in MemoryNodeBuilderAuthorizablePropertyTest.testSetPropertyByRelPath() sometimes causes an IllegalStateException in MemoryNodeBuilder. This might be a problem with the latter uncovered by the recent switch to the p2 index mechanism (OAK-511).  code java.lang.IllegalStateException     at com.google.common.base.Preconditions.checkState(Preconditions.java:133)     at org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.read(MemoryNodeBuilder.java:205)     at org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.getChildNodeNames(MemoryNodeBuilder.java:379)     at org.apache.jackrabbit.oak.plugins.index.p2.strategy.ContentMirrorStoreStrategy.remove(ContentMirrorStoreStrategy.java:66)     at org.apache.jackrabbit.oak.plugins.index.p2.Property2IndexUpdate.apply(Property2IndexUpdate.java:143)     at org.apache.jackrabbit.oak.plugins.index.p2.Property2IndexDiff.apply(Property2IndexDiff.java:232)     at org.apache.jackrabbit.oak.plugins.index.IndexHookManager.apply(IndexHookManager.java:71)     at org.apache.jackrabbit.oak.plugins.index.IndexHookManager.processCommit(IndexHookManager.java:61)     at org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:59)     at org.apache.jackrabbit.oak.kernel.KernelNodeStoreBranch.merge(KernelNodeStoreBranch.java:127)     at org.apache.jackrabbit.oak.core.RootImpl 2.run(RootImpl.java:240)     at org.apache.jackrabbit.oak.core.RootImpl 2.run(RootImpl.java:236)     at java.security.AccessController.doPrivileged(Native Method)     at javax.security.auth.Subject.doAs(Subject.java:337)     at org.apache.jackrabbit.oak.core.RootImpl.commit(RootImpl.java:235)     at org.apache.jackrabbit.oak.jcr.SessionDelegate.save(SessionDelegate.java:255)     at org.apache.jackrabbit.oak.jcr.SessionImpl.save(SessionImpl.java:283)     at org.apache.jackrabbit.oak.jcr.security.user.AbstractUserTest.tearDown(AbstractUserTest.java:72)     at org.apache.jackrabbit.test.AbstractJCRTest.run(AbstractJCRTest.java:456)     at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)     at org.junit.runner.JUnitCore.run(JUnitCore.java:157)     at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:76)     at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:195)     at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:63)     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)     at com.intellij.rt.execution.application.AppMain.main(AppMain.java:120)  code", "A_clean_title": ["illegalstateexcept", "illeg", "state", "except", "memorynodebuilderauthorizablepropertytest", "testsetpropertybyrelpath", "memori", "node", "builder", "authoriz", "properti", "test", "test", "set", "properti", "by", "rel", "path", "sometim", "caus", "illegalstateexcept", "illeg", "state", "except", "memorynodebuild", "memori", "node", "builder", "thi", "might", "problem", "latter", "uncov", "by", "recent", "switch", "p2", "index", "mechan", "oak", "511", "code", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "at", "com", "googl", "common", "base", "precondit", "checkstat", "check", "state", "precondit", "java:133", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "memorynodebuild", "read", "memori", "node", "builder", "memorynodebuild", "java:205", "memori", "node", "builder", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "memorynodebuild", "getchildnodenam", "memori", "node", "builder", "get", "child", "node", "name", "memorynodebuild", "java:379", "memori", "node", "builder", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "p2", "strategi", "contentmirrorstorestrategi", "remov", "content", "mirror", "store", "strategi", "contentmirrorstorestrategi", "java:66", "content", "mirror", "store", "strategi", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "p2", "property2indexupd", "appli", "property2index", "updat", "property2indexupd", "java:143", "property2index", "updat", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "p2", "property2indexdiff", "appli", "property2index", "diff", "property2indexdiff", "java:232", "property2index", "diff", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "indexhookmanag", "appli", "index", "hook", "manag", "indexhookmanag", "java:71", "index", "hook", "manag", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "indexhookmanag", "processcommit", "index", "hook", "manag", "process", "commit", "indexhookmanag", "java:61", "index", "hook", "manag", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositehook", "processcommit", "composit", "hook", "process", "commit", "compositehook", "java:59", "composit", "hook", "at", "org", "apach", "jackrabbit", "oak", "kernel", "kernelnodestorebranch", "merg", "kernel", "node", "store", "branch", "kernelnodestorebranch", "java:127", "kernel", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "root", "impl", "run", "rootimpl", "java:240", "root", "impl", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "root", "impl", "run", "rootimpl", "java:236", "root", "impl", "at", "java", "secur", "accesscontrol", "doprivileg", "access", "control", "privileg", "nativ", "method", "at", "javax", "secur", "auth", "subject", "doa", "as", "subject", "java:337", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "commit", "root", "impl", "rootimpl", "java:235", "root", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:255", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "sessionimpl", "save", "session", "impl", "sessionimpl", "java:283", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "secur", "user", "abstractusertest", "teardown", "abstract", "user", "test", "tear", "down", "abstractusertest", "java:72", "abstract", "user", "test", "at", "org", "apach", "jackrabbit", "test", "abstractjcrtest", "run", "abstract", "jcr", "test", "abstractjcrtest", "java:456", "abstract", "jcr", "test", "at", "org", "junit", "intern", "runner", "junit38classrunn", "run", "unit38class", "runner", "junit38classrunn", "java:83", "unit38class", "runner", "at", "org", "junit", "runner", "junitcor", "run", "unit", "core", "junitcor", "java:157", "unit", "core", "at", "com", "intellij", "junit4", "junit4ideatestrunn", "startrunnerwitharg", "unit4idea", "test", "runner", "start", "runner", "arg", "junit4ideatestrunn", "java:76", "unit4idea", "test", "runner", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "preparestreamsandstart", "unit", "starter", "prepar", "stream", "start", "junitstart", "java:195", "unit", "starter", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "main", "unit", "starter", "junitstart", "java:63", "unit", "starter", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "com", "intellij", "rt", "execut", "applic", "appmain", "main", "app", "main", "appmain", "java:120", "app", "main", "code"], "B_title": "IllegalStateException in MemoryNodeBuilder", "B_clean_title": ["illegalstateexcept", "illeg", "state", "except", "memorynodebuild", "memori", "node", "builder"]},
{"A_title": "Incorrect handling of multivalued comparisons in queriesSection 6.7.14|http://www.day.com/specs/jcr/2.0/6_Query.html#6.7.16 Comparison of the JCR 2.0 spec says:  bq. ... operand1 may evaluate to an array of values (for example the values of a multi-valued property) in which case the comparison is separately performed for each element of the array and the Comparison constraint is satisfied as a whole if the comparison against any element of the array is satisfied.  This is currently not the case in Oak. Instead only the first value of the array is used in the comparison.", "A_clean_title": ["incorrect", "handl", "multivalu", "comparison", "queriessect", "queri", "section", "14|http", "day", "html", "www", "com", "spec", "jcr", "queri", "16", "comparison", "jcr", "spec", "say", "bq", "operand1", "may", "evalu", "array", "valu", "exampl", "valu", "multi", "valu", "properti", "which", "case", "comparison", "separ", "perform", "each", "element", "array", "comparison", "constraint", "satisfi", "as", "whole", "comparison", "against", "ani", "element", "array", "satisfi", "thi", "current", "not", "case", "oak", "instead", "onli", "first", "valu", "array", "use", "comparison"], "B_title": "Incorrect handling of multivalued comparisons in queries", "B_clean_title": ["incorrect", "handl", "multivalu", "comparison", "queri"]},
{"A_title": "Mockito 1.10.x timeout verification needs JUnit classes (VerifyError NoClassDefFoundError)If JUnit is not on the classpath and mockito is version 1.10.x (as of now 1.10.1 up to 1.10.19) and the code is using the timeout verification which is not supposed to be related to JUnit then the JVM may fail with a VerifyError or a NoClassDefFoundError.", "A_clean_title": ["mockito", "10", "timeout", "verif", "need", "junit", "unit", "class", "verifyerror", "verifi", "error", "noclassdeffounderror", "no", "class", "def", "found", "error", "junit", "unit", "not", "classpath", "mockito", "version", "10", "as", "now", "10", "up", "10", "19", "code", "timeout", "verif", "which", "not", "suppos", "relat", "junit", "unit", "then", "jvm", "may", "fail", "verifyerror", "verifi", "error", "or", "noclassdeffounderror", "no", "class", "def", "found", "error"], "B_title": "Merge branch issue-152-incorrect-junit-dependencies", "B_clean_title": ["merg", "branch", "issu", "152", "incorrect", "junit", "depend"]},
{"A_title": "A 404 error occurs when using a CryptoMapperUnder certain prerequisites a 404 error occurs.  The prerequisites are: - A _CryptoMapper_ is used as _RequestMapper_ - _SecuritySettings.enforceMounts_ is set to true - Class _SomePage_ is *not* annotated with _@MountPath_  Reason: In _BookmarkableMapper.parseRequest_ (called indirectly by _CryptoMapper.mapRequest_) the method _matches_ returns _false_ as _reverseUrl_ is the *encrypted URL* (_rootRequestMapper_ is a _CryptoMapper_) but _BookmarkableMapper.matches_ expects a *decrypted URL*.  _BookmarkableMapper_ - lines 132 ff.: code Url reverseUrl = application.getRootRequestMapper().mapHandler( new RenderPageRequestHandler(new PageProvider(pageClass))); if (!matches(request.cloneWithUrl(reverseUrl)))  return null;  code  As a result _BookmarkableMapper.mapRequest_ and hence _CryptoMapper.mapRequest_ returns _null_ resulting in a 404 error.", "A_clean_title": ["404", "error", "occur", "when", "cryptomapperund", "crypto", "mapper", "under", "certain", "prerequisit", "404", "error", "occur", "prerequisit", "are", "cryptomapp", "crypto", "mapper", "use", "as", "requestmapp", "request", "mapper", "securityset", "enforcemount", "secur", "set", "enforc", "mount", "set", "true", "class", "somepag", "some", "page", "not", "annot", "mountpath", "mount", "path", "reason", "bookmarkablemapp", "parserequest", "bookmark", "mapper", "pars", "request", "call", "indirectli", "by", "cryptomapp", "maprequest", "crypto", "mapper", "map", "request", "method", "match", "return", "fals", "as", "reverseurl", "revers", "url", "encrypt", "url", "rootrequestmapp", "root", "request", "mapper", "cryptomapp", "crypto", "mapper", "but", "bookmarkablemapp", "match", "bookmark", "mapper", "expect", "decrypt", "url", "bookmarkablemapp", "bookmark", "mapper", "line", "132", "ff", "code", "url", "reverseurl", "revers", "url", "applic", "getrootrequestmapp", "get", "root", "request", "mapper", "maphandl", "map", "handler", "new", "renderpagerequesthandl", "render", "page", "request", "handler", "new", "pageprovid", "page", "provid", "pageclass", "page", "class", "match", "request", "clonewithurl", "clone", "url", "reverseurl", "revers", "url", "return", "null", "code", "as", "result", "bookmarkablemapp", "maprequest", "bookmark", "mapper", "map", "request", "henc", "cryptomapp", "maprequest", "crypto", "mapper", "map", "request", "return", "null", "result", "404", "error"], "B_title": "BookmarkableMapper now checks if a page is mounted to work properly if we use CryptoMapper and we are enforce page mounting", "B_clean_title": ["bookmarkablemapp", "bookmark", "mapper", "now", "check", "page", "mount", "work", "properli", "we", "use", "cryptomapp", "crypto", "mapper", "we", "are", "enforc", "page", "mount"]},
{"A_title": "NodeBuilder deleted child nodes can come backWhile working on OAK-520 Ive noticed a problem with the NodeBuilder: when we delete an entire hierarchy of nodes and then recreate a part of it some of the previously deleted nodes can come back.  This only happens when there are more than 3 levels of nodes.  So given a hierarchy of nodes: /x/y/z deleted x and simply use the NodeBuilder to traverse down on the same path: .child(x).child(y). At this point the z child reappears even though it was deleted before.   Ill attach a test case shortly.", "A_clean_title": ["nodebuild", "node", "builder", "delet", "child", "node", "come", "backwhil", "back", "while", "work", "oak", "520", "ive", "notic", "problem", "nodebuild", "node", "builder", "when", "we", "delet", "entir", "hierarchi", "node", "then", "recreat", "part", "it", "some", "previous", "delet", "node", "come", "back", "thi", "onli", "happen", "when", "there", "are", "more", "than", "level", "node", "so", "given", "hierarchi", "node", "delet", "simpli", "use", "nodebuild", "node", "builder", "travers", "down", "same", "path", "child", "child", "at", "thi", "point", "child", "reappear", "even", "though", "it", "wa", "delet", "befor", "ill", "attach", "test", "case", "shortli"], "B_title": "NodeBuilder deleted child nodes can come back", "B_clean_title": ["nodebuild", "node", "builder", "delet", "child", "node", "come", "back"]},
{"A_title": "Commit fails even though change made it to the DocumentStoreIn some rare cases it may happen that the DocumentNodeStore considers a commit as failed even though the changes were applied entirely to the DocumentStore. The issue happens when the update of the commit root is applied to the storage of a DocumentStore but then shortly after the communication between Oak the the storage system fails. On the Oak side the call will be considered as failed but the change was actually applied.  The issue can be reproduced with the test attached to OAK-1641 and a replica-set with 3 nodes. Killing the primary node and restarting it a after a while in a loop will eventually lead to a commit that conflicts itself.", "A_clean_title": ["commit", "fail", "even", "though", "chang", "made", "it", "documentstorein", "document", "store", "some", "rare", "case", "it", "may", "happen", "that", "documentnodestor", "document", "node", "store", "consid", "commit", "as", "fail", "even", "though", "chang", "were", "appli", "entir", "documentstor", "document", "store", "issu", "happen", "when", "updat", "commit", "root", "appli", "storag", "documentstor", "document", "store", "but", "then", "shortli", "after", "commun", "between", "oak", "storag", "system", "fail", "oak", "side", "call", "will", "consid", "as", "fail", "but", "chang", "wa", "actual", "appli", "issu", "reproduc", "test", "attach", "oak", "1641", "replica", "set", "node", "kill", "primari", "node", "restart", "it", "after", "while", "loop", "will", "eventu", "lead", "commit", "that", "conflict", "itself"], "B_title": "Commit fails even though change made it to the DocumentStore", "B_clean_title": ["commit", "fail", "even", "though", "chang", "made", "it", "documentstor", "document", "store"]},
{"A_title": "MultivariateNormalDistribution.density(double) returns wrong value when the dimension is oddTo reproduce:  Assert.assertEquals(0.398942280401433 new MultivariateNormalDistribution(new double0 new double1).density(new double0) 1e-15);", "A_clean_title": ["multivariatenormaldistribut", "densiti", "multivari", "normal", "distribut", "doubl", "return", "wrong", "valu", "when", "dimens", "oddto", "odd", "reproduc", "assert", "assertequ", "assert", "equal", "398942280401433", "new", "multivariatenormaldistribut", "multivari", "normal", "distribut", "new", "double0", "new", "double1", "densiti", "new", "double0", "1e", "15"], "B_title": "Fixed truncated value. Thanks to Piotr Wydrych. Added unit test: comparing density values with univariate normal distribution.", "B_clean_title": ["fix", "truncat", "valu", "thank", "piotr", "wydrych", "ad", "unit", "test", "compar", "densiti", "valu", "univari", "normal", "distribut"]},
{"A_title": "FastMath.pow(double long) enters an infinite loop with Long.MIN_VALUEFastMath.pow(double long) enters an infinite loop with Long.MIN_VALUE. It cannot be negated so unsigned shift (>>>) is required instead of a signed one (>>).", "A_clean_title": ["fastmath", "pow", "fast", "math", "doubl", "long", "enter", "infinit", "loop", "long", "pow", "min", "valuefastmath", "valu", "fast", "math", "doubl", "long", "enter", "infinit", "loop", "long", "min", "valu", "it", "not", "negat", "so", "unsign", "shift", "requir", "instead", "sign", "one"], "B_title": "Fixed infinite loop in FastMath.pow(double long) with Long.MIN_VALUE.", "B_clean_title": ["fix", "infinit", "loop", "fastmath", "pow", "fast", "math", "doubl", "long", "long", "min", "valu"]},
{"A_title": "Make sure iterators handle deletion entries properlyIn minor compaction scope and in non-full major compaction scopes the iterator may see deletion entries. These entries should be preserved by all iterators except ones that are strictly scan-time iterators that will never be configured for the minc or majc scopes. Deletion entries are only removed during full major compactions.", "A_clean_title": ["make", "sure", "iter", "handl", "delet", "entri", "properlyin", "properli", "minor", "compact", "scope", "non", "full", "major", "compact", "scope", "iter", "may", "see", "delet", "entri", "these", "entri", "preserv", "by", "all", "iter", "except", "one", "that", "are", "strictli", "scan", "time", "iter", "that", "will", "never", "configur", "minc", "or", "majc", "scope", "delet", "entri", "are", "onli", "remov", "dure", "full", "major", "compact"], "B_title": "made GrepIterator a Filter to handle deletions - trunk", "B_clean_title": ["made", "grepiter", "grep", "iter", "filter", "handl", "delet", "trunk"]},
{"A_title": "MapSerializer._orderEntries() throws NPE when operating on ConcurrentHashMapIt seems that the fix introduced for  #1411 in 2.8 can be problematic for ConcurrentSkipListMap (and possibly other map data structures).  doc for ConcurrentSkipListMap.doGet()", "A_clean_title": ["mapseri", "map", "serial", "orderentri", "order", "entri", "throw", "npe", "when", "oper", "concurrenthashmapit", "concurr", "hash", "map", "it", "seem", "that", "fix", "introduc", "1411", "problemat", "concurrentskiplistmap", "concurr", "skip", "list", "map", "possibl", "other", "map", "data", "structur", "doc", "concurrentskiplistmap", "doget", "concurr", "skip", "list", "map", "get"], "B_title": "Fixed #1513", "B_clean_title": ["fix", "1513"]},
{"A_title": "element.toString() crashes with a NP in DefaultJavaPrettyPrinter.visitCtTypeReference()When analyzing elasticsearch we get a NP when calling element.toString().  As this has something to do with type references I cant give you a concrete source file with this problem but rather a part of the project as tar archive. (  elasticsearch.tar.gz )", "A_clean_title": ["element", "tostr", "string", "crash", "np", "defaultjavaprettyprint", "visitcttyperefer", "default", "java", "pretti", "printer", "visit", "ct", "type", "refer", "when", "analyz", "elasticsearch", "we", "get", "np", "when", "call", "element", "tostr", "string", "as", "thi", "ha", "someth", "type", "refer", "cant", "give", "you", "concret", "sourc", "file", "thi", "problem", "but", "rather", "part", "project", "as", "tar", "archiv", "elasticsearch", "tar", "gz"], "B_title": "fix: visibility detection issue in CtElement #1099 (#1102)  * reproduce ElasticSearch access path problem #1099    * fix access path problem    * fix other tests    * Add one more assert on tests to check behaviour when overriding inner class. Replace some assertTrue by assertEquals to help debug test.", "B_clean_title": ["fix", "visibl", "detect", "issu", "ctelement", "ct", "element", "1099", "1102", "reproduc", "elasticsearch", "elast", "search", "access", "path", "problem", "1099", "fix", "access", "path", "problem", "fix", "other", "test", "add", "one", "more", "assert", "test", "check", "behaviour", "when", "overrid", "inner", "class", "replac", "some", "asserttru", "assert", "true", "by", "assertequ", "assert", "equal", "help", "debug", "test"]},
{"A_title": "RestartResponseAtInterceptPageException.InterceptData is never clearedRestartResponseAtInterceptPageException.InterceptData is supposed to be cleared after continueToOriginalDestination() is called. This is accomplished via RestartResponseAtInterceptPageException.MAPPER which is registered in the SystemMapper.  However there seems to be a serious bug here. The MAPPER always returns a compatibilityScore of 0 and thus is never actually invoked. The InterceptData is thus never cleared. Furthermore even if the MAPPER did return a Integer.MAX_VALUE score it would still not be invoked in many scenarios since other mappers in the SystemMapper are registered later and therefore have higher priority.  In practice this can lead to very odd login behavior in Wicket applications (which is where RestartResponseAtInterceptPageException is typically used). For example if the user clicks a login link they may end up on a totally unexpected page due to stale InterceptData that is hanging around in the session.  I am attaching a quick start that demonstrates the problem as well as a patch the fixes the compatibilityScore and moves the MAPPER to a higher priority in the SystemMapper.", "A_clean_title": ["restartresponseatinterceptpageexcept", "interceptdata", "restart", "respons", "at", "intercept", "page", "except", "intercept", "data", "never", "clearedrestartresponseatinterceptpageexcept", "interceptdata", "clear", "restart", "respons", "at", "intercept", "page", "except", "intercept", "data", "suppos", "clear", "after", "continuetooriginaldestin", "continu", "origin", "destin", "call", "thi", "accomplish", "via", "restartresponseatinterceptpageexcept", "mapper", "restart", "respons", "at", "intercept", "page", "except", "which", "regist", "systemmapp", "system", "mapper", "howev", "there", "seem", "seriou", "bug", "here", "mapper", "alway", "return", "compatibilityscor", "compat", "score", "thu", "never", "actual", "invok", "interceptdata", "intercept", "data", "thu", "never", "clear", "furthermor", "even", "mapper", "did", "return", "integ", "max", "valu", "score", "it", "would", "still", "not", "invok", "mani", "scenario", "sinc", "other", "mapper", "systemmapp", "system", "mapper", "are", "regist", "later", "therefor", "have", "higher", "prioriti", "practic", "thi", "lead", "veri", "odd", "login", "behavior", "wicket", "applic", "which", "where", "restartresponseatinterceptpageexcept", "restart", "respons", "at", "intercept", "page", "except", "typic", "use", "exampl", "user", "click", "login", "link", "they", "may", "end", "up", "total", "unexpect", "page", "due", "stale", "interceptdata", "intercept", "data", "that", "hang", "around", "session", "am", "attach", "quick", "start", "that", "demonstr", "problem", "as", "well", "as", "patch", "fix", "compatibilityscor", "compat", "score", "move", "mapper", "higher", "prioriti", "systemmapp", "system", "mapper"], "B_title": "RestartResponseAtInterceptPageException.InterceptData is never cleared", "B_clean_title": ["restartresponseatinterceptpageexcept", "interceptdata", "restart", "respons", "at", "intercept", "page", "except", "intercept", "data", "never", "clear"]},
{"A_title": "FileOutputFormat writes to wrong path if path ends with /The FileOutputFormat duplicates the last directory of a path if the path ends  with a slash /. For example if the output path is specified as /home/myuser/outputPath/ the output is written to /home/myuser/outputPath/outputPath/.  This bug was introduced by commit 8fc04e4da8a36866e10564205c3f900894f4f6e0", "A_clean_title": ["fileoutputformat", "file", "output", "format", "write", "wrong", "path", "path", "end", "fileoutputformat", "file", "output", "format", "duplic", "last", "directori", "path", "path", "end", "slash", "exampl", "output", "path", "specifi", "as", "home", "myuser", "outputpath", "output", "path", "output", "written", "home", "myuser", "outputpath", "outputpath", "output", "path", "output", "path", "thi", "bug", "wa", "introduc", "by", "commit", "8fc04e4da8a36866e10564205c3f900894f4f6e0"], "B_title": "Remove tailing slash from paths. Add tests for Path and FileOutputFormat.", "B_clean_title": ["remov", "tail", "slash", "path", "add", "test", "path", "fileoutputformat", "file", "output", "format"]},
{"A_title": "TreeTypeProvider returns wrong type for version related node type definitionsthe following paths with result in type VERSION instead of DEFAULT and might lead to unexpected results wrt read access:  - /jcr:system/jcr:nodeTypes/rep:system/rep:namedChildNodeDefinitions/jcr:versionStorage - /jcr:system/jcr:nodeTypes/rep:system/rep:namedChildNodeDefinitions/jcr:activities - /jcr:system/jcr:nodeTypes/rep:system/rep:namedChildNodeDefinitions/jcr:configurations", "A_clean_title": ["treetypeprovid", "tree", "type", "provid", "return", "wrong", "type", "version", "relat", "node", "type", "definitionsth", "follow", "path", "result", "type", "version", "instead", "default", "might", "lead", "unexpect", "result", "wrt", "read", "access", "jcr", "system", "jcr", "nodetyp", "rep", "node", "type", "system", "rep", "namedchildnodedefinit", "jcr", "name", "child", "node", "definit", "versionstorag", "version", "storag", "jcr", "system", "jcr", "nodetyp", "rep", "node", "type", "system", "rep", "namedchildnodedefinit", "jcr", "name", "child", "node", "definit", "activ", "jcr", "system", "jcr", "nodetyp", "rep", "node", "type", "system", "rep", "namedchildnodedefinit", "jcr", "name", "child", "node", "definit", "configur"], "B_title": ": TreeTypeProvider returns wrong type for version related node type definitions", "B_clean_title": ["treetypeprovid", "tree", "type", "provid", "return", "wrong", "type", "version", "relat", "node", "type", "definit"]},
{"A_title": "Multipart Form and AjaxSubmitLink will result in invalid redirect after user session expiresHi  I have hit an issue similar to this one:  https://issues.apache.org/jira/browse/WICKET-3141  I do not receive any errors from Wicket itself to help clarify so I will try to explain using an example.  The example below with which I could recreate the issue uses the default SignInPanel (in my LoginPage.clas) and AuthenticatedWebSession to authenticate the user and store the session:  protected Class<? extends WebPage> getSignInPageClass()  return LoginPage.class;   If the authentiation is succesfull then the user is redirect back to the test page:  protected void onSignInSucceeded()  setResponsePage(Test.class);   So far so good. However if I use a form with setMultiPart(true) in combination with an AjaxSubmitLink as shown in the following piece of code:  import org.apache.wicket.ajax.AjaxRequestTarget; import org.apache.wicket.ajax.markup.html.form.AjaxSubmitLink; import org.apache.wicket.authroles.authorization.strategies.role.annotations.AuthorizeInstantiation; import org.apache.wicket.markup.html.WebPage; import org.apache.wicket.markup.html.form.Form;  @AuthorizeInstantiation(USER) public class Test extends WebPage   public Test()  super();  final Form testForm =  new Form(testForm);  testForm.setMultiPart(true);  testForm.add(new AjaxSubmitLink(testButton testForm)   @Override protected void onSubmit(AjaxRequestTarget target Form form)  super.onSubmit(); ;  @Override protected void onError(AjaxRequestTarget target Form form)   ; );  add(testForm);    And have selected the option Remember credentials in the SignInPanel clicking on the testButton AFTER the session has expired will result in:  http://localhost:8080/PaladinWicket/?3-1.IBehaviorListener.0-testForm-testButton&wicket-ajax=true&wicket-ajax-baseurl=.  which displays this in the browser:  This XML file does not appear to have any style information associated with it. The document tree is shown below. <ajax-response> <redirect> <!CDATA .?1 > </redirect> </ajax-response>", "A_clean_title": ["multipart", "form", "ajaxsubmitlink", "ajax", "submit", "link", "will", "result", "invalid", "redirect", "after", "user", "session", "expireshi", "expir", "hi", "have", "hit", "issu", "similar", "thi", "one", "http", "3141", "apach", "issu", "org", "jira", "brows", "wicket", "not", "receiv", "ani", "error", "wicket", "itself", "help", "clarifi", "so", "will", "tri", "explain", "exampl", "exampl", "below", "which", "could", "recreat", "issu", "use", "default", "signinpanel", "sign", "panel", "my", "loginpag", "cla", "login", "page", "authenticatedwebsess", "authent", "web", "session", "authent", "user", "store", "session", "protect", "class", "extend", "webpag", "web", "page", "getsigninpageclass", "get", "sign", "page", "class", "return", "loginpag", "class", "login", "page", "authenti", "succesful", "then", "user", "redirect", "back", "test", "page", "protect", "void", "onsigninsucceed", "sign", "succeed", "setresponsepag", "set", "respons", "page", "test", "class", "so", "far", "so", "good", "howev", "use", "form", "setmultipart", "set", "multi", "part", "true", "combin", "ajaxsubmitlink", "ajax", "submit", "link", "as", "shown", "follow", "piec", "code", "import", "org", "apach", "wicket", "ajax", "ajaxrequesttarget", "ajax", "request", "target", "import", "org", "apach", "wicket", "ajax", "markup", "html", "form", "ajaxsubmitlink", "ajax", "submit", "link", "import", "org", "apach", "wicket", "authrol", "author", "strategi", "role", "annot", "authorizeinstanti", "author", "instanti", "import", "org", "apach", "wicket", "markup", "html", "webpag", "web", "page", "import", "org", "apach", "wicket", "markup", "html", "form", "form", "authorizeinstanti", "author", "instanti", "user", "public", "class", "test", "extend", "webpag", "web", "page", "public", "test", "super", "final", "form", "testform", "test", "form", "new", "form", "testform", "test", "form", "testform", "setmultipart", "test", "form", "set", "multi", "part", "true", "testform", "add", "test", "form", "new", "ajaxsubmitlink", "ajax", "submit", "link", "testbutton", "test", "button", "testform", "test", "form", "overrid", "protect", "void", "onsubmit", "submit", "ajaxrequesttarget", "ajax", "request", "target", "target", "form", "form", "super", "onsubmit", "submit", "overrid", "protect", "void", "onerror", "error", "ajaxrequesttarget", "ajax", "request", "target", "target", "form", "form", "add", "testform", "test", "form", "have", "select", "option", "rememb", "credenti", "signinpanel", "sign", "panel", "click", "testbutton", "test", "button", "after", "session", "ha", "expir", "will", "result", "http", "localhost:8080", "paladinwicket", "paladin", "wicket", "testform", "testbutton", "ibehaviorlisten", "test", "form", "test", "button", "behavior", "listen", "wicket", "ajax=tru", "wicket", "ajax", "baseurl=", "which", "display", "thi", "browser", "thi", "xml", "file", "not", "appear", "have", "ani", "style", "inform", "associ", "it", "document", "tree", "shown", "below", "ajax", "respons", "redirect", "cdata", "redirect", "respons", "ajax"], "B_title": "Multipart Form and AjaxSubmitLink will result in invalid redirect after user session expires", "B_clean_title": ["multipart", "form", "ajaxsubmitlink", "ajax", "submit", "link", "will", "result", "invalid", "redirect", "after", "user", "session", "expir"]},
{"A_title": "SimplexSolver not working as expected 2SimplexSolver didnt find the optimal solution.  Program for Lpsolve: ===================== /* Objective function */ max: 7 a 3 b;  /* Constraints */ R1: +3 a -5 c <= 0; R2: +2 a -5 d <= 0; R3: +2 b -5 c <= 0; R4: +3 b -5 d <= 0; R5: +3 a +2 b <= 5; R6: +2 a +3 b <= 5;  /* Variable bounds */ a <= 1; b <= 1; ===================== Results(correct): a = 1 b = 1 value = 10   Program for SimplexSolve: ===================== LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double7 3 0 0 0); Collection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>(); podmienky.add(new LinearConstraint(new double1 0 0 0 Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double0 1 0 0 Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double3 0 -5 0 Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double2 0 0 -5 Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double0 2 -5 0 Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double0 3 0 -5 Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double3 2 0 0 Relationship.LEQ 5)); podmienky.add(new LinearConstraint(new double2 3 0 0 Relationship.LEQ 5)); SimplexSolver solver = new SimplexSolver(); RealPointValuePair result = solver.optimize(kritFcia podmienky GoalType.MAXIMIZE true); ===================== Results(incorrect): a = 1 b = 0.5 value = 8.5  P.S. I used the latest software from the repository (including MATH-286 fix).", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "2simplexsolv", "2simplex", "solver", "didnt", "find", "optim", "solut", "program", "lpsolv", "object", "function", "max", "constraint", "r1", "+3", "r2", "+2", "r3", "+2", "r4", "+3", "r5", "+3", "+2", "r6", "+2", "+3", "variabl", "bound", "result", "correct", "valu", "10", "program", "simplexsolv", "simplex", "solv", "linearobjectivefunct", "linear", "object", "function", "kritfcia", "krit", "fcia", "new", "linearobjectivefunct", "linear", "object", "function", "new", "double7", "collect", "linearconstraint", "linear", "constraint", "podmienki", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double1", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double0", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double3", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double2", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double0", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double0", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double3", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double2", "relationship", "leq", "simplexsolv", "simplex", "solver", "solver", "new", "simplexsolv", "simplex", "solver", "realpointvaluepair", "real", "point", "valu", "pair", "result", "solver", "optim", "kritfcia", "krit", "fcia", "podmienki", "goaltyp", "maxim", "goal", "type", "true", "result", "incorrect", "valu", "use", "latest", "softwar", "repositori", "includ", "math", "286", "fix"], "B_title": "fixed an error induced by zero entries in simplex solver JIRA: MATH-288", "B_clean_title": ["fix", "error", "induc", "by", "zero", "entri", "simplex", "solver", "jira", "math", "288"]},
{"A_title": "Released checkpoint can still be retrievedThe following fails on the 2nd assertion on the MongoMK  code assertTrue(store.release(cp)); assertNull(store.retrieve(cp)); code  The JavaDoc on the release method is a bit vague but I assume it is safe to assume that when it returns true the checkpoint should be gone. If not we should update the JavaDoc.", "A_clean_title": ["releas", "checkpoint", "still", "retrievedth", "retriev", "follow", "fail", "2nd", "assert", "mongomk", "mongo", "mk", "code", "asserttru", "assert", "true", "store", "releas", "cp", "assertnul", "assert", "null", "store", "retriev", "cp", "code", "javadoc", "java", "doc", "releas", "method", "bit", "vagu", "but", "assum", "it", "safe", "assum", "that", "when", "it", "return", "true", "checkpoint", "gone", "not", "we", "updat", "javadoc", "java", "doc"], "B_title": "Released checkpoint can still be retrieved", "B_clean_title": ["releas", "checkpoint", "still", "retriev"]},
{"A_title": "Type extractor cannot determine type of functionThis function fails in the type extractor.  code public static final class DuplicateValue<T> implements MapFunction<Tuple1<T> Tuple2<T T>>   @Override public Tuple2<T T> map(Tuple1<T> vertex)  return new Tuple2<T T>(vertex.f0 vertex.f0);   code", "A_clean_title": ["type", "extractor", "not", "determin", "type", "functionthi", "function", "thi", "function", "fail", "type", "extractor", "code", "public", "static", "final", "class", "duplicatevalu", "duplic", "valu", "implement", "mapfunct", "map", "function", "tuple1", "tuple2", "overrid", "public", "tuple2", "map", "tuple1", "vertex", "return", "new", "tuple2", "vertex", "f0", "vertex", "f0", "code"], "B_title": "TypeExtractor resolves also variables inside Tuple-input", "B_clean_title": ["typeextractor", "type", "extractor", "resolv", "also", "variabl", "insid", "tupl", "input"]},
{"A_title": "A (stateless) page immediately disappears after the first renderUsing setResponsePage(new SomeStatelessNonBookmarkablePage(aParameter)) renders the page but trying to reload the page in the browser fails with PageExpiredException.  The reason is that the page is stateless and thus it is not saved in the page stores. Since it was scheduled for render with setResponsePage(Page) method its Url is created by PageInstanceMapper (i.e. something like: wicket/page?1). An attempt to refresh such page fails with Page with id 1 is not found => PageExpiredException.  Igor suggested to call page.setStatelessHint(false) for all pages passed to PageProvider(IRequestablePage) constructor i.e. such pages must be stored. This solved the problem but exposed few more problems: - MockPageManager (used in WicketTester) until now always touched/stored pages no matter their statelessness - org.apache.wicket.markup.html.internal.EnclosureTest.testRender10() was wrong for some unknown reason. All expectations against EnclosurePageExpectedResult_10-2.html should not have the enclosure rendered because input component is invisible", "A_clean_title": ["stateless", "page", "immedi", "disappear", "after", "first", "renderus", "render", "setresponsepag", "set", "respons", "page", "new", "somestatelessnonbookmarkablepag", "some", "stateless", "non", "bookmark", "page", "aparamet", "paramet", "render", "page", "but", "tri", "reload", "page", "browser", "fail", "pageexpiredexcept", "page", "expir", "except", "reason", "that", "page", "stateless", "thu", "it", "not", "save", "page", "store", "sinc", "it", "wa", "schedul", "render", "setresponsepag", "set", "respons", "page", "page", "method", "it", "url", "creat", "by", "pageinstancemapp", "page", "instanc", "mapper", "someth", "like", "wicket", "page", "attempt", "refresh", "such", "page", "fail", "page", "id", "not", "found", "pageexpiredexcept", "page", "expir", "except", "igor", "suggest", "call", "page", "setstatelesshint", "set", "stateless", "hint", "fals", "all", "page", "pass", "pageprovid", "page", "provid", "irequestablepag", "request", "page", "constructor", "such", "page", "must", "store", "thi", "solv", "problem", "but", "expos", "few", "more", "problem", "mockpagemanag", "mock", "page", "manag", "use", "wickettest", "wicket", "tester", "until", "now", "alway", "touch", "store", "page", "no", "matter", "their", "stateless", "org", "apach", "wicket", "markup", "html", "intern", "enclosuretest", "testrender10", "enclosur", "test", "test", "render10", "wa", "wrong", "some", "unknown", "reason", "all", "expect", "against", "enclosurepageexpectedresult", "10", "html", "enclosur", "page", "expect", "result", "not", "have", "enclosur", "render", "becaus", "input", "compon", "invis"], "B_title": "A (stateless) page immediately disappears after the first render", "B_clean_title": ["stateless", "page", "immedi", "disappear", "after", "first", "render"]},
{"A_title": "KeySelectorUtil.getSelectorForKeys and TypeExtractor.getKeySelectorTypes are incompatibleThe following code snippet fails because KeySelectorUtil.getSelectorForKeys returns the base Tuple type.  ```java TypeInformation<Tuple2<Integer Integer>> typeInfo = TypeExtractor .getForObject(Tuple2.of(0 0));  ExecutionConfig config = new ExecutionConfig();  KeySelector<Tuple2<Integer Integer> ?> keySelector = KeySelectorUtil.getSelectorForKeys( new Keys.ExpressionKeys<>(new int0 typeInfo) typeInfo config);  // fails with InvalidTypesException TypeExtractor.getKeySelectorTypes(keySelector typeInfo);  ```  However if I manually define the key selector as follows the snippet works fine due to the key type being an integer.  ```java KeySelector<Tuple2<Integer Integer> Integer> keySelector =  new KeySelector<Tuple2<Integer Integer> Integer>()  @Override public Integer getKey(Tuple2<Integer Integer> value) throws Exception  return value.f0;  ; ```  The error message looks like this: org.apache.flink.api.common.functions.InvalidTypesException: Usage of class Tuple as a type is not allowed. Use a concrete subclass (e.g. Tuple1 Tuple2 etc.) instead. at org.apache.flink.api.java.typeutils.TypeExtractor.createTypeInfoWithTypeHierarchy(TypeExtractor.java:401) at org.apache.flink.api.java.typeutils.TypeExtractor.privateCreateTypeInfo(TypeExtractor.java:379) at org.apache.flink.api.java.typeutils.TypeExtractor.getUnaryOperatorReturnType(TypeExtractor.java:279) at org.apache.flink.api.java.typeutils.TypeExtractor.getKeySelectorTypes(TypeExtractor.java:229) at org.apache.flink.api.java.typeutils.TypeExtractor.getKeySelectorTypes(TypeExtractor.java:223)", "A_clean_title": ["keyselectorutil", "getselectorforkey", "key", "selector", "util", "get", "selector", "key", "typeextractor", "getkeyselectortyp", "type", "extractor", "get", "key", "selector", "type", "are", "incompatibleth", "incompat", "follow", "code", "snippet", "fail", "becaus", "keyselectorutil", "getselectorforkey", "key", "selector", "util", "get", "selector", "key", "return", "base", "tupl", "type", "java", "typeinform", "type", "inform", "tuple2", "integ", "integ", "typeinfo", "type", "info", "typeextractor", "type", "extractor", "getforobject", "get", "object", "tuple2", "executionconfig", "execut", "config", "config", "new", "executionconfig", "execut", "config", "keyselector", "key", "selector", "tuple2", "integ", "integ", "keyselector", "key", "selector", "keyselectorutil", "getselectorforkey", "key", "selector", "util", "get", "selector", "key", "new", "key", "expressionkey", "express", "key", "new", "int0", "typeinfo", "type", "info", "typeinfo", "type", "info", "config", "fail", "invalidtypesexcept", "invalid", "type", "except", "typeextractor", "getkeyselectortyp", "type", "extractor", "get", "key", "selector", "type", "keyselector", "key", "selector", "typeinfo", "type", "info", "howev", "manual", "defin", "key", "selector", "as", "follow", "snippet", "work", "fine", "due", "key", "type", "be", "integ", "java", "keyselector", "key", "selector", "tuple2", "integ", "integ", "integ", "keyselector", "key", "selector", "new", "keyselector", "key", "selector", "tuple2", "integ", "integ", "integ", "overrid", "public", "integ", "getkey", "get", "key", "tuple2", "integ", "integ", "valu", "throw", "except", "return", "valu", "f0", "error", "messag", "look", "like", "thi", "org", "apach", "flink", "api", "common", "function", "invalidtypesexcept", "invalid", "type", "except", "usag", "class", "tupl", "as", "type", "not", "allow", "use", "concret", "subclass", "tuple1", "tuple2", "etc", "instead", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "createtypeinfowithtypehierarchi", "type", "extractor", "creat", "type", "info", "type", "hierarchi", "typeextractor", "java:401", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "privatecreatetypeinfo", "type", "extractor", "privat", "creat", "type", "info", "typeextractor", "java:379", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "getunaryoperatorreturntyp", "type", "extractor", "get", "unari", "oper", "return", "type", "typeextractor", "java:279", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "getkeyselectortyp", "type", "extractor", "get", "key", "selector", "type", "typeextractor", "java:229", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "getkeyselectortyp", "type", "extractor", "get", "key", "selector", "type", "typeextractor", "java:223", "type", "extractor"], "B_title": "streaming KeySelectorUtil interacts well with type extraction", "B_clean_title": ["stream", "keyselectorutil", "key", "selector", "util", "interact", "well", "type", "extract"]},
{"A_title": "Different output from RestAPI and command line jarNone", "A_clean_title": ["differ", "output", "restapi", "rest", "api", "command", "line", "jarnon", "jar", "none"], "B_title": "Fixes issue 1017 ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=47616701", "B_clean_title": ["fix", "issu", "1017", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=47616701"]},
{"A_title": "BackgroundLeaseUpdate not scheduled when asyncDelay=0The BackgroundLeaseUpdate extends from NodeStoreTask which returns from the run() method when asyncDelay is 0. This is fine for the background read and update tasks. However the lease update task must run even when asyncDelay is set to zero.", "A_clean_title": ["backgroundleaseupd", "background", "leas", "updat", "not", "schedul", "when", "asyncdelay=0th", "async", "delay=0th", "backgroundleaseupd", "background", "leas", "updat", "extend", "nodestoretask", "node", "store", "task", "which", "return", "run", "method", "when", "asyncdelay", "async", "delay", "thi", "fine", "background", "read", "updat", "task", "howev", "leas", "updat", "task", "must", "run", "even", "when", "asyncdelay", "async", "delay", "set", "zero"], "B_title": "BackgroundLeaseUpdate not scheduled when asyncDelay=0", "B_clean_title": ["backgroundleaseupd", "background", "leas", "updat", "not", "schedul", "when", "asyncdelay=0", "async", "delay=0"]},
{"A_title": "CacheLIRS concurrency issueSome of the methods of the cache can throw a NullPointerException when the cache is used concurrently. Example stack trace:  code java.lang.NullPointerException: null org.apache.jackrabbit.oak.cache.CacheLIRS.values(CacheLIRS.java:470)  org.apache.jackrabbit.oak.cache.CacheLIRS 1.values(CacheLIRS.java:1432) org.apache.jackrabbit.oak.plugins.segment.file.FileStore.flush(FileStore.java:205) code", "A_clean_title": ["cachelir", "cach", "lir", "concurr", "issuesom", "issu", "some", "method", "cach", "throw", "nullpointerexcept", "null", "pointer", "except", "when", "cach", "use", "concurr", "exampl", "stack", "trace", "code", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "null", "org", "apach", "jackrabbit", "oak", "cach", "cachelir", "valu", "cach", "lir", "cachelir", "java:470", "cach", "lir", "org", "apach", "jackrabbit", "oak", "cach", "cachelir", "cach", "lir", "valu", "cachelir", "java:1432", "cach", "lir", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "file", "filestor", "flush", "file", "store", "filestor", "java:205", "file", "store", "code"], "B_title": "CacheLIRS concurrency issue (allow concurrent clear and refresh without loader)", "B_clean_title": ["cachelir", "cach", "lir", "concurr", "issu", "allow", "concurr", "clear", "refresh", "without", "loader"]},
{"A_title": "weight versus sigma in AbstractLeastSquaresIn AbstractLeastSquares residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS() these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation it should multiply the square of the residual even in the computation of the chi2.   Once corrected getRMS() can even reduce   public double getRMS() return Math.sqrt(getChiSquare()/rows);", "A_clean_title": ["weight", "versu", "sigma", "abstractleastsquaresin", "abstract", "least", "squar", "abstractleastsquar", "abstract", "least", "squar", "residualsweight", "residu", "weight", "contain", "weight", "assign", "each", "observ", "method", "getrm", "get", "rm", "these", "weight", "are", "multipl", "as", "they", "unlik", "getchisquar", "get", "chi", "squar", "where", "it", "appear", "at", "denomin", "weight", "realli", "weight", "observ", "it", "multipli", "squar", "residu", "even", "comput", "chi2", "onc", "correct", "getrm", "get", "rm", "even", "reduc", "public", "doubl", "getrm", "get", "rm", "return", "math", "sqrt", "getchisquar", "get", "chi", "squar", "row"], "B_title": "fixed", "B_clean_title": ["fix"]},
{"A_title": "ClassGeneratingPropertyAccessorFactory.isTypeInjectable(…) fails with NPE for entities in default packages DATACMNS-1201opened and commented Introspecting ClassGeneratingPropertyAccessorFactory support for an entity fails with an NPE if the entity resides in the default package.     Affects: 1.13.8 (Ingalls SR8) 2.0 GA (Kay)  Referenced from: pull request #256  Backported to:  2.0.1 (Kay SR1)  1.13.9 (Ingalls SR9)", "A_clean_title": ["classgeneratingpropertyaccessorfactori", "istypeinject", "class", "gener", "properti", "accessor", "factori", "type", "inject", "fail", "npe", "entiti", "default", "packag", "datacmn", "1201open", "comment", "introspect", "classgeneratingpropertyaccessorfactori", "class", "gener", "properti", "accessor", "factori", "support", "entiti", "fail", "npe", "entiti", "resid", "default", "packag", "affect", "13", "ingal", "sr8", "ga", "kay", "referenc", "pull", "request", "256", "backport", "kay", "sr1", "13", "ingal", "sr9"], "B_title": "DATACMNS-1201 - Support generated property accessors for types in default packages.  We now support generated property accessors for types that reside in the default package.  Original pull request: #256.", "B_clean_title": ["datacmn", "1201", "support", "gener", "properti", "accessor", "type", "default", "packag", "we", "now", "support", "gener", "properti", "accessor", "type", "that", "resid", "default", "packag", "origin", "pull", "request", "256"]},
{"A_title": "RDB/MongoDocumentStore may return stale documentsIt appears that the implementations of the update method sometimes populate the memory cache with documents that do not reflect any current or previous state in the persistence (that is miss changes made by another node).  (will attach test)", "A_clean_title": ["rdb", "mongodocumentstor", "mongo", "document", "store", "may", "return", "stale", "documentsit", "document", "it", "appear", "that", "implement", "updat", "method", "sometim", "popul", "memori", "cach", "document", "that", "not", "reflect", "ani", "current", "or", "previou", "state", "persist", "that", "miss", "chang", "made", "by", "anoth", "node", "will", "attach", "test"], "B_title": "RDB/MongoDocumentStore may return stale documents", "B_clean_title": ["rdb", "mongodocumentstor", "mongo", "document", "store", "may", "return", "stale", "document"]},
{"A_title": "TabbedPanel CSS last is wrong if last step is not visibleTabbedPanel renders a last CSS class for the last tab this fails however if the last tab is not visible.", "A_clean_title": ["tabbedpanel", "tab", "panel", "css", "last", "wrong", "last", "step", "not", "visibletabbedpanel", "visibl", "tab", "panel", "render", "last", "css", "class", "last", "tab", "thi", "fail", "howev", "last", "tab", "not", "visibl"], "B_title": "last visible tabs css", "B_clean_title": ["last", "visibl", "tab", "css"]},
{"A_title": "Failing tests on Windows machineNone", "A_clean_title": ["fail", "test", "window", "machinenon", "machin", "none"], "B_title": "printing args on smart nulls NullPointerException message (Issue #225)", "B_clean_title": ["print", "arg", "smart", "null", "nullpointerexcept", "null", "pointer", "except", "messag", "issu", "225"]},
{"A_title": "NPE with nested property modelsAfter updated from 1.4.8 to 1.4.14 I got this bug.  The problem is with nested property models where the top model has a null model object that is bound to a TextField. You get a NPE when the page is rendered. There is a quick workaround by overriding getOjbectClass() on the property model.  I provide a running example of the problem.", "A_clean_title": ["npe", "nest", "properti", "modelsaft", "model", "after", "updat", "14", "got", "thi", "bug", "problem", "nest", "properti", "model", "where", "top", "model", "ha", "null", "model", "object", "that", "bound", "textfield", "text", "field", "you", "get", "npe", "when", "page", "render", "there", "quick", "workaround", "by", "overrid", "getojbectclass", "get", "ojbect", "class", "properti", "model", "provid", "run", "exampl", "problem"], "B_title": "- Preventing the attempt to resolve the property class for a null target at AbstractPropertyModel - Test asserting that there is no problem in working with an AbstractPropertyModel targeting an IObjectClassAwareModel not initialized with an known class. Issue: WICKET-3253", "B_clean_title": ["prevent", "attempt", "resolv", "properti", "class", "null", "target", "at", "abstractpropertymodel", "abstract", "properti", "model", "test", "assert", "that", "there", "no", "problem", "work", "abstractpropertymodel", "abstract", "properti", "model", "target", "iobjectclassawaremodel", "object", "class", "awar", "model", "not", "initi", "known", "class", "issu", "wicket", "3253"]},
{"A_title": "Ordered index fails with old index contentWith the latest changes the ordered index no longer works with old index data. When running the latest Oak 1.0.2 snapshot run against an Oak 1.0.0 repository with an existing ordered index the index fails with the exception below.  As a workaround the ordered index can be manually re-built. Either the index re-build needs to be automatic or the ordered index needs to work with the old index content.  noformat java.lang.IndexOutOfBoundsException: index (3) must be less than size (1)     at com.google.common.base.Preconditions.checkElementIndex(Preconditions.java:306)     at com.google.common.base.Preconditions.checkElementIndex(Preconditions.java:285)     at org.apache.jackrabbit.oak.plugins.segment.SegmentPropertyState.getValue(SegmentPropertyState.java:157)     at org.apache.jackrabbit.oak.plugins.index.property.strategy.OrderedContentMirrorStoreStrategy.getPropertyNext(OrderedContentMirrorStoreStrategy.java:1024) noformat", "A_clean_title": ["order", "index", "fail", "old", "index", "contentwith", "content", "latest", "chang", "order", "index", "no", "longer", "work", "old", "index", "data", "when", "run", "latest", "oak", "snapshot", "run", "against", "oak", "repositori", "exist", "order", "index", "index", "fail", "except", "below", "as", "workaround", "order", "index", "manual", "re", "built", "either", "index", "re", "build", "need", "automat", "or", "order", "index", "need", "work", "old", "index", "content", "noformat", "java", "lang", "indexoutofboundsexcept", "index", "out", "bound", "except", "index", "must", "less", "than", "size", "at", "com", "googl", "common", "base", "precondit", "checkelementindex", "check", "element", "index", "precondit", "java:306", "at", "com", "googl", "common", "base", "precondit", "checkelementindex", "check", "element", "index", "precondit", "java:285", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentpropertyst", "getvalu", "segment", "properti", "state", "get", "valu", "segmentpropertyst", "java:157", "segment", "properti", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "properti", "strategi", "orderedcontentmirrorstorestrategi", "getpropertynext", "order", "content", "mirror", "store", "strategi", "get", "properti", "next", "orderedcontentmirrorstorestrategi", "java:1024", "order", "content", "mirror", "store", "strategi", "noformat"], "B_title": "Ordered index fails with old index content", "B_clean_title": ["order", "index", "fail", "old", "index", "content"]},
{"A_title": "NullPointerException while translating union nodeThe NepheleJobGraphGenerator throws a NullPointerException when translating a binary union operator. The BinaryUnionPlanNode is not replaced by a NAryUnionPlanNode and thus is still treated as a DualInputVertex. Accessing the driver code of the BinaryUnionPlanNode causes then the NullPointerException.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "while", "translat", "union", "nodeth", "node", "nephelejobgraphgener", "nephel", "job", "graph", "gener", "throw", "nullpointerexcept", "null", "pointer", "except", "when", "translat", "binari", "union", "oper", "binaryunionplannod", "binari", "union", "plan", "node", "not", "replac", "by", "naryunionplannod", "ari", "union", "plan", "node", "thu", "still", "treat", "as", "dualinputvertex", "dual", "input", "vertex", "access", "driver", "code", "binaryunionplannod", "binari", "union", "plan", "node", "caus", "then", "nullpointerexcept", "null", "pointer", "except"], "B_title": "Fix for bug in union replacement", "B_clean_title": ["fix", "bug", "union", "replac"]},
{"A_title": "LocaleUtils.toLocale does not parse strings starting with an underscoreHi Javadocs of Locale.toString() states that If the language is missing the string will begin with an underbar.. This is not handled in the LocaleUtils.toLocale method if it is meant to be the inversion method of Locale.toString(). The fix for the ticket 328 does not handle well the case fr__P which I found out during fixing the first bug. I am attaching the patch for both problems.", "A_clean_title": ["localeutil", "tolocal", "local", "util", "local", "not", "pars", "string", "start", "underscorehi", "underscor", "hi", "javadoc", "local", "tostr", "string", "state", "that", "languag", "miss", "string", "will", "begin", "underbar", "thi", "not", "handl", "localeutil", "tolocal", "local", "util", "local", "method", "it", "meant", "invers", "method", "local", "tostr", "string", "fix", "ticket", "328", "not", "handl", "well", "case", "fr", "which", "found", "out", "dure", "fix", "first", "bug", "am", "attach", "patch", "both", "problem"], "B_title": "LocaleUtils.toLocale does not parse strings starting with an underscore.", "B_clean_title": ["localeutil", "tolocal", "local", "util", "local", "not", "pars", "string", "start", "underscor"]},
{"A_title": "AccumuloVFSClassloader creates conflicting local cache directory names when vfs.cache.dir property is set.When the vfs.cache.dir property is not set the AccumuloVFSClassloader will use java.io.tmpdir as a base directory for the local cache of jars and then generate a unique directory name using a combination of the processid hostname and userid executing the JVM.  When the vfs.cache.dir property is set that value is used as the base directory and  an attempt to generate a unique directory is made using an AtomicInteger. This isnt suitable because for non-long lived processes this will always be 1 - and theres a good chance that directory already exists and is owned by another user and not writable to by the user in question.   This leads to a failure of the invoked accumulo component to start.  Modify the behavior of the unique directory creation when vfs.cache.dir is set so that it employs the same mechanism for unique directory naming that is used when it is not set.", "A_clean_title": ["accumulovfsclassload", "accumulo", "vf", "classload", "creat", "conflict", "local", "cach", "directori", "name", "when", "vf", "cach", "dir", "properti", "set", "when", "vf", "cach", "dir", "properti", "not", "set", "accumulovfsclassload", "accumulo", "vf", "classload", "will", "use", "java", "io", "tmpdir", "as", "base", "directori", "local", "cach", "jar", "then", "gener", "uniqu", "directori", "name", "combin", "processid", "hostnam", "userid", "execut", "jvm", "when", "vf", "cach", "dir", "properti", "set", "that", "valu", "use", "as", "base", "directori", "attempt", "gener", "uniqu", "directori", "made", "atomicinteg", "atom", "integ", "thi", "isnt", "suitabl", "becaus", "non", "long", "live", "process", "thi", "will", "alway", "there", "good", "chanc", "that", "directori", "alreadi", "exist", "own", "by", "anoth", "user", "not", "writabl", "by", "user", "question", "thi", "lead", "failur", "invok", "accumulo", "compon", "start", "modifi", "behavior", "uniqu", "directori", "creation", "when", "vf", "cach", "dir", "set", "so", "that", "it", "employ", "same", "mechan", "uniqu", "directori", "name", "that", "use", "when", "it", "not", "set"], "B_title": "Fix for AccumuloVFSClassloader conflicting cache directories", "B_clean_title": ["fix", "accumulovfsclassload", "accumulo", "vf", "classload", "conflict", "cach", "directori"]},
{"A_title": "Bug in Hybrid Hash Join: Request to spill a partition with less than two buffers.The following exception is thrown when running the example triangle listing with an unmodified master build (4cadc3d6).  noformat ./bin/flink run ~/flink-examples/flink-java-examples/target/flink-java-examples-0.10-SNAPSHOT-EnumTrianglesOpt.jar ~/rmat/undirected/s19_e8.ssv output noformat  The only changes to flink-conf.yaml are taskmanager.numberOfTaskSlots: 8 and parallelism.default: 8.  I have confirmed with input files s19_e8.ssv|https://drive.google.com/file/d/0B6TrSsnHj2HxR2lnMHR4amdyTnM/view?usp=sharing (40 MB) and s20_e8.ssv|https://drive.google.com/file/d/0B6TrSsnHj2HxNi1HbmptU29MTm8/view?usp=sharing (83 MB). On a second machine only the larger file caused the exception.  noformat org.apache.flink.client.program.ProgramInvocationException: The program execution failed: Job execution failed. at org.apache.flink.client.program.Client.runBlocking(Client.java:407) at org.apache.flink.client.program.Client.runBlocking(Client.java:386) at org.apache.flink.client.program.Client.runBlocking(Client.java:353) at org.apache.flink.client.program.ContextEnvironment.execute(ContextEnvironment.java:64) at org.apache.flink.examples.java.graph.EnumTrianglesOpt.main(EnumTrianglesOpt.java:125) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:434) at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:350) at org.apache.flink.client.program.Client.runBlocking(Client.java:290) at org.apache.flink.client.CliFrontend.executeProgramBlocking(CliFrontend.java:675) at org.apache.flink.client.CliFrontend.run(CliFrontend.java:324) at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:977) at org.apache.flink.client.CliFrontend.main(CliFrontend.java:1027) Caused by: org.apache.flink.runtime.client.JobExecutionException: Job execution failed. at org.apache.flink.runtime.jobmanager.JobManager  anonfun handleMessage 1.applyOrElse(JobManager.scala:425) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LeaderSessionMessageFilter  anonfun receive 1.applyOrElse(LeaderSessionMessageFilter.scala:36) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:33) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:28) at scala.PartialFunction class.applyOrElse(PartialFunction.scala:118) at org.apache.flink.runtime.LogMessages  anon 1.applyOrElse(LogMessages.scala:28) at akka.actor.Actor class.aroundReceive(Actor.scala:465) at org.apache.flink.runtime.jobmanager.JobManager.aroundReceive(JobManager.scala:107) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) at akka.actor.ActorCell.invoke(ActorCell.scala:487) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:254) at akka.dispatch.Mailbox.run(Mailbox.scala:221) at akka.dispatch.Mailbox.exec(Mailbox.scala:231) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) Caused by: java.lang.RuntimeException: Bug in Hybrid Hash Join: Request to spill a partition with less than two buffers. at org.apache.flink.runtime.operators.hash.HashPartition.spillPartition(HashPartition.java:288) at org.apache.flink.runtime.operators.hash.MutableHashTable.spillPartition(MutableHashTable.java:1108) at org.apache.flink.runtime.operators.hash.MutableHashTable.insertBucketEntry(MutableHashTable.java:934) at org.apache.flink.runtime.operators.hash.MutableHashTable.insertIntoTable(MutableHashTable.java:859) at org.apache.flink.runtime.operators.hash.MutableHashTable.buildTableFromSpilledPartition(MutableHashTable.java:819) at org.apache.flink.runtime.operators.hash.MutableHashTable.prepareNextPartition(MutableHashTable.java:517) at org.apache.flink.runtime.operators.hash.MutableHashTable.nextRecord(MutableHashTable.java:556) at org.apache.flink.runtime.operators.hash.NonReusingBuildFirstHashMatchIterator.callWithNextKey(NonReusingBuildFirstHashMatchIterator.java:104) at org.apache.flink.runtime.operators.JoinDriver.run(JoinDriver.java:208) at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:489) at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:354) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:579) at java.lang.Thread.run(Thread.java:745) noformat", "A_clean_title": ["bug", "hybrid", "hash", "join", "request", "spill", "partit", "less", "than", "two", "buffer", "follow", "except", "thrown", "when", "run", "exampl", "triangl", "list", "unmodifi", "master", "build", "4cadc3d6", "noformat", "bin", "flink", "run", "java", "java", "exampl", "snapshot", "flink", "exampl", "flink", "exampl", "target", "flink", "10", "enumtrianglesopt", "jar", "enum", "triangl", "opt", "ssv", "e8", "rmat", "undirect", "s19", "output", "noformat", "onli", "chang", "flink", "conf", "yaml", "are", "taskmanag", "numberoftaskslot", "number", "task", "slot", "parallel", "default", "have", "confirm", "input", "file", "ssv|http", "s19", "e8", "googl", "drive", "com", "file", "0b6trssnhj2hxr2lnmhr4amdytnm", "view", "0b6tr", "ssn", "hj2hx", "r2ln", "mhr4amdi", "tn", "usp=shar", "40", "mb", "ssv|http", "s20", "e8", "googl", "drive", "com", "file", "0b6trssnhj2hxni1hbmptu29mtm8", "view", "0b6tr", "ssn", "hj2hx", "ni1hbmpt", "u29m", "tm8", "usp=shar", "83", "mb", "second", "machin", "onli", "larger", "file", "caus", "except", "noformat", "org", "apach", "flink", "client", "program", "programinvocationexcept", "program", "invoc", "except", "program", "execut", "fail", "job", "execut", "fail", "at", "org", "apach", "flink", "client", "program", "client", "runblock", "run", "block", "client", "java:407", "at", "org", "apach", "flink", "client", "program", "client", "runblock", "run", "block", "client", "java:386", "at", "org", "apach", "flink", "client", "program", "client", "runblock", "run", "block", "client", "java:353", "at", "org", "apach", "flink", "client", "program", "contextenviron", "execut", "context", "environ", "contextenviron", "java:64", "context", "environ", "at", "org", "apach", "flink", "exampl", "java", "graph", "enumtrianglesopt", "main", "enum", "triangl", "opt", "enumtrianglesopt", "java:125", "enum", "triangl", "opt", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:62", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:43", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:497", "at", "org", "apach", "flink", "client", "program", "packagedprogram", "callmainmethod", "packag", "program", "call", "main", "method", "packagedprogram", "java:434", "packag", "program", "at", "org", "apach", "flink", "client", "program", "packagedprogram", "invokeinteractivemodeforexecut", "packag", "program", "invok", "interact", "mode", "execut", "packagedprogram", "java:350", "packag", "program", "at", "org", "apach", "flink", "client", "program", "client", "runblock", "run", "block", "client", "java:290", "at", "org", "apach", "flink", "client", "clifrontend", "executeprogramblock", "cli", "frontend", "execut", "program", "block", "clifrontend", "java:675", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "run", "cli", "frontend", "clifrontend", "java:324", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "parseparamet", "cli", "frontend", "pars", "paramet", "clifrontend", "java:977", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "main", "cli", "frontend", "clifrontend", "java:1027", "cli", "frontend", "caus", "by", "org", "apach", "flink", "runtim", "client", "jobexecutionexcept", "job", "execut", "except", "job", "execut", "fail", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "anonfun", "handlemessag", "handl", "messag", "applyorels", "appli", "or", "jobmanag", "scala:425", "job", "manag", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "leadersessionmessagefilt", "leader", "session", "messag", "filter", "anonfun", "receiv", "applyorels", "appli", "or", "leadersessionmessagefilt", "scala:36", "leader", "session", "messag", "filter", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:33", "log", "messag", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:28", "log", "messag", "at", "scala", "partialfunct", "partial", "function", "class", "applyorels", "appli", "or", "partialfunct", "scala:118", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "applyorels", "appli", "or", "logmessag", "scala:28", "log", "messag", "at", "akka", "actor", "actor", "class", "aroundrec", "around", "receiv", "actor", "scala:465", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "aroundrec", "job", "manag", "around", "receiv", "jobmanag", "scala:107", "job", "manag", "at", "akka", "actor", "actorcel", "receivemessag", "actor", "cell", "receiv", "messag", "actorcel", "scala:516", "actor", "cell", "at", "akka", "actor", "actorcel", "invok", "actor", "cell", "actorcel", "scala:487", "actor", "cell", "at", "akka", "dispatch", "mailbox", "processmailbox", "process", "mailbox", "mailbox", "scala:254", "at", "akka", "dispatch", "mailbox", "run", "mailbox", "scala:221", "at", "akka", "dispatch", "mailbox", "exec", "mailbox", "scala:231", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "caus", "by", "java", "lang", "runtimeexcept", "runtim", "except", "bug", "hybrid", "hash", "join", "request", "spill", "partit", "less", "than", "two", "buffer", "at", "org", "apach", "flink", "runtim", "oper", "hash", "hashpartit", "spillpartit", "hash", "partit", "spill", "partit", "hashpartit", "java:288", "hash", "partit", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "spillpartit", "mutabl", "hash", "tabl", "spill", "partit", "mutablehasht", "java:1108", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "insertbucketentri", "mutabl", "hash", "tabl", "insert", "bucket", "entri", "mutablehasht", "java:934", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "insertintot", "mutabl", "hash", "tabl", "insert", "into", "tabl", "mutablehasht", "java:859", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "buildtablefromspilledpartit", "mutabl", "hash", "tabl", "build", "tabl", "spill", "partit", "mutablehasht", "java:819", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "preparenextpartit", "mutabl", "hash", "tabl", "prepar", "next", "partit", "mutablehasht", "java:517", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "nextrecord", "mutabl", "hash", "tabl", "next", "record", "mutablehasht", "java:556", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "nonreusingbuildfirsthashmatchiter", "callwithnextkey", "non", "reus", "build", "first", "hash", "match", "iter", "call", "next", "key", "nonreusingbuildfirsthashmatchiter", "java:104", "non", "reus", "build", "first", "hash", "match", "iter", "at", "org", "apach", "flink", "runtim", "oper", "joindriv", "run", "join", "driver", "joindriv", "java:208", "join", "driver", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "run", "regular", "pact", "task", "regularpacttask", "java:489", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "invok", "regular", "pact", "task", "regularpacttask", "java:354", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "taskmanag", "task", "run", "task", "java:579", "at", "java", "lang", "thread", "run", "thread", "java:745", "noformat"], "B_title": "runtime Fix hash table spilling partition selection.", "B_clean_title": ["runtim", "fix", "hash", "tabl", "spill", "partit", "select"]},
{"A_title": "Folder containing an admin user should not be removedThe action of removing a folder that contains the admin user should fail.  This is already the case if it is tried to remove the admin node .  Attaching unit test", "A_clean_title": ["folder", "contain", "admin", "user", "not", "removedth", "remov", "action", "remov", "folder", "that", "contain", "admin", "user", "fail", "thi", "alreadi", "case", "it", "tri", "remov", "admin", "node", "attach", "unit", "test"], "B_title": ": Folder containing an admin user should not be removed", "B_clean_title": ["folder", "contain", "admin", "user", "not", "remov"]},
{"A_title": "SegmentNodeStore rebase operation assumes wrong child node orderThis popped up during the async merge process. The merge first does a rebase which can fail making some index files look like they disappeared 0 wrapping the actual root cause.  The problem is that the rebase failed and removed the missing file. This can be seen by analyzing the :conflict marker info: bq. addExistingNode _b_Lucene41_0.doc _b.fdx _b.fdt _b_4.del  so it points to something trying to add some index related files twice almost like a concurrent commit exception.  Digging even deeper I found that the rebase operation during the state comparison phase assumes a certain order of child nodes 1 and based on that tries to read the mentioned nodes again thinking that they are new ones when if fact they are already present in the list 2. This causes a conflict which fails the entire async update process but also any lucene search as the index files are now gone and the index is in a corrupted state.   0  noformat *WARN* pool-5-thread-2 org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate Index update async failed org.apache.jackrabbit.oak.api.CommitFailedException: OakLucene0004: Failed to close the Lucene index at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.leave(LuceneIndexEditor.java:122) at org.apache.jackrabbit.oak.spi.commit.VisibleEditor.leave(VisibleEditor.java:64) at org.apache.jackrabbit.oak.spi.commit.VisibleEditor.leave(VisibleEditor.java:64) at org.apache.jackrabbit.oak.plugins.index.IndexUpdate.leave(IndexUpdate.java:129) at org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(EditorDiff.java:56) at org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:100) at org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:105) at org.quartz.core.JobRunShell.run(JobRunShell.java:207) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:724) Caused by: java.io.FileNotFoundException: _b_Lucene41_0.doc at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory.openInput(OakDirectory.java:145) noformat  1 http://svn.apache.org/viewvc/jackrabbit/oak/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/MapRecord.java?view=markup#l329  2 before child list noformat _b_Lucene41_0.doc _b.fdx _b.fdt segments_34 _b_4.del _b_Lucene41_0.pos _b.nvm _b.nvd _b.fnm _3n.si _b_Lucene41_0.tip _b_Lucene41_0.tim _3n.cfe segments.gen _3n.cfs _b.si noformat  after list noformat _b_Lucene41_0.pos _3k.cfs _3j_1.del _b.nvm _b.nvd _3d.cfe _3d.cfs _b.fnm _3j.si _3h.si _3i.cfe _3i.cfs _3e_2.del _3f.si _b_Lucene41_0.tip _b_Lucene41_0.tim segments.gen _3e.cfe _3e.cfs _b.si_3g.si _3l.si _3i_1.del _3d_3.del _3e.si _3d.si _b_Lucene41_0.doc _3h_2.del _3i.si _3k_1.del _3j.cfe _3j.cfs _b.fdx _b.fdt _3g_1.del _3k.si _3l.cfe _3l.cfs segments_33 _3f_1.del _3h.cfe _3h.cfs _b_4.del _3f.cfe _3f.cfs _3g.cfe _3g.cfs noformat", "A_clean_title": ["segmentnodestor", "segment", "node", "store", "rebas", "oper", "assum", "wrong", "child", "node", "orderthi", "order", "thi", "pop", "up", "dure", "async", "merg", "process", "merg", "first", "rebas", "which", "fail", "make", "some", "index", "file", "look", "like", "they", "disappear", "wrap", "actual", "root", "caus", "problem", "that", "rebas", "fail", "remov", "miss", "file", "thi", "seen", "by", "analyz", "conflict", "marker", "info", "bq", "addexistingnod", "add", "exist", "node", "doc", "lucene41", "fdx", "fdt", "del", "so", "it", "point", "someth", "tri", "add", "some", "index", "relat", "file", "twice", "almost", "like", "concurr", "commit", "except", "dig", "even", "deeper", "found", "that", "rebas", "oper", "dure", "state", "comparison", "phase", "assum", "certain", "order", "child", "node", "base", "that", "tri", "read", "mention", "node", "again", "think", "that", "they", "are", "new", "one", "when", "fact", "they", "are", "alreadi", "present", "list", "thi", "caus", "conflict", "which", "fail", "entir", "async", "updat", "process", "but", "also", "ani", "lucen", "search", "as", "index", "file", "are", "now", "gone", "index", "corrupt", "state", "noformat", "warn", "pool", "thread", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "async", "index", "updat", "index", "updat", "async", "fail", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "commit", "fail", "except", "oaklucene0004", "oak", "lucene0004", "fail", "close", "lucen", "index", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexeditor", "leav", "lucen", "index", "editor", "luceneindexeditor", "java:122", "lucen", "index", "editor", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "visibleeditor", "leav", "visibl", "editor", "visibleeditor", "java:64", "visibl", "editor", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "visibleeditor", "leav", "visibl", "editor", "visibleeditor", "java:64", "visibl", "editor", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "indexupd", "leav", "index", "updat", "indexupd", "java:129", "index", "updat", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "editordiff", "process", "editor", "diff", "editordiff", "java:56", "editor", "diff", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "run", "async", "index", "updat", "asyncindexupd", "java:100", "async", "index", "updat", "at", "org", "apach", "sling", "common", "schedul", "impl", "quartzjobexecutor", "execut", "quartz", "job", "executor", "quartzjobexecutor", "java:105", "quartz", "job", "executor", "at", "org", "quartz", "core", "jobrunshel", "run", "job", "run", "shell", "jobrunshel", "java:207", "job", "run", "shell", "at", "java", "util", "concurr", "threadpoolexecutor", "runwork", "thread", "pool", "executor", "run", "worker", "threadpoolexecutor", "java:1145", "thread", "pool", "executor", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:615", "thread", "pool", "executor", "at", "java", "lang", "thread", "run", "thread", "java:724", "caus", "by", "java", "io", "filenotfoundexcept", "file", "not", "found", "except", "doc", "lucene41", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "oakdirectori", "openinput", "oak", "directori", "open", "input", "oakdirectori", "java:145", "oak", "directori", "noformat", "http", "apach", "java", "svn", "org", "viewvc", "jackrabbit", "oak", "trunk", "oak", "core", "src", "main", "java", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "maprecord", "map", "record", "view=markup", "l329", "befor", "child", "list", "noformat", "doc", "lucene41", "fdx", "fdt", "segment", "34", "del", "po", "lucene41", "nvm", "nvd", "fnm", "si", "3n", "tip", "lucene41", "tim", "lucene41", "cfe", "3n", "segment", "gen", "cf", "3n", "si", "noformat", "after", "list", "noformat", "po", "lucene41", "cf", "3k", "del", "3j", "nvm", "nvd", "cfe", "3d", "cf", "3d", "fnm", "si", "3j", "si", "3h", "cfe", "3i", "cf", "3i", "del", "3e", "si", "3f", "tip", "lucene41", "tim", "lucene41", "segment", "gen", "cfe", "3e", "cf", "3e", "si", "si", "3g", "si", "3l", "del", "3i", "del", "3d", "si", "3e", "si", "3d", "doc", "lucene41", "del", "3h", "si", "3i", "del", "3k", "cfe", "3j", "cf", "3j", "fdx", "fdt", "del", "3g", "si", "3k", "cfe", "3l", "cf", "3l", "segment", "33", "del", "3f", "cfe", "3h", "cf", "3h", "del", "cfe", "3f", "cf", "3f", "cfe", "3g", "cf", "3g", "noformat"], "B_title": "SegmentNodeStore rebase operation assumes wrong child node order", "B_clean_title": ["segmentnodestor", "segment", "node", "store", "rebas", "oper", "assum", "wrong", "child", "node", "order"]},
{"A_title": "missing base64/ URL encodingyesterday i showed the concept of omponents to a friend and stumled into something i dont understand and think it might be a bug.    I have a small panelcompoment that holds a searchform (textfield + submit) nothing special here the code behind looks like:     @Override         public void onSubmit()                       String suchFeld = getSuchfeld();             if(suchFeld.length()>0)                              PageParameters params = new PageParameters();                 params.add(findesuchFeld);                 setResponsePage(Suche.classparams);                          else                              setResponsePage(getPage().getClass());                         the component is put into a BasePage:    public BasePage()          ....             add(bar);         add(new SuchPanel(SuchPanel));         .....    wich is then extended by the real page:   public class Foo extends BasePage          /** Creates a new instance of Zigarren */     public Foo()             wich works all fine however if the class name contains non ascii letters (e.g: ö ä ü etc.) it gives me a bug if nothing is entered into the search and the part   public class Zubehör extends BasePage          /** Creates a new instance of Zubehör */     public Zubehör()         setResponsePage(getPage().getClass()); comes to action the trouble is that the page might have the URL: ?wicket:bookmarkablePage=:de.pages.Zubeh%C3%B6r but the form tries to go to :  wicket:bookmarkablePage=:de.pages.Zubeh%F6r   wich results in a CODE 404 in the App Server", "A_clean_title": ["miss", "base64", "url", "encodingyesterday", "show", "concept", "ompon", "friend", "stuml", "into", "someth", "dont", "understand", "think", "it", "might", "bug", "have", "small", "panelcompo", "that", "hold", "searchform", "textfield", "submit", "noth", "special", "here", "code", "behind", "look", "like", "overrid", "public", "void", "onsubmit", "submit", "string", "suchfeld", "such", "feld", "getsuchfeld", "get", "suchfeld", "suchfeld", "length", "such", "feld", "pageparamet", "page", "paramet", "param", "new", "pageparamet", "page", "paramet", "param", "add", "findesuchfeld", "findesuch", "feld", "setresponsepag", "set", "respons", "page", "such", "classparam", "setresponsepag", "set", "respons", "page", "getpag", "get", "page", "getclass", "get", "class", "compon", "put", "into", "basepag", "base", "page", "public", "basepag", "base", "page", "add", "bar", "add", "new", "suchpanel", "such", "panel", "suchpanel", "such", "panel", "wich", "then", "extend", "by", "real", "page", "public", "class", "foo", "extend", "basepag", "base", "page", "creat", "new", "instanc", "zigarren", "public", "foo", "wich", "work", "all", "fine", "howev", "class", "name", "contain", "non", "ascii", "letter", "etc", "it", "give", "me", "bug", "noth", "enter", "into", "search", "part", "public", "class", "zubehör", "extend", "basepag", "base", "page", "creat", "new", "instanc", "zubehör", "public", "zubehör", "setresponsepag", "set", "respons", "page", "getpag", "get", "page", "getclass", "get", "class", "come", "action", "troubl", "that", "page", "might", "have", "url", "wicket", "bookmarkablepage=", "bookmark", "page=", "de", "page", "zubeh", "c3", "b6r", "but", "form", "tri", "go", "wicket", "bookmarkablepage=", "bookmark", "page=", "de", "page", "zubeh", "f6r", "wich", "result", "code", "404", "app", "server"], "B_title": "Make sure that bookmarkable urls for classes containing non-ascii characters is encoded properly.", "B_clean_title": ["make", "sure", "that", "bookmark", "url", "class", "contain", "non", "ascii", "charact", "encod", "properli"]},
{"A_title": "TokenLoginModule does not set userId on auth infothe token login module does not set the userid in the authinfo (because it does not know it). and the LoginModuleImpl does not overwrite the AuthInfo if it already exists.  the consequence: Session.getUserID() returns NULL for logins that create a token.  I think that the authinfos should be added even if they already exist. and all users of the public credentials need to be aware that authinfos can exist that are not complete.", "A_clean_title": ["tokenloginmodul", "token", "login", "modul", "not", "set", "userid", "user", "id", "auth", "infoth", "token", "login", "modul", "not", "set", "userid", "authinfo", "becaus", "it", "not", "know", "it", "loginmoduleimpl", "login", "modul", "impl", "not", "overwrit", "authinfo", "auth", "info", "it", "alreadi", "exist", "consequ", "session", "getuserid", "get", "user", "id", "return", "null", "login", "that", "creat", "token", "think", "that", "authinfo", "ad", "even", "they", "alreadi", "exist", "all", "user", "public", "credenti", "need", "awar", "that", "authinfo", "exist", "that", "are", "not", "complet"], "B_title": "    OAK-1363", "B_clean_title": ["oak", "1363"]},
{"A_title": "Lucene index rules should be case insensitiveFollowing the lucene index definitions update the ignored properties are upgraded as a lower case version but the rest of the lucene bits (indexing) still take the case into account resulting in the exclude rules being ignored and properties being indexed.", "A_clean_title": ["lucen", "index", "rule", "case", "insensitivefollow", "insensit", "follow", "lucen", "index", "definit", "updat", "ignor", "properti", "are", "upgrad", "as", "lower", "case", "version", "but", "rest", "lucen", "bit", "index", "still", "take", "case", "into", "account", "result", "exclud", "rule", "be", "ignor", "properti", "be", "index"], "B_title": "- Lucene index rules should be case insensitive", "B_clean_title": ["lucen", "index", "rule", "case", "insensit"]},
{"A_title": "@JsonEnumDefaultValue should take precedence over FAIL_ON_NUMBERS_FOR_ENUMSConsider the following  ObjectMapper definition:  With this  ObjectMapper  when one attempts to deserialize an enum value V for an enum with an @JsonEnumDefaultValue element the deserialization will:   Pass if  Pass if  Fail if  To me this seems highly unintuitive. I would have expected the  READ_UNKNOWN_ENUM_VALUES_USING_DEFAULT_VALUE feature to take precedence over the FAIL_ON_NUMBERS_FOR_ENUMS feature in those cases where it applies (i.e. when deserializing an enum with a default element). Ive put together a test class enumerating the relevant cases. See the inline comments towards the bottom. In four cases I feel that Jacksons current behavior is not as one might expect.   Would love to hear your thoughts on this. (If there is some other feature I should enable to get the behavior Im looking for let me know :).)", "A_clean_title": ["jsonenumdefaultvalu", "json", "enum", "default", "valu", "take", "preced", "over", "fail", "number", "enumsconsid", "enum", "consid", "follow", "objectmapp", "object", "mapper", "definit", "thi", "objectmapp", "object", "mapper", "when", "one", "attempt", "deseri", "enum", "valu", "enum", "jsonenumdefaultvalu", "json", "enum", "default", "valu", "element", "deseri", "will", "pass", "pass", "fail", "me", "thi", "seem", "highli", "unintuit", "would", "have", "expect", "read", "unknown", "enum", "valu", "default", "valu", "featur", "take", "preced", "over", "fail", "number", "enum", "featur", "those", "case", "where", "it", "appli", "when", "deseri", "enum", "default", "element", "ive", "put", "togeth", "test", "class", "enumer", "relev", "case", "see", "inlin", "comment", "toward", "bottom", "four", "case", "feel", "that", "jackson", "current", "behavior", "not", "as", "one", "might", "expect", "would", "love", "hear", "your", "thought", "thi", "there", "some", "other", "featur", "enabl", "get", "behavior", "im", "look", "let", "me", "know"], "B_title": "Fixed #1505", "B_clean_title": ["fix", "1505"]},
{"A_title": "Component reAttach and versioningIm reAttaching a component doing something like:   MyFooPanel p1 = new MyFooPanel(this panel;);  MyBarPanel p2 = new MyBarPanel(this panel);  p1.reAttach();   When I try to restore to the initial page version I found that the component with id panel is not a children component of the page.   I have investigated it and I think it is because when the component is reAttached the order in which the changes are added to the ChangesList is:  - Add p2.  - Remove p1.   When the initial version is restored the undo functionality is done in reverse mode like  - Add p1.  - Remove p2.   The problem is p1 and p2 have the same id so when p2 is removed what is removing is p1 that has just added.   Oscar.", "A_clean_title": ["compon", "reattach", "re", "attach", "versioningim", "version", "im", "reattach", "re", "attach", "compon", "do", "someth", "like", "myfoopanel", "my", "foo", "panel", "p1", "new", "myfoopanel", "my", "foo", "panel", "thi", "panel", "mybarpanel", "my", "bar", "panel", "p2", "new", "mybarpanel", "my", "bar", "panel", "thi", "panel", "p1", "reattach", "re", "attach", "when", "tri", "restor", "initi", "page", "version", "found", "that", "compon", "id", "panel", "not", "children", "compon", "page", "have", "investig", "it", "think", "it", "becaus", "when", "compon", "reattach", "re", "attach", "order", "which", "chang", "are", "ad", "changeslist", "chang", "list", "add", "p2", "remov", "p1", "when", "initi", "version", "restor", "undo", "function", "done", "revers", "mode", "like", "add", "p1", "remov", "p2", "problem", "p1", "p2", "have", "same", "id", "so", "when", "p2", "remov", "what", "remov", "p1", "that", "ha", "just", "ad", "oscar"], "B_title": "bug fix for http://issues.apache.org/jira/browse/WICKET-172 1> remove(child) would only look at the id not at the instance. 2> addedComponent was first called before removedComponent (switched) some code cleanup.", "B_clean_title": ["bug", "fix", "http", "172", "apach", "issu", "org", "jira", "brows", "wicket", "remov", "child", "would", "onli", "look", "at", "id", "not", "at", "instanc", "addedcompon", "ad", "compon", "wa", "first", "call", "befor", "removedcompon", "remov", "compon", "switch", "some", "code", "cleanup"]},
{"A_title": "anonymous object type inference behavior is different when calling constructorsNone", "A_clean_title": ["anonym", "object", "type", "infer", "behavior", "differ", "when", "call", "constructorsnon", "constructor", "none"], "B_title": "Fix some bugs in new inference: - traverse children before the parent - do backwards inference on params like we do for CALL Fixes issue 729", "B_clean_title": ["fix", "some", "bug", "new", "infer", "travers", "children", "befor", "parent", "backward", "infer", "param", "like", "we", "call", "fix", "issu", "729"]},
{"A_title": "ExtendedMessageFormat: OutOfMemory with custom format registry and a pattern containing single quotesWhen using ExtendedMessageFormat with a custom format registry and a pattern conatining single quotes an OutOfMemoryError will occur. Example that will cause error: ExtendedMessageFormatTest.java  private static Map<String Object> formatRegistry = new HashMap<String Object>();         static          formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT new DummyFormatFactory());               public static void main(String args)          ExtendedMessageFormat mf = new ExtendedMessageFormat(its a dummy test! formatRegistry);         String formattedPattern = mf.format(new String great);         System.out.println(formattedPattern);          The following change starting at line 421 on the 2.4 release seems to fix the problem: ExtendedMessageFormat.java CURRENT (Broken): if (escapingOn && cstart == QUOTE)          return appendTo == null ? null : appendTo.append(QUOTE);   WORKING: if (escapingOn && cstart == QUOTE)          next(pos);         return appendTo == null ? null : appendTo.append(QUOTE);", "A_clean_title": ["extendedmessageformat", "extend", "messag", "format", "outofmemori", "out", "memori", "custom", "format", "registri", "pattern", "contain", "singl", "quoteswhen", "quot", "when", "extendedmessageformat", "extend", "messag", "format", "custom", "format", "registri", "pattern", "conatin", "singl", "quot", "outofmemoryerror", "out", "memori", "error", "will", "occur", "exampl", "that", "will", "caus", "error", "extendedmessageformattest", "java", "extend", "messag", "format", "test", "privat", "static", "map", "string", "object", "formatregistri", "format", "registri", "new", "hashmap", "hash", "map", "string", "object", "static", "formatregistri", "put", "format", "registri", "dummyformatfactori", "dummi", "format", "factori", "dummi", "format", "new", "dummyformatfactori", "dummi", "format", "factori", "public", "static", "void", "main", "string", "arg", "extendedmessageformat", "extend", "messag", "format", "mf", "new", "extendedmessageformat", "extend", "messag", "format", "it", "dummi", "test", "formatregistri", "format", "registri", "string", "formattedpattern", "format", "pattern", "mf", "format", "new", "string", "great", "system", "out", "println", "formattedpattern", "format", "pattern", "follow", "chang", "start", "at", "line", "421", "releas", "seem", "fix", "problem", "extendedmessageformat", "java", "extend", "messag", "format", "current", "broken", "escapingon", "escap", "cstart", "quot", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot", "work", "escapingon", "escap", "cstart", "quot", "next", "po", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot"], "B_title": "Fix for LANG-477 OutOfMemory with custom format registry and a pattern containing single quotes - thanks to Duncan Eley", "B_clean_title": ["fix", "lang", "477", "outofmemori", "out", "memori", "custom", "format", "registri", "pattern", "contain", "singl", "quot", "thank", "duncan", "eley"]},
{"A_title": "SmartLinkLabel failing to process email with -In a similar vein to WICKET-3174 - using SmartLinkLabel with an email address that includes a - generates a link only on the right-most part of the address.   Example:  - my-test@example.com  Will generate a link like:  - my-<a href=mailto:test@example.com>test@example.com</a>   The addition of the - char is a valid email address format.", "A_clean_title": ["smartlinklabel", "smart", "link", "label", "fail", "process", "email", "similar", "vein", "wicket", "3174", "smartlinklabel", "smart", "link", "label", "email", "address", "that", "includ", "gener", "link", "onli", "right", "most", "part", "address", "exampl", "my", "test", "exampl", "com", "will", "gener", "link", "like", "my", "href=mailto", "test", "exampl", "com", "test", "exampl", "com", "addit", "char", "valid", "email", "address", "format"], "B_title": "SmartLinkLabel escape minus in pattern", "B_clean_title": ["smartlinklabel", "smart", "link", "label", "escap", "minu", "pattern"]},
{"A_title": "bug with implicit namespaces across modulesNone", "A_clean_title": ["bug", "implicit", "namespac", "across", "modulesnon", "modul", "none"], "B_title": "Fix bug with implicit namespaces across modules. Contributed by bolinfest Fixes issue 261", "B_clean_title": ["fix", "bug", "implicit", "namespac", "across", "modul", "contribut", "by", "bolinfest", "fix", "issu", "261"]},
{"A_title": "Access to disconnected MemoryNodeBuilder should throw IllegalStateExceptionNone", "A_clean_title": ["access", "disconnect", "memorynodebuild", "memori", "node", "builder", "throw", "illegalstateexceptionnon", "illeg", "state", "except", "none"], "B_title": "Access to disconnected MemoryNodeBuilder should throw IllegalStateException", "B_clean_title": ["access", "disconnect", "memorynodebuild", "memori", "node", "builder", "throw", "illegalstateexcept", "illeg", "state", "except"]},
{"A_title": "AccumuloInputFormat cannot fetch empty column familyThe following fails: code:java Job job = new Job(); HashSet<Pair<TextText>> cols = new HashSet<Pair<TextText>>(); cols.add(new Pair<TextText>(new Text() null)); AccumuloInputFormat.fetchColumns(job cols); Set<Pair<TextText>> setCols = AccumuloInputFormat.getFetchedColumns(job); assertEquals(cols.size() setCols.size()); code", "A_clean_title": ["accumuloinputformat", "accumulo", "input", "format", "not", "fetch", "empti", "column", "familyth", "famili", "follow", "fail", "code", "java", "job", "job", "new", "job", "hashset", "hash", "set", "pair", "texttext", "text", "text", "col", "new", "hashset", "hash", "set", "pair", "texttext", "text", "text", "col", "add", "new", "pair", "texttext", "text", "text", "new", "text", "null", "accumuloinputformat", "fetchcolumn", "accumulo", "input", "format", "fetch", "column", "job", "col", "set", "pair", "texttext", "text", "text", "setcol", "set", "col", "accumuloinputformat", "getfetchedcolumn", "accumulo", "input", "format", "get", "fetch", "column", "job", "assertequ", "assert", "equal", "col", "size", "setcol", "size", "set", "col", "code"], "B_title": "Handle empty column family correctly for AccumuloInputFormat", "B_clean_title": ["handl", "empti", "column", "famili", "correctli", "accumuloinputformat", "accumulo", "input", "format"]},
{"A_title": "Brent optimizer doesnt use the Base optimizer iteration counterBrentOptimizer uses iter defined in doOptimize  to count iterations. It should ideally use the iteration counter defined for the BaseOptimizer.", "A_clean_title": ["brent", "optim", "doesnt", "use", "base", "optim", "iter", "counterbrentoptim", "counter", "brent", "optim", "use", "iter", "defin", "dooptim", "optim", "count", "iter", "it", "ideal", "use", "iter", "counter", "defin", "baseoptim", "base", "optim"], "B_title": "Use base class iteration counter. Reported by Ajo Fod.", "B_clean_title": ["use", "base", "class", "iter", "counter", "report", "by", "ajo", "fod"]},
{"A_title": "Enum key for Map ignores SerializationFeature.WRITE_ENUMS_USING_INDEXVersion: latest 2.8  Failing unit tests added here:   https://github.com/SolaKun/jackson-databind/commit/6e095f75edd1de3eb33be5950c56d562bd6d584a Only java.util.Map test case provided but doesnt work with EnumMap as well..", "A_clean_title": ["enum", "key", "map", "ignor", "serializationfeatur", "serial", "featur", "write", "enum", "indexvers", "index", "version", "latest", "fail", "unit", "test", "ad", "here", "http", "databind", "commit", "6e095f75edd1de3eb33be5950c56d562bd6d584a", "github", "com", "solakun", "jackson", "sola", "kun", "onli", "java", "util", "map", "test", "case", "provid", "but", "doesnt", "work", "enummap", "enum", "map", "as", "well"], "B_title": "Fixed #1570", "B_clean_title": ["fix", "1570"]},
{"A_title": "NumberUtils does not handle upper-case hex: 0X and -0XNumberUtils.createNumber() should work equally for 0x1234 and 0X1234; currently 0X1234 generates a NumberFormatException Integer.decode() handles both upper and lower case hex.", "A_clean_title": ["numberutil", "number", "util", "not", "handl", "upper", "case", "hex", "0x", "0xnumberutil", "createnumb", "0x", "number", "util", "creat", "number", "work", "equal", "0x1234", "0x1234", "current", "0x1234", "gener", "numberformatexcept", "number", "format", "except", "integ", "decod", "handl", "both", "upper", "lower", "case", "hex"], "B_title": "NumberUtils does not handle upper-case hex: 0X and -0X", "B_clean_title": ["numberutil", "number", "util", "not", "handl", "upper", "case", "hex", "0x", "0x"]},
{"A_title": "Processor is not using templated type when process method is in an abstract classWe define an abstract spoon Processor declaring a process method on a templated type:     And create a concrete class extending the previous one:      The problem is that both the concrete processors are receiving every classes that matches the  upper bound of our template.", "A_clean_title": ["processor", "not", "templat", "type", "when", "process", "method", "abstract", "classw", "class", "we", "defin", "abstract", "spoon", "processor", "declar", "process", "method", "templat", "type", "creat", "concret", "class", "extend", "previou", "one", "problem", "that", "both", "concret", "processor", "are", "receiv", "everi", "class", "that", "match", "upper", "bound", "our", "templat"], "B_title": "fix: fix issue related to processing generic types (#1504)  fix #1503", "B_clean_title": ["fix", "fix", "issu", "relat", "process", "gener", "type", "1504", "fix", "1503"]},
{"A_title": "Revision GC fails when split documents with very long paths are presentMy company is using the MongoDB microkernel with Oak and weve noticed that the daily revision GC is failing with errors like this: code 13.07.2015 13:06:16.261 *ERROR* pool-7-thread-1-Maintenance Queue(com/adobe/granite/maintenance/job/RevisionCleanupTask) org.apache.jackrabbit.oak.management.ManagementOperation Revision garbage collection failed java.lang.IllegalArgumentException: 13:h113f9d0fe7ac0f87fa06397c37b9ffd4b372eeb1ec93e0818bb4024a32587820 at org.apache.jackrabbit.oak.plugins.document.Revision.fromString(Revision.java:236) at org.apache.jackrabbit.oak.plugins.document.SplitDocumentCleanUp.disconnect(SplitDocumentCleanUp.java:84) at org.apache.jackrabbit.oak.plugins.document.SplitDocumentCleanUp.disconnect(SplitDocumentCleanUp.java:56) at org.apache.jackrabbit.oak.plugins.document.VersionGCSupport.deleteSplitDocuments(VersionGCSupport.java:53) at org.apache.jackrabbit.oak.plugins.document.VersionGarbageCollector.collectSplitDocuments(VersionGarbageCollector.java:117) at org.apache.jackrabbit.oak.plugins.document.VersionGarbageCollector.gc(VersionGarbageCollector.java:105) at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreService 2.run(DocumentNodeStoreService.java:511) at org.apache.jackrabbit.oak.spi.state.RevisionGC 1.call(RevisionGC.java:68) at org.apache.jackrabbit.oak.spi.state.RevisionGC 1.call(RevisionGC.java:64) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745) code  Ive narrowed the issue down to the disconnect(NodeDocument) method of the SplitDocumentCleanUp class|https://svn.apache.org/repos/asf/jackrabbit/oak/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitDocumentCleanUp.java. The method always tries to extract the path of the node from its ID but this wont work for documents whose path is very long because those documents will have the hash of their path in the ID.  I believe this code should fix the issue but I havent had a chance to actually try it: code     private void disconnect(NodeDocument splitDoc)          String mainId = Utils.getIdFromPath(splitDoc.getMainPath());         NodeDocument doc = store.find(NODES mainId);         if (doc == null)              LOG.warn(Main document  already removed. Split document is                      mainId splitId);             return;                  String path = splitDoc.getPath();         int slashIdx = path.lastIndexOf(/);         int height = Integer.parseInt(path.substring(slashIdx + 1));         Revision rev = Revision.fromString(                 path.substring(path.lastIndexOf(/ slashIdx - 1) + 1 slashIdx));         doc = doc.findPrevReferencingDoc(rev height);         if (doc == null)              LOG.warn(Split document  not referenced anymore. Main document is                      splitId mainId);             return;                  // remove reference         if (doc.getSplitDocType() == INTERMEDIATE)              disconnectFromIntermediate(doc rev);          else              markStaleOnMain(doc rev height);               code By using getPath() the code should automatically use either the ID or the _path property whichever is right for the document.", "A_clean_title": ["revis", "gc", "fail", "when", "split", "document", "veri", "long", "path", "are", "presentmi", "present", "my", "compani", "mongodb", "mongo", "db", "microkernel", "oak", "weve", "notic", "that", "daili", "revis", "gc", "fail", "error", "like", "thi", "code", "13", "07", "2015", "13:06:16", "261", "error", "pool", "thread", "mainten", "queue", "com", "adob", "granit", "mainten", "job", "revisioncleanuptask", "revis", "cleanup", "task", "org", "apach", "jackrabbit", "oak", "manag", "managementoper", "manag", "oper", "revis", "garbag", "collect", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "13", "h113f9d0fe7ac0f87fa06397c37b9ffd4b372eeb1ec93e0818bb4024a32587820", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "revis", "fromstr", "string", "revis", "java:236", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "splitdocumentcleanup", "disconnect", "split", "document", "clean", "up", "splitdocumentcleanup", "java:84", "split", "document", "clean", "up", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "splitdocumentcleanup", "disconnect", "split", "document", "clean", "up", "splitdocumentcleanup", "java:56", "split", "document", "clean", "up", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "versiongcsupport", "deletesplitdocu", "version", "gc", "support", "delet", "split", "document", "versiongcsupport", "java:53", "version", "gc", "support", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "versiongarbagecollector", "collectsplitdocu", "version", "garbag", "collector", "collect", "split", "document", "versiongarbagecollector", "java:117", "version", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "versiongarbagecollector", "gc", "version", "garbag", "collector", "versiongarbagecollector", "java:105", "version", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestoreservic", "document", "node", "store", "servic", "run", "documentnodestoreservic", "java:511", "document", "node", "store", "servic", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "revisiongc", "revis", "gc", "call", "revisiongc", "java:68", "revis", "gc", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "revisiongc", "revis", "gc", "call", "revisiongc", "java:64", "revis", "gc", "at", "java", "util", "concurr", "futuretask", "run", "futur", "task", "futuretask", "java:262", "futur", "task", "at", "java", "util", "concurr", "threadpoolexecutor", "runwork", "thread", "pool", "executor", "run", "worker", "threadpoolexecutor", "java:1145", "thread", "pool", "executor", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:615", "thread", "pool", "executor", "at", "java", "lang", "thread", "run", "thread", "java:745", "code", "ive", "narrow", "issu", "down", "disconnect", "nodedocu", "node", "document", "method", "splitdocumentcleanup", "split", "document", "clean", "up", "class|http", "apach", "java", "svn", "org", "repo", "asf", "jackrabbit", "oak", "trunk", "oak", "core", "src", "main", "java", "org", "apach", "jackrabbit", "oak", "plugin", "document", "splitdocumentcleanup", "split", "document", "clean", "up", "method", "alway", "tri", "extract", "path", "node", "it", "id", "but", "thi", "wont", "work", "document", "whose", "path", "veri", "long", "becaus", "those", "document", "will", "have", "hash", "their", "path", "id", "believ", "thi", "code", "fix", "issu", "but", "havent", "had", "chanc", "actual", "tri", "it", "code", "privat", "void", "disconnect", "nodedocu", "node", "document", "splitdoc", "split", "doc", "string", "mainid", "main", "id", "util", "getidfrompath", "get", "id", "path", "splitdoc", "getmainpath", "split", "doc", "get", "main", "path", "nodedocu", "node", "document", "doc", "store", "find", "node", "mainid", "main", "id", "doc", "null", "log", "warn", "main", "document", "alreadi", "remov", "split", "document", "mainid", "main", "id", "splitid", "split", "id", "return", "string", "path", "splitdoc", "getpath", "split", "doc", "get", "path", "int", "slashidx", "slash", "idx", "path", "lastindexof", "last", "index", "int", "height", "integ", "parseint", "pars", "int", "path", "substr", "slashidx", "slash", "idx", "revis", "rev", "revis", "fromstr", "string", "path", "substr", "path", "lastindexof", "last", "index", "slashidx", "slash", "idx", "slashidx", "slash", "idx", "doc", "doc", "findprevreferencingdoc", "find", "prev", "referenc", "doc", "rev", "height", "doc", "null", "log", "warn", "split", "document", "not", "referenc", "anymor", "main", "document", "splitid", "split", "id", "mainid", "main", "id", "return", "remov", "refer", "doc", "getsplitdoctyp", "get", "split", "doc", "type", "intermedi", "disconnectfromintermedi", "disconnect", "intermedi", "doc", "rev", "markstaleonmain", "mark", "stale", "main", "doc", "rev", "height", "code", "by", "getpath", "get", "path", "code", "automat", "use", "either", "id", "or", "path", "properti", "whichev", "right", "document"], "B_title": "Revision GC fails when split documents with very long paths are present", "B_clean_title": ["revis", "gc", "fail", "when", "split", "document", "veri", "long", "path", "are", "present"]},
{"A_title": "Negative value with restrictNonNegativeProblem: commons-math-2.2 SimplexSolver.  A variable with 0 coefficient may be assigned a negative value nevertheless restrictToNonnegative flag in call: SimplexSolver.optimize(function constraints GoalType.MINIMIZE true);  Function 1 * x + 1 * y + 0  Constraints: 1 * x + 0 * y = 1  Result: x = 1; y = -1;  Probably variables with 0 coefficients are omitted at some point of computation and because of that the restrictions do not affect their values.", "A_clean_title": ["neg", "valu", "restrictnonnegativeproblem", "restrict", "non", "neg", "problem", "common", "math", "simplexsolv", "simplex", "solver", "variabl", "coeffici", "may", "assign", "neg", "valu", "nevertheless", "restricttononneg", "restrict", "nonneg", "flag", "call", "simplexsolv", "optim", "simplex", "solver", "function", "constraint", "goaltyp", "minim", "goal", "type", "true", "function", "constraint", "result", "probabl", "variabl", "coeffici", "are", "omit", "at", "some", "point", "comput", "becaus", "that", "restrict", "not", "affect", "their", "valu"], "B_title": "Fixed case of unconstrained variables that still occur in the objective function in simplex solver.", "B_clean_title": ["fix", "case", "unconstrain", "variabl", "that", "still", "occur", "object", "function", "simplex", "solver"]},
{"A_title": "WicketTester does not follow absolute redirectsWicket tester does not follow absolute redirects:  This is a problem when using HttpsMapper. For example when requesting a page over http:// with an forced redirect to https:// for secure access will make wicket tester return null for the last renderer page instead of the rendered page instance. In general all kinds of absolute redirects to another page will not be tracked by wicket tester. So this potentially a problem for all kinds of tests that rely on absolute redirects.", "A_clean_title": ["wickettest", "wicket", "tester", "not", "follow", "absolut", "redirectswicket", "redirect", "wicket", "tester", "not", "follow", "absolut", "redirect", "thi", "problem", "when", "httpsmapper", "http", "mapper", "exampl", "when", "request", "page", "over", "http", "forc", "redirect", "http", "secur", "access", "will", "make", "wicket", "tester", "return", "null", "last", "render", "page", "instead", "render", "page", "instanc", "gener", "all", "kind", "absolut", "redirect", "anoth", "page", "will", "not", "track", "by", "wicket", "tester", "so", "thi", "potenti", "problem", "all", "kind", "test", "that", "reli", "absolut", "redirect"], "B_title": "WicketTester does not follow absolute redirects", "B_clean_title": ["wickettest", "wicket", "tester", "not", "follow", "absolut", "redirect"]},
{"A_title": "IllegalStateException at com.google.javascript.rhino.jstype.FunctionType.getInstanceTypeNone", "A_clean_title": ["illegalstateexcept", "illeg", "state", "except", "at", "com", "googl", "javascript", "rhino", "jstype", "functiontyp", "getinstancetypenon", "function", "type", "get", "instanc", "type", "none"], "B_title": "Skip checks if constructor has no instance type.", "B_clean_title": ["skip", "check", "constructor", "ha", "no", "instanc", "type"]},
{"A_title": "Query: for joins sometimes no or the wrong index is usedCurrently no index is used for the join condition. For example the query:  code select * from nodeTypeA as a  inner join nodeTypeB as b on isdescendantnode(b a)  where lower(a.x) = y and b.property is not null code  currently doesnt take into account that the path of the selector a is known at the time selector b is accessed (given that selector a is executed first). So in this case the query would use an index on the property b.property even if this index has a very bad selectivity (many nodes with this problem) or the query would use the node type index on nodeTypeB even if there are many nodes of this type.  Instead most likely the query should do a traversal using the isdescendantnode(b a) join condition.", "A_clean_title": ["queri", "join", "sometim", "no", "or", "wrong", "index", "usedcurr", "use", "current", "no", "index", "use", "join", "condit", "exampl", "queri", "code", "select", "nodetypea", "node", "type", "as", "inner", "join", "nodetypeb", "node", "type", "as", "isdescendantnod", "where", "lower", "properti", "not", "null", "code", "current", "doesnt", "take", "into", "account", "that", "path", "selector", "known", "at", "time", "selector", "access", "given", "that", "selector", "execut", "first", "so", "thi", "case", "queri", "would", "use", "index", "properti", "properti", "even", "thi", "index", "ha", "veri", "bad", "select", "mani", "node", "thi", "problem", "or", "queri", "would", "use", "node", "type", "index", "nodetypeb", "node", "type", "even", "there", "are", "mani", "node", "thi", "type", "instead", "most", "like", "queri", "travers", "isdescendantnod", "join", "condit"], "B_title": "Query: for joins sometimes no or the wrong index is used", "B_clean_title": ["queri", "join", "sometim", "no", "or", "wrong", "index", "use"]},
{"A_title": "Malformed solr delete queryFollowing OAK-734 the solr query tests are failing because of a parsing error on the wildcard delete query.  The exact query is path_exact:/test* which apparently upsets the lucene parser somehow.  Full trace:  code SEVERE: org.apache.solr.common.SolrException: org.apache.lucene.queryparser.classic.ParseException: Cannot parse path_exact:/test*: Lexical error at line 1 column 18.  Encountered: <EOF> after : /test* at org.apache.solr.update.DirectUpdateHandler2.getQuery(DirectUpdateHandler2.java:328) at org.apache.solr.update.DirectUpdateHandler2.deleteByQuery(DirectUpdateHandler2.java:340) at org.apache.solr.update.processor.RunUpdateProcessor.processDelete(RunUpdateProcessorFactory.java:72) at org.apache.solr.update.processor.UpdateRequestProcessor.processDelete(UpdateRequestProcessor.java:55) at org.apache.solr.update.processor.DistributedUpdateProcessor.doLocalDelete(DistributedUpdateProcessor.java:437) at org.apache.solr.update.processor.DistributedUpdateProcessor.doDeleteByQuery(DistributedUpdateProcessor.java:835) at org.apache.solr.update.processor.DistributedUpdateProcessor.processDelete(DistributedUpdateProcessor.java:657) at org.apache.solr.update.processor.LogUpdateProcessor.processDelete(LogUpdateProcessorFactory.java:121) at org.apache.solr.handler.loader.XMLLoader.processDelete(XMLLoader.java:330) at org.apache.solr.handler.loader.XMLLoader.processUpdate(XMLLoader.java:261) at org.apache.solr.handler.loader.XMLLoader.load(XMLLoader.java:157) at org.apache.solr.handler.UpdateRequestHandler 1.load(UpdateRequestHandler.java:92) at org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody(ContentStreamHandlerBase.java:74) at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:129) at org.apache.solr.core.SolrCore.execute(SolrCore.java:1699) at org.apache.solr.client.solrj.embedded.EmbeddedSolrServer.request(EmbeddedSolrServer.java:150) at org.apache.solr.client.solrj.request.AbstractUpdateRequest.process(AbstractUpdateRequest.java:117) at org.apache.solr.client.solrj.SolrServer.deleteByQuery(SolrServer.java:285) at org.apache.solr.client.solrj.SolrServer.deleteByQuery(SolrServer.java:271) at org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexUpdate.deleteSubtreeWriter(SolrIndexUpdate.java:161) at org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexUpdate.apply(SolrIndexUpdate.java:98) at org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexDiff.leave(SolrIndexDiff.java:202) at org.apache.jackrabbit.oak.spi.commit.CompositeEditor.leave(CompositeEditor.java:74) at org.apache.jackrabbit.oak.plugins.index.IndexHookManagerDiff.leave(IndexHookManagerDiff.java:117) at org.apache.jackrabbit.oak.spi.commit.EditorHook EditorDiff.process(EditorHook.java:115) at org.apache.jackrabbit.oak.spi.commit.EditorHook.process(EditorHook.java:80) at org.apache.jackrabbit.oak.spi.commit.EditorHook.processCommit(EditorHook.java:54) at org.apache.jackrabbit.oak.kernel.KernelNodeStoreBranch.merge(KernelNodeStoreBranch.java:144) at org.apache.jackrabbit.oak.core.RootImpl 2.run(RootImpl.java:266) at org.apache.jackrabbit.oak.core.RootImpl 2.run(RootImpl.java:1) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:337) at org.apache.jackrabbit.oak.core.RootImpl.commit(RootImpl.java:261) at org.apache.jackrabbit.oak.query.AbstractQueryTest.test(AbstractQueryTest.java:236) at org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTest.sql2(SolrIndexQueryTest.java:79) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.junit.runners.model.FrameworkMethod 1.runReflectiveCall(FrameworkMethod.java:44) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:76) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) at org.junit.runners.ParentRunner 3.run(ParentRunner.java:193) at org.junit.runners.ParentRunner 1.schedule(ParentRunner.java:52) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191) at org.junit.runners.ParentRunner.access 000(ParentRunner.java:42) at org.junit.runners.ParentRunner 2.evaluate(ParentRunner.java:184) at org.junit.runners.ParentRunner.run(ParentRunner.java:236) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197) Caused by: org.apache.lucene.queryparser.classic.ParseException: Cannot parse path_exact:/test*: Lexical error at line 1 column 18.  Encountered: <EOF> after : /test* at org.apache.lucene.queryparser.classic.QueryParserBase.parse(QueryParserBase.java:130) at org.apache.solr.search.LuceneQParser.parse(LuceneQParserPlugin.java:72) at org.apache.solr.search.QParser.getQuery(QParser.java:143) at org.apache.solr.update.DirectUpdateHandler2.getQuery(DirectUpdateHandler2.java:310) ... 58 more Caused by: org.apache.lucene.queryparser.classic.TokenMgrError: Lexical error at line 1 column 18.  Encountered: <EOF> after : /test* at org.apache.lucene.queryparser.classic.QueryParserTokenManager.getNextToken(QueryParserTokenManager.java:1048) at org.apache.lucene.queryparser.classic.QueryParser.jj_ntk(QueryParser.java:638) at org.apache.lucene.queryparser.classic.QueryParser.Clause(QueryParser.java:246) at org.apache.lucene.queryparser.classic.QueryParser.Query(QueryParser.java:181) at org.apache.lucene.queryparser.classic.QueryParser.TopLevelQuery(QueryParser.java:170) at org.apache.lucene.queryparser.classic.QueryParserBase.parse(QueryParserBase.java:120) ... 61 more code", "A_clean_title": ["malform", "solr", "delet", "queryfollow", "queri", "follow", "oak", "734", "solr", "queri", "test", "are", "fail", "becaus", "pars", "error", "wildcard", "delet", "queri", "exact", "queri", "path", "exact", "test", "which", "appar", "upset", "lucen", "parser", "somehow", "full", "trace", "code", "sever", "org", "apach", "solr", "common", "solrexcept", "solr", "except", "org", "apach", "lucen", "querypars", "classic", "parseexcept", "pars", "except", "not", "pars", "path", "exact", "test", "lexic", "error", "at", "line", "column", "18", "encount", "eof", "after", "test", "at", "org", "apach", "solr", "updat", "directupdatehandler2", "getqueri", "direct", "updat", "handler2", "get", "queri", "directupdatehandler2", "java:328", "direct", "updat", "handler2", "at", "org", "apach", "solr", "updat", "directupdatehandler2", "deletebyqueri", "direct", "updat", "handler2", "delet", "by", "queri", "directupdatehandler2", "java:340", "direct", "updat", "handler2", "at", "org", "apach", "solr", "updat", "processor", "runupdateprocessor", "processdelet", "run", "updat", "processor", "process", "delet", "runupdateprocessorfactori", "java:72", "run", "updat", "processor", "factori", "at", "org", "apach", "solr", "updat", "processor", "updaterequestprocessor", "processdelet", "updat", "request", "processor", "process", "delet", "updaterequestprocessor", "java:55", "updat", "request", "processor", "at", "org", "apach", "solr", "updat", "processor", "distributedupdateprocessor", "dolocaldelet", "distribut", "updat", "processor", "local", "delet", "distributedupdateprocessor", "java:437", "distribut", "updat", "processor", "at", "org", "apach", "solr", "updat", "processor", "distributedupdateprocessor", "dodeletebyqueri", "distribut", "updat", "processor", "delet", "by", "queri", "distributedupdateprocessor", "java:835", "distribut", "updat", "processor", "at", "org", "apach", "solr", "updat", "processor", "distributedupdateprocessor", "processdelet", "distribut", "updat", "processor", "process", "delet", "distributedupdateprocessor", "java:657", "distribut", "updat", "processor", "at", "org", "apach", "solr", "updat", "processor", "logupdateprocessor", "processdelet", "log", "updat", "processor", "process", "delet", "logupdateprocessorfactori", "java:121", "log", "updat", "processor", "factori", "at", "org", "apach", "solr", "handler", "loader", "xmlloader", "processdelet", "xml", "loader", "process", "delet", "xmlloader", "java:330", "xml", "loader", "at", "org", "apach", "solr", "handler", "loader", "xmlloader", "processupd", "xml", "loader", "process", "updat", "xmlloader", "java:261", "xml", "loader", "at", "org", "apach", "solr", "handler", "loader", "xmlloader", "load", "xml", "loader", "xmlloader", "java:157", "xml", "loader", "at", "org", "apach", "solr", "handler", "updaterequesthandl", "updat", "request", "handler", "load", "updaterequesthandl", "java:92", "updat", "request", "handler", "at", "org", "apach", "solr", "handler", "contentstreamhandlerbas", "handlerequestbodi", "content", "stream", "handler", "base", "handl", "request", "bodi", "contentstreamhandlerbas", "java:74", "content", "stream", "handler", "base", "at", "org", "apach", "solr", "handler", "requesthandlerbas", "handlerequest", "request", "handler", "base", "handl", "request", "requesthandlerbas", "java:129", "request", "handler", "base", "at", "org", "apach", "solr", "core", "solrcor", "execut", "solr", "core", "solrcor", "java:1699", "solr", "core", "at", "org", "apach", "solr", "client", "solrj", "embed", "embeddedsolrserv", "request", "embed", "solr", "server", "embeddedsolrserv", "java:150", "embed", "solr", "server", "at", "org", "apach", "solr", "client", "solrj", "request", "abstractupdaterequest", "process", "abstract", "updat", "request", "abstractupdaterequest", "java:117", "abstract", "updat", "request", "at", "org", "apach", "solr", "client", "solrj", "solrserv", "deletebyqueri", "solr", "server", "delet", "by", "queri", "solrserv", "java:285", "solr", "server", "at", "org", "apach", "solr", "client", "solrj", "solrserv", "deletebyqueri", "solr", "server", "delet", "by", "queri", "solrserv", "java:271", "solr", "server", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "solr", "index", "solrindexupd", "deletesubtreewrit", "solr", "index", "updat", "delet", "subtre", "writer", "solrindexupd", "java:161", "solr", "index", "updat", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "solr", "index", "solrindexupd", "appli", "solr", "index", "updat", "solrindexupd", "java:98", "solr", "index", "updat", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "solr", "index", "solrindexdiff", "leav", "solr", "index", "diff", "solrindexdiff", "java:202", "solr", "index", "diff", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositeeditor", "leav", "composit", "editor", "compositeeditor", "java:74", "composit", "editor", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "indexhookmanagerdiff", "leav", "index", "hook", "manag", "diff", "indexhookmanagerdiff", "java:117", "index", "hook", "manag", "diff", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "editorhook", "editor", "hook", "editordiff", "process", "editor", "diff", "editorhook", "java:115", "editor", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "editorhook", "process", "editor", "hook", "editorhook", "java:80", "editor", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "editorhook", "processcommit", "editor", "hook", "process", "commit", "editorhook", "java:54", "editor", "hook", "at", "org", "apach", "jackrabbit", "oak", "kernel", "kernelnodestorebranch", "merg", "kernel", "node", "store", "branch", "kernelnodestorebranch", "java:144", "kernel", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "root", "impl", "run", "rootimpl", "java:266", "root", "impl", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "root", "impl", "run", "rootimpl", "java:1", "root", "impl", "at", "java", "secur", "accesscontrol", "doprivileg", "access", "control", "privileg", "nativ", "method", "at", "javax", "secur", "auth", "subject", "doa", "as", "subject", "java:337", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "commit", "root", "impl", "rootimpl", "java:261", "root", "impl", "at", "org", "apach", "jackrabbit", "oak", "queri", "abstractquerytest", "test", "abstract", "queri", "test", "abstractquerytest", "java:236", "abstract", "queri", "test", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "solr", "queri", "solrindexquerytest", "sql2", "solr", "index", "queri", "test", "solrindexquerytest", "java:79", "solr", "index", "queri", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "org", "junit", "runner", "model", "frameworkmethod", "framework", "method", "runreflectivecal", "run", "reflect", "call", "frameworkmethod", "java:44", "framework", "method", "at", "org", "junit", "intern", "runner", "model", "reflectivecal", "run", "reflect", "callabl", "reflectivecal", "java:15", "reflect", "callabl", "at", "org", "junit", "runner", "model", "frameworkmethod", "invokeexplos", "framework", "method", "invok", "explos", "frameworkmethod", "java:41", "framework", "method", "at", "org", "junit", "intern", "runner", "statement", "invokemethod", "evalu", "invok", "method", "invokemethod", "java:20", "invok", "method", "at", "org", "junit", "intern", "runner", "statement", "runbefor", "evalu", "run", "befor", "runbefor", "java:28", "run", "befor", "at", "org", "junit", "intern", "runner", "statement", "runaft", "evalu", "run", "after", "runaft", "java:31", "run", "after", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:76", "block", "unit4class", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:50", "block", "unit4class", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "run", "parentrunn", "java:193", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "schedul", "parentrunn", "java:52", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "runchildren", "parent", "runner", "run", "children", "parentrunn", "java:191", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "access", "parent", "runner", "000", "parentrunn", "java:42", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "evalu", "parentrunn", "java:184", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "run", "parent", "runner", "parentrunn", "java:236", "parent", "runner", "at", "org", "eclips", "jdt", "intern", "junit4", "runner", "junit4testrefer", "run", "unit4test", "refer", "junit4testrefer", "java:50", "unit4test", "refer", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "testexecut", "run", "test", "execut", "testexecut", "java:38", "test", "execut", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:467", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:683", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "run", "remot", "test", "runner", "remotetestrunn", "java:390", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "main", "remot", "test", "runner", "remotetestrunn", "java:197", "remot", "test", "runner", "caus", "by", "org", "apach", "lucen", "querypars", "classic", "parseexcept", "pars", "except", "not", "pars", "path", "exact", "test", "lexic", "error", "at", "line", "column", "18", "encount", "eof", "after", "test", "at", "org", "apach", "lucen", "querypars", "classic", "queryparserbas", "pars", "queri", "parser", "base", "queryparserbas", "java:130", "queri", "parser", "base", "at", "org", "apach", "solr", "search", "luceneqpars", "pars", "lucen", "parser", "luceneqparserplugin", "java:72", "lucen", "parser", "plugin", "at", "org", "apach", "solr", "search", "qparser", "getqueri", "parser", "get", "queri", "qparser", "java:143", "parser", "at", "org", "apach", "solr", "updat", "directupdatehandler2", "getqueri", "direct", "updat", "handler2", "get", "queri", "directupdatehandler2", "java:310", "direct", "updat", "handler2", "58", "more", "caus", "by", "org", "apach", "lucen", "querypars", "classic", "tokenmgrerror", "token", "mgr", "error", "lexic", "error", "at", "line", "column", "18", "encount", "eof", "after", "test", "at", "org", "apach", "lucen", "querypars", "classic", "queryparsertokenmanag", "getnexttoken", "queri", "parser", "token", "manag", "get", "next", "token", "queryparsertokenmanag", "java:1048", "queri", "parser", "token", "manag", "at", "org", "apach", "lucen", "querypars", "classic", "querypars", "queri", "parser", "jj", "ntk", "querypars", "java:638", "queri", "parser", "at", "org", "apach", "lucen", "querypars", "classic", "querypars", "claus", "queri", "parser", "querypars", "java:246", "queri", "parser", "at", "org", "apach", "lucen", "querypars", "classic", "querypars", "queri", "queri", "parser", "querypars", "java:181", "queri", "parser", "at", "org", "apach", "lucen", "querypars", "classic", "querypars", "toplevelqueri", "queri", "parser", "top", "level", "queri", "querypars", "java:170", "queri", "parser", "at", "org", "apach", "lucen", "querypars", "classic", "queryparserbas", "pars", "queri", "parser", "base", "queryparserbas", "java:120", "queri", "parser", "base", "61", "more", "code"], "B_title": "Malformed solr delete query", "B_clean_title": ["malform", "solr", "delet", "queri"]},
{"A_title": "ArgumentCaptor no longer working for varargsWhen upgrading 1.10.8 the verify passes but the getValue() fails with this error. One other piece of info came to light as a result of creating the MCVE - the test works fine if the Date is the only element passed for bindVariables. That is remove var1 from target and test code then the test runs fine under 1.9.5 and 1.10.8. Also it doesnt matter that the captor is for a Date. The same issue occurs if the parameter is of another type such as Integer.", "A_clean_title": ["argumentcaptor", "argument", "captor", "no", "longer", "work", "varargswhen", "vararg", "when", "upgrad", "10", "verifi", "pass", "but", "getvalu", "get", "valu", "fail", "thi", "error", "one", "other", "piec", "info", "came", "light", "as", "result", "creat", "mcve", "test", "work", "fine", "date", "onli", "element", "pass", "bindvari", "bind", "variabl", "that", "remov", "var1", "target", "test", "code", "then", "test", "run", "fine", "under", "10", "also", "it", "doesnt", "matter", "that", "captor", "date", "same", "issu", "occur", "paramet", "anoth", "type", "such", "as", "integ"], "B_title": "Fixed issue 188 @Captor annotation should work OK with nested parametrized type", "B_clean_title": ["fix", "issu", "188", "captor", "annot", "work", "ok", "nest", "parametr", "type"]},
{"A_title": "URL IPv6 parsingThere is an issue with native IPv6 address parsing. https://::1/myapp URL parsing fails:  org.apache.wicket.request.Url.parse(https://::1/myapp) generates an exception: java.lang.NumberFormatException: For input string: 1 at java.lang.NumberFormatException.forInputString( NumberFormatException.java:65) at java.lang.Integer.parseInt(Integer.java:492)  However https://::1:80/myapp works as expected.", "A_clean_title": ["url", "ipv6", "pv6", "parsingther", "pars", "there", "issu", "nativ", "ipv6", "pv6", "address", "pars", "http", ":1", "myapp", "url", "pars", "fail", "org", "apach", "wicket", "request", "url", "pars", "http", ":1", "myapp", "gener", "except", "java", "lang", "numberformatexcept", "number", "format", "except", "input", "string", "at", "java", "lang", "numberformatexcept", "forinputstr", "number", "format", "except", "input", "string", "numberformatexcept", "java:65", "number", "format", "except", "at", "java", "lang", "integ", "parseint", "pars", "int", "integ", "java:492", "howev", "http", ":1:80", "myapp", "work", "as", "expect"], "B_title": "URL IPv6 parsing", "B_clean_title": ["url", "ipv6", "pv6", "pars"]},
{"A_title": "Fraction percentageValue rare overflowThe percentageValue() method of the Fraction class works by first multiplying the Fraction by 100 then converting the Fraction to a double. This causes overflows when the numerator is greater than Integer.MAX_VALUE/100 even when the value of the fraction is far below this value. The patch changes the method to first convert to a double value and then multiply this value by 100 - the result should be the same but with less overflows. An addition to the test for the method that covers this bug is also included.", "A_clean_title": ["fraction", "percentagevalu", "percentag", "valu", "rare", "overflowth", "overflow", "percentagevalu", "percentag", "valu", "method", "fraction", "class", "work", "by", "first", "multipli", "fraction", "by", "100", "then", "convert", "fraction", "doubl", "thi", "caus", "overflow", "when", "numer", "greater", "than", "integ", "max", "valu", "100", "even", "when", "valu", "fraction", "far", "below", "thi", "valu", "patch", "chang", "method", "first", "convert", "doubl", "valu", "then", "multipli", "thi", "valu", "by", "100", "result", "same", "but", "less", "overflow", "addit", "test", "method", "that", "cover", "thi", "bug", "also", "includ"], "B_title": "Avoid overflow.", "B_clean_title": ["avoid", "overflow"]},
{"A_title": "Component#setDefaultModel() should call #modelChanging()Component#setDefaultModel() should call #modelChanging() as #setDefaultModelObject() does. It worked by chance so far because addStateChange() is called.  http://markmail.org/thread/uxl6uufusggqbb6s", "A_clean_title": ["compon", "setdefaultmodel", "set", "default", "model", "call", "modelchang", "model", "chang", "compon", "setdefaultmodel", "set", "default", "model", "call", "modelchang", "model", "chang", "as", "setdefaultmodelobject", "set", "default", "model", "object", "it", "work", "by", "chanc", "so", "far", "becaus", "addstatechang", "add", "state", "chang", "call", "http", "markmail", "org", "thread", "uxl6uufusggqbb6"], "B_title": "Component#setDefaultModel() should call #modelChanging()", "B_clean_title": ["compon", "setdefaultmodel", "set", "default", "model", "call", "modelchang", "model", "chang"]},
{"A_title": "Validity checks missing for readFields and Thrift deserializationClasses in o.a.a.core.data (and potentially elsewhere) that support construction from a Thrift object and/or population from a DataInput (via a readFields() method) often lack data validity checks that the classes constructors enforce. The missing checks make it possible for an attacker to create invalid objects by manipulating the bytes being read. The situation is analogous to the need to check objects deserialized from their Java serialized form within the readObject() method.", "A_clean_title": ["valid", "check", "miss", "readfield", "read", "field", "thrift", "deserializationclass", "deseri", "class", "core", "data", "potenti", "elsewher", "that", "support", "construct", "thrift", "object", "or", "popul", "datainput", "data", "input", "via", "readfield", "read", "field", "method", "often", "lack", "data", "valid", "check", "that", "class", "constructor", "enforc", "miss", "check", "make", "it", "possibl", "attack", "creat", "invalid", "object", "by", "manipul", "byte", "be", "read", "situat", "analog", "need", "check", "object", "deseri", "their", "java", "serial", "form", "within", "readobject", "read", "object", "method"], "B_title": "merge to 1.5.1-SNAPSHOT", "B_clean_title": ["merg", "snapshot"]},
{"A_title": "RDB Updated blob still deleted even if deletion interval lowerIf an existing blob is uploaded again the timestamp of the existing entry is updated in the meta table. Subsequently if a call to delete (RDBBlobStore#countDeleteChunks) is made with maxLastModifiedTime parameter of less than the updated time above the entry in the meta table is not touched but the data table entry is wiped out.   Refer https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/rdb/RDBBlobStore.java#L510", "A_clean_title": ["rdb", "updat", "blob", "still", "delet", "even", "delet", "interv", "lowerif", "lower", "exist", "blob", "upload", "again", "timestamp", "exist", "entri", "updat", "meta", "tabl", "subsequ", "call", "delet", "rdbblobstor", "rdb", "blob", "store", "countdeletechunk", "count", "delet", "chunk", "made", "maxlastmodifiedtim", "max", "last", "modifi", "time", "paramet", "less", "than", "updat", "time", "abov", "entri", "meta", "tabl", "not", "touch", "but", "data", "tabl", "entri", "wipe", "out", "refer", "http", "oak", "blob", "trunk", "oak", "java", "github", "com", "apach", "jackrabbit", "core", "src", "main", "java", "org", "apach", "jackrabbit", "oak", "plugin", "document", "rdb", "rdbblobstor", "rdb", "blob", "store", "l510"], "B_title": "RDBBlobStore - fix problem when cleaning up data rows", "B_clean_title": ["rdbblobstor", "rdb", "blob", "store", "fix", "problem", "when", "clean", "up", "data", "row"]},
{"A_title": "StringEscapeUtils.escapeJava(String) escapes / charactersCommons Lang 2.4 StringEscapeUtils.escapeJava(String) now escapes / characters which is not a valid escapable character in Java strings.  I havent tried the other Java escape/unescape methods to see if they have a similar problem or that only Java escapable characters are escaped by escapeJava(String). This bug may have appeared as an unintended side-effect of the fix for LANG-363. Also the javadoc for escapeJava is now a little off in that / should now be included in the sentence describing the differences between Java and Javascript strings with respect to escaping rules. The following is a JUnit3 test demonstrating the bug. import junit.framework.TestCase; import org.apache.commons.lang.StringEscapeUtils; public class StringEscapeUtilsTest extends TestCase      public void testEscapeJavaWithSlash()           final String input = String with a slash (/) in it;                  final String expected = input;         final String actual   = StringEscapeUtils.escapeJava( input );          /**          * In 2.4 StringEscapeUtils.escapeJava(String) escapes / characters          * which are not a valid character to escape in a Java string.            */         assertEquals( expected actual );", "A_clean_title": ["stringescapeutil", "escapejava", "string", "escap", "util", "escap", "java", "string", "escap", "characterscommon", "charact", "common", "lang", "stringescapeutil", "escapejava", "string", "escap", "util", "escap", "java", "string", "now", "escap", "charact", "which", "not", "valid", "escap", "charact", "java", "string", "havent", "tri", "other", "java", "escap", "unescap", "method", "see", "they", "have", "similar", "problem", "or", "that", "onli", "java", "escap", "charact", "are", "escap", "by", "escapejava", "escap", "java", "string", "thi", "bug", "may", "have", "appear", "as", "unintend", "side", "effect", "fix", "lang", "363", "also", "javadoc", "escapejava", "escap", "java", "now", "littl", "off", "that", "now", "includ", "sentenc", "describ", "differ", "between", "java", "javascript", "string", "respect", "escap", "rule", "follow", "junit3", "unit3", "test", "demonstr", "bug", "import", "junit", "framework", "testcas", "test", "case", "import", "org", "apach", "common", "lang", "stringescapeutil", "string", "escap", "util", "public", "class", "stringescapeutilstest", "string", "escap", "util", "test", "extend", "testcas", "test", "case", "public", "void", "testescapejavawithslash", "test", "escap", "java", "slash", "final", "string", "input", "string", "slash", "it", "final", "string", "expect", "input", "final", "string", "actual", "stringescapeutil", "escapejava", "string", "escap", "util", "escap", "java", "input", "stringescapeutil", "escapejava", "string", "escap", "util", "escap", "java", "string", "escap", "charact", "which", "are", "not", "valid", "charact", "escap", "java", "string", "assertequ", "assert", "equal", "expect", "actual"], "B_title": "StringEscapeUtils.escapeJava(String) escapes / characters", "B_clean_title": ["stringescapeutil", "escapejava", "string", "escap", "util", "escap", "java", "string", "escap", "charact"]},
{"A_title": "NumberUtils.createNumber throws NumberFormatException for one digit longNumberUtils.createNumber throws a NumberFormatException when parsing 1l 2l .. etc... It works fine if you try to parse 01l or 02l.  The condition isDigits(numeric.substring(1)) line 455 return false as numeric.substring(1) is an empty string for 1l", "A_clean_title": ["numberutil", "createnumb", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "one", "digit", "longnumberutil", "createnumb", "long", "number", "util", "creat", "number", "throw", "numberformatexcept", "number", "format", "except", "when", "pars", "1l", "2l", "etc", "it", "work", "fine", "you", "tri", "pars", "01l", "or", "02l", "condit", "isdigit", "digit", "numer", "substr", "line", "455", "return", "fals", "as", "numer", "substr", "empti", "string", "1l"], "B_title": "Fixing LANG-300 (reported by Jeremy Lemaire) - 1L to 9L incorrectly throw exceptions when passed into NumberUtils.createNumber. Fixed in both the math.NumbersUtils and the deprecated NumberUtils classes.", "B_clean_title": ["fix", "lang", "300", "report", "by", "jeremi", "lemair", "1l", "9l", "incorrectli", "throw", "except", "when", "pass", "into", "numberutil", "createnumb", "number", "util", "creat", "number", "fix", "both", "math", "numbersutil", "number", "util", "deprec", "numberutil", "number", "util", "class"]},
{"A_title": "weight versus sigma in AbstractLeastSquaresIn AbstractLeastSquares residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS() these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation it should multiply the square of the residual even in the computation of the chi2.  Once corrected getRMS() can even reduce  public double getRMS()  return Math.sqrt(getChiSquare()/rows);", "A_clean_title": ["weight", "versu", "sigma", "abstractleastsquaresin", "abstract", "least", "squar", "abstractleastsquar", "abstract", "least", "squar", "residualsweight", "residu", "weight", "contain", "weight", "assign", "each", "observ", "method", "getrm", "get", "rm", "these", "weight", "are", "multipl", "as", "they", "unlik", "getchisquar", "get", "chi", "squar", "where", "it", "appear", "at", "denomin", "weight", "realli", "weight", "observ", "it", "multipli", "squar", "residu", "even", "comput", "chi2", "onc", "correct", "getrm", "get", "rm", "even", "reduc", "public", "doubl", "getrm", "get", "rm", "return", "math", "sqrt", "getchisquar", "get", "chi", "squar", "row"], "B_title": "fixed", "B_clean_title": ["fix"]},
{"A_title": "OnChangeAjaxBehavior attached to DropDownChoice produces two Ajax requests in Chrome v35I have a DropDownChoice with attached OnChangeAjaxBehavior like this: code:borderStyle=solid new DropDownChoice<>(dd new Model<>() Arrays.asList( First Second))     .add( new OnChangeAjaxBehavior()          @Override         protected void onUpdate(AjaxRequestTarget target)              System.out.println( update );          ); code  When selecting any of drop down options two Ajax requests being generated. It behaves OK in IE FF and Chrome v34 only Chrome v35 is affected", "A_clean_title": ["onchangeajaxbehavior", "chang", "ajax", "behavior", "attach", "dropdownchoic", "drop", "down", "choic", "produc", "two", "ajax", "request", "chrome", "v35i", "have", "dropdownchoic", "drop", "down", "choic", "attach", "onchangeajaxbehavior", "chang", "ajax", "behavior", "like", "thi", "code", "borderstyle=solid", "border", "style=solid", "new", "dropdownchoic", "drop", "down", "choic", "dd", "new", "model", "array", "aslist", "as", "list", "first", "second", "add", "new", "onchangeajaxbehavior", "chang", "ajax", "behavior", "overrid", "protect", "void", "onupd", "updat", "ajaxrequesttarget", "ajax", "request", "target", "target", "system", "out", "println", "updat", "code", "when", "select", "ani", "drop", "down", "option", "two", "ajax", "request", "be", "gener", "it", "behav", "ok", "ie", "ff", "chrome", "v34", "onli", "chrome", "v35", "affect"], "B_title": "OnChangeAjaxBehavior attached to DropDownChoice produces two Ajax requests in the last versions of Chrome Opera and IE", "B_clean_title": ["onchangeajaxbehavior", "chang", "ajax", "behavior", "attach", "dropdownchoic", "drop", "down", "choic", "produc", "two", "ajax", "request", "last", "version", "chrome", "opera", "ie"]},
{"A_title": "MathUtils.binomialCoefficient(nk) fails for large resultsProbably due to rounding errors MathUtils.binomialCoefficient(nk) fails for results near Long.MAX_VALUE. The existence of failures can be demonstrated by testing the recursive property:           assertEquals(MathUtils.binomialCoefficient(6532) + MathUtils.binomialCoefficient(6533)                  MathUtils.binomialCoefficient(6633));   Or by directly using the (externally calculated and hopefully correct) expected value:           assertEquals(7219428434016265740L MathUtils.binomialCoefficient(6633));   I suggest a nonrecursive test implementation along the lines of MathUtilsTest.java     /**      * Exact implementation using BigInteger and the explicit formula      * (n k) == ((k-1)*...*n) / (1*...*(n-k))      */ public static long binomialCoefficient(int n int k)  if (k == 0 || k == n) return 1; BigInteger result = BigInteger.ONE; for (int i = k + 1; i <= n; i++)  result = result.multiply(BigInteger.valueOf(i));  for (int i = 1; i <= n - k; i++)  result = result.divide(BigInteger.valueOf(i));  if (result.compareTo(BigInteger.valueOf(Long.MAX_VALUE)) > 0)  throw new ArithmeticException(                                 Binomial coefficient overflow:  + n +   + k);  return result.longValue();    Which would allow you to test the expected values directly:           assertEquals(binomialCoefficient(6633) MathUtils.binomialCoefficient(6633));", "A_clean_title": ["mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "nk", "fail", "larg", "resultsprob", "result", "probabl", "due", "round", "error", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "nk", "fail", "result", "near", "long", "max", "valu", "exist", "failur", "demonstr", "by", "test", "recurs", "properti", "assertequ", "assert", "equal", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "6532", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "6533", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "6633", "or", "by", "directli", "extern", "calcul", "hope", "correct", "expect", "valu", "assertequ", "assert", "equal", "7219428434016265740l", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "6633", "suggest", "nonrecurs", "test", "implement", "along", "line", "mathutilstest", "java", "math", "util", "test", "exact", "implement", "biginteg", "big", "integ", "explicit", "formula", "public", "static", "long", "binomialcoeffici", "binomi", "coeffici", "int", "int", "return", "biginteg", "big", "integ", "result", "biginteg", "one", "big", "integ", "int", "i++", "result", "result", "multipli", "biginteg", "valueof", "big", "integ", "valu", "int", "i++", "result", "result", "divid", "biginteg", "valueof", "big", "integ", "valu", "result", "compareto", "compar", "biginteg", "valueof", "big", "integ", "valu", "long", "max", "valu", "throw", "new", "arithmeticexcept", "arithmet", "except", "binomi", "coeffici", "overflow", "return", "result", "longvalu", "long", "valu", "which", "would", "allow", "you", "test", "expect", "valu", "directli", "assertequ", "assert", "equal", "binomialcoeffici", "binomi", "coeffici", "6633", "mathutil", "binomialcoeffici", "math", "util", "binomi", "coeffici", "6633"], "B_title": "Fixed error in binomial coefficient computation JIRA: MATH-241 Reported and patched by Christian Semrau", "B_clean_title": ["fix", "error", "binomi", "coeffici", "comput", "jira", "math", "241", "report", "patch", "by", "christian", "semrau"]},
{"A_title": "StringEscapeUtils.escapeHtml incorrectly converts unicode characters above U+00FFFF into 2 charactersCharacters that are represented as a 2 characters internaly by java are incorrectly converted by the function. The following test displays the problem quite nicely: import org.apache.commons.lang.*; public class J2      public static void main(String args) throws Exception          // this is the utf8 representation of the character:         // COUNTING ROD UNIT DIGIT THREE         // in unicode         // codepoint: U+1D362         byte data = new byte   (byte)0xF0 (byte)0x9D (byte)0x8D (byte)0xA2  ;         //output is: &#55348;&#57186;         // should be: &#119650;         System.out.println( + StringEscapeUtils.escapeHtml(new String(data UTF8)) + );       Should be very quick to fix feel free to drop me an email if you want a patch.", "A_clean_title": ["stringescapeutil", "escapehtml", "string", "escap", "util", "escap", "html", "incorrectli", "convert", "unicod", "charact", "abov", "u+00ffff", "into", "characterscharact", "charact", "charact", "that", "are", "repres", "as", "charact", "internali", "by", "java", "are", "incorrectli", "convert", "by", "function", "follow", "test", "display", "problem", "quit", "nice", "import", "org", "apach", "common", "lang", "public", "class", "j2", "public", "static", "void", "main", "string", "arg", "throw", "except", "thi", "utf8", "represent", "charact", "count", "rod", "unit", "digit", "three", "unicod", "codepoint", "u+1d362", "byte", "data", "new", "byte", "byte", "0xf0", "0x", "f0", "byte", "0x9d", "byte", "0x8d", "byte", "0xa2", "0x", "a2", "output", "55348", "57186", "119650", "system", "out", "println", "stringescapeutil", "escapehtml", "string", "escap", "util", "escap", "html", "new", "string", "data", "utf8", "veri", "quick", "fix", "feel", "free", "drop", "me", "email", "you", "want", "patch"], "B_title": "Applying Alexander Kjalls patch from LANG-480; along with a unit test made from his example. Fixes unicode conversion above U+00FFFF being done into 2 characters", "B_clean_title": ["appli", "alexand", "kjall", "patch", "lang", "480", "along", "unit", "test", "made", "hi", "exampl", "fix", "unicod", "convers", "abov", "u+00ffff", "be", "done", "into", "charact"]},
{"A_title": "multiple <style> tags in header are rendered incorrectlyI created a small quickstart.  The BasePage has some multiple <style> tags. Only he first one is rendered correctly all following render the tag body only the surrounding <style></style> is missing.", "A_clean_title": ["multipl", "style", "tag", "header", "are", "render", "incorrectlyi", "incorrectli", "creat", "small", "quickstart", "basepag", "base", "page", "ha", "some", "multipl", "style", "tag", "onli", "he", "first", "one", "render", "correctli", "all", "follow", "render", "tag", "bodi", "onli", "surround", "style", "style", "miss"], "B_title": "render PageHeaderItems all at once", "B_clean_title": ["render", "pageheaderitem", "page", "header", "item", "all", "at", "onc"]},
{"A_title": "FLAG_INHERITABLE_MODEL and default model changeThe issue is about correctness of Component#setDefaultModel (Component#setModelImpl) method behavior. I expect that the flag FLAG_INHERITABLE_MODEL should be checked there and turned off in case if new model is not a IComponentInheritedModel.   Let check the next code: public MyPanel(String id)   super(id);   ...   form.setModel(new CompoundPropertyModel(this));   DropDownChoice ddc = new DropDownChoice(variant Arrays.ofList(...))     // p1     @Override     protected void onInitialize()         super.onInitialize();        setModel(new DefaultingWrapModel(getModel() Model.of(default value));            // p2        ;   ddc.setNullValid(false);   ddc.setRequired(true);   form.add(ddc);   ...   In the (p1) the DDC will initialize with CompoundPropertyModel and the FLAG_INHERITABLE_MODEL will be turned on soon by the first invocation of FormComponent#getModel().   In the (p2) we wrap the DDC model with the model which provide the default value (DefaultingWrapModel implements IWrapModel). So we change the model but the FLAG_INHERITABLE_MODEL is still turned on. On the Component#detach() event the method Component#setModelImpl(null) will be invoked for the ddc and the DefaultingWrapModel instance will be lost:  // reset the model to null when the current model is a IWrapModel and // the model that created it/wrapped in it is a IComponentInheritedModel // The model will be created next time. if (getFlag(FLAG_INHERITABLE_MODEL))  setModelImpl(null); setFlag(FLAG_INHERITABLE_MODEL false);   I think that such behavior is unexpected.  http://apache-wicket.1842946.n4.nabble.com/1-4-15-FLAG-INHERITABLE-MODEL-and-default-model-change-td3252093.html", "A_clean_title": ["flag", "inherit", "model", "default", "model", "changeth", "chang", "issu", "about", "correct", "compon", "setdefaultmodel", "set", "default", "model", "compon", "setmodelimpl", "set", "model", "impl", "method", "behavior", "expect", "that", "flag", "flag", "inherit", "model", "check", "there", "turn", "off", "case", "new", "model", "not", "icomponentinheritedmodel", "compon", "inherit", "model", "let", "check", "next", "code", "public", "mypanel", "my", "panel", "string", "id", "super", "id", "form", "setmodel", "set", "model", "new", "compoundpropertymodel", "compound", "properti", "model", "thi", "dropdownchoic", "drop", "down", "choic", "ddc", "new", "dropdownchoic", "drop", "down", "choic", "variant", "array", "oflist", "list", "p1", "overrid", "protect", "void", "oniniti", "initi", "super", "oniniti", "initi", "setmodel", "set", "model", "new", "defaultingwrapmodel", "default", "wrap", "model", "getmodel", "get", "model", "model", "default", "valu", "p2", "ddc", "setnullvalid", "set", "null", "valid", "fals", "ddc", "setrequir", "set", "requir", "true", "form", "add", "ddc", "p1", "ddc", "will", "initi", "compoundpropertymodel", "compound", "properti", "model", "flag", "inherit", "model", "will", "turn", "soon", "by", "first", "invoc", "formcompon", "form", "compon", "getmodel", "get", "model", "p2", "we", "wrap", "ddc", "model", "model", "which", "provid", "default", "valu", "defaultingwrapmodel", "default", "wrap", "model", "implement", "iwrapmodel", "wrap", "model", "so", "we", "chang", "model", "but", "flag", "inherit", "model", "still", "turn", "compon", "detach", "event", "method", "compon", "setmodelimpl", "set", "model", "impl", "null", "will", "invok", "ddc", "defaultingwrapmodel", "default", "wrap", "model", "instanc", "will", "lost", "reset", "model", "null", "when", "current", "model", "iwrapmodel", "wrap", "model", "model", "that", "creat", "it", "wrap", "it", "icomponentinheritedmodel", "compon", "inherit", "model", "model", "will", "creat", "next", "time", "getflag", "get", "flag", "flag", "inherit", "model", "setmodelimpl", "set", "model", "impl", "null", "setflag", "set", "flag", "flag", "inherit", "model", "fals", "think", "that", "such", "behavior", "unexpect", "http", "15", "flag", "inherit", "model", "default", "model", "chang", "apach", "wicket", "1842946", "n4", "nabbl", "td3252093", "html", "com"], "B_title": "FLAG_INHERITABLE_MODEL and default model change", "B_clean_title": ["flag", "inherit", "model", "default", "model", "chang"]},
{"A_title": "Partial.with fails with NPEFails with yearOfCentury year and yearOfEra. Probably because weekyear has a null range duration type.", "A_clean_title": ["partial", "fail", "npefail", "npe", "fail", "yearofcenturi", "year", "centuri", "year", "yearofera", "year", "era", "probabl", "becaus", "weekyear", "ha", "null", "rang", "durat", "type"], "B_title": "Fix NPE in Partial.with()", "B_clean_title": ["fix", "npe", "partial"]},
{"A_title": "GJChronology rejects valid Julian datesThe 2nd statement fails with org.joda.time.IllegalFieldValueException: Value 29 for dayOfMonth must be in the range 128.  Given that I left the cutover date at the default (October 15 1582) isnt 1500/02/29 a valid date in the GJChronology?", "A_clean_title": ["gjchronolog", "gj", "chronolog", "reject", "valid", "julian", "datesth", "date", "2nd", "statement", "fail", "org", "joda", "time", "illegalfieldvalueexcept", "illeg", "field", "valu", "except", "valu", "29", "dayofmonth", "day", "month", "must", "rang", "128", "given", "that", "left", "cutov", "date", "at", "default", "octob", "15", "1582", "isnt", "1500", "02", "29", "valid", "date", "gjchronolog", "gj", "chronolog"], "B_title": "Fix GJChronology to allow some leap year dates in JulianChronology to be created 3446915", "B_clean_title": ["fix", "gjchronolog", "gj", "chronolog", "allow", "some", "leap", "year", "date", "julianchronolog", "julian", "chronolog", "creat", "3446915"]},
{"A_title": "Allow KeySelectors to implement ResultTypeQueryableSee https://github.com/apache/flink/pull/354", "A_clean_title": ["allow", "keyselector", "key", "selector", "implement", "resulttypequeryablese", "result", "type", "queryabl", "see", "http", "github", "com", "apach", "flink", "pull", "354"], "B_title": "Fixes wrong input validation if function has no generics", "B_clean_title": ["fix", "wrong", "input", "valid", "function", "ha", "no", "gener"]},
{"A_title": "Node becomes invalid after Session#move()moving or renaming an existing (saved) node renders that node instance invalid and any access on that node instance will throw IllegalStateException.", "A_clean_title": ["node", "becom", "invalid", "after", "session", "move", "move", "or", "renam", "exist", "save", "node", "render", "that", "node", "instanc", "invalid", "ani", "access", "that", "node", "instanc", "will", "throw", "illegalstateexcept", "illeg", "state", "except"], "B_title": "Node becomes invalid after Session#move() throw invalid item state exception on disconnected nodes", "B_clean_title": ["node", "becom", "invalid", "after", "session", "move", "throw", "invalid", "item", "state", "except", "disconnect", "node"]},
{"A_title": "void function () (); wrongly identified as having no side effectsNone", "A_clean_title": ["void", "function", "wrongli", "identifi", "as", "have", "no", "side", "effectsnon", "effect", "none"], "B_title": "fix a mishandling of the void keyword also fix a bunch of apis fixes issue 504", "B_clean_title": ["fix", "mishandl", "void", "keyword", "also", "fix", "bunch", "api", "fix", "issu", "504"]},
{"A_title": "assignment to object in conditional causes type error on function w/ record type return typeNone", "A_clean_title": ["assign", "object", "condit", "caus", "type", "error", "function", "record", "type", "return", "typenon", "type", "none"], "B_title": "push reverse-inference into the type system fixes issue 669", "B_clean_title": ["push", "revers", "infer", "into", "type", "system", "fix", "issu", "669"]},
{"A_title": "Handling of semicolons in form action URLsWhat I expect to happen when there is no semicolon support in Wicket is that a URL in a form like below stays intact and will not be cut off at the position of the first semicolon:  <form action=http://localhost:8080/dor/abc_1234:56;023:456_def_78;90.html method=post><input type=submit value=Submit /></form>  In my application the part abc_1234:56;023:456_def_78;90.html is named1 in the mapping below:  mount(new MountedMapper(dor/#named1 TestPage.class new MyPageParametersEncoder()));  and parsed in MyPageParametersEncoder.  The officially intended use of semicolons in URLs seems to be specified in RFC 1808 - Relative Uniform Resource Locators 2.4.5. (http://www.faqs.org/rfcs/rfc1808.html). But that´s not what I´m looking for.  If I had not some pages running on this syntax I could easily swap the semicolon with another symbol. Nevertheless and if I´m correctly informed I think those URLs should not be cut off.  (Quotation from the mailing list)  The quickstart can be tested with the following URLs:  http://localhost:8080/dor/abc_1234:56;023:456_def_78;90.html http://localhost:8080/dor/abc_1234:56%3B023:456_def_78%3B90.html http://localhost:8080/dor/?abc=1234:56%3B023:456&def=78%3B90  The crucial part is the action attribute in the form in the page´s source code which contains i.e. ./abc_1234:56?-1.IFormSubmitListener-form.", "A_clean_title": ["handl", "semicolon", "form", "action", "urlswhat", "ur", "ls", "what", "expect", "happen", "when", "there", "no", "semicolon", "support", "wicket", "that", "url", "form", "like", "below", "stay", "intact", "will", "not", "cut", "off", "at", "posit", "first", "semicolon", "form", "action=http", "1234:56", "localhost:8080", "dor", "abc", "023:456", "def", "78", "90", "html", "method=post", "input", "type=submit", "value=submit", "form", "my", "applic", "part", "abc", "1234:56", "023:456", "def", "78", "90", "html", "named1", "map", "below", "mount", "new", "mountedmapp", "mount", "mapper", "dor", "named1", "testpag", "class", "test", "page", "new", "mypageparametersencod", "my", "page", "paramet", "encod", "pars", "mypageparametersencod", "my", "page", "paramet", "encod", "offici", "intend", "use", "semicolon", "url", "ur", "ls", "seem", "specifi", "rfc", "1808", "rel", "uniform", "resourc", "locat", "http", "faq", "html", "www", "org", "rfc", "rfc1808", "but", "that´", "not", "what", "i´m", "look", "had", "not", "some", "page", "run", "thi", "syntax", "could", "easili", "swap", "semicolon", "anoth", "symbol", "nevertheless", "i´m", "correctli", "inform", "think", "those", "url", "ur", "ls", "not", "cut", "off", "quotat", "mail", "list", "quickstart", "test", "follow", "url", "ur", "ls", "http", "1234:56", "localhost:8080", "dor", "abc", "023:456", "def", "78", "90", "html", "http", "1234:56", "localhost:8080", "dor", "abc", "3b023:456", "def", "78", "3b90", "html", "http", "localhost:8080", "dor", "abc=1234:56", "3b023:456", "def=78", "3b90", "crucial", "part", "action", "attribut", "form", "page´", "sourc", "code", "which", "contain", "1234:56", "abc", "form", "iformsubmitlisten", "form", "submit", "listen"], "B_title": "Handling of semicolons in form action URLs", "B_clean_title": ["handl", "semicolon", "form", "action", "url", "ur", "ls"]},
{"A_title": "Dequeueing problem when there is TransparentWebMarkupContainer around <wicket:child/>While testing 7.0.0-M1 release Ive found an issue with wicket-bootstraps sample application.  Here is a minified version of it that reproduces the problem. The two important things are: - a TransparentWebMarkupContainer (TWMC) is attached to <html> tag in the base page - the sub page is requested  It appears that dequeueing logic cannot find the closing tag of the TWMC and thinks that </wicket:child> is the closing tag.", "A_clean_title": ["dequeu", "problem", "when", "there", "transparentwebmarkupcontain", "transpar", "web", "markup", "contain", "around", "wicket", "child", "while", "test", "m1", "releas", "ive", "found", "issu", "wicket", "bootstrap", "sampl", "applic", "here", "minifi", "version", "it", "that", "reproduc", "problem", "two", "import", "thing", "are", "transparentwebmarkupcontain", "transpar", "web", "markup", "contain", "twmc", "attach", "html", "tag", "base", "page", "sub", "page", "request", "it", "appear", "that", "dequeu", "logic", "not", "find", "close", "tag", "twmc", "think", "that", "wicket", "child", "close", "tag"], "B_title": "Dequeueing problem when there is TransparentWebMarkupContainer around <wicket:child/>", "B_clean_title": ["dequeu", "problem", "when", "there", "transparentwebmarkupcontain", "transpar", "web", "markup", "contain", "around", "wicket", "child"]},
{"A_title": "FileInputFormat.addFilesInDir miscalculates total sizeIn FileInputFormat.addFilesInDir the length variable should start from 0 because the return value is always used by adding it to the length (instead of just assigning). So with the current version the length before the call will be seen twice in the result.  mvn verify caught this for me now. The reason why this hasnt been seen yet is because testGetStatisticsMultipleNestedFiles catches this only if it gets the listings of the outer directory in a certain order. Concretely if the inner directory is seen before the other file in the outer directory then length is 0 at that point so the bug doesnt show. But if the other file is seen first then its size is added twice to the total result.", "A_clean_title": ["fileinputformat", "addfilesindir", "file", "input", "format", "add", "file", "dir", "miscalcul", "total", "sizein", "size", "fileinputformat", "addfilesindir", "file", "input", "format", "add", "file", "dir", "length", "variabl", "start", "becaus", "return", "valu", "alway", "use", "by", "ad", "it", "length", "instead", "just", "assign", "so", "current", "version", "length", "befor", "call", "will", "seen", "twice", "result", "mvn", "verifi", "caught", "thi", "me", "now", "reason", "whi", "thi", "hasnt", "been", "seen", "yet", "becaus", "testgetstatisticsmultiplenestedfil", "test", "get", "statist", "multipl", "nest", "file", "catch", "thi", "onli", "it", "get", "list", "outer", "directori", "certain", "order", "concret", "inner", "directori", "seen", "befor", "other", "file", "outer", "directori", "then", "length", "at", "that", "point", "so", "bug", "doesnt", "show", "but", "other", "file", "seen", "first", "then", "it", "size", "ad", "twice", "total", "result"], "B_title": "Fix the recursive summation in FileInputFormat.addFilesInDir", "B_clean_title": ["fix", "recurs", "summat", "fileinputformat", "addfilesindir", "file", "input", "format", "add", "file", "dir"]},
{"A_title": "In stat.Frequency getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable)Drop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change Frequency.java    /**  Returns the percentage of values that are equal to v @deprecated replaced by  @link #getPct(Comparable)  as of 2.0      */     @Deprecated     public double getPct(Object v)           return getCumPct((Comparable<?>) v);", "A_clean_title": ["stat", "frequenc", "getpct", "get", "pct", "object", "use", "getcumpct", "get", "cum", "pct", "compar", "instead", "getpct", "get", "pct", "compar", "drop", "replac", "not", "possibl", "becaus", "all", "getpct", "get", "pct", "call", "will", "cummul", "without", "code", "chang", "frequenc", "java", "return", "percentag", "valu", "that", "are", "equal", "deprec", "replac", "by", "link", "getpct", "get", "pct", "compar", "as", "deprec", "public", "doubl", "getpct", "get", "pct", "object", "return", "getcumpct", "get", "cum", "pct", "compar"], "B_title": "Fixed regression in Frequency.getPct(Object) introduced in 2.0. Cumulative percent was being returned for Object arguments in place of percent.", "B_clean_title": ["fix", "regress", "frequenc", "getpct", "get", "pct", "object", "introduc", "cumul", "percent", "wa", "be", "return", "object", "argument", "place", "percent"]},
{"A_title": "Infinite recursion when deserializing a class extending a Map with a recursive value type.Hello I am using jackson-databind 2.8.8 and have a class with an unusual definition (extending a Map where the values are of the type of the same class). It seems like I am facing an infinite recursion issue.  To reproduce you can re-use or inspire from the class defined  here . Then when executing the following code:    When calling  readValue() the mapper throws a StackOverflowException  heres the stacktrace:  Looking briefly into the code it seems like because of the recursive definition of the class the  equals call in MapLikeType may never get out of this loop. Any idea? Thanks.", "A_clean_title": ["infinit", "recurs", "when", "deseri", "class", "extend", "map", "recurs", "valu", "type", "hello", "am", "jackson", "databind", "have", "class", "unusu", "definit", "extend", "map", "where", "valu", "are", "type", "same", "class", "it", "seem", "like", "am", "face", "infinit", "recurs", "issu", "reproduc", "you", "re", "use", "or", "inspir", "class", "defin", "here", "then", "when", "execut", "follow", "code", "when", "call", "readvalu", "read", "valu", "mapper", "throw", "stackoverflowexcept", "stack", "overflow", "except", "here", "stacktrac", "look", "briefli", "into", "code", "it", "seem", "like", "becaus", "recurs", "definit", "class", "equal", "call", "mapliketyp", "map", "like", "type", "may", "never", "get", "out", "thi", "loop", "ani", "idea", "thank"], "B_title": "Fix #1658", "B_clean_title": ["fix", "1658"]},
{"A_title": "EmptyNodeState.equals() brokenEmptyNodeState.equals() returns incorrect results when the other node state is not of type EmptyNodeState and the two states have differing exists() flags.", "A_clean_title": ["emptynodest", "equal", "empti", "node", "state", "brokenemptynodest", "equal", "broken", "empti", "node", "state", "return", "incorrect", "result", "when", "other", "node", "state", "not", "type", "emptynodest", "empti", "node", "state", "two", "state", "have", "differ", "exist", "flag"], "B_title": "EmptyNodeState.equals() broken", "B_clean_title": ["emptynodest", "equal", "empti", "node", "state", "broken"]},
{"A_title": "WicketTester does not follow absolute redirectsWicket tester does not follow absolute redirects:  This is a problem when using HttpsMapper. For example when requesting a page over http:// with an forced redirect to https:// for secure access will make wicket tester return null for the last renderer page instead of the rendered page instance. In general all kinds of absolute redirects to another page will not be tracked by wicket tester. So this potentially a problem for all kinds of tests that rely on absolute redirects.", "A_clean_title": ["wickettest", "wicket", "tester", "not", "follow", "absolut", "redirectswicket", "redirect", "wicket", "tester", "not", "follow", "absolut", "redirect", "thi", "problem", "when", "httpsmapper", "http", "mapper", "exampl", "when", "request", "page", "over", "http", "forc", "redirect", "http", "secur", "access", "will", "make", "wicket", "tester", "return", "null", "last", "render", "page", "instead", "render", "page", "instanc", "gener", "all", "kind", "absolut", "redirect", "anoth", "page", "will", "not", "track", "by", "wicket", "tester", "so", "thi", "potenti", "problem", "all", "kind", "test", "that", "reli", "absolut", "redirect"], "B_title": "WicketTester does not follow absolute redirects: make Url.parse(..) capable of parsing absolute urls", "B_clean_title": ["wickettest", "wicket", "tester", "not", "follow", "absolut", "redirect", "make", "url", "pars", "capabl", "pars", "absolut", "url"]},
{"A_title": "Questionable behaviour of GJChronology when dates pass 1BCI expect the following test to pass:  However I never provided 0 for the year myself. I thought it was the job of the framework to skip over non-existent year 0 for me to return 1 BC?", "A_clean_title": ["question", "behaviour", "gjchronolog", "gj", "chronolog", "when", "date", "pass", "1bci", "expect", "follow", "test", "pass", "howev", "never", "provid", "year", "myself", "thought", "it", "wa", "job", "framework", "skip", "over", "non", "exist", "year", "me", "return", "bc"], "B_title": "Fix GJChronology.plus/minus across cutover and year zero", "B_clean_title": ["fix", "gjchronolog", "gj", "chronolog", "plu", "minu", "across", "cutov", "year", "zero"]},
{"A_title": "FastDateFormat formats year differently than SimpleDateFormat in Java 7Starting with Java 7 does SimpleDateFormat format a year pattern of Y or YYY as 2003 instead of 03 as in former Java releases. According Javadoc this pattern should have been always been formatted as number therefore the new behavior seems to be a bug fix in the JDK. FastDateFormat is adjusted to behave the same.", "A_clean_title": ["fastdateformat", "fast", "date", "format", "format", "year", "differ", "than", "simpledateformat", "simpl", "date", "format", "java", "7start", "java", "simpledateformat", "simpl", "date", "format", "format", "year", "pattern", "or", "yyy", "as", "2003", "instead", "03", "as", "former", "java", "releas", "accord", "javadoc", "thi", "pattern", "have", "been", "alway", "been", "format", "as", "number", "therefor", "new", "behavior", "seem", "bug", "fix", "jdk", "fastdateformat", "fast", "date", "format", "adjust", "behav", "same"], "B_title": "Adjust FastDateFormat for Java 7 behavior regarding format of the year pattern (LANG-719).", "B_clean_title": ["adjust", "fastdateformat", "fast", "date", "format", "java", "behavior", "regard", "format", "year", "pattern", "lang", "719"]},
{"A_title": "ClassCastException when requesting for non-page classorg.apache.wicket.request.mapper.BookmarkableMapper tries to instantiate Page even for classes which are not Page. Requesting http://localhost:8080/wicket/bookmarkable/com.mycompany.Pojo fails with:  ERROR - DefaultExceptionMapper     - Unexpected error occurred java.lang.ClassCastException: com.mycompany.Pojo at org.apache.wicket.session.DefaultPageFactory.newPage(DefaultPageFactory.java:155) at org.apache.wicket.session.DefaultPageFactory.newPage(DefaultPageFactory.java:59) at org.apache.wicket.session.DefaultPageFactory.newPage(DefaultPageFactory.java:43) at org.apache.wicket.Application 2.newPageInstance(Application.java:1425) at org.apache.wicket.request.handler.PageProvider.getPageInstance(PageProvider.java:259) at org.apache.wicket.request.handler.PageProvider.getPageInstance(PageProvider.java:160) at org.apache.wicket.request.handler.render.WebPageRenderer.getPage(WebPageRenderer.java:59) at org.apache.wicket.request.handler.render.WebPageRenderer.renderPage(WebPageRenderer.java:131) at org.apache.wicket.request.handler.render.WebPageRenderer.respond(WebPageRenderer.java:232) at org.apache.wicket.request.handler.RenderPageRequestHandler.respond(RenderPageRequestHandler.java:147) at org.apache.wicket.request.RequestHandlerStack.executeRequestHandler(RequestHandlerStack.java:84) at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:217) at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:253) at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:135) at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:188) at org.mortbay.jetty.servlet.ServletHandler CachedChain.doFilter(ServletHandler.java:1157)          .....", "A_clean_title": ["classcastexcept", "class", "cast", "except", "when", "request", "non", "page", "classorg", "apach", "wicket", "request", "mapper", "bookmarkablemapp", "bookmark", "mapper", "tri", "instanti", "page", "even", "class", "which", "are", "not", "page", "request", "http", "mycompani", "pojo", "localhost:8080", "wicket", "bookmark", "com", "fail", "error", "defaultexceptionmapp", "default", "except", "mapper", "unexpect", "error", "occur", "java", "lang", "classcastexcept", "class", "cast", "except", "com", "mycompani", "pojo", "at", "org", "apach", "wicket", "session", "defaultpagefactori", "newpag", "default", "page", "factori", "new", "page", "defaultpagefactori", "java:155", "default", "page", "factori", "at", "org", "apach", "wicket", "session", "defaultpagefactori", "newpag", "default", "page", "factori", "new", "page", "defaultpagefactori", "java:59", "default", "page", "factori", "at", "org", "apach", "wicket", "session", "defaultpagefactori", "newpag", "default", "page", "factori", "new", "page", "defaultpagefactori", "java:43", "default", "page", "factori", "at", "org", "apach", "wicket", "applic", "newpageinst", "new", "page", "instanc", "applic", "java:1425", "at", "org", "apach", "wicket", "request", "handler", "pageprovid", "getpageinst", "page", "provid", "get", "page", "instanc", "pageprovid", "java:259", "page", "provid", "at", "org", "apach", "wicket", "request", "handler", "pageprovid", "getpageinst", "page", "provid", "get", "page", "instanc", "pageprovid", "java:160", "page", "provid", "at", "org", "apach", "wicket", "request", "handler", "render", "webpagerender", "getpag", "web", "page", "render", "get", "page", "webpagerender", "java:59", "web", "page", "render", "at", "org", "apach", "wicket", "request", "handler", "render", "webpagerender", "renderpag", "web", "page", "render", "render", "page", "webpagerender", "java:131", "web", "page", "render", "at", "org", "apach", "wicket", "request", "handler", "render", "webpagerender", "respond", "web", "page", "render", "webpagerender", "java:232", "web", "page", "render", "at", "org", "apach", "wicket", "request", "handler", "renderpagerequesthandl", "respond", "render", "page", "request", "handler", "renderpagerequesthandl", "java:147", "render", "page", "request", "handler", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "executerequesthandl", "request", "handler", "stack", "execut", "request", "handler", "requesthandlerstack", "java:84", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:217", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:253", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:135", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:188", "wicket", "filter", "at", "org", "mortbay", "jetti", "servlet", "servlethandl", "servlet", "handler", "cachedchain", "dofilt", "cach", "chain", "filter", "servlethandl", "java:1157", "servlet", "handler"], "B_title": "ClassCastException when requesting for non-page class", "B_clean_title": ["classcastexcept", "class", "cast", "except", "when", "request", "non", "page", "class"]},
{"A_title": "Make sure iterators handle deletion entries properlyIn minor compaction scope and in non-full major compaction scopes the iterator may see deletion entries. These entries should be preserved by all iterators except ones that are strictly scan-time iterators that will never be configured for the minc or majc scopes. Deletion entries are only removed during full major compactions.", "A_clean_title": ["make", "sure", "iter", "handl", "delet", "entri", "properlyin", "properli", "minor", "compact", "scope", "non", "full", "major", "compact", "scope", "iter", "may", "see", "delet", "entri", "these", "entri", "preserv", "by", "all", "iter", "except", "one", "that", "are", "strictli", "scan", "time", "iter", "that", "will", "never", "configur", "minc", "or", "majc", "scope", "delet", "entri", "are", "onli", "remov", "dure", "full", "major", "compact"], "B_title": "expanded javadocs and added deletion handling to Filter", "B_clean_title": ["expand", "javadoc", "ad", "delet", "handl", "filter"]},
{"A_title": "StatUtils.sum returns NaN for zero-length arraysStatUtils.sum returns NaN for zero-length arrays which is:  1. inconsistent with the mathematical notion of sum: in maths sum_i=0^N-1 a_i will be 0 for N=0. In particular the identity  sum_i=0^k-1 a_i + sum_i=k^N-1 = sum_i=0^N-1  is broken for k = 0 since NaN + x = NaN not x.  2. introduces hard to debug erros (returning a NaN is one of the worst forms of reporting an exceptional condition as NaNs propagate silently and require manual tracing during the debugging)  3. enforces special case handling when the user expects that the summed array can have a zero length.  The correct behaviour is in my opinion to return 0.0 not NaN in the above case.", "A_clean_title": ["statutil", "sum", "stat", "util", "return", "nan", "na", "zero", "length", "arraysstatutil", "sum", "array", "stat", "util", "return", "nan", "na", "zero", "length", "array", "which", "inconsist", "mathemat", "notion", "sum", "math", "sum", "i=0^n", "will", "n=0", "particular", "ident", "sum", "i=0^k", "sum", "i=k^n", "sum", "i=0^n", "broken", "sinc", "nan", "na", "nan", "na", "not", "introduc", "hard", "debug", "erro", "return", "nan", "na", "one", "worst", "form", "report", "except", "condit", "as", "nan", "na", "ns", "propag", "silent", "requir", "manual", "trace", "dure", "debug", "enforc", "special", "case", "handl", "when", "user", "expect", "that", "sum", "array", "have", "zero", "length", "correct", "behaviour", "my", "opinion", "return", "not", "nan", "na", "abov", "case"], "B_title": "Change the default value for those UnivariateStatistics that have a conventional value on the empty set. JIRA: MATH-373", "B_clean_title": ["chang", "default", "valu", "those", "univariatestatist", "univari", "statist", "that", "have", "convent", "valu", "empti", "set", "jira", "math", "373"]},
{"A_title": "Inconsistency in Node#setProperty in case of null valueSetting a null value to a single valued property will result in null being returned while executing the same on a multivalued property will return the removed property.  jr2 returned the removed property in both cases as far as i  remember and i would suggest that we dont change that behavior. in particular since the specification IMO doesnt allow to return null-values for these methods.", "A_clean_title": ["inconsist", "node", "setproperti", "set", "properti", "case", "null", "valueset", "valu", "set", "null", "valu", "singl", "valu", "properti", "will", "result", "null", "be", "return", "while", "execut", "same", "multivalu", "properti", "will", "return", "remov", "properti", "jr2", "return", "remov", "properti", "both", "case", "as", "far", "as", "rememb", "would", "suggest", "that", "we", "dont", "chang", "that", "behavior", "particular", "sinc", "specif", "imo", "doesnt", "allow", "return", "null", "valu", "these", "method"], "B_title": "Inconsistency in Node#setProperty in case of null value - return a Property instance at the location where the property was removed - updated tests in CRUDTest accordingly", "B_clean_title": ["inconsist", "node", "setproperti", "set", "properti", "case", "null", "valu", "return", "properti", "instanc", "at", "locat", "where", "properti", "wa", "remov", "updat", "test", "crudtest", "crud", "test", "accordingli"]},
{"A_title": "Constructor of PolyhedronsSet throws NullPointerExceptionThe following statement throws a NullPointerException: new org.apache.commons.math3.geometry.euclidean.threed.PolyhedronsSet(0.0d 0.0d 0.0d 0.0d 0.0d 0.0d);  I found that other numbers also produce that effect. The stack trace: java.lang.NullPointerException         at org.apache.commons.math3.geometry.partitioning.BSPTree.fitToCell(BSPTree.java:297)         at org.apache.commons.math3.geometry.partitioning.BSPTree.insertCut(BSPTree.java:155)         at org.apache.commons.math3.geometry.partitioning.RegionFactory.buildConvex(RegionFactory.java:55)         at org.apache.commons.math3.geometry.euclidean.threed.PolyhedronsSet.buildBoundary(PolyhedronsSet.java:119)         at org.apache.commons.math3.geometry.euclidean.threed.PolyhedronsSet.<init>(PolyhedronsSet.java:97)", "A_clean_title": ["constructor", "polyhedronsset", "polyhedron", "set", "throw", "nullpointerexceptionth", "null", "pointer", "except", "follow", "statement", "throw", "nullpointerexcept", "null", "pointer", "except", "new", "org", "apach", "common", "math3", "geometri", "euclidean", "threed", "polyhedronsset", "polyhedron", "set", "0d", "0d", "0d", "0d", "0d", "0d", "found", "that", "other", "number", "also", "produc", "that", "effect", "stack", "trace", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "common", "math3", "geometri", "partit", "bsptree", "fittocel", "bsp", "tree", "fit", "cell", "bsptree", "java:297", "bsp", "tree", "at", "org", "apach", "common", "math3", "geometri", "partit", "bsptree", "insertcut", "bsp", "tree", "insert", "cut", "bsptree", "java:155", "bsp", "tree", "at", "org", "apach", "common", "math3", "geometri", "partit", "regionfactori", "buildconvex", "region", "factori", "build", "convex", "regionfactori", "java:55", "region", "factori", "at", "org", "apach", "common", "math3", "geometri", "euclidean", "threed", "polyhedronsset", "buildboundari", "polyhedron", "set", "build", "boundari", "polyhedronsset", "java:119", "polyhedron", "set", "at", "org", "apach", "common", "math3", "geometri", "euclidean", "threed", "polyhedronsset", "polyhedron", "set", "init", "polyhedronsset", "java:97", "polyhedron", "set"], "B_title": "Build empty polyhedrons set when given equal min/max boundaries.", "B_clean_title": ["build", "empti", "polyhedron", "set", "when", "given", "equal", "min", "max", "boundari"]},
{"A_title": "IResponseFilter doesnt work in 1.5In current 1.5-SNAPSHOT there are no callers of org.apache.wicket.settings.IRequestCycleSettings.getResponseFilters() and thus filters are never executed.", "A_clean_title": ["iresponsefilt", "respons", "filter", "doesnt", "work", "5in", "current", "snapshot", "there", "are", "no", "caller", "org", "apach", "wicket", "set", "irequestcycleset", "getresponsefilt", "request", "cycl", "set", "get", "respons", "filter", "thu", "filter", "are", "never", "execut"], "B_title": "IResponseFilter doesnt work in 1.5", "B_clean_title": ["iresponsefilt", "respons", "filter", "doesnt", "work"]},
{"A_title": "NPE in MarkSweepGarbageCollector.saveBatchToFile during Datastore GC with FileDataStoreDuring running a datastore garbage collection on a Jackrabbit 2 FileDataStore (org.apache.jackrabbit.oak.plugins.blob.datastore.FileDataStore see http://jackrabbit.apache.org/oak/docs/osgi_config.html) an NPE is thrown code 13.05.2014 17:50:16.944 *ERROR* qtp1416657193-147 org.apache.jackrabbit.oak.management.ManagementOperation Blob garbage collection failed java.lang.RuntimeException: Error in retrieving references at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector 1.addReference(MarkSweepGarbageCollector.java:395) at org.apache.jackrabbit.oak.plugins.segment.Segment.collectBlobReferences(Segment.java:248) at org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.collectBlobReferences(SegmentTracker.java:178) at org.apache.jackrabbit.oak.plugins.segment.SegmentBlobReferenceRetriever.collectReferences(SegmentBlobReferenceRetriever.java:38) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector.iterateNodeTree(MarkSweepGarbageCollector.java:361) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector.mark(MarkSweepGarbageCollector.java:201) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector.markAndSweep(MarkSweepGarbageCollector.java:173) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector.collectGarbage(MarkSweepGarbageCollector.java:149) at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService 2.collectGarbage(SegmentNodeStoreService.java:185) at org.apache.jackrabbit.oak.plugins.blob.BlobGC 1.call(BlobGC.java:68) at org.apache.jackrabbit.oak.plugins.blob.BlobGC 1.call(BlobGC.java:64) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.NullPointerException: null at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:192) at com.google.common.base.Joiner.toString(Joiner.java:436) at com.google.common.base.Joiner.appendTo(Joiner.java:108) at com.google.common.base.Joiner.appendTo(Joiner.java:152) at com.google.common.base.Joiner.join(Joiner.java:193) at com.google.common.base.Joiner.join(Joiner.java:183) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector.saveBatchToFile(MarkSweepGarbageCollector.java:317) at org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector 1.addReference(MarkSweepGarbageCollector.java:391) ... 14 common frames omitted code  Attached you find the OSGi config for both the nodestore and the datastore.", "A_clean_title": ["npe", "marksweepgarbagecollector", "savebatchtofil", "mark", "sweep", "garbag", "collector", "save", "batch", "file", "dure", "datastor", "gc", "filedatastoredur", "file", "data", "store", "dure", "run", "datastor", "garbag", "collect", "jackrabbit", "filedatastor", "file", "data", "store", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "datastor", "filedatastor", "file", "data", "store", "see", "http", "apach", "html", "jackrabbit", "config", "org", "oak", "doc", "osgi", "npe", "thrown", "code", "13", "05", "2014", "17:50:16", "944", "error", "qtp1416657193", "147", "org", "apach", "jackrabbit", "oak", "manag", "managementoper", "manag", "oper", "blob", "garbag", "collect", "fail", "java", "lang", "runtimeexcept", "runtim", "except", "error", "retriev", "refer", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "mark", "sweep", "garbag", "collector", "addrefer", "add", "refer", "marksweepgarbagecollector", "java:395", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segment", "collectblobrefer", "collect", "blob", "refer", "segment", "java:248", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmenttrack", "collectblobrefer", "segment", "tracker", "collect", "blob", "refer", "segmenttrack", "java:178", "segment", "tracker", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentblobreferenceretriev", "collectrefer", "segment", "blob", "refer", "retriev", "collect", "refer", "segmentblobreferenceretriev", "java:38", "segment", "blob", "refer", "retriev", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "iteratenodetre", "mark", "sweep", "garbag", "collector", "iter", "node", "tree", "marksweepgarbagecollector", "java:361", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "mark", "mark", "sweep", "garbag", "collector", "marksweepgarbagecollector", "java:201", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "markandsweep", "mark", "sweep", "garbag", "collector", "mark", "sweep", "marksweepgarbagecollector", "java:173", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "collectgarbag", "mark", "sweep", "garbag", "collector", "collect", "garbag", "marksweepgarbagecollector", "java:149", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodestoreservic", "segment", "node", "store", "servic", "collectgarbag", "collect", "garbag", "segmentnodestoreservic", "java:185", "segment", "node", "store", "servic", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "blobgc", "blob", "gc", "call", "blobgc", "java:68", "blob", "gc", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "blobgc", "blob", "gc", "call", "blobgc", "java:64", "blob", "gc", "at", "java", "util", "concurr", "futuretask", "run", "futur", "task", "futuretask", "java:262", "futur", "task", "at", "java", "util", "concurr", "threadpoolexecutor", "runwork", "thread", "pool", "executor", "run", "worker", "threadpoolexecutor", "java:1145", "thread", "pool", "executor", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:615", "thread", "pool", "executor", "at", "java", "lang", "thread", "run", "thread", "java:745", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "null", "at", "com", "googl", "common", "base", "precondit", "checknotnul", "check", "not", "null", "precondit", "java:192", "at", "com", "googl", "common", "base", "joiner", "tostr", "string", "joiner", "java:436", "at", "com", "googl", "common", "base", "joiner", "appendto", "append", "joiner", "java:108", "at", "com", "googl", "common", "base", "joiner", "appendto", "append", "joiner", "java:152", "at", "com", "googl", "common", "base", "joiner", "join", "joiner", "java:193", "at", "com", "googl", "common", "base", "joiner", "join", "joiner", "java:183", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "savebatchtofil", "mark", "sweep", "garbag", "collector", "save", "batch", "file", "marksweepgarbagecollector", "java:317", "mark", "sweep", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "blob", "marksweepgarbagecollector", "mark", "sweep", "garbag", "collector", "addrefer", "add", "refer", "marksweepgarbagecollector", "java:391", "mark", "sweep", "garbag", "collector", "14", "common", "frame", "omit", "code", "attach", "you", "find", "osgi", "os", "gi", "config", "both", "nodestor", "datastor"], "B_title": "NPE in MarkSweepGarbageCollector.saveBatchToFile during Datastore GC with FileDataStore", "B_clean_title": ["npe", "marksweepgarbagecollector", "savebatchtofil", "mark", "sweep", "garbag", "collector", "save", "batch", "file", "dure", "datastor", "gc", "filedatastor", "file", "data", "store"]},
{"A_title": "Reproduceable crash with switch statementNone", "A_clean_title": ["reproduc", "crash", "switch", "statementnon", "statement", "none"], "B_title": "Dont remove nodes out of traversal order. Fixes issue 311.", "B_clean_title": ["dont", "remov", "node", "out", "travers", "order", "fix", "issu", "311"]},
{"A_title": "numerical problems in rotation creationbuilding a rotation from the following vector pairs leads to NaN: u1 = -4921140.837095533 -2.1512094250440013E7 -890093.279426377 u2 = -2.7238580938724895E9 -2.169664921341876E9 6.749688708885301E10 v1 = 1 0 0 v2 = 0 0 1 The constructor first changes the (v1 v2) pair into (v1 v2) ensuring the following scalar products hold:  <v1|v1> == <u1|u1>  <v2|v2> == <u2|u2>  <u1 |u2>  == <v1|v2> Once the (v1 v2) pair has been computed we compute the cross product:   k = (v1 - u1)^(v2 - u2) and the scalar product:   c = <k | (u1^u2)> By construction c is positive or null and the quaternion axis we want to build is q = k/2*sqrt(c). c should be null only if some of the vectors are aligned and this is dealt with later in the algorithm. However there are numerical problems with the vector above with the way these computations are done as shown by the following comparisons showing the result we get from our Java code and the result we get from manual computation with the same formulas but with enhanced precision: commons math:   k = 38514476.5            -84.                           -1168590144 high precision: k = 38514410.36093388...  -0.374075245201180409222711... -1168590152.10599715208... and it becomes worse when computing c because the vectors are almost orthogonal to each other hence inducing additional cancellations. We get: commons math    c = -1.2397173627587605E20 high precision: c =  558382746168463196.7079627... We have lost ALL significant digits in cancellations and even the sign is wrong!", "A_clean_title": ["numer", "problem", "rotat", "creationbuild", "rotat", "follow", "vector", "pair", "lead", "nan", "na", "u1", "4921140", "837095533", "1512094250440013e7", "890093", "279426377", "u2", "7238580938724895e9", "169664921341876e9", "749688708885301e10", "v1", "v2", "constructor", "first", "chang", "v1", "v2", "pair", "into", "v1", "v2", "ensur", "follow", "scalar", "product", "hold", "v1|v1", "u1|u1", "v2|v2", "u2|u2", "u1", "|u2", "v1|v2", "onc", "v1", "v2", "pair", "ha", "been", "comput", "we", "comput", "cross", "product", "v1", "u1", "v2", "u2", "scalar", "product", "u1^u2", "by", "construct", "posit", "or", "null", "quaternion", "axi", "we", "want", "build", "sqrt", "null", "onli", "some", "vector", "are", "align", "thi", "dealt", "later", "algorithm", "howev", "there", "are", "numer", "problem", "vector", "abov", "way", "these", "comput", "are", "done", "as", "shown", "by", "follow", "comparison", "show", "result", "we", "get", "our", "java", "code", "result", "we", "get", "manual", "comput", "same", "formula", "but", "enhanc", "precis", "common", "math", "38514476", "84", "1168590144", "high", "precis", "38514410", "36093388", "374075245201180409222711", "1168590152", "10599715208", "it", "becom", "wors", "when", "comput", "becaus", "vector", "are", "almost", "orthogon", "each", "other", "henc", "induc", "addit", "cancel", "we", "get", "common", "math", "2397173627587605e20", "high", "precis", "558382746168463196", "7079627", "we", "have", "lost", "all", "signific", "digit", "cancel", "even", "sign", "wrong"], "B_title": "Fixed a wrong detection of rotation axis versus vectors plane in Rotation constructor using two vectors pairs.", "B_clean_title": ["fix", "wrong", "detect", "rotat", "axi", "versu", "vector", "plane", "rotat", "constructor", "two", "vector", "pair"]},
{"A_title": "Cross foreign cluster revision comparison may be wrongRunning one of the access control related benchmarks concurrently on a MongoDB may result in strange conflicts even when DocumentNodeStore retries the commit. The root cause may be a wrong revision comparison when both revision to compare are from a foreign cluster node and one of them is not withing the known seen-at revision ranges.", "A_clean_title": ["cross", "foreign", "cluster", "revis", "comparison", "may", "wrongrun", "wrong", "run", "one", "access", "control", "relat", "benchmark", "concurr", "mongodb", "mongo", "db", "may", "result", "strang", "conflict", "even", "when", "documentnodestor", "document", "node", "store", "retri", "commit", "root", "caus", "may", "wrong", "revis", "comparison", "when", "both", "revis", "compar", "are", "foreign", "cluster", "node", "one", "them", "not", "with", "known", "seen", "at", "revis", "rang"], "B_title": "Cross foreign cluster revision comparison may be wrong", "B_clean_title": ["cross", "foreign", "cluster", "revis", "comparison", "may", "wrong"]},
{"A_title": "Background update may create journal entry with incorrect idThe conflict check does not consider changes that are made visible between the rebase and the background read.", "A_clean_title": ["background", "updat", "may", "creat", "journal", "entri", "incorrect", "idth", "id", "conflict", "check", "not", "consid", "chang", "that", "are", "made", "visibl", "between", "rebas", "background", "read"], "B_title": "Commit does not detect conflict when background read happens after rebase", "B_clean_title": ["commit", "not", "detect", "conflict", "when", "background", "read", "happen", "after", "rebas"]},
{"A_title": "ListenerInterfaceRequestHandler#respond throws ComponentNotFoundException as a side-effectThe following exception occurs instead of a generic WicketRuntimeException:  16:27:56.181 WARN  (RequestCycle.java:343) Handling the following exception qtp9826071-207 org.apache.wicket.core.request.handler.ComponentNotFoundException: Could not find component xyz on page class MyPage’        at org.apache.wicket.core.request.handler.PageAndComponentProvider.getComponent(PageAndComponentProvider.java:182) ~org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.core.request.handler.ListenerInterfaceRequestHandler.getComponent(ListenerInterfaceRequestHandler.java:90) ~org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.core.request.handler.ListenerInterfaceRequestHandler.respond(ListenerInterfaceRequestHandler.java:231) ~org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.request.cycle.RequestCycle HandlerExecutor.respond(RequestCycle.java:861) ~org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:64) ~org.apache.wicket.request_6.12.0.jar:6.12.0        at org.apache.wicket.request.cycle.RequestCycle.execute(RequestCycle.java:261) org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:218) org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:289) org.apache.wicket.core_6.12.0.jar:6.12.0        at org.apache.wicket.protocol.http.WicketFilter.processRequestCycle(WicketFilter.java:259) org.apache.wicket.core_6.12.0.jar:6.12.0  in fact this is a side effect if you look at the code:         @Override        public void respond(final IRequestCycle requestCycle)                      final IRequestablePage page = getPage();              final boolean freshPage = pageComponentProvider.isPageInstanceFresh();              final boolean isAjax = ((WebRequest)requestCycle.getRequest()).isAjax();              IRequestableComponent component = null;              try                                   component = getComponent();                            catch (ComponentNotFoundException e)                                   // either the page is stateless and the component we are looking for is not added in the                     // constructor                     // or the page is stateful+stale and a new instances was created by pageprovider                     // we denote this by setting component to null                     component = null;                            if ((component == null && freshPage) ||                      (component != null && getComponent().getPage() == page))                             ....                             else                                     throw new WicketRuntimeException(Component  + getComponent() +                             has been removed from page.);                          You see that getComponent() is called twice.  1) Once guarded by a catch   - and - 2) once unguarded  So if the component cant be found AND freshPage is false as a sideeffect instead of the WicketRuntimeException with the removed message a componentnotfound exception is raised as a side effect.  I see two possible solutions for this  a) either it is intentional that a ComponentNotFoundException is thrown then it should be thrown from the catch block like               catch (ComponentNotFoundException e)                                   if (!freshPage)                         throw e;                                     b) if it is unintentionall in the else case ther should be a simple check like this   if (component == null)                          throw new WicketRuntimeException(Component for path  + getPath() +                            and page +page.getClass().getName()+ has been removed from page.);                      else                         throw new WicketRuntimeException(Component  + component +                            has been removed from page.);                        Beside this: it would be a good idea to mention at least the page class in either case.", "A_clean_title": ["listenerinterfacerequesthandl", "listen", "interfac", "request", "handler", "respond", "throw", "componentnotfoundexcept", "compon", "not", "found", "except", "as", "side", "effectth", "effect", "follow", "except", "occur", "instead", "gener", "wicketruntimeexcept", "wicket", "runtim", "except", "16:27:56", "181", "warn", "requestcycl", "java:343", "request", "cycl", "handl", "follow", "except", "qtp9826071", "207", "org", "apach", "wicket", "core", "request", "handler", "componentnotfoundexcept", "compon", "not", "found", "except", "could", "not", "find", "compon", "xyz", "page", "class", "mypag", "my", "page", "at", "org", "apach", "wicket", "core", "request", "handler", "pageandcomponentprovid", "getcompon", "page", "compon", "provid", "get", "compon", "pageandcomponentprovid", "java:182", "page", "compon", "provid", "~org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "core", "request", "handler", "listenerinterfacerequesthandl", "getcompon", "listen", "interfac", "request", "handler", "get", "compon", "listenerinterfacerequesthandl", "java:90", "listen", "interfac", "request", "handler", "~org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "core", "request", "handler", "listenerinterfacerequesthandl", "respond", "listen", "interfac", "request", "handler", "listenerinterfacerequesthandl", "java:231", "listen", "interfac", "request", "handler", "~org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "request", "cycl", "handlerexecutor", "respond", "handler", "executor", "requestcycl", "java:861", "request", "cycl", "~org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:64", "request", "handler", "stack", "~org", "apach", "wicket", "12", "jar:6", "12", "request", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "execut", "request", "cycl", "requestcycl", "java:261", "request", "cycl", "org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:218", "request", "cycl", "org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:289", "request", "cycl", "org", "apach", "wicket", "12", "jar:6", "12", "core", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequestcycl", "wicket", "filter", "process", "request", "cycl", "wicketfilt", "java:259", "wicket", "filter", "org", "apach", "wicket", "12", "jar:6", "12", "core", "fact", "thi", "side", "effect", "you", "look", "at", "code", "overrid", "public", "void", "respond", "final", "irequestcycl", "request", "cycl", "requestcycl", "request", "cycl", "final", "irequestablepag", "request", "page", "page", "getpag", "get", "page", "final", "boolean", "freshpag", "fresh", "page", "pagecomponentprovid", "ispageinstancefresh", "page", "compon", "provid", "page", "instanc", "fresh", "final", "boolean", "isajax", "ajax", "webrequest", "web", "request", "requestcycl", "getrequest", "request", "cycl", "get", "request", "isajax", "ajax", "irequestablecompon", "request", "compon", "compon", "null", "tri", "compon", "getcompon", "get", "compon", "catch", "componentnotfoundexcept", "compon", "not", "found", "except", "either", "page", "stateless", "compon", "we", "are", "look", "not", "ad", "constructor", "or", "page", "stateful+stal", "new", "instanc", "wa", "creat", "by", "pageprovid", "we", "denot", "thi", "by", "set", "compon", "null", "compon", "null", "compon", "null", "freshpag", "fresh", "page", "compon", "null", "getcompon", "get", "compon", "getpag", "get", "page", "page", "throw", "new", "wicketruntimeexcept", "wicket", "runtim", "except", "compon", "getcompon", "get", "compon", "ha", "been", "remov", "page", "you", "see", "that", "getcompon", "get", "compon", "call", "twice", "onc", "guard", "by", "catch", "onc", "unguard", "so", "compon", "cant", "found", "freshpag", "fresh", "page", "fals", "as", "sideeffect", "instead", "wicketruntimeexcept", "wicket", "runtim", "except", "remov", "messag", "componentnotfound", "except", "rais", "as", "side", "effect", "see", "two", "possibl", "solut", "thi", "either", "it", "intent", "that", "componentnotfoundexcept", "compon", "not", "found", "except", "thrown", "then", "it", "thrown", "catch", "block", "like", "catch", "componentnotfoundexcept", "compon", "not", "found", "except", "freshpag", "fresh", "page", "throw", "it", "unintentional", "case", "ther", "simpl", "check", "like", "thi", "compon", "null", "throw", "new", "wicketruntimeexcept", "wicket", "runtim", "except", "compon", "path", "getpath", "get", "path", "page", "+page", "getclass", "get", "class", "getnam", "get", "name", "ha", "been", "remov", "page", "throw", "new", "wicketruntimeexcept", "wicket", "runtim", "except", "compon", "compon", "ha", "been", "remov", "page", "besid", "thi", "it", "would", "good", "idea", "mention", "at", "least", "page", "class", "either", "case"], "B_title": "watch out for null component; break early from method", "B_clean_title": ["watch", "out", "null", "compon", "break", "earli", "method"]},
{"A_title": "NullPointerException in vertex-centric iterationHello to my Squirrels  I came across this exception when having a vertex-centric iteration output followed by a group by.  Im not sure if what is causing it since I saw this error in a rather large pipeline but I managed to reproduce it with this code example | https://github.com/vasia/flink/commit/1b7bbca1a6130fbcfe98b4b9b43967eb4c61f309 and a sufficiently large dataset e.g. this one | http://snap.stanford.edu/data/com-DBLP.html (Im running this locally). It seems like a null Buffer in RecordWriter.  The exception message is the following:  Exception in thread main org.apache.flink.runtime.client.JobExecutionException: Job execution failed. at org.apache.flink.runtime.jobmanager.JobManager anonfun receiveWithLogMessages 1.applyOrElse(JobManager.scala:319) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.ActorLogMessages anon 1.apply(ActorLogMessages.scala:37) at org.apache.flink.runtime.ActorLogMessages anon 1.apply(ActorLogMessages.scala:30) at scala.PartialFunction class.applyOrElse(PartialFunction.scala:118) at org.apache.flink.runtime.ActorLogMessages anon 1.applyOrElse(ActorLogMessages.scala:30) at akka.actor.Actor class.aroundReceive(Actor.scala:465) at org.apache.flink.runtime.jobmanager.JobManager.aroundReceive(JobManager.scala:94) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) at akka.actor.ActorCell.invoke(ActorCell.scala:487) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:254) at akka.dispatch.Mailbox.run(Mailbox.scala:221) at akka.dispatch.Mailbox.exec(Mailbox.scala:231) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) Caused by: java.lang.NullPointerException at org.apache.flink.runtime.io.network.api.serialization.SpanningRecordSerializer.setNextBuffer(SpanningRecordSerializer.java:93) at org.apache.flink.runtime.io.network.api.writer.RecordWriter.emit(RecordWriter.java:92) at org.apache.flink.runtime.operators.shipping.OutputCollector.collect(OutputCollector.java:65) at org.apache.flink.runtime.iterative.task.IterationHeadPactTask.streamSolutionSetToFinalOutput(IterationHeadPactTask.java:405) at org.apache.flink.runtime.iterative.task.IterationHeadPactTask.run(IterationHeadPactTask.java:365) at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:360) at org.apache.flink.runtime.execution.RuntimeEnvironment.run(RuntimeEnvironment.java:221) at java.lang.Thread.run(Thread.java:745)", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "vertex", "centric", "iterationhello", "iter", "hello", "my", "squirrel", "came", "across", "thi", "except", "when", "have", "vertex", "centric", "iter", "output", "follow", "by", "group", "by", "im", "not", "sure", "what", "caus", "it", "sinc", "saw", "thi", "error", "rather", "larg", "pipelin", "but", "manag", "reproduc", "it", "thi", "code", "exampl", "http", "github", "com", "vasia", "flink", "commit", "1b7bbca1a6130fbcfe98b4b9b43967eb4c61f309", "suffici", "larg", "dataset", "thi", "one", "http", "stanford", "dblp", "html", "snap", "edu", "data", "com", "im", "run", "thi", "local", "it", "seem", "like", "null", "buffer", "recordwrit", "record", "writer", "except", "messag", "follow", "except", "thread", "main", "org", "apach", "flink", "runtim", "client", "jobexecutionexcept", "job", "execut", "except", "job", "execut", "fail", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "anonfun", "receivewithlogmessag", "receiv", "log", "messag", "applyorels", "appli", "or", "jobmanag", "scala:319", "job", "manag", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "actorlogmessag", "actor", "log", "messag", "anon", "appli", "actorlogmessag", "scala:37", "actor", "log", "messag", "at", "org", "apach", "flink", "runtim", "actorlogmessag", "actor", "log", "messag", "anon", "appli", "actorlogmessag", "scala:30", "actor", "log", "messag", "at", "scala", "partialfunct", "partial", "function", "class", "applyorels", "appli", "or", "partialfunct", "scala:118", "partial", "function", "at", "org", "apach", "flink", "runtim", "actorlogmessag", "actor", "log", "messag", "anon", "applyorels", "appli", "or", "actorlogmessag", "scala:30", "actor", "log", "messag", "at", "akka", "actor", "actor", "class", "aroundrec", "around", "receiv", "actor", "scala:465", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "aroundrec", "job", "manag", "around", "receiv", "jobmanag", "scala:94", "job", "manag", "at", "akka", "actor", "actorcel", "receivemessag", "actor", "cell", "receiv", "messag", "actorcel", "scala:516", "actor", "cell", "at", "akka", "actor", "actorcel", "invok", "actor", "cell", "actorcel", "scala:487", "actor", "cell", "at", "akka", "dispatch", "mailbox", "processmailbox", "process", "mailbox", "mailbox", "scala:254", "at", "akka", "dispatch", "mailbox", "run", "mailbox", "scala:221", "at", "akka", "dispatch", "mailbox", "exec", "mailbox", "scala:231", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "flink", "runtim", "io", "network", "api", "serial", "spanningrecordseri", "setnextbuff", "span", "record", "serial", "set", "next", "buffer", "spanningrecordseri", "java:93", "span", "record", "serial", "at", "org", "apach", "flink", "runtim", "io", "network", "api", "writer", "recordwrit", "emit", "record", "writer", "recordwrit", "java:92", "record", "writer", "at", "org", "apach", "flink", "runtim", "oper", "ship", "outputcollector", "collect", "output", "collector", "outputcollector", "java:65", "output", "collector", "at", "org", "apach", "flink", "runtim", "iter", "task", "iterationheadpacttask", "streamsolutionsettofinaloutput", "iter", "head", "pact", "task", "stream", "solut", "set", "final", "output", "iterationheadpacttask", "java:405", "iter", "head", "pact", "task", "at", "org", "apach", "flink", "runtim", "iter", "task", "iterationheadpacttask", "run", "iter", "head", "pact", "task", "iterationheadpacttask", "java:365", "iter", "head", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "invok", "regular", "pact", "task", "regularpacttask", "java:360", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "run", "runtim", "environ", "runtimeenviron", "java:221", "runtim", "environ", "at", "java", "lang", "thread", "run", "thread", "java:745"], "B_title": "runtime Improve exception when bufferpools have been shut down.", "B_clean_title": ["runtim", "improv", "except", "when", "bufferpool", "have", "been", "shut", "down"]},
{"A_title": "org.apache.commons.lang3.math.Fraction does not reduce (Integer.MIN_VALUE 2^k)The greatestCommonDivisor method in class Fraction does not find the gcd of Integer.MIN_VALUE and 2^k and this case can be triggered by taking Integer.MIN_VALUE as the numerator. Note that the case of taking Integer.MIN_VALUE as the denominator is handled explicitly in the getReducedFraction factory method. FractionTest.java // additional test cases public void testReducedFactory_int_int()  // ... f = Fraction.getReducedFraction(Integer.MIN_VALUE 2); assertEquals(Integer.MIN_VALUE / 2 f.getNumerator()); assertEquals(1 f.getDenominator());  public void testReduce()  // ... f = Fraction.getFraction(Integer.MIN_VALUE 2); result = f.reduce(); assertEquals(Integer.MIN_VALUE / 2 result.getNumerator()); assertEquals(1 result.getDenominator());", "A_clean_title": ["org", "apach", "common", "lang3", "math", "fraction", "not", "reduc", "integ", "min", "valu", "2^k", "greatestcommondivisor", "greatest", "common", "divisor", "method", "class", "fraction", "not", "find", "gcd", "integ", "min", "valu", "2^k", "thi", "case", "trigger", "by", "take", "integ", "min", "valu", "as", "numer", "note", "that", "case", "take", "integ", "min", "valu", "as", "denomin", "handl", "explicitli", "getreducedfract", "get", "reduc", "fraction", "factori", "method", "fractiontest", "java", "fraction", "test", "addit", "test", "case", "public", "void", "testreducedfactori", "int", "int", "test", "reduc", "factori", "fraction", "getreducedfract", "get", "reduc", "fraction", "integ", "min", "valu", "assertequ", "assert", "equal", "integ", "min", "valu", "getnumer", "get", "numer", "assertequ", "assert", "equal", "getdenomin", "get", "denomin", "public", "void", "testreduc", "test", "reduc", "fraction", "getfract", "get", "fraction", "integ", "min", "valu", "result", "reduc", "assertequ", "assert", "equal", "integ", "min", "valu", "result", "getnumer", "get", "numer", "assertequ", "assert", "equal", "result", "getdenomin", "get", "denomin"], "B_title": "Adding first method check from Maths MathUtils.gcd method; and unit tests showing that this was needed. Bug reported and solved by Christian Semrau LANG-662", "B_clean_title": ["ad", "first", "method", "check", "math", "mathutil", "gcd", "math", "util", "method", "unit", "test", "show", "that", "thi", "wa", "need", "bug", "report", "solv", "by", "christian", "semrau", "lang", "662"]},
{"A_title": "Digamma calculation produces SOE on NaN argumentDigamma doesnt work particularly well with NaNs.  How to reproduce: call Gamma.digamma(Double.NaN)  Expected outcome: returns NaN or throws a meaningful exception  Real outcome: crashes with StackOverflowException as digamma enters infinite recursion.", "A_clean_title": ["digamma", "calcul", "produc", "soe", "nan", "na", "argumentdigamma", "argument", "digamma", "doesnt", "work", "particularli", "well", "nan", "na", "ns", "how", "reproduc", "call", "gamma", "digamma", "doubl", "nan", "na", "expect", "outcom", "return", "nan", "na", "or", "throw", "meaning", "except", "real", "outcom", "crash", "stackoverflowexcept", "stack", "overflow", "except", "as", "digamma", "enter", "infinit", "recurs"], "B_title": "Propagate input value to Gamma#digamma and Gamma#trigamma if the input is not a real value to avoid infinite recursion. Thanks to Aleksei Dievskii.", "B_clean_title": ["propag", "input", "valu", "gamma", "digamma", "gamma", "trigamma", "input", "not", "real", "valu", "avoid", "infinit", "recurs", "thank", "aleksei", "dievskii"]},
{"A_title": "issues with JsopBuilder.encode and .escape1) escape() escapes many characters that do not need to be escaped (>127)  2) encode() does not encode many control characters that would need to be escaped when read through a JSON parser.", "A_clean_title": ["issu", "jsopbuild", "encod", "jsop", "builder", "escape1", "escap", "escap", "mani", "charact", "that", "not", "need", "escap", "127", "encod", "not", "encod", "mani", "control", "charact", "that", "would", "need", "escap", "when", "read", "through", "json", "parser"], "B_title": "issues with JsopBuilder.encode and .escape", "B_clean_title": ["issu", "jsopbuild", "encod", "jsop", "builder", "escap"]},
{"A_title": "Using render strategy ONE_PASS_RENDER fails for Ajax requestsI have an application which has two pages. Page A has an AjaxLink which makes some checks and either sets some error feedback and stays on the same page (e.g. login page with Invalid user error) or if everything is OK then redirects to page B (via setResponsePage(B.class)). The problem comes when the current render strategy is ONE_PASS_RENDER. In this case no matter that fromUrl and toUrl are different and the request is Ajax the current code directly writes the page markup to the response. I think it should trigger a redirect instead. I am not sure whether it should be redirect to render or to buffer ...", "A_clean_title": ["render", "strategi", "one", "pass", "render", "fail", "ajax", "requestsi", "request", "have", "applic", "which", "ha", "two", "page", "page", "ha", "ajaxlink", "ajax", "link", "which", "make", "some", "check", "either", "set", "some", "error", "feedback", "stay", "same", "page", "login", "page", "invalid", "user", "error", "or", "everyth", "ok", "then", "redirect", "page", "via", "setresponsepag", "set", "respons", "page", "class", "problem", "come", "when", "current", "render", "strategi", "one", "pass", "render", "thi", "case", "no", "matter", "that", "fromurl", "url", "tourl", "url", "are", "differ", "request", "ajax", "current", "code", "directli", "write", "page", "markup", "respons", "think", "it", "trigger", "redirect", "instead", "am", "not", "sure", "whether", "it", "redirect", "render", "or", "buffer"], "B_title": "Using render strategy ONE_PASS_RENDER fails for Ajax requests", "B_clean_title": ["render", "strategi", "one", "pass", "render", "fail", "ajax", "request"]},
{"A_title": "Mixin based rules not working for relative propertiesIf an indexing rule is defined for mixin then it does not work as expected for relative properties.  Issue here being that most of logic in Aggregate class (which is used for relative property handling also) relies on nodes primaryType and does not account for mixin type", "A_clean_title": ["mixin", "base", "rule", "not", "work", "rel", "propertiesif", "properti", "index", "rule", "defin", "mixin", "then", "it", "not", "work", "as", "expect", "rel", "properti", "issu", "here", "be", "that", "most", "logic", "aggreg", "class", "which", "use", "rel", "properti", "handl", "also", "reli", "node", "primarytyp", "primari", "type", "not", "account", "mixin", "type"], "B_title": "- Mixin based rules not working for relative properties", "B_clean_title": ["mixin", "base", "rule", "not", "work", "rel", "properti"]},
{"A_title": "HarmonicFitter.ParameterGuesser sometimes fails to return sensible valuesThe inner class ParameterGuesser in HarmonicFitter (package o.a.c.m.optimization.fitting) fails to compute a usable guess for the amplitude parameter.", "A_clean_title": ["harmonicfitt", "parameterguess", "harmon", "fitter", "paramet", "guesser", "sometim", "fail", "return", "sensibl", "valuesth", "valu", "inner", "class", "parameterguess", "paramet", "guesser", "harmonicfitt", "harmon", "fitter", "packag", "optim", "fit", "fail", "comput", "usabl", "guess", "amplitud", "paramet"], "B_title": "Generate an exception when the parameter guessing procedure cannot perform correctly (in rare ill-conditioned cases).", "B_clean_title": ["gener", "except", "when", "paramet", "guess", "procedur", "not", "perform", "correctli", "rare", "ill", "condit", "case"]},
{"A_title": "MutableTree#isNew: replace implementation by NodeBuilder#isNewSimilar to the issue described in OAK-1177 we may consider replacing the implementation of MutableTree#isNew by the corresponding call on the NodeBuilder.  See also OAK-947.", "A_clean_title": ["mutabletre", "mutabl", "tree", "isnew", "new", "replac", "implement", "by", "nodebuild", "node", "builder", "isnewsimilar", "new", "similar", "issu", "describ", "oak", "1177", "we", "may", "consid", "replac", "implement", "mutabletre", "mutabl", "tree", "isnew", "new", "by", "correspond", "call", "nodebuild", "node", "builder", "see", "also", "oak", "947"], "B_title": "MutableTree#isNew: replace implementation by NodeBuilder#isNew", "B_clean_title": ["mutabletre", "mutabl", "tree", "isnew", "new", "replac", "implement", "by", "nodebuild", "node", "builder", "isnew", "new"]},
{"A_title": "Last-modified header of external markup is ignoredWhen using external base markup(in my case a drupal page with a wicket:child element in it) this markup is supposed to be cached after first fetch. For subsequent requests the last-modified header is checked to see if the markup has changed and when it has the markup is fetched again.  This does not work Connections.getLastModified(URL url) always returns 0 when the URL is a http url(in fact when url.openConnection returns a sun.net.www.protocol.http.HttpURLConnection.  Solution could be to not setDoInput to false on this URLConnection(tested that)", "A_clean_title": ["last", "modifi", "header", "extern", "markup", "ignoredwhen", "ignor", "when", "extern", "base", "markup", "my", "case", "drupal", "page", "wicket", "child", "element", "it", "thi", "markup", "suppos", "cach", "after", "first", "fetch", "subsequ", "request", "last", "modifi", "header", "check", "see", "markup", "ha", "chang", "when", "it", "ha", "markup", "fetch", "again", "thi", "not", "work", "connect", "getlastmodifi", "get", "last", "modifi", "url", "url", "alway", "return", "when", "url", "http", "url", "fact", "when", "url", "openconnect", "open", "connect", "return", "sun", "net", "www", "protocol", "http", "httpurlconnect", "http", "url", "connect", "solut", "could", "not", "setdoinput", "set", "input", "fals", "thi", "urlconnect", "url", "connect", "test", "that"], "B_title": "Last-modified header of external markup is ignored", "B_clean_title": ["last", "modifi", "header", "extern", "markup", "ignor"]},
{"A_title": "Bug in DoubleParser and FloatParser - empty String is not casted to 0Hi  I found the bug when I wanted to read a csv file which had a line like: ||n  If I treat it as a Tuple2<LongLong> I get as expected a tuple (0L0L).  But if I want to read it into a Double-Tuple or a Float-Tuple I get the following error:  java.lang.AssertionError: Test failed due to a org.apache.flink.api.common.io.ParseException: Line could not be parsed: || ParserError NUMERIC_VALUE_FORMAT_ERROR   This error can be solved by adding an additional condition for empty strings in the FloatParser / DoubleParser.  We definitely need the CSVReader to be able to read empty values.  I can fix it like described if there are no better ideas :)", "A_clean_title": ["bug", "doublepars", "doubl", "parser", "floatpars", "float", "parser", "empti", "string", "not", "cast", "0hi", "found", "bug", "when", "want", "read", "csv", "file", "which", "had", "line", "like", "||n", "treat", "it", "as", "tuple2", "longlong", "long", "long", "get", "as", "expect", "tupl", "0l0l", "but", "want", "read", "it", "into", "doubl", "tupl", "or", "float", "tupl", "get", "follow", "error", "java", "lang", "assertionerror", "assert", "error", "test", "fail", "due", "org", "apach", "flink", "api", "common", "io", "parseexcept", "pars", "except", "line", "could", "not", "pars", "parsererror", "parser", "error", "numer", "valu", "format", "error", "thi", "error", "solv", "by", "ad", "addit", "condit", "empti", "string", "floatpars", "float", "parser", "doublepars", "doubl", "parser", "we", "definit", "need", "csvreader", "csv", "reader", "abl", "read", "empti", "valu", "fix", "it", "like", "describ", "there", "are", "no", "better", "idea"], "B_title": "Consistent behavior of numeric value parsers.", "B_clean_title": ["consist", "behavior", "numer", "valu", "parser"]},
{"A_title": "Mock Accumulo Inverts order of mutations w/ same timestampMock accumulo has different behavior than real accumulo when the same key is updated in the same millisecond.  The hidden in memory map counter in mock accumulo needs to sort descending.", "A_clean_title": ["mock", "accumulo", "invert", "order", "mutat", "same", "timestampmock", "timestamp", "mock", "accumulo", "ha", "differ", "behavior", "than", "real", "accumulo", "when", "same", "key", "updat", "same", "millisecond", "hidden", "memori", "map", "counter", "mock", "accumulo", "need", "sort", "descend"], "B_title": "made mock accumulo sort incoming mutations the same as accumulo", "B_clean_title": ["made", "mock", "accumulo", "sort", "incom", "mutat", "same", "as", "accumulo"]},
{"A_title": "BitStreamGenerators (MersenneTwister Well generators) do not clear normal deviate cache on setSeedThe BitStream generators generate normal deviates (for nextGaussian) in pairs caching the last value generated. When reseeded the cache should be cleared; otherwise seeding two generators with the same value is not guaranteed to generate the same sequence.", "A_clean_title": ["bitstreamgener", "bit", "stream", "gener", "mersennetwist", "mersenn", "twister", "well", "gener", "not", "clear", "normal", "deviat", "cach", "setseedth", "set", "seed", "bitstream", "bit", "stream", "gener", "gener", "normal", "deviat", "nextgaussian", "next", "gaussian", "pair", "cach", "last", "valu", "gener", "when", "reseed", "cach", "clear", "otherwis", "seed", "two", "gener", "same", "valu", "not", "guarante", "gener", "same", "sequenc"], "B_title": "Made ISAACRandom clear its normal deviate cache on reseed. JIRA: MATH-723.", "B_clean_title": ["made", "isaacrandom", "isaac", "random", "clear", "it", "normal", "deviat", "cach", "rese", "jira", "math", "723"]},
{"A_title": "Constructor types that return all or unknown fail to parseNone", "A_clean_title": ["constructor", "type", "that", "return", "all", "or", "unknown", "fail", "parsenon", "pars", "none"], "B_title": "Tweak the grammar for this/new types. Fixes issue 1105 R=johnlenz", "B_clean_title": ["tweak", "grammar", "thi", "new", "type", "fix", "issu", "1105", "r=johnlenz"]},
{"A_title": "Bug in method appendFixedWidthPadRight of class StrBuilder causes an ArrayIndexOutOfBoundsExceptionTheres a bug in method appendFixedWidthPadRight of class StrBuilder: public StrBuilder appendFixedWidthPadRight(Object obj int width char padChar)          if (width > 0)              ensureCapacity(size + width);             String str = (obj == null ? getNullText() : obj.toString());             int strLen = str.length();             if (strLen >= width)    ==>            str.getChars(0 strLen buffer size);   <==== BUG: it should be str.getChars(0 width buffer size);               else                  int padLen = width - strLen;                 str.getChars(0 strLen buffer size);                 for (int i = 0; i < padLen; i++)                       buffersize + strLen + i = padChar;                                           size += width;                  return this;      This is causing an ArrayIndexOutOfBoundsException so this method is unusable when strLen > width. Its counterpart method appendFixedWidthPadLeft seems to be ok.", "A_clean_title": ["bug", "method", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "class", "strbuilder", "str", "builder", "caus", "arrayindexoutofboundsexceptionther", "array", "index", "out", "bound", "except", "there", "bug", "method", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "class", "strbuilder", "str", "builder", "public", "strbuilder", "str", "builder", "appendfixedwidthpadright", "append", "fix", "width", "pad", "right", "object", "obj", "int", "width", "char", "padchar", "pad", "char", "width", "ensurecapac", "ensur", "capac", "size", "width", "string", "str", "obj", "null", "getnulltext", "get", "null", "text", "obj", "tostr", "string", "int", "strlen", "str", "len", "str", "length", "strlen", "str", "len", "width", "str", "getchar", "get", "char", "strlen", "str", "len", "buffer", "size", "bug", "it", "str", "getchar", "get", "char", "width", "buffer", "size", "int", "padlen", "pad", "len", "width", "strlen", "str", "len", "str", "getchar", "get", "char", "strlen", "str", "len", "buffer", "size", "int", "padlen", "pad", "len", "i++", "buffers", "strlen", "str", "len", "padchar", "pad", "char", "size", "width", "return", "thi", "thi", "caus", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "so", "thi", "method", "unus", "when", "strlen", "str", "len", "width", "it", "counterpart", "method", "appendfixedwidthpadleft", "append", "fix", "width", "pad", "left", "seem", "ok"], "B_title": "Applying a unit test for LANG-299 and the fix that Francisco Benavent suggests.", "B_clean_title": ["appli", "unit", "test", "lang", "299", "fix", "that", "francisco", "benav", "suggest"]},
{"A_title": "Minified name resolves incorrectly if default resource reference is usedIn PackageResourceReference.  When a default reference to a minified resource is used (i.e. the resource wasnt mounted) the resource reference name includes .min.   When trying to resolve the minified name another .min is appended resulting in the minified name resolving to html5.min.min.js.   As a result the PackageResourceReference concludes that the resource was not minified and adds compression.", "A_clean_title": ["minifi", "name", "resolv", "incorrectli", "default", "resourc", "refer", "usedin", "use", "packageresourcerefer", "packag", "resourc", "refer", "when", "default", "refer", "minifi", "resourc", "use", "resourc", "wasnt", "mount", "resourc", "refer", "name", "includ", "min", "when", "tri", "resolv", "minifi", "name", "anoth", "min", "append", "result", "minifi", "name", "resolv", "html5", "min", "min", "js", "as", "result", "packageresourcerefer", "packag", "resourc", "refer", "conclud", "that", "resourc", "wa", "not", "minifi", "add", "compress"], "B_title": "", "B_clean_title": []},
{"A_title": "NoSuchElementException thrown by NodeDocumentFollowing error is seen with latest 1.0.9-SNAPSHOT builds on some system  noformat Caused by: java.util.NoSuchElementException: null         at java.util.TreeMap.key(TreeMap.java:1221)         at java.util.TreeMap.firstKey(TreeMap.java:285)         at java.util.Collections UnmodifiableSortedMap.firstKey(Collections.java:1549)         at com.google.common.collect.ForwardingSortedMap.firstKey(ForwardingSortedMap.java:73)         at org.apache.jackrabbit.oak.plugins.document.NodeDocument.getNodeAtRevision(NodeDocument.java:819)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readNode(DocumentNodeStore.java:930) noformat  Most likely the above occurs because a TreeMap associated with some key in NodeDocument is empty.  noformat 23.01.2015 01:57:23.308 *WARN* pool-11-thread-5org.apache.jackrabbit.oak.plugins.observation.NodeObserver Error whiledispatching observation eventscom.google.common.util.concurrent.UncheckedExecutionException:com.google.common.util.concurrent.UncheckedExecutionException:java.util.NoSuchElementException         at com.google.common.cache.LocalCache Segment.get(LocalCache.java:2199)         at com.google.common.cache.LocalCache.get(LocalCache.java:3932)         at com.google.common.cache.LocalCache LocalManualCache.get(LocalCache.java:4721)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.getChildren(DocumentNodeStore.java:731)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.diffImpl(DocumentNodeStore.java:1666)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.access 200(DocumentNodeStore.java:105)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore 7.call(DocumentNodeStore.java:1260)         at org.apache.jackrabbit.oak.plugins.document.MongoDiffCache.getChanges(MongoDiffCache.java:88)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.diffChildren(DocumentNodeStore.java:1255)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeState.compareAgainstBaseState(DocumentNodeState.java:260)         at org.apache.jackrabbit.oak.plugins.observation.EventGenerator Continuation.run(EventGenerator.java:172)         at org.apache.jackrabbit.oak.plugins.observation.EventGenerator.generate(EventGenerator.java:118)         at org.apache.jackrabbit.oak.plugins.observation.NodeObserver.contentChanged(NodeObserver.java:156)         at org.apache.jackrabbit.oak.spi.commit.BackgroundObserver 1 1.call(BackgroundObserver.java:117)         at org.apache.jackrabbit.oak.spi.commit.BackgroundObserver 1 1.call(BackgroundObserver.java:111)         at java.util.concurrent.FutureTask.run(FutureTask.java:262)         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)         at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:615)         at java.lang.Thread.run(Thread.java:744) Caused by: com.google.common.util.concurrent.UncheckedExecutionException:java.util.NoSuchElementException         at com.google.common.cache.LocalCache Segment.get(LocalCache.java:2199)         at com.google.common.cache.LocalCache.get(LocalCache.java:3932)         at com.google.common.cache.LocalCache LocalManualCache.get(LocalCache.java:4721)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.getNode(DocumentNodeStore.java:704)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readChildren(DocumentNodeStore.java:786)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore 4.call(DocumentNodeStore.java:734)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore 4.call(DocumentNodeStore.java:731)         at com.google.common.cache.LocalCache LocalManualCache 1.load(LocalCache.java:4724)         at com.google.common.cache.LocalCache LoadingValueReference.loadFuture(LocalCache.java:3522)         at com.google.common.cache.LocalCache Segment.loadSync(LocalCache.java:2315)         at com.google.common.cache.LocalCache Segment.lockedGetOrLoad(LocalCache.java:2278)         at com.google.common.cache.LocalCache Segment.get(LocalCache.java:2193)        ... 18 common frames omitted Caused by: java.util.NoSuchElementException: null         at java.util.TreeMap.key(TreeMap.java:1221)         at java.util.TreeMap.firstKey(TreeMap.java:285)         at java.util.Collections UnmodifiableSortedMap.firstKey(Collections.java:1549)         at com.google.common.collect.ForwardingSortedMap.firstKey(ForwardingSortedMap.java:73)         at org.apache.jackrabbit.oak.plugins.document.NodeDocument.getNodeAtRevision(NodeDocument.java:819)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readNode(DocumentNodeStore.java:930)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore 3.call(DocumentNodeStore.java:707)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore 3.call(DocumentNodeStore.java:704)         at com.google.common.cache.LocalCache LocalManualCache 1.load(LocalCache.java:4724)         at com.google.common.cache.LocalCache LoadingValueReference.loadFuture(LocalCache.java:3522)         at com.google.common.cache.LocalCache Segment.loadSync(LocalCache.java:2315)         at com.google.common.cache.LocalCache Segment.lockedGetOrLoad(LocalCache.java:2278)         at com.google.common.cache.LocalCache Segment.get(LocalCache.java:2193) noformat", "A_clean_title": ["nosuchelementexcept", "no", "such", "element", "except", "thrown", "by", "nodedocumentfollow", "node", "document", "follow", "error", "seen", "latest", "snapshot", "build", "some", "system", "noformat", "caus", "by", "java", "util", "nosuchelementexcept", "no", "such", "element", "except", "null", "at", "java", "util", "treemap", "key", "tree", "map", "treemap", "java:1221", "tree", "map", "at", "java", "util", "treemap", "firstkey", "tree", "map", "first", "key", "treemap", "java:285", "tree", "map", "at", "java", "util", "collect", "unmodifiablesortedmap", "firstkey", "unmodifi", "sort", "map", "first", "key", "collect", "java:1549", "at", "com", "googl", "common", "collect", "forwardingsortedmap", "firstkey", "forward", "sort", "map", "first", "key", "forwardingsortedmap", "java:73", "forward", "sort", "map", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "nodedocu", "getnodeatrevis", "node", "document", "get", "node", "at", "revis", "nodedocu", "java:819", "node", "document", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "readnod", "document", "node", "store", "read", "node", "documentnodestor", "java:930", "document", "node", "store", "noformat", "most", "like", "abov", "occur", "becaus", "treemap", "tree", "map", "associ", "some", "key", "nodedocu", "node", "document", "empti", "noformat", "23", "01", "2015", "01:57:23", "308", "warn", "pool", "11", "thread", "5org", "apach", "jackrabbit", "oak", "plugin", "observ", "nodeobserv", "node", "observ", "error", "whiledispatch", "observ", "eventscom", "googl", "common", "util", "concurr", "uncheckedexecutionexcept", "uncheck", "execut", "except", "com", "googl", "common", "util", "concurr", "uncheckedexecutionexcept", "uncheck", "execut", "except", "java", "util", "nosuchelementexcept", "no", "such", "element", "except", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "get", "localcach", "java:2199", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "get", "local", "cach", "localcach", "java:3932", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "localmanualcach", "get", "local", "manual", "cach", "localcach", "java:4721", "local", "cach", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "getchildren", "document", "node", "store", "get", "children", "documentnodestor", "java:731", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "diffimpl", "document", "node", "store", "diff", "impl", "documentnodestor", "java:1666", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "access", "document", "node", "store", "200", "documentnodestor", "java:105", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "document", "node", "store", "call", "documentnodestor", "java:1260", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "mongodiffcach", "getchang", "mongo", "diff", "cach", "get", "chang", "mongodiffcach", "java:88", "mongo", "diff", "cach", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "diffchildren", "document", "node", "store", "diff", "children", "documentnodestor", "java:1255", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodest", "compareagainstbasest", "document", "node", "state", "compar", "against", "base", "state", "documentnodest", "java:260", "document", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "observ", "eventgener", "event", "gener", "continu", "run", "eventgener", "java:172", "event", "gener", "at", "org", "apach", "jackrabbit", "oak", "plugin", "observ", "eventgener", "gener", "event", "gener", "eventgener", "java:118", "event", "gener", "at", "org", "apach", "jackrabbit", "oak", "plugin", "observ", "nodeobserv", "contentchang", "node", "observ", "content", "chang", "nodeobserv", "java:156", "node", "observ", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "backgroundobserv", "background", "observ", "call", "backgroundobserv", "java:117", "background", "observ", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "backgroundobserv", "background", "observ", "call", "backgroundobserv", "java:111", "background", "observ", "at", "java", "util", "concurr", "futuretask", "run", "futur", "task", "futuretask", "java:262", "futur", "task", "at", "java", "util", "concurr", "threadpoolexecutor", "runwork", "thread", "pool", "executor", "run", "worker", "threadpoolexecutor", "java:1145", "thread", "pool", "executor", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:615", "thread", "pool", "executor", "at", "java", "lang", "thread", "run", "thread", "java:744", "caus", "by", "com", "googl", "common", "util", "concurr", "uncheckedexecutionexcept", "uncheck", "execut", "except", "java", "util", "nosuchelementexcept", "no", "such", "element", "except", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "get", "localcach", "java:2199", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "get", "local", "cach", "localcach", "java:3932", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "localmanualcach", "get", "local", "manual", "cach", "localcach", "java:4721", "local", "cach", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "getnod", "document", "node", "store", "get", "node", "documentnodestor", "java:704", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "readchildren", "document", "node", "store", "read", "children", "documentnodestor", "java:786", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "document", "node", "store", "call", "documentnodestor", "java:734", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "document", "node", "store", "call", "documentnodestor", "java:731", "document", "node", "store", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "localmanualcach", "local", "manual", "cach", "load", "localcach", "java:4724", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "loadingvaluerefer", "loadfutur", "load", "valu", "refer", "load", "futur", "localcach", "java:3522", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "loadsync", "load", "sync", "localcach", "java:2315", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "lockedgetorload", "lock", "get", "or", "load", "localcach", "java:2278", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "get", "localcach", "java:2193", "local", "cach", "18", "common", "frame", "omit", "caus", "by", "java", "util", "nosuchelementexcept", "no", "such", "element", "except", "null", "at", "java", "util", "treemap", "key", "tree", "map", "treemap", "java:1221", "tree", "map", "at", "java", "util", "treemap", "firstkey", "tree", "map", "first", "key", "treemap", "java:285", "tree", "map", "at", "java", "util", "collect", "unmodifiablesortedmap", "firstkey", "unmodifi", "sort", "map", "first", "key", "collect", "java:1549", "at", "com", "googl", "common", "collect", "forwardingsortedmap", "firstkey", "forward", "sort", "map", "first", "key", "forwardingsortedmap", "java:73", "forward", "sort", "map", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "nodedocu", "getnodeatrevis", "node", "document", "get", "node", "at", "revis", "nodedocu", "java:819", "node", "document", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "readnod", "document", "node", "store", "read", "node", "documentnodestor", "java:930", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "document", "node", "store", "call", "documentnodestor", "java:707", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "document", "node", "store", "call", "documentnodestor", "java:704", "document", "node", "store", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "localmanualcach", "local", "manual", "cach", "load", "localcach", "java:4724", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "loadingvaluerefer", "loadfutur", "load", "valu", "refer", "load", "futur", "localcach", "java:3522", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "loadsync", "load", "sync", "localcach", "java:2315", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "lockedgetorload", "lock", "get", "or", "load", "localcach", "java:2278", "local", "cach", "at", "com", "googl", "common", "cach", "localcach", "local", "cach", "segment", "get", "localcach", "java:2193", "local", "cach", "noformat"], "B_title": "NoSuchElementException thrown by NodeDocument", "B_clean_title": ["nosuchelementexcept", "no", "such", "element", "except", "thrown", "by", "nodedocu", "node", "document"]},
{"A_title": "Incorrect mapping of the MET time zoneThis timezone is mapped to Asia/Tehran in DateTimeZone. It should be middle europena time.", "A_clean_title": ["incorrect", "map", "met", "time", "zonethi", "zone", "thi", "timezon", "map", "asia", "tehran", "datetimezon", "date", "time", "zone", "it", "middl", "europena", "time"], "B_title": "3216471 Time-zone ID MET from java.util.TimeZone is now mapped correctly. Other time-zone conversions have been updated appropriately", "B_clean_title": ["3216471", "time", "zone", "id", "met", "java", "util", "timezon", "time", "zone", "now", "map", "correctli", "other", "time", "zone", "convers", "have", "been", "updat", "appropri"]},
{"A_title": "getKernel fails for buckets with only multiple instances of the same value in random.EmpiricalDistributionAfter loading a set of values into an EmpericalDistribution assume that theres a case where a single bin ONLY contains multiple instances of the same value.  In this case the standard deviation will equal zero.  This will fail when getKernel attempts to create a NormalDistribution.  The other case where stddev=0 is when there is only a single value in the bin and this is handled by returning a ConstantRealDistribution rather than a NormalDistrbution.  See: https://issues.apache.org/jira/browse/MATH-984", "A_clean_title": ["getkernel", "get", "kernel", "fail", "bucket", "onli", "multipl", "instanc", "same", "valu", "random", "empiricaldistributionaft", "empir", "distribut", "after", "load", "set", "valu", "into", "empericaldistribut", "emper", "distribut", "assum", "that", "there", "case", "where", "singl", "bin", "onli", "contain", "multipl", "instanc", "same", "valu", "thi", "case", "standard", "deviat", "will", "equal", "zero", "thi", "will", "fail", "when", "getkernel", "get", "kernel", "attempt", "creat", "normaldistribut", "normal", "distribut", "other", "case", "where", "stddev=0", "when", "there", "onli", "singl", "valu", "bin", "thi", "handl", "by", "return", "constantrealdistribut", "constant", "real", "distribut", "rather", "than", "normaldistrbut", "normal", "distrbut", "see", "http", "984", "apach", "issu", "org", "jira", "brows", "math"], "B_title": "Made getKernel return a constant distribution for zero variance bins.  JIRA: MATH-1203.", "B_clean_title": ["made", "getkernel", "get", "kernel", "return", "constant", "distribut", "zero", "varianc", "bin", "jira", "math", "1203"]},
{"A_title": "Parallel execution of ConcurrentReadAccessControlledTreeTest fails with MongoMKThe is caused by concurrent creation of test content and the conflict it creates in the index. Every Oak test instance tries to create /oak:index/nodetype/:index/nt%3Afile but only one will succeed. AFAICS there are two options how to handle this:  - Implement conflict annotation (OAK-1185) though Im not sure this will really work. On commit the rebase happens first when changes from the other Oak instance may not be visible yet. Then the commit hook runs and perform another branch commit with the changes which works fine. Only the last step fails when MongoMK tries to merge the branch. This is the point when the conflict may be detected.  - Implement a retry logic in MongoMK/NS", "A_clean_title": ["parallel", "execut", "concurrentreadaccesscontrolledtreetest", "concurr", "read", "access", "control", "tree", "test", "fail", "mongomkth", "mongo", "mk", "caus", "by", "concurr", "creation", "test", "content", "conflict", "it", "creat", "index", "everi", "oak", "test", "instanc", "tri", "creat", "oak", "index", "nodetyp", "index", "nt", "3afil", "but", "onli", "one", "will", "succeed", "afaic", "there", "are", "two", "option", "how", "handl", "thi", "implement", "conflict", "annot", "oak", "1185", "though", "im", "not", "sure", "thi", "will", "realli", "work", "commit", "rebas", "happen", "first", "when", "chang", "other", "oak", "instanc", "may", "not", "visibl", "yet", "then", "commit", "hook", "run", "perform", "anoth", "branch", "commit", "chang", "which", "work", "fine", "onli", "last", "step", "fail", "when", "mongomk", "mongo", "mk", "tri", "merg", "branch", "thi", "point", "when", "conflict", "may", "detect", "implement", "retri", "logic", "mongomk", "ns", "mongo", "mk"], "B_title": "Parallel execution of ConcurrentReadAccessControlledTreeTest fails with MongoMK - change MongoMK.reset() to actually undo the commits applying the reverse diff is not sufficient - additional tests", "B_clean_title": ["parallel", "execut", "concurrentreadaccesscontrolledtreetest", "concurr", "read", "access", "control", "tree", "test", "fail", "mongomk", "mongo", "mk", "chang", "mongomk", "reset", "mongo", "mk", "actual", "undo", "commit", "appli", "revers", "diff", "not", "suffici", "addit", "test"]},
{"A_title": "JSCompiler does not recursively resolve typedefsNone", "A_clean_title": ["jscompil", "js", "compil", "not", "recurs", "resolv", "typedefsnon", "typedef", "none"], "B_title": "When expanding goog.scope aliases in type expressions do not expand the alias until previous aliases have been expanded. fixes issue 772", "B_clean_title": ["when", "expand", "goog", "scope", "alias", "type", "express", "not", "expand", "alia", "until", "previou", "alias", "have", "been", "expand", "fix", "issu", "772"]},
{"A_title": "PackageMapper - Could not resolve classIt seems that the PackageMapper try to resolve much more than it is supposed to do for instance if Ive 2 pages test1/TestPage1 and test2/TestPage2 then it tries to resolve test2/TestPage1 when I reach the page1...   WARN  - WicketObjects              - Could not resolve class com.mycompany.test2.TestPage1 java.lang.ClassNotFoundException: com.mycompany.test2.TestPage1     at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1714)     at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1559)     at java.lang.Class.forName0(Native Method)     at java.lang.Class.forName(Class.java:270)     at org.apache.wicket.application.AbstractClassResolver.resolveClass(AbstractClassResolver.java:108)     at org.apache.wicket.core.util.lang.WicketObjects.resolveClass(WicketObjects.java:71)     at org.apache.wicket.core.request.mapper.AbstractComponentMapper.getPageClass(AbstractComponentMapper.java:134)     at org.apache.wicket.core.request.mapper.PackageMapper.parseRequest(PackageMapper.java:152)     at org.apache.wicket.core.request.mapper.AbstractBookmarkableMapper.mapRequest(AbstractBookmarkableMapper.java:322)     at org.apache.wicket.request.mapper.CompoundRequestMapper.mapRequest(CompoundRequestMapper.java:152)     at org.apache.wicket.request.cycle.RequestCycle.resolveRequestHandler(RequestCycle.java:189)     at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:219)     at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:293)     at org.apache.wicket.protocol.http.WicketFilter.processRequestCycle(WicketFilter.java:261)     at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:203)     at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:284)", "A_clean_title": ["packagemapp", "packag", "mapper", "could", "not", "resolv", "classit", "class", "it", "seem", "that", "packagemapp", "packag", "mapper", "tri", "resolv", "much", "more", "than", "it", "suppos", "instanc", "ive", "page", "test1", "testpage1", "test", "page1", "test2", "testpage2", "test", "page2", "then", "it", "tri", "resolv", "test2", "testpage1", "test", "page1", "when", "reach", "page1", "warn", "wicketobject", "wicket", "object", "could", "not", "resolv", "class", "com", "mycompani", "test2", "testpage1", "test", "page1", "java", "lang", "classnotfoundexcept", "class", "not", "found", "except", "com", "mycompani", "test2", "testpage1", "test", "page1", "at", "org", "apach", "catalina", "loader", "webappclassload", "loadclass", "webapp", "class", "loader", "load", "class", "webappclassload", "java:1714", "webapp", "class", "loader", "at", "org", "apach", "catalina", "loader", "webappclassload", "loadclass", "webapp", "class", "loader", "load", "class", "webappclassload", "java:1559", "webapp", "class", "loader", "at", "java", "lang", "class", "forname0", "name0", "nativ", "method", "at", "java", "lang", "class", "fornam", "name", "class", "java:270", "at", "org", "apach", "wicket", "applic", "abstractclassresolv", "resolveclass", "abstract", "class", "resolv", "resolv", "class", "abstractclassresolv", "java:108", "abstract", "class", "resolv", "at", "org", "apach", "wicket", "core", "util", "lang", "wicketobject", "resolveclass", "wicket", "object", "resolv", "class", "wicketobject", "java:71", "wicket", "object", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractcomponentmapp", "getpageclass", "abstract", "compon", "mapper", "get", "page", "class", "abstractcomponentmapp", "java:134", "abstract", "compon", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "packagemapp", "parserequest", "packag", "mapper", "pars", "request", "packagemapp", "java:152", "packag", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractbookmarkablemapp", "maprequest", "abstract", "bookmark", "mapper", "map", "request", "abstractbookmarkablemapp", "java:322", "abstract", "bookmark", "mapper", "at", "org", "apach", "wicket", "request", "mapper", "compoundrequestmapp", "maprequest", "compound", "request", "mapper", "map", "request", "compoundrequestmapp", "java:152", "compound", "request", "mapper", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "resolverequesthandl", "request", "cycl", "resolv", "request", "handler", "requestcycl", "java:189", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:219", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:293", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequestcycl", "wicket", "filter", "process", "request", "cycl", "wicketfilt", "java:261", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:203", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:284", "wicket", "filter"], "B_title": "PackageMapper issue WICKET-5565. The compatibility score is not correct.", "B_clean_title": ["packagemapp", "packag", "mapper", "issu", "wicket", "5565", "compat", "score", "not", "correct"]},
{"A_title": "ConvergenceException in NormalDistributionImpl.cumulativeProbability()I get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity -Infinity. For instance in the following code: @Test public void testCumulative()  final NormalDistribution nd = new NormalDistributionImpl(); for (int i = 0; i < 500; i++)  final double val = Math.exp; try   System.out.println(val =  + val +  cumulative =  + nd.cumulativeProbability(val));   catch (MathException e)   e.printStackTrace(); fail();    In version 2.0 I get no exception.  My suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values) not just MaxIterationsExceededException.", "A_clean_title": ["convergenceexcept", "converg", "except", "normaldistributionimpl", "cumulativeprob", "normal", "distribut", "impl", "cumul", "probabl", "get", "convergenceexcept", "converg", "except", "normaldistributionimpl", "cumulativeprob", "normal", "distribut", "impl", "cumul", "probabl", "veri", "larg", "small", "paramet", "includ", "infin", "infin", "instanc", "follow", "code", "test", "public", "void", "testcumul", "test", "cumul", "final", "normaldistribut", "normal", "distribut", "nd", "new", "normaldistributionimpl", "normal", "distribut", "impl", "int", "500", "i++", "final", "doubl", "val", "math", "exp", "tri", "system", "out", "println", "val", "val", "cumul", "nd", "cumulativeprob", "cumul", "probabl", "val", "catch", "mathexcept", "math", "except", "printstacktrac", "print", "stack", "trace", "fail", "version", "get", "no", "except", "my", "suggest", "chang", "implement", "cumulativeprob", "cumul", "probabl", "doubl", "catch", "all", "convergenceexcept", "converg", "except", "return", "veri", "larg", "veri", "small", "valu", "not", "just", "maxiterationsexceededexcept", "max", "iter", "exceed", "except"], "B_title": "Modified NormalDistributionImpl.cumulativeProbability to return 0 or 1 respectively for values more than 40 standard deviations from the mean. For these values the actual probability is indistinguishable from 0 or 1 as a double.  Top coding improves performance for extreme values and prevents convergence exceptions.", "B_clean_title": ["modifi", "normaldistributionimpl", "cumulativeprob", "normal", "distribut", "impl", "cumul", "probabl", "return", "or", "respect", "valu", "more", "than", "40", "standard", "deviat", "mean", "these", "valu", "actual", "probabl", "indistinguish", "or", "as", "doubl", "top", "code", "improv", "perform", "extrem", "valu", "prevent", "converg", "except"]},
{"A_title": "Node not accessible after document splitIn a cluster setup it may happen that a node becomes inaccessible when all remaining local revision entries after a split are not yet visible to a cluster node.", "A_clean_title": ["node", "not", "access", "after", "document", "splitin", "split", "cluster", "setup", "it", "may", "happen", "that", "node", "becom", "inaccess", "when", "all", "remain", "local", "revis", "entri", "after", "split", "are", "not", "yet", "visibl", "cluster", "node"], "B_title": "Node not accessible after document split", "B_clean_title": ["node", "not", "access", "after", "document", "split"]},
{"A_title": "Locking issues seen with CopyOnWrite mode enabledWhen CopyOnWrite mode is enabled and incremental mode is enabled i.e. indexPath property set then failure in any indexing cycle would prevent further indexing from progressing. For e.g. if any indexing cycle fails then subsequent indexing cycle would fail with Lucene locking related exception  noformat Caused by: org.apache.lucene.store.LockObtainFailedException: Lock obtain timed out: NativeFSLock@/tmp/junit8067118705344013640/2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7ae/1/write.lock at org.apache.lucene.store.Lock.obtain(Lock.java:89) at org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:707) at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorContext.getWriter(LuceneIndexEditorContext.java:169) at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.addOrUpdate(LuceneIndexEditor.java:293) ... 37 more noformat  Any further indexing would continue to fail with this exception", "A_clean_title": ["lock", "issu", "seen", "copyonwrit", "copi", "write", "mode", "enabledwhen", "enabl", "when", "copyonwrit", "copi", "write", "mode", "enabl", "increment", "mode", "enabl", "indexpath", "index", "path", "properti", "set", "then", "failur", "ani", "index", "cycl", "would", "prevent", "further", "index", "progress", "ani", "index", "cycl", "fail", "then", "subsequ", "index", "cycl", "would", "fail", "lucen", "lock", "relat", "except", "noformat", "caus", "by", "org", "apach", "lucen", "store", "lockobtainfailedexcept", "lock", "obtain", "fail", "except", "lock", "obtain", "time", "out", "nativefslock", "nativ", "fs", "lock", "lock", "tmp", "junit8067118705344013640", "2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7a", "write", "at", "org", "apach", "lucen", "store", "lock", "obtain", "lock", "java:89", "at", "org", "apach", "lucen", "index", "indexwrit", "index", "writer", "init", "indexwrit", "java:707", "index", "writer", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexeditorcontext", "getwrit", "lucen", "index", "editor", "context", "get", "writer", "luceneindexeditorcontext", "java:169", "lucen", "index", "editor", "context", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexeditor", "addorupd", "lucen", "index", "editor", "add", "or", "updat", "luceneindexeditor", "java:293", "lucen", "index", "editor", "37", "more", "noformat", "ani", "further", "index", "would", "continu", "fail", "thi", "except"], "B_title": "- Locking issues seen with CopyOnWrite mode enabled", "B_clean_title": ["lock", "issu", "seen", "copyonwrit", "copi", "write", "mode", "enabl"]},
{"A_title": "Make Mockito JUnit rule easier to useMockito JUnit rule easier to use by avoiding the need to pass test instance. Make it compatible with JUnit 4.7+ instead of 4.9+.", "A_clean_title": ["make", "mockito", "junit", "unit", "rule", "easier", "usemockito", "use", "mockito", "junit", "unit", "rule", "easier", "use", "by", "avoid", "need", "pass", "test", "instanc", "make", "it", "compat", "junit", "unit", "7+", "instead", "9+"], "B_title": "Inform the user with a good message when she tries to callRealMethod() on a mock of a interface. Fixed issue 140", "B_clean_title": ["inform", "user", "good", "messag", "when", "she", "tri", "callrealmethod", "call", "real", "method", "mock", "interfac", "fix", "issu", "140"]},
{"A_title": "key.followingKey(PartialKey.ROW_COLFAM_COLQUAL_COLVIS) can produce a key with an invalid COLVISNeed a new algorithm for calculating the next biggest column visibility because tagging 0 to the end creates an invalid column visibility. We might be able to minimize the timestamp for this (i.e. set timestamp to Long.MIN_VALUE but keep column and row elements the same).", "A_clean_title": ["key", "followingkey", "follow", "key", "partialkey", "partial", "key", "row", "colfam", "colqual", "colvi", "produc", "key", "invalid", "colvisne", "colvi", "need", "new", "algorithm", "calcul", "next", "biggest", "column", "visibl", "becaus", "tag", "end", "creat", "invalid", "column", "visibl", "we", "might", "abl", "minim", "timestamp", "thi", "set", "timestamp", "long", "min", "valu", "but", "keep", "column", "row", "element", "same"], "B_title": "merged to trunk", "B_clean_title": ["merg", "trunk"]},
{"A_title": "Calling addNode on a node that has orderable child nodes violates specificationit seems to me that the current behavior of Node.addNode for a node that  has orderable child nodes violates the specification (section 23.3):  quote 23.3 Adding a New Child Node When a child node is added to a node that has orderable child nodes it is added to the end of the list. quote  however the following test will fail:  code @Test     public void testAddNode() throws Exception          new TestContentLoader().loadTestContent(getAdminSession());          Session session = getAdminSession();         Node test = session.getRootNode().addNode(test test:orderableFolder);         assertTrue(test.getPrimaryNodeType().hasOrderableChildNodes());          Node n1 = test.addNode(a);         Node n2 = test.addNode(b);         session.save();          NodeIterator it = test.getNodes();         assertEquals(a it.nextNode().getName());         assertEquals(b it.nextNode().getName());      code", "A_clean_title": ["call", "addnod", "add", "node", "node", "that", "ha", "order", "child", "node", "violat", "specificationit", "seem", "me", "that", "current", "behavior", "node", "addnod", "add", "node", "node", "that", "ha", "order", "child", "node", "violat", "specif", "section", "23", "quot", "23", "ad", "new", "child", "node", "when", "child", "node", "ad", "node", "that", "ha", "order", "child", "node", "it", "ad", "end", "list", "quot", "howev", "follow", "test", "will", "fail", "code", "test", "public", "void", "testaddnod", "test", "add", "node", "throw", "except", "new", "testcontentload", "test", "content", "loader", "loadtestcont", "load", "test", "content", "getadminsess", "get", "admin", "session", "session", "session", "getadminsess", "get", "admin", "session", "node", "test", "session", "getrootnod", "get", "root", "node", "addnod", "add", "node", "test", "test", "orderablefold", "order", "folder", "asserttru", "assert", "true", "test", "getprimarynodetyp", "get", "primari", "node", "type", "hasorderablechildnod", "ha", "order", "child", "node", "node", "n1", "test", "addnod", "add", "node", "node", "n2", "test", "addnod", "add", "node", "session", "save", "nodeiter", "node", "iter", "it", "test", "getnod", "get", "node", "assertequ", "assert", "equal", "it", "nextnod", "next", "node", "getnam", "get", "name", "assertequ", "assert", "equal", "it", "nextnod", "next", "node", "getnam", "get", "name", "code"], "B_title": "Calling addNode on a node that has orderable child nodes violates specification", "B_clean_title": ["call", "addnod", "add", "node", "node", "that", "ha", "order", "child", "node", "violat", "specif"]},
{"A_title": "StatelessForm submitted to the wrong pageI made a small application to reproduce the problem. You can download it from http://aditsu.net/wickettest.zip  Ill try to attach it too. Dependencies: jetty 6 wicket 1.4-m3 slf4j log4j Steps to reproduce: 1. Run the test.Start class 2. Open http://localhost:8080 in a browser 3. Open http://localhost:8080/page2 in a new tab 4. Go to the first tab and click submit  Result:  WicketRuntimeException: unable to find component with path form on stateless page Page class = test.Page2 id = 0 version = 0  It looks like the 2 pages are created with the same id in 2 different pagemaps but when I submit the form it goes to the second pagemap and finds the second page (with no form on it).", "A_clean_title": ["statelessform", "stateless", "form", "submit", "wrong", "pagei", "page", "made", "small", "applic", "reproduc", "problem", "you", "download", "it", "http", "zip", "aditsu", "net", "wickettest", "ill", "tri", "attach", "it", "too", "depend", "jetti", "wicket", "m3", "slf4j", "log4j", "step", "reproduc", "run", "test", "start", "class", "open", "http", "localhost:8080", "browser", "open", "http", "localhost:8080", "page2", "new", "tab", "go", "first", "tab", "click", "submit", "result", "wicketruntimeexcept", "wicket", "runtim", "except", "unabl", "find", "compon", "path", "form", "stateless", "page", "page", "class", "test", "page2", "id", "version", "it", "look", "like", "page", "are", "creat", "same", "id", "differ", "pagemap", "but", "when", "submit", "form", "it", "goe", "second", "pagemap", "find", "second", "page", "no", "form", "it"], "B_title": "StatelessForm submitted to the wrong page Issue: WICKET-1897", "B_clean_title": ["statelessform", "stateless", "form", "submit", "wrong", "page", "issu", "wicket", "1897"]},
{"A_title": "BaseWicketTester#startComponentInPage fails for pages with <wicket:header-items></wicket:header> placeholderI am using the BaseWicketTester.html#startComponentInPage(C)|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#startComponentInPage(C) to validate individual components/panels.  I am overriding the BaseWicketTester.html#createPage()|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#createPage() and BaseWicketTester.html#createPageMarkup(java.lang.String)|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#createPageMarkup(java.lang.String) methods to return a dummy page that contains a placeholder for components-to-be-tested. The dummy page extends my base page class.  My base page class makes use of the <wicket:header-items/>|https://cwiki.apache.org/confluence/display/WICKET/Wickets+XHTML+tags#WicketsXHTMLtags-Elementwicket:header-items placeholder tag.  When attempting to use BaseWicketTester.html#createPage()|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#createPage() method the method fails with the following error message: |Error while parsing the markup for the autogenerated page: More than one <wicket:header-items/> detected in the <head> element. Only one is allowed.  If I remove the <wicket:header-items/>|https://cwiki.apache.org/confluence/display/WICKET/Wickets+XHTML+tags#WicketsXHTMLtags-Elementwicket:header-items placeholder tag from my base page class the test runs successfully.  The test only fails when using the BaseWicketTester.html#startComponentInPage(C)|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#startComponentInPage(C) which only accepts one argument. If I use the BaseWicketTester.html#startComponentInPage(C org.apache.wicket.markup.IMarkupFragment)|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/util/tester/BaseWicketTester.html#startComponentInPage(C org.apache.wicket.markup.IMarkupFragment) and pass in the MarkupFragment of the test class as the second argument then the test runs successfully e.g.  code tester.startComponentInPage(new MyPanel(DummyPanelPage.TEST_PANEL_ID)  new MyDummyPanelPage(new PageParameters()).getMarkup()); code  It would seem that the <wicket:header-items/>|https://cwiki.apache.org/confluence/display/WICKET/Wickets+XHTML+tags#WicketsXHTMLtags-Elementwicket:header-items placeholder tag clashes with the ContainerInfo|https://ci.apache.org/projects/wicket/apidocs/6.x/org/apache/wicket/markup/ContainerInfo.html class used by the testing framework but this is by no means my area of expertise.  I am attaching a quick-start app with a TestHomePage test class that reproduces the issue.  Thank you in advance!", "A_clean_title": ["basewickettest", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "fail", "page", "wicket", "header", "item", "wicket", "header", "placeholderi", "placehold", "am", "basewickettest", "html", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "valid", "individu", "compon", "panel", "am", "overrid", "basewickettest", "html", "base", "wicket", "tester", "createpag", "creat", "page", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "createpag", "creat", "page", "basewickettest", "html", "base", "wicket", "tester", "createpagemarkup", "creat", "page", "markup", "java", "lang", "string", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "createpagemarkup", "creat", "page", "markup", "java", "lang", "string", "method", "return", "dummi", "page", "that", "contain", "placehold", "compon", "test", "dummi", "page", "extend", "my", "base", "page", "class", "my", "base", "page", "class", "make", "use", "wicket", "header", "item", "|http", "apach", "cwiki", "org", "confluenc", "display", "wicket", "wickets+xhtml+tag", "wicketsxhtmltag", "elementwicket", "wicket", "xhtm", "ltag", "header", "item", "placehold", "tag", "when", "attempt", "use", "basewickettest", "html", "base", "wicket", "tester", "createpag", "creat", "page", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "createpag", "creat", "page", "method", "method", "fail", "follow", "error", "messag", "|error", "while", "pars", "markup", "autogener", "page", "more", "than", "one", "wicket", "header", "item", "detect", "head", "element", "onli", "one", "allow", "remov", "wicket", "header", "item", "|http", "apach", "cwiki", "org", "confluenc", "display", "wicket", "wickets+xhtml+tag", "wicketsxhtmltag", "elementwicket", "wicket", "xhtm", "ltag", "header", "item", "placehold", "tag", "my", "base", "page", "class", "test", "run", "success", "test", "onli", "fail", "when", "basewickettest", "html", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "which", "onli", "accept", "one", "argument", "use", "basewickettest", "html", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "org", "apach", "wicket", "markup", "imarkupfrag", "markup", "fragment", "|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "util", "tester", "basewickettest", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "org", "apach", "wicket", "markup", "imarkupfrag", "markup", "fragment", "pass", "markupfrag", "markup", "fragment", "test", "class", "as", "second", "argument", "then", "test", "run", "success", "code", "tester", "startcomponentinpag", "start", "compon", "page", "new", "mypanel", "my", "panel", "dummypanelpag", "dummi", "panel", "page", "test", "panel", "id", "new", "mydummypanelpag", "my", "dummi", "panel", "page", "new", "pageparamet", "page", "paramet", "getmarkup", "get", "markup", "code", "it", "would", "seem", "that", "wicket", "header", "item", "|http", "apach", "cwiki", "org", "confluenc", "display", "wicket", "wickets+xhtml+tag", "wicketsxhtmltag", "elementwicket", "wicket", "xhtm", "ltag", "header", "item", "placehold", "tag", "clash", "containerinfo|http", "contain", "info|http", "apach", "html", "ci", "org", "project", "wicket", "apidoc", "org", "apach", "wicket", "markup", "containerinfo", "contain", "info", "class", "use", "by", "test", "framework", "but", "thi", "by", "no", "mean", "my", "area", "expertis", "am", "attach", "quick", "start", "app", "testhomepag", "test", "home", "page", "test", "class", "that", "reproduc", "issu", "thank", "you", "advanc"], "B_title": "BaseWicketTester#startComponentInPage fails for pages with <wicket:header-items></wicket:header> placeholder", "B_clean_title": ["basewickettest", "base", "wicket", "tester", "startcomponentinpag", "start", "compon", "page", "fail", "page", "wicket", "header", "item", "wicket", "header", "placehold"]},
{"A_title": "Obvious optimizations dont works in inline ifNone", "A_clean_title": ["obviou", "optim", "dont", "work", "inlin", "ifnon", "none"], "B_title": "Fix more regressions caused by TRUE/FALSE denormalization. Fixes issue 413", "B_clean_title": ["fix", "more", "regress", "caus", "by", "true", "fals", "denorm", "fix", "issu", "413"]},
{"A_title": "Error while configuring analyzer by compositionError while creating analyzer by composition from osgi due to an illegal argument jcr:primaryType passed to TokenizerFactory.forName(clazz args) in NodeStateAnalyzerFactory.loadTokenizer()  noformat Caused by: java.lang.IllegalArgumentException: Unknown parameters: jcr:primaryType=nt:unstructured at org.apache.lucene.analysis.core.LowerCaseFilterFactory.<init>(LowerCaseFilterFactory.java:45) noformat", "A_clean_title": ["error", "while", "configur", "analyz", "by", "compositionerror", "composit", "error", "while", "creat", "analyz", "by", "composit", "osgi", "due", "illeg", "argument", "jcr", "primarytyp", "primari", "type", "pass", "tokenizerfactori", "fornam", "token", "factori", "name", "clazz", "arg", "nodestateanalyzerfactori", "loadtoken", "node", "state", "analyz", "factori", "load", "token", "noformat", "caus", "by", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "unknown", "paramet", "jcr", "primarytype=nt", "primari", "type=nt", "unstructur", "at", "org", "apach", "lucen", "analysi", "core", "lowercasefilterfactori", "lower", "case", "filter", "factori", "init", "lowercasefilterfactori", "java:45", "lower", "case", "filter", "factori", "noformat"], "B_title": "- Error while configuring analyzer by composition", "B_clean_title": ["error", "while", "configur", "analyz", "by", "composit"]},
{"A_title": "Beta LogNormalDistribution WeibullDistribution give slightly wrong answer for extremely small args due to log/exp inaccuracyBackground for those who arent familiar: math libs like Math and FastMath have two mysterious methods log1p and expm1. log1p(x) = log(1+x) and expm1(x) = exp(x)-1 mathetmatically but can return a correct answer even when x was small where floating-point error due to the addition/subtraction introduces a relatively large error.  There are three instances in the code that can employ these specialized methods and gain a measurable improvement in accuracy. See patch and tests for an example -- try the tests without the code change to see the error.", "A_clean_title": ["beta", "lognormaldistribut", "log", "normal", "distribut", "weibulldistribut", "weibul", "distribut", "give", "slightli", "wrong", "answer", "extrem", "small", "arg", "due", "log", "exp", "inaccuracybackground", "inaccuraci", "background", "those", "who", "arent", "familiar", "math", "lib", "like", "math", "fastmath", "fast", "math", "have", "two", "mysteri", "method", "log1p", "expm1", "log1p", "log", "1+x", "expm1", "exp", "mathetmat", "but", "return", "correct", "answer", "even", "when", "wa", "small", "where", "float", "point", "error", "due", "addit", "subtract", "introduc", "rel", "larg", "error", "there", "are", "three", "instanc", "code", "that", "employ", "these", "special", "method", "gain", "measur", "improv", "accuraci", "see", "patch", "test", "exampl", "tri", "test", "without", "code", "chang", "see", "error"], "B_title": "Precision improvements by using expm1 and log1p. Thanks to Sean Owen.", "B_clean_title": ["precis", "improv", "by", "expm1", "log1p", "thank", "sean", "owen"]},
{"A_title": "onBeforeRender called too early on stateless pageIm having a problem with a ListView that displays an outdated list. In my test the ListView uses a Model that returns a static variable just to make sure the model is independent from any page instance. As far as I can tell this problem has nothing to do with the model but with the way Wicket prepares for a request listener invocation.  The exact setup is this: - the page contains a ListView and (outside of the list) a Link that adds an item to the list in its onClick(). The list itself is stored in a static variable. - the page is stateless - the pages components are created in onInitialize()  Result: The list doesnt show the most recently added item. Reloading the original page shows the correct list. Note that by reloading I mean entering the pages original URL since the browsers address bar now contains the request listener URL due to the page being stateless.  This is how I think is happens: - Initially rendering the page works fine. The page is then discarded since its stateless. - Clicking on the link creates a new page instance to invoke the links request listener. - IPageAndComponentProvider.getComponent() cannot find the link yet since it is not created until onInitialize() has been called. - as a consequence it calls page.internalInitialize() and internalPrepareForRender(false) - this creates the link but it also creates the ListView and prepares it for rendering. This in turn polls the ListViews model and creates list items. It also marks the ListView as prepared for render which is the crucial point. - The links request listener runs and adds an item to the list. - After the request listener handler the page render handler runs - That handler renders the page including the ListView - ... but it doesnt call onBeforeRender() on the ListView anymore because its already marked as prepared for render! So it doesnt pick up the new up-to-date list from its model.  Im not sure if Im doing it wrong but then it doesnt seem quite right that onBeforeRender() gets called before invoking the listener but not actually before rendering. Theres probably some kind of logic behind the decision to run onBeforeRender() only when this hasnt yet happened right? Is there a general way to unprepare the component in onClick()?  --- Re: #internalPrepareForRender(false) should not mark the page as rendered (thus the false parameter).  The problem is I think not that the component is being marked as *rendered* but as *prepared for render*. From class Component:  protected void onBeforeRender()    setFlag(FLAG_PREPARED_FOR_RENDER true);   onBeforeRenderChildren();   setRequestFlag(RFLAG_BEFORE_RENDER_SUPER_CALL_VERIFIED true);   Note the first line. This causes subsequent invocations of internalBeforeRender() to skip the relevant part.", "A_clean_title": ["onbeforerend", "befor", "render", "call", "too", "earli", "stateless", "pageim", "page", "im", "have", "problem", "listview", "list", "view", "that", "display", "outdat", "list", "my", "test", "listview", "list", "view", "use", "model", "that", "return", "static", "variabl", "just", "make", "sure", "model", "independ", "ani", "page", "instanc", "as", "far", "as", "tell", "thi", "problem", "ha", "noth", "model", "but", "way", "wicket", "prepar", "request", "listen", "invoc", "exact", "setup", "thi", "page", "contain", "listview", "list", "view", "outsid", "list", "link", "that", "add", "item", "list", "it", "onclick", "click", "list", "itself", "store", "static", "variabl", "page", "stateless", "page", "compon", "are", "creat", "oniniti", "initi", "result", "list", "doesnt", "show", "most", "recent", "ad", "item", "reload", "origin", "page", "show", "correct", "list", "note", "that", "by", "reload", "mean", "enter", "page", "origin", "url", "sinc", "browser", "address", "bar", "now", "contain", "request", "listen", "url", "due", "page", "be", "stateless", "thi", "how", "think", "happen", "initi", "render", "page", "work", "fine", "page", "then", "discard", "sinc", "it", "stateless", "click", "link", "creat", "new", "page", "instanc", "invok", "link", "request", "listen", "ipageandcomponentprovid", "getcompon", "page", "compon", "provid", "get", "compon", "not", "find", "link", "yet", "sinc", "it", "not", "creat", "until", "oniniti", "initi", "ha", "been", "call", "as", "consequ", "it", "call", "page", "internaliniti", "intern", "initi", "internalprepareforrend", "intern", "prepar", "render", "fals", "thi", "creat", "link", "but", "it", "also", "creat", "listview", "list", "view", "prepar", "it", "render", "thi", "turn", "poll", "listview", "list", "view", "model", "creat", "list", "item", "it", "also", "mark", "listview", "list", "view", "as", "prepar", "render", "which", "crucial", "point", "link", "request", "listen", "run", "add", "item", "list", "after", "request", "listen", "handler", "page", "render", "handler", "run", "that", "handler", "render", "page", "includ", "listview", "list", "view", "but", "it", "doesnt", "call", "onbeforerend", "befor", "render", "listview", "list", "view", "anymor", "becaus", "it", "alreadi", "mark", "as", "prepar", "render", "so", "it", "doesnt", "pick", "up", "new", "up", "date", "list", "it", "model", "im", "not", "sure", "im", "do", "it", "wrong", "but", "then", "it", "doesnt", "seem", "quit", "right", "that", "onbeforerend", "befor", "render", "get", "call", "befor", "invok", "listen", "but", "not", "actual", "befor", "render", "there", "probabl", "some", "kind", "logic", "behind", "decis", "run", "onbeforerend", "befor", "render", "onli", "when", "thi", "hasnt", "yet", "happen", "right", "there", "gener", "way", "unprepar", "compon", "onclick", "click", "re", "internalprepareforrend", "intern", "prepar", "render", "fals", "not", "mark", "page", "as", "render", "thu", "fals", "paramet", "problem", "think", "not", "that", "compon", "be", "mark", "as", "render", "but", "as", "prepar", "render", "class", "compon", "protect", "void", "onbeforerend", "befor", "render", "setflag", "set", "flag", "flag", "prepar", "render", "true", "onbeforerenderchildren", "befor", "render", "children", "setrequestflag", "set", "request", "flag", "rflag", "befor", "render", "super", "call", "verifi", "true", "note", "first", "line", "thi", "caus", "subsequ", "invoc", "internalbeforerend", "intern", "befor", "render", "skip", "relev", "part"], "B_title": "always reset FLAG_PREPARED_FOR_RENDER so stateless page is re-prepared before next render", "B_clean_title": ["alway", "reset", "flag", "prepar", "render", "so", "stateless", "page", "re", "prepar", "befor", "next", "render"]},
{"A_title": "404 Error on Nested ModalWindows in IE7 and IE8When opening a ModalWindow inside a ModalWindow the inner ModalWindow generates a 404 error.  Both windows use a PageCreator for content.  To replicate you must use an actual IE 7 or IE 8 browser as this does not replicate using developer tools and setting the document and brower to IE 7.  The problem can be seen at http://www.wicket-library.com/wicket-examples/ajax/modal-window.  I will attach a Quickstart as well.", "A_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8when", "open", "modalwindow", "modal", "window", "insid", "modalwindow", "modal", "window", "inner", "modalwindow", "modal", "window", "gener", "404", "error", "both", "window", "use", "pagecr", "page", "creator", "content", "replic", "you", "must", "use", "actual", "ie", "or", "ie", "browser", "as", "thi", "not", "replic", "develop", "tool", "set", "document", "brower", "ie", "problem", "seen", "at", "http", "window", "wicket", "librari", "exampl", "ajax", "modal", "www", "com", "wicket", "will", "attach", "quickstart", "as", "well"], "B_title": "404 Error on Nested ModalWindows in IE7 and IE8", "B_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8"]},
{"A_title": "chiSquare(double expected long observed) is returning incorrect test statisticChiSquareTestImpl is returning incorrect chi-squared value. An implicit assumption of public double chiSquare(double expected long observed) is that the sum of expected and observed are equal. That is in the code: for (int i = 0; i < observed.length; i++)               dev = ((double) observedi - expectedi);             sumSq += dev * dev / expectedi;          this calculation is only correct if sum(observed)==sum(expected). When they are not equal then one must rescale the expected value by sum(observed) / sum(expected) so that they are. Ironically it is an example in the unit test ChiSquareTestTest that highlights the error: long observed1 =   500 623 72 70 31  ;         double expected1 =   485 541 82 61 37  ;         assertEquals( chi-square test statistic 16.4131070362 testStatistic.chiSquare(expected1 observed1) 1E-10);         assertEquals(chi-square p-value 0.002512096 testStatistic.chiSquareTest(expected1 observed1) 1E-9); 16.413 is not correct because the expected values do not make sense they should be: 521.19403 581.37313  88.11940  65.55224  39.76119 so that the sum of expected equals 1296 which is the sum of observed. Here is some R code (r-project.org) which proves it: > o1 1 500 623  72  70  31 > e1 1 485 541  82  61  37 > chisq.test(o1p=e1rescale.p=TRUE)         Chi-squared test for given probabilities data:  o1  X-squared = 9.0233 df = 4 p-value = 0.06052 > chisq.test(o1p=e1rescale.p=TRUE) observed 1 500 623  72  70  31 > chisq.test(o1p=e1rescale.p=TRUE) expected 1 521.19403 581.37313  88.11940  65.55224  39.76119", "A_clean_title": ["chisquar", "chi", "squar", "doubl", "expect", "long", "observ", "return", "incorrect", "test", "statisticchisquaretestimpl", "statist", "chi", "squar", "test", "impl", "return", "incorrect", "chi", "squar", "valu", "implicit", "assumpt", "public", "doubl", "chisquar", "chi", "squar", "doubl", "expect", "long", "observ", "that", "sum", "expect", "observ", "are", "equal", "that", "code", "int", "observ", "length", "i++", "dev", "doubl", "observedi", "expectedi", "sumsq", "sum", "sq", "dev", "dev", "expectedi", "thi", "calcul", "onli", "correct", "sum", "observ", "==sum", "expect", "when", "they", "are", "not", "equal", "then", "one", "must", "rescal", "expect", "valu", "by", "sum", "observ", "sum", "expect", "so", "that", "they", "are", "iron", "it", "exampl", "unit", "test", "chisquaretesttest", "chi", "squar", "test", "test", "that", "highlight", "error", "long", "observed1", "500", "623", "72", "70", "31", "doubl", "expected1", "485", "541", "82", "61", "37", "assertequ", "assert", "equal", "chi", "squar", "test", "statist", "16", "4131070362", "teststatist", "chisquar", "test", "statist", "chi", "squar", "expected1", "observed1", "1e", "10", "assertequ", "assert", "equal", "chi", "squar", "valu", "002512096", "teststatist", "chisquaretest", "test", "statist", "chi", "squar", "test", "expected1", "observed1", "1e", "16", "413", "not", "correct", "becaus", "expect", "valu", "not", "make", "sens", "they", "521", "19403", "581", "37313", "88", "11940", "65", "55224", "39", "76119", "so", "that", "sum", "expect", "equal", "1296", "which", "sum", "observ", "here", "some", "code", "project", "org", "which", "prove", "it", "o1", "500", "623", "72", "70", "31", "e1", "485", "541", "82", "61", "37", "chisq", "test", "o1p=e1rescal", "p=true", "chi", "squar", "test", "given", "probabl", "data", "o1", "squar", "0233", "df", "valu", "06052", "chisq", "test", "o1p=e1rescal", "p=true", "observ", "500", "623", "72", "70", "31", "chisq", "test", "o1p=e1rescal", "p=true", "expect", "521", "19403", "581", "37313", "88", "11940", "65", "55224", "39", "76119"], "B_title": "Added check and rescaling of expected counts to sum to sum of expected counts if necessary in ChiSquare test. JIRA: MATH-175 Reported and patched by Carl Anderson.", "B_clean_title": ["ad", "check", "rescal", "expect", "count", "sum", "sum", "expect", "count", "necessari", "chisquar", "chi", "squar", "test", "jira", "math", "175", "report", "patch", "by", "carl", "anderson"]},
{"A_title": "Integer overflow in OpenMapRealMatrixcomputeKey() has an integer overflow. Since it is a sparse matrix this is quite easily encountered long before heap space is exhausted. The attached code demonstrates the problem which could potentially be a security vulnerability (for example if one was to use this matrix to store access control information). Workaround: never create an OpenMapRealMatrix with more cells than are addressable with an int.", "A_clean_title": ["integ", "overflow", "openmaprealmatrixcomputekey", "open", "map", "real", "matrixcomput", "key", "ha", "integ", "overflow", "sinc", "it", "spars", "matrix", "thi", "quit", "easili", "encount", "long", "befor", "heap", "space", "exhaust", "attach", "code", "demonstr", "problem", "which", "could", "potenti", "secur", "vulner", "exampl", "one", "wa", "use", "thi", "matrix", "store", "access", "control", "inform", "workaround", "never", "creat", "openmaprealmatrix", "open", "map", "real", "matrix", "more", "cell", "than", "are", "address", "int"], "B_title": "Fixed an integer overflow in OpenMapRealMatrix.", "B_clean_title": ["fix", "integ", "overflow", "openmaprealmatrix", "open", "map", "real", "matrix"]},
{"A_title": "Inconsistent handling of invalid names/pathsPassing an invalid name to a JCR method might or might not throw a RepositoryException depending on whether name re-mappings exist or not:  code session.itemExists(/jcr:content); code  returns false if no name re-mappings exist but throws a RepositoryException otherwise.", "A_clean_title": ["inconsist", "handl", "invalid", "name", "pathspass", "path", "pass", "invalid", "name", "jcr", "method", "might", "or", "might", "not", "throw", "repositoryexcept", "repositori", "except", "depend", "whether", "name", "re", "map", "exist", "or", "not", "code", "session", "itemexist", "item", "exist", "jcr", "content", "code", "return", "fals", "no", "name", "re", "map", "exist", "but", "throw", "repositoryexcept", "repositori", "except", "otherwis"], "B_title": "Inconsistent handling of invalid names/paths", "B_clean_title": ["inconsist", "handl", "invalid", "name", "path"]},
{"A_title": "NPE in FormComponent#updateCollectionModel in case of no converted input and unmodifiable collectionThere are 2 issues with FormComponent#updateCollectionModel. 1) converted input is not checked for null before wrapping it to ArrayList 2) converted input is not checked for null then model returns unmodifiable collection. The both issues causes NPE.", "A_clean_title": ["npe", "formcompon", "form", "compon", "updatecollectionmodel", "updat", "collect", "model", "case", "no", "convert", "input", "unmodifi", "collectionther", "collect", "there", "are", "issu", "formcompon", "form", "compon", "updatecollectionmodel", "updat", "collect", "model", "convert", "input", "not", "check", "null", "befor", "wrap", "it", "arraylist", "array", "list", "convert", "input", "not", "check", "null", "then", "model", "return", "unmodifi", "collect", "both", "issu", "caus", "npe"], "B_title": "FormComponent#updateCollectionModel must check convertedInput for null before wrapping into ArrayListFormComponent#updateCollectionModel must check convertedInput for null before wrapping into ArrayList", "B_clean_title": ["formcompon", "form", "compon", "updatecollectionmodel", "updat", "collect", "model", "must", "check", "convertedinput", "convert", "input", "null", "befor", "wrap", "into", "arraylistformcompon", "array", "list", "form", "compon", "updatecollectionmodel", "updat", "collect", "model", "must", "check", "convertedinput", "convert", "input", "null", "befor", "wrap", "into", "arraylist", "array", "list"]},
{"A_title": "CreditCardValidator accepts invalid inputs(1) The onValidate() method of the CreditCardValidator class returns true for invalid inputs with null or unicode character such as 400000000000000.  (2) Also there is no length check on the input therefore even invalid length inputs such as 9845 are accepted.  (3) There is no check for invalid issuer identifier i.e.  840898920205250 is accepted where 84XXXX is not a valid issuer identifier", "A_clean_title": ["creditcardvalid", "credit", "card", "valid", "accept", "invalid", "input", "onvalid", "valid", "method", "creditcardvalid", "credit", "card", "valid", "class", "return", "true", "invalid", "input", "null", "or", "unicod", "charact", "such", "as", "400000000000000", "also", "there", "no", "length", "check", "input", "therefor", "even", "invalid", "length", "input", "such", "as", "9845", "are", "accept", "there", "no", "check", "invalid", "issuer", "identifi", "840898920205250", "accept", "where", "84xxxx", "not", "valid", "issuer", "identifi"], "B_title": "fixed CreditCardValidator accepts invalid inputs Issue: WICKET-2552", "B_clean_title": ["fix", "creditcardvalid", "credit", "card", "valid", "accept", "invalid", "input", "issu", "wicket", "2552"]},
{"A_title": "Upgrade should not overwrite new oak specific builtin nodetypesNone", "A_clean_title": ["upgrad", "not", "overwrit", "new", "oak", "specif", "builtin", "nodetypesnon", "nodetyp", "none"], "B_title": "Upgrade should not overwrite new oak specific builtin nodetypes", "B_clean_title": ["upgrad", "not", "overwrit", "new", "oak", "specif", "builtin", "nodetyp"]},
{"A_title": ".indexOf fails to produce missing property warningNone", "A_clean_title": ["indexof", "index", "fail", "produc", "miss", "properti", "warningnon", "warn", "none"], "B_title": "Treat the bottom function type as empty. Fixes issue 301.", "B_clean_title": ["treat", "bottom", "function", "type", "as", "empti", "fix", "issu", "301"]},
{"A_title": "Prototype methods cant be used from the constructor in case prototype is explicitly defined.None", "A_clean_title": ["prototyp", "method", "cant", "use", "constructor", "case", "prototyp", "explicitli", "defin", "none"], "B_title": "Support chrome-teams style of defining prototypes. Fixes issue 537", "B_clean_title": ["support", "chrome", "team", "style", "defin", "prototyp", "fix", "issu", "537"]},
{"A_title": "Commit.rollback() may remove changes from other commitCommit.rollback() removes documents it previously created. With concurrent commits it may happen that this method removes documents some other commit modified in the meantime.", "A_clean_title": ["commit", "rollback", "may", "remov", "chang", "other", "commitcommit", "rollback", "commit", "commit", "remov", "document", "it", "previous", "creat", "concurr", "commit", "it", "may", "happen", "that", "thi", "method", "remov", "document", "some", "other", "commit", "modifi", "meantim"], "B_title": "Commit.rollback() may remove changes from other commit", "B_clean_title": ["commit", "rollback", "may", "remov", "chang", "other", "commit"]},
{"A_title": "BrentOptimizer not always reporting the best pointBrentOptimizer (package o.a.c.m.optimization.univariate) does not check that the point it is going to return is indeed the best one it has encountered. Indeed the last evaluated point might be slightly worse than the one before last.", "A_clean_title": ["brentoptim", "brent", "optim", "not", "alway", "report", "best", "pointbrentoptim", "point", "brent", "optim", "packag", "optim", "univari", "not", "check", "that", "point", "it", "go", "return", "inde", "best", "one", "it", "ha", "encount", "inde", "last", "evalu", "point", "might", "slightli", "wors", "than", "one", "befor", "last"], "B_title": "(second take). Best point must be returned.", "B_clean_title": ["second", "take", "best", "point", "must", "return"]},
{"A_title": "DebugBar throws an java.lang.ExceptionInInitializerError when Tomcat is restartedI have just added the DebugBar to our base page and since then when Tomcat is restarted and session would be reloaded by this it throws this exception:  1    ERROR org.apache.catalina.session.ManagerBase  - Exception loading sessions from persistent storage java.lang.ExceptionInInitializerError at sun.misc.Unsafe.ensureClassInitialized(Native Method) at sun.reflect.UnsafeFieldAccessorFactory.newFieldAccessor(UnsafeFieldAccessorFactory.java:25) at sun.reflect.ReflectionFactory.newFieldAccessor(ReflectionFactory.java:122) at java.lang.reflect.Field.acquireFieldAccessor(Field.java:918) at java.lang.reflect.Field.getFieldAccessor(Field.java:899) at java.lang.reflect.Field.getLong(Field.java:528) at java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1614) at java.io.ObjectStreamClass.access 700(ObjectStreamClass.java:52) at java.io.ObjectStreamClass 2.run(ObjectStreamClass.java:425) at java.security.AccessController.doPrivileged(Native Method) at java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:413) at java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:310) at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:547) at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1583) at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1496) at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1583) at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1496) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1732) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1667) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1323) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.defaultReadObject(ObjectInputStream.java:480) at org.apache.wicket.Component.readObject(Component.java:4469) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:974) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1849) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1667) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1323) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:351) at java.util.concurrent.CopyOnWriteArrayList.readObject(CopyOnWriteArrayList.java:845) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:974) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1849) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1871) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1667) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1323) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1947) at java.io.ObjectInputStream.defaultReadObject(ObjectInputStream.java:480) at org.apache.wicket.Page.readPageObject(Page.java:1349) at org.apache.wicket.Component.readObject(Component.java:4465) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:974) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1849) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:351) at org.apache.wicket.protocol.http.SecondLevelCacheSessionStore SecondLevelCachePageMap.readObject(SecondLevelCacheSessionStore.java:412) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:974) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1849) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1753) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1329) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:351) at org.apache.catalina.session.StandardSession.readObject(StandardSession.java:1407) at org.apache.catalina.session.StandardSession.readObjectData(StandardSession.java:931) at org.apache.catalina.session.StandardManager.doLoad(StandardManager.java:394) at org.apache.catalina.session.StandardManager.load(StandardManager.java:321) at org.apache.catalina.session.StandardManager.start(StandardManager.java:637) at org.apache.catalina.core.ContainerBase.setManager(ContainerBase.java:432) at org.apache.catalina.core.StandardContext.start(StandardContext.java:4160) at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1014) at org.apache.catalina.core.StandardHost.start(StandardHost.java:736) at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1014) at org.apache.catalina.core.StandardEngine.start(StandardEngine.java:443) at org.apache.catalina.core.StandardService.start(StandardService.java:448) at org.apache.catalina.core.StandardServer.start(StandardServer.java:700) at org.apache.catalina.startup.Catalina.start(Catalina.java:552) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:295) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:433) Caused by: org.apache.wicket.WicketRuntimeException: There is no application attached to current thread main at org.apache.wicket.Application.get(Application.java:178) at org.apache.wicket.devutils.debugbar.DebugBar.getContributors(DebugBar.java:146) at org.apache.wicket.devutils.debugbar.DebugBar.registerContributor(DebugBar.java:140) at org.apache.wicket.devutils.debugbar.DebugBar.registerStandardContributors(DebugBar.java:152) at org.apache.wicket.devutils.debugbar.DebugBar.<clinit>(DebugBar.java:65) ... 109 more", "A_clean_title": ["debugbar", "debug", "bar", "throw", "java", "lang", "exceptionininitializererror", "except", "initi", "error", "when", "tomcat", "restartedi", "restart", "have", "just", "ad", "debugbar", "debug", "bar", "our", "base", "page", "sinc", "then", "when", "tomcat", "restart", "session", "would", "reload", "by", "thi", "it", "throw", "thi", "except", "error", "org", "apach", "catalina", "session", "managerbas", "manag", "base", "except", "load", "session", "persist", "storag", "java", "lang", "exceptionininitializererror", "except", "initi", "error", "at", "sun", "misc", "unsaf", "ensureclassiniti", "ensur", "class", "initi", "nativ", "method", "at", "sun", "reflect", "unsafefieldaccessorfactori", "newfieldaccessor", "unsaf", "field", "accessor", "factori", "new", "field", "accessor", "unsafefieldaccessorfactori", "java:25", "unsaf", "field", "accessor", "factori", "at", "sun", "reflect", "reflectionfactori", "newfieldaccessor", "reflect", "factori", "new", "field", "accessor", "reflectionfactori", "java:122", "reflect", "factori", "at", "java", "lang", "reflect", "field", "acquirefieldaccessor", "acquir", "field", "accessor", "field", "java:918", "at", "java", "lang", "reflect", "field", "getfieldaccessor", "get", "field", "accessor", "field", "java:899", "at", "java", "lang", "reflect", "field", "getlong", "get", "long", "field", "java:528", "at", "java", "io", "objectstreamclass", "getdeclaredsuid", "object", "stream", "class", "get", "declar", "suid", "objectstreamclass", "java:1614", "object", "stream", "class", "at", "java", "io", "objectstreamclass", "access", "object", "stream", "class", "700", "objectstreamclass", "java:52", "object", "stream", "class", "at", "java", "io", "objectstreamclass", "object", "stream", "class", "run", "objectstreamclass", "java:425", "object", "stream", "class", "at", "java", "secur", "accesscontrol", "doprivileg", "access", "control", "privileg", "nativ", "method", "at", "java", "io", "objectstreamclass", "object", "stream", "class", "init", "objectstreamclass", "java:413", "object", "stream", "class", "at", "java", "io", "objectstreamclass", "lookup", "object", "stream", "class", "objectstreamclass", "java:310", "object", "stream", "class", "at", "java", "io", "objectstreamclass", "initnonproxi", "object", "stream", "class", "init", "non", "proxi", "objectstreamclass", "java:547", "object", "stream", "class", "at", "java", "io", "objectinputstream", "readnonproxydesc", "object", "input", "stream", "read", "non", "proxi", "desc", "objectinputstream", "java:1583", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readclassdesc", "object", "input", "stream", "read", "class", "desc", "objectinputstream", "java:1496", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readnonproxydesc", "object", "input", "stream", "read", "non", "proxi", "desc", "objectinputstream", "java:1583", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readclassdesc", "object", "input", "stream", "read", "class", "desc", "objectinputstream", "java:1496", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1732", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readarray", "object", "input", "stream", "read", "array", "objectinputstream", "java:1667", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1323", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1871", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadobject", "object", "input", "stream", "default", "read", "object", "objectinputstream", "java:480", "object", "input", "stream", "at", "org", "apach", "wicket", "compon", "readobject", "read", "object", "compon", "java:4469", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "java", "io", "objectstreamclass", "invokereadobject", "object", "stream", "class", "invok", "read", "object", "objectstreamclass", "java:974", "object", "stream", "class", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1849", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readarray", "object", "input", "stream", "read", "array", "objectinputstream", "java:1667", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1323", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1871", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject", "object", "input", "stream", "read", "object", "objectinputstream", "java:351", "object", "input", "stream", "at", "java", "util", "concurr", "copyonwritearraylist", "readobject", "copi", "write", "array", "list", "read", "object", "copyonwritearraylist", "java:845", "copi", "write", "array", "list", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "java", "io", "objectstreamclass", "invokereadobject", "object", "stream", "class", "invok", "read", "object", "objectstreamclass", "java:974", "object", "stream", "class", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1849", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1871", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1871", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1871", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readarray", "object", "input", "stream", "read", "array", "objectinputstream", "java:1667", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1323", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadfield", "object", "input", "stream", "default", "read", "field", "objectinputstream", "java:1947", "object", "input", "stream", "at", "java", "io", "objectinputstream", "defaultreadobject", "object", "input", "stream", "default", "read", "object", "objectinputstream", "java:480", "object", "input", "stream", "at", "org", "apach", "wicket", "page", "readpageobject", "read", "page", "object", "page", "java:1349", "at", "org", "apach", "wicket", "compon", "readobject", "read", "object", "compon", "java:4465", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "java", "io", "objectstreamclass", "invokereadobject", "object", "stream", "class", "invok", "read", "object", "objectstreamclass", "java:974", "object", "stream", "class", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1849", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject", "object", "input", "stream", "read", "object", "objectinputstream", "java:351", "object", "input", "stream", "at", "org", "apach", "wicket", "protocol", "http", "secondlevelcachesessionstor", "second", "level", "cach", "session", "store", "secondlevelcachepagemap", "readobject", "second", "level", "cach", "page", "map", "read", "object", "secondlevelcachesessionstor", "java:412", "second", "level", "cach", "session", "store", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "java", "io", "objectstreamclass", "invokereadobject", "object", "stream", "class", "invok", "read", "object", "objectstreamclass", "java:974", "object", "stream", "class", "at", "java", "io", "objectinputstream", "readserialdata", "object", "input", "stream", "read", "serial", "data", "objectinputstream", "java:1849", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readordinaryobject", "object", "input", "stream", "read", "ordinari", "object", "objectinputstream", "java:1753", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject0", "object", "input", "stream", "read", "object0", "objectinputstream", "java:1329", "object", "input", "stream", "at", "java", "io", "objectinputstream", "readobject", "object", "input", "stream", "read", "object", "objectinputstream", "java:351", "object", "input", "stream", "at", "org", "apach", "catalina", "session", "standardsess", "readobject", "standard", "session", "read", "object", "standardsess", "java:1407", "standard", "session", "at", "org", "apach", "catalina", "session", "standardsess", "readobjectdata", "standard", "session", "read", "object", "data", "standardsess", "java:931", "standard", "session", "at", "org", "apach", "catalina", "session", "standardmanag", "doload", "standard", "manag", "load", "standardmanag", "java:394", "standard", "manag", "at", "org", "apach", "catalina", "session", "standardmanag", "load", "standard", "manag", "standardmanag", "java:321", "standard", "manag", "at", "org", "apach", "catalina", "session", "standardmanag", "start", "standard", "manag", "standardmanag", "java:637", "standard", "manag", "at", "org", "apach", "catalina", "core", "containerbas", "setmanag", "contain", "base", "set", "manag", "containerbas", "java:432", "contain", "base", "at", "org", "apach", "catalina", "core", "standardcontext", "start", "standard", "context", "standardcontext", "java:4160", "standard", "context", "at", "org", "apach", "catalina", "core", "containerbas", "start", "contain", "base", "containerbas", "java:1014", "contain", "base", "at", "org", "apach", "catalina", "core", "standardhost", "start", "standard", "host", "standardhost", "java:736", "standard", "host", "at", "org", "apach", "catalina", "core", "containerbas", "start", "contain", "base", "containerbas", "java:1014", "contain", "base", "at", "org", "apach", "catalina", "core", "standardengin", "start", "standard", "engin", "standardengin", "java:443", "standard", "engin", "at", "org", "apach", "catalina", "core", "standardservic", "start", "standard", "servic", "standardservic", "java:448", "standard", "servic", "at", "org", "apach", "catalina", "core", "standardserv", "start", "standard", "server", "standardserv", "java:700", "standard", "server", "at", "org", "apach", "catalina", "startup", "catalina", "start", "catalina", "java:552", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "org", "apach", "catalina", "startup", "bootstrap", "start", "bootstrap", "java:295", "at", "org", "apach", "catalina", "startup", "bootstrap", "main", "bootstrap", "java:433", "caus", "by", "org", "apach", "wicket", "wicketruntimeexcept", "wicket", "runtim", "except", "there", "no", "applic", "attach", "current", "thread", "main", "at", "org", "apach", "wicket", "applic", "get", "applic", "java:178", "at", "org", "apach", "wicket", "devutil", "debugbar", "debugbar", "getcontributor", "debug", "bar", "get", "contributor", "debugbar", "java:146", "debug", "bar", "at", "org", "apach", "wicket", "devutil", "debugbar", "debugbar", "registercontributor", "debug", "bar", "regist", "contributor", "debugbar", "java:140", "debug", "bar", "at", "org", "apach", "wicket", "devutil", "debugbar", "debugbar", "registerstandardcontributor", "debug", "bar", "regist", "standard", "contributor", "debugbar", "java:152", "debug", "bar", "at", "org", "apach", "wicket", "devutil", "debugbar", "debugbar", "debug", "bar", "clinit", "debugbar", "java:65", "debug", "bar", "109", "more"], "B_title": "", "B_clean_title": []},
{"A_title": "DateLexicoder fails to correctly order dates prior to 1970DateLexicoder incorrectly orders dates before 1970 at the end of all other dates.  Therefore the order was correct for all dates if the user only wrote dates before 1970 or only dates after 1970 but not if they did both.  The DateLexicoder should be fixed to store using a signed LongLexicoder internally instead of the ULongLexicoder that it used before.", "A_clean_title": ["datelexicod", "date", "lexicod", "fail", "correctli", "order", "date", "prior", "1970datelexicod", "1970date", "lexicod", "incorrectli", "order", "date", "befor", "1970", "at", "end", "all", "other", "date", "therefor", "order", "wa", "correct", "all", "date", "user", "onli", "wrote", "date", "befor", "1970", "or", "onli", "date", "after", "1970", "but", "not", "they", "did", "both", "datelexicod", "date", "lexicod", "fix", "store", "sign", "longlexicod", "long", "lexicod", "intern", "instead", "ulonglexicod", "long", "lexicod", "that", "it", "use", "befor"], "B_title": "Fix broken DateLexicoder ordering", "B_clean_title": ["fix", "broken", "datelexicod", "date", "lexicod", "order"]},
{"A_title": "SimplexSolver gives bad resultsMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0 in a simple test problem. It works well in commons-math-2.2.", "A_clean_title": ["simplexsolv", "simplex", "solver", "give", "bad", "resultsmethod", "result", "method", "simplexsolv", "optimez", "simplex", "solver", "give", "bad", "result", "common", "math3", "simpl", "test", "problem", "it", "work", "well", "common", "math"], "B_title": "use epsilon criteria when deciding to drop columns after phase 1.", "B_clean_title": ["use", "epsilon", "criteria", "when", "decid", "drop", "column", "after", "phase"]},
{"A_title": "DeserializationFeature.UNWRAP_SINGLE_VALUE_ARRAYS only works for POJOs MapsDocumentation of  DeserializationFeature.UNWRAP_SINGLE_VALUE_ARRAYS only mentiones exceptional behavior for more than one value in the array (If more than one value is found in the array a JsonMappingException is thrown.). But trying to parse  value :   with value as String produces the following Stacktrace: (Parsing as null might be expected instead)   This shouldnt be problematic when using  DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT  but it does not take precedence over DeserializationFeature.UNWRAP_SINGLE_VALUE_ARRAYS (bug?) and still gives me the error from above! Are there any workarounds? I still need to map single element arrays that sometimes appear to be empty. (I am using version 2.5.1 tested also 2.6.0: same behavior)", "A_clean_title": ["deserializationfeatur", "deseri", "featur", "unwrap", "singl", "valu", "array", "onli", "work", "pojo", "poj", "os", "mapsdocument", "map", "document", "deserializationfeatur", "deseri", "featur", "unwrap", "singl", "valu", "array", "onli", "mention", "except", "behavior", "more", "than", "one", "valu", "array", "more", "than", "one", "valu", "found", "array", "jsonmappingexcept", "json", "map", "except", "thrown", "but", "tri", "pars", "valu", "valu", "as", "string", "produc", "follow", "stacktrac", "pars", "as", "null", "might", "expect", "instead", "thi", "shouldnt", "problemat", "when", "deserializationfeatur", "deseri", "featur", "accept", "empti", "array", "as", "null", "object", "but", "it", "not", "take", "preced", "over", "deserializationfeatur", "deseri", "featur", "unwrap", "singl", "valu", "array", "bug", "still", "give", "me", "error", "abov", "are", "there", "ani", "workaround", "still", "need", "map", "singl", "element", "array", "that", "sometim", "appear", "empti", "am", "version", "test", "also", "same", "behavior"], "B_title": "Add enum handling wrt #994", "B_clean_title": ["add", "enum", "handl", "wrt", "994"]},
{"A_title": "Node.getNodes throwing exception if user does not have access to any child nodeWhen trying to obtain child iterator via Node.getNodes InvalidItemStateException is thrown if user does not have access to its content  code:java     @Test     public void testGetChildren() throws Exception          deny(path privilegesFromName(PrivilegeConstants.JCR_ADD_CHILD_NODES));         NodeIterator it1 = testSession.getNode(path).getNodes();         while(it1.hasNext())             Node n = it1.nextNode();             NodeIterator it2 = n.getNodes();               code  Executing above code leads to following exception  noformat javax.jcr.InvalidItemStateException: Item is stale at org.apache.jackrabbit.oak.jcr.delegate.NodeDelegate.getTree(NodeDelegate.java:827) at org.apache.jackrabbit.oak.jcr.delegate.NodeDelegate.getChildren(NodeDelegate.java:336) at org.apache.jackrabbit.oak.jcr.session.NodeImpl 8.perform(NodeImpl.java:546) at org.apache.jackrabbit.oak.jcr.session.NodeImpl 8.perform(NodeImpl.java:543) at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:125) at org.apache.jackrabbit.oak.jcr.session.ItemImpl.perform(ItemImpl.java:113) at org.apache.jackrabbit.oak.jcr.session.NodeImpl.getNodes(NodeImpl.java:543) at org.apache.jackrabbit.oak.jcr.security.authorization.ReadPropertyTest.testGetChildren(ReadPropertyTest.java:135) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at org.apache.jackrabbit.test.AbstractJCRTest.run(AbstractJCRTest.java:464) at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83) at org.junit.runner.JUnitCore.run(JUnitCore.java:157) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:77) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:195) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:63) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:120) noformat  The exception is thrown for path /testroot/node1/rep:policy.   The issue occurs because the NodeIterator it1 includes rep:policy and later when its child are accessed security check leads to exception. Probably the it1 should not include rep:policy as part of child list and filter it out", "A_clean_title": ["node", "getnod", "get", "node", "throw", "except", "user", "not", "have", "access", "ani", "child", "nodewhen", "node", "when", "tri", "obtain", "child", "iter", "via", "node", "getnod", "get", "node", "invaliditemstateexcept", "invalid", "item", "state", "except", "thrown", "user", "not", "have", "access", "it", "content", "code", "java", "test", "public", "void", "testgetchildren", "test", "get", "children", "throw", "except", "deni", "path", "privilegesfromnam", "privileg", "name", "privilegeconst", "privileg", "constant", "jcr", "add", "child", "node", "nodeiter", "node", "iter", "it1", "testsess", "getnod", "test", "session", "get", "node", "path", "getnod", "get", "node", "while", "it1", "hasnext", "ha", "next", "node", "it1", "nextnod", "next", "node", "nodeiter", "node", "iter", "it2", "getnod", "get", "node", "code", "execut", "abov", "code", "lead", "follow", "except", "noformat", "javax", "jcr", "invaliditemstateexcept", "invalid", "item", "state", "except", "item", "stale", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "nodedeleg", "gettre", "node", "deleg", "get", "tree", "nodedeleg", "java:827", "node", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "nodedeleg", "getchildren", "node", "deleg", "get", "children", "nodedeleg", "java:336", "node", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "nodeimpl", "node", "impl", "perform", "nodeimpl", "java:546", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "nodeimpl", "node", "impl", "perform", "nodeimpl", "java:543", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "perform", "session", "deleg", "sessiondeleg", "java:125", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "itemimpl", "perform", "item", "impl", "itemimpl", "java:113", "item", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "nodeimpl", "getnod", "node", "impl", "get", "node", "nodeimpl", "java:543", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "secur", "author", "readpropertytest", "testgetchildren", "read", "properti", "test", "test", "get", "children", "readpropertytest", "java:135", "read", "properti", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "org", "apach", "jackrabbit", "test", "abstractjcrtest", "run", "abstract", "jcr", "test", "abstractjcrtest", "java:464", "abstract", "jcr", "test", "at", "org", "junit", "intern", "runner", "junit38classrunn", "run", "unit38class", "runner", "junit38classrunn", "java:83", "unit38class", "runner", "at", "org", "junit", "runner", "junitcor", "run", "unit", "core", "junitcor", "java:157", "unit", "core", "at", "com", "intellij", "junit4", "junit4ideatestrunn", "startrunnerwitharg", "unit4idea", "test", "runner", "start", "runner", "arg", "junit4ideatestrunn", "java:77", "unit4idea", "test", "runner", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "preparestreamsandstart", "unit", "starter", "prepar", "stream", "start", "junitstart", "java:195", "unit", "starter", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "main", "unit", "starter", "junitstart", "java:63", "unit", "starter", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "com", "intellij", "rt", "execut", "applic", "appmain", "main", "app", "main", "appmain", "java:120", "app", "main", "noformat", "except", "thrown", "path", "testroot", "node1", "rep", "polici", "issu", "occur", "becaus", "nodeiter", "node", "iter", "it1", "includ", "rep", "polici", "later", "when", "it", "child", "are", "access", "secur", "check", "lead", "except", "probabl", "it1", "not", "includ", "rep", "polici", "as", "part", "child", "list", "filter", "it", "out"], "B_title": "- Node.getNodes throwing exception if user does not have access to any child node", "B_clean_title": ["node", "getnod", "get", "node", "throw", "except", "user", "not", "have", "access", "ani", "child", "node"]},
{"A_title": "Form gets submitted using AjaxSubmitBehavior when sub-form has errorsfrom http://www.nabble.com/Should-a-form-submit-when-sub-form-has-error%27s--tt22803314.html  I have a main-form where I add a panel that contains another form. This sub-form contains a formvalidator that gives the error. However the main-form is submitted but the feedbackpanel does show the error message set in the sub-forms validator.  Ill attach 2 patches with testcases displaying the behavior in wicket 1.3 vs 1.4  (As a side note I had to rename the org.apache.wicket.markup.html.form.validation.TestHomePage to org.apache.wicket.markup.html.form.validation.HomePageTest to get the test to run when building wicket)", "A_clean_title": ["form", "get", "submit", "ajaxsubmitbehavior", "ajax", "submit", "behavior", "when", "sub", "form", "ha", "errorsfrom", "http", "form", "submit", "when", "sub", "form", "ha", "error", "nabbl", "www", "com", "27", "tt22803314", "html", "have", "main", "form", "where", "add", "panel", "that", "contain", "anoth", "form", "thi", "sub", "form", "contain", "formvalid", "that", "give", "error", "howev", "main", "form", "submit", "but", "feedbackpanel", "show", "error", "messag", "set", "sub", "form", "valid", "ill", "attach", "patch", "testcas", "display", "behavior", "wicket", "vs", "as", "side", "note", "had", "renam", "org", "apach", "wicket", "markup", "html", "form", "valid", "testhomepag", "test", "home", "page", "org", "apach", "wicket", "markup", "html", "form", "valid", "homepagetest", "home", "page", "test", "get", "test", "run", "when", "build", "wicket"], "B_title": "fixed: Form gets submitted using AjaxSubmitBehavior when sub-form has errors Issue: WICKET-2202", "B_clean_title": ["fix", "form", "get", "submit", "ajaxsubmitbehavior", "ajax", "submit", "behavior", "when", "sub", "form", "ha", "error", "issu", "wicket", "2202"]},
{"A_title": "Resolve table name to table id once in Accumulo input formatAccumuloInputFormat (and I suspect AccumuloOutputFormat) sends the table name to each mapper.  The mapper uses this table name to create a scanner.  In the case of the following events a map reduce job could read from two different table ids.      # start M/R job reading table A  # rename table A (tableId=1) to table C  # rename table B (tableId=2) to table A  If the input format passed table id 1 to the mappers then the renames would not cause a problem.", "A_clean_title": ["resolv", "tabl", "name", "tabl", "id", "onc", "accumulo", "input", "formataccumuloinputformat", "format", "accumulo", "input", "format", "suspect", "accumulooutputformat", "accumulo", "output", "format", "send", "tabl", "name", "each", "mapper", "mapper", "use", "thi", "tabl", "name", "creat", "scanner", "case", "follow", "event", "map", "reduc", "job", "could", "read", "two", "differ", "tabl", "id", "start", "job", "read", "tabl", "renam", "tabl", "tableid=1", "tabl", "id=1", "tabl", "renam", "tabl", "tableid=2", "tabl", "id=2", "tabl", "input", "format", "pass", "tabl", "id", "mapper", "then", "renam", "would", "not", "caus", "problem"], "B_title": "fixed input format w/ mock", "B_clean_title": ["fix", "input", "format", "mock"]},
{"A_title": "NumberUtils.isNumber() Should Return True for Valid Number with a Trailing Decimal PlaceNumberUtils.isNumber() should return true for a valid number ending in a trailing decimal place; e.g. 2. should be considered a number because new BigDecimal(2.) works fine.  This could be done by adding the code below after line 1444 which is the if (charsi == e || charsi == E) block. if (charsi == .)      if (hasDecPoint || hasExp)           // two decimal points or dec in exponent            return false;          return foundDigit; // single trailing decimal point after non-exponent is ok", "A_clean_title": ["numberutil", "isnumb", "number", "util", "number", "return", "true", "valid", "number", "trail", "decim", "placenumberutil", "isnumb", "place", "number", "util", "number", "return", "true", "valid", "number", "end", "trail", "decim", "place", "consid", "number", "becaus", "new", "bigdecim", "big", "decim", "work", "fine", "thi", "could", "done", "by", "ad", "code", "below", "after", "line", "1444", "which", "charsi", "charsi", "block", "charsi", "hasdecpoint", "ha", "dec", "point", "hasexp", "ha", "exp", "two", "decim", "point", "or", "dec", "expon", "return", "fals", "return", "founddigit", "found", "digit", "singl", "trail", "decim", "point", "after", "non", "expon", "ok"], "B_title": "isNumber(String) and createNumber(String) both modified to support 2.. LANG-521", "B_clean_title": ["isnumb", "number", "string", "createnumb", "creat", "number", "string", "both", "modifi", "support", "lang", "521"]},
{"A_title": "ClassUtils.getShortClassName() will not work with an array;  it seems to add a semicolon to the end.A semicolon is introduced into the class name at the end for all arrays... String sArray = new String2; sArray0 = mark; sArray1 = is cool; String simpleString = chris; assertEquals(String ClassUtils.getShortClassName(simpleString null)); assertEquals(String; ClassUtils.getShortClassName(sArray null));", "A_clean_title": ["classutil", "getshortclassnam", "class", "util", "get", "short", "class", "name", "will", "not", "work", "array", "it", "seem", "add", "semicolon", "end", "semicolon", "introduc", "into", "class", "name", "at", "end", "all", "array", "string", "sarray", "array", "new", "string2", "sarray0", "array0", "mark", "sarray1", "array1", "cool", "string", "simplestr", "simpl", "string", "chri", "assertequ", "assert", "equal", "string", "classutil", "getshortclassnam", "class", "util", "get", "short", "class", "name", "simplestr", "simpl", "string", "null", "assertequ", "assert", "equal", "string", "classutil", "getshortclassnam", "class", "util", "get", "short", "class", "name", "sarray", "array", "null"], "B_title": "Applying my patch from LANG-535 - adding support to getShortClassName and getPackageName for arrays including primitive arrays and multi-dimensional arrays. Also stopped getPackageName relying on the underlying class.getPackage as its sometimes null", "B_clean_title": ["appli", "my", "patch", "lang", "535", "ad", "support", "getshortclassnam", "get", "short", "class", "name", "getpackagenam", "get", "packag", "name", "array", "includ", "primit", "array", "multi", "dimension", "array", "also", "stop", "getpackagenam", "get", "packag", "name", "reli", "underli", "class", "getpackag", "get", "packag", "as", "it", "sometim", "null"]},
{"A_title": "AbstractEstimator: getCovariances() and guessParametersErrors() crash when having bound parametersthe two methods getCovariances() and guessParametersErrors() from org.apache.commons.math.estimation.AbstractEstimator crash with ArrayOutOfBounds exception when some of the parameters are bound. The reason is that the Jacobian is calculated only for the unbound parameters. in the code you loop through all parameters. line #166: final int cols = problem.getAllParameters().length; should be replaced by:  final int cols = problem.getUnboundParameters().length; (similar changes could be done in guessParametersErrors()) the dissadvantage of the above bug fix is that what is returned to the user is an array with smaller size than the number of all parameters. Alternatively you can have some logic in the code which writes zeros for the elements of the covariance matrix corresponding to the bound parameters", "A_clean_title": ["abstractestim", "abstract", "estim", "getcovari", "get", "covari", "guessparameterserror", "guess", "paramet", "error", "crash", "when", "have", "bound", "parametersth", "two", "method", "getcovari", "get", "covari", "guessparameterserror", "guess", "paramet", "error", "org", "apach", "common", "math", "estim", "abstractestim", "abstract", "estim", "crash", "arrayoutofbound", "array", "out", "bound", "except", "when", "some", "paramet", "are", "bound", "reason", "that", "jacobian", "calcul", "onli", "unbound", "paramet", "code", "you", "loop", "through", "all", "paramet", "line", "166", "final", "int", "col", "problem", "getallparamet", "get", "all", "paramet", "length", "replac", "by", "final", "int", "col", "problem", "getunboundparamet", "get", "unbound", "paramet", "length", "similar", "chang", "could", "done", "guessparameterserror", "guess", "paramet", "error", "dissadvantag", "abov", "bug", "fix", "that", "what", "return", "user", "array", "smaller", "size", "than", "number", "all", "paramet", "altern", "you", "have", "some", "logic", "code", "which", "write", "zero", "element", "covari", "matrix", "correspond", "bound", "paramet"], "B_title": "fixed crashes in AbstractEstimator when some parameters are bound. getCovariances() and guessParametersErrors() now only give result about unbound parameters JIRA: MATH-200", "B_clean_title": ["fix", "crash", "abstractestim", "abstract", "estim", "when", "some", "paramet", "are", "bound", "getcovari", "get", "covari", "guessparameterserror", "guess", "paramet", "error", "now", "onli", "give", "result", "about", "unbound", "paramet", "jira", "math", "200"]},
{"A_title": "Race leading to IndexOutOfBoundsException when querying for buffer while releasing SpillablePartitionWhen running a code as simple as:   noformat ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();  DataSet<Edge<String NullValue>> edges = getEdgesDataSet(env); Graph<String NullValue NullValue> graph = Graph.fromDataSet(edges env);  DataSet<Tuple2<String Long>> degrees = graph.getDegrees(); degrees.writeAsCsv(outputPath n  ); env.execute();  on the Freindster data set: https://snap.stanford.edu/data/com-Friendster.html; on 30 Wally nodes   I get the following exception: java.lang.Exception: The data preparation for task CoGroup (CoGroup at inDegrees(Graph.java:701))  caused an error: Error obtaining the sorted input: Thread SortMerger Reading Thread terminated due to an exception: Fatal error at remote task manager wally028.cit.tu-berlin.de/130.149.249.38:53730. at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:471) at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:362) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:559) at java.lang.Thread.run(Thread.java:722) Caused by: java.lang.RuntimeException: Error obtaining the sorted input: Thread SortMerger Reading Thread terminated due to an exception: Fatal error at remote task manager wally028.cit.tu-berlin.de/130.149.249.38:53730. at org.apache.flink.runtime.operators.sort.UnilateralSortMerger.getIterator(UnilateralSortMerger.java:607) at org.apache.flink.runtime.operators.RegularPactTask.getInput(RegularPactTask.java:1145) at org.apache.flink.runtime.operators.CoGroupDriver.prepare(CoGroupDriver.java:98) at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:466) ... 3 more Caused by: java.io.IOException: Thread SortMerger Reading Thread terminated due to an exception: Fatal error at remote task manager wally028.cit.tu-berlin.de/130.149.249.38:53730. at org.apache.flink.runtime.operators.sort.UnilateralSortMerger ThreadBase.run(UnilateralSortMerger.java:784) Caused by: org.apache.flink.runtime.io.network.netty.exception.RemoteTransportException: Fatal error at remote task manager wally028.cit.tu-berlin.de/130.149.249.38:53730. at org.apache.flink.runtime.io.network.netty.PartitionRequestClientHandler.decodeMsg(PartitionRequestClientHandler.java:227) at org.apache.flink.runtime.io.network.netty.PartitionRequestClientHandler.channelRead(PartitionRequestClientHandler.java:162) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:339) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:324) at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:339) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:324) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:242) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:339) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:324) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:847) at io.netty.channel.nio.AbstractNioByteChannel NioByteUnsafe.read(AbstractNioByteChannel.java:131) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354) at io.netty.util.concurrent.SingleThreadEventExecutor 2.run(SingleThreadEventExecutor.java:111) at java.lang.Thread.run(Thread.java:722) Caused by: java.io.IOException: Index: 133 Size: 0  noformat  Code works fine for the twitter data set for instance which is bigger in size but contains less vertices.", "A_clean_title": ["race", "lead", "indexoutofboundsexcept", "index", "out", "bound", "except", "when", "queri", "buffer", "while", "releas", "spillablepartitionwhen", "spillabl", "partit", "when", "run", "code", "as", "simpl", "as", "noformat", "executionenviron", "execut", "environ", "env", "executionenviron", "getexecutionenviron", "execut", "environ", "get", "execut", "environ", "dataset", "data", "set", "edg", "string", "nullvalu", "null", "valu", "edg", "getedgesdataset", "get", "edg", "data", "set", "env", "graph", "string", "nullvalu", "null", "valu", "nullvalu", "null", "valu", "graph", "graph", "fromdataset", "data", "set", "edg", "env", "dataset", "data", "set", "tuple2", "string", "long", "degre", "graph", "getdegre", "get", "degre", "degre", "writeascsv", "write", "as", "csv", "outputpath", "output", "path", "env", "execut", "freindster", "data", "set", "http", "stanford", "friendster", "html", "snap", "edu", "data", "com", "30", "walli", "node", "get", "follow", "except", "java", "lang", "except", "data", "prepar", "task", "cogroup", "co", "group", "cogroup", "co", "group", "at", "indegre", "degre", "graph", "java:701", "caus", "error", "error", "obtain", "sort", "input", "thread", "sortmerg", "sort", "merger", "read", "thread", "termin", "due", "except", "fatal", "error", "at", "remot", "task", "manag", "wally028", "cit", "tu", "berlin", "149", "249", "38:53730", "de", "130", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "run", "regular", "pact", "task", "regularpacttask", "java:471", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "invok", "regular", "pact", "task", "regularpacttask", "java:362", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "taskmanag", "task", "run", "task", "java:559", "at", "java", "lang", "thread", "run", "thread", "java:722", "caus", "by", "java", "lang", "runtimeexcept", "runtim", "except", "error", "obtain", "sort", "input", "thread", "sortmerg", "sort", "merger", "read", "thread", "termin", "due", "except", "fatal", "error", "at", "remot", "task", "manag", "wally028", "cit", "tu", "berlin", "149", "249", "38:53730", "de", "130", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "getiter", "unilater", "sort", "merger", "get", "iter", "unilateralsortmerg", "java:607", "unilater", "sort", "merger", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "getinput", "regular", "pact", "task", "get", "input", "regularpacttask", "java:1145", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "cogroupdriv", "prepar", "co", "group", "driver", "cogroupdriv", "java:98", "co", "group", "driver", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "run", "regular", "pact", "task", "regularpacttask", "java:466", "regular", "pact", "task", "more", "caus", "by", "java", "io", "ioexcept", "io", "except", "thread", "sortmerg", "sort", "merger", "read", "thread", "termin", "due", "except", "fatal", "error", "at", "remot", "task", "manag", "wally028", "cit", "tu", "berlin", "149", "249", "38:53730", "de", "130", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "unilater", "sort", "merger", "threadbas", "run", "thread", "base", "unilateralsortmerg", "java:784", "unilater", "sort", "merger", "caus", "by", "org", "apach", "flink", "runtim", "io", "network", "netti", "except", "remotetransportexcept", "remot", "transport", "except", "fatal", "error", "at", "remot", "task", "manag", "wally028", "cit", "tu", "berlin", "149", "249", "38:53730", "de", "130", "at", "org", "apach", "flink", "runtim", "io", "network", "netti", "partitionrequestclienthandl", "decodemsg", "partit", "request", "client", "handler", "decod", "msg", "partitionrequestclienthandl", "java:227", "partit", "request", "client", "handler", "at", "org", "apach", "flink", "runtim", "io", "network", "netti", "partitionrequestclienthandl", "channelread", "partit", "request", "client", "handler", "channel", "read", "partitionrequestclienthandl", "java:162", "partit", "request", "client", "handler", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "invokechannelread", "abstract", "channel", "handler", "context", "invok", "channel", "read", "abstractchannelhandlercontext", "java:339", "abstract", "channel", "handler", "context", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "firechannelread", "abstract", "channel", "handler", "context", "fire", "channel", "read", "abstractchannelhandlercontext", "java:324", "abstract", "channel", "handler", "context", "at", "io", "netti", "handler", "codec", "messagetomessagedecod", "channelread", "messag", "messag", "decod", "channel", "read", "messagetomessagedecod", "java:103", "messag", "messag", "decod", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "invokechannelread", "abstract", "channel", "handler", "context", "invok", "channel", "read", "abstractchannelhandlercontext", "java:339", "abstract", "channel", "handler", "context", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "firechannelread", "abstract", "channel", "handler", "context", "fire", "channel", "read", "abstractchannelhandlercontext", "java:324", "abstract", "channel", "handler", "context", "at", "io", "netti", "handler", "codec", "bytetomessagedecod", "channelread", "byte", "messag", "decod", "channel", "read", "bytetomessagedecod", "java:242", "byte", "messag", "decod", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "invokechannelread", "abstract", "channel", "handler", "context", "invok", "channel", "read", "abstractchannelhandlercontext", "java:339", "abstract", "channel", "handler", "context", "at", "io", "netti", "channel", "abstractchannelhandlercontext", "firechannelread", "abstract", "channel", "handler", "context", "fire", "channel", "read", "abstractchannelhandlercontext", "java:324", "abstract", "channel", "handler", "context", "at", "io", "netti", "channel", "defaultchannelpipelin", "firechannelread", "default", "channel", "pipelin", "fire", "channel", "read", "defaultchannelpipelin", "java:847", "default", "channel", "pipelin", "at", "io", "netti", "channel", "nio", "abstractniobytechannel", "abstract", "nio", "byte", "channel", "niobyteunsaf", "read", "nio", "byte", "unsaf", "abstractniobytechannel", "java:131", "abstract", "nio", "byte", "channel", "at", "io", "netti", "channel", "nio", "nioeventloop", "processselectedkey", "nio", "event", "loop", "process", "select", "key", "nioeventloop", "java:511", "nio", "event", "loop", "at", "io", "netti", "channel", "nio", "nioeventloop", "processselectedkeysoptim", "nio", "event", "loop", "process", "select", "key", "optim", "nioeventloop", "java:468", "nio", "event", "loop", "at", "io", "netti", "channel", "nio", "nioeventloop", "processselectedkey", "nio", "event", "loop", "process", "select", "key", "nioeventloop", "java:382", "nio", "event", "loop", "at", "io", "netti", "channel", "nio", "nioeventloop", "run", "nio", "event", "loop", "nioeventloop", "java:354", "nio", "event", "loop", "at", "io", "netti", "util", "concurr", "singlethreadeventexecutor", "singl", "thread", "event", "executor", "run", "singlethreadeventexecutor", "java:111", "singl", "thread", "event", "executor", "at", "java", "lang", "thread", "run", "thread", "java:722", "caus", "by", "java", "io", "ioexcept", "io", "except", "index", "133", "size", "noformat", "code", "work", "fine", "twitter", "data", "set", "instanc", "which", "bigger", "size", "but", "contain", "less", "vertic"], "B_title": "runtime Check if parent released before querying in-memory buffer in SpillableSubpartitionView", "B_clean_title": ["runtim", "check", "parent", "releas", "befor", "queri", "memori", "buffer", "spillablesubpartitionview", "spillabl", "subpartit", "view"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test:  @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);    fails with  illegal state: maximal count (100) exceeded: evaluations   Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "fail", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Work around infinite loop.", "B_clean_title": ["work", "around", "infinit", "loop"]},
{"A_title": "ArrayIndexOutOfBoundsException in Segment.getRefId()It looks like there is some SegmentMK bug that causes the Segment.getRefId() to throw an ArrayIndexOutOfBoundsException in some fairly rare corner cases. The data was originally migrated into oak via the crx2oak tool mentioned here: http://docs.adobe.com/docs/en/aem/6-0/deploy/upgrade.html That tool uses *oak-core-1.0.0* creating an oak instance.  Similar to OAK-1566 this system was using FileDataStore with SegmentNodeStore.  In this case the error is seen when running offline compaction using oak-run-1.1-SNAPSHOT.jar (latest).  code:none > java -Xmx4096m -jar oak-run-1.1-SNAPSHOT.jar compact /oak/crx-quickstart/repository/segmentstore Apache Jackrabbit Oak 1.1-SNAPSHOT Compacting /wcm/cq-author/crx-quickstart/repository/segmentstore before data00055a.tar data00064a.tar data00045b.tar data00005a.tar data00018a.tar data00022a.tar data00047a.tar data00037a.tar data00049a.tar data00014a.tar data00066a.tar data00020a.tar data00058a.tar data00065a.tar data00069a.tar data00012a.tar data00009a.tar data00060a.tar data00041a.tar data00016a.tar data00072a.tar data00048a.tar data00061a.tar data00053a.tar data00038a.tar data00001a.tar data00034a.tar data00003a.tar data00052a.tar data00006a.tar data00027a.tar data00031a.tar data00056a.tar data00035a.tar data00063a.tar data00068a.tar data00008v.tar data00010a.tar data00043b.tar data00021a.tar data00017a.tar data00024a.tar data00054a.tar data00051a.tar data00057a.tar data00059a.tar data00036a.tar data00033a.tar data00019a.tar data00046a.tar data00067a.tar data00004a.tar data00044a.tar data00013a.tar data00070a.tar data00026a.tar data00002a.tar data00011a.tar journal.log data00030a.tar data00042a.tar data00025a.tar data00062a.tar data00023a.tar data00071a.tar data00032b.tar data00040a.tar data00015a.tar data00029a.tar data00050a.tar data00000a.tar data00007a.tar data00028a.tar data00039a.tar -> compacting Exception in thread main java.lang.ArrayIndexOutOfBoundsException: 206 at org.apache.jackrabbit.oak.plugins.segment.Segment.getRefId(Segment.java:191) at org.apache.jackrabbit.oak.plugins.segment.Segment.internalReadRecordId(Segment.java:299) at org.apache.jackrabbit.oak.plugins.segment.Segment.readRecordId(Segment.java:295) at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplateId(SegmentNodeState.java:69) at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplate(SegmentNodeState.java:78) at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getProperties(SegmentNodeState.java:150) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:154) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.Compactor CompactDiff.childNodeAdded(Compactor.java:124) at org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:395) at org.apache.jackrabbit.oak.plugins.segment.Compactor.process(Compactor.java:80) at org.apache.jackrabbit.oak.plugins.segment.Compactor.compact(Compactor.java:85) at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.compact(FileStore.java:438) at org.apache.jackrabbit.oak.run.Main.compact(Main.java:311) at org.apache.jackrabbit.oak.run.Main.main(Main.java:133) code", "A_clean_title": ["arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "segment", "getrefid", "get", "ref", "id", "it", "look", "like", "there", "some", "segmentmk", "segment", "mk", "bug", "that", "caus", "segment", "getrefid", "get", "ref", "id", "throw", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "some", "fairli", "rare", "corner", "case", "data", "wa", "origin", "migrat", "into", "oak", "via", "crx2oak", "tool", "mention", "here", "http", "adob", "html", "doc", "com", "doc", "en", "aem", "deploy", "upgrad", "that", "tool", "use", "oak", "core", "creat", "oak", "instanc", "similar", "oak", "1566", "thi", "system", "wa", "filedatastor", "file", "data", "store", "segmentnodestor", "segment", "node", "store", "thi", "case", "error", "seen", "when", "run", "offlin", "compact", "oak", "run", "snapshot", "jar", "latest", "code", "none", "java", "xmx4096m", "jar", "oak", "run", "snapshot", "jar", "compact", "oak", "crx", "quickstart", "repositori", "segmentstor", "apach", "jackrabbit", "oak", "snapshot", "compact", "wcm", "cq", "author", "crx", "quickstart", "repositori", "segmentstor", "befor", "data00055a", "tar", "data00064a", "tar", "data00045b", "tar", "data00005a", "tar", "data00018a", "tar", "data00022a", "tar", "data00047a", "tar", "data00037a", "tar", "data00049a", "tar", "data00014a", "tar", "data00066a", "tar", "data00020a", "tar", "data00058a", "tar", "data00065a", "tar", "data00069a", "tar", "data00012a", "tar", "data00009a", "tar", "data00060a", "tar", "data00041a", "tar", "data00016a", "tar", "data00072a", "tar", "data00048a", "tar", "data00061a", "tar", "data00053a", "tar", "data00038a", "tar", "data00001a", "tar", "data00034a", "tar", "data00003a", "tar", "data00052a", "tar", "data00006a", "tar", "data00027a", "tar", "data00031a", "tar", "data00056a", "tar", "data00035a", "tar", "data00063a", "tar", "data00068a", "tar", "data00008v", "tar", "data00010a", "tar", "data00043b", "tar", "data00021a", "tar", "data00017a", "tar", "data00024a", "tar", "data00054a", "tar", "data00051a", "tar", "data00057a", "tar", "data00059a", "tar", "data00036a", "tar", "data00033a", "tar", "data00019a", "tar", "data00046a", "tar", "data00067a", "tar", "data00004a", "tar", "data00044a", "tar", "data00013a", "tar", "data00070a", "tar", "data00026a", "tar", "data00002a", "tar", "data00011a", "tar", "journal", "log", "data00030a", "tar", "data00042a", "tar", "data00025a", "tar", "data00062a", "tar", "data00023a", "tar", "data00071a", "tar", "data00032b", "tar", "data00040a", "tar", "data00015a", "tar", "data00029a", "tar", "data00050a", "tar", "data00000a", "tar", "data00007a", "tar", "data00028a", "tar", "data00039a", "tar", "compact", "except", "thread", "main", "java", "lang", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "206", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segment", "getrefid", "get", "ref", "id", "segment", "java:191", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segment", "internalreadrecordid", "intern", "read", "record", "id", "segment", "java:299", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segment", "readrecordid", "read", "record", "id", "segment", "java:295", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "gettemplateid", "segment", "node", "state", "get", "templat", "id", "segmentnodest", "java:69", "segment", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "gettempl", "segment", "node", "state", "get", "templat", "segmentnodest", "java:78", "segment", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "getproperti", "segment", "node", "state", "get", "properti", "segmentnodest", "java:150", "segment", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:154", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compactdiff", "childnodead", "compact", "diff", "child", "node", "ad", "compactor", "java:124", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "emptynodest", "compareagainstemptyst", "empti", "node", "state", "compar", "against", "empti", "state", "emptynodest", "java:160", "empti", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "compareagainstbasest", "segment", "node", "state", "compar", "against", "base", "state", "segmentnodest", "java:395", "segment", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "process", "compactor", "java:80", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactor", "compact", "compactor", "java:85", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "file", "filestor", "compact", "file", "store", "filestor", "java:438", "file", "store", "at", "org", "apach", "jackrabbit", "oak", "run", "main", "compact", "main", "java:311", "at", "org", "apach", "jackrabbit", "oak", "run", "main", "main", "main", "java:133", "code"], "B_title": "ArrayIndexOutOfBoundsException in Segment.getRefId() - Applying Toms fix - Asserting length <= buffer.length - More aggressive tests case", "B_clean_title": ["arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "segment", "getrefid", "get", "ref", "id", "appli", "tom", "fix", "assert", "length", "buffer", "length", "more", "aggress", "test", "case"]},
{"A_title": "Remove username from initializationThis is an artifact from a brief transition area during the 1.5 development. We have a flag for the user to set what the root username is except its never used. We should remove both the variable and the flag for it.", "A_clean_title": ["remov", "usernam", "initializationthi", "initi", "thi", "artifact", "brief", "transit", "area", "dure", "develop", "we", "have", "flag", "user", "set", "what", "root", "usernam", "except", "it", "never", "use", "we", "remov", "both", "variabl", "flag", "it"], "B_title": "Thought this flag was gone in MAC fixed now", "B_clean_title": ["thought", "thi", "flag", "wa", "gone", "mac", "fix", "now"]},
{"A_title": "segments compareAgainstBaseState wont call childNodeDeleted when deleting last and adding n nodesSegmentNodeState.compareAgainstBaseState fails to call NodeStateDiff.childNodeDeleted when for the same parent the only child is deleted and at the same time multiple new different children are added.  Reason is that the current code|https://github.com/apache/jackrabbit-oak/blob/a9ce70b61567ffe27529dad8eb5d38ced77cf8ad/oak-segment/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentNodeState.java#L558 for afterChildName == MANY_CHILD_NODES *and* beforeChildName == ONE_CHILD_NODE does not handle all cases: it assumes that after contains the before child and doesnt handle the situation where the before child has gone.", "A_clean_title": ["segment", "compareagainstbasest", "compar", "against", "base", "state", "wont", "call", "childnodedelet", "child", "node", "delet", "when", "delet", "last", "ad", "nodessegmentnodest", "compareagainstbasest", "node", "segment", "node", "state", "compar", "against", "base", "state", "fail", "call", "nodestatediff", "childnodedelet", "node", "state", "diff", "child", "node", "delet", "when", "same", "parent", "onli", "child", "delet", "at", "same", "time", "multipl", "new", "differ", "children", "are", "ad", "reason", "that", "current", "code|http", "oak", "blob", "a9ce70b61567ffe27529dad8eb5d38ced77cf8ad", "oak", "java", "github", "com", "apach", "jackrabbit", "segment", "src", "main", "java", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentnodest", "segment", "node", "state", "l558", "afterchildnam", "after", "child", "name", "mani", "child", "node", "beforechildnam", "befor", "child", "name", "one", "child", "node", "not", "handl", "all", "case", "it", "assum", "that", "after", "contain", "befor", "child", "doesnt", "handl", "situat", "where", "befor", "child", "ha", "gone"], "B_title": ": fix for compareAgainstBaseState which properly handles deletion of last child and adding multiple new children in same go", "B_clean_title": ["fix", "compareagainstbasest", "compar", "against", "base", "state", "which", "properli", "handl", "delet", "last", "child", "ad", "multipl", "new", "children", "same", "go"]},
{"A_title": "@lends does not work unless class is defined beforehandNone", "A_clean_title": ["lend", "not", "work", "unless", "class", "defin", "beforehandnon", "beforehand", "none"], "B_title": "defer evaluation of the @lends annotation fixes issue 314", "B_clean_title": ["defer", "evalu", "lend", "annot", "fix", "issu", "314"]},
{"A_title": "StackOverflowError when calling getObject() from load() in LDMThe fix for WICKET-5772 caused an infinite loop when calling getObject() from inside load() in LoadableDetachableModel. While of course unwise to do so and nobody in their right mind would do so directly such a cycle can be triggered through a series of unrelated calls emanating from load().", "A_clean_title": ["stackoverflowerror", "stack", "overflow", "error", "when", "call", "getobject", "get", "object", "load", "ldmthe", "ldm", "fix", "wicket", "5772", "caus", "infinit", "loop", "when", "call", "getobject", "get", "object", "insid", "load", "loadabledetachablemodel", "loadabl", "detach", "model", "while", "cours", "unwis", "so", "nobodi", "their", "right", "mind", "would", "so", "directli", "such", "cycl", "trigger", "through", "seri", "unrel", "call", "eman", "load"], "B_title": "StackOverflowError in LoadableDetachableModel", "B_clean_title": ["stackoverflowerror", "stack", "overflow", "error", "loadabledetachablemodel", "loadabl", "detach", "model"]},
{"A_title": "math Complex Tanh for big numbersHi  In Complex.java the tanh is computed with the following formula:  tanh(a + bi) = sinh(2a)/(cosh(2a)+cos(2b)) + sin(2b)/(cosh(2a)+cos(2b))i  The problem that Im finding is that as soon as a is a big number both sinh(2a) and cosh(2a) are infinity and then the method tanh returns in the real part NaN (infinity/infinity) when it should return 1.0.  Wouldnt it be appropiate to add something as in the FastMath library??:  if (real>20.0)       return createComplex(1.0 0.0);  if (real<-20.0)       return createComplex(-1.0 0.0);    Best regards  JBB", "A_clean_title": ["math", "complex", "tanh", "big", "numbershi", "number", "hi", "complex", "java", "tanh", "comput", "follow", "formula", "tanh", "bi", "sinh", "2a", "cosh", "2a", "+co", "2b", "sin", "2b", "cosh", "2a", "+co", "2b", "problem", "that", "im", "find", "that", "as", "soon", "as", "big", "number", "both", "sinh", "2a", "cosh", "2a", "are", "infin", "then", "method", "tanh", "return", "real", "part", "nan", "na", "infin", "infin", "when", "it", "return", "wouldnt", "it", "appropi", "add", "someth", "as", "fastmath", "fast", "math", "librari", "real", "20", "return", "createcomplex", "creat", "complex", "real", "20", "return", "createcomplex", "creat", "complex", "best", "regard", "jbb"], "B_title": "Introduced tests to guard against overflow (MATH-722). Corrected Javadoc and updated unit tests accordingly.", "B_clean_title": ["introduc", "test", "guard", "against", "overflow", "math", "722", "correct", "javadoc", "updat", "unit", "test", "accordingli"]},
{"A_title": "Incomplete beta function I(x a b) is inaccurate for large values of a and/or bThis was first reported in MATH-718. The result of the current implementation of the incomplete beta function I(x a b) is inaccurate when a and/or b are large-ish.     Ive skimmed through slatec|http://www.netlib.org/slatec/fnlib/betai.f GSL Boost|http://www.boost.org/doc/libs/1_38_0/libs/math/doc/sf_and_dist/html/math_toolkit/special/sf_beta/ibeta_function.html as well as NR. At first sight neither uses the same method to compute this function. I think TOMS-708|http://www.netlib.org/toms/708 is probably the best option.    _Issue moved from MATH project on January 27 2018 (concerned implementation was moved to module commons-numbers-gamma of Commons Numbers)._", "A_clean_title": ["incomplet", "beta", "function", "inaccur", "larg", "valu", "or", "bthi", "thi", "wa", "first", "report", "math", "718", "result", "current", "implement", "incomplet", "beta", "function", "inaccur", "when", "or", "are", "larg", "ish", "ive", "skim", "through", "slatec|http", "netlib", "www", "org", "slatec", "fnlib", "betai", "gsl", "boost|http", "boost", "html", "www", "38", "function", "org", "doc", "lib", "lib", "math", "doc", "sf", "dist", "html", "math", "toolkit", "special", "sf", "beta", "ibeta", "as", "well", "as", "nr", "at", "first", "sight", "neither", "use", "same", "method", "comput", "thi", "function", "think", "tom", "708|http", "netlib", "www", "org", "tom", "708", "probabl", "best", "option", "issu", "move", "math", "project", "januari", "27", "2018", "concern", "implement", "wa", "move", "modul", "common", "number", "gamma", "common", "number"], "B_title": "New implementation of Beta.logBeta(double double) based on the NSWC library of mathematical functions.   - increased accuracy   - deprecation of Beta.logBeta(double double double int) as the new     implementation is no longer iterative.   - some private methods are tested through reflection.", "B_clean_title": ["new", "implement", "beta", "logbeta", "log", "beta", "doubl", "doubl", "base", "nswc", "librari", "mathemat", "function", "increas", "accuraci", "deprec", "beta", "logbeta", "log", "beta", "doubl", "doubl", "doubl", "int", "as", "new", "implement", "no", "longer", "iter", "some", "privat", "method", "are", "test", "through", "reflect"]},
{"A_title": "Use of ThreadLocals in ToStringStyle and HashCodeBuilder trigger memory leaks in container environmentsThe thread local in org.apache.commons.lang3.builder.ToStringStyle is created but never removed and no API is provided to remove it. If a webapps use of LANG triggers the loading of this class a reference chain will be created that will cause a memory leak on web application reload. See http://markmail.org/thread/uetw2fdrsqgbh2cv for more info.", "A_clean_title": ["use", "threadloc", "thread", "local", "tostringstyl", "string", "style", "hashcodebuild", "hash", "code", "builder", "trigger", "memori", "leak", "contain", "environmentsth", "environ", "thread", "local", "org", "apach", "common", "lang3", "builder", "tostringstyl", "string", "style", "creat", "but", "never", "remov", "no", "api", "provid", "remov", "it", "webapp", "use", "lang", "trigger", "load", "thi", "class", "refer", "chain", "will", "creat", "that", "will", "caus", "memori", "leak", "web", "applic", "reload", "see", "http", "markmail", "org", "thread", "uetw2fdrsqgbh2cv", "more", "info"], "B_title": "part 2: refactor ToStringStyle and ToStringBuilderTest to verify that we are unsetting the registry when no longer needed", "B_clean_title": ["part", "refactor", "tostringstyl", "string", "style", "tostringbuildertest", "string", "builder", "test", "verifi", "that", "we", "are", "unset", "registri", "when", "no", "longer", "need"]},
{"A_title": "AccumuloVFSClassloader incorrectly treats folders as folders of jar filesSpecifying a directory of classes is incorrectly interpreted as a directory of jars in the general.dynamic.classpaths configuration property.  Example: adding a path such as *_ ACCUMULO_HOME/core/target/classes_* gets incorrectly interpreted as *_ ACCUMULO_HOME/core/target/classes/*_* and evaluates to *_ ACCUMULO_HOME/core/target/classes/org_* and *_ ACCUMULO_HOME/core/target/classes/META-INF_* but *NOT* to *_ ACCUMULO_HOME/core/target/classes_* as expected.", "A_clean_title": ["accumulovfsclassload", "accumulo", "vf", "classload", "incorrectli", "treat", "folder", "as", "folder", "jar", "filesspecifi", "file", "specifi", "directori", "class", "incorrectli", "interpret", "as", "directori", "jar", "gener", "dynam", "classpath", "configur", "properti", "exampl", "ad", "path", "such", "as", "accumulo", "home", "core", "target", "class", "get", "incorrectli", "interpret", "as", "accumulo", "home", "core", "target", "class", "evalu", "accumulo", "home", "core", "target", "class", "org", "accumulo", "inf", "home", "core", "target", "class", "meta", "but", "not", "accumulo", "home", "core", "target", "class", "as", "expect"], "B_title": "I jumped the gun", "B_clean_title": ["jump", "gun"]},
{"A_title": "Void is not added to TypeInfoParserList l = Arrays.asList(new Tuple2<VoidLong>(null 1L)); TypeInformation t = TypeInfoParser.parse(Tuple2<VoidLong>); DataSet<Tuple2<VoidLong>> data = env.fromCollection(l t); data.print(); Throws: Exception in thread main java.lang.IllegalArgumentException: String could not be parsed: Class Void could not be found for use as custom object. Please note that inner classes must be declared static. at org.apache.flink.api.java.typeutils.TypeInfoParser.parse(TypeInfoParser.java:90) at org.apache.flink.hadoopcompatibility.mapreduce.example.ParquetOutput.main(ParquetOutput.java:92) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134) Caused by: java.lang.IllegalArgumentException: Class Void could not be found for use as custom object. Please note that inner classes must be declared static. at org.apache.flink.api.java.typeutils.TypeInfoParser.parse(TypeInfoParser.java:290) at org.apache.flink.api.java.typeutils.TypeInfoParser.parse(TypeInfoParser.java:133) at org.apache.flink.api.java.typeutils.TypeInfoParser.parse(TypeInfoParser.java:88) ... 6 more", "A_clean_title": ["void", "not", "ad", "typeinfoparserlist", "type", "info", "parser", "list", "array", "aslist", "as", "list", "new", "tuple2", "voidlong", "void", "long", "null", "1l", "typeinform", "type", "inform", "typeinfopars", "pars", "type", "info", "parser", "tuple2", "voidlong", "void", "long", "dataset", "data", "set", "tuple2", "voidlong", "void", "long", "data", "env", "fromcollect", "collect", "data", "print", "throw", "except", "thread", "main", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "string", "could", "not", "pars", "class", "void", "could", "not", "found", "use", "as", "custom", "object", "pleas", "note", "that", "inner", "class", "must", "declar", "static", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeinfopars", "pars", "type", "info", "parser", "typeinfopars", "java:90", "type", "info", "parser", "at", "org", "apach", "flink", "hadoopcompat", "mapreduc", "exampl", "parquetoutput", "main", "parquet", "output", "parquetoutput", "java:92", "parquet", "output", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:57", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:43", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:606", "at", "com", "intellij", "rt", "execut", "applic", "appmain", "main", "app", "main", "appmain", "java:134", "app", "main", "caus", "by", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "class", "void", "could", "not", "found", "use", "as", "custom", "object", "pleas", "note", "that", "inner", "class", "must", "declar", "static", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeinfopars", "pars", "type", "info", "parser", "typeinfopars", "java:290", "type", "info", "parser", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeinfopars", "pars", "type", "info", "parser", "typeinfopars", "java:133", "type", "info", "parser", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeinfopars", "pars", "type", "info", "parser", "typeinfopars", "java:88", "type", "info", "parser", "more"], "B_title": "Adds the new basic types Void and Date to the TypeInfoParser", "B_clean_title": ["add", "new", "basic", "type", "void", "date", "typeinfopars", "type", "info", "parser"]},
{"A_title": "Entries in _commitRoot not purgedEntries in _commitRoot are not purged or moved to previous documents if there are no changes with those revisions. Usually there is always a change associated with a _commitRoot but in some cases it may happen that the only update on the document is for non-revisioned data like the _children flag.", "A_clean_title": ["entri", "commitroot", "commit", "root", "not", "purgedentri", "purg", "entri", "commitroot", "commit", "root", "are", "not", "purg", "or", "move", "previou", "document", "there", "are", "no", "chang", "those", "revis", "usual", "there", "alway", "chang", "associ", "commitroot", "commit", "root", "but", "some", "case", "it", "may", "happen", "that", "onli", "updat", "document", "non", "revis", "data", "like", "children", "flag"], "B_title": "Entries in _commitRoot not purged", "B_clean_title": ["entri", "commitroot", "commit", "root", "not", "purg"]},
{"A_title": "Boosting fields not working as expectedWhen the boost support was added the intention was to support a usecase like   quote For the fulltext search on a node where the fulltext content is derived from multiple field it should be possible to boost specific text contributed by individual field. Meaning that if a title field is boosted more than description the title (part) in the fulltext field will mean more than the description (part) in the fulltext field. quote  This would enable a user to perform a search like _/jcr:root/content/geometrixx-outdoors/en//element(* cq:Page)jcr:contains(. Keyword)_ and get a result where pages having Keyword in title come above in search result compared to those where Keyword is found in description.  Current implementation just sets the boost while add the field value to fulltext field with the intention that Lucene would use the boost as explained above. However it does not work like that and boost value gets multiplies with other field and hence boosting does not work as expected", "A_clean_title": ["boost", "field", "not", "work", "as", "expectedwhen", "expect", "when", "boost", "support", "wa", "ad", "intent", "wa", "support", "usecas", "like", "quot", "fulltext", "search", "node", "where", "fulltext", "content", "deriv", "multipl", "field", "it", "possibl", "boost", "specif", "text", "contribut", "by", "individu", "field", "mean", "that", "titl", "field", "boost", "more", "than", "descript", "titl", "part", "fulltext", "field", "will", "mean", "more", "than", "descript", "part", "fulltext", "field", "quot", "thi", "would", "enabl", "user", "perform", "search", "like", "jcr", "root", "content", "geometrixx", "outdoor", "en", "element", "cq", "page", "jcr", "contain", "keyword", "get", "result", "where", "page", "have", "keyword", "titl", "come", "abov", "search", "result", "compar", "those", "where", "keyword", "found", "descript", "current", "implement", "just", "set", "boost", "while", "add", "field", "valu", "fulltext", "field", "intent", "that", "lucen", "would", "use", "boost", "as", "explain", "abov", "howev", "it", "not", "work", "like", "that", "boost", "valu", "get", "multipli", "other", "field", "henc", "boost", "not", "work", "as", "expect"], "B_title": "- Boosting fields not working as expected", "B_clean_title": ["boost", "field", "not", "work", "as", "expect"]},
{"A_title": "implementation of smallest enclosing ball algorithm sometime failsThe algorithm for finding the smallest ball is designed in such a way the radius should be strictly increasing at each iteration.  In some cases it is not true and one iteration has a smaller ball. In most cases there is no consequence there is just one or two more iterations. However in rare cases discovered while testing 3D this generates an infinite loop.  Some very short offending cases have already been identified and added to the test suite. These cases are currently deactivated in the main repository while I am already working on them. The test cases are  * WelzlEncloser2DTest.testReducingBall * WelzlEncloser2DTest.testLargeSamples * WelzlEncloser3DTest.testInfiniteLoop * WelzlEncloser3DTest.testLargeSamples", "A_clean_title": ["implement", "smallest", "enclos", "ball", "algorithm", "sometim", "failsth", "fail", "algorithm", "find", "smallest", "ball", "design", "such", "way", "radiu", "strictli", "increas", "at", "each", "iter", "some", "case", "it", "not", "true", "one", "iter", "ha", "smaller", "ball", "most", "case", "there", "no", "consequ", "there", "just", "one", "or", "two", "more", "iter", "howev", "rare", "case", "discov", "while", "test", "3d", "thi", "gener", "infinit", "loop", "some", "veri", "short", "offend", "case", "have", "alreadi", "been", "identifi", "ad", "test", "suit", "these", "case", "are", "current", "deactiv", "main", "repositori", "while", "am", "alreadi", "work", "them", "test", "case", "are", "welzlencloser2dtest", "testreducingbal", "welzl", "encloser2d", "test", "test", "reduc", "ball", "welzlencloser2dtest", "testlargesampl", "welzl", "encloser2d", "test", "test", "larg", "sampl", "welzlencloser3dtest", "testinfiniteloop", "welzl", "encloser3d", "test", "test", "infinit", "loop", "welzlencloser3dtest", "testlargesampl", "welzl", "encloser3d", "test", "test", "larg", "sampl"], "B_title": "Partly fixed MATH-1096.", "B_clean_title": ["partli", "fix", "math", "1096"]},
{"A_title": "Property Index: cost calculation is wrong (zero) when searching for many valuesCurrently for queries of the form   code select * from nt:unstructured where type = xyz code  the node type index is used in some cases even if there is an index on the property type. The reason is that the cost for the node type index is 0 due to a bug. The node type index internally uses the property index on the property jcr:primaryType and asks for the cost using all possible children node types of nt:unstructured. The returned cost is 0 because of this bug. The cost estimation is an extrapolation of the number of entries for the first 3 values. It is currently coded as:  code count = count / size / i; code  when in fact it should be written as:  code count = count * size / i; code", "A_clean_title": ["properti", "index", "cost", "calcul", "wrong", "zero", "when", "search", "mani", "valuescurr", "valu", "current", "queri", "form", "code", "select", "nt", "unstructur", "where", "type", "xyz", "code", "node", "type", "index", "use", "some", "case", "even", "there", "index", "properti", "type", "reason", "that", "cost", "node", "type", "index", "due", "bug", "node", "type", "index", "intern", "use", "properti", "index", "properti", "jcr", "primarytyp", "primari", "type", "ask", "cost", "all", "possibl", "children", "node", "type", "nt", "unstructur", "return", "cost", "becaus", "thi", "bug", "cost", "estim", "extrapol", "number", "entri", "first", "valu", "it", "current", "code", "as", "code", "count", "count", "size", "code", "when", "fact", "it", "written", "as", "code", "count", "count", "size", "code"], "B_title": "Property Index: cost calculation is wrong (zero) when searching for many values", "B_clean_title": ["properti", "index", "cost", "calcul", "wrong", "zero", "when", "search", "mani", "valu"]},
{"A_title": "Dont allow viewfs in instance.volumesI think one of our folks put viewfs into instance.volumes on accident. File references in accumulo.root and accumulo.metadata were then written with viewfs in the path. The garbage collector then throws errors as compactions occur and it tries delete and move the files to the hdfs users trash directory.  viewfs should never be allowed in instance.volumes property. It should fail.", "A_clean_title": ["dont", "allow", "viewf", "instanc", "volumesi", "volum", "think", "one", "our", "folk", "put", "viewf", "into", "instanc", "volum", "accid", "file", "refer", "accumulo", "root", "accumulo", "metadata", "were", "then", "written", "viewf", "path", "garbag", "collector", "then", "throw", "error", "as", "compact", "occur", "it", "tri", "delet", "move", "file", "hdf", "user", "trash", "directori", "viewf", "never", "allow", "instanc", "volum", "properti", "it", "fail"], "B_title": "check for viewfs", "B_clean_title": ["check", "viewf"]},
{"A_title": "MultiDirectional optimzation loops forver if started at the correct solutionMultiDirectional.iterateSimplex loops forever if the starting point is the correct solution. see the attached test case (testMultiDirectionalCorrectStart) as an example.", "A_clean_title": ["multidirect", "multi", "direct", "optimz", "loop", "forver", "start", "at", "correct", "solutionmultidirect", "iteratesimplex", "solut", "multi", "direct", "iter", "simplex", "loop", "forev", "start", "point", "correct", "solut", "see", "attach", "test", "case", "testmultidirectionalcorrectstart", "test", "multi", "direct", "correct", "start", "as", "exampl"], "B_title": "Prevent infinite loops in multi-directional direct optimization method when the start point is exactly at the optimal point JIRA: MATH-283", "B_clean_title": ["prevent", "infinit", "loop", "multi", "direct", "direct", "optim", "method", "when", "start", "point", "exactli", "at", "optim", "point", "jira", "math", "283"]},
{"A_title": "Node.hasNode(foo2) must not throw PathNotFoundExceptionsimilar to OAK-1225 Node.hasNode(foo2) should return false", "A_clean_title": ["node", "hasnod", "ha", "node", "foo2", "must", "not", "throw", "pathnotfoundexceptionsimilar", "path", "not", "found", "exceptionsimilar", "oak", "1225", "node", "hasnod", "ha", "node", "foo2", "return", "fals"], "B_title": "Node.hasNode(foo2) must not throw PathNotFoundException", "B_clean_title": ["node", "hasnod", "ha", "node", "foo2", "must", "not", "throw", "pathnotfoundexcept", "path", "not", "found", "except"]},
{"A_title": "Percentile Computation errsIn the following test the 75th percentile is _smaller_ than the 25th percentile leaving me with a negative interquartile range.  code:title=Bar.java|borderStyle=solid @Test public void negativePercentiles()          double data = new double                 -0.012086732064244697                  -0.24975668704012527                  0.5706168483164684                  -0.322111769955327                  0.24166759508327315                  Double.NaN                  0.16698443218942854                  -0.10427763937565114                  -0.15595963093172435                  -0.028075857595882995                  -0.24137994506058857                  0.47543170476574426                  -0.07495595384947631                  0.37445697625436497                  -0.09944199541668033         ;         DescriptiveStatistics descriptiveStatistics = new DescriptiveStatistics(data);          double threeQuarters = descriptiveStatistics.getPercentile(75);         double oneQuarter = descriptiveStatistics.getPercentile(25);          double IQR = threeQuarters - oneQuarter;                  System.out.println(String.format(25th percentile %s 75th percentile %s oneQuarter threeQuarters ));                  assert IQR >= 0;               code", "A_clean_title": ["percentil", "comput", "errsin", "err", "follow", "test", "75th", "percentil", "smaller", "than", "25th", "percentil", "leav", "me", "neg", "interquartil", "rang", "code", "title=bar", "java|borderstyle=solid", "java|bord", "style=solid", "test", "public", "void", "negativepercentil", "neg", "percentil", "doubl", "data", "new", "doubl", "012086732064244697", "24975668704012527", "5706168483164684", "322111769955327", "24166759508327315", "doubl", "nan", "na", "16698443218942854", "10427763937565114", "15595963093172435", "028075857595882995", "24137994506058857", "47543170476574426", "07495595384947631", "37445697625436497", "09944199541668033", "descriptivestatist", "descript", "statist", "descriptivestatist", "descript", "statist", "new", "descriptivestatist", "descript", "statist", "data", "doubl", "threequart", "three", "quarter", "descriptivestatist", "getpercentil", "descript", "statist", "get", "percentil", "75", "doubl", "onequart", "one", "quarter", "descriptivestatist", "getpercentil", "descript", "statist", "get", "percentil", "25", "doubl", "iqr", "threequart", "three", "quarter", "onequart", "one", "quarter", "system", "out", "println", "string", "format", "25th", "percentil", "75th", "percentil", "onequart", "one", "quarter", "threequart", "three", "quarter", "assert", "iqr", "code"], "B_title": "Fix wrong sorting in the presence of NaN.", "B_clean_title": ["fix", "wrong", "sort", "presenc", "nan", "na"]},
{"A_title": "Lucene AND query with a complex OR phrase returns incorrect resultQueries like this noformat/jcr:root/content//element(* test:Asset)(jcr:contains(. cube)) and (jcr:contains(jcr:content/@foo a OR b)) noformat returns wrong results.  This get converted to noformat+:fulltext:cube full:jcr:content/foo:a full:jcr:content/foo:b noformat", "A_clean_title": ["lucen", "queri", "complex", "or", "phrase", "return", "incorrect", "resultqueri", "result", "queri", "like", "thi", "noformat", "jcr", "root", "content", "element", "test", "asset", "jcr", "contain", "cube", "jcr", "contain", "jcr", "content", "foo", "or", "noformat", "return", "wrong", "result", "thi", "get", "convert", "noformat+", "fulltext", "cube", "full", "jcr", "content", "foo", "full", "jcr", "content", "foo", "noformat"], "B_title": "Lucene AND query with a complex OR phrase returns incorrect result Fixed by not flattening the boolean query", "B_clean_title": ["lucen", "queri", "complex", "or", "phrase", "return", "incorrect", "result", "fix", "by", "not", "flatten", "boolean", "queri"]},
{"A_title": "Page header isnt rendered for pages where URL has changed during renderDue to the changes in WICKET-5309 a page is re-rendered when any of the URL segments is modified during the request:  From WebPageRenderer.java:  code // the url might have changed after page has been rendered (e.g. the // stateless flag might have changed because stateful components // were added) final Url afterRenderUrl = requestCycle .mapUrlFor(getRenderPageRequestHandler());  if (beforeRenderUrl.getSegments().equals(afterRenderUrl.getSegments()) == false)  // the amount of segments is different - generated relative URLs // will not work we need to rerender the page. This can happen // with IRequestHandlers that produce different URLs with // different amount of segments for stateless and stateful pages response = renderPage(afterRenderUrl requestCycle);   if (currentUrl.equals(afterRenderUrl)) code  The re-render causes the <head> section to be empty because it was already rendered in the first try.", "A_clean_title": ["page", "header", "isnt", "render", "page", "where", "url", "ha", "chang", "dure", "renderdu", "render", "due", "chang", "wicket", "5309", "page", "re", "render", "when", "ani", "url", "segment", "modifi", "dure", "request", "webpagerender", "java", "web", "page", "render", "code", "url", "might", "have", "chang", "after", "page", "ha", "been", "render", "stateless", "flag", "might", "have", "chang", "becaus", "state", "compon", "were", "ad", "final", "url", "afterrenderurl", "after", "render", "url", "requestcycl", "request", "cycl", "mapurlfor", "map", "url", "getrenderpagerequesthandl", "get", "render", "page", "request", "handler", "beforerenderurl", "getseg", "befor", "render", "url", "get", "segment", "equal", "afterrenderurl", "getseg", "after", "render", "url", "get", "segment", "fals", "amount", "segment", "differ", "gener", "rel", "url", "ur", "ls", "will", "not", "work", "we", "need", "rerend", "page", "thi", "happen", "irequesthandl", "request", "handler", "that", "produc", "differ", "url", "ur", "ls", "differ", "amount", "segment", "stateless", "state", "page", "respons", "renderpag", "render", "page", "afterrenderurl", "after", "render", "url", "requestcycl", "request", "cycl", "currenturl", "equal", "current", "url", "afterrenderurl", "after", "render", "url", "code", "re", "render", "caus", "head", "section", "empti", "becaus", "it", "wa", "alreadi", "render", "first", "tri"], "B_title": "drop headerResponse and renderedComponentsPerScope in #onAfterRender() so a second rendering re-renders the header", "B_clean_title": ["drop", "headerrespons", "header", "respons", "renderedcomponentsperscop", "render", "compon", "per", "scope", "onafterrend", "after", "render", "so", "second", "render", "re", "render", "header"]},
{"A_title": "new multivariate vector optimizers cannot be used with large number of weightsWhen using the Weigth class to pass a large number of weights to multivariate vector optimizers an nxn full matrix is created (and copied) when a n elements vector is used. This exhausts memory when n is large. This happens for example when using curve fitters (even simple curve fitters like polynomial ones for low degree) with large number of points. I encountered this with curve fitting on 41200 points which created a matrix with 1.7 billion elements.", "A_clean_title": ["new", "multivari", "vector", "optim", "not", "use", "larg", "number", "weightswhen", "weight", "when", "weigth", "class", "pass", "larg", "number", "weight", "multivari", "vector", "optim", "nxn", "full", "matrix", "creat", "copi", "when", "element", "vector", "use", "thi", "exhaust", "memori", "when", "larg", "thi", "happen", "exampl", "when", "curv", "fitter", "even", "simpl", "curv", "fitter", "like", "polynomi", "one", "low", "degre", "larg", "number", "point", "encount", "thi", "curv", "fit", "41200", "point", "which", "creat", "matrix", "billion", "element"], "B_title": "Avoid memory exhaustion for large number of unclorrelated observations.", "B_clean_title": ["avoid", "memori", "exhaust", "larg", "number", "unclorrel", "observ"]},
{"A_title": "BrentOptimizer not always reporting the best pointBrentOptimizer (package o.a.c.m.optimization.univariate) does not check that the point it is going to return is indeed the best one it has encountered. Indeed the last evaluated point might be slightly worse than the one before last.", "A_clean_title": ["brentoptim", "brent", "optim", "not", "alway", "report", "best", "pointbrentoptim", "point", "brent", "optim", "packag", "optim", "univari", "not", "check", "that", "point", "it", "go", "return", "inde", "best", "one", "it", "ha", "encount", "inde", "last", "evalu", "point", "might", "slightli", "wors", "than", "one", "befor", "last"], "B_title": "The best point is sometimes not the last one evaluated.", "B_clean_title": ["best", "point", "sometim", "not", "last", "one", "evalu"]},
{"A_title": "CEP operator does not forward watermarks properlyThe CEP stream operator dont emit a proper watermark when using event time.", "A_clean_title": ["cep", "oper", "not", "forward", "watermark", "properlyth", "properli", "cep", "stream", "oper", "dont", "emit", "proper", "watermark", "when", "event", "time"], "B_title": "cep Add proper watermark emission to CEP operators", "B_clean_title": ["cep", "add", "proper", "watermark", "emiss", "cep", "oper"]},
{"A_title": "ClientConfiguration.getAllPropertiesWithPrefix doesnt workI think I introduced this method for trace.span.receiver.* and didnt write a test for it.  My mistake.", "A_clean_title": ["clientconfigur", "getallpropertieswithprefix", "client", "configur", "get", "all", "properti", "prefix", "doesnt", "worki", "work", "think", "introduc", "thi", "method", "trace", "span", "receiv", "didnt", "write", "test", "it", "my", "mistak"], "B_title": "fix ClientConfiguration.getAllPropertiesWithPrefix and add test", "B_clean_title": ["fix", "clientconfigur", "getallpropertieswithprefix", "client", "configur", "get", "all", "properti", "prefix", "add", "test"]},
{"A_title": "Validity checks missing for readFields and Thrift deserializationClasses in o.a.a.core.data (and potentially elsewhere) that support construction from a Thrift object and/or population from a DataInput (via a readFields() method) often lack data validity checks that the classes constructors enforce. The missing checks make it possible for an attacker to create invalid objects by manipulating the bytes being read. The situation is analogous to the need to check objects deserialized from their Java serialized form within the readObject() method.", "A_clean_title": ["valid", "check", "miss", "readfield", "read", "field", "thrift", "deserializationclass", "deseri", "class", "core", "data", "potenti", "elsewher", "that", "support", "construct", "thrift", "object", "or", "popul", "datainput", "data", "input", "via", "readfield", "read", "field", "method", "often", "lack", "data", "valid", "check", "that", "class", "constructor", "enforc", "miss", "check", "make", "it", "possibl", "attack", "creat", "invalid", "object", "by", "manipul", "byte", "be", "read", "situat", "analog", "need", "check", "object", "deseri", "their", "java", "serial", "form", "within", "readobject", "read", "object", "method"], "B_title": "Add data integrity checks to Key and Mutation", "B_clean_title": ["add", "data", "integr", "check", "key", "mutat"]},
{"A_title": "RepositoryBeanNameGenerator fails to resolve bean names for custom implementations detected via Springs component index DATACMNS-1115opened and commented After upgrading to Spring Boot 2.0.0.M2 and Spring Data Kay.M4 I cannot start my microservices any more which are accessing MongoDB. A testcase is appended to produce the stacktrace below.  First I thought it is a Spring Boot issue spring-projects/spring-boot#9780 Stacktrace:    Affects: 2.0 M4 (Kay)  Attachments:     Backported to:  1.13.5 (Ingalls SR5)  1.12.12 (Hopper SR12)", "A_clean_title": ["repositorybeannamegener", "repositori", "bean", "name", "gener", "fail", "resolv", "bean", "name", "custom", "implement", "detect", "via", "spring", "compon", "index", "datacmn", "1115open", "comment", "after", "upgrad", "spring", "boot", "m2", "spring", "data", "kay", "m4", "not", "start", "my", "microservic", "ani", "more", "which", "are", "access", "mongodb", "mongo", "db", "testcas", "append", "produc", "stacktrac", "below", "first", "thought", "it", "spring", "boot", "issu", "spring", "boot", "project", "spring", "9780", "stacktrac", "affect", "m4", "kay", "attach", "backport", "13", "ingal", "sr5", "12", "12", "hopper", "sr12"], "B_title": "DATACMNS-1115 - Improve RepositoryBeanNameGenerator to properly resolve bean names for indexed BeanDefinitions.  Previously RepositoryBeanNameGenerator applied the custom bean name lookup if the BeanDefinition given was not a ScannedGenericBeanDefinition. That in turn had been the case for custom implementation classes that were obtained through classpath scanning. With Spring 5 an index file can be used by the scanner which in turn will cause AnnotatedGenericBeanDefinition instances being returned. That caused the code path to lookup the first constructor argument to kick in (usually used to obtain the repository interface from repository factory beans) and cause a NullPointerException.  We now forward AnnotatedBeanDefinitions as is and only apply the custom lookup for everything else i.e. the bean definitions used for the factories.", "B_clean_title": ["datacmn", "1115", "improv", "repositorybeannamegener", "repositori", "bean", "name", "gener", "properli", "resolv", "bean", "name", "index", "beandefinit", "bean", "definit", "previous", "repositorybeannamegener", "repositori", "bean", "name", "gener", "appli", "custom", "bean", "name", "lookup", "beandefinit", "bean", "definit", "given", "wa", "not", "scannedgenericbeandefinit", "scan", "gener", "bean", "definit", "that", "turn", "had", "been", "case", "custom", "implement", "class", "that", "were", "obtain", "through", "classpath", "scan", "spring", "index", "file", "use", "by", "scanner", "which", "turn", "will", "caus", "annotatedgenericbeandefinit", "annot", "gener", "bean", "definit", "instanc", "be", "return", "that", "caus", "code", "path", "lookup", "first", "constructor", "argument", "kick", "usual", "use", "obtain", "repositori", "interfac", "repositori", "factori", "bean", "caus", "nullpointerexcept", "null", "pointer", "except", "we", "now", "forward", "annotatedbeandefinit", "annot", "bean", "definit", "as", "onli", "appli", "custom", "lookup", "everyth", "bean", "definit", "use", "factori"]},
{"A_title": "Shell displays authTimeout poorlyThe authTimeout in the shell is displayed badly when executing about -v. Even though it is configured in integer minutes it is converted to seconds for display as a floating point number with 2 decimals. This makes no sense since the decimals will always be .00.  We can keep the units in seconds I guess but this needs to be displayed with %ds not %.2fs. This was broken in ACCUMULO-3224 by using TimeUnit to convert the number instead of dividing by 1000.0 as we were doing manually before.", "A_clean_title": ["shell", "display", "authtimeout", "auth", "timeout", "poorlyth", "poorli", "authtimeout", "auth", "timeout", "shell", "display", "badli", "when", "execut", "about", "even", "though", "it", "configur", "integ", "minut", "it", "convert", "second", "display", "as", "float", "point", "number", "decim", "thi", "make", "no", "sens", "sinc", "decim", "will", "alway", "00", "we", "keep", "unit", "second", "guess", "but", "thi", "need", "display", "ds", "not", "2f", "thi", "wa", "broken", "accumulo", "3224", "by", "timeunit", "time", "unit", "convert", "number", "instead", "divid", "by", "1000", "as", "we", "were", "do", "manual", "befor"], "B_title": "Format long as decimal integer not floating-point", "B_clean_title": ["format", "long", "as", "decim", "integ", "not", "float", "point"]},
{"A_title": "Lucene Index should ignore property existence checksSome optimizations on the query engine transform certain clauses in property existence checks. ie (p = somevalue turns into p is not null).  This doesnt play well with lucene as it can not  effectively build a not null query even worse the query doesnt return any results.  As a fix Ill just skip the existence constraints from the generated lucene query.", "A_clean_title": ["lucen", "index", "ignor", "properti", "exist", "checkssom", "check", "some", "optim", "queri", "engin", "transform", "certain", "claus", "properti", "exist", "check", "ie", "somevalu", "turn", "into", "not", "null", "thi", "doesnt", "play", "well", "lucen", "as", "it", "not", "effect", "build", "not", "null", "queri", "even", "wors", "queri", "doesnt", "return", "ani", "result", "as", "fix", "ill", "just", "skip", "exist", "constraint", "gener", "lucen", "queri"], "B_title": "Lucene Index should ignore property existence checks", "B_clean_title": ["lucen", "index", "ignor", "properti", "exist", "check"]},
{"A_title": "bug in org.apache.wicket.validation.validator.UrlValidatorLooks like there is a bug in UrlValidator. It validates URLs like http://testhost.local/pages/index.php as invalid. But URL is valid! Try to execute new java.net.URL(http://testhost.local/pages/index.php); for example. It does not throws MalformedURLException because URL is valid.  In method: UrlValidator.isValidAuthority() there is code: if (topLevel.length() < 2 || topLevel.length() > 4)return false; Looks like this > 4 is a wrong constraint.", "A_clean_title": ["bug", "org", "apach", "wicket", "valid", "valid", "urlvalidatorlook", "url", "valid", "look", "like", "there", "bug", "urlvalid", "url", "valid", "it", "valid", "url", "ur", "ls", "like", "http", "php", "testhost", "local", "page", "index", "as", "invalid", "but", "url", "valid", "tri", "execut", "new", "java", "net", "url", "http", "php", "testhost", "local", "page", "index", "exampl", "it", "not", "throw", "malformedurlexcept", "malform", "url", "except", "becaus", "url", "valid", "method", "urlvalid", "isvalidauthor", "url", "valid", "valid", "author", "there", "code", "toplevel", "length", "top", "level", "toplevel", "length", "top", "level", "return", "fals", "look", "like", "thi", "wrong", "constraint"], "B_title": "allow longer authorities in the url such as local Issue: WICKET-4255", "B_clean_title": ["allow", "longer", "author", "url", "such", "as", "local", "issu", "wicket", "4255"]},
{"A_title": "Ordered index does not return relative properties for un-restricted indexesEven if we specify an index without any restriction to node type; the ordered index does not return any result for relative properties", "A_clean_title": ["order", "index", "not", "return", "rel", "properti", "un", "restrict", "indexeseven", "index", "even", "we", "specifi", "index", "without", "ani", "restrict", "node", "type", "order", "index", "not", "return", "ani", "result", "rel", "properti"], "B_title": "- Ordered index does not return relative properties for un-restricted indexes", "B_clean_title": ["order", "index", "not", "return", "rel", "properti", "un", "restrict", "index"]},
{"A_title": "Brent solver doesnt throw IllegalArgumentException when initial guess has the wrong signJavadoc for public double solve(final UnivariateRealFunction f final double min final double max final double initial) claims that if the values of the function at the three points have the same sign an IllegalArgumentException is thrown. This case isnt even checked.", "A_clean_title": ["brent", "solver", "doesnt", "throw", "illegalargumentexcept", "illeg", "argument", "except", "when", "initi", "guess", "ha", "wrong", "signjavadoc", "sign", "javadoc", "public", "doubl", "solv", "final", "univariaterealfunct", "univari", "real", "function", "final", "doubl", "min", "final", "doubl", "max", "final", "doubl", "initi", "claim", "that", "valu", "function", "at", "three", "point", "have", "same", "sign", "illegalargumentexcept", "illeg", "argument", "except", "thrown", "thi", "case", "isnt", "even", "check"], "B_title": "Fixed a missing bracketing check of initial interval in Brent solver JIRA: MATH-343", "B_clean_title": ["fix", "miss", "bracket", "check", "initi", "interv", "brent", "solver", "jira", "math", "343"]},
{"A_title": "bug in inverseCumulativeProbability() for Normal Distribution@version  Revision: 617953    Date: 2008-02-02 22:54:00 -0700 (Sat 02 Feb 2008)    */ public class NormalDistributionImpl extends AbstractContinuousDistribution    @version  Revision: 506600    Date: 2007-02-12 12:35:59 -0700 (Mon 12 Feb 2007)    */ public abstract class AbstractContinuousDistribution  This code:         DistributionFactory factory = app.getDistributionFactory();         NormalDistribution normal = factory.createNormalDistribution(01);         double result = normal.inverseCumulativeProbability(0.9772498680518209); gives the exception below. It should return (approx) 2.0000... normal.inverseCumulativeProbability(0.977249868051820); works fine These also give errors: 0.9986501019683698 (should return 3.0000...) 0.9999683287581673 (should return 4.0000...) org.apache.commons.math.MathException: Number of iterations=1 maximum iterations=2147483647 initial=1 lower bound=0 upper bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 final a value=0 final b value=2 f(a)=-0.477 f(b)=0 at org.apache.commons.math.distribution.AbstractContinuousDistribution.inverseCumulativeProbability(AbstractContinuousDistribution.java:103) at org.apache.commons.math.distribution.NormalDistributionImpl.inverseCumulativeProbability(NormalDistributionImpl.java:145)", "A_clean_title": ["bug", "inversecumulativeprob", "invers", "cumul", "probabl", "normal", "distribut", "version", "revis", "617953", "date", "2008", "02", "02", "22:54:00", "0700", "sat", "02", "feb", "2008", "public", "class", "normaldistributionimpl", "normal", "distribut", "impl", "extend", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "version", "revis", "506600", "date", "2007", "02", "12", "12:35:59", "0700", "mon", "12", "feb", "2007", "public", "abstract", "class", "abstractcontinuousdistribut", "abstract", "continu", "distribut", "thi", "code", "distributionfactori", "distribut", "factori", "factori", "app", "getdistributionfactori", "get", "distribut", "factori", "normaldistribut", "normal", "distribut", "normal", "factori", "createnormaldistribut", "creat", "normal", "distribut", "01", "doubl", "result", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "9772498680518209", "give", "except", "below", "it", "return", "approx", "0000", "normal", "inversecumulativeprob", "invers", "cumul", "probabl", "977249868051820", "work", "fine", "these", "also", "give", "error", "9986501019683698", "return", "0000", "9999683287581673", "return", "0000", "org", "apach", "common", "math", "mathexcept", "math", "except", "number", "iterations=1", "maximum", "iterations=2147483647", "initial=1", "lower", "bound=0", "upper", "bound=179769313486231570000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "final", "value=0", "final", "value=2", "477", "=0", "at", "org", "apach", "common", "math", "distribut", "abstractcontinuousdistribut", "inversecumulativeprob", "abstract", "continu", "distribut", "invers", "cumul", "probabl", "abstractcontinuousdistribut", "java:103", "abstract", "continu", "distribut", "at", "org", "apach", "common", "math", "distribut", "normaldistributionimpl", "inversecumulativeprob", "normal", "distribut", "impl", "invers", "cumul", "probabl", "normaldistributionimpl", "java:145", "normal", "distribut", "impl"], "B_title": "fixed a bracketing issue due to inconsistent checks JIRA: MATH-280", "B_clean_title": ["fix", "bracket", "issu", "due", "inconsist", "check", "jira", "math", "280"]},
{"A_title": "Incorrect URL for setResponsePage() within a Form#onSubmit( )If the WebApplication uses IRequestCycleSettings.RenderStrategy.ONE_PASS_RENDER the issue described and exemplified in the attached quickstart at  https://issues.apache.org/jira/browse/WICKET-3442  prevails.   Clicking the link on /pageone results in this URL: /pageone?0-1.IFormSubmitListener-form", "A_clean_title": ["incorrect", "url", "setresponsepag", "set", "respons", "page", "within", "form", "onsubmit", "submit", "webappl", "web", "applic", "use", "irequestcycleset", "renderstrategi", "request", "cycl", "set", "render", "strategi", "one", "pass", "render", "issu", "describ", "exemplifi", "attach", "quickstart", "at", "http", "3442", "apach", "issu", "org", "jira", "brows", "wicket", "prevail", "click", "link", "pageon", "result", "thi", "url", "pageon", "form", "iformsubmitlisten", "form", "submit", "listen"], "B_title": "Incorrect URL for setResponsePage() within a Form#onSubmit( )", "B_clean_title": ["incorrect", "url", "setresponsepag", "set", "respons", "page", "within", "form", "onsubmit", "submit"]},
{"A_title": "MathRuntimeException with simple ebeMultiply on OpenMapRealVectorThe following piece of code  import org.apache.commons.math.linear.OpenMapRealVector; import org.apache.commons.math.linear.RealVector;  public class DemoBugOpenMapRealVector      public static void main(String args)          final RealVector u = new OpenMapRealVector(3 1E-6);         u.setEntry(0 1.);         u.setEntry(1 0.);         u.setEntry(2 2.);         final RealVector v = new OpenMapRealVector(3 1E-6);         v.setEntry(0 0.);         v.setEntry(1 3.);         v.setEntry(2 0.);         System.out.println(u);         System.out.println(v);         System.out.println(u.ebeMultiply(v));         raises an exception  org.apache.commons.math.linear.OpenMapRealVector@7170a9b6 Exception in thread main org.apache.commons.math.MathRuntimeException 6: map has been modified while iterating at org.apache.commons.math.MathRuntimeException.createConcurrentModificationException(MathRuntimeException.java:373) at org.apache.commons.math.util.OpenIntToDoubleHashMap Iterator.advance(OpenIntToDoubleHashMap.java:564) at org.apache.commons.math.linear.OpenMapRealVector.ebeMultiply(OpenMapRealVector.java:372) at org.apache.commons.math.linear.OpenMapRealVector.ebeMultiply(OpenMapRealVector.java:1) at DemoBugOpenMapRealVector.main(DemoBugOpenMapRealVector.java:17)", "A_clean_title": ["mathruntimeexcept", "math", "runtim", "except", "simpl", "ebemultipli", "ebe", "multipli", "openmaprealvectorth", "open", "map", "real", "vector", "follow", "piec", "code", "import", "org", "apach", "common", "math", "linear", "openmaprealvector", "open", "map", "real", "vector", "import", "org", "apach", "common", "math", "linear", "realvector", "real", "vector", "public", "class", "demobugopenmaprealvector", "demo", "bug", "open", "map", "real", "vector", "public", "static", "void", "main", "string", "arg", "final", "realvector", "real", "vector", "new", "openmaprealvector", "open", "map", "real", "vector", "1e", "setentri", "set", "entri", "setentri", "set", "entri", "setentri", "set", "entri", "final", "realvector", "real", "vector", "new", "openmaprealvector", "open", "map", "real", "vector", "1e", "setentri", "set", "entri", "setentri", "set", "entri", "setentri", "set", "entri", "system", "out", "println", "system", "out", "println", "system", "out", "println", "ebemultipli", "ebe", "multipli", "rais", "except", "org", "apach", "common", "math", "linear", "openmaprealvector", "open", "map", "real", "vector", "7170a9b6", "except", "thread", "main", "org", "apach", "common", "math", "mathruntimeexcept", "math", "runtim", "except", "map", "ha", "been", "modifi", "while", "iter", "at", "org", "apach", "common", "math", "mathruntimeexcept", "createconcurrentmodificationexcept", "math", "runtim", "except", "creat", "concurr", "modif", "except", "mathruntimeexcept", "java:373", "math", "runtim", "except", "at", "org", "apach", "common", "math", "util", "openinttodoublehashmap", "open", "int", "doubl", "hash", "map", "iter", "advanc", "openinttodoublehashmap", "java:564", "open", "int", "doubl", "hash", "map", "at", "org", "apach", "common", "math", "linear", "openmaprealvector", "ebemultipli", "open", "map", "real", "vector", "ebe", "multipli", "openmaprealvector", "java:372", "open", "map", "real", "vector", "at", "org", "apach", "common", "math", "linear", "openmaprealvector", "ebemultipli", "open", "map", "real", "vector", "ebe", "multipli", "openmaprealvector", "java:1", "open", "map", "real", "vector", "at", "demobugopenmaprealvector", "main", "demo", "bug", "open", "map", "real", "vector", "demobugopenmaprealvector", "java:17", "demo", "bug", "open", "map", "real", "vector"], "B_title": "Iterate on the original vector not on the copy that is modified.", "B_clean_title": ["iter", "origin", "vector", "not", "copi", "that", "modifi"]},
{"A_title": "wicketTester.executeAjaxEvent(combo onchange); works with 1.4-rc1 but not anymore with 1.4-rc2Try the attached Unit Test.", "A_clean_title": ["wickettest", "executeajaxev", "wicket", "tester", "execut", "ajax", "event", "combo", "onchang", "work", "rc1", "but", "not", "anymor", "rc2tri", "attach", "unit", "test"], "B_title": "fixed and added test case: wicketTester.executeAjaxEvent(combo onchange); works with 1.4-rc1 but not anymore with 1.4-rc2 Issue: WICKET-2261", "B_clean_title": ["fix", "ad", "test", "case", "wickettest", "executeajaxev", "wicket", "tester", "execut", "ajax", "event", "combo", "onchang", "work", "rc1", "but", "not", "anymor", "rc2", "issu", "wicket", "2261"]},
{"A_title": "Context must read system properties to rewrite properties from file.Context must read system properties to rewrite properties from file.", "A_clean_title": ["context", "must", "read", "system", "properti", "rewrit", "properti", "file", "context", "must", "read", "system", "properti", "rewrit", "properti", "file"], "B_title": "Context must read system properties to rewrite properties from file.  Close #58", "B_clean_title": ["context", "must", "read", "system", "properti", "rewrit", "properti", "file", "close", "58"]},
{"A_title": "Bugs in RealVector.ebeMultiply(RealVector) and ebeDivide(RealVector)OpenMapRealVector.ebeMultiply(RealVector) and OpenMapRealVector.ebeDivide(RealVector) return wrong values when one entry of the specified RealVector is nan or infinity. The bug is easy to understand. Here is the current implementation of ebeMultiply      public OpenMapRealVector ebeMultiply(RealVector v)          checkVectorDimensions(v.getDimension());         OpenMapRealVector res = new OpenMapRealVector(this);         Iterator iter = entries.iterator();         while (iter.hasNext())              iter.advance();             res.setEntry(iter.key() iter.value() * v.getEntry(iter.key()));                  return res;        The assumption is that for any double x x * 0d == 0d holds which is not true. The bug is easy enough to identify but more complex to solve. The only solution I can come up with is to loop through all entries of v (instead of those entries which correspond to non-zero entries of this). Im afraid about performance losses.", "A_clean_title": ["bug", "realvector", "ebemultipli", "real", "vector", "ebe", "multipli", "realvector", "real", "vector", "ebedivid", "ebe", "divid", "realvector", "real", "vector", "openmaprealvector", "ebemultipli", "open", "map", "real", "vector", "ebe", "multipli", "realvector", "real", "vector", "openmaprealvector", "ebedivid", "open", "map", "real", "vector", "ebe", "divid", "realvector", "real", "vector", "return", "wrong", "valu", "when", "one", "entri", "specifi", "realvector", "real", "vector", "nan", "or", "infin", "bug", "easi", "understand", "here", "current", "implement", "ebemultipli", "ebe", "multipli", "public", "openmaprealvector", "open", "map", "real", "vector", "ebemultipli", "ebe", "multipli", "realvector", "real", "vector", "checkvectordimens", "check", "vector", "dimens", "getdimens", "get", "dimens", "openmaprealvector", "open", "map", "real", "vector", "re", "new", "openmaprealvector", "open", "map", "real", "vector", "thi", "iter", "iter", "entri", "iter", "while", "iter", "hasnext", "ha", "next", "iter", "advanc", "re", "setentri", "set", "entri", "iter", "key", "iter", "valu", "getentri", "get", "entri", "iter", "key", "return", "re", "assumpt", "that", "ani", "doubl", "0d", "0d", "hold", "which", "not", "true", "bug", "easi", "enough", "identifi", "but", "more", "complex", "solv", "onli", "solut", "come", "up", "loop", "through", "all", "entri", "instead", "those", "entri", "which", "correspond", "non", "zero", "entri", "thi", "im", "afraid", "about", "perform", "loss"], "B_title": "  - modified OpenMapRealVector.ebeMultiply() and ebeDivide() to handle special cases  0d * NaN 0d * Infinity 0d / 0d and 0d / NaN.   - added implementation of isNaN() and isInfinite() to SparseRealVectorTest.SparseRealVectorTestImpl in order to allow for testing of OpenMapRealVector.ebeMultiply() and ebeDivide() with mixed types.", "B_clean_title": ["modifi", "openmaprealvector", "ebemultipli", "open", "map", "real", "vector", "ebe", "multipli", "ebedivid", "ebe", "divid", "handl", "special", "case", "0d", "nan", "na", "0d", "infin", "0d", "0d", "0d", "nan", "na", "ad", "implement", "isnan", "na", "isinfinit", "infinit", "sparserealvectortest", "sparserealvectortestimpl", "spars", "real", "vector", "test", "spars", "real", "vector", "test", "impl", "order", "allow", "test", "openmaprealvector", "ebemultipli", "open", "map", "real", "vector", "ebe", "multipli", "ebedivid", "ebe", "divid", "mix", "type"]},
{"A_title": "Using an IValidator on an AjaxEditableLabel causes ClassCastExceptionAjaxEditableLabel<Integer> label = new AjaxEditableLabel<Integer>(label new PropertyModel<Integer>(this value)); form.add(label); label.setRequired(true); label.add(new RangeValidator<Integer>(1 10));  Using a RangeValidator<Integer> on an AjaxEditableLabel<Integer>  causes an ClassCastException after editing the label.   java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String  This can be avoided by setting the type explicit on the AjaxEditableLabel.  label.setType(Integer.class);  But this wasnt necessary in Wicket 1.4.19. In this version all works fine without setting the type explicit.  I found out that AbstractTextComponent.resolveType() is not able to get the type of the DefaultModel of the AjaxEditableLabel in Wicket 1.5.3.  I will attach two QuickStarts to demonstrate the bug. One with wicket 1.4.19 and the other with Wicket 1.5.3", "A_clean_title": ["ivalid", "valid", "ajaxeditablelabel", "ajax", "edit", "label", "caus", "classcastexceptionajaxeditablelabel", "class", "cast", "except", "ajax", "edit", "label", "integ", "label", "new", "ajaxeditablelabel", "ajax", "edit", "label", "integ", "label", "new", "propertymodel", "properti", "model", "integ", "thi", "valu", "form", "add", "label", "label", "setrequir", "set", "requir", "true", "label", "add", "new", "rangevalid", "rang", "valid", "integ", "10", "rangevalid", "rang", "valid", "integ", "ajaxeditablelabel", "ajax", "edit", "label", "integ", "caus", "classcastexcept", "class", "cast", "except", "after", "edit", "label", "java", "lang", "classcastexcept", "class", "cast", "except", "java", "lang", "integ", "not", "cast", "java", "lang", "string", "thi", "avoid", "by", "set", "type", "explicit", "ajaxeditablelabel", "ajax", "edit", "label", "label", "settyp", "set", "type", "integ", "class", "but", "thi", "wasnt", "necessari", "wicket", "19", "thi", "version", "all", "work", "fine", "without", "set", "type", "explicit", "found", "out", "that", "abstracttextcompon", "resolvetyp", "abstract", "text", "compon", "resolv", "type", "not", "abl", "get", "type", "defaultmodel", "default", "model", "ajaxeditablelabel", "ajax", "edit", "label", "wicket", "will", "attach", "two", "quickstart", "quick", "start", "demonstr", "bug", "one", "wicket", "19", "other", "wicket"], "B_title": "Preventing the AjaxEditableLabel from loose its model object type when initializing its editor component Issue: WICKET-4259", "B_clean_title": ["prevent", "ajaxeditablelabel", "ajax", "edit", "label", "loos", "it", "model", "object", "type", "when", "initi", "it", "editor", "compon", "issu", "wicket", "4259"]},
{"A_title": "NPE during syncAllExternalUsers in LdapIdentityProvider.createUserWhen executing the JMX method syncAllExternalUsers the following NPE has been encountered. This likely indicates that - for a particular user - there is no attribute uid:  code java.lang.NullPointerException at org.apache.jackrabbit.oak.security.authentication.ldap.impl.LdapIdentityProvider.createUser(LdapIdentityProvider.java:667) at org.apache.jackrabbit.oak.security.authentication.ldap.impl.LdapIdentityProvider.access 000(LdapIdentityProvider.java:88) at org.apache.jackrabbit.oak.security.authentication.ldap.impl.LdapIdentityProvider 1.getNext(LdapIdentityProvider.java:281) at org.apache.jackrabbit.oak.security.authentication.ldap.impl.LdapIdentityProvider 1.getNext(LdapIdentityProvider.java:273) at org.apache.jackrabbit.commons.iterator.AbstractLazyIterator.hasNext(AbstractLazyIterator.java:39) at org.apache.jackrabbit.oak.spi.security.authentication.external.impl.jmx.SyncMBeanImpl Delegatee.syncAllExternalUsers(SyncMBeanImpl.java:245) at org.apache.jackrabbit.oak.spi.security.authentication.external.impl.jmx.SyncMBeanImpl.syncAllExternalUsers(SyncMBeanImpl.java:426) code", "A_clean_title": ["npe", "dure", "syncallexternalus", "sync", "all", "extern", "user", "ldapidentityprovid", "createuserwhen", "ldap", "ident", "provid", "creat", "user", "when", "execut", "jmx", "method", "syncallexternalus", "sync", "all", "extern", "user", "follow", "npe", "ha", "been", "encount", "thi", "like", "indic", "that", "particular", "user", "there", "no", "attribut", "uid", "code", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "jackrabbit", "oak", "secur", "authent", "ldap", "impl", "ldapidentityprovid", "createus", "ldap", "ident", "provid", "creat", "user", "ldapidentityprovid", "java:667", "ldap", "ident", "provid", "at", "org", "apach", "jackrabbit", "oak", "secur", "authent", "ldap", "impl", "ldapidentityprovid", "access", "ldap", "ident", "provid", "000", "ldapidentityprovid", "java:88", "ldap", "ident", "provid", "at", "org", "apach", "jackrabbit", "oak", "secur", "authent", "ldap", "impl", "ldapidentityprovid", "ldap", "ident", "provid", "getnext", "get", "next", "ldapidentityprovid", "java:281", "ldap", "ident", "provid", "at", "org", "apach", "jackrabbit", "oak", "secur", "authent", "ldap", "impl", "ldapidentityprovid", "ldap", "ident", "provid", "getnext", "get", "next", "ldapidentityprovid", "java:273", "ldap", "ident", "provid", "at", "org", "apach", "jackrabbit", "common", "iter", "abstractlazyiter", "hasnext", "abstract", "lazi", "iter", "ha", "next", "abstractlazyiter", "java:39", "abstract", "lazi", "iter", "at", "org", "apach", "jackrabbit", "oak", "spi", "secur", "authent", "extern", "impl", "jmx", "syncmbeanimpl", "sync", "bean", "impl", "delegate", "syncallexternalus", "sync", "all", "extern", "user", "syncmbeanimpl", "java:245", "sync", "bean", "impl", "at", "org", "apach", "jackrabbit", "oak", "spi", "secur", "authent", "extern", "impl", "jmx", "syncmbeanimpl", "syncallexternalus", "sync", "bean", "impl", "sync", "all", "extern", "user", "syncmbeanimpl", "java:426", "sync", "bean", "impl", "code"], "B_title": "NPE during syncAllExternalUsers in LdapIdentityProvider.createUser", "B_clean_title": ["npe", "dure", "syncallexternalus", "sync", "all", "extern", "user", "ldapidentityprovid", "createus", "ldap", "ident", "provid", "creat", "user"]},
{"A_title": "NodeDocument.getNewestRevision() incorrect when there are previous documentsThe method may incorrectly return null when there are previous documents and the base revision is lower than all local changes.  This is most likely caused by changes done for OAK-3388.", "A_clean_title": ["nodedocu", "getnewestrevis", "node", "document", "get", "newest", "revis", "incorrect", "when", "there", "are", "previou", "documentsth", "document", "method", "may", "incorrectli", "return", "null", "when", "there", "are", "previou", "document", "base", "revis", "lower", "than", "all", "local", "chang", "thi", "most", "like", "caus", "by", "chang", "done", "oak", "3388"], "B_title": "NodeDocument.getNewestRevision() incorrect when there are previous documents", "B_clean_title": ["nodedocu", "getnewestrevis", "node", "document", "get", "newest", "revis", "incorrect", "when", "there", "are", "previou", "document"]},
{"A_title": "StringUtils.join throws NPE when toString returns null for one of objects in collectionTry    StringUtils.join(new Object         new Object()            @Override           public String toString()              return null;                          );   ToString should probably never return null but it does in javax.mail.internet.InternetAddress", "A_clean_title": ["stringutil", "join", "string", "util", "throw", "npe", "when", "tostr", "string", "return", "null", "one", "object", "collectiontri", "collect", "tri", "stringutil", "join", "string", "util", "new", "object", "new", "object", "overrid", "public", "string", "tostr", "string", "return", "null", "tostr", "string", "probabl", "never", "return", "null", "but", "it", "javax", "mail", "internet", "internetaddress", "internet", "address"], "B_title": "Applying Ilyas patch from LANG-703 fixing an NPE when toString returns null", "B_clean_title": ["appli", "ilya", "patch", "lang", "703", "fix", "npe", "when", "tostr", "string", "return", "null"]},
{"A_title": "bug in removeStatementIn this example if you want to remove the second i++ with  block.removeStatement(block.getStatement(3));  Spoon removes the first one.  (found by  @martinezmatias thanks!)", "A_clean_title": ["bug", "removestatementin", "remov", "statement", "thi", "exampl", "you", "want", "remov", "second", "i++", "block", "removestat", "remov", "statement", "block", "getstat", "get", "statement", "spoon", "remov", "first", "one", "found", "by", "martinezmatia", "thank"], "B_title": "fix: fix wrong behavior for special cases in removeStatement. Closes #1221. (#1224)", "B_clean_title": ["fix", "fix", "wrong", "behavior", "special", "case", "removestat", "remov", "statement", "close", "1221", "1224"]},
{"A_title": "PageParameters#set not follow INamedParameters#set behaviorCouple of problems to work with page parameters: Major - The PageParameters#set(final String name final Object value final int index) used remove/add pattern instead of set parameter value by specified index. Minor - Inposible to get the index of key in elegant way to use obtained index in #set operation", "A_clean_title": ["pageparamet", "page", "paramet", "set", "not", "follow", "inamedparamet", "name", "paramet", "set", "behaviorcoupl", "behavior", "coupl", "problem", "work", "page", "paramet", "major", "pageparamet", "page", "paramet", "set", "final", "string", "name", "final", "object", "valu", "final", "int", "index", "use", "remov", "add", "pattern", "instead", "set", "paramet", "valu", "by", "specifi", "index", "minor", "inpos", "get", "index", "key", "eleg", "way", "use", "obtain", "index", "set", "oper"], "B_title": "PageParameters#set not follow INamedParameters#set behavior", "B_clean_title": ["pageparamet", "page", "paramet", "set", "not", "follow", "inamedparamet", "name", "paramet", "set", "behavior"]},
{"A_title": "Inconsistent handling of non-JSDoc commentsNone", "A_clean_title": ["inconsist", "handl", "non", "jsdoc", "js", "doc", "commentsnon", "comment", "none"], "B_title": "Improve detection of suspicious block comments.", "B_clean_title": ["improv", "detect", "suspici", "block", "comment"]},
{"A_title": "Wrong constructor picked up when deserializing objectI discovered an issue with Jackson 2.7.8 (and Jackson 2.8.4) when several constructors have parameters annotated with  @JsonProperty but only one is annotated with @JsonCreator . Heres a test case to reproduce it:   This test throws an the following exception:   After some debugging it looks like that  BasicDeserializerFactory#_addDeserializerConstructors(...) is looping over all the constructors and is not favoring an explicit constructor over a non-explicit one. I actually dont know what should be the expected behavior: should jackson fail when two constructors are annotated or should jackson favor the one annotated with  @JsonCreator . Both options look reasonable to me (and Im actually removing one of the constructors).", "A_clean_title": ["wrong", "constructor", "pick", "up", "when", "deseri", "objecti", "object", "discov", "issu", "jackson", "jackson", "when", "sever", "constructor", "have", "paramet", "annot", "jsonproperti", "json", "properti", "but", "onli", "one", "annot", "jsoncreat", "json", "creator", "here", "test", "case", "reproduc", "it", "thi", "test", "throw", "follow", "except", "after", "some", "debug", "it", "look", "like", "that", "basicdeserializerfactori", "basic", "deseri", "factori", "adddeserializerconstructor", "add", "deseri", "constructor", "loop", "over", "all", "constructor", "not", "favor", "explicit", "constructor", "over", "non", "explicit", "one", "actual", "dont", "know", "what", "expect", "behavior", "jackson", "fail", "when", "two", "constructor", "are", "annot", "or", "jackson", "favor", "one", "annot", "jsoncreat", "json", "creator", "both", "option", "look", "reason", "me", "im", "actual", "remov", "one", "constructor"], "B_title": "Fix #1476", "B_clean_title": ["fix", "1476"]},
{"A_title": "JCommon 1.0.12 ShapeUtilities.equal(path1path2)The comparison of two GeneralPath objects uses the same PathIterator for both objects. equal(GeneralPath path1 GeneralPath path2) will thus return true for any pair of non-null GeneralPath instances having the same windingRule.", "A_clean_title": ["jcommon", "common", "12", "shapeutil", "equal", "shape", "util", "path1path2", "comparison", "two", "generalpath", "gener", "path", "object", "use", "same", "pathiter", "path", "iter", "both", "object", "equal", "generalpath", "gener", "path", "path1", "generalpath", "gener", "path", "path2", "will", "thu", "return", "true", "ani", "pair", "non", "null", "generalpath", "gener", "path", "instanc", "have", "same", "windingrul", "wind", "rule"], "B_title": "source/org/jfree/chart/util/SerialUtilities.java (readShape): Handle SEG_CLOSE for GeneralPath Use correct path for comparison.", "B_clean_title": ["java", "sourc", "org", "jfree", "chart", "util", "serialutil", "serial", "util", "readshap", "read", "shape", "handl", "seg", "close", "generalpath", "gener", "path", "use", "correct", "path", "comparison"]},
{"A_title": "ProxyingHandlerMethodArgumentResolver handles interfaces not intended for projection DATACMNS-776opened and commented A Spring Boot application that depends on  spring-boot-starter-data-pa and uses Spring Mobile will create a proxy for Spring Mobiles Device interface when its injected into a handler method. Calling isMobile on this proxy fails as follows:  The culprit is  ProxyingHandlerMethodArgumentResolver which takes responsibility for any argument thats an interface. I can work around the problem by ensuring that Spring Mobiles DeviceHandlerMethodArgumentResolver appears before ProxyingHandlerMethodArgumentResolver in Spring MVCs list of argument resolvers but Id prefer not to have to do so. Can ProxyingHandlerMethodArgumentResolver be fixed so that it either doesnt claim responsibility for anything thats an interface or so that it returns a working proxy?   Affects: 1.10.2 (Fowler SR2) 1.11 GA (Gosling)  Issue Links:     Backported to:  1.13 GA (Ingalls)  1.12.7 (Hopper SR7)  1.11.7 (Gosling SR7) 4 votes 8 watchers", "A_clean_title": ["proxyinghandlermethodargumentresolv", "proxi", "handler", "method", "argument", "resolv", "handl", "interfac", "not", "intend", "project", "datacmn", "776open", "comment", "spring", "boot", "applic", "that", "depend", "spring", "boot", "starter", "data", "pa", "use", "spring", "mobil", "will", "creat", "proxi", "spring", "mobil", "devic", "interfac", "when", "it", "inject", "into", "handler", "method", "call", "ismobil", "mobil", "thi", "proxi", "fail", "as", "follow", "culprit", "proxyinghandlermethodargumentresolv", "proxi", "handler", "method", "argument", "resolv", "which", "take", "respons", "ani", "argument", "that", "interfac", "work", "around", "problem", "by", "ensur", "that", "spring", "mobil", "devicehandlermethodargumentresolv", "devic", "handler", "method", "argument", "resolv", "appear", "befor", "proxyinghandlermethodargumentresolv", "proxi", "handler", "method", "argument", "resolv", "spring", "mvc", "mv", "cs", "list", "argument", "resolv", "but", "id", "prefer", "not", "have", "so", "proxyinghandlermethodargumentresolv", "proxi", "handler", "method", "argument", "resolv", "fix", "so", "that", "it", "either", "doesnt", "claim", "respons", "anyth", "that", "interfac", "or", "so", "that", "it", "return", "work", "proxi", "affect", "10", "fowler", "sr2", "11", "ga", "gosl", "issu", "link", "backport", "13", "ga", "ingal", "12", "hopper", "sr7", "11", "gosl", "sr7", "vote", "watcher"], "B_title": "DATACMNS-776 - Made ProxyingHandlerMethodArgumentResolver to only support user types or annotated ones.  ProxyingHandlerMethodArgumentResolver is now more lenient when it comes to which types to support for proxying. As indicated in the ticket weve been to aggressive opting in for all interfaces which - depending on the order of converter registrations - caused us interfering with other interface based resolutions (e.g. in Spring Mobile Security etc.).  We now only aggressively kick in if either the type or parameter is annotated with @ProjectedPayload or the type itself is not a Spring Framework or native Java one. This should leave user defined types still be accepted whereas the types we previously erroneously interfered with should now be ignored.", "B_clean_title": ["datacmn", "776", "made", "proxyinghandlermethodargumentresolv", "proxi", "handler", "method", "argument", "resolv", "onli", "support", "user", "type", "or", "annot", "one", "proxyinghandlermethodargumentresolv", "proxi", "handler", "method", "argument", "resolv", "now", "more", "lenient", "when", "it", "come", "which", "type", "support", "proxi", "as", "indic", "ticket", "weve", "been", "aggress", "opt", "all", "interfac", "which", "depend", "order", "convert", "registr", "caus", "us", "interf", "other", "interfac", "base", "resolut", "spring", "mobil", "secur", "etc", "we", "now", "onli", "aggress", "kick", "either", "type", "or", "paramet", "annot", "projectedpayload", "project", "payload", "or", "type", "itself", "not", "spring", "framework", "or", "nativ", "java", "one", "thi", "leav", "user", "defin", "type", "still", "accept", "wherea", "type", "we", "previous", "erron", "interf", "now", "ignor"]},
{"A_title": "ArgumentCaptor no longer working for varargsWhen upgrading 1.10.8 the verify passes but the getValue() fails with this error. One other piece of info came to light as a result of creating the MCVE - the test works fine if the Date is the only element passed for bindVariables. That is remove var1 from target and test code then the test runs fine under 1.9.5 and 1.10.8. Also it doesnt matter that the captor is for a Date. The same issue occurs if the parameter is of another type such as Integer.", "A_clean_title": ["argumentcaptor", "argument", "captor", "no", "longer", "work", "varargswhen", "vararg", "when", "upgrad", "10", "verifi", "pass", "but", "getvalu", "get", "valu", "fail", "thi", "error", "one", "other", "piec", "info", "came", "light", "as", "result", "creat", "mcve", "test", "work", "fine", "date", "onli", "element", "pass", "bindvari", "bind", "variabl", "that", "remov", "var1", "target", "test", "code", "then", "test", "run", "fine", "under", "10", "also", "it", "doesnt", "matter", "that", "captor", "date", "same", "issu", "occur", "paramet", "anoth", "type", "such", "as", "integ"], "B_title": "Fix for issue 211", "B_clean_title": ["fix", "issu", "211"]},
{"A_title": "MultidimensionalCounter does not throw NoSuchElementExceptionThe iterator should throw when next() is called even though hasNext() would return false.", "A_clean_title": ["multidimensionalcount", "multidimension", "counter", "not", "throw", "nosuchelementexceptionth", "no", "such", "element", "except", "iter", "throw", "when", "next", "call", "even", "though", "hasnext", "ha", "next", "would", "return", "fals"], "B_title": "Ensure that bad usage will raise an exception.", "B_clean_title": ["ensur", "that", "bad", "usag", "will", "rais", "except"]},
{"A_title": "Classify non-rightmost expressions as problematicNone", "A_clean_title": ["classifi", "non", "rightmost", "express", "as", "problematicnon", "problemat", "none"], "B_title": "Automated g4 rollback", "B_clean_title": ["autom", "g4", "rollback"]},
{"A_title": "compiler crashes when  goog.provide used with non stringNone", "A_clean_title": ["compil", "crash", "when", "goog", "provid", "use", "non", "stringnon", "string", "none"], "B_title": "Handle bad goog.require/goog.provide calls more gracefully. Fixes issue 530.", "B_clean_title": ["handl", "bad", "goog", "provid", "requir", "goog", "call", "more", "grace", "fix", "issu", "530"]},
{"A_title": ":childOrder out of sync when node is made orderable concurrentlyThe ChildOrderConflictHandler does not merge the :childOrder when an addExistingProperty conflict occurs.", "A_clean_title": ["childord", "child", "order", "out", "sync", "when", "node", "made", "order", "concurrentlyth", "concurr", "childorderconflicthandl", "child", "order", "conflict", "handler", "not", "merg", "childord", "child", "order", "when", "addexistingproperti", "add", "exist", "properti", "conflict", "occur"], "B_title": ":childOrder out of sync when node is made orderable concurrently", "B_clean_title": ["childord", "child", "order", "out", "sync", "when", "node", "made", "order", "concurr"]},
{"A_title": "Async Update fails after IllegalArgumentExceptionThe async index update can fail due to a mismatch between an index definition and the actual content. If that is the case it seems that it can no longer make any progress. Instead it re-indexes the latest changes over and over again until it hits the problematic property.  Discussion at http://markmail.org/thread/42bixzkrkwv4s6tq  Stacktrace attached.", "A_clean_title": ["async", "updat", "fail", "after", "illegalargumentexceptionth", "illeg", "argument", "except", "async", "index", "updat", "fail", "due", "mismatch", "between", "index", "definit", "actual", "content", "that", "case", "it", "seem", "that", "it", "no", "longer", "make", "ani", "progress", "instead", "it", "re", "index", "latest", "chang", "over", "over", "again", "until", "it", "hit", "problemat", "properti", "discuss", "at", "http", "markmail", "org", "thread", "42bixzkrkwv4s6tq", "stacktrac", "attach"], "B_title": "Async Update fails after IllegalArgumentException", "B_clean_title": ["async", "updat", "fail", "after", "illegalargumentexcept", "illeg", "argument", "except"]},
{"A_title": "BlockedOutputStream can hit a StackOverflowErrorThis issue mostly came up after a resolution to ACCUMULO-2668 that allows a byte to be passed directly to the underlying stream from the NoFlushOutputStream.  The problem appears to be due to the BlockedOutputStream.write(byte int int) implementation that recursively writes out blocks/buffers out. When the stream is passed a large mutation (128MB was sufficient to trigger the error for me) this will cause a StackOverflowError.   This is appears to be specifically with encryption at rest turned on.  A simple fix would be to unroll the recursion.", "A_clean_title": ["blockedoutputstream", "block", "output", "stream", "hit", "stackoverflowerrorthi", "stack", "overflow", "error", "thi", "issu", "mostli", "came", "up", "after", "resolut", "accumulo", "2668", "that", "allow", "byte", "pass", "directli", "underli", "stream", "noflushoutputstream", "no", "flush", "output", "stream", "problem", "appear", "due", "blockedoutputstream", "write", "block", "output", "stream", "byte", "int", "int", "implement", "that", "recurs", "write", "out", "block", "buffer", "out", "when", "stream", "pass", "larg", "mutat", "128mb", "wa", "suffici", "trigger", "error", "me", "thi", "will", "caus", "stackoverflowerror", "stack", "overflow", "error", "thi", "appear", "specif", "encrypt", "at", "rest", "turn", "simpl", "fix", "would", "unrol", "recurs"], "B_title": "Refactoring BlockedOutputStream to not recurse. With test", "B_clean_title": ["refactor", "blockedoutputstream", "block", "output", "stream", "not", "recurs", "test"]},
{"A_title": "Fixing AjaxTimerBehaviorTestThis is an attempt to fix failing testcase:  target/surefire-reports/wicket.ajax.AjaxTimerBehaviorTest.txt ------------------------------------------------------------------------------- Test set: wicket.ajax.AjaxTimerBehaviorTest ------------------------------------------------------------------------------- Tests run: 2 Failures: 2 Errors: 0 Skipped: 0 Time elapsed: 0.113 sec <<< FAILURE! testAddToAjaxUpdate(wicket.ajax.AjaxTimerBehaviorTest)  Time elapsed: 0.063 sec  <<< FAILURE! junit.framework.AssertionFailedError: There should be 1 and only 1 script in the markup for this behaviorbut 0 were found exp ected:<1> but was:<0>         at junit.framework.Assert.fail(Assert.java:47)         at junit.framework.Assert.failNotEquals(Assert.java:282)         at junit.framework.Assert.assertEquals(Assert.java:64)         at junit.framework.Assert.assertEquals(Assert.java:201)         at wicket.ajax.AjaxTimerBehaviorTest.validateTimerScript(AjaxTimerBehaviorTest.java:178)         at wicket.ajax.AjaxTimerBehaviorTest.validate(AjaxTimerBehaviorTest.java:143)         at wicket.ajax.AjaxTimerBehaviorTest.testAddToAjaxUpdate(AjaxTimerBehaviorTest.java:99)  testAddToWebPage(wicket.ajax.AjaxTimerBehaviorTest)  Time elapsed: 0.026 sec  <<< FAILURE! junit.framework.AssertionFailedError: There should be 1 and only 1 script in the markup for this behaviorbut 0 were found exp ected:<1> but was:<0>         at junit.framework.Assert.fail(Assert.java:47)         at junit.framework.Assert.failNotEquals(Assert.java:282)         at junit.framework.Assert.assertEquals(Assert.java:64)         at junit.framework.Assert.assertEquals(Assert.java:201)         at wicket.ajax.AjaxTimerBehaviorTest.validateTimerScript(AjaxTimerBehaviorTest.java:178)         at wicket.ajax.AjaxTimerBehaviorTest.validate(AjaxTimerBehaviorTest.java:155)         at wicket.ajax.AjaxTimerBehaviorTest.testAddToWebPage(AjaxTimerBehaviorTest.java:127)  The attached patch properly handles the case when the callback script is added in body onload.  Also AbstractAjaxTimerBehavior needs to handle AjaxRequestTarget properly because adding a body onload has no effect in an ajax request.", "A_clean_title": ["fix", "ajaxtimerbehaviortestthi", "ajax", "timer", "behavior", "test", "thi", "attempt", "fix", "fail", "testcas", "target", "surefir", "ajax", "ajaxtimerbehaviortest", "txt", "report", "wicket", "ajax", "timer", "behavior", "test", "test", "set", "wicket", "ajax", "ajaxtimerbehaviortest", "ajax", "timer", "behavior", "test", "test", "run", "failur", "error", "skip", "time", "elaps", "113", "sec", "failur", "testaddtoajaxupd", "test", "add", "ajax", "updat", "wicket", "ajax", "ajaxtimerbehaviortest", "ajax", "timer", "behavior", "test", "time", "elaps", "063", "sec", "failur", "junit", "framework", "assertionfailederror", "assert", "fail", "error", "there", "onli", "script", "markup", "thi", "behaviorbut", "were", "found", "exp", "ect", "but", "wa", "at", "junit", "framework", "assert", "fail", "assert", "java:47", "at", "junit", "framework", "assert", "failnotequ", "fail", "not", "equal", "assert", "java:282", "at", "junit", "framework", "assert", "assertequ", "assert", "equal", "assert", "java:64", "at", "junit", "framework", "assert", "assertequ", "assert", "equal", "assert", "java:201", "at", "wicket", "ajax", "ajaxtimerbehaviortest", "validatetimerscript", "ajax", "timer", "behavior", "test", "valid", "timer", "script", "ajaxtimerbehaviortest", "java:178", "ajax", "timer", "behavior", "test", "at", "wicket", "ajax", "ajaxtimerbehaviortest", "valid", "ajax", "timer", "behavior", "test", "ajaxtimerbehaviortest", "java:143", "ajax", "timer", "behavior", "test", "at", "wicket", "ajax", "ajaxtimerbehaviortest", "testaddtoajaxupd", "ajax", "timer", "behavior", "test", "test", "add", "ajax", "updat", "ajaxtimerbehaviortest", "java:99", "ajax", "timer", "behavior", "test", "testaddtowebpag", "test", "add", "web", "page", "wicket", "ajax", "ajaxtimerbehaviortest", "ajax", "timer", "behavior", "test", "time", "elaps", "026", "sec", "failur", "junit", "framework", "assertionfailederror", "assert", "fail", "error", "there", "onli", "script", "markup", "thi", "behaviorbut", "were", "found", "exp", "ect", "but", "wa", "at", "junit", "framework", "assert", "fail", "assert", "java:47", "at", "junit", "framework", "assert", "failnotequ", "fail", "not", "equal", "assert", "java:282", "at", "junit", "framework", "assert", "assertequ", "assert", "equal", "assert", "java:64", "at", "junit", "framework", "assert", "assertequ", "assert", "equal", "assert", "java:201", "at", "wicket", "ajax", "ajaxtimerbehaviortest", "validatetimerscript", "ajax", "timer", "behavior", "test", "valid", "timer", "script", "ajaxtimerbehaviortest", "java:178", "ajax", "timer", "behavior", "test", "at", "wicket", "ajax", "ajaxtimerbehaviortest", "valid", "ajax", "timer", "behavior", "test", "ajaxtimerbehaviortest", "java:155", "ajax", "timer", "behavior", "test", "at", "wicket", "ajax", "ajaxtimerbehaviortest", "testaddtowebpag", "ajax", "timer", "behavior", "test", "test", "add", "web", "page", "ajaxtimerbehaviortest", "java:127", "ajax", "timer", "behavior", "test", "attach", "patch", "properli", "handl", "case", "when", "callback", "script", "ad", "bodi", "onload", "also", "abstractajaxtimerbehavior", "abstract", "ajax", "timer", "behavior", "need", "handl", "ajaxrequesttarget", "ajax", "request", "target", "properli", "becaus", "ad", "bodi", "onload", "ha", "no", "effect", "ajax", "request"], "B_title": "Fixing AjaxTimerBehaviorTest. It looks ok. The rendered outputs in both an AJAX and NOT-AJAX situation looks fine (escaping of  is correct). JBQ please use Java1.4 in any wicket1.x projects which requires this (String.replace(String String) doesnt exist in 1.4)", "B_clean_title": ["fix", "ajaxtimerbehaviortest", "ajax", "timer", "behavior", "test", "it", "look", "ok", "render", "output", "both", "ajax", "not", "ajax", "situat", "look", "fine", "escap", "correct", "jbq", "pleas", "use", "java1", "ani", "wicket1", "project", "which", "requir", "thi", "string", "replac", "string", "string", "doesnt", "exist"]},
{"A_title": "Last warning or error in output is truncatedNone", "A_clean_title": ["last", "warn", "or", "error", "output", "truncatednon", "truncat", "none"], "B_title": "When getting a line from the source code according to the line number if it happens to be the last line and n character is missing in the end of the file we should still return the last line.", "B_clean_title": ["when", "get", "line", "sourc", "code", "accord", "line", "number", "it", "happen", "last", "line", "charact", "miss", "end", "file", "we", "still", "return", "last", "line"]},
{"A_title": "StdDateFormat deserializes dates with no tz/offset as UTC instead of configured timezonePrior to version  2.8.9  dates without time zone or time offset (eg 1970-01-01T00:00:00.000 ) were deserialised in the TimeZone set on the ObjectMapper. Starting from 2.8.9  these dates are deserialised in UTC - which is a major (breaking) change in behaviour... Example:", "A_clean_title": ["stddateformat", "std", "date", "format", "deseri", "date", "no", "tz", "offset", "as", "utc", "instead", "configur", "timezoneprior", "timezon", "prior", "version", "date", "without", "time", "zone", "or", "time", "offset", "eg", "1970", "01", "01t00:00:00", "000", "were", "deserialis", "timezon", "time", "zone", "set", "objectmapp", "object", "mapper", "start", "these", "date", "are", "deserialis", "utc", "which", "major", "break", "chang", "behaviour", "exampl"], "B_title": "Fix #1657 (I hope)", "B_clean_title": ["fix", "1657", "hope"]},
{"A_title": "LevenbergMarquardtOptimizer reports 0 iterationsThe method LevenbergMarquardtOptimizer.getIterations() does not report the correct number of iterations; It always returns 0. A quick look at the code shows that only SimplexOptimizer calls BaseOptimizer.incrementEvaluationsCount()  Ive put a test case below. Notice how the evaluations count is correctly incremented but the iterations count is not.  noformat     @Test     public void testGetIterations()          // setup         LevenbergMarquardtOptimizer otim = new LevenbergMarquardtOptimizer();          // action         otim.optimize(new MaxEval(100) new Target(new double  1 )                 new Weight(new double  1 ) new InitialGuess(                         new double  3 ) new ModelFunction(                         new MultivariateVectorFunction()                              @Override                             public double value(double point)                                     throws IllegalArgumentException                                  return new double  FastMath.pow(point0 4) ;                                                      ) new ModelFunctionJacobian(                         new MultivariateMatrixFunction()                              @Override                             public double value(double point)                                     throws IllegalArgumentException                                  return new double   0.25 * FastMath.pow(                                         point0 3)  ;                                                      ));          // verify         assertThat(otim.getEvaluations() greaterThan(1));         assertThat(otim.getIterations() greaterThan(1));       noformat", "A_clean_title": ["levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "report", "iterationsth", "iter", "method", "levenbergmarquardtoptim", "getiter", "levenberg", "marquardt", "optim", "get", "iter", "not", "report", "correct", "number", "iter", "it", "alway", "return", "quick", "look", "at", "code", "show", "that", "onli", "simplexoptim", "simplex", "optim", "call", "baseoptim", "incrementevaluationscount", "base", "optim", "increment", "evalu", "count", "ive", "put", "test", "case", "below", "notic", "how", "evalu", "count", "correctli", "increment", "but", "iter", "count", "not", "noformat", "test", "public", "void", "testgetiter", "test", "get", "iter", "setup", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "otim", "new", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "action", "otim", "optim", "new", "maxev", "max", "eval", "100", "new", "target", "new", "doubl", "new", "weight", "new", "doubl", "new", "initialguess", "initi", "guess", "new", "doubl", "new", "modelfunct", "model", "function", "new", "multivariatevectorfunct", "multivari", "vector", "function", "overrid", "public", "doubl", "valu", "doubl", "point", "throw", "illegalargumentexcept", "illeg", "argument", "except", "return", "new", "doubl", "fastmath", "pow", "fast", "math", "point0", "new", "modelfunctionjacobian", "model", "function", "jacobian", "new", "multivariatematrixfunct", "multivari", "matrix", "function", "overrid", "public", "doubl", "valu", "doubl", "point", "throw", "illegalargumentexcept", "illeg", "argument", "except", "return", "new", "doubl", "25", "fastmath", "pow", "fast", "math", "point0", "verifi", "assertthat", "assert", "that", "otim", "getevalu", "get", "evalu", "greaterthan", "greater", "than", "assertthat", "assert", "that", "otim", "getiter", "get", "iter", "greaterthan", "greater", "than", "noformat"], "B_title": "Increment iteration counter. By default the maximum number of iterations is Integer.MAX_VALUE.", "B_clean_title": ["increment", "iter", "counter", "by", "default", "maximum", "number", "iter", "integ", "max", "valu"]},
{"A_title": "event state not updated if an unrelated event triggers a RESET_STATE during ODE integrationWhen an ODE solver manages several different event types there are some unwanted side effects. If one event handler asks for a RESET_STATE (for integration state) when its eventOccurred method is called the other event handlers that did not trigger an event in the same step are not updated correctly due to an early return. As a result when the next step is processed with a reset integration state the forgotten event still refer to the start date of the previous state. This implies that when these event handlers will be checked for In some cases the function defining an event g(double t double y) is called with state parameters y that are completely wrong. In one case when the y array should have contained values between -1 and +1 one function call got values up to 1.0e20. The attached file reproduces the problem.", "A_clean_title": ["event", "state", "not", "updat", "unrel", "event", "trigger", "reset", "state", "dure", "ode", "integrationwhen", "integr", "when", "ode", "solver", "manag", "sever", "differ", "event", "type", "there", "are", "some", "unwant", "side", "effect", "one", "event", "handler", "ask", "reset", "state", "integr", "state", "when", "it", "eventoccur", "event", "occur", "method", "call", "other", "event", "handler", "that", "did", "not", "trigger", "event", "same", "step", "are", "not", "updat", "correctli", "due", "earli", "return", "as", "result", "when", "next", "step", "process", "reset", "integr", "state", "forgotten", "event", "still", "refer", "start", "date", "previou", "state", "thi", "impli", "that", "when", "these", "event", "handler", "will", "check", "some", "case", "function", "defin", "event", "doubl", "doubl", "call", "state", "paramet", "that", "are", "complet", "wrong", "one", "case", "when", "array", "have", "contain", "valu", "between", "+1", "one", "function", "call", "got", "valu", "up", "0e20", "attach", "file", "reproduc", "problem"], "B_title": "Fixed missing update in ODE event handlers.", "B_clean_title": ["fix", "miss", "updat", "ode", "event", "handler"]},
{"A_title": "Argument matcher anyXxx() (i.e. anyString() anyList()) should not match nullsNote that the function is called with an integer (not a string) and still the mocked function return the value which it should return only when a string is passed. The same works when using anyBoolean() or any other methof from any* family.", "A_clean_title": ["argument", "matcher", "anyxxx", "ani", "xxx", "anystr", "ani", "string", "anylist", "ani", "list", "not", "match", "nullsnot", "null", "note", "that", "function", "call", "integ", "not", "string", "still", "mock", "function", "return", "valu", "which", "it", "return", "onli", "when", "string", "pass", "same", "work", "when", "anyboolean", "ani", "boolean", "or", "ani", "other", "methof", "ani", "famili"], "B_title": "Stop anyX() methods matching null inputs", "B_clean_title": ["stop", "anyx", "ani", "method", "match", "null", "input"]},
{"A_title": "Tree.getStatus() and Tree.getPropertyStatus() fail for items whose parent has been removedNone", "A_clean_title": ["tree", "getstatu", "get", "statu", "tree", "getpropertystatu", "get", "properti", "statu", "fail", "item", "whose", "parent", "ha", "been", "removednon", "remov", "none"], "B_title": "Tree.getStatus() and Tree.getPropertyStatus() fail for items whose parent has been removed", "B_clean_title": ["tree", "getstatu", "get", "statu", "tree", "getpropertystatu", "get", "properti", "statu", "fail", "item", "whose", "parent", "ha", "been", "remov"]},
{"A_title": "Quaternion not normalized after constructionThe use of the Rotation(Vector3D u1Vector3D u2Vector3D v1Vector3D v2) constructor with normalized angle can apparently lead to un-normalized quaternion. This case appeared to me with the following data : u1 = (0.9999988431610581 -0.0015210774290851095 0.0) u2 = (0.0 0.0 1.0) and  v1 = (0.9999999999999999 0.0 0.0) v2 = (0.0 0.0 -1.0)  This lead to the following quaternion : q0 = 225783.35177064248 q1 = 0.0 q2 = 0.0 q3 = -3.3684446110762543E-9  I was expecting to have a normalized quaternion as input vectors are normalized. Does the quaternion shouldnt be normalized ? Ive joined the corresponding piece of code as JUnit Test case", "A_clean_title": ["quaternion", "not", "normal", "after", "constructionth", "construct", "use", "rotat", "vector3d", "u1vector3d", "u2vector3d", "v1vector3d", "v2", "constructor", "normal", "angl", "appar", "lead", "un", "normal", "quaternion", "thi", "case", "appear", "me", "follow", "data", "u1", "9999988431610581", "0015210774290851095", "u2", "v1", "9999999999999999", "v2", "thi", "lead", "follow", "quaternion", "q0", "225783", "35177064248", "q1", "q2", "q3", "3684446110762543e", "wa", "expect", "have", "normal", "quaternion", "as", "input", "vector", "are", "normal", "quaternion", "shouldnt", "normal", "ive", "join", "correspond", "piec", "code", "as", "junit", "unit", "test", "case"], "B_title": "Fixed a problem when building rotations from two pairs of vectors. In very rare cases due to numerical inaccuracies the computed quaternion was not normalized (some examples went as high as 1.0e8) and even after normalization the quaternion was plain wrong.", "B_clean_title": ["fix", "problem", "when", "build", "rotat", "two", "pair", "vector", "veri", "rare", "case", "due", "numer", "inaccuraci", "comput", "quaternion", "wa", "not", "normal", "some", "exampl", "went", "as", "high", "as", "0e8", "even", "after", "normal", "quaternion", "wa", "plain", "wrong"]},
{"A_title": "MonotoneChain handling of collinear points drops low points in a near-columnThis code code val points = List(   new Vector2D(     16.078200000000184     -36.52519999989808   )   new Vector2D(     19.164300000000186     -36.52519999989808   )   new Vector2D(     19.1643     -25.28136477910407   )   new Vector2D(     19.1643     -17.678400000004157   ) ) new hull.MonotoneChain().generate(points.asJava) code  results in the exception: code org.apache.commons.math3.exception.ConvergenceException: illegal state: convergence failed at org.apache.commons.math3.geometry.euclidean.twod.hull.AbstractConvexHullGenerator2D.generate(AbstractConvexHullGenerator2D.java:106) at org.apache.commons.math3.geometry.euclidean.twod.hull.MonotoneChain.generate(MonotoneChain.java:50) at .<init>(<console>:13) at .<clinit>(<console>) at .<init>(<console>:11) at .<clinit>(<console>) at  print(<console>) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at scala.tools.nsc.interpreter.IMain ReadEvalPrint.call(IMain.scala:704) at scala.tools.nsc.interpreter.IMain Request  anonfun 14.apply(IMain.scala:920) at scala.tools.nsc.interpreter.Line  anonfun 1.apply mcV sp(Line.scala:43) at scala.tools.nsc.io.package  anon 2.run(package.scala:25) at java.lang.Thread.run(Thread.java:662) code  This will be tricky to fix. Not only is the point (19.164300000000186 -36.52519999989808) is being dropped incorrectly but any point dropped in one hull risks creating a kink when combined with the other hull.", "A_clean_title": ["monotonechain", "monoton", "chain", "handl", "collinear", "point", "drop", "low", "point", "near", "columnthi", "column", "thi", "code", "code", "val", "point", "list", "new", "vector2d", "16", "078200000000184", "36", "52519999989808", "new", "vector2d", "19", "164300000000186", "36", "52519999989808", "new", "vector2d", "19", "1643", "25", "28136477910407", "new", "vector2d", "19", "1643", "17", "678400000004157", "new", "hull", "monotonechain", "monoton", "chain", "gener", "point", "asjava", "as", "java", "code", "result", "except", "code", "org", "apach", "common", "math3", "except", "convergenceexcept", "converg", "except", "illeg", "state", "converg", "fail", "at", "org", "apach", "common", "math3", "geometri", "euclidean", "twod", "hull", "abstractconvexhullgenerator2d", "gener", "abstract", "convex", "hull", "generator2d", "abstractconvexhullgenerator2d", "java:106", "abstract", "convex", "hull", "generator2d", "at", "org", "apach", "common", "math3", "geometri", "euclidean", "twod", "hull", "monotonechain", "gener", "monoton", "chain", "monotonechain", "java:50", "monoton", "chain", "at", "init", "consol", ":13", "at", "clinit", "consol", "at", "init", "consol", ":11", "at", "clinit", "consol", "at", "print", "consol", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "scala", "tool", "nsc", "interpret", "imain", "main", "readevalprint", "call", "read", "eval", "print", "imain", "scala:704", "main", "at", "scala", "tool", "nsc", "interpret", "imain", "main", "request", "anonfun", "14", "appli", "imain", "scala:920", "main", "at", "scala", "tool", "nsc", "interpret", "line", "anonfun", "appli", "mcv", "mc", "sp", "line", "scala:43", "at", "scala", "tool", "nsc", "io", "packag", "anon", "run", "packag", "scala:25", "at", "java", "lang", "thread", "run", "thread", "java:662", "code", "thi", "will", "tricki", "fix", "not", "onli", "point", "19", "164300000000186", "36", "52519999989808", "be", "drop", "incorrectli", "but", "ani", "point", "drop", "one", "hull", "risk", "creat", "kink", "when", "combin", "other", "hull"], "B_title": "Fix MonotoneChain with collinear points as input: take tolerance factor into account when initially sorting the input points. Thanks to Guillaume Marceau for the report.", "B_clean_title": ["fix", "monotonechain", "monoton", "chain", "collinear", "point", "as", "input", "take", "toler", "factor", "into", "account", "when", "initi", "sort", "input", "point", "thank", "guillaum", "marceau", "report"]},
{"A_title": "DropDownChoice no selection valueThis problem came from this topic: http://apache-wicket.1842946.n4.nabble.com/DropDownChoice-no-selection-value-td3160661.html  Ive noticed that the method AbstractSingleSelectChoice.getNoSelectionValue() returns the value for no selection. In AbstractSingleSelectChoice.getDefaultChoice(final Object selected) on line 314:        return n<option selected=selected value=> + option + </option>;   and on line 296:        buffer.append( value=>).append(option).append(</option>);   In those cases the null value option has empty value attribute. Wouldnt it be more consistent for this option to have the value attribute with the result provided from getNoSelectionValue()?", "A_clean_title": ["dropdownchoic", "drop", "down", "choic", "no", "select", "valuethi", "valu", "thi", "problem", "came", "thi", "topic", "http", "no", "select", "valu", "apach", "wicket", "1842946", "n4", "nabbl", "td3160661", "html", "com", "dropdownchoic", "drop", "down", "choic", "ive", "notic", "that", "method", "abstractsingleselectchoic", "getnoselectionvalu", "abstract", "singl", "select", "choic", "get", "no", "select", "valu", "return", "valu", "no", "select", "abstractsingleselectchoic", "getdefaultchoic", "abstract", "singl", "select", "choic", "get", "default", "choic", "final", "object", "select", "line", "314", "return", "option", "selected=select", "value=", "option", "option", "line", "296", "buffer", "append", "value=", "append", "option", "append", "option", "those", "case", "null", "valu", "option", "ha", "empti", "valu", "attribut", "wouldnt", "it", "more", "consist", "thi", "option", "have", "valu", "attribut", "result", "provid", "getnoselectionvalu", "get", "no", "select", "valu"], "B_title": "DropDownChoice no selection value", "B_clean_title": ["dropdownchoic", "drop", "down", "choic", "no", "select", "valu"]},
{"A_title": "RootImplFuzzIT test failuresAs seen in the CI build RootImplFuzzIT fails every now and then. This might be because of OAK-174 but theres been quite a bit of other work on the same area so this could be caused also by something else.  The troublesome seeds as seen in failing CI builds are 1437930918 206057576 1638075186 1705736349 -1856261793 and 569172885.", "A_clean_title": ["rootimplfuzzit", "root", "impl", "fuzz", "it", "test", "failuresa", "failur", "as", "seen", "ci", "build", "rootimplfuzzit", "root", "impl", "fuzz", "it", "fail", "everi", "now", "then", "thi", "might", "becaus", "oak", "174", "but", "there", "been", "quit", "bit", "other", "work", "same", "area", "so", "thi", "could", "caus", "also", "by", "someth", "troublesom", "seed", "as", "seen", "fail", "ci", "build", "are", "1437930918", "206057576", "1638075186", "1705736349", "1856261793", "569172885"], "B_title": "RootImplFuzzIT test failures", "B_clean_title": ["rootimplfuzzit", "root", "impl", "fuzz", "it", "test", "failur"]},
{"A_title": "Adding a component in Component#onInitialize() leads to StackOverflowErrorAdding a component in Page#onInitialize() leads to StackOverflowError:   at org.apache.wicket.MarkupContainer.addedComponent(MarkupContainer.java:978)      at org.apache.wicket.MarkupContainer.add(MarkupContainer.java:168)      at org.apache.wicket.examples.WicketExamplePage.onInitialize(WicketExamplePage.java:67)      at org.apache.wicket.Component.initialize(Component.java:970)      at org.apache.wicket.MarkupContainer.initialize(MarkupContainer.java:992)      at org.apache.wicket.Page.componentAdded(Page.java:1130)      at org.apache.wicket.MarkupContainer.addedComponent(MarkupContainer.java:978)      at org.apache.wicket.MarkupContainer.add(MarkupContainer.java:168)      at org.apache.wicket.examples.WicketExamplePage.onInitialize(WicketExamplePage.java:67)      at org.apache.wicket.Component.initialize(Component.java:970)      at org.apache.wicket.MarkupContainer.initialize(MarkupContainer.java:992)      at org.apache.wicket.Page.componentAdded(Page.java:1130)      at org.apache.wicket.MarkupContainer.addedComponent(MarkupContainer.java:978)      at org.apache.wicket.MarkupContainer.add(MarkupContainer.java:168)      at org.apache.wicket.examples.WicketExamplePage.onInitialize(WicketExamplePage.java:67)      at org.apache.wicket.Component.initialize(Component.java:970)      at org.apache.wicket.MarkupContainer.initialize(MarkupContainer.java:992)      at org.apache.wicket.Page.componentAdded(Page.java:1130)      at org.apache.wicket.MarkupContainer.addedComponent(MarkupContainer.java:978)      at org.apache.wicket.MarkupContainer.add(MarkupContainer.java:168)      at org.apache.wicket.examples.WicketExamplePage.onInitialize(WicketExamplePage.java:67)      at org.apache.wicket.Component.initialize(Component.java:970)      at org.apache.wicket.MarkupContainer.initialize(MarkupContainer.java:992)      at org.apache.wicket.Page.componentAdded(Page.java:1130)      at org.apache.wicket.MarkupContainer.addedComponent(MarkupContainer.java:978)      at org.apache.wicket.MarkupContainer.add(MarkupContainer.java:168)      at org.apache.wicket.examples.WicketExamplePage.onInitialize(WicketExamplePage.java:67)      at org.apache.wicket.Component.initialize(Component.java:970) ...", "A_clean_title": ["ad", "compon", "compon", "oniniti", "initi", "lead", "stackoverflowerrorad", "stack", "overflow", "error", "ad", "compon", "page", "oniniti", "initi", "lead", "stackoverflowerror", "stack", "overflow", "error", "at", "org", "apach", "wicket", "markupcontain", "addedcompon", "markup", "contain", "ad", "compon", "markupcontain", "java:978", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "add", "markup", "contain", "markupcontain", "java:168", "markup", "contain", "at", "org", "apach", "wicket", "exampl", "wicketexamplepag", "oniniti", "wicket", "exampl", "page", "initi", "wicketexamplepag", "java:67", "wicket", "exampl", "page", "at", "org", "apach", "wicket", "compon", "initi", "compon", "java:970", "at", "org", "apach", "wicket", "markupcontain", "initi", "markup", "contain", "markupcontain", "java:992", "markup", "contain", "at", "org", "apach", "wicket", "page", "componentad", "compon", "ad", "page", "java:1130", "at", "org", "apach", "wicket", "markupcontain", "addedcompon", "markup", "contain", "ad", "compon", "markupcontain", "java:978", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "add", "markup", "contain", "markupcontain", "java:168", "markup", "contain", "at", "org", "apach", "wicket", "exampl", "wicketexamplepag", "oniniti", "wicket", "exampl", "page", "initi", "wicketexamplepag", "java:67", "wicket", "exampl", "page", "at", "org", "apach", "wicket", "compon", "initi", "compon", "java:970", "at", "org", "apach", "wicket", "markupcontain", "initi", "markup", "contain", "markupcontain", "java:992", "markup", "contain", "at", "org", "apach", "wicket", "page", "componentad", "compon", "ad", "page", "java:1130", "at", "org", "apach", "wicket", "markupcontain", "addedcompon", "markup", "contain", "ad", "compon", "markupcontain", "java:978", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "add", "markup", "contain", "markupcontain", "java:168", "markup", "contain", "at", "org", "apach", "wicket", "exampl", "wicketexamplepag", "oniniti", "wicket", "exampl", "page", "initi", "wicketexamplepag", "java:67", "wicket", "exampl", "page", "at", "org", "apach", "wicket", "compon", "initi", "compon", "java:970", "at", "org", "apach", "wicket", "markupcontain", "initi", "markup", "contain", "markupcontain", "java:992", "markup", "contain", "at", "org", "apach", "wicket", "page", "componentad", "compon", "ad", "page", "java:1130", "at", "org", "apach", "wicket", "markupcontain", "addedcompon", "markup", "contain", "ad", "compon", "markupcontain", "java:978", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "add", "markup", "contain", "markupcontain", "java:168", "markup", "contain", "at", "org", "apach", "wicket", "exampl", "wicketexamplepag", "oniniti", "wicket", "exampl", "page", "initi", "wicketexamplepag", "java:67", "wicket", "exampl", "page", "at", "org", "apach", "wicket", "compon", "initi", "compon", "java:970", "at", "org", "apach", "wicket", "markupcontain", "initi", "markup", "contain", "markupcontain", "java:992", "markup", "contain", "at", "org", "apach", "wicket", "page", "componentad", "compon", "ad", "page", "java:1130", "at", "org", "apach", "wicket", "markupcontain", "addedcompon", "markup", "contain", "ad", "compon", "markupcontain", "java:978", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "add", "markup", "contain", "markupcontain", "java:168", "markup", "contain", "at", "org", "apach", "wicket", "exampl", "wicketexamplepag", "oniniti", "wicket", "exampl", "page", "initi", "wicketexamplepag", "java:67", "wicket", "exampl", "page", "at", "org", "apach", "wicket", "compon", "initi", "compon", "java:970"], "B_title": "Adding a component in Component#onInitialize() leads to StackOverflowError", "B_clean_title": ["ad", "compon", "compon", "oniniti", "initi", "lead", "stackoverflowerror", "stack", "overflow", "error"]},
{"A_title": "encodeUrl fails parsing jsessionid when using root contextWe are using Selenium 2.26.0 to test our Wicket application using Jetty 6.1.25 (also tried 7.0.0.pre5) and Firefox 12 as client browser.  With Wicket 1.5.8 everything worked fine but updating to 1.5.9 the following error occurs on first request:  java.lang.NumberFormatException: For input string: 56704;jsessionid=t3j8z4tsuazh1jfbcnjr8ryg at java.lang.NumberFormatException.forInputString(NumberFormatException.java:48) at java.lang.Integer.parseInt(Integer.java:458) at java.lang.Integer.parseInt(Integer.java:499) at org.apache.wicket.request.Url.parse(Url.java:195) at org.apache.wicket.request.Url.parse(Url.java:121) at org.apache.wicket.protocol.http.servlet.ServletWebResponse.encodeURL(ServletWebResponse.java:194) at org.apache.wicket.protocol.http.HeaderBufferingWebResponse.encodeURL(HeaderBufferingWebResponse.java:161) at org.apache.wicket.request.cycle.RequestCycle.renderUrl(RequestCycle.java:524) at org.apache.wicket.request.cycle.RequestCycle.urlFor(RequestCycle.java:492) at org.apache.wicket.request.cycle.RequestCycle.urlFor(RequestCycle.java:477) at org.apache.wicket.Component.urlFor(Component.java:3319) at org.apache.wicket.markup.html.link.BookmarkablePageLink.getURL(BookmarkablePageLink.java:209) at org.apache.wicket.markup.html.link.Link.onComponentTag(Link.java:361) at org.apache.wicket.Component.internalRenderComponent(Component.java:2530) at org.apache.wicket.MarkupContainer.onRender(MarkupContainer.java:1530) at org.apache.wicket.Component.internalRender(Component.java:2389) at org.apache.wicket.Component.render(Component.java:2317) at org.apache.wicket.MarkupContainer.renderNext(MarkupContainer.java:1428) at org.apache.wicket.MarkupContainer.renderAll(MarkupContainer.java:1592) at org.apache.wicket.Page.onRender(Page.java:907) at org.apache.wicket.markup.html.WebPage.onRender(WebPage.java:140) at org.apache.wicket.Component.internalRender(Component.java:2389) at org.apache.wicket.Component.render(Component.java:2317) at org.apache.wicket.Page.renderPage(Page.java:1035) at org.apache.wicket.request.handler.render.WebPageRenderer.renderPage(WebPageRenderer.java:118) at org.apache.wicket.request.handler.render.WebPageRenderer.respond(WebPageRenderer.java:246) at org.apache.wicket.request.handler.RenderPageRequestHandler.respond(RenderPageRequestHandler.java:167) at org.apache.wicket.request.cycle.RequestCycle HandlerExecutor.respond(RequestCycle.java:784) at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:64) at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:304) at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:313) at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:313) at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:313) at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:313) at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:313) at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:313) at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:313) at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:313) at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:313) at org.apache.wicket.request.cycle.RequestCycle.executeExceptionRequestHandler(RequestCycle.java:313) at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:227) at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:283) at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:188) at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:244)  Using debugger the encodeUrl method has variables   fullUrl = http://localhost:56704 encodedFullUrl = http://localhost:56704;jsessionid=8kxeo3reannw1qjtxgkju8yiu  before the exception occurs. I believe this is related to https://issues.apache.org/jira/browse/WICKET-4645.", "A_clean_title": ["encodeurl", "encod", "url", "fail", "pars", "jsessionid", "when", "root", "contextw", "context", "we", "are", "selenium", "26", "test", "our", "wicket", "applic", "jetti", "25", "also", "tri", "pre5", "firefox", "12", "as", "client", "browser", "wicket", "everyth", "work", "fine", "but", "updat", "follow", "error", "occur", "first", "request", "java", "lang", "numberformatexcept", "number", "format", "except", "input", "string", "56704", "jsessionid=t3j8z4tsuazh1jfbcnjr8ryg", "at", "java", "lang", "numberformatexcept", "forinputstr", "number", "format", "except", "input", "string", "numberformatexcept", "java:48", "number", "format", "except", "at", "java", "lang", "integ", "parseint", "pars", "int", "integ", "java:458", "at", "java", "lang", "integ", "parseint", "pars", "int", "integ", "java:499", "at", "org", "apach", "wicket", "request", "url", "pars", "url", "java:195", "at", "org", "apach", "wicket", "request", "url", "pars", "url", "java:121", "at", "org", "apach", "wicket", "protocol", "http", "servlet", "servletwebrespons", "encodeurl", "servlet", "web", "respons", "encod", "url", "servletwebrespons", "java:194", "servlet", "web", "respons", "at", "org", "apach", "wicket", "protocol", "http", "headerbufferingwebrespons", "encodeurl", "header", "buffer", "web", "respons", "encod", "url", "headerbufferingwebrespons", "java:161", "header", "buffer", "web", "respons", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "renderurl", "request", "cycl", "render", "url", "requestcycl", "java:524", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "urlfor", "request", "cycl", "url", "requestcycl", "java:492", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "urlfor", "request", "cycl", "url", "requestcycl", "java:477", "request", "cycl", "at", "org", "apach", "wicket", "compon", "urlfor", "url", "compon", "java:3319", "at", "org", "apach", "wicket", "markup", "html", "link", "bookmarkablepagelink", "geturl", "bookmark", "page", "link", "get", "url", "bookmarkablepagelink", "java:209", "bookmark", "page", "link", "at", "org", "apach", "wicket", "markup", "html", "link", "link", "oncomponenttag", "compon", "tag", "link", "java:361", "at", "org", "apach", "wicket", "compon", "internalrendercompon", "intern", "render", "compon", "compon", "java:2530", "at", "org", "apach", "wicket", "markupcontain", "onrend", "markup", "contain", "render", "markupcontain", "java:1530", "markup", "contain", "at", "org", "apach", "wicket", "compon", "internalrend", "intern", "render", "compon", "java:2389", "at", "org", "apach", "wicket", "compon", "render", "compon", "java:2317", "at", "org", "apach", "wicket", "markupcontain", "rendernext", "markup", "contain", "render", "next", "markupcontain", "java:1428", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "renderal", "markup", "contain", "render", "all", "markupcontain", "java:1592", "markup", "contain", "at", "org", "apach", "wicket", "page", "onrend", "render", "page", "java:907", "at", "org", "apach", "wicket", "markup", "html", "webpag", "onrend", "web", "page", "render", "webpag", "java:140", "web", "page", "at", "org", "apach", "wicket", "compon", "internalrend", "intern", "render", "compon", "java:2389", "at", "org", "apach", "wicket", "compon", "render", "compon", "java:2317", "at", "org", "apach", "wicket", "page", "renderpag", "render", "page", "page", "java:1035", "at", "org", "apach", "wicket", "request", "handler", "render", "webpagerender", "renderpag", "web", "page", "render", "render", "page", "webpagerender", "java:118", "web", "page", "render", "at", "org", "apach", "wicket", "request", "handler", "render", "webpagerender", "respond", "web", "page", "render", "webpagerender", "java:246", "web", "page", "render", "at", "org", "apach", "wicket", "request", "handler", "renderpagerequesthandl", "respond", "render", "page", "request", "handler", "renderpagerequesthandl", "java:167", "render", "page", "request", "handler", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "request", "cycl", "handlerexecutor", "respond", "handler", "executor", "requestcycl", "java:784", "request", "cycl", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:64", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:304", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:313", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:313", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:313", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:313", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:313", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:313", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:313", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:313", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:313", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "executeexceptionrequesthandl", "request", "cycl", "execut", "except", "request", "handler", "requestcycl", "java:313", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:227", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:283", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:188", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:244", "wicket", "filter", "debugg", "encodeurl", "encod", "url", "method", "ha", "variabl", "fullurl", "full", "url", "http", "localhost:56704", "encodedfullurl", "encod", "full", "url", "http", "localhost:56704", "jsessionid=8kxeo3reannw1qjtxgkju8yiu", "befor", "except", "occur", "believ", "thi", "relat", "http", "4645", "apach", "issu", "org", "jira", "brows", "wicket"], "B_title": "semicolon (;) starts segments if no slash is present", "B_clean_title": ["semicolon", "start", "segment", "no", "slash", "present"]},
{"A_title": "Indexes: re-index automatically when adding an indexWhen adding an index via import of content the index is not automatically re-built. This is problematic because subsequent queries will return no data because of that. Currently the only way to re-index is to set the reindex property to true.  I suggest that indexes are automatically re-indexes if the hidden child node (:data I believe) is missing. This is in addition to the reindex property.", "A_clean_title": ["index", "re", "index", "automat", "when", "ad", "indexwhen", "index", "when", "ad", "index", "via", "import", "content", "index", "not", "automat", "re", "built", "thi", "problemat", "becaus", "subsequ", "queri", "will", "return", "no", "data", "becaus", "that", "current", "onli", "way", "re", "index", "set", "reindex", "properti", "true", "suggest", "that", "index", "are", "automat", "re", "index", "hidden", "child", "node", "data", "believ", "miss", "thi", "addit", "reindex", "properti"], "B_title": "Indexes: re-index automatically when adding an index", "B_clean_title": ["index", "re", "index", "automat", "when", "ad", "index"]},
{"A_title": "Query test failures on buildbotSince revision 1398915 various query tests fail on buildbot|http://ci.apache.org/builders/oak-trunk/builds/784:  code sql1(org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexQueryTest): No LoginModules configured for jackrabbit.oak sql2(org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexQueryTest): No LoginModules configured for jackrabbit.oak xpath(org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexQueryTest): No LoginModules configured for jackrabbit.oak bindVariableTest(org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexQueryTest): No LoginModules configured for jackrabbit.oak sql1(org.apache.jackrabbit.oak.plugins.index.property.PropertyIndexQueryTest): No LoginModules configured for jackrabbit.oak sql2(org.apache.jackrabbit.oak.plugins.index.property.PropertyIndexQueryTest): No LoginModules configured for jackrabbit.oak xpath(org.apache.jackrabbit.oak.plugins.index.property.PropertyIndexQueryTest): No LoginModules configured for jackrabbit.oak bindVariableTest(org.apache.jackrabbit.oak.plugins.index.property.PropertyIndexQueryTest): No LoginModules configured for jackrabbit.oak sql2Explain(org.apache.jackrabbit.oak.plugins.index.old.QueryTest): No LoginModules configured for jackrabbit.oak sql1(org.apache.jackrabbit.oak.plugins.index.old.QueryTest): No LoginModules configured for jackrabbit.oak xpath(org.apache.jackrabbit.oak.plugins.index.old.QueryTest): No LoginModules configured for jackrabbit.oak bindVariableTest(org.apache.jackrabbit.oak.plugins.index.old.QueryTest): No LoginModules configured for jackrabbit.oak sql1(org.apache.jackrabbit.oak.query.index.TraversingIndexQueryTest): No LoginModules configured for jackrabbit.oak sql2(org.apache.jackrabbit.oak.query.index.TraversingIndexQueryTest): No LoginModules configured for jackrabbit.oak xpath(org.apache.jackrabbit.oak.query.index.TraversingIndexQueryTest): No LoginModules configured for jackrabbit.oak bindVariableTest(org.apache.jackrabbit.oak.query.index.TraversingIndexQueryTest): No LoginModules configured for jackrabbit.oak code", "A_clean_title": ["queri", "test", "failur", "buildbotsinc", "buildbot", "sinc", "revis", "1398915", "variou", "queri", "test", "fail", "buildbot|http", "apach", "trunk", "build", "784", "ci", "org", "builder", "oak", "code", "sql1", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexquerytest", "lucen", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "sql2", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexquerytest", "lucen", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "xpath", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexquerytest", "lucen", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "bindvariabletest", "bind", "variabl", "test", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexquerytest", "lucen", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "sql1", "org", "apach", "jackrabbit", "oak", "plugin", "index", "properti", "propertyindexquerytest", "properti", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "sql2", "org", "apach", "jackrabbit", "oak", "plugin", "index", "properti", "propertyindexquerytest", "properti", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "xpath", "org", "apach", "jackrabbit", "oak", "plugin", "index", "properti", "propertyindexquerytest", "properti", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "bindvariabletest", "bind", "variabl", "test", "org", "apach", "jackrabbit", "oak", "plugin", "index", "properti", "propertyindexquerytest", "properti", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "sql2explain", "org", "apach", "jackrabbit", "oak", "plugin", "index", "old", "querytest", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "sql1", "org", "apach", "jackrabbit", "oak", "plugin", "index", "old", "querytest", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "xpath", "org", "apach", "jackrabbit", "oak", "plugin", "index", "old", "querytest", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "bindvariabletest", "bind", "variabl", "test", "org", "apach", "jackrabbit", "oak", "plugin", "index", "old", "querytest", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "sql1", "org", "apach", "jackrabbit", "oak", "queri", "index", "traversingindexquerytest", "travers", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "sql2", "org", "apach", "jackrabbit", "oak", "queri", "index", "traversingindexquerytest", "travers", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "xpath", "org", "apach", "jackrabbit", "oak", "queri", "index", "traversingindexquerytest", "travers", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "bindvariabletest", "bind", "variabl", "test", "org", "apach", "jackrabbit", "oak", "queri", "index", "traversingindexquerytest", "travers", "index", "queri", "test", "no", "loginmodul", "login", "modul", "configur", "jackrabbit", "oak", "code"], "B_title": "Query test failures on buildbot - revert changes from revision 1399172 - use default login module configuration when none is given", "B_clean_title": ["queri", "test", "failur", "buildbot", "revert", "chang", "revis", "1399172", "use", "default", "login", "modul", "configur", "when", "none", "given"]},
{"A_title": "HarmonicFitter.ParameterGuesser sometimes fails to return sensible valuesThe inner class ParameterGuesser in HarmonicFitter (package o.a.c.m.optimization.fitting) fails to compute a usable guess for the amplitude parameter.", "A_clean_title": ["harmonicfitt", "parameterguess", "harmon", "fitter", "paramet", "guesser", "sometim", "fail", "return", "sensibl", "valuesth", "valu", "inner", "class", "parameterguess", "paramet", "guesser", "harmonicfitt", "harmon", "fitter", "packag", "optim", "fit", "fail", "comput", "usabl", "guess", "amplitud", "paramet"], "B_title": "Generate an exception when the parameter guessing procedure cannot perform correctly (in rare ill-conditioned cases).", "B_clean_title": ["gener", "except", "when", "paramet", "guess", "procedur", "not", "perform", "correctli", "rare", "ill", "condit", "case"]},
{"A_title": "Changes to SourcePosition in 5.5.0 ?Hello  according to #1081 I dont find any mentions of changes to the SourcePosition. In our use case we want to calculate the size of constructors and methods. Which worked just fine in 5.4.  Now with the 5.5 Snapshot I want to analyze a file which has a inner private class with no constructors. Spoon generates a default private constructor with one statement -> super() . The start line of this constructor is 1 and getPosition().getFile() returns null while the statements (super()) line is 383 and it has a file. My method throws a NP as my method size calculation now is wrong and gets passed the threshold and I try to access the file of the generated private constructor.  I always can implement the case to ignore generated constructors but I just want to make sure this is intented or not.", "A_clean_title": ["chang", "sourceposit", "sourc", "posit", "hello", "accord", "1081", "dont", "find", "ani", "mention", "chang", "sourceposit", "sourc", "posit", "our", "use", "case", "we", "want", "calcul", "size", "constructor", "method", "which", "work", "just", "fine", "now", "snapshot", "want", "analyz", "file", "which", "ha", "inner", "privat", "class", "no", "constructor", "spoon", "gener", "default", "privat", "constructor", "one", "statement", "super", "start", "line", "thi", "constructor", "getposit", "get", "posit", "getfil", "get", "file", "return", "null", "while", "statement", "super", "line", "383", "it", "ha", "file", "my", "method", "throw", "np", "as", "my", "method", "size", "calcul", "now", "wrong", "get", "pass", "threshold", "tri", "access", "file", "gener", "privat", "constructor", "alway", "implement", "case", "ignor", "gener", "constructor", "but", "just", "want", "make", "sure", "thi", "intent", "or", "not"], "B_title": "fix(position): implicit elements do not have position (#1086)  Fix #1084", "B_clean_title": ["fix", "posit", "implicit", "element", "not", "have", "posit", "1086", "fix", "1084"]},
{"A_title": "Ajax update renders parent/child JS in different order than initial Page renderSee attached quickstart.  On initial page load the child Javascripts are rendered and executed first followed by the parents JS - in this case a Datatables.net JS. Everything works fine.  However if you click on a link in the DefaultDataTable we trigger a DDT refresh via Ajax and then you can see that the parents JS is executed first before the child JS - this causes a problem since the parent JS modifies the visible rows in the table and Wicket can no longer find some of the child rows.  I expected the order of JS contributions to be the same for initial page render and any Ajax updates.", "A_clean_title": ["ajax", "updat", "render", "parent", "child", "js", "differ", "order", "than", "initi", "page", "renderse", "render", "see", "attach", "quickstart", "initi", "page", "load", "child", "javascript", "are", "render", "execut", "first", "follow", "by", "parent", "js", "thi", "case", "datat", "net", "js", "everyth", "work", "fine", "howev", "you", "click", "link", "defaultdatat", "default", "data", "tabl", "we", "trigger", "ddt", "refresh", "via", "ajax", "then", "you", "see", "that", "parent", "js", "execut", "first", "befor", "child", "js", "thi", "caus", "problem", "sinc", "parent", "js", "modifi", "visibl", "row", "tabl", "wicket", "no", "longer", "find", "some", "child", "row", "expect", "order", "js", "contribut", "same", "initi", "page", "render", "ani", "ajax", "updat"], "B_title": "ensure consistent JavaScript ordering with Wickets IHeaderRenderStrategy for Ajax responses and removing special handling of Ajax response in AjaxEventBehavior i.e. not calling appendJavaScript()", "B_clean_title": ["ensur", "consist", "javascript", "java", "script", "order", "wicket", "iheaderrenderstrategi", "header", "render", "strategi", "ajax", "respons", "remov", "special", "handl", "ajax", "respons", "ajaxeventbehavior", "ajax", "event", "behavior", "not", "call", "appendjavascript", "append", "java", "script"]},
{"A_title": "Interaction betwen IAjaxRegionMarkupIdProvider renderPlaceholderTag and visibilityIve just discovered what I think is a bug with IAjaxRegionMarkupIdProvider. We are using it on a Behavior that provides a border to form components (label mandatory marker etc) which for the most part works great.  We have encountered a problem when toggling the visibility of a form component with this behavior via ajax.   The component is first sent out visible and the markup is all correct.  A change elsewhere on the page causes the component to be set to not visible and redrawn via ajax. The ajax response contains a tag with a markupid generated via renderPlaceholderTag. This does not take into account the  IAjaxRegionMarkupIdProvider behaviour.  Another change happens on the page causing the component to become visible and the ajax replace cant happen because the component with the correct markupId is not present.", "A_clean_title": ["interact", "betwen", "iajaxregionmarkupidprovid", "ajax", "region", "markup", "id", "provid", "renderplaceholdertag", "render", "placehold", "tag", "visibility", "visibl", "ive", "just", "discov", "what", "think", "bug", "iajaxregionmarkupidprovid", "ajax", "region", "markup", "id", "provid", "we", "are", "it", "behavior", "that", "provid", "border", "form", "compon", "label", "mandatori", "marker", "etc", "which", "most", "part", "work", "great", "we", "have", "encount", "problem", "when", "toggl", "visibl", "form", "compon", "thi", "behavior", "via", "ajax", "compon", "first", "sent", "out", "visibl", "markup", "all", "correct", "chang", "elsewher", "page", "caus", "compon", "set", "not", "visibl", "redrawn", "via", "ajax", "ajax", "respons", "contain", "tag", "markupid", "gener", "via", "renderplaceholdertag", "render", "placehold", "tag", "thi", "not", "take", "into", "account", "iajaxregionmarkupidprovid", "ajax", "region", "markup", "id", "provid", "behaviour", "anoth", "chang", "happen", "page", "caus", "compon", "becom", "visibl", "ajax", "replac", "cant", "happen", "becaus", "compon", "correct", "markupid", "markup", "id", "not", "present"], "B_title": "Interaction betwen IAjaxRegionMarkupIdProvider renderPlaceholderTag and visibility", "B_clean_title": ["interact", "betwen", "iajaxregionmarkupidprovid", "ajax", "region", "markup", "id", "provid", "renderplaceholdertag", "render", "placehold", "tag", "visibl"]},
{"A_title": ".withHourOfDay() sets hour inconsistantly on DST transition.When the hour of day is set to the ambiguous hour on the daylight to standard time transition in a given time zone the result is inconsistent for different time zones. Shoul the hour be set to the daylight hour or the standard hour for all time zones? I cant find anything that documents this behavior.  My test code below returns different results for different time zones. The very last assertion fails on the Australia time zone cutover.", "A_clean_title": ["withhourofday", "hour", "day", "set", "hour", "inconsistantli", "dst", "transit", "when", "hour", "day", "set", "ambigu", "hour", "daylight", "standard", "time", "transit", "given", "time", "zone", "result", "inconsist", "differ", "time", "zone", "shoul", "hour", "set", "daylight", "hour", "or", "standard", "hour", "all", "time", "zone", "cant", "find", "anyth", "that", "document", "thi", "behavior", "my", "test", "code", "below", "return", "differ", "result", "differ", "time", "zone", "veri", "last", "assert", "fail", "australia", "time", "zone", "cutov"], "B_title": "bugs 310276021824442553453 New method now retains the offset wherever possible during calculations This affects higher methods like withHourOfDay/withMinuteOfHour/withSecondOfMinute/withMillisOfSecond which now do not change offset when called within a DST overlap", "B_clean_title": ["bug", "310276021824442553453", "new", "method", "now", "retain", "offset", "wherev", "possibl", "dure", "calcul", "thi", "affect", "higher", "method", "like", "withhourofday", "withminuteofhour", "withsecondofminut", "withmillisofsecond", "hour", "day", "minut", "hour", "second", "minut", "milli", "second", "which", "now", "not", "chang", "offset", "when", "call", "within", "dst", "overlap"]},
{"A_title": "DateTimeFormatter.parseInto broken when no year in formatIn Joda Time 2.0 the default year was set to 2000 so that Feb 29 could be parsed correctly. However parseInto now overwrites the given instants year with 2000 (or whatever iDefaultYear is set to). The correct behavior would seem to be to use the given instants year instead of iDefaultYear. This does mean that Feb 29 might not be parseable if the instants year is not a leap year but in this case the caller asked for that in a sense.", "A_clean_title": ["datetimeformatt", "parseinto", "date", "time", "formatt", "pars", "into", "broken", "when", "no", "year", "formatin", "format", "joda", "time", "default", "year", "wa", "set", "2000", "so", "that", "feb", "29", "could", "pars", "correctli", "howev", "parseinto", "pars", "into", "now", "overwrit", "given", "instant", "year", "2000", "or", "whatev", "idefaultyear", "default", "year", "set", "correct", "behavior", "would", "seem", "use", "given", "instant", "year", "instead", "idefaultyear", "default", "year", "thi", "mean", "that", "feb", "29", "might", "not", "parseabl", "instant", "year", "not", "leap", "year", "but", "thi", "case", "caller", "ask", "that", "sens"], "B_title": "Fix DateTimeFormatter.parseInto() 3522138", "B_clean_title": ["fix", "datetimeformatt", "parseinto", "date", "time", "formatt", "pars", "into", "3522138"]},
{"A_title": "stacking combiners produces a strange resultPaste the following into your shell:  noformat deletetable test createtable test setiter -t test -p 16 -scan -n test_1 -class org.apache.accumulo.core.iterators.user.SummingCombiner  count:a  STRING setiter -t test -p 17 -scan -n test_2 -class org.apache.accumulo.core.iterators.user.SummingCombiner  count:a  STRING setiter -t test -p 18 -scan -n test_3 -class org.apache.accumulo.core.iterators.user.SummingCombiner  count:a  STRING setiter -t test -p 10 -scan -n test_4 -class org.apache.accumulo.core.iterators.user.SummingCombiner  count  STRING insert row count a 1 insert row count a 1 insert row count b 1 insert row count b 1 insert row count b 1 insert row count c 1 scan noformat  I expect:  noformat row count:a     2 row count:b     3 row count:c     1 noformat  But instead I get this: noformat row count:a     12 noformat", "A_clean_title": ["stack", "combin", "produc", "strang", "resultpast", "result", "past", "follow", "into", "your", "shell", "noformat", "deletet", "test", "createt", "test", "setit", "test", "16", "scan", "test", "class", "org", "apach", "accumulo", "core", "iter", "user", "summingcombin", "sum", "combin", "count", "string", "setit", "test", "17", "scan", "test", "class", "org", "apach", "accumulo", "core", "iter", "user", "summingcombin", "sum", "combin", "count", "string", "setit", "test", "18", "scan", "test", "class", "org", "apach", "accumulo", "core", "iter", "user", "summingcombin", "sum", "combin", "count", "string", "setit", "test", "10", "scan", "test", "class", "org", "apach", "accumulo", "core", "iter", "user", "summingcombin", "sum", "combin", "count", "string", "insert", "row", "count", "insert", "row", "count", "insert", "row", "count", "insert", "row", "count", "insert", "row", "count", "insert", "row", "count", "scan", "noformat", "expect", "noformat", "row", "count", "row", "count", "row", "count", "noformat", "but", "instead", "get", "thi", "noformat", "row", "count", "12", "noformat"], "B_title": "fix combiners over iterators that mutate their top key", "B_clean_title": ["fix", "combin", "over", "iter", "that", "mutat", "their", "top", "key"]},
{"A_title": "MockAccumulo doesnt throw informative errorsUsers are unable to tell if an error has occurred and whether it is due to unimplemented features in MockAccumulo.", "A_clean_title": ["mockaccumulo", "mock", "accumulo", "doesnt", "throw", "inform", "errorsus", "error", "user", "are", "unabl", "tell", "error", "ha", "occur", "whether", "it", "due", "unimpl", "featur", "mockaccumulo", "mock", "accumulo"], "B_title": "employed more TableNotFound / TableExists Exceptions in TableOperations - merged to trunk", "B_clean_title": ["employ", "more", "tablenotfound", "tabl", "not", "found", "tableexist", "tabl", "exist", "except", "tableoper", "tabl", "oper", "merg", "trunk"]},
{"A_title": "Prototype method incorrectly removedNone", "A_clean_title": ["prototyp", "method", "incorrectli", "removednon", "remov", "none"], "B_title": "Fix DisambiguateProperties handling of quoted properties", "B_clean_title": ["fix", "disambiguateproperti", "disambigu", "properti", "handl", "quot", "properti"]},
{"A_title": "MultidimensionalCounter.getCounts(int) returns wrong array of indicesMultidimensionalCounter counter = new MultidimensionalCounter(2 4); for (Integer i : counter)      int x = counter.getCounts;     System.out.println(i +   + Arrays.toString);  Output is: 0 0 0 1 0 1 2 0 2 3 0 2   <=== should be 0 3 4 1 0 5 1 1 6 1 2 7 1 2   <=== should be 1 3", "A_clean_title": ["multidimensionalcount", "getcount", "multidimension", "counter", "get", "count", "int", "return", "wrong", "array", "indicesmultidimensionalcount", "indic", "multidimension", "counter", "counter", "new", "multidimensionalcount", "multidimension", "counter", "integ", "counter", "int", "counter", "getcount", "get", "count", "system", "out", "println", "array", "tostr", "string", "output"], "B_title": "Fixed bug in MultidimensionalCounter. Thanks to James Bence.", "B_clean_title": ["fix", "bug", "multidimensionalcount", "multidimension", "counter", "thank", "jame", "benc"]},
{"A_title": "SimplexSolver returning wrong answer from optimizeSimplexSolver fails for the following linear program:  min 2x1 +15x2 +18x3  Subject to    -x1 +2x2  -6x3 <=-10             x2  +2x3 <= 6    2x1      +10x3 <= 19     -x1  +x2       <= -2     x1x2x3 >= 0  Solution should be x1 = 7 x2 = 0 x3 = 1/2 Objective function = 23  Instead it is returning x1 = 9.5 x2 = 1/8 x3 = 0 Objective function = 20.875  Constraint number 1 is violated by this answer", "A_clean_title": ["simplexsolv", "simplex", "solver", "return", "wrong", "answer", "optimizesimplexsolv", "optim", "simplex", "solver", "fail", "follow", "linear", "program", "min", "2x1", "+15x2", "+18x3", "subject", "x1", "+2x2", "6x3", "10", "x2", "+2x3", "2x1", "+10x3", "19", "x1", "+x2", "x1x2x3", "solut", "x1", "x2", "x3", "object", "function", "23", "instead", "it", "return", "x1", "x2", "x3", "object", "function", "20", "875", "constraint", "number", "violat", "by", "thi", "answer"], "B_title": "Throw a DimensionMismatchException if dimension of constraints and objective function does not match in SimplexSolver.", "B_clean_title": ["throw", "dimensionmismatchexcept", "dimens", "mismatch", "except", "dimens", "constraint", "object", "function", "not", "match", "simplexsolv", "simplex", "solver"]},
{"A_title": "AbstractPersistentProperty.getRawType() does not consider generics DATACMNS-1139opened and commented  AbstractPersistentProperty.getRawType() currently uses the fields or property descriptors type which in turn doesnt use our generics resolution mechanism which means for generic fields youll get different results if you call ….getTypeInformation().getType() and ….getRawType()   Affects: 1.12.11 (Hopper SR11) 1.13.6 (Ingalls SR6) 2.0 RC2 (Kay)  Backported to:  1.13.7 (Ingalls SR7)  1.12.12 (Hopper SR12)", "A_clean_title": ["abstractpersistentproperti", "getrawtyp", "abstract", "persist", "properti", "get", "raw", "type", "not", "consid", "gener", "datacmn", "1139open", "comment", "abstractpersistentproperti", "getrawtyp", "abstract", "persist", "properti", "get", "raw", "type", "current", "use", "field", "or", "properti", "descriptor", "type", "which", "turn", "doesnt", "use", "our", "gener", "resolut", "mechan", "which", "mean", "gener", "field", "youll", "get", "differ", "result", "you", "call", "gettypeinform", "get", "type", "inform", "gettyp", "get", "type", "getrawtyp", "get", "raw", "type", "affect", "12", "11", "hopper", "sr11", "13", "ingal", "sr6", "rc2", "kay", "backport", "13", "ingal", "sr7", "12", "12", "hopper", "sr12"], "B_title": "DATACMNS-1139 - AbstractPersistentProperty.getRawType() now correctly resolves generics.  Were now favoring the generic TypeInformation over trying to resolve the property type via field or PropertyDescriptor as only the former does proper generic type resolution.", "B_clean_title": ["datacmn", "1139", "abstractpersistentproperti", "getrawtyp", "abstract", "persist", "properti", "get", "raw", "type", "now", "correctli", "resolv", "gener", "were", "now", "favor", "gener", "typeinform", "type", "inform", "over", "tri", "resolv", "properti", "type", "via", "field", "or", "propertydescriptor", "properti", "descriptor", "as", "onli", "former", "proper", "gener", "type", "resolut"]},
{"A_title": "StringUtils methods do not handle Unicode 2.0+ supplementary characters correctly.StringUtils.containsAny methods incorrectly matches Unicode 2.0+ supplementary characters. For example define a test fixture to be the Unicode character U+20000 where U+20000 is written in Java source as uD840uDC00 private static final String CharU20000 = uD840uDC00; private static final String CharU20001 = uD840uDC01; You can see Unicode supplementary characters correctly implemented in the JRE call: assertEquals(-1 CharU20000.indexOf(CharU20001)); But this is broken: assertEquals(false StringUtils.containsAny(CharU20000 CharU20001)); assertEquals(false StringUtils.containsAny(CharU20001 CharU20000)); This is fine: assertEquals(true StringUtils.contains(CharU20000 + CharU20001 CharU20000)); assertEquals(true StringUtils.contains(CharU20000 + CharU20001 CharU20001)); assertEquals(true StringUtils.contains(CharU20000 CharU20000)); assertEquals(false StringUtils.contains(CharU20000 CharU20001)); because the method calls the JRE to perform the match. More than you want to know:  http://java.sun.com/developer/technicalArticles/Intl/Supplementary/", "A_clean_title": ["stringutil", "string", "util", "method", "not", "handl", "unicod", "0+", "supplementari", "charact", "correctli", "stringutil", "containsani", "string", "util", "contain", "ani", "method", "incorrectli", "match", "unicod", "0+", "supplementari", "charact", "exampl", "defin", "test", "fixtur", "unicod", "charact", "u+20000", "where", "u+20000", "written", "java", "sourc", "as", "ud840udc00", "d840u", "dc00", "privat", "static", "final", "string", "charu20000", "char", "u20000", "ud840udc00", "d840u", "dc00", "privat", "static", "final", "string", "charu20001", "char", "u20001", "ud840udc01", "d840u", "dc01", "you", "see", "unicod", "supplementari", "charact", "correctli", "implement", "jre", "call", "assertequ", "assert", "equal", "charu20000", "indexof", "char", "u20000", "index", "charu20001", "char", "u20001", "but", "thi", "broken", "assertequ", "assert", "equal", "fals", "stringutil", "containsani", "string", "util", "contain", "ani", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "assertequ", "assert", "equal", "fals", "stringutil", "containsani", "string", "util", "contain", "ani", "charu20001", "char", "u20001", "charu20000", "char", "u20000", "thi", "fine", "assertequ", "assert", "equal", "true", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "charu20000", "char", "u20000", "assertequ", "assert", "equal", "true", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "charu20001", "char", "u20001", "assertequ", "assert", "equal", "true", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20000", "char", "u20000", "assertequ", "assert", "equal", "fals", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "becaus", "method", "call", "jre", "perform", "match", "more", "than", "you", "want", "know", "http", "sun", "java", "com", "develop", "technicalarticl", "intl", "supplementari", "technic", "articl"], "B_title": "StringUtils.containsAny methods incorrectly matches Unicode 2.0+ supplementary characters.", "B_clean_title": ["stringutil", "containsani", "string", "util", "contain", "ani", "method", "incorrectli", "match", "unicod", "0+", "supplementari", "charact"]},
{"A_title": "Basic variable is not found correctly in simplex tableauThe last patch to SimplexTableau caused an automated test suite Im running at work to go down a new code path and uncover what is hopefully the last bug remaining in the Simplex code. SimplexTableau was assuming an entry in the tableau had to be nonzero to indicate a basic variable which is incorrect - the entry should have a value equal to 1.", "A_clean_title": ["basic", "variabl", "not", "found", "correctli", "simplex", "tableauth", "tableau", "last", "patch", "simplextableau", "simplex", "tableau", "caus", "autom", "test", "suit", "im", "run", "at", "work", "go", "down", "new", "code", "path", "uncov", "what", "hope", "last", "bug", "remain", "simplex", "code", "simplextableau", "simplex", "tableau", "wa", "assum", "entri", "tableau", "had", "nonzero", "indic", "basic", "variabl", "which", "incorrect", "entri", "have", "valu", "equal"], "B_title": "Fixed a wrong check for basic variables JIRA: MATH-273", "B_clean_title": ["fix", "wrong", "check", "basic", "variabl", "jira", "math", "273"]},
{"A_title": "RealMatrixImpl#operate gets result vector dimensions wrongorg.apache.commons.math.linear.RealMatrixImpl#operate tries to create a result vector that always has the same length as the input vector. This can result in runtime exceptions if the matrix is non-square and it always yields incorrect results if the matrix is non-square. The correct behaviour would of course be to create a vector with the same length as the row dimension of the matrix. Thus line 640 in RealMatrixImpl.java should read double out = new doublenRows; instead of double out = new doublev.length;", "A_clean_title": ["realmatriximpl", "real", "matrix", "impl", "oper", "get", "result", "vector", "dimens", "wrongorg", "apach", "common", "math", "linear", "realmatriximpl", "real", "matrix", "impl", "oper", "tri", "creat", "result", "vector", "that", "alway", "ha", "same", "length", "as", "input", "vector", "thi", "result", "runtim", "except", "matrix", "non", "squar", "it", "alway", "yield", "incorrect", "result", "matrix", "non", "squar", "correct", "behaviour", "would", "cours", "creat", "vector", "same", "length", "as", "row", "dimens", "matrix", "thu", "line", "640", "realmatriximpl", "java", "real", "matrix", "impl", "read", "doubl", "out", "new", "doublenrow", "doublen", "row", "instead", "doubl", "out", "new", "doublev", "length"], "B_title": "fixed dimension error in operate method for RealMatrixImpl and BigMatrixImpl JIRA: MATH-209", "B_clean_title": ["fix", "dimens", "error", "oper", "method", "realmatriximpl", "real", "matrix", "impl", "bigmatriximpl", "big", "matrix", "impl", "jira", "math", "209"]},
{"A_title": "master killed a tablet serverMaster killed a tablet server for having long hold times.  The tablet server had this error during minor compaction:  noformat 01 23:57:20073 security.ZKAuthenticator ERROR: org.apache.zookeeper.KeeperException NoNodeException: KeeperErrorCode = NoNode for /accumulo/88cd0f63-a36a-4218-86b1-9ba1d2cccf08/users/user004 org.apache.zookeeper.KeeperException NoNodeException: KeeperErrorCode = NoNode for /accumulo/88cd0f63-a36a-4218-86b1-9ba1d2cccf08/users/user004         at org.apache.zookeeper.KeeperException.create(KeeperException.java:102)         at org.apache.zookeeper.KeeperException.create(KeeperException.java:42)         at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1243)         at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1271)         at org.apache.accumulo.core.zookeeper.ZooUtil.recursiveDelete(ZooUtil.java:103)         at org.apache.accumulo.core.zookeeper.ZooUtil.recursiveDelete(ZooUtil.java:117)         at org.apache.accumulo.server.zookeeper.ZooReaderWriter.recursiveDelete(ZooReaderWriter.java:67)         at sun.reflect.GeneratedMethodAccessor53.invoke(Unknown Source)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)         at java.lang.reflect.Method.invoke(Method.java:597)         at org.apache.accumulo.server.zookeeper.ZooReaderWriter 1.invoke(ZooReaderWriter.java:169)         at  Proxy4.recursiveDelete(Unknown Source)         at org.apache.accumulo.server.security.ZKAuthenticator.dropUser(ZKAuthenticator.java:252)         at org.apache.accumulo.server.security.Auditor.dropUser(Auditor.java:104)         at org.apache.accumulo.server.client.ClientServiceHandler.dropUser(ClientServiceHandler.java:136)         at sun.reflect.GeneratedMethodAccessor52.invoke(Unknown Source)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)         at java.lang.reflect.Method.invoke(Method.java:597)         at cloudtrace.instrument.thrift.TraceWrap 1.invoke(TraceWrap.java:58)         at  Proxy2.dropUser(Unknown Source)         at org.apache.accumulo.core.client.impl.thrift.ClientService Processor dropUser.process(ClientService.java:2257)         at org.apache.accumulo.core.tabletserver.thrift.TabletClientService Processor.process(TabletClientService.java:2037)         at org.apache.accumulo.server.util.TServerUtils TimedProcessor.process(TServerUtils.java:151)         at org.apache.thrift.server.TNonblockingServer FrameBuffer.invoke(TNonblockingServer.java:631)         at org.apache.accumulo.server.util.TServerUtils THsHaServer Invocation.run(TServerUtils.java:199)         at java.util.concurrent.ThreadPoolExecutor Worker.runTask(ThreadPoolExecutor.java:886)         at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:908)         at org.apache.accumulo.core.util.LoggingRunnable.run(LoggingRunnable.java:34)         at java.lang.Thread.run(Thread.java:662)  noformat  This tablet was the result of a split that occurred during a delete.  The master missed this tablet when taking tablets offline.  We need to do a consistency check on the offline tablets before deleting the table information in zookeeper.", "A_clean_title": ["master", "kill", "tablet", "servermast", "server", "master", "kill", "tablet", "server", "have", "long", "hold", "time", "tablet", "server", "had", "thi", "error", "dure", "minor", "compact", "noformat", "01", "23:57:20073", "secur", "zkauthent", "zk", "authent", "error", "org", "apach", "zookeep", "keeperexcept", "keeper", "except", "nonodeexcept", "no", "node", "except", "keepererrorcod", "keeper", "error", "code", "nonod", "no", "node", "a36a", "4218", "86b1", "accumulo", "88cd0f63", "9ba1d2cccf08", "user", "user004", "org", "apach", "zookeep", "keeperexcept", "keeper", "except", "nonodeexcept", "no", "node", "except", "keepererrorcod", "keeper", "error", "code", "nonod", "no", "node", "a36a", "4218", "86b1", "accumulo", "88cd0f63", "9ba1d2cccf08", "user", "user004", "at", "org", "apach", "zookeep", "keeperexcept", "creat", "keeper", "except", "keeperexcept", "java:102", "keeper", "except", "at", "org", "apach", "zookeep", "keeperexcept", "creat", "keeper", "except", "keeperexcept", "java:42", "keeper", "except", "at", "org", "apach", "zookeep", "zookeep", "getchildren", "zoo", "keeper", "get", "children", "zookeep", "java:1243", "zoo", "keeper", "at", "org", "apach", "zookeep", "zookeep", "getchildren", "zoo", "keeper", "get", "children", "zookeep", "java:1271", "zoo", "keeper", "at", "org", "apach", "accumulo", "core", "zookeep", "zooutil", "recursivedelet", "zoo", "util", "recurs", "delet", "zooutil", "java:103", "zoo", "util", "at", "org", "apach", "accumulo", "core", "zookeep", "zooutil", "recursivedelet", "zoo", "util", "recurs", "delet", "zooutil", "java:117", "zoo", "util", "at", "org", "apach", "accumulo", "server", "zookeep", "zooreaderwrit", "recursivedelet", "zoo", "reader", "writer", "recurs", "delet", "zooreaderwrit", "java:67", "zoo", "reader", "writer", "at", "sun", "reflect", "generatedmethodaccessor53", "invok", "gener", "method", "accessor53", "unknown", "sourc", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "org", "apach", "accumulo", "server", "zookeep", "zooreaderwrit", "zoo", "reader", "writer", "invok", "zooreaderwrit", "java:169", "zoo", "reader", "writer", "at", "proxy4", "recursivedelet", "recurs", "delet", "unknown", "sourc", "at", "org", "apach", "accumulo", "server", "secur", "zkauthent", "dropus", "zk", "authent", "drop", "user", "zkauthent", "java:252", "zk", "authent", "at", "org", "apach", "accumulo", "server", "secur", "auditor", "dropus", "drop", "user", "auditor", "java:104", "at", "org", "apach", "accumulo", "server", "client", "clientservicehandl", "dropus", "client", "servic", "handler", "drop", "user", "clientservicehandl", "java:136", "client", "servic", "handler", "at", "sun", "reflect", "generatedmethodaccessor52", "invok", "gener", "method", "accessor52", "unknown", "sourc", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "cloudtrac", "instrument", "thrift", "tracewrap", "trace", "wrap", "invok", "tracewrap", "java:58", "trace", "wrap", "at", "proxy2", "dropus", "drop", "user", "unknown", "sourc", "at", "org", "apach", "accumulo", "core", "client", "impl", "thrift", "clientservic", "client", "servic", "processor", "dropus", "process", "drop", "user", "clientservic", "java:2257", "client", "servic", "at", "org", "apach", "accumulo", "core", "tabletserv", "thrift", "tabletclientservic", "tablet", "client", "servic", "processor", "process", "tabletclientservic", "java:2037", "tablet", "client", "servic", "at", "org", "apach", "accumulo", "server", "util", "tserverutil", "server", "util", "timedprocessor", "process", "time", "processor", "tserverutil", "java:151", "server", "util", "at", "org", "apach", "thrift", "server", "tnonblockingserv", "nonblock", "server", "framebuff", "invok", "frame", "buffer", "tnonblockingserv", "java:631", "nonblock", "server", "at", "org", "apach", "accumulo", "server", "util", "tserverutil", "server", "util", "thshaserv", "hs", "server", "invoc", "run", "tserverutil", "java:199", "server", "util", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "runtask", "run", "task", "threadpoolexecutor", "java:886", "thread", "pool", "executor", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:908", "thread", "pool", "executor", "at", "org", "apach", "accumulo", "core", "util", "loggingrunn", "run", "log", "runnabl", "loggingrunn", "java:34", "log", "runnabl", "at", "java", "lang", "thread", "run", "thread", "java:662", "noformat", "thi", "tablet", "wa", "result", "split", "that", "occur", "dure", "delet", "master", "miss", "thi", "tablet", "when", "take", "tablet", "offlin", "we", "need", "consist", "check", "offlin", "tablet", "befor", "delet", "tabl", "inform", "zookeep"], "B_title": "ACCUMULO-379 ACCUMULO-375 merged from 1.4", "B_clean_title": ["accumulo", "379", "accumulo", "375", "merg"]},
{"A_title": "Keyed State does not work with DOP=1When changing the DOP from 3 to 1 in StatefulOperatorTest.apiTest() the test fails. The reason seems to be that the element is not properly set when chaining is happening.  Also requiring this: code headContext.setNextInput(nextRecord); streamOperator.processElement(nextRecord); code  to be called seems rather fragile. Why not set the element in processElement(). This would also make for cleaner encapsulation since now all outside code must assume that operators have a StreamingRuntimeContext on which they set the next element.  The state/keyed state machinery seems dangerously undertested.", "A_clean_title": ["key", "state", "not", "work", "dop=1when", "chang", "dop", "statefuloperatortest", "apitest", "state", "oper", "test", "api", "test", "test", "fail", "reason", "seem", "that", "element", "not", "properli", "set", "when", "chain", "happen", "also", "requir", "thi", "code", "headcontext", "setnextinput", "head", "context", "set", "next", "input", "nextrecord", "next", "record", "streamoper", "processel", "stream", "oper", "process", "element", "nextrecord", "next", "record", "code", "call", "seem", "rather", "fragil", "whi", "not", "set", "element", "processel", "process", "element", "thi", "would", "also", "make", "cleaner", "encapsul", "sinc", "now", "all", "outsid", "code", "must", "assum", "that", "oper", "have", "streamingruntimecontext", "stream", "runtim", "context", "which", "they", "set", "next", "element", "state", "key", "state", "machineri", "seem", "danger", "undertest"], "B_title": "streaming Fix partitioned state next-input setting for copying chained collectors", "B_clean_title": ["stream", "fix", "partit", "state", "next", "input", "set", "copi", "chain", "collector"]},
{"A_title": "Wildcards in relative property paths dont work in search expressionsA search XPath of the form: code /jcr:root/etc/commerce/products//*@size=M or */@size=M code returns: code Invalid path: * code (This works fine in Jackrabbit.)", "A_clean_title": ["wildcard", "rel", "properti", "path", "dont", "work", "search", "expressionsa", "express", "search", "xpath", "path", "form", "code", "jcr", "root", "etc", "commerc", "product", "size=m", "or", "size=m", "code", "return", "code", "invalid", "path", "code", "thi", "work", "fine", "jackrabbit"], "B_title": "Wildcards in relative property paths dont work in search expressions", "B_clean_title": ["wildcard", "rel", "properti", "path", "dont", "work", "search", "express"]},
{"A_title": "CompactCommand description is incorrectThe compact command has the following description  code root@accumulo> compact -? usage: compact <table> <table> -? -b <begin-row> --cancel -e <end-row> -nf -ns <namespace> | -p <pattern> | -t <tableName>  -pn <profile>  -w description: sets all tablets for a table to major compact as soon as possible (based on current time)   -?--help                       display this help   -b--begin-row <begin-row>      begin row (inclusive)      --cancel                     cancel user initiated compactions   -e--end-row <end-row>          end row (inclusive)   -nf--noFlush                   do not flush table data in memory before compacting.   -ns--namespace <namespace>     name of a namespace to operate on   -p--pattern <pattern>          regex pattern of table names to operate on   -pn--profile <profile>         iterator profile name   -t--table <tableName>          name of a table to operate on   -w--wait                       wait for compact to finish code  However the --begin-row is not inclusive.  Here is a simple demonstration. code createtable compacttest addsplits a b c insert a 1   insert a 2   insert b 3   insert b 4   insert c 5   insert c 6   flush -w scan -t accumulo.metadata -np compact -b a -e c -t compacttest -w scan -t accumulo.metadata -np deletetable compacttest -f code  You will see that file associated with the a split is still a F flush file which the files in the b and c split are A files.  Not sure if the fix is to update the commands description which would be easy or to make the begin row actually inclusive.", "A_clean_title": ["compactcommand", "compact", "command", "descript", "incorrectth", "incorrect", "compact", "command", "ha", "follow", "descript", "code", "root", "accumulo", "compact", "usag", "compact", "tabl", "tabl", "begin", "row", "cancel", "end", "row", "nf", "ns", "namespac", "pattern", "tablenam", "tabl", "name", "pn", "profil", "descript", "set", "all", "tablet", "tabl", "major", "compact", "as", "soon", "as", "possibl", "base", "current", "time", "help", "display", "thi", "help", "begin", "row", "begin", "row", "begin", "row", "inclus", "cancel", "cancel", "user", "initi", "compact", "end", "row", "end", "row", "end", "row", "inclus", "nf", "noflush", "no", "flush", "not", "flush", "tabl", "data", "memori", "befor", "compact", "ns", "namespac", "namespac", "name", "namespac", "oper", "pattern", "pattern", "regex", "pattern", "tabl", "name", "oper", "pn", "profil", "profil", "iter", "profil", "name", "tabl", "tablenam", "tabl", "name", "name", "tabl", "oper", "wait", "wait", "compact", "finish", "code", "howev", "begin", "row", "not", "inclus", "here", "simpl", "demonstr", "code", "createt", "compacttest", "addsplit", "insert", "insert", "insert", "insert", "insert", "insert", "flush", "scan", "accumulo", "metadata", "np", "compact", "compacttest", "scan", "accumulo", "metadata", "np", "deletet", "compacttest", "code", "you", "will", "see", "that", "file", "associ", "split", "still", "flush", "file", "which", "file", "split", "are", "file", "not", "sure", "fix", "updat", "command", "descript", "which", "would", "easi", "or", "make", "begin", "row", "actual", "inclus"], "B_title": "Fix the description of -b options", "B_clean_title": ["fix", "descript", "option"]},
{"A_title": "Link always causes Page to become stateful regardless of visibilityDespite the changes made in WICKET-4468  an invisible Link still causes a Page to become stateful.   The problem seems to be that Component#isStateless does this before even checking the visibility:   if (!getStatelessHint())  return false;    ... and Link#getStatelessHint() just contains just return false .", "A_clean_title": ["link", "alway", "caus", "page", "becom", "state", "regardless", "visibilitydespit", "visibl", "despit", "chang", "made", "wicket", "4468", "invis", "link", "still", "caus", "page", "becom", "state", "problem", "seem", "that", "compon", "isstateless", "stateless", "thi", "befor", "even", "check", "visibl", "getstatelesshint", "get", "stateless", "hint", "return", "fals", "link", "getstatelesshint", "get", "stateless", "hint", "just", "contain", "just", "return", "fals"], "B_title": "Link always causes Page to become stateful regardless of visibility", "B_clean_title": ["link", "alway", "caus", "page", "becom", "state", "regardless", "visibl"]},
{"A_title": "bracket function gives up too earlyIn UnivariateSolverUtils.bracket(...) the search ends prematurely if a = lowerBound which ignores some roots in the interval.", "A_clean_title": ["bracket", "function", "give", "up", "too", "earlyin", "earli", "univariatesolverutil", "bracket", "univari", "solver", "util", "search", "end", "prematur", "lowerbound", "lower", "bound", "which", "ignor", "some", "root", "interv"], "B_title": "bracket function gives up too early", "B_clean_title": ["bracket", "function", "give", "up", "too", "earli"]},
{"A_title": "NPE when using ComponentRenderer.renderComponent on a panel with <wicket:enclosure>Hi  Consider this example: <wicket:panel> <wicket:enclosure child=externalLink> <a wicket:id=externalLink>Link</a> </wicket:enclosure> </wicket:panel>  When trying to render such a panel with ComponentRenderer.renderComponent a NPE is thrown because Wicket try to render Enclosure without initializing it.  Root cause: java.lang.NullPointerException at org.apache.wicket.markup.html.internal.Enclosure.isVisible(Enclosure.java:143) at org.apache.wicket.Component.determineVisibility(Component.java:4363) at org.apache.wicket.Component.internalBeforeRender(Component.java:916) at org.apache.wicket.Component.beforeRender(Component.java:991) at org.apache.wicket.Component.internalPrepareForRender(Component.java:2214) at org.apache.wicket.Component.render(Component.java:2303) at org.apache.wicket.MarkupContainer.renderNext(MarkupContainer.java:1390) at org.apache.wicket.MarkupContainer.renderAll(MarkupContainer.java:1554) at org.apache.wicket.MarkupContainer.renderComponentTagBody(MarkupContainer.java:1529) at org.apache.wicket.MarkupContainer.renderAssociatedMarkup(MarkupContainer.java:689) at org.apache.wicket.markup.html.panel.AssociatedMarkupSourcingStrategy.renderAssociatedMarkup(AssociatedMarkupSourcingStrategy.java:76) at org.apache.wicket.markup.html.panel.PanelMarkupSourcingStrategy.onComponentTagBody(PanelMarkupSourcingStrategy.java:112) at org.apache.wicket.Component.internalRenderComponent(Component.java:2549) ... 29 more  See the attached quickstart.  Ive looked a little into it and it seems that RenderPage (used by ComponentRenderer to render components) is never initialized. Therefore the panels children are never initialized too (see MarkupContainer l.930) and this causes Enclosure to have a null childComponent.  Thanks.", "A_clean_title": ["npe", "when", "componentrender", "rendercompon", "compon", "render", "render", "compon", "panel", "wicket", "enclosur", "hi", "consid", "thi", "exampl", "wicket", "panel", "wicket", "enclosur", "child=externallink", "child=extern", "link", "wicket", "id=externallink", "id=extern", "link", "link", "wicket", "enclosur", "wicket", "panel", "when", "tri", "render", "such", "panel", "componentrender", "rendercompon", "compon", "render", "render", "compon", "npe", "thrown", "becaus", "wicket", "tri", "render", "enclosur", "without", "initi", "it", "root", "caus", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "wicket", "markup", "html", "intern", "enclosur", "isvis", "visibl", "enclosur", "java:143", "at", "org", "apach", "wicket", "compon", "determinevis", "determin", "visibl", "compon", "java:4363", "at", "org", "apach", "wicket", "compon", "internalbeforerend", "intern", "befor", "render", "compon", "java:916", "at", "org", "apach", "wicket", "compon", "beforerend", "befor", "render", "compon", "java:991", "at", "org", "apach", "wicket", "compon", "internalprepareforrend", "intern", "prepar", "render", "compon", "java:2214", "at", "org", "apach", "wicket", "compon", "render", "compon", "java:2303", "at", "org", "apach", "wicket", "markupcontain", "rendernext", "markup", "contain", "render", "next", "markupcontain", "java:1390", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "renderal", "markup", "contain", "render", "all", "markupcontain", "java:1554", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "rendercomponenttagbodi", "markup", "contain", "render", "compon", "tag", "bodi", "markupcontain", "java:1529", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "renderassociatedmarkup", "markup", "contain", "render", "associ", "markup", "markupcontain", "java:689", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "associatedmarkupsourcingstrategi", "renderassociatedmarkup", "associ", "markup", "sourc", "strategi", "render", "associ", "markup", "associatedmarkupsourcingstrategi", "java:76", "associ", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "panelmarkupsourcingstrategi", "oncomponenttagbodi", "panel", "markup", "sourc", "strategi", "compon", "tag", "bodi", "panelmarkupsourcingstrategi", "java:112", "panel", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "compon", "internalrendercompon", "intern", "render", "compon", "compon", "java:2549", "29", "more", "see", "attach", "quickstart", "ive", "look", "littl", "into", "it", "it", "seem", "that", "renderpag", "render", "page", "use", "by", "componentrender", "compon", "render", "render", "compon", "never", "initi", "therefor", "panel", "children", "are", "never", "initi", "too", "see", "markupcontain", "markup", "contain", "930", "thi", "caus", "enclosur", "have", "null", "childcompon", "child", "compon", "thank"], "B_title": "NPE when using ComponentRenderer.renderComponent on a panel with <wicket:enclosure>", "B_clean_title": ["npe", "when", "componentrender", "rendercompon", "compon", "render", "render", "compon", "panel", "wicket", "enclosur"]},
{"A_title": "LookupTranslator accepts CharSequence as input but fails to work with implementations other than StringThe core of org.apache.commons.lang3.text.translate is a HashMap<CharSequence CharSequence> lookupMap. From the Javadoc of CharSequence (emphasis mine):  This interface does not refine the general contracts of the equals and hashCode methods. The result of comparing two objects that implement CharSequence is therefore in general undefined. Each object may be implemented by a different class and there is no guarantee that each class will be capable of testing its instances for equality with those of the other. It is therefore inappropriate to use arbitrary CharSequence instances as elements in a set or as keys in a map. The current implementation causes code such as the following to not work as expected:  CharSequence cs1 = 1 < 2; CharSequence cs2 = CharBuffer.wrap(1 < 2.toCharArray());  System.out.println(StringEscapeUtils.ESCAPE_HTML4.translate(cs1)); System.out.println(StringEscapeUtils.ESCAPE_HTML4.translate(cs2));   ... which gives the following results (but should be identical):  1 &lt; 2 1 < 2   The problem at a minimum is that CharBuffer.equals is even documented in the Javadoc that:  A char buffer is not equal to any other type of object. ... so a lookup on a CharBuffer in the Map will always fail when compared against the String implementations that it contains. An obvious work-around is to instead use something along the lines of either of the following:  System.out.println(StringEscapeUtils.ESCAPE_HTML4.translate(cs2.toString())); System.out.println(StringEscapeUtils.escapeHtml4(cs2.toString()));   ... which forces everything back to a String.  However this is not practical when working with large sets of data which would require significant heap allocations and garbage collection concerns.  (As such I was actually trying to use the translate method that outputs to a Writer - but simplified the above examples to omit this.) Another option that Im considering is to use a custom CharSequence wrapper around a char that implements hashCode() and equals() to work with those implemented on String.  (However this will be interesting due to the symmetric assumption - which is further interesting that String.equals is currently implemented using instanceof - even though String is final...)", "A_clean_title": ["lookuptransl", "lookup", "translat", "accept", "charsequ", "char", "sequenc", "as", "input", "but", "fail", "work", "implement", "other", "than", "stringth", "string", "core", "org", "apach", "common", "lang3", "text", "translat", "hashmap", "hash", "map", "charsequ", "char", "sequenc", "charsequ", "char", "sequenc", "lookupmap", "lookup", "map", "javadoc", "charsequ", "char", "sequenc", "emphasi", "mine", "thi", "interfac", "not", "refin", "gener", "contract", "equal", "hashcod", "hash", "code", "method", "result", "compar", "two", "object", "that", "implement", "charsequ", "char", "sequenc", "therefor", "gener", "undefin", "each", "object", "may", "implement", "by", "differ", "class", "there", "no", "guarante", "that", "each", "class", "will", "capabl", "test", "it", "instanc", "equal", "those", "other", "it", "therefor", "inappropri", "use", "arbitrari", "charsequ", "char", "sequenc", "instanc", "as", "element", "set", "or", "as", "key", "map", "current", "implement", "caus", "code", "such", "as", "follow", "not", "work", "as", "expect", "charsequ", "char", "sequenc", "cs1", "charsequ", "char", "sequenc", "cs2", "charbuff", "wrap", "char", "buffer", "tochararray", "char", "array", "system", "out", "println", "stringescapeutil", "translat", "string", "escap", "util", "escap", "html4", "cs1", "system", "out", "println", "stringescapeutil", "translat", "string", "escap", "util", "escap", "html4", "cs2", "which", "give", "follow", "result", "but", "ident", "lt", "problem", "at", "minimum", "that", "charbuff", "equal", "char", "buffer", "even", "document", "javadoc", "that", "char", "buffer", "not", "equal", "ani", "other", "type", "object", "so", "lookup", "charbuff", "char", "buffer", "map", "will", "alway", "fail", "when", "compar", "against", "string", "implement", "that", "it", "contain", "obviou", "work", "around", "instead", "use", "someth", "along", "line", "either", "follow", "system", "out", "println", "stringescapeutil", "translat", "string", "escap", "util", "escap", "html4", "cs2", "tostr", "string", "system", "out", "println", "stringescapeutil", "escapehtml4", "string", "escap", "util", "escap", "html4", "cs2", "tostr", "string", "which", "forc", "everyth", "back", "string", "howev", "thi", "not", "practic", "when", "work", "larg", "set", "data", "which", "would", "requir", "signific", "heap", "alloc", "garbag", "collect", "concern", "as", "such", "wa", "actual", "tri", "use", "translat", "method", "that", "output", "writer", "but", "simplifi", "abov", "exampl", "omit", "thi", "anoth", "option", "that", "im", "consid", "use", "custom", "charsequ", "char", "sequenc", "wrapper", "around", "char", "that", "implement", "hashcod", "hash", "code", "equal", "work", "those", "implement", "string", "howev", "thi", "will", "interest", "due", "symmetr", "assumpt", "which", "further", "interest", "that", "string", "equal", "current", "implement", "instanceof", "even", "though", "string", "final"], "B_title": "Allow LookupTranslator to support CharSequence properly; previously it was working only for CharSequences that implemented hashCode and equals(Object). LANG-882", "B_clean_title": ["allow", "lookuptransl", "lookup", "translat", "support", "charsequ", "char", "sequenc", "properli", "previous", "it", "wa", "work", "onli", "charsequ", "char", "sequenc", "that", "implement", "hashcod", "hash", "code", "equal", "object", "lang", "882"]},
{"A_title": "wicket:border: inconsistency between add() and remove()Assuming c1 is a Border and c2 is some component the following sequence crashes with duplicate addition:  c1.add(c2); c1.remove(c2); c1.add(c2);  The reason for this is that remove() doesnt remove the object from the bodycontainer. The sequence can be made to work by changing the middle line to:  c1.getBodyContainer().remove(c2);  That remove() doesnt look the component from the same container as add() adds it to seems to violate the principle of least astonishment. Unfortunately the Component structure manipulation API has more methods such as swap() size() get() etc. which are final and cant be overridden by Border as they are. It could be best to force all users to use c1.getBodyContainer().add() instead of c1.add() because consistent operation is probably easier to deal with in the long run than behavior that conforms to initial assumptions but has flaws elsewhere.  This ticket suggests removing the overload of add() and documenting the difference in migration guide.", "A_clean_title": ["wicket", "border", "inconsist", "between", "add", "remov", "assum", "c1", "border", "c2", "some", "compon", "follow", "sequenc", "crash", "duplic", "addit", "c1", "add", "c2", "c1", "remov", "c2", "c1", "add", "c2", "reason", "thi", "that", "remov", "doesnt", "remov", "object", "bodycontain", "sequenc", "made", "work", "by", "chang", "middl", "line", "c1", "getbodycontain", "get", "bodi", "contain", "remov", "c2", "that", "remov", "doesnt", "look", "compon", "same", "contain", "as", "add", "add", "it", "seem", "violat", "principl", "least", "astonish", "unfortun", "compon", "structur", "manipul", "api", "ha", "more", "method", "such", "as", "swap", "size", "get", "etc", "which", "are", "final", "cant", "overridden", "by", "border", "as", "they", "are", "it", "could", "best", "forc", "all", "user", "use", "c1", "getbodycontain", "get", "bodi", "contain", "add", "instead", "c1", "add", "becaus", "consist", "oper", "probabl", "easier", "deal", "long", "run", "than", "behavior", "that", "conform", "initi", "assumpt", "but", "ha", "flaw", "elsewher", "thi", "ticket", "suggest", "remov", "overload", "add", "document", "differ", "migrat", "guid"], "B_title": "quickie test fix need to think some more about this :/ Issue: WICKET-3702", "B_clean_title": ["quicki", "test", "fix", "need", "think", "some", "more", "about", "thi", "issu", "wicket", "3702"]},
{"A_title": "StackOverflowError exception when running closure compiler (javascript attached)None", "A_clean_title": ["stackoverflowerror", "stack", "overflow", "error", "except", "when", "run", "closur", "compil", "javascript", "attach", "none"], "B_title": "More recursion unrolling Fixes issue 691", "B_clean_title": ["more", "recurs", "unrol", "fix", "issu", "691"]},
{"A_title": "Optimizer does not push properties out of bulk iterationsFlinks optimizer should be able to reuse interesting properties from outside the loop. In order to do that it is sometimes necessary to append a NoOp node to the step function which recomputes the required properties.  This is currently not working for BulkIterations because the plans with the appended NoOp nodes are not added to the overall list of candidates.  This not only leads to sub-optimal plan selection but sometimes to the rejection of valid jobs. The following job for example will be falsely rejected by flink.  code ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();  DataSet<Tuple1<Long>> input1 = env.generateSequence(1 10).map(new MapFunction<Long Tuple1<Long>>()  @Override public Tuple1<Long> map(Long value) throws Exception  return new Tuple1<>(value);  );  DataSet<Tuple1<Long>> input2 = env.generateSequence(1 10).map(new MapFunction<Long Tuple1<Long>>()  @Override public Tuple1<Long> map(Long value) throws Exception  return new Tuple1<>(value);  );  DataSet<Tuple1<Long>> distinctInput = input1.distinct();  IterativeDataSet<Tuple1<Long>> iteration = distinctInput.iterate(10);  DataSet<Tuple1<Long>> iterationStep = iteration .coGroup(input2) .where(0) .equalTo(0) .with(new CoGroupFunction<Tuple1<Long> Tuple1<Long> Tuple1<Long>>()  @Override public void coGroup( Iterable<Tuple1<Long>> first Iterable<Tuple1<Long>> second Collector<Tuple1<Long>> out) throws Exception  Iterator<Tuple1<Long>> it = first.iterator();  if (it.hasNext())  out.collect(it.next());   );  DataSet<Tuple1<Long>> iterationResult = iteration.closeWith(iterationStep);  iterationResult.output(new DiscardingOutputFormat<Tuple1<Long>>()); code", "A_clean_title": ["optim", "not", "push", "properti", "out", "bulk", "iterationsflink", "iter", "flink", "optim", "abl", "reus", "interest", "properti", "outsid", "loop", "order", "that", "it", "sometim", "necessari", "append", "noop", "no", "op", "node", "step", "function", "which", "recomput", "requir", "properti", "thi", "current", "not", "work", "bulkiter", "bulk", "iter", "becaus", "plan", "append", "noop", "no", "op", "node", "are", "not", "ad", "overal", "list", "candid", "thi", "not", "onli", "lead", "sub", "optim", "plan", "select", "but", "sometim", "reject", "valid", "job", "follow", "job", "exampl", "will", "fals", "reject", "by", "flink", "code", "executionenviron", "execut", "environ", "env", "executionenviron", "getexecutionenviron", "execut", "environ", "get", "execut", "environ", "dataset", "data", "set", "tuple1", "long", "input1", "env", "generatesequ", "gener", "sequenc", "10", "map", "new", "mapfunct", "map", "function", "long", "tuple1", "long", "overrid", "public", "tuple1", "long", "map", "long", "valu", "throw", "except", "return", "new", "tuple1", "valu", "dataset", "data", "set", "tuple1", "long", "input2", "env", "generatesequ", "gener", "sequenc", "10", "map", "new", "mapfunct", "map", "function", "long", "tuple1", "long", "overrid", "public", "tuple1", "long", "map", "long", "valu", "throw", "except", "return", "new", "tuple1", "valu", "dataset", "data", "set", "tuple1", "long", "distinctinput", "distinct", "input", "input1", "distinct", "iterativedataset", "iter", "data", "set", "tuple1", "long", "iter", "distinctinput", "iter", "distinct", "input", "10", "dataset", "data", "set", "tuple1", "long", "iterationstep", "iter", "step", "iter", "cogroup", "co", "group", "input2", "where", "equalto", "equal", "new", "cogroupfunct", "co", "group", "function", "tuple1", "long", "tuple1", "long", "tuple1", "long", "overrid", "public", "void", "cogroup", "co", "group", "iter", "tuple1", "long", "first", "iter", "tuple1", "long", "second", "collector", "tuple1", "long", "out", "throw", "except", "iter", "tuple1", "long", "it", "first", "iter", "it", "hasnext", "ha", "next", "out", "collect", "it", "next", "dataset", "data", "set", "tuple1", "long", "iterationresult", "iter", "result", "iter", "closewith", "close", "iterationstep", "iter", "step", "iterationresult", "output", "iter", "result", "new", "discardingoutputformat", "discard", "output", "format", "tuple1", "long", "code"], "B_title": "optimizer Fix instantiation of bulk iteration candidates", "B_clean_title": ["optim", "fix", "instanti", "bulk", "iter", "candid"]},
{"A_title": "CMAESOptimizer with bounds fits finely near lower bound and coarsely near upper bound.When fitting with bounds the CMAESOptimizer fits finely near the lower bound and coarsely near the upper bound.  This is because it internally maps the fitted parameter range into the interval 01.  The unit of least precision (ulp) between floating point numbers is much smaller near zero than near one.  Thus fits have much better resolution near the lower bound (which is mapped to zero) than the upper bound (which is mapped to one).  I will attach a example program to demonstrate.", "A_clean_title": ["cmaesoptim", "cmae", "optim", "bound", "fit", "fine", "near", "lower", "bound", "coars", "near", "upper", "bound", "when", "fit", "bound", "cmaesoptim", "cmae", "optim", "fit", "fine", "near", "lower", "bound", "coars", "near", "upper", "bound", "thi", "becaus", "it", "intern", "map", "fit", "paramet", "rang", "into", "interv", "01", "unit", "least", "precis", "ulp", "between", "float", "point", "number", "much", "smaller", "near", "zero", "than", "near", "one", "thu", "fit", "have", "much", "better", "resolut", "near", "lower", "bound", "which", "map", "zero", "than", "upper", "bound", "which", "map", "one", "will", "attach", "exampl", "program", "demonstr"], "B_title": "Previous commit was missing a crucial modification (in the repair method) an inconsistency which entailed the failing of some tests. With that modification (thanks to Nikolaus Hansen) it was established that the encode and decode steps were indeed useless. This commit thus removes them and all the code that was necessary only because of those two methods. Finite and infinite can now be freely mixed. Unit tests that depended on those limitations were also removed (thus also the one that was added following MATH-865).", "B_clean_title": ["previou", "commit", "wa", "miss", "crucial", "modif", "repair", "method", "inconsist", "which", "entail", "fail", "some", "test", "that", "modif", "thank", "nikolau", "hansen", "it", "wa", "establish", "that", "encod", "decod", "step", "were", "inde", "useless", "thi", "commit", "thu", "remov", "them", "all", "code", "that", "wa", "necessari", "onli", "becaus", "those", "two", "method", "finit", "infinit", "now", "freeli", "mix", "unit", "test", "that", "depend", "those", "limit", "were", "also", "remov", "thu", "also", "one", "that", "wa", "ad", "follow", "math", "865"]},
{"A_title": "Fix for MultiplePiePlotWhen dataset is passed into constructor for MultiplePiePlot the dataset is not wired to a listener as it would be if setDataset is called.", "A_clean_title": ["fix", "multiplepieplotwhen", "multipl", "pie", "plot", "when", "dataset", "pass", "into", "constructor", "multiplepieplot", "multipl", "pie", "plot", "dataset", "not", "wire", "listen", "as", "it", "would", "setdataset", "set", "dataset", "call"], "B_title": "source/org/jfree/chart/plot/MultiplePiePlot.java (MultiplePiePlot(CategoryDataset)): Call setDataset() to ensure that plot registers as a dataset listener.", "B_clean_title": ["java", "sourc", "org", "jfree", "chart", "plot", "multiplepieplot", "multipl", "pie", "plot", "multiplepieplot", "multipl", "pie", "plot", "categorydataset", "categori", "dataset", "call", "setdataset", "set", "dataset", "ensur", "that", "plot", "regist", "as", "dataset", "listen"]},
{"A_title": "Complex Add and Subtract handle NaN arguments differently but javadoc contracts are the sameFor both Complex add and subtract the javadoc states that       * If either this or <code>rhs</code> has a NaN value in either part      * @link #NaN is returned; otherwise Inifinite and NaN values are      * returned in the parts of the result according to the rules for      * @link java.lang.Double arithmetic   Subtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored since this looks like a code merge problem going back to 1.1).", "A_clean_title": ["complex", "add", "subtract", "handl", "nan", "na", "argument", "differ", "but", "javadoc", "contract", "are", "samefor", "same", "both", "complex", "add", "subtract", "javadoc", "state", "that", "either", "thi", "or", "code", "rh", "code", "ha", "nan", "na", "valu", "either", "part", "link", "nan", "na", "return", "otherwis", "inifinit", "nan", "na", "valu", "are", "return", "part", "result", "accord", "rule", "link", "java", "lang", "doubl", "arithmet", "subtract", "includ", "isnan", "na", "test", "return", "complex", "nan", "na", "either", "complex", "argument", "isnan", "na", "but", "add", "omit", "thi", "test", "test", "ad", "add", "implement", "actual", "restor", "sinc", "thi", "look", "like", "code", "merg", "problem", "go", "back"], "B_title": "Fixed add method to match javadoc contract when one or both addends has NaN parts.", "B_clean_title": ["fix", "add", "method", "match", "javadoc", "contract", "when", "one", "or", "both", "addend", "ha", "nan", "na", "part"]},
{"A_title": "When I upload data with one row data is not uploadedHow to Reproduce  Upload with advanced importer add mode:   eric_de_test_model.xlsx Upload csv in this zip:  eu_bbmri_eric_DE_biobanks.csv.zip Expected behavior  1 row is added to the biobanks table  Observed behavior  Import succeeds 0 rows imported", "A_clean_title": ["when", "upload", "data", "one", "row", "data", "not", "uploadedhow", "upload", "how", "reproduc", "upload", "advanc", "import", "add", "mode", "xlsx", "eric", "de", "test", "model", "upload", "csv", "thi", "zip", "csv", "zip", "eu", "bbmri", "eric", "de", "biobank", "expect", "behavior", "row", "ad", "biobank", "tabl", "observ", "behavior", "import", "succe", "row", "import"], "B_title": "Merge pull request #7274 from dennishendriksen/fix/7183-csvImportRowMissing  Fix #7183 CSV read exception on #values mismatch with #headers", "B_clean_title": ["merg", "pull", "request", "7274", "csvimportrowmiss", "dennishendriksen", "fix", "7183", "csv", "import", "row", "miss", "fix", "7183", "csv", "read", "except", "valu", "mismatch", "header"]},
{"A_title": "FastDateFormats z pattern does not respect timezone of Calendar instances passed to format()The work on LANG-462 has introduced a time zone formatting bug in FastDateFormat in commons-lang3. The problem can be seen by this snippet:  // Always prints timezone name of machines default timezone ignoring TZ // set on calendar even though the printed time itself respects calendars TZ. Calendar myCal = Calendar.getInstance(TimeZone.getTimeZone(US/Central)); System.out.println(FastDateFormat.getInstance(h:mma z).format(myCal));   If you happen to be in US/Central this will print the right thing but just try it with US/Eastern US/Pacific etc.  It will print the time in the correct timezone but the timezone name at the end (the z pattern) will always be the system default timezone.  This is a regression against commons-lang 2.x. Basically when the forced time zone code was removed the TimeZoneNameRule class stopped respecting the Calendar instances timezone and instead now always uses the mTimeZone of the FastDateFormat instance itself (which is only supposed to be used when formatting timezone-less objects such as Date or long). The removal of the forced time zone stuff is surely the right thing to do (it was a mess).  I think the fix is to change the TimeZoneNameRule inner class to not take a TimeZone instance but rather to use the TimeZone on the Calendar instance passed into appendTo() just like TimeZoneNumberRule does.  Presumably then for efficiency one would use the getTimeZoneDisplay() package-static method to quickly retrieve the required timezones display name.", "A_clean_title": ["fastdateformat", "fast", "date", "format", "pattern", "not", "respect", "timezon", "calendar", "instanc", "pass", "format", "work", "lang", "462", "ha", "introduc", "time", "zone", "format", "bug", "fastdateformat", "fast", "date", "format", "common", "lang3", "problem", "seen", "by", "thi", "snippet", "alway", "print", "timezon", "name", "machin", "default", "timezon", "ignor", "tz", "set", "calendar", "even", "though", "print", "time", "itself", "respect", "calendar", "tz", "calendar", "mycal", "my", "cal", "calendar", "getinst", "get", "instanc", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "us", "central", "system", "out", "println", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "mma", "format", "mycal", "my", "cal", "you", "happen", "us", "central", "thi", "will", "print", "right", "thing", "but", "just", "tri", "it", "us", "eastern", "us", "pacif", "etc", "it", "will", "print", "time", "correct", "timezon", "but", "timezon", "name", "at", "end", "pattern", "will", "alway", "system", "default", "timezon", "thi", "regress", "against", "common", "lang", "basic", "when", "forc", "time", "zone", "code", "wa", "remov", "timezonenamerul", "time", "zone", "name", "rule", "class", "stop", "respect", "calendar", "instanc", "timezon", "instead", "now", "alway", "use", "mtimezon", "time", "zone", "fastdateformat", "fast", "date", "format", "instanc", "itself", "which", "onli", "suppos", "use", "when", "format", "timezon", "less", "object", "such", "as", "date", "or", "long", "remov", "forc", "time", "zone", "stuff", "sure", "right", "thing", "it", "wa", "mess", "think", "fix", "chang", "timezonenamerul", "time", "zone", "name", "rule", "inner", "class", "not", "take", "timezon", "time", "zone", "instanc", "but", "rather", "use", "timezon", "time", "zone", "calendar", "instanc", "pass", "into", "appendto", "append", "just", "like", "timezonenumberrul", "time", "zone", "number", "rule", "presum", "then", "effici", "one", "would", "use", "gettimezonedisplay", "get", "time", "zone", "display", "packag", "static", "method", "quickli", "retriev", "requir", "timezon", "display", "name"], "B_title": "FastDateFormats z pattern does not respect timezone of Calendar instances passed to format()", "B_clean_title": ["fastdateformat", "fast", "date", "format", "pattern", "not", "respect", "timezon", "calendar", "instanc", "pass", "format"]},
{"A_title": "IndexCopier might create empty files in case of error occuring while copyingOn some of the setups following logs are seen noformat error.log:12.03.2015 03:53:59.785 *WARN* pool-5-thread-90 org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier Found local copy for _2uv.cfs in MMapDirectory@/mnt/installation/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 lockFactory=NativeFSLockFactory@/mnt/installation/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 but size of local 0 differs from remote 1070972. Content would be read from remote file only error.log:12.03.2015 03:54:02.883 *WARN* pool-5-thread-125 org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier Found local copy for _2rr.si in MMapDirectory@/mnt/installation/crx-quickstart/repository/index/43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def/1 lockFactory=NativeFSLockFactory@/mnt/installation/crx-quickstart/repository/index/43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def/1 but size of local 0 differs from remote 240. Content would be read from remote file only error.log:12.03.2015 03:54:03.467 *WARN* pool-5-thread-132 org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier Found local copy for _2ro_3.del in MMapDirectory@/mnt/installation/crx-quickstart/repository/index/43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def/1 lockFactory=NativeFSLockFactory@/mnt/installation/crx-quickstart/repository/index/43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def/1 but size of local 0 differs from remote 42. Content would be read from remote file only error.log:12.03.2015 03:54:03.737 *WARN* pool-5-thread-135 org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier Found local copy for _2rm_2.del in MMapDirectory@/mnt/installation/crx-quickstart/repository/index/43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def/1 lockFactory=NativeFSLockFactory@/mnt/installation/crx-quickstart/repository/index/43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def/1 but size of local 0 differs from remote 35. Content would be read from remote file only noformat  They indicate that copier has created files of size 0. Looking at the code flow this can happen in case while starting copying some error occurs in between. org.apache.lucene.store.Directory#copy do take care of removing the file in case of error but that is done only for IOException and not for other cases.  As a fix the logic should ensure that local file gets deleted if the copy was not successful", "A_clean_title": ["indexcopi", "index", "copier", "might", "creat", "empti", "file", "case", "error", "occur", "while", "copyingon", "copi", "some", "setup", "follow", "log", "are", "seen", "noformat", "error", "log:12", "03", "2015", "03:53:59", "785", "warn", "pool", "thread", "90", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexcopi", "index", "copier", "found", "local", "copi", "cf", "2uv", "mmapdirectori", "map", "directori", "mnt", "instal", "crx", "quickstart", "repositori", "index", "e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293", "lockfactory=nativefslockfactori", "lock", "factory=n", "fs", "lock", "factori", "mnt", "instal", "crx", "quickstart", "repositori", "index", "e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293", "but", "size", "local", "differ", "remot", "1070972", "content", "would", "read", "remot", "file", "onli", "error", "log:12", "03", "2015", "03:54:02", "883", "warn", "pool", "thread", "125", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexcopi", "index", "copier", "found", "local", "copi", "si", "2rr", "mmapdirectori", "map", "directori", "mnt", "instal", "crx", "quickstart", "repositori", "index", "43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def", "lockfactory=nativefslockfactori", "lock", "factory=n", "fs", "lock", "factori", "mnt", "instal", "crx", "quickstart", "repositori", "index", "43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def", "but", "size", "local", "differ", "remot", "240", "content", "would", "read", "remot", "file", "onli", "error", "log:12", "03", "2015", "03:54:03", "467", "warn", "pool", "thread", "132", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexcopi", "index", "copier", "found", "local", "copi", "del", "2ro", "mmapdirectori", "map", "directori", "mnt", "instal", "crx", "quickstart", "repositori", "index", "43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def", "lockfactory=nativefslockfactori", "lock", "factory=n", "fs", "lock", "factori", "mnt", "instal", "crx", "quickstart", "repositori", "index", "43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def", "but", "size", "local", "differ", "remot", "42", "content", "would", "read", "remot", "file", "onli", "error", "log:12", "03", "2015", "03:54:03", "737", "warn", "pool", "thread", "135", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "indexcopi", "index", "copier", "found", "local", "copi", "del", "2rm", "mmapdirectori", "map", "directori", "mnt", "instal", "crx", "quickstart", "repositori", "index", "43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def", "lockfactory=nativefslockfactori", "lock", "factory=n", "fs", "lock", "factori", "mnt", "instal", "crx", "quickstart", "repositori", "index", "43b36b107f8ce7e162c15b22508aa457ff6ae0083ed3e12d14a7dab67f886def", "but", "size", "local", "differ", "remot", "35", "content", "would", "read", "remot", "file", "onli", "noformat", "they", "indic", "that", "copier", "ha", "creat", "file", "size", "look", "at", "code", "flow", "thi", "happen", "case", "while", "start", "copi", "some", "error", "occur", "between", "org", "apach", "lucen", "store", "directori", "copi", "take", "care", "remov", "file", "case", "error", "but", "that", "done", "onli", "ioexcept", "io", "except", "not", "other", "case", "as", "fix", "logic", "ensur", "that", "local", "file", "get", "delet", "copi", "wa", "not", "success"], "B_title": "- IndexCopier might create empty files in case of error occuring while copying", "B_clean_title": ["indexcopi", "index", "copier", "might", "creat", "empti", "file", "case", "error", "occur", "while", "copi"]},
{"A_title": "Regression: Could not find child with id: <ID> in the wicket:enclosure for non-component tagAttached testcase passes with wicket-1.4.1 but fails with 1.4.2 saying:  org.apache.wicket.WicketRuntimeException: Could not find child with id: radio in the wicket:enclosure at org.apache.wicket.markup.html.internal.Enclosure.checkChildComponent(Enclosure.java:210) at org.apache.wicket.markup.html.internal.Enclosure.ensureAllChildrenPresent(Enclosure.java:249) at org.apache.wicket.markup.html.internal.Enclosure.onComponentTagBody(Enclosure.java:169) at org.apache.wicket.Component.renderComponent(Component.java:2626) at org.apache.wicket.MarkupContainer.onRender(MarkupContainer.java:1512) at org.apache.wicket.Component.render(Component.java:2457) at org.apache.wicket.MarkupContainer.autoAdd(MarkupContainer.java:229) at org.apache.wicket.markup.resolver.EnclosureResolver.resolve(EnclosureResolver.java:61) at org.apache.wicket.markup.resolver.ComponentResolvers.resolve(ComponentResolvers.java:81) at org.apache.wicket.MarkupContainer.renderNext(MarkupContainer.java:1418) at org.apache.wicket.MarkupContainer.renderComponentTagBody(MarkupContainer.java:1577) at org.apache.wicket.MarkupContainer.onComponentTagBody(MarkupContainer.java:1501) at org.apache.wicket.Component.renderComponent(Component.java:2626) at org.apache.wicket.MarkupContainer.onRender(MarkupContainer.java:1512) at org.apache.wicket.Component.render(Component.java:2457) at org.apache.wicket.MarkupContainer.renderNext(MarkupContainer.java:1414) at org.apache.wicket.MarkupContainer.renderAll(MarkupContainer.java:1528) at org.apache.wicket.Page.onRender(Page.java:1545) at org.apache.wicket.Component.render(Component.java:2457) at org.apache.wicket.Page.renderPage(Page.java:914) at org.apache.wicket.request.target.component.BookmarkablePageRequestTarget.respond(BookmarkablePageRequestTarget.java:262) at org.apache.wicket.request.AbstractRequestCycleProcessor.respond(AbstractRequestCycleProcessor.java:105) at org.apache.wicket.RequestCycle.processEventsAndRespond(RequestCycle.java:1258) at org.apache.wicket.RequestCycle.step(RequestCycle.java:1329) at org.apache.wicket.RequestCycle.steps(RequestCycle.java:1428) at org.apache.wicket.RequestCycle.request(RequestCycle.java:594) at org.apache.wicket.protocol.http.MockWebApplication.processRequestCycle(MockWebApplication.java:478) at org.apache.wicket.protocol.http.MockWebApplication.processRequestCycle(MockWebApplication.java:390) at org.apache.wicket.util.tester.BaseWicketTester.startPage(BaseWicketTester.java:300) at org.apache.wicket.EnclosurePageTest.testRender(EnclosurePageTest.java:23) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at junit.framework.TestCase.runTest(TestCase.java:154) at junit.framework.TestCase.runBare(TestCase.java:127) at junit.framework.TestResult 1.protect(TestResult.java:106) at junit.framework.TestResult.runProtected(TestResult.java:124) at junit.framework.TestResult.run(TestResult.java:109) at junit.framework.TestCase.run(TestCase.java:118) at junit.framework.TestSuite.runTest(TestSuite.java:208) at junit.framework.TestSuite.run(TestSuite.java:203) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.maven.surefire.junit.JUnitTestSet.execute(JUnitTestSet.java:213) at org.apache.maven.surefire.suite.AbstractDirectoryTestSuite.executeTestSet(AbstractDirectoryTestSuite.java:140) at org.apache.maven.surefire.suite.AbstractDirectoryTestSuite.execute(AbstractDirectoryTestSuite.java:127) at org.apache.maven.surefire.Surefire.run(Surefire.java:177) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.maven.surefire.booter.SurefireBooter.runSuitesInProcess(SurefireBooter.java:345) at org.apache.maven.surefire.booter.SurefireBooter.main(SurefireBooter.java:1009)", "A_clean_title": ["regress", "could", "not", "find", "child", "id", "id", "wicket", "enclosur", "non", "compon", "tagattach", "tag", "attach", "testcas", "pass", "wicket", "but", "fail", "say", "org", "apach", "wicket", "wicketruntimeexcept", "wicket", "runtim", "except", "could", "not", "find", "child", "id", "radio", "wicket", "enclosur", "at", "org", "apach", "wicket", "markup", "html", "intern", "enclosur", "checkchildcompon", "check", "child", "compon", "enclosur", "java:210", "at", "org", "apach", "wicket", "markup", "html", "intern", "enclosur", "ensureallchildrenpres", "ensur", "all", "children", "present", "enclosur", "java:249", "at", "org", "apach", "wicket", "markup", "html", "intern", "enclosur", "oncomponenttagbodi", "compon", "tag", "bodi", "enclosur", "java:169", "at", "org", "apach", "wicket", "compon", "rendercompon", "render", "compon", "compon", "java:2626", "at", "org", "apach", "wicket", "markupcontain", "onrend", "markup", "contain", "render", "markupcontain", "java:1512", "markup", "contain", "at", "org", "apach", "wicket", "compon", "render", "compon", "java:2457", "at", "org", "apach", "wicket", "markupcontain", "autoadd", "markup", "contain", "auto", "add", "markupcontain", "java:229", "markup", "contain", "at", "org", "apach", "wicket", "markup", "resolv", "enclosureresolv", "resolv", "enclosur", "resolv", "enclosureresolv", "java:61", "enclosur", "resolv", "at", "org", "apach", "wicket", "markup", "resolv", "componentresolv", "resolv", "compon", "resolv", "componentresolv", "java:81", "compon", "resolv", "at", "org", "apach", "wicket", "markupcontain", "rendernext", "markup", "contain", "render", "next", "markupcontain", "java:1418", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "rendercomponenttagbodi", "markup", "contain", "render", "compon", "tag", "bodi", "markupcontain", "java:1577", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "oncomponenttagbodi", "markup", "contain", "compon", "tag", "bodi", "markupcontain", "java:1501", "markup", "contain", "at", "org", "apach", "wicket", "compon", "rendercompon", "render", "compon", "compon", "java:2626", "at", "org", "apach", "wicket", "markupcontain", "onrend", "markup", "contain", "render", "markupcontain", "java:1512", "markup", "contain", "at", "org", "apach", "wicket", "compon", "render", "compon", "java:2457", "at", "org", "apach", "wicket", "markupcontain", "rendernext", "markup", "contain", "render", "next", "markupcontain", "java:1414", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "renderal", "markup", "contain", "render", "all", "markupcontain", "java:1528", "markup", "contain", "at", "org", "apach", "wicket", "page", "onrend", "render", "page", "java:1545", "at", "org", "apach", "wicket", "compon", "render", "compon", "java:2457", "at", "org", "apach", "wicket", "page", "renderpag", "render", "page", "page", "java:914", "at", "org", "apach", "wicket", "request", "target", "compon", "bookmarkablepagerequesttarget", "respond", "bookmark", "page", "request", "target", "bookmarkablepagerequesttarget", "java:262", "bookmark", "page", "request", "target", "at", "org", "apach", "wicket", "request", "abstractrequestcycleprocessor", "respond", "abstract", "request", "cycl", "processor", "abstractrequestcycleprocessor", "java:105", "abstract", "request", "cycl", "processor", "at", "org", "apach", "wicket", "requestcycl", "processeventsandrespond", "request", "cycl", "process", "event", "respond", "requestcycl", "java:1258", "request", "cycl", "at", "org", "apach", "wicket", "requestcycl", "step", "request", "cycl", "requestcycl", "java:1329", "request", "cycl", "at", "org", "apach", "wicket", "requestcycl", "step", "request", "cycl", "requestcycl", "java:1428", "request", "cycl", "at", "org", "apach", "wicket", "requestcycl", "request", "request", "cycl", "requestcycl", "java:594", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "http", "mockwebappl", "processrequestcycl", "mock", "web", "applic", "process", "request", "cycl", "mockwebappl", "java:478", "mock", "web", "applic", "at", "org", "apach", "wicket", "protocol", "http", "mockwebappl", "processrequestcycl", "mock", "web", "applic", "process", "request", "cycl", "mockwebappl", "java:390", "mock", "web", "applic", "at", "org", "apach", "wicket", "util", "tester", "basewickettest", "startpag", "base", "wicket", "tester", "start", "page", "basewickettest", "java:300", "base", "wicket", "tester", "at", "org", "apach", "wicket", "enclosurepagetest", "testrend", "enclosur", "page", "test", "test", "render", "enclosurepagetest", "java:23", "enclosur", "page", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "junit", "framework", "testcas", "runtest", "test", "case", "run", "test", "testcas", "java:154", "test", "case", "at", "junit", "framework", "testcas", "runbar", "test", "case", "run", "bare", "testcas", "java:127", "test", "case", "at", "junit", "framework", "testresult", "test", "result", "protect", "testresult", "java:106", "test", "result", "at", "junit", "framework", "testresult", "runprotect", "test", "result", "run", "protect", "testresult", "java:124", "test", "result", "at", "junit", "framework", "testresult", "run", "test", "result", "testresult", "java:109", "test", "result", "at", "junit", "framework", "testcas", "run", "test", "case", "testcas", "java:118", "test", "case", "at", "junit", "framework", "testsuit", "runtest", "test", "suit", "run", "test", "testsuit", "java:208", "test", "suit", "at", "junit", "framework", "testsuit", "run", "test", "suit", "testsuit", "java:203", "test", "suit", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "org", "apach", "maven", "surefir", "junit", "junittestset", "execut", "unit", "test", "set", "junittestset", "java:213", "unit", "test", "set", "at", "org", "apach", "maven", "surefir", "suit", "abstractdirectorytestsuit", "executetestset", "abstract", "directori", "test", "suit", "execut", "test", "set", "abstractdirectorytestsuit", "java:140", "abstract", "directori", "test", "suit", "at", "org", "apach", "maven", "surefir", "suit", "abstractdirectorytestsuit", "execut", "abstract", "directori", "test", "suit", "abstractdirectorytestsuit", "java:127", "abstract", "directori", "test", "suit", "at", "org", "apach", "maven", "surefir", "surefir", "run", "surefir", "java:177", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "org", "apach", "maven", "surefir", "booter", "surefireboot", "runsuitesinprocess", "surefir", "booter", "run", "suit", "process", "surefireboot", "java:345", "surefir", "booter", "at", "org", "apach", "maven", "surefir", "booter", "surefireboot", "main", "surefir", "booter", "surefireboot", "java:1009", "surefir", "booter"], "B_title": "fixed:  Regression: Could not find child with id: <ID> in the wicket:enclosure for non-component tag Issue: WICKET-2506", "B_clean_title": ["fix", "regress", "could", "not", "find", "child", "id", "id", "wicket", "enclosur", "non", "compon", "tag", "issu", "wicket", "2506"]},
{"A_title": "AsyncIndexUpdate may resurrect nodesThere is a race condition in the AsyncIndexUpdate.run() method. The implementation creates a checkpoint used as the after node state for the comparison with the previous checkpoint. In a next step a builder is created from the current root state of the node store. Node removed between the checkpoint call and retrieving the root state may get resurrected by the AsyncIndexUpdate.", "A_clean_title": ["asyncindexupd", "async", "index", "updat", "may", "resurrect", "nodesther", "node", "there", "race", "condit", "asyncindexupd", "run", "async", "index", "updat", "method", "implement", "creat", "checkpoint", "use", "as", "after", "node", "state", "comparison", "previou", "checkpoint", "next", "step", "builder", "creat", "current", "root", "state", "node", "store", "node", "remov", "between", "checkpoint", "call", "retriev", "root", "state", "may", "get", "resurrect", "by", "asyncindexupd", "async", "index", "updat"], "B_title": "AsyncIndexUpdate may resurrect nodes", "B_clean_title": ["asyncindexupd", "async", "index", "updat", "may", "resurrect", "node"]},
{"A_title": "Incorrect boundry matching for MockTableOperations.deleteRowsThe api for deleteRows specifies: Delete rows between (start end but the current implementation for MockTableOperations.deleteRows is implemented as (start end)  Here is the failing test case  code:java public class TestDelete    private static final String INSTANCE = mock;   private static final String TABLE = foo;   private static final String USER = user;   private static final String PASS = password;   private static final Authorizations AUTHS = new Authorizations();    @Test   public void testDelete() throws TableNotFoundException AccumuloException       AccumuloSecurityException TableExistsException       MockInstance mockAcc = new MockInstance(INSTANCE);     Connector conn = mockAcc.getConnector(USER new PasswordToken(PASS));     conn.tableOperations().create(TABLE);     conn.securityOperations().grantTablePermission(USER TABLE TablePermission.READ);     conn.securityOperations().grantTablePermission(USER TABLE TablePermission.WRITE);      Mutation mut = new Mutation(2);     mut.put(colfam colqual value);     BatchWriter writer = conn.createBatchWriter(TABLE new BatchWriterConfig());     writer.addMutation(mut);      Scanner scan = conn.createScanner(TABLE AUTHS);     scan.setRange(new Range(2 2));      assertEquals(1 countRecords(scan));          // this should delete (12      conn.tableOperations().deleteRows(TABLE new Text(1) new Text(2));      scan = conn.createScanner(TABLE AUTHS);     scan.setRange(new Range(2 2));          // this will fail if row 2 exists     assertEquals(0 countRecords(scan));       private int countRecords(Scanner scan)      int cnt = 0;     for (Entry<Key Value> entry : scan)        cnt++;          scan.close();     return cnt;     code", "A_clean_title": ["incorrect", "boundri", "match", "mocktableoper", "deleterowsth", "mock", "tabl", "oper", "delet", "row", "api", "deleterow", "delet", "row", "specifi", "delet", "row", "between", "start", "end", "but", "current", "implement", "mocktableoper", "deleterow", "mock", "tabl", "oper", "delet", "row", "implement", "as", "start", "end", "here", "fail", "test", "case", "code", "java", "public", "class", "testdelet", "test", "delet", "privat", "static", "final", "string", "instanc", "mock", "privat", "static", "final", "string", "tabl", "foo", "privat", "static", "final", "string", "user", "user", "privat", "static", "final", "string", "pass", "password", "privat", "static", "final", "author", "auth", "new", "author", "test", "public", "void", "testdelet", "test", "delet", "throw", "tablenotfoundexcept", "tabl", "not", "found", "except", "accumuloexcept", "accumulo", "except", "accumulosecurityexcept", "accumulo", "secur", "except", "tableexistsexcept", "tabl", "exist", "except", "mockinst", "mock", "instanc", "mockacc", "mock", "acc", "new", "mockinst", "mock", "instanc", "instanc", "connector", "conn", "mockacc", "getconnector", "mock", "acc", "get", "connector", "user", "new", "passwordtoken", "password", "token", "pass", "conn", "tableoper", "tabl", "oper", "creat", "tabl", "conn", "securityoper", "secur", "oper", "granttablepermiss", "grant", "tabl", "permiss", "user", "tabl", "tablepermiss", "read", "tabl", "permiss", "conn", "securityoper", "secur", "oper", "granttablepermiss", "grant", "tabl", "permiss", "user", "tabl", "tablepermiss", "write", "tabl", "permiss", "mutat", "mut", "new", "mutat", "mut", "put", "colfam", "colqual", "valu", "batchwrit", "batch", "writer", "writer", "conn", "createbatchwrit", "creat", "batch", "writer", "tabl", "new", "batchwriterconfig", "batch", "writer", "config", "writer", "addmut", "add", "mutat", "mut", "scanner", "scan", "conn", "createscann", "creat", "scanner", "tabl", "auth", "scan", "setrang", "set", "rang", "new", "rang", "assertequ", "assert", "equal", "countrecord", "count", "record", "scan", "thi", "delet", "12", "conn", "tableoper", "tabl", "oper", "deleterow", "delet", "row", "tabl", "new", "text", "new", "text", "scan", "conn", "createscann", "creat", "scanner", "tabl", "auth", "scan", "setrang", "set", "rang", "new", "rang", "thi", "will", "fail", "row", "exist", "assertequ", "assert", "equal", "countrecord", "count", "record", "scan", "privat", "int", "countrecord", "count", "record", "scanner", "scan", "int", "cnt", "entri", "key", "valu", "entri", "scan", "cnt++", "scan", "close", "return", "cnt", "code"], "B_title": "Fix match boundaries for MockTableOperations.deleteRows to be consistent with actual accumulo instance", "B_clean_title": ["fix", "match", "boundari", "mocktableoper", "deleterow", "mock", "tabl", "oper", "delet", "row", "consist", "actual", "accumulo", "instanc"]},
{"A_title": "Cannot see version with --versionNone", "A_clean_title": ["not", "see", "version", "versionnon", "version", "none"], "B_title": "fix a bug in open-source args parsing. Fixes issue 319.", "B_clean_title": ["fix", "bug", "open", "sourc", "arg", "pars", "fix", "issu", "319"]},
{"A_title": "ArrayUtils.addAll(T array1 T... array2) does not handle mixed types very wellArrayUtils.addAll(T array1 T... array2) does not handle mixed array types very well. The stack trace for  Number st = ArrayUtils.addAll(new Integer 1  new Long 2L ); starts: java.lang.ArrayStoreException at java.lang.System.arraycopy(Native Method) at org.apache.commons.lang3.ArrayUtils.addAll(ArrayUtils.java:2962) which is not all that obvious. It would be a lot clearer if the method threw an IlegalArgumentException or similar.", "A_clean_title": ["arrayutil", "addal", "array", "util", "add", "all", "array1", "array2", "not", "handl", "mix", "type", "veri", "wellarrayutil", "addal", "well", "array", "util", "add", "all", "array1", "array2", "not", "handl", "mix", "array", "type", "veri", "well", "stack", "trace", "number", "st", "arrayutil", "addal", "array", "util", "add", "all", "new", "integ", "new", "long", "2l", "start", "java", "lang", "arraystoreexcept", "array", "store", "except", "at", "java", "lang", "system", "arraycopi", "nativ", "method", "at", "org", "apach", "common", "lang3", "arrayutil", "addal", "array", "util", "add", "all", "arrayutil", "java:2962", "array", "util", "which", "not", "all", "that", "obviou", "it", "would", "lot", "clearer", "method", "threw", "ilegalargumentexcept", "ileg", "argument", "except", "or", "similar"], "B_title": "- ArrayUtils.addAll(T array1 T... array2) does not handle mixed types very well Also remove unnecessary main() and suite() from test class", "B_clean_title": ["arrayutil", "addal", "array", "util", "add", "all", "array1", "array2", "not", "handl", "mix", "type", "veri", "well", "also", "remov", "unnecessari", "main", "suit", "test", "class"]},
{"A_title": "Problem with WICKET-4441 and RestartResponseAtInterceptPageExceptionWICKET-4441 introduced an issue when our app has an authorization strategy and user is logged out. If user tries to access a protected url/page RestartResponseAtInterceptPageException is handled by DefaultExceptionMapper and leads to exception page instead of redirecting user.", "A_clean_title": ["problem", "wicket", "4441", "restartresponseatinterceptpageexceptionwicket", "4441", "restart", "respons", "at", "intercept", "page", "except", "wicket", "introduc", "issu", "when", "our", "app", "ha", "author", "strategi", "user", "log", "out", "user", "tri", "access", "protect", "url", "page", "restartresponseatinterceptpageexcept", "restart", "respons", "at", "intercept", "page", "except", "handl", "by", "defaultexceptionmapp", "default", "except", "mapper", "lead", "except", "page", "instead", "redirect", "user"], "B_title": "Problem with WICKET-4441 and RestartResponseAtInterceptPageException", "B_clean_title": ["problem", "wicket", "4441", "restartresponseatinterceptpageexcept", "restart", "respons", "at", "intercept", "page", "except"]},
{"A_title": "Localization messages stops working with validators since 1.4-rc2With the previous 1.3.6 and 1.4-rc1 releases I was capable to restrict a localization message for a validation to only one wicket id e.g. :  in foobar.java RequiredTextField nameTF = new RequiredTextField(name); nameTF.add(StringValidator.lengthBetween(2 255)); nameTF.add(new PatternValidator(^|:*));  and in foobar.properties name.Required=some text name.StringValidator.range=some other text name.PatternValidator=some other text again  So like this I could have to create an another RequiredTextField named password and attach to it a different localization message (for example password.Required=blabla).  But somehow with the 1.4-rc2-5 it looks like that this function is broken it only recognizes the localization text when I remove the name. prefix from my property.", "A_clean_title": ["local", "messag", "stop", "work", "valid", "sinc", "rc2with", "previou", "rc1", "releas", "wa", "capabl", "restrict", "local", "messag", "valid", "onli", "one", "wicket", "id", "foobar", "java", "requiredtextfield", "requir", "text", "field", "nametf", "name", "tf", "new", "requiredtextfield", "requir", "text", "field", "name", "nametf", "add", "name", "tf", "stringvalid", "lengthbetween", "string", "valid", "length", "between", "255", "nametf", "add", "name", "tf", "new", "patternvalid", "pattern", "valid", "foobar", "properti", "name", "required=som", "text", "name", "stringvalid", "range=som", "string", "valid", "other", "text", "name", "patternvalidator=som", "pattern", "validator=som", "other", "text", "again", "so", "like", "thi", "could", "have", "creat", "anoth", "requiredtextfield", "requir", "text", "field", "name", "password", "attach", "it", "differ", "local", "messag", "exampl", "password", "required=blabla", "but", "somehow", "rc2", "it", "look", "like", "that", "thi", "function", "broken", "it", "onli", "recogn", "local", "text", "when", "remov", "name", "prefix", "my", "properti"], "B_title": "Localization messages stops working with validators since 1.4-rc2 Issue: WICKET-2350", "B_clean_title": ["local", "messag", "stop", "work", "valid", "sinc", "rc2", "issu", "wicket", "2350"]},
{"A_title": "BitsStreamGenerator#nextBytes(byte) is wrongSequential calls to the BitsStreamGenerator#nextBytes(byte) must generate the same sequence of bytes no matter by chunks of which size it was divided. This is also how java.util.Random#nextBytes(byte) works.  When nextBytes(byte) is called with a bytes array of length multiple of 4 it makes one unneeded call to next(int) method. This is wrong and produces an inconsistent behavior of classes like MersenneTwister.  I made a new implementation of the BitsStreamGenerator#nextBytes(byte) see attached code.", "A_clean_title": ["bitsstreamgener", "bit", "stream", "gener", "nextbyt", "next", "byte", "byte", "wrongsequenti", "wrong", "sequenti", "call", "bitsstreamgener", "bit", "stream", "gener", "nextbyt", "next", "byte", "byte", "must", "gener", "same", "sequenc", "byte", "no", "matter", "by", "chunk", "which", "size", "it", "wa", "divid", "thi", "also", "how", "java", "util", "random", "nextbyt", "next", "byte", "byte", "work", "when", "nextbyt", "next", "byte", "byte", "call", "byte", "array", "length", "multipl", "it", "make", "one", "unneed", "call", "next", "int", "method", "thi", "wrong", "produc", "inconsist", "behavior", "class", "like", "mersennetwist", "mersenn", "twister", "made", "new", "implement", "bitsstreamgener", "bit", "stream", "gener", "nextbyt", "next", "byte", "byte", "see", "attach", "code"], "B_title": "", "B_clean_title": []},
{"A_title": "Special functions not very accurateThe Gamma and Beta functions return values in double precision but the default epsilon is set to 10e-9. I think that the default should be set to the highest possible accuracy as this is what Id expect to be returned by a double precision routine. Note that the erf function already uses a call to Gamma.regularizedGammaP with an epsilon of 1.0e-15.", "A_clean_title": ["special", "function", "not", "veri", "accurateth", "accur", "gamma", "beta", "function", "return", "valu", "doubl", "precis", "but", "default", "epsilon", "set", "10e", "think", "that", "default", "set", "highest", "possibl", "accuraci", "as", "thi", "what", "id", "expect", "return", "by", "doubl", "precis", "routin", "note", "that", "erf", "function", "alreadi", "use", "call", "gamma", "regularizedgammap", "regular", "gamma", "epsilon", "15", "0e"], "B_title": "Increased default epsilon for Gamma Beta function evaluation. JIRA: MATH-166 Reported and patched by Lukas Theussl", "B_clean_title": ["increas", "default", "epsilon", "gamma", "beta", "function", "evalu", "jira", "math", "166", "report", "patch", "by", "luka", "theussl"]},
{"A_title": "FileMonitoring function throws NPE when location is emptyStreamExecutionEnvironment.readFileStream() does not handle a missing location properly. I would suggest to log that the location is empty and continue running the job.  A test covering the correct behavior is also needed.", "A_clean_title": ["filemonitor", "file", "monitor", "function", "throw", "npe", "when", "locat", "emptystreamexecutionenviron", "readfilestream", "empti", "stream", "execut", "environ", "read", "file", "stream", "not", "handl", "miss", "locat", "properli", "would", "suggest", "log", "that", "locat", "empti", "continu", "run", "job", "test", "cover", "correct", "behavior", "also", "need"], "B_title": "streaming FileMonitoring function logs on empty location", "B_clean_title": ["stream", "filemonitor", "file", "monitor", "function", "log", "empti", "locat"]},
{"A_title": "wrong result in eigen decompositionSome results computed by EigenDecompositionImpl are wrong. The following case computed by Fortran Lapack fails with version 2.0      public void testMathpbx02()           double mainTridiagonal =            7484.860960227216 18405.28129035345 13855.225609560746          10016.708722343366 559.8117399576674 6750.190788301587              71.21428769782159         ;         double secondaryTridiagonal =           -4175.0885704763661975.79558582419945193.178422374075            1995.28665916917975.34535882933804-234.0808002076056         ;          // the reference values have been computed using routine DSTEMR         // from the fortran library LAPACK version 3.2.1         double refEigenValues =          20654.74489030697441216828.208208485466457         6893.1559126349948206757.083016675340332         5887.79988568855878864.309089923240379         57.992628792736340         ;         RealVector refEigenVectors =          new ArrayRealVector(new double -0.270356342026904 0.852811091326997 0.399639490702077 0.198794657813990 0.019739323307666 0.000106983022327 -0.000001216636321)         new ArrayRealVector(new double 0.179995273578326-0.4028078481530420.7018709935257340.5550582110148880.0680791488982360.000509139115227-0.000007112235617)         new ArrayRealVector(new double -0.399582721284727-0.056629954519333-0.5144064885228270.7111681645185800.2255480812763670.125943999652923-0.004321507456014)         new ArrayRealVector(new double 0.0585157215728210.0102001300577390.063516274916536-0.090696087449378-0.0171484204325970.991318870265707-0.034707338554096)         new ArrayRealVector(new double 0.8552059955375640.327134656629775-0.2653823970605480.2826907290267060.105736068025572-0.0091381266220390.000367751821196)         new ArrayRealVector(new double -0.002913069901144-0.0051775157771010.041906334478672-0.1093159184162580.4361923054567410.0263073156395350.891797507436344)         new ArrayRealVector(new double -0.005738311176435-0.0102076116703780.082662420517928-0.2157338860943680.861606487840411-0.025478530652759-0.451080697503958)         ;          // the following line triggers the exception         EigenDecomposition decomposition =             new EigenDecompositionImpl(mainTridiagonal secondaryTridiagonal MathUtils.SAFE_MIN);          double eigenValues = decomposition.getRealEigenvalues();         for (int i = 0; i < refEigenValues.length; ++i)              assertEquals(refEigenValuesi eigenValuesi 1.0e-3);             if (refEigenVectorsi.dotProduct(decomposition.getEigenvector(i)) < 0)                  assertEquals(0 refEigenVectorsi.add(decomposition.getEigenvector(i)).getNorm() 1.0e-5);              else                  assertEquals(0 refEigenVectorsi.subtract(decomposition.getEigenvector(i)).getNorm() 1.0e-5);", "A_clean_title": ["wrong", "result", "eigen", "decompositionsom", "decomposit", "some", "result", "comput", "by", "eigendecompositionimpl", "eigen", "decomposit", "impl", "are", "wrong", "follow", "case", "comput", "by", "fortran", "lapack", "fail", "version", "public", "void", "testmathpbx02", "test", "mathpbx02", "doubl", "maintridiagon", "main", "tridiagon", "7484", "860960227216", "18405", "28129035345", "13855", "225609560746", "10016", "708722343366", "559", "8117399576674", "6750", "190788301587", "71", "21428769782159", "doubl", "secondarytridiagon", "secondari", "tridiagon", "4175", "0885704763661975", "79558582419945193", "178422374075", "1995", "28665916917975", "34535882933804", "234", "0808002076056", "refer", "valu", "have", "been", "comput", "routin", "dstemr", "fortran", "librari", "lapack", "version", "doubl", "refeigenvalu", "ref", "eigen", "valu", "20654", "74489030697441216828", "208208485466457", "6893", "1559126349948206757", "083016675340332", "5887", "79988568855878864", "309089923240379", "57", "992628792736340", "realvector", "real", "vector", "refeigenvector", "ref", "eigen", "vector", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "270356342026904", "852811091326997", "399639490702077", "198794657813990", "019739323307666", "000106983022327", "000001216636321", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "179995273578326", "4028078481530420", "7018709935257340", "5550582110148880", "0680791488982360", "000509139115227", "000007112235617", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "399582721284727", "056629954519333", "5144064885228270", "7111681645185800", "2255480812763670", "125943999652923", "004321507456014", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "0585157215728210", "0102001300577390", "063516274916536", "090696087449378", "0171484204325970", "991318870265707", "034707338554096", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "8552059955375640", "327134656629775", "2653823970605480", "2826907290267060", "105736068025572", "0091381266220390", "000367751821196", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "002913069901144", "0051775157771010", "041906334478672", "1093159184162580", "4361923054567410", "0263073156395350", "891797507436344", "new", "arrayrealvector", "array", "real", "vector", "new", "doubl", "005738311176435", "0102076116703780", "082662420517928", "2157338860943680", "861606487840411", "025478530652759", "451080697503958", "follow", "line", "trigger", "except", "eigendecomposit", "eigen", "decomposit", "decomposit", "new", "eigendecompositionimpl", "eigen", "decomposit", "impl", "maintridiagon", "main", "tridiagon", "secondarytridiagon", "secondari", "tridiagon", "mathutil", "math", "util", "safe", "min", "doubl", "eigenvalu", "eigen", "valu", "decomposit", "getrealeigenvalu", "get", "real", "eigenvalu", "int", "refeigenvalu", "length", "ref", "eigen", "valu", "++i", "assertequ", "assert", "equal", "refeigenvaluesi", "ref", "eigen", "valuesi", "eigenvaluesi", "eigen", "valuesi", "0e", "refeigenvectorsi", "dotproduct", "ref", "eigen", "vectorsi", "dot", "product", "decomposit", "geteigenvector", "get", "eigenvector", "assertequ", "assert", "equal", "refeigenvectorsi", "add", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e", "assertequ", "assert", "equal", "refeigenvectorsi", "subtract", "ref", "eigen", "vectorsi", "decomposit", "geteigenvector", "get", "eigenvector", "getnorm", "get", "norm", "0e"], "B_title": "Fixed an index computation error in eigen decomposition. Once again kudos to Dimitri for debugging this. JIRA: MATH-318", "B_clean_title": ["fix", "index", "comput", "error", "eigen", "decomposit", "onc", "again", "kudo", "dimitri", "debug", "thi", "jira", "math", "318"]},
{"A_title": "CtTypeReferenceImpl#getSuperClass() fails in noClasspath modeThe method has the following implementation:   As you can see it doesnt check for noClasspath and thus may fail when calling  getActualClass() .", "A_clean_title": ["cttypereferenceimpl", "ct", "type", "refer", "impl", "getsuperclass", "get", "super", "class", "fail", "noclasspath", "no", "classpath", "modeth", "mode", "method", "ha", "follow", "implement", "as", "you", "see", "it", "doesnt", "check", "noclasspath", "no", "classpath", "thu", "may", "fail", "when", "call", "getactualclass", "get", "actual", "class"], "B_title": "fix: getSuperClass does not throw exception in noClassPath mode. (#1128)  Fix #1125", "B_clean_title": ["fix", "getsuperclass", "get", "super", "class", "not", "throw", "except", "noclasspath", "no", "class", "path", "mode", "1128", "fix", "1125"]},
{"A_title": "ParentNotInitializedException when processing comments with -cI am aware that comments can be processed using the command -c  since Spoon 5.2.0. Thanks for this feature.  When using Spoon to process comments in either code snippet below ParentNotInitializedException will be thrown. An empty processor can be used to reproduce this issue. This happens in both Spoon 5.2 and 5.4.  public class Comment_1      public class Comment2      Details of the exception are as follows.  spoon.reflect.declaration.ParentNotInitializedException: parent not initialized for class spoon.support.reflect.code.CtCommentImpl (/home/jifeng/workspace/Temp4/src/main/java/example/Comment1.java:17)  at spoon.support.reflect.declaration.CtElementImpl.getParent(CtElementImpl.java:284) at spoon.support.compiler.jdt.JDTCommentBuilder.insertCommentInAST(JDTCommentBuilder.java:377) at spoon.support.compiler.jdt.JDTCommentBuilder.buildComment(JDTCommentBuilder.java:131) at spoon.support.compiler.jdt.JDTCommentBuilder.build(JDTCommentBuilder.java:96) at spoon.support.compiler.jdt.JDTBasedSpoonCompiler.buildSources(JDTBasedSpoonCompiler.java:387) at spoon.support.compiler.jdt.JDTBasedSpoonCompiler.build(JDTBasedSpoonCompiler.java:116) at spoon.support.compiler.jdt.JDTBasedSpoonCompiler.build(JDTBasedSpoonCompiler.java:99) at spoon.Launcher.buildModel(Launcher.java:712) at spoon.Launcher.run(Launcher.java:663) at spoon.Launcher.run(Launcher.java:106) at spoon.Launcher.main(Launcher.java:99)", "A_clean_title": ["parentnotinitializedexcept", "parent", "not", "initi", "except", "when", "process", "comment", "ci", "am", "awar", "that", "comment", "process", "command", "sinc", "spoon", "thank", "thi", "featur", "when", "spoon", "process", "comment", "either", "code", "snippet", "below", "parentnotinitializedexcept", "parent", "not", "initi", "except", "will", "thrown", "empti", "processor", "use", "reproduc", "thi", "issu", "thi", "happen", "both", "spoon", "public", "class", "comment", "public", "class", "comment2", "detail", "except", "are", "as", "follow", "spoon", "reflect", "declar", "parentnotinitializedexcept", "parent", "not", "initi", "except", "parent", "not", "initi", "class", "spoon", "support", "reflect", "code", "ctcommentimpl", "ct", "comment", "impl", "java:17", "home", "jifeng", "workspac", "temp4", "src", "main", "java", "exampl", "comment1", "at", "spoon", "support", "reflect", "declar", "ctelementimpl", "getpar", "ct", "element", "impl", "get", "parent", "ctelementimpl", "java:284", "ct", "element", "impl", "at", "spoon", "support", "compil", "jdt", "jdtcommentbuild", "insertcommentinast", "jdt", "comment", "builder", "insert", "comment", "ast", "jdtcommentbuild", "java:377", "jdt", "comment", "builder", "at", "spoon", "support", "compil", "jdt", "jdtcommentbuild", "buildcom", "jdt", "comment", "builder", "build", "comment", "jdtcommentbuild", "java:131", "jdt", "comment", "builder", "at", "spoon", "support", "compil", "jdt", "jdtcommentbuild", "build", "jdt", "comment", "builder", "jdtcommentbuild", "java:96", "jdt", "comment", "builder", "at", "spoon", "support", "compil", "jdt", "jdtbasedspooncompil", "buildsourc", "jdt", "base", "spoon", "compil", "build", "sourc", "jdtbasedspooncompil", "java:387", "jdt", "base", "spoon", "compil", "at", "spoon", "support", "compil", "jdt", "jdtbasedspooncompil", "build", "jdt", "base", "spoon", "compil", "jdtbasedspooncompil", "java:116", "jdt", "base", "spoon", "compil", "at", "spoon", "support", "compil", "jdt", "jdtbasedspooncompil", "build", "jdt", "base", "spoon", "compil", "jdtbasedspooncompil", "java:99", "jdt", "base", "spoon", "compil", "at", "spoon", "launcher", "buildmodel", "build", "model", "launcher", "java:712", "at", "spoon", "launcher", "run", "launcher", "java:663", "at", "spoon", "launcher", "run", "launcher", "java:106", "at", "spoon", "launcher", "main", "launcher", "java:99"], "B_title": "fix(comment): fix bug in comments in array initialization (#1088)  Closes #1073", "B_clean_title": ["fix", "comment", "fix", "bug", "comment", "array", "initi", "1088", "close", "1073"]},
{"A_title": "MoveDetector does not detect moved nodes that have been moved in an earlier commit alreadyNone", "A_clean_title": ["movedetector", "move", "detector", "not", "detect", "move", "node", "that", "have", "been", "move", "earlier", "commit", "alreadynon", "alreadi", "none"], "B_title": "MoveDetector does not detect moved nodes that have been moved in an earlier commit already Properly annotate moved node in the face of moves from earlier commits", "B_clean_title": ["movedetector", "move", "detector", "not", "detect", "move", "node", "that", "have", "been", "move", "earlier", "commit", "alreadi", "properli", "annot", "move", "node", "face", "move", "earlier", "commit"]},
{"A_title": "goog.addSingletonGetter prevents unused class removalNone", "A_clean_title": ["goog", "addsingletongett", "add", "singleton", "getter", "prevent", "unus", "class", "removalnon", "remov", "none"], "B_title": "Remove addSingletonGetter stragglers. Fixes issue 668", "B_clean_title": ["remov", "addsingletongett", "add", "singleton", "getter", "straggler", "fix", "issu", "668"]},
{"A_title": "ResourceUtils.getLocaleFromFilename cant handle minimized resources wellI think the ResourceUtils.getLocaleFromFilename(String path) has the order of locale and minimization wrong: It currently parses: File.min_Lang_Coun_Var.ext while the typical convention is File_Lang_Coun_Var.min.ext Surely considering the ResourceUtils.getMinifiedName() method which does work according to convention.", "A_clean_title": ["resourceutil", "getlocalefromfilenam", "resourc", "util", "get", "local", "filenam", "cant", "handl", "minim", "resourc", "welli", "well", "think", "resourceutil", "getlocalefromfilenam", "resourc", "util", "get", "local", "filenam", "string", "path", "ha", "order", "local", "minim", "wrong", "it", "current", "pars", "file", "ext", "min", "lang", "coun", "var", "while", "typic", "convent", "min", "ext", "file", "lang", "coun", "var", "sure", "consid", "resourceutil", "getminifiednam", "resourc", "util", "get", "minifi", "name", "method", "which", "work", "accord", "convent"], "B_title": "Fixed locale from resource filename", "B_clean_title": ["fix", "local", "resourc", "filenam"]},
{"A_title": "WebSocketRequestHandler is not set as a scheduled and thus RequestCycle#find(AjaxRequestTarget.class) doesnt workAs discussed at https://groups.google.com/d/topic/wicket-jquery-ui/fw6TdyO5o18/discussion AbstractWebSocketProcessor doesnt schedules the WebSocketRequestHandler in the request cycle and thus it is not reachable for user code via RequestCycle#find(Class) API.  Additionally the configured application RequestCycle listeners are not notified.", "A_clean_title": ["websocketrequesthandl", "web", "socket", "request", "handler", "not", "set", "as", "schedul", "thu", "requestcycl", "request", "cycl", "find", "ajaxrequesttarget", "class", "ajax", "request", "target", "doesnt", "worka", "work", "as", "discuss", "at", "http", "jqueri", "googl", "ui", "fw6tdyo5o18", "discuss", "group", "com", "topic", "wicket", "fw6tdi", "o5o18", "abstractwebsocketprocessor", "abstract", "web", "socket", "processor", "doesnt", "schedul", "websocketrequesthandl", "web", "socket", "request", "handler", "request", "cycl", "thu", "it", "not", "reachabl", "user", "code", "via", "requestcycl", "request", "cycl", "find", "class", "api", "addit", "configur", "applic", "requestcycl", "request", "cycl", "listen", "are", "not", "notifi"], "B_title": "WebSocketRequestHandler is not set as a scheduled and thus RequestCycle#find(AjaxRequestTarget.class) doesnt work", "B_clean_title": ["websocketrequesthandl", "web", "socket", "request", "handler", "not", "set", "as", "schedul", "thu", "requestcycl", "request", "cycl", "find", "ajaxrequesttarget", "class", "ajax", "request", "target", "doesnt", "work"]},
{"A_title": "ServletWebResponse#encodeUrl() makes absolute Urls relativeWhen an absolute (full) URL is passed to ServletWebResponse#encodeUrl() it will be returned relative if the container encodes a session ID.", "A_clean_title": ["servletwebrespons", "servlet", "web", "respons", "encodeurl", "encod", "url", "make", "absolut", "url", "relativewhen", "rel", "when", "absolut", "full", "url", "pass", "servletwebrespons", "servlet", "web", "respons", "encodeurl", "encod", "url", "it", "will", "return", "rel", "contain", "encod", "session", "id"], "B_title": "absolute URLs stay absolute after encoding", "B_clean_title": ["absolut", "url", "ur", "ls", "stay", "absolut", "after", "encod"]},
{"A_title": "DataStoreBlobStore does not take into maxLastModifiedTime when fetching all chunksCurrently the DataStoreBlobStore has a pending TODO  code  @Override     public Iterator<String> getAllChunkIds(long maxLastModifiedTime) throws Exception          //TODO Ignores the maxLastModifiedTime currently.         return Iterators.transform(delegate.getAllIdentifiers() new Function<DataIdentifier String>()              @Nullable             @Override             public String apply(@Nullable DataIdentifier input)                  return input.toString();                      );      code  Due to this it currently returns all blobId. This would issue when new binary gets created while a blob gc is running as such binaries might be considered orphan and deleted", "A_clean_title": ["datastoreblobstor", "data", "store", "blob", "store", "not", "take", "into", "maxlastmodifiedtim", "max", "last", "modifi", "time", "when", "fetch", "all", "chunkscurr", "chunk", "current", "datastoreblobstor", "data", "store", "blob", "store", "ha", "pend", "todo", "code", "overrid", "public", "iter", "string", "getallchunkid", "get", "all", "chunk", "id", "long", "maxlastmodifiedtim", "max", "last", "modifi", "time", "throw", "except", "todo", "ignor", "maxlastmodifiedtim", "max", "last", "modifi", "time", "current", "return", "iter", "transform", "deleg", "getallidentifi", "get", "all", "identifi", "new", "function", "dataidentifi", "data", "identifi", "string", "nullabl", "overrid", "public", "string", "appli", "nullabl", "dataidentifi", "data", "identifi", "input", "return", "input", "tostr", "string", "code", "due", "thi", "it", "current", "return", "all", "blobid", "blob", "id", "thi", "would", "issu", "when", "new", "binari", "get", "creat", "while", "blob", "gc", "run", "as", "such", "binari", "might", "consid", "orphan", "delet"], "B_title": "- DataStoreBlobStore does not take into maxLastModifiedTime when fetching all chunks", "B_clean_title": ["datastoreblobstor", "data", "store", "blob", "store", "not", "take", "into", "maxlastmodifiedtim", "max", "last", "modifi", "time", "when", "fetch", "all", "chunk"]},
{"A_title": "Failing HTTPS redirect to RequireHttps annotated pages with ONE_PASS_RENDER strategyActivated JS: Start the quickstart -> Press the submit buttons -> See the secured page with https!  Deactivates JS: (NoScript Firefox Plugin): Start the quickstart -> Press the submit buttons -> See the secured page BUT with HTTP!  There was no proper https redirect.  If I change the rendering strategy to REDIRECT_TO_BUFFER everything works fine but if I change the strategy to ONE_PASS_RENDER the https forwarding doest work anymore. But only if I deactivate all scripts...  Regards Dmitriy", "A_clean_title": ["fail", "http", "redirect", "requirehttp", "requir", "http", "annot", "page", "one", "pass", "render", "strategyactiv", "strategi", "activ", "js", "start", "quickstart", "press", "submit", "button", "see", "secur", "page", "http", "deactiv", "js", "noscript", "no", "script", "firefox", "plugin", "start", "quickstart", "press", "submit", "button", "see", "secur", "page", "but", "http", "there", "wa", "no", "proper", "http", "redirect", "chang", "render", "strategi", "redirect", "buffer", "everyth", "work", "fine", "but", "chang", "strategi", "one", "pass", "render", "http", "forward", "doest", "work", "anymor", "but", "onli", "deactiv", "all", "script", "regard", "dmitriy"], "B_title": "Failing HTTPS redirect to RequireHttps annotated pages with ONE_PASS_RENDER strategy", "B_clean_title": ["fail", "http", "redirect", "requirehttp", "requir", "http", "annot", "page", "one", "pass", "render", "strategi"]},
{"A_title": "BSPTree class and recovery of a Euclidean 3D BRepNew to the work here. Thanks for your efforts on this code. I create a BSPTree from a BoundaryRep (Brep) my test Brep is a cube as represented by a float array containing 8 3D points in(xyz) order and an array of indices (12 triplets for the 12 faces of the cube). I construct a BSPMesh() as shown in the code below. I can construct the PolyhedronsSet() but have problems extracting the faces from the BSPTree to reconstruct the BRep. The attached code (BSPMesh2.java) shows that a small change to 1 of the vertex positions causes/corrects the problem. Any ideas?", "A_clean_title": ["bsptree", "bsp", "tree", "class", "recoveri", "euclidean", "3d", "brepnew", "rep", "new", "work", "here", "thank", "your", "effort", "thi", "code", "creat", "bsptree", "bsp", "tree", "boundaryrep", "boundari", "rep", "brep", "my", "test", "brep", "cube", "as", "repres", "by", "float", "array", "contain", "3d", "point", "xyz", "order", "array", "indic", "12", "triplet", "12", "face", "cube", "construct", "bspmesh", "bsp", "mesh", "as", "shown", "code", "below", "construct", "polyhedronsset", "polyhedron", "set", "but", "have", "problem", "extract", "face", "bsptree", "bsp", "tree", "reconstruct", "brep", "rep", "attach", "code", "bspmesh2", "java", "bsp", "mesh2", "show", "that", "small", "chang", "vertex", "posit", "caus", "correct", "problem", "ani", "idea"], "B_title": "Fixed a wrong assumption on BSP tree attributes.", "B_clean_title": ["fix", "wrong", "assumpt", "bsp", "tree", "attribut"]},
{"A_title": "AjaxRequestAttributes extra parameters arent properly handled in getCallbackFunction()extra parameters of an Ajax behaviour can be accessed by getRequest().getRequestParameters().getParameterValue(key)  but if one uses getCallbackFunction() of an AbstractDefaultAjaxBehavior these parameters get screwed and can no longer be accessed in the same manner.   the problem seems to be the merge in attrs.ep = Wicket.merge(attrs.ep params);", "A_clean_title": ["ajaxrequestattribut", "ajax", "request", "attribut", "extra", "paramet", "arent", "properli", "handl", "getcallbackfunct", "get", "callback", "function", "extra", "paramet", "ajax", "behaviour", "access", "by", "getrequest", "get", "request", "getrequestparamet", "get", "request", "paramet", "getparametervalu", "get", "paramet", "valu", "key", "but", "one", "use", "getcallbackfunct", "get", "callback", "function", "abstractdefaultajaxbehavior", "abstract", "default", "ajax", "behavior", "these", "paramet", "get", "screw", "no", "longer", "access", "same", "manner", "problem", "seem", "merg", "attr", "ep", "wicket", "merg", "attr", "ep", "param"], "B_title": "AjaxRequestAttributes extra parameters arent properly handled in getCallbackFunction()", "B_clean_title": ["ajaxrequestattribut", "ajax", "request", "attribut", "extra", "paramet", "arent", "properli", "handl", "getcallbackfunct", "get", "callback", "function"]},
{"A_title": "IndexOutOfBoundsException when PropertyResolver is using an invalid list indexWhen using  PropertyResolver.getValue(myList1 myBean)  the PropertyResolver ListGetSet.getValue() (line 762) unconditionally does: return ((List)object).get(index); which throws an   java.lang.IndexOutOfBoundsException: Index: 1 Size: 1  if the backing list contains only one element (at index 0). Shouldnt the implementation rather return null like with every other property not found? Like when using bla.bli.blo as a lookup string and there is no bla field and no getBla() method?  So this method should rather be:  org.apache.wicket.util.lang.PropertyResolver ListGetSet.getValue():  /**  * @see org.apache.wicket.util.lang.PropertyResolver.IGetAndSet#getValue(java.lang.Object)  */ public Object getValue(Object object)  List list = (List) object; if (index >= list.size())  return null;  return list.get(index);", "A_clean_title": ["indexoutofboundsexcept", "index", "out", "bound", "except", "when", "propertyresolv", "properti", "resolv", "invalid", "list", "indexwhen", "index", "when", "propertyresolv", "getvalu", "properti", "resolv", "get", "valu", "mylist1", "my", "list1", "mybean", "my", "bean", "propertyresolv", "properti", "resolv", "listgetset", "getvalu", "list", "get", "set", "get", "valu", "line", "762", "uncondit", "return", "list", "object", "get", "index", "which", "throw", "java", "lang", "indexoutofboundsexcept", "index", "out", "bound", "except", "index", "size", "back", "list", "contain", "onli", "one", "element", "at", "index", "shouldnt", "implement", "rather", "return", "null", "like", "everi", "other", "properti", "not", "found", "like", "when", "bla", "bli", "blo", "as", "lookup", "string", "there", "no", "bla", "field", "no", "getbla", "get", "bla", "method", "so", "thi", "method", "rather", "org", "apach", "wicket", "util", "lang", "propertyresolv", "properti", "resolv", "listgetset", "getvalu", "list", "get", "set", "get", "valu", "see", "org", "apach", "wicket", "util", "lang", "propertyresolv", "igetandset", "properti", "resolv", "get", "set", "getvalu", "get", "valu", "java", "lang", "object", "public", "object", "getvalu", "get", "valu", "object", "object", "list", "list", "list", "object", "index", "list", "size", "return", "null", "return", "list", "get", "index"], "B_title": "IndexOutOfBoundsException when PropertyResolver is using an invalid list index PropertyModel does not support index only property (0) Issue: WICKET-23372354", "B_clean_title": ["indexoutofboundsexcept", "index", "out", "bound", "except", "when", "propertyresolv", "properti", "resolv", "invalid", "list", "index", "propertymodel", "properti", "model", "not", "support", "index", "onli", "properti", "issu", "wicket", "23372354"]},
{"A_title": "Item names starting with X cause RepositoryExceptionThe exception is RepositoryException: Invalid name or path: 0 foo  E.g. for an item named 0 foo.  I guess oak-jcr tries to interpret it as a name in expanded form but does not find a namespace uri for 0. IIRC these names are valid in Jackrabbit 2.x.", "A_clean_title": ["item", "name", "start", "caus", "repositoryexceptionth", "repositori", "except", "except", "repositoryexcept", "repositori", "except", "invalid", "name", "or", "path", "foo", "item", "name", "foo", "guess", "oak", "jcr", "tri", "interpret", "it", "as", "name", "expand", "form", "but", "not", "find", "namespac", "uri", "iirc", "these", "name", "are", "valid", "jackrabbit"], "B_title": "Item names starting with X cause RepositoryException", "B_clean_title": ["item", "name", "start", "caus", "repositoryexcept", "repositori", "except"]},
{"A_title": "fix proposal for #114None", "A_clean_title": ["fix", "propos", "114none"], "B_title": "Fixed issue 138 again hopefully this time forever :)", "B_clean_title": ["fix", "issu", "138", "again", "hope", "thi", "time", "forev"]},
{"A_title": "FileResourceStream returns unknown content typeSee http://apache-wicket.1842946.n4.nabble.com/PackageResourceReference-and-Doctype-in-Markup-file-tp3889467p3889587.html  The response for FileResourceStreams returns an unknown content type for css- and image-files. Correct content types should be text/css and image/png (see also attached quickstart).", "A_clean_title": ["fileresourcestream", "file", "resourc", "stream", "return", "unknown", "content", "typese", "type", "see", "http", "doctyp", "markup", "file", "apach", "wicket", "1842946", "n4", "nabbl", "tp3889467p3889587", "html", "com", "packageresourcerefer", "packag", "resourc", "refer", "respons", "fileresourcestream", "file", "resourc", "stream", "return", "unknown", "content", "type", "css", "imag", "file", "correct", "content", "type", "text", "css", "imag", "png", "see", "also", "attach", "quickstart"], "B_title": "FileResourceStream returns unknown content type", "B_clean_title": ["fileresourcestream", "file", "resourc", "stream", "return", "unknown", "content", "type"]},
{"A_title": "fieldsGrouping for multiple output streams failsIf a Spout or Bolt declares multiple output streams and another Bolt connects to one of those streams via fieldsGrouping  the call to FlinkTopologyBuilder.createTopology() fails with the following exception:  noformat org.apache.flink.api.common.InvalidProgramException: Specifying keys via field positions is only valid for tuple data types. Type: PojoType<org.apache.flink.stormcompatibility.util.SplitStreamType fields = streamId: String value: GenericType<java.lang.Object>> at org.apache.flink.api.java.operators.Keys ExpressionKeys.<init>(Keys.java:209) at org.apache.flink.api.java.operators.Keys ExpressionKeys.<init>(Keys.java:203) at org.apache.flink.streaming.api.datastream.DataStream.groupBy(DataStream.java:285) at org.apache.flink.stormcompatibility.api.FlinkTopologyBuilder.createTopology(FlinkTopologyBuilder.java:200) at org.apache.flink.stormcompatibility.api.FlinkTopologyBuilderTest.testFieldsGroupingOnMultipleBoltOutputStreams(FlinkTopologyBuilderTest.java:73) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.junit.runners.model.FrameworkMethod 1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) at org.junit.runners.ParentRunner 3.run(ParentRunner.java:238) at org.junit.runners.ParentRunner 1.schedule(ParentRunner.java:63) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) at org.junit.runners.ParentRunner.access 000(ParentRunner.java:53) at org.junit.runners.ParentRunner 2.evaluate(ParentRunner.java:229) at org.junit.runners.ParentRunner.run(ParentRunner.java:309) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197) noformat  Fix: either introduce a mapper that flattens the SplitStreamType in to regular tuple type that is nested inside or provide a custom KeySelector.", "A_clean_title": ["fieldsgroup", "field", "group", "multipl", "output", "stream", "failsif", "fail", "spout", "or", "bolt", "declar", "multipl", "output", "stream", "anoth", "bolt", "connect", "one", "those", "stream", "via", "fieldsgroup", "field", "group", "call", "flinktopologybuild", "createtopolog", "flink", "topolog", "builder", "creat", "topolog", "fail", "follow", "except", "noformat", "org", "apach", "flink", "api", "common", "invalidprogramexcept", "invalid", "program", "except", "specifi", "key", "via", "field", "posit", "onli", "valid", "tupl", "data", "type", "type", "pojotyp", "pojo", "type", "org", "apach", "flink", "stormcompat", "util", "splitstreamtyp", "split", "stream", "type", "field", "streamid", "stream", "id", "string", "valu", "generictyp", "gener", "type", "java", "lang", "object", "at", "org", "apach", "flink", "api", "java", "oper", "key", "expressionkey", "express", "key", "init", "key", "java:209", "at", "org", "apach", "flink", "api", "java", "oper", "key", "expressionkey", "express", "key", "init", "key", "java:203", "at", "org", "apach", "flink", "stream", "api", "datastream", "datastream", "groupbi", "data", "stream", "group", "by", "datastream", "java:285", "data", "stream", "at", "org", "apach", "flink", "stormcompat", "api", "flinktopologybuild", "createtopolog", "flink", "topolog", "builder", "creat", "topolog", "flinktopologybuild", "java:200", "flink", "topolog", "builder", "at", "org", "apach", "flink", "stormcompat", "api", "flinktopologybuildertest", "testfieldsgroupingonmultipleboltoutputstream", "flink", "topolog", "builder", "test", "test", "field", "group", "multipl", "bolt", "output", "stream", "flinktopologybuildertest", "java:73", "flink", "topolog", "builder", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:57", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:43", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:606", "at", "org", "junit", "runner", "model", "frameworkmethod", "framework", "method", "runreflectivecal", "run", "reflect", "call", "frameworkmethod", "java:47", "framework", "method", "at", "org", "junit", "intern", "runner", "model", "reflectivecal", "run", "reflect", "callabl", "reflectivecal", "java:12", "reflect", "callabl", "at", "org", "junit", "runner", "model", "frameworkmethod", "invokeexplos", "framework", "method", "invok", "explos", "frameworkmethod", "java:44", "framework", "method", "at", "org", "junit", "intern", "runner", "statement", "invokemethod", "evalu", "invok", "method", "invokemethod", "java:17", "invok", "method", "at", "org", "junit", "runner", "parentrunn", "runleaf", "parent", "runner", "run", "leaf", "parentrunn", "java:271", "parent", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:70", "block", "unit4class", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:50", "block", "unit4class", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "run", "parentrunn", "java:238", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "schedul", "parentrunn", "java:63", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "runchildren", "parent", "runner", "run", "children", "parentrunn", "java:236", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "access", "parent", "runner", "000", "parentrunn", "java:53", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "evalu", "parentrunn", "java:229", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "run", "parent", "runner", "parentrunn", "java:309", "parent", "runner", "at", "org", "eclips", "jdt", "intern", "junit4", "runner", "junit4testrefer", "run", "unit4test", "refer", "junit4testrefer", "java:50", "unit4test", "refer", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "testexecut", "run", "test", "execut", "testexecut", "java:38", "test", "execut", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:467", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:683", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "run", "remot", "test", "runner", "remotetestrunn", "java:390", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "main", "remot", "test", "runner", "remotetestrunn", "java:197", "remot", "test", "runner", "noformat", "fix", "either", "introduc", "mapper", "that", "flatten", "splitstreamtyp", "split", "stream", "type", "regular", "tupl", "type", "that", "nest", "insid", "or", "provid", "custom", "keyselector", "key", "selector"], "B_title": "fieldsGrouping for multiple output streams fails  - added SplitStreamTypeKeySelector and JUnit tests", "B_clean_title": ["fieldsgroup", "field", "group", "multipl", "output", "stream", "fail", "ad", "splitstreamtypekeyselector", "split", "stream", "type", "key", "selector", "junit", "unit", "test"]},
{"A_title": "FastDateParser does not handle white-space properlyThe SimpleDateFormat Javadoc does not treat white-space specially however FastDateParser treats a single white-space as being any number of white-space characters. This means that FDP will parse dates that fail when parsed by SDP.", "A_clean_title": ["fastdatepars", "fast", "date", "parser", "not", "handl", "white", "space", "properlyth", "properli", "simpledateformat", "simpl", "date", "format", "javadoc", "not", "treat", "white", "space", "special", "howev", "fastdatepars", "fast", "date", "parser", "treat", "singl", "white", "space", "as", "be", "ani", "number", "white", "space", "charact", "thi", "mean", "that", "fdp", "will", "pars", "date", "that", "fail", "when", "pars", "by", "sdp"], "B_title": "FastDateParser does not handle white-space properly", "B_clean_title": ["fastdatepars", "fast", "date", "parser", "not", "handl", "white", "space", "properli"]},
{"A_title": "404 Error on Nested ModalWindows in IE7 and IE8When opening a ModalWindow inside a ModalWindow the inner ModalWindow generates a 404 error.  Both windows use a PageCreator for content.  To replicate you must use an actual IE 7 or IE 8 browser as this does not replicate using developer tools and setting the document and brower to IE 7.  The problem can be seen at http://www.wicket-library.com/wicket-examples/ajax/modal-window.  I will attach a Quickstart as well.", "A_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8when", "open", "modalwindow", "modal", "window", "insid", "modalwindow", "modal", "window", "inner", "modalwindow", "modal", "window", "gener", "404", "error", "both", "window", "use", "pagecr", "page", "creator", "content", "replic", "you", "must", "use", "actual", "ie", "or", "ie", "browser", "as", "thi", "not", "replic", "develop", "tool", "set", "document", "brower", "ie", "problem", "seen", "at", "http", "window", "wicket", "librari", "exampl", "ajax", "modal", "www", "com", "wicket", "will", "attach", "quickstart", "as", "well"], "B_title": "404 Error on Nested ModalWindows in IE7 and IE8", "B_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8"]},
{"A_title": "CtElementImpl.getMetadataKeys() throws NPEI get NPE when invoking method getMetadataKeys() on CtElement. Looking through source code it looks like metadata can be null. It should have null check and return null like getMetadata() method or return empty set.", "A_clean_title": ["ctelementimpl", "getmetadatakey", "ct", "element", "impl", "get", "metadata", "key", "throw", "npei", "get", "npe", "when", "invok", "method", "getmetadatakey", "get", "metadata", "key", "ctelement", "ct", "element", "look", "through", "sourc", "code", "it", "look", "like", "metadata", "null", "it", "have", "null", "check", "return", "null", "like", "getmetadata", "get", "metadata", "method", "or", "return", "empti", "set"], "B_title": "fix: fix NPE in CtElement#getMetadataKeys. Closes #1239 (#1240)", "B_clean_title": ["fix", "fix", "npe", "ctelement", "ct", "element", "getmetadatakey", "get", "metadata", "key", "close", "1239", "1240"]},
{"A_title": "compiler assumes that arguments can be shadowedNone", "A_clean_title": ["compil", "assum", "that", "argument", "shadowednon", "shadow", "none"], "B_title": "var arguments never shadows the built-in arguments array. Fixes issue 115.", "B_clean_title": ["var", "argument", "never", "shadow", "built", "argument", "array", "fix", "issu", "115"]},
{"A_title": "Null model for AttributeAppender should not render empty attributeI cant think of a reason this would be valid but passing in null model renders <span class=>Test</span>.  If previous and new attribute are both null the component should render cleanly like <span>Test</span>.", "A_clean_title": ["null", "model", "attributeappend", "attribut", "append", "not", "render", "empti", "attributei", "attribut", "cant", "think", "reason", "thi", "would", "valid", "but", "pass", "null", "model", "render", "span", "class=", "test", "span", "previou", "new", "attribut", "are", "both", "null", "compon", "render", "cleanli", "like", "span", "test", "span"], "B_title": "Null model for AttributeAppender should not render empty attribute", "B_clean_title": ["null", "model", "attributeappend", "attribut", "append", "not", "render", "empti", "attribut"]},
{"A_title": "ResizableDoubleArray does not work with double array of size 1When attempting to create a ResizableDoubleArray with an array of a single value (e.g. 4.0) the constructor creates an internal array with 16 entries that are all 0.0  Bug looks like it might be on line 414 of ResizableDoubleArray.java:          if (data != null && data.length > 1)", "A_clean_title": ["resizabledoublearray", "resiz", "doubl", "array", "not", "work", "doubl", "array", "size", "1when", "attempt", "creat", "resizabledoublearray", "resiz", "doubl", "array", "array", "singl", "valu", "constructor", "creat", "intern", "array", "16", "entri", "that", "are", "all", "bug", "look", "like", "it", "might", "line", "414", "resizabledoublearray", "java", "resiz", "doubl", "array", "data", "null", "data", "length"], "B_title": "Changed data size check to be positive length not > 1 to fix ResizableDoubleArray constructor failure on input array of length 1.", "B_clean_title": ["chang", "data", "size", "check", "posit", "length", "not", "fix", "resizabledoublearray", "resiz", "doubl", "array", "constructor", "failur", "input", "array", "length"]},
{"A_title": "In RealVector dotProduct and outerProduct return wrong results due to misuse of sparse iteratorsIn class RealVector the default implementation of RealMatrix outerProduct(RealVector) uses sparse iterators on the entries of the two vectors. The rationale behind this is that 0d * x == 0d is true for all double x. This assumption is in fact false since 0d * NaN == NaN.  Proposed fix is to loop through *all* entries of both vectors. This can have a significant impact on the CPU cost but robustness should probably be preferred over speed in default implementations.  Same issue occurs with double dotProduct(RealVector) which uses sparse iterators for this only.  Another option would be to through an exception if isNaN() is true in which case caching could be used for both isNaN() and isInfinite().", "A_clean_title": ["realvector", "real", "vector", "dotproduct", "dot", "product", "outerproduct", "outer", "product", "return", "wrong", "result", "due", "misus", "spars", "iteratorsin", "iter", "class", "realvector", "real", "vector", "default", "implement", "realmatrix", "real", "matrix", "outerproduct", "outer", "product", "realvector", "real", "vector", "use", "spars", "iter", "entri", "two", "vector", "rational", "behind", "thi", "that", "0d", "0d", "true", "all", "doubl", "thi", "assumpt", "fact", "fals", "sinc", "0d", "nan", "na", "nan", "na", "propos", "fix", "loop", "through", "all", "entri", "both", "vector", "thi", "have", "signific", "impact", "cpu", "cost", "but", "robust", "probabl", "prefer", "over", "speed", "default", "implement", "same", "issu", "occur", "doubl", "dotproduct", "dot", "product", "realvector", "real", "vector", "which", "use", "spars", "iter", "thi", "onli", "anoth", "option", "would", "through", "except", "isnan", "na", "true", "which", "case", "cach", "could", "use", "both", "isnan", "na", "isinfinit", "infinit"], "B_title": "fixed a bug in RealVector.dotProduct(RealVector). Now loops through *all* entries of the vectors.", "B_clean_title": ["fix", "bug", "realvector", "dotproduct", "real", "vector", "dot", "product", "realvector", "real", "vector", "now", "loop", "through", "all", "entri", "vector"]},
{"A_title": "ByteArrayResource throws error if data is nullWhen ByteArrayResource#getData(org.apache.wicket.request.resource.IResource.Attributes) returns null the class throws a WicketRuntimeException.  This behavior differs from DynamicImageResource and ResourceStreamResource which instead issue the following call: response.setError(HttpServletResponse.SC_NOT_FOUND);  ByteArrayResource should follow the same behavior. This would allow for instance to use it for resources which depend on the contents of attributes.getParameters(). When the parameters are invalid a 404 should be issued instead of an exception.", "A_clean_title": ["bytearrayresourc", "byte", "array", "resourc", "throw", "error", "data", "nullwhen", "null", "when", "bytearrayresourc", "byte", "array", "resourc", "getdata", "get", "data", "org", "apach", "wicket", "request", "resourc", "iresourc", "attribut", "resourc", "return", "null", "class", "throw", "wicketruntimeexcept", "wicket", "runtim", "except", "thi", "behavior", "differ", "dynamicimageresourc", "dynam", "imag", "resourc", "resourcestreamresourc", "resourc", "stream", "resourc", "which", "instead", "issu", "follow", "call", "respons", "seterror", "set", "error", "httpservletrespons", "http", "servlet", "respons", "sc", "not", "found", "bytearrayresourc", "byte", "array", "resourc", "follow", "same", "behavior", "thi", "would", "allow", "instanc", "use", "it", "resourc", "which", "depend", "content", "attribut", "getparamet", "get", "paramet", "when", "paramet", "are", "invalid", "404", "issu", "instead", "except"], "B_title": "ByteArrayResource throws error if data is null", "B_clean_title": ["bytearrayresourc", "byte", "array", "resourc", "throw", "error", "data", "null"]},
{"A_title": "java.lang.IllegalArgumentException when running FlatTreeWithAceForSamePrincipalTestRunning  code java -jar oak-run*.jar benchmark FlatTreeWithAceForSamePrincipalTest Oak-Tar code will end with code java.lang.IllegalArgumentException at com.google.common.base.Preconditions.checkArgument(Preconditions.java:77) at org.apache.jackrabbit.oak.plugins.segment.ListRecord.<init>(ListRecord.java:37) at org.apache.jackrabbit.oak.plugins.segment.ListRecord.getEntries(ListRecord.java:80) at org.apache.jackrabbit.oak.plugins.segment.SegmentPropertyState.getValue(SegmentPropertyState.java:130) at org.apache.jackrabbit.oak.util.PropertyBuilder.assignFrom(PropertyBuilder.java:225) at org.apache.jackrabbit.oak.util.PropertyBuilder.copy(PropertyBuilder.java:136) at org.apache.jackrabbit.oak.core.MutableTree.addChild(MutableTree.java:216) at org.apache.jackrabbit.oak.util.TreeUtil.addChild(TreeUtil.java:190) at org.apache.jackrabbit.oak.jcr.delegate.NodeDelegate.internalAddChild(NodeDelegate.java:841) at org.apache.jackrabbit.oak.jcr.delegate.NodeDelegate.addChild(NodeDelegate.java:684) at org.apache.jackrabbit.oak.jcr.session.NodeImpl 5.perform(NodeImpl.java:288) at org.apache.jackrabbit.oak.jcr.session.NodeImpl 5.perform(NodeImpl.java:253) at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:125) at org.apache.jackrabbit.oak.jcr.session.ItemImpl.perform(ItemImpl.java:111) at org.apache.jackrabbit.oak.jcr.session.NodeImpl.addNode(NodeImpl.java:253) at org.apache.jackrabbit.oak.jcr.session.NodeImpl.addNode(NodeImpl.java:238) at org.apache.jackrabbit.oak.benchmark.FlatTreeWithAceForSamePrincipalTest.beforeSuite(FlatTreeWithAceForSamePrincipalTest.java:56) at org.apache.jackrabbit.oak.benchmark.AbstractTest.setUp(AbstractTest.java:113) at org.apache.jackrabbit.oak.benchmark.FlatTreeWithAceForSamePrincipalTest.setUp(FlatTreeWithAceForSamePrincipalTest.java:31) at org.apache.jackrabbit.oak.benchmark.AbstractTest.runTest(AbstractTest.java:151) at org.apache.jackrabbit.oak.benchmark.AbstractTest.run(AbstractTest.java:138) at org.apache.jackrabbit.oak.benchmark.FlatTreeWithAceForSamePrincipalTest.run(FlatTreeWithAceForSamePrincipalTest.java:31) at org.apache.jackrabbit.oak.benchmark.BenchmarkRunner.main(BenchmarkRunner.java:195) at org.apache.jackrabbit.oak.run.Main.main(Main.java:81)  code", "A_clean_title": ["java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "when", "run", "flattreewithaceforsameprincipaltestrun", "flat", "tree", "ace", "same", "princip", "test", "run", "code", "java", "jar", "oak", "run", "jar", "benchmark", "flattreewithaceforsameprincipaltest", "flat", "tree", "ace", "same", "princip", "test", "oak", "tar", "code", "will", "end", "code", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "at", "com", "googl", "common", "base", "precondit", "checkargu", "check", "argument", "precondit", "java:77", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "listrecord", "list", "record", "init", "listrecord", "java:37", "list", "record", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "listrecord", "getentri", "list", "record", "get", "entri", "listrecord", "java:80", "list", "record", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentpropertyst", "getvalu", "segment", "properti", "state", "get", "valu", "segmentpropertyst", "java:130", "segment", "properti", "state", "at", "org", "apach", "jackrabbit", "oak", "util", "propertybuild", "assignfrom", "properti", "builder", "assign", "propertybuild", "java:225", "properti", "builder", "at", "org", "apach", "jackrabbit", "oak", "util", "propertybuild", "copi", "properti", "builder", "propertybuild", "java:136", "properti", "builder", "at", "org", "apach", "jackrabbit", "oak", "core", "mutabletre", "addchild", "mutabl", "tree", "add", "child", "mutabletre", "java:216", "mutabl", "tree", "at", "org", "apach", "jackrabbit", "oak", "util", "treeutil", "addchild", "tree", "util", "add", "child", "treeutil", "java:190", "tree", "util", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "nodedeleg", "internaladdchild", "node", "deleg", "intern", "add", "child", "nodedeleg", "java:841", "node", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "nodedeleg", "addchild", "node", "deleg", "add", "child", "nodedeleg", "java:684", "node", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "nodeimpl", "node", "impl", "perform", "nodeimpl", "java:288", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "nodeimpl", "node", "impl", "perform", "nodeimpl", "java:253", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "perform", "session", "deleg", "sessiondeleg", "java:125", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "itemimpl", "perform", "item", "impl", "itemimpl", "java:111", "item", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "nodeimpl", "addnod", "node", "impl", "add", "node", "nodeimpl", "java:253", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "nodeimpl", "addnod", "node", "impl", "add", "node", "nodeimpl", "java:238", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "flattreewithaceforsameprincipaltest", "beforesuit", "flat", "tree", "ace", "same", "princip", "test", "befor", "suit", "flattreewithaceforsameprincipaltest", "java:56", "flat", "tree", "ace", "same", "princip", "test", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "abstracttest", "setup", "abstract", "test", "set", "up", "abstracttest", "java:113", "abstract", "test", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "flattreewithaceforsameprincipaltest", "setup", "flat", "tree", "ace", "same", "princip", "test", "set", "up", "flattreewithaceforsameprincipaltest", "java:31", "flat", "tree", "ace", "same", "princip", "test", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "abstracttest", "runtest", "abstract", "test", "run", "test", "abstracttest", "java:151", "abstract", "test", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "abstracttest", "run", "abstract", "test", "abstracttest", "java:138", "abstract", "test", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "flattreewithaceforsameprincipaltest", "run", "flat", "tree", "ace", "same", "princip", "test", "flattreewithaceforsameprincipaltest", "java:31", "flat", "tree", "ace", "same", "princip", "test", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "benchmarkrunn", "main", "benchmark", "runner", "benchmarkrunn", "java:195", "benchmark", "runner", "at", "org", "apach", "jackrabbit", "oak", "run", "main", "main", "main", "java:81", "code"], "B_title": "java.lang.IllegalArgumentException when running FlatTreeWithAceForSamePrincipalTest", "B_clean_title": ["java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "when", "run", "flattreewithaceforsameprincipaltest", "flat", "tree", "ace", "same", "princip", "test"]},
{"A_title": "FastDateFormat getDateInstance() and getDateTimeInstance() assume Locale.getDefault() wont changeThe FastDateFormat getDateInstance() and getDateTimeInstance()  methods create the HashMap key from various items including the locale. If the locale is null then it is not made part of the key but the stored object is created using the current default locale. If the Locale is changed subsequently then the wrong locale is applied. Patch for test case to follow.", "A_clean_title": ["fastdateformat", "fast", "date", "format", "getdateinst", "get", "date", "instanc", "getdatetimeinst", "get", "date", "time", "instanc", "assum", "local", "getdefault", "get", "default", "wont", "changeth", "chang", "fastdateformat", "fast", "date", "format", "getdateinst", "get", "date", "instanc", "getdatetimeinst", "get", "date", "time", "instanc", "method", "creat", "hashmap", "hash", "map", "key", "variou", "item", "includ", "local", "local", "null", "then", "it", "not", "made", "part", "key", "but", "store", "object", "creat", "current", "default", "local", "local", "chang", "subsequ", "then", "wrong", "local", "appli", "patch", "test", "case", "follow"], "B_title": "Applying Sebbs test and fix from LANG-368 - fixing it so that FastDateFormat getDateInstance and getDateTimeInstance continue to work if Locale.getDefault() changes", "B_clean_title": ["appli", "sebb", "test", "fix", "lang", "368", "fix", "it", "so", "that", "fastdateformat", "fast", "date", "format", "getdateinst", "get", "date", "instanc", "getdatetimeinst", "get", "date", "time", "instanc", "continu", "work", "local", "getdefault", "get", "default", "chang"]},
{"A_title": "The compiler quotes the 0 keys in object literalsNone", "A_clean_title": ["compil", "quot", "key", "object", "literalsnon", "liter", "none"], "B_title": "Dont quote 0 object literal keys. Fixes issue 942 ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=44143868", "B_clean_title": ["dont", "quot", "object", "liter", "key", "fix", "issu", "942", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=44143868"]},
{"A_title": "404 Error on Nested ModalWindows in IE7 and IE8When opening a ModalWindow inside a ModalWindow the inner ModalWindow generates a 404 error.  Both windows use a PageCreator for content.  To replicate you must use an actual IE 7 or IE 8 browser as this does not replicate using developer tools and setting the document and brower to IE 7.  The problem can be seen at http://www.wicket-library.com/wicket-examples/ajax/modal-window.  I will attach a Quickstart as well.", "A_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8when", "open", "modalwindow", "modal", "window", "insid", "modalwindow", "modal", "window", "inner", "modalwindow", "modal", "window", "gener", "404", "error", "both", "window", "use", "pagecr", "page", "creator", "content", "replic", "you", "must", "use", "actual", "ie", "or", "ie", "browser", "as", "thi", "not", "replic", "develop", "tool", "set", "document", "brower", "ie", "problem", "seen", "at", "http", "window", "wicket", "librari", "exampl", "ajax", "modal", "www", "com", "wicket", "will", "attach", "quickstart", "as", "well"], "B_title": "404 Error on Nested ModalWindows in IE7 and IE8", "B_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8"]},
{"A_title": "Different behaviour of PeriodFormatterWhen the hour of day is set to the ambiguous hour on the daylight to standard time transition in a given time zone the result is inconsistent for different time zones. Shoul the hour be set to the daylight hour or the standard hour for all time zones? I cant find anything that documents this behavior.  My test code below returns different results for different time zones. The very last assertion fails on the Australia time zone cutover.", "A_clean_title": ["differ", "behaviour", "periodformatterwhen", "period", "formatt", "when", "hour", "day", "set", "ambigu", "hour", "daylight", "standard", "time", "transit", "given", "time", "zone", "result", "inconsist", "differ", "time", "zone", "shoul", "hour", "set", "daylight", "hour", "or", "standard", "hour", "all", "time", "zone", "cant", "find", "anyth", "that", "document", "thi", "behavior", "my", "test", "code", "below", "return", "differ", "result", "differ", "time", "zone", "veri", "last", "assert", "fail", "australia", "time", "zone", "cutov"], "B_title": "Period formatter builder append(PeriodFormatter) did not handle some case 2495455 test from Bjoern Ricks", "B_clean_title": ["period", "formatt", "builder", "append", "periodformatt", "period", "formatt", "did", "not", "handl", "some", "case", "2495455", "test", "bjoern", "rick"]},
{"A_title": "Calling  blacklistLibOrExtJars without arguments causes an ExceptionCalling  blacklistLibOrExtJars() without arguments throws java.lang.IllegalArgumentException: Can only blacklist jars by leafname: /System/Library/Java/Extensions/MRJToolkit.jar while whitelistLibOrExtJars() without arguments works fine.", "A_clean_title": ["call", "blacklistliborextjar", "blacklist", "lib", "or", "ext", "jar", "without", "argument", "caus", "exceptioncal", "except", "call", "blacklistliborextjar", "blacklist", "lib", "or", "ext", "jar", "without", "argument", "throw", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "onli", "blacklist", "jar", "by", "leafnam", "jar", "system", "librari", "java", "extens", "mrjtoolkit", "mrj", "toolkit", "while", "whitelistliborextjar", "whitelist", "lib", "or", "ext", "jar", "without", "argument", "work", "fine"], "B_title": "Merge pull request #278 from larsgrefer/fix/gh-277  Fix #277", "B_clean_title": ["merg", "pull", "request", "278", "277", "larsgref", "fix", "gh", "fix", "277"]},
{"A_title": "Preserve doesnt preserve whitespace at start of lineNone", "A_clean_title": ["preserv", "doesnt", "preserv", "whitespac", "at", "start", "linenon", "line", "none"], "B_title": "preserve whitespace at the beginning of license blocks makes the <code> in closure docs look a lot better fixes issue 701", "B_clean_title": ["preserv", "whitespac", "at", "begin", "licens", "block", "make", "code", "closur", "doc", "look", "lot", "better", "fix", "issu", "701"]},
{"A_title": "NPE in  KMeansPlusPlusClusterer unittestWhen running this unittest I am facing this NPE: java.lang.NullPointerException at org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer.assignPointsToClusters(KMeansPlusPlusClusterer.java:91) This is the unittest: package org.fao.fisheries.chronicles.calcuation.cluster; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertTrue; import java.util.Arrays; import java.util.List; import java.util.Random; import org.apache.commons.math.stat.clustering.Cluster; import org.apache.commons.math.stat.clustering.EuclideanIntegerPoint; import org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer; import org.fao.fisheries.chronicles.input.CsvImportProcess; import org.fao.fisheries.chronicles.input.Top200Csv; import org.junit.Test; public class ClusterAnalysisTest  @Test public void testPerformClusterAnalysis2()  KMeansPlusPlusClusterer<EuclideanIntegerPoint> transformer = new KMeansPlusPlusClusterer<EuclideanIntegerPoint>( new Random(1746432956321l)); EuclideanIntegerPoint points = new EuclideanIntegerPoint  new EuclideanIntegerPoint(new int   1959 325100  ) new EuclideanIntegerPoint(new int   1960 373200  ) ; List<Cluster<EuclideanIntegerPoint>> clusters = transformer.cluster(Arrays.asList(points) 1 1); assertEquals(1 clusters.size());", "A_clean_title": ["npe", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "unittestwhen", "unittest", "when", "run", "thi", "unittest", "am", "face", "thi", "npe", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "common", "math", "stat", "cluster", "kmeanspluspluscluster", "assignpointstoclust", "mean", "plu", "plu", "cluster", "assign", "point", "cluster", "kmeanspluspluscluster", "java:91", "mean", "plu", "plu", "cluster", "thi", "unittest", "packag", "org", "fao", "fisheri", "chronicl", "calcuat", "cluster", "import", "static", "org", "junit", "assert", "assertequ", "assert", "equal", "import", "static", "org", "junit", "assert", "asserttru", "assert", "true", "import", "java", "util", "array", "import", "java", "util", "list", "import", "java", "util", "random", "import", "org", "apach", "common", "math", "stat", "cluster", "cluster", "import", "org", "apach", "common", "math", "stat", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "import", "org", "apach", "common", "math", "stat", "cluster", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "import", "org", "fao", "fisheri", "chronicl", "input", "csvimportprocess", "csv", "import", "process", "import", "org", "fao", "fisheri", "chronicl", "input", "top200csv", "import", "org", "junit", "test", "public", "class", "clusteranalysistest", "cluster", "analysi", "test", "test", "public", "void", "testperformclusteranalysis2", "test", "perform", "cluster", "analysis2", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "transform", "new", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "random", "1746432956321l", "euclideanintegerpoint", "euclidean", "integ", "point", "point", "new", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "int", "1959", "325100", "new", "euclideanintegerpoint", "euclidean", "integ", "point", "new", "int", "1960", "373200", "list", "cluster", "euclideanintegerpoint", "euclidean", "integ", "point", "cluster", "transform", "cluster", "array", "aslist", "as", "list", "point", "assertequ", "assert", "equal", "cluster", "size"], "B_title": "Fixed an overflow error in MathUtils.distance that was causing KMeansPlusPlusClusterer to fail with a NullPointerException when component distances between points exceeded Integer.MAXVALUE. JIRA: MATH-305 Reported by Erik van Ingen", "B_clean_title": ["fix", "overflow", "error", "mathutil", "distanc", "math", "util", "that", "wa", "caus", "kmeanspluspluscluster", "mean", "plu", "plu", "cluster", "fail", "nullpointerexcept", "null", "pointer", "except", "when", "compon", "distanc", "between", "point", "exceed", "integ", "maxvalu", "jira", "math", "305", "report", "by", "erik", "van", "ingen"]},
{"A_title": "Ensure there is a max/min valid offsetDateTimeZone does not apply a max/min value for an offset. However the parse method is limited to 23:59. Make 23:59:59.999 the maximum.", "A_clean_title": ["ensur", "there", "max", "min", "valid", "offsetdatetimezon", "offset", "date", "time", "zone", "not", "appli", "max", "min", "valu", "offset", "howev", "pars", "method", "limit", "23:59", "make", "23:59:59", "999", "maximum"], "B_title": "Ensure there is a max/min valid offset in DateTimeZone", "B_clean_title": ["ensur", "there", "max", "min", "valid", "offset", "datetimezon", "date", "time", "zone"]},
{"A_title": "Exception thrown from com.google.javascript.jscomp.CollapseProperties.addStubsForUndeclaredPropertiesNone", "A_clean_title": ["except", "thrown", "com", "googl", "javascript", "jscomp", "collapseproperti", "addstubsforundeclaredpropertiesnon", "collaps", "properti", "add", "stub", "undeclar", "properti", "none"], "B_title": "- Fix issue #19 - attach jsdoc comments without annotations to nodes", "B_clean_title": ["fix", "issu", "19", "attach", "jsdoc", "comment", "without", "annot", "node"]},
{"A_title": "Debug settings / serialize session attributes option not workingSession attributes are serialized even if this debug setting is turned off. Ive noticed that the code that serializes attributes and logs their serialized size in HttpSessionStore#setAttribute is duplicated in Session#setAttribute - but without the debug settings condition. This code was added by the recent patch resolving WICKET-100 and only in the trunk not in the wicket-1.x branch... why???  Regards Bendis", "A_clean_title": ["debug", "set", "serial", "session", "attribut", "option", "not", "workingsess", "work", "session", "attribut", "are", "serial", "even", "thi", "debug", "set", "turn", "off", "ive", "notic", "that", "code", "that", "serial", "attribut", "log", "their", "serial", "size", "httpsessionstor", "http", "session", "store", "setattribut", "set", "attribut", "duplic", "session", "setattribut", "set", "attribut", "but", "without", "debug", "set", "condit", "thi", "code", "wa", "ad", "by", "recent", "patch", "resolv", "wicket", "100", "onli", "trunk", "not", "wicket", "branch", "whi", "regard", "bendi"], "B_title": "", "B_clean_title": []},
{"A_title": "The Urls query parameters are not properly URL encodedIf page parameter has a value with special characters like  then it is rendered as it is in the produced markup and is only XML encoded but never URL encoded. This causes broken html for example in the case when a Link is attached to a non- a|area|link tag:   <html><body><span wicket:id=link onclick=var win = this.ownerDocument.defaultView || this.ownerDocument.parentWindow; if (win == window)  window.location.href=&#039;bookmarkable/org.apache.wicket.MockPageWithLink?urlEscapeNeeded=someone&#039;s+ba+parameter&#039;;  ;return false></span></body></html>  Notice that &#039; after someone closes the location.href string too early and breaks the app.", "A_clean_title": ["url", "queri", "paramet", "are", "not", "properli", "url", "encodedif", "encod", "page", "paramet", "ha", "valu", "special", "charact", "like", "then", "it", "render", "as", "it", "produc", "markup", "onli", "xml", "encod", "but", "never", "url", "encod", "thi", "caus", "broken", "html", "exampl", "case", "when", "link", "attach", "non", "a|area|link", "tag", "html", "bodi", "span", "wicket", "id=link", "onclick=var", "win", "thi", "ownerdocu", "defaultview", "owner", "document", "default", "view", "thi", "ownerdocu", "parentwindow", "owner", "document", "parent", "window", "win", "window", "window", "locat", "href=", "039", "apach", "wicket", "mockpagewithlink", "bookmark", "org", "mock", "page", "link", "urlescapeneeded=someon", "url", "escap", "needed=someon", "039", "s+ba+paramet", "039", "return", "fals", "span", "bodi", "html", "notic", "that", "039", "after", "someon", "close", "locat", "href", "string", "too", "earli", "break", "app"], "B_title": "The Urls query parameters are not properly URL encoded", "B_clean_title": ["url", "queri", "paramet", "are", "not", "properli", "url", "encod"]},
{"A_title": "Inline enclosure doesnt work if wicket:message attribute is used on the same tagMarkup like:          <div wicket:enclosure=child wicket:message=title:something>         <div>Inner div         <span wicket:id=child>Blah</span>         </div>         </div>  doesnt work (Inner div is visible no matter whether child is visible or not) because the auto component created for wicket:message breaks somehow wicket:enclosure.", "A_clean_title": ["inlin", "enclosur", "doesnt", "work", "wicket", "messag", "attribut", "use", "same", "tagmarkup", "tag", "markup", "like", "div", "wicket", "enclosure=child", "wicket", "message=titl", "someth", "div", "inner", "div", "span", "wicket", "id=child", "blah", "span", "div", "div", "doesnt", "work", "inner", "div", "visibl", "no", "matter", "whether", "child", "visibl", "or", "not", "becaus", "auto", "compon", "creat", "wicket", "messag", "break", "somehow", "wicket", "enclosur"], "B_title": "Inline enclosure doesnt work if wicket:message attribute is used on the same tag", "B_clean_title": ["inlin", "enclosur", "doesnt", "work", "wicket", "messag", "attribut", "use", "same", "tag"]},
{"A_title": "Sling I18N queries not supported by OakThe Sling I18N component issues XPath queries like the following:  code:none //element(*mix:language)fn:lower-case(@jcr:language)=en//element(*sling:Message)@sling:message/(@sling:key|@sling:message) code  Such queries currently fail with the following exception:  code:none javax.jcr.query.InvalidQueryException: java.text.ParseException: Query: //element(*mix:language)fn:lower-(*)case(@jcr:language)=en//element(*sling:Message)@sling:message/(@sling:key|@sling:message); expected: (         at org.apache.jackrabbit.oak.jcr.query.QueryManagerImpl.executeQuery(QueryManagerImpl.java:115)         at org.apache.jackrabbit.oak.jcr.query.QueryImpl.execute(QueryImpl.java:85)         at org.apache.sling.jcr.resource.JcrResourceUtil.query(JcrResourceUtil.java:52)         at org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProvider.queryResources(JcrResourceProvider.java:262)         ... 54 more Caused by: java.text.ParseException: Query: //element(*mix:language)fn:lower-(*)case(@jcr:language)=en//element(*sling:Message)@sling:message/(@sling:key|@sling:message); expected: (         at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.getSyntaxError(XPathToSQL2Converter.java:704)         at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.read(XPathToSQL2Converter.java:410)         at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.parseExpression(XPathToSQL2Converter.java:336)         at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.parseCondition(XPathToSQL2Converter.java:279)         at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.parseAnd(XPathToSQL2Converter.java:252)         at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.parseConstraint(XPathToSQL2Converter.java:244)         at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.convert(XPathToSQL2Converter.java:153)         at org.apache.jackrabbit.oak.query.QueryEngineImpl.parseQuery(QueryEngineImpl.java:86)         at org.apache.jackrabbit.oak.query.QueryEngineImpl.executeQuery(QueryEngineImpl.java:99)         at org.apache.jackrabbit.oak.query.QueryEngineImpl.executeQuery(QueryEngineImpl.java:39)         at org.apache.jackrabbit.oak.jcr.query.QueryManagerImpl.executeQuery(QueryManagerImpl.java:110) code", "A_clean_title": ["sling", "i18n", "queri", "not", "support", "by", "oakth", "oak", "sling", "i18n", "compon", "issu", "xpath", "path", "queri", "like", "follow", "code", "none", "element", "mix", "languag", "fn", "lower", "case", "jcr", "languag", "=en", "element", "sling", "messag", "sling", "messag", "sling", "key|", "sling", "messag", "code", "such", "queri", "current", "fail", "follow", "except", "code", "none", "javax", "jcr", "queri", "invalidqueryexcept", "invalid", "queri", "except", "java", "text", "parseexcept", "pars", "except", "queri", "element", "mix", "languag", "fn", "lower", "case", "jcr", "languag", "=en", "element", "sling", "messag", "sling", "messag", "sling", "key|", "sling", "messag", "expect", "at", "org", "apach", "jackrabbit", "oak", "jcr", "queri", "querymanagerimpl", "executequeri", "queri", "manag", "impl", "execut", "queri", "querymanagerimpl", "java:115", "queri", "manag", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "queri", "queryimpl", "execut", "queri", "impl", "queryimpl", "java:85", "queri", "impl", "at", "org", "apach", "sling", "jcr", "resourc", "jcrresourceutil", "queri", "jcr", "resourc", "util", "jcrresourceutil", "java:52", "jcr", "resourc", "util", "at", "org", "apach", "sling", "jcr", "resourc", "intern", "helper", "jcr", "jcrresourceprovid", "queryresourc", "jcr", "resourc", "provid", "queri", "resourc", "jcrresourceprovid", "java:262", "jcr", "resourc", "provid", "54", "more", "caus", "by", "java", "text", "parseexcept", "pars", "except", "queri", "element", "mix", "languag", "fn", "lower", "case", "jcr", "languag", "=en", "element", "sling", "messag", "sling", "messag", "sling", "key|", "sling", "messag", "expect", "at", "org", "apach", "jackrabbit", "oak", "queri", "xpathtosql2convert", "getsyntaxerror", "path", "sql2convert", "get", "syntax", "error", "xpathtosql2convert", "java:704", "path", "sql2convert", "at", "org", "apach", "jackrabbit", "oak", "queri", "xpathtosql2convert", "read", "path", "sql2convert", "xpathtosql2convert", "java:410", "path", "sql2convert", "at", "org", "apach", "jackrabbit", "oak", "queri", "xpathtosql2convert", "parseexpress", "path", "sql2convert", "pars", "express", "xpathtosql2convert", "java:336", "path", "sql2convert", "at", "org", "apach", "jackrabbit", "oak", "queri", "xpathtosql2convert", "parsecondit", "path", "sql2convert", "pars", "condit", "xpathtosql2convert", "java:279", "path", "sql2convert", "at", "org", "apach", "jackrabbit", "oak", "queri", "xpathtosql2convert", "parseand", "path", "sql2convert", "pars", "xpathtosql2convert", "java:252", "path", "sql2convert", "at", "org", "apach", "jackrabbit", "oak", "queri", "xpathtosql2convert", "parseconstraint", "path", "sql2convert", "pars", "constraint", "xpathtosql2convert", "java:244", "path", "sql2convert", "at", "org", "apach", "jackrabbit", "oak", "queri", "xpathtosql2convert", "convert", "path", "sql2convert", "xpathtosql2convert", "java:153", "path", "sql2convert", "at", "org", "apach", "jackrabbit", "oak", "queri", "queryengineimpl", "parsequeri", "queri", "engin", "impl", "pars", "queri", "queryengineimpl", "java:86", "queri", "engin", "impl", "at", "org", "apach", "jackrabbit", "oak", "queri", "queryengineimpl", "executequeri", "queri", "engin", "impl", "execut", "queri", "queryengineimpl", "java:99", "queri", "engin", "impl", "at", "org", "apach", "jackrabbit", "oak", "queri", "queryengineimpl", "executequeri", "queri", "engin", "impl", "execut", "queri", "queryengineimpl", "java:39", "queri", "engin", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "queri", "querymanagerimpl", "executequeri", "queri", "manag", "impl", "execut", "queri", "querymanagerimpl", "java:110", "queri", "manag", "impl", "code"], "B_title": "Sling I18N queries not supported by Oak (partial fix)", "B_clean_title": ["sling", "i18n", "queri", "not", "support", "by", "oak", "partial", "fix"]},
{"A_title": "XPath queries: compatibility for missing @ in front of property namesXPath queries with conditions of the form noformatid=testnoformat are not problematic. Jackrabbit 2.x interpreted such conditions as noformat@id=testnoformat and Oak currently interprets them as noformat@id/* = testnoformat as this is the expected behavior for conditions of the form noformatjcr:contains(id test)noformat.  I believe the condition noformatid=testnoformat is illegal and it would be better to throw an exception instead saying a @ is missing.", "A_clean_title": ["xpath", "path", "queri", "compat", "miss", "front", "properti", "namesxpath", "name", "path", "queri", "condit", "form", "noformatid=testnoformat", "are", "not", "problemat", "jackrabbit", "interpret", "such", "condit", "as", "noformat", "id=testnoformat", "oak", "current", "interpret", "them", "as", "noformat", "id", "testnoformat", "as", "thi", "expect", "behavior", "condit", "form", "noformatjcr", "contain", "id", "test", "noformat", "believ", "condit", "noformatid=testnoformat", "illeg", "it", "would", "better", "throw", "except", "instead", "say", "miss"], "B_title": "XPath queries: compatibility for missing @ in front of property names", "B_clean_title": ["xpath", "path", "queri", "compat", "miss", "front", "properti", "name"]},
{"A_title": "@this emits warning when used with a typedefNone", "A_clean_title": ["thi", "emit", "warn", "when", "use", "typedefnon", "typedef", "none"], "B_title": "Coerce null and undefined out of the @this type when we resolve lazily. We already do this when we resolve @this blocks immediately. Theres some question about whether we should be coercing to the global object instead but im going to just punt on this for now. Fixes issue 274", "B_clean_title": ["coerc", "null", "undefin", "out", "thi", "type", "when", "we", "resolv", "lazili", "we", "alreadi", "thi", "when", "we", "resolv", "thi", "block", "immedi", "there", "some", "question", "about", "whether", "we", "coerc", "global", "object", "instead", "but", "im", "go", "just", "punt", "thi", "now", "fix", "issu", "274"]},
{"A_title": "Division by zeroIn class Complex division by zero always returns NaN. I think that it should return NaN only when the numerator is also ZERO otherwise the result should be INF. See here|http://en.wikipedia.org/wiki/Riemann_sphere#Arithmetic_operations.", "A_clean_title": ["divis", "by", "zeroin", "zero", "class", "complex", "divis", "by", "zero", "alway", "return", "nan", "na", "think", "that", "it", "return", "nan", "na", "onli", "when", "numer", "also", "zero", "otherwis", "result", "inf", "see", "here|http", "wikipedia", "en", "sphere", "org", "wiki", "riemann", "arithmet", "oper"], "B_title": "Complex division by zero:  z / 0 = INF if z is not ZERO  0 / 0 = NaN", "B_clean_title": ["complex", "divis", "by", "zero", "inf", "not", "zero", "nan", "na"]},
{"A_title": "NPE in DateTimeZoneBuilderWhen a DateTimeZone is build with duplicate-named recurring saving time in a first thread all goes Ok: a warning message is generated and an identifier is automatically generated in PrecalculatedZone.create(). When a second thread does the same an NPE is generated in ZoneInfoCompiler.verbose().  The cause is that the cVerbose ThreadLocal is incorrectly initialized in ZoneInfoCompiler ...will initialize cVerbose only for the first thread and not for the subsequent ones. The NPE is caused by the autoboxing in: . A better approach could be to remove the initialization and test for null:", "A_clean_title": ["npe", "datetimezonebuilderwhen", "date", "time", "zone", "builder", "when", "datetimezon", "date", "time", "zone", "build", "duplic", "name", "recur", "save", "time", "first", "thread", "all", "goe", "ok", "warn", "messag", "gener", "identifi", "automat", "gener", "precalculatedzon", "creat", "precalcul", "zone", "when", "second", "thread", "same", "npe", "gener", "zoneinfocompil", "verbos", "zone", "info", "compil", "caus", "that", "cverbos", "verbos", "threadloc", "thread", "local", "incorrectli", "initi", "zoneinfocompil", "zone", "info", "compil", "will", "initi", "cverbos", "verbos", "onli", "first", "thread", "not", "subsequ", "one", "npe", "caus", "by", "autobox", "better", "approach", "could", "remov", "initi", "test", "null"], "B_title": "Fix ZoneInfoCompiler and DateTimeZoneBuilder multi-threading", "B_clean_title": ["fix", "zoneinfocompil", "zone", "info", "compil", "datetimezonebuild", "date", "time", "zone", "builder", "multi", "thread"]},
{"A_title": "Dates.round() behaves incorrectly for minutes and secondsGet unexpected output for rounding by minutes or seconds. public void testRound()      Calendar testCalendar = Calendar.getInstance(TimeZone.getTimeZone(GMT));     testCalendar.set(2007 6 2 8 9 50);     Date date = testCalendar.getTime();     System.out.println(Before round()  + date);     System.out.println(After round()   + DateUtils.round(date Calendar.MINUTE));  --2.1 produces Before round() Mon Jul 02 03:09:50 CDT 2007 After round()  Mon Jul 02 03:10:00 CDT 2007 – this is what I would expect --2.2 and 2.3 produces Before round() Mon Jul 02 03:09:50 CDT 2007 After round()  Mon Jul 02 03:01:00 CDT 2007 – this appears to be wrong", "A_clean_title": ["date", "round", "behav", "incorrectli", "minut", "secondsget", "second", "get", "unexpect", "output", "round", "by", "minut", "or", "second", "public", "void", "testround", "test", "round", "calendar", "testcalendar", "test", "calendar", "calendar", "getinst", "get", "instanc", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "testcalendar", "set", "test", "calendar", "2007", "50", "date", "date", "testcalendar", "gettim", "test", "calendar", "get", "time", "system", "out", "println", "befor", "round", "date", "system", "out", "println", "after", "round", "dateutil", "round", "date", "util", "date", "calendar", "minut", "produc", "befor", "round", "mon", "jul", "02", "03:09:50", "cdt", "2007", "after", "round", "mon", "jul", "02", "03:10:00", "cdt", "2007", "thi", "what", "would", "expect", "produc", "befor", "round", "mon", "jul", "02", "03:09:50", "cdt", "2007", "after", "round", "mon", "jul", "02", "03:01:00", "cdt", "2007", "thi", "appear", "wrong"], "B_title": "Applying the fix and the test patches from LANG-346 - fixes bugs in DateUtils.round() for minutes and seconds. Patch from Dave Meikle", "B_clean_title": ["appli", "fix", "test", "patch", "lang", "346", "fix", "bug", "dateutil", "round", "date", "util", "minut", "second", "patch", "dave", "meikl"]},
{"A_title": "XPath: querying for nodes named text element and rep:excerpt failsQueries that contain text or element as a node name currently fail because the the parser assumes text() / element(...). Example query that fails:  noformat /jcr:root/content/text/jcr:content//element(*nt:unstructured) noformat  A workaround is to use the escape mechanism that is:  noformat /jcr:root/tmp/_x0074_ext/jcr:content//element(*nt:unstructured) noformat  It looks like ( and ) are valid characters in node names but to query for those characters they need to be escaped.", "A_clean_title": ["xpath", "path", "queri", "node", "name", "text", "element", "rep", "excerpt", "failsqueri", "fail", "queri", "that", "contain", "text", "or", "element", "as", "node", "name", "current", "fail", "becaus", "parser", "assum", "text", "element", "exampl", "queri", "that", "fail", "noformat", "jcr", "root", "content", "text", "jcr", "content", "element", "nt", "unstructur", "noformat", "workaround", "use", "escap", "mechan", "that", "noformat", "jcr", "x0074", "root", "tmp", "ext", "jcr", "content", "element", "nt", "unstructur", "noformat", "it", "look", "like", "are", "valid", "charact", "node", "name", "but", "queri", "those", "charact", "they", "need", "escap"], "B_title": "XPath: querying for nodes named text element and rep:excerpt fails", "B_clean_title": ["xpath", "path", "queri", "node", "name", "text", "element", "rep", "excerpt", "fail"]},
{"A_title": "Event broadcast type Depth does not work when the sink is a Component but not a MarkupContainerEvent broadcast type Depth does not work when the sink is a Component but not a MarkupContainer. In this case no sinks receive the event.", "A_clean_title": ["event", "broadcast", "type", "depth", "not", "work", "when", "sink", "compon", "but", "not", "markupcontainerev", "markup", "contain", "event", "broadcast", "type", "depth", "not", "work", "when", "sink", "compon", "but", "not", "markupcontain", "markup", "contain", "thi", "case", "no", "sink", "receiv", "event"], "B_title": "Issue: WICKET-3539", "B_clean_title": ["issu", "wicket", "3539"]},
{"A_title": "AbstractTextComponent not escaping html data by default therefore user text is not redisplayed correctlyUser input is not escaped in all text fields by default (and the default is not configurable).  This leads to user entered text not being redisplayed correctly.  * You can replicate using the project from WICKET-3330. * Just enter the text my&frac12;companyname and press enter * The field will not redisplay the text entered properly", "A_clean_title": ["abstracttextcompon", "abstract", "text", "compon", "not", "escap", "html", "data", "by", "default", "therefor", "user", "text", "not", "redisplay", "correctlyus", "correctli", "user", "input", "not", "escap", "all", "text", "field", "by", "default", "default", "not", "configur", "thi", "lead", "user", "enter", "text", "not", "be", "redisplay", "correctli", "you", "replic", "project", "wicket", "3330", "just", "enter", "text", "my", "frac12", "companynam", "press", "enter", "field", "will", "not", "redisplay", "text", "enter", "properli"], "B_title": "unescape markup attribute during parsing dont unescape while rendering", "B_clean_title": ["unescap", "markup", "attribut", "dure", "pars", "dont", "unescap", "while", "render"]},
{"A_title": "SmartLinkLabel doesnt recognize already tagged linksThe SmartLinkLabel works as expected for the texts without <a>..</a> tag.  for text like extensions @ http://www.wicketframework.org/wicket-extensions/index.html are cool!! SmartLinkLabel generates the html -  extensions @ <a href=http://www.wicketframework.org/wicket-extensions/index.html>http://www.wicketframework.org/wicket-extensions/index.html</a> are cool!!  but for the text like extensions @ <a href=http://www.wicketframework.org/wicket-extensions/index.html>http://www.wicketframework.org/wicket-extensions/index.html</a> are cool!! SmartLinkLabel generates the html -  extensions @ <a href=<a href=http://www.wicketframework.org/wicket-extensions/index.html>http://www.wicketframework.org/wicket-extensions/index.html</a>><a href=http://www.wicketframework.org/wicket-extensions/index.html>http://www.wicketframework.org/wicket-extensions/index.html</a></a> are cool!!  I think this is a bug & needs a fix.", "A_clean_title": ["smartlinklabel", "smart", "link", "label", "doesnt", "recogn", "alreadi", "tag", "linksth", "link", "smartlinklabel", "smart", "link", "label", "work", "as", "expect", "text", "without", "tag", "text", "like", "extens", "http", "wicketframework", "html", "www", "org", "wicket", "extens", "index", "are", "cool", "smartlinklabel", "smart", "link", "label", "gener", "html", "extens", "href=http", "wicketframework", "html", "www", "org", "wicket", "extens", "index", "http", "wicketframework", "html", "www", "org", "wicket", "extens", "index", "are", "cool", "but", "text", "like", "extens", "href=http", "wicketframework", "html", "www", "org", "wicket", "extens", "index", "http", "wicketframework", "html", "www", "org", "wicket", "extens", "index", "are", "cool", "smartlinklabel", "smart", "link", "label", "gener", "html", "extens", "href=", "href=http", "wicketframework", "html", "www", "org", "wicket", "extens", "index", "http", "wicketframework", "html", "www", "org", "wicket", "extens", "index", "href=http", "wicketframework", "html", "www", "org", "wicket", "extens", "index", "http", "wicketframework", "html", "www", "org", "wicket", "extens", "index", "are", "cool", "think", "thi", "bug", "need", "fix"], "B_title": "SmartLinkLabel doesnt recognize already tagged links", "B_clean_title": ["smartlinklabel", "smart", "link", "label", "doesnt", "recogn", "alreadi", "tag", "link"]},
{"A_title": "display the exact number of tablet serversThis is a regression of ACCUMULO-1140", "A_clean_title": ["display", "exact", "number", "tablet", "serversthi", "server", "thi", "regress", "accumulo", "1140"], "B_title": "fixed PreciseNumberType and wrote a unit test to make sure it really does precise numbers", "B_clean_title": ["fix", "precisenumbertyp", "precis", "number", "type", "wrote", "unit", "test", "make", "sure", "it", "realli", "precis", "number"]},
{"A_title": "du on a table without files does not reportnoformat shell> createtable t shell> du t shell> noformat  expected:  noformat shell> du t              0 t shell> noformat", "A_clean_title": ["du", "tabl", "without", "file", "not", "reportnoformat", "shell", "createt", "shell", "du", "shell", "noformat", "expect", "noformat", "shell", "du", "shell", "noformat"], "B_title": "applying Kevin Faros patch to fix du on an empty table", "B_clean_title": ["appli", "kevin", "faro", "patch", "fix", "du", "empti", "tabl"]},
{"A_title": "Streaming does not correctly forward ExecutionConfig to runtimeWhen running streaming jobs you see this log entry: Environment did not contain an ExecutionConfig - using a default config.  Some parts of the code use an ExecutionConfig at runtime. This will be a default config without registered serializers and other user settings.", "A_clean_title": ["stream", "not", "correctli", "forward", "executionconfig", "execut", "config", "runtimewhen", "runtim", "when", "run", "stream", "job", "you", "see", "thi", "log", "entri", "environ", "did", "not", "contain", "executionconfig", "execut", "config", "default", "config", "some", "part", "code", "use", "executionconfig", "execut", "config", "at", "runtim", "thi", "will", "default", "config", "without", "regist", "serial", "other", "user", "set"], "B_title": "streaming Add ExecutionConfig serialization for streaming jobs", "B_clean_title": ["stream", "add", "executionconfig", "execut", "config", "serial", "stream", "job"]},
{"A_title": "ArrayIndexOutOfBoundsException in MathArrays.linearCombinationWhen MathArrays.linearCombination is passed arguments with length 1 it throws an ArrayOutOfBoundsException. This is caused by this line:  double prodHighNext = prodHigh1;  linearCombination should check the length of the arguments and fall back to simple multiplication if length == 1.", "A_clean_title": ["arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "matharray", "linearcombinationwhen", "math", "array", "linear", "combin", "when", "matharray", "linearcombin", "math", "array", "linear", "combin", "pass", "argument", "length", "it", "throw", "arrayoutofboundsexcept", "array", "out", "bound", "except", "thi", "caus", "by", "thi", "line", "doubl", "prodhighnext", "prod", "high", "next", "prodhigh1", "prod", "high1", "linearcombin", "linear", "combin", "check", "length", "argument", "fall", "back", "simpl", "multipl", "length"], "B_title": "Array of length 1 must be handled as a special case.", "B_clean_title": ["array", "length", "must", "handl", "as", "special", "case"]},
{"A_title": "NaN singular value from SVDThe following jython code Start code  from org.apache.commons.math.linear import *   Alist = 1.0 2.0 3.02.03.04.03.05.07.0   A = Array2DRowRealMatrix(Alist)   decomp = SingularValueDecompositionImpl(A)   print decomp.getSingularValues()  End code  prints array(d 11.218599757513008 0.3781791648535976 nan) The last singular value should be something very close to 0 since the matrix is rank deficient.  When i use the result from getSolver() to solve a system i end  up with a bunch of NaNs in the solution.  I assumed i would get back a least squares solution.  Does this SVD implementation require that the matrix be full rank?  If so then i would expect an exception to be thrown from the constructor or one of the methods.", "A_clean_title": ["nan", "na", "singular", "valu", "svdthe", "svd", "follow", "jython", "code", "start", "code", "org", "apach", "common", "math", "linear", "import", "alist", "02", "03", "04", "03", "05", "07", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "alist", "decomp", "singularvaluedecompositionimpl", "singular", "valu", "decomposit", "impl", "print", "decomp", "getsingularvalu", "get", "singular", "valu", "end", "code", "print", "array", "11", "218599757513008", "3781791648535976", "nan", "last", "singular", "valu", "someth", "veri", "close", "sinc", "matrix", "rank", "defici", "when", "use", "result", "getsolv", "get", "solver", "solv", "system", "end", "up", "bunch", "nan", "na", "ns", "solut", "assum", "would", "get", "back", "least", "squar", "solut", "thi", "svd", "implement", "requir", "that", "matrix", "full", "rank", "so", "then", "would", "expect", "except", "thrown", "constructor", "or", "one", "method"], "B_title": "Singular Value Decomposition now computes either the compact SVD (using only positive singular values) or truncated SVD (using a user-specified maximal number of singular values). Fixed Singular Value Decomposition solving of singular systems. JIRA: MATH-320 MATH-321", "B_clean_title": ["singular", "valu", "decomposit", "now", "comput", "either", "compact", "svd", "onli", "posit", "singular", "valu", "or", "truncat", "svd", "user", "specifi", "maxim", "number", "singular", "valu", "fix", "singular", "valu", "decomposit", "solv", "singular", "system", "jira", "math", "320", "math", "321"]},
{"A_title": "hashCode for Mutation has an unfortunate implementationWhile looking at how a tablet server processes constraint violations I happened to look into Mutations hashCode implementation:  code   @Override   public int hashCode()      return toThrift(false).hashCode();    code  Clicking through to TMutation hashCode finds this gem:  code   @Override   public int hashCode()      return 0;    code", "A_clean_title": ["hashcod", "hash", "code", "mutat", "ha", "unfortun", "implementationwhil", "implement", "while", "look", "at", "how", "tablet", "server", "process", "constraint", "violat", "happen", "look", "into", "mutat", "hashcod", "hash", "code", "implement", "code", "overrid", "public", "int", "hashcod", "hash", "code", "return", "tothrift", "thrift", "fals", "hashcod", "hash", "code", "code", "click", "through", "tmutat", "mutat", "hashcod", "hash", "code", "find", "thi", "gem", "code", "overrid", "public", "int", "hashcod", "hash", "code", "return", "code"], "B_title": "more better hashCode", "B_clean_title": ["more", "better", "hashcod", "hash", "code"]},
{"A_title": "issues with JsopBuilder.encode and .escape1) escape() escapes many characters that do not need to be escaped (>127)  2) encode() does not encode many control characters that would need to be escaped when read through a JSON parser.", "A_clean_title": ["issu", "jsopbuild", "encod", "jsop", "builder", "escape1", "escap", "escap", "mani", "charact", "that", "not", "need", "escap", "127", "encod", "not", "encod", "mani", "control", "charact", "that", "would", "need", "escap", "when", "read", "through", "json", "parser"], "B_title": "- optimize escape/encode not to encode characters >= 127 update tests (patch by Thomas Mueller)", "B_clean_title": ["optim", "escap", "encod", "not", "encod", "charact", "127", "updat", "test", "patch", "by", "thoma", "mueller"]},
{"A_title": "WebPageRenderer must not render full page in Ajax requestsWebPageRenderer renders the full page when WebRequest#shouldPreserveClientUrl() is true or RedirectStrategy.NEVER_REDIRECT is configured.  For Ajax request this means that wicket-ajax-js will not be able to parse the HTML response.", "A_clean_title": ["webpagerender", "web", "page", "render", "must", "not", "render", "full", "page", "ajax", "requestswebpagerender", "request", "web", "page", "render", "render", "full", "page", "when", "webrequest", "web", "request", "shouldpreserveclienturl", "preserv", "client", "url", "true", "or", "redirectstrategi", "redirect", "strategi", "never", "redirect", "configur", "ajax", "request", "thi", "mean", "that", "wicket", "ajax", "js", "will", "not", "abl", "pars", "html", "respons"], "B_title": "rendering and writing of a page should never happen on an Ajax request even if other circumstances imply otherwise", "B_clean_title": ["render", "write", "page", "never", "happen", "ajax", "request", "even", "other", "circumst", "impli", "otherwis"]},
{"A_title": "Problem spying on abstract classesTheres a problem with spying on abstract classes when the real implementation calls out to the abstract method.", "A_clean_title": ["problem", "spi", "abstract", "classesther", "class", "there", "problem", "spi", "abstract", "class", "when", "real", "implement", "call", "out", "abstract", "method"], "B_title": "Changed CallsRealMethods to delegate to default answer for abstract methods.", "B_clean_title": ["chang", "callsrealmethod", "call", "real", "method", "deleg", "default", "answer", "abstract", "method"]},
{"A_title": "nicer textual printing of typed parametersWhen matchers fail but yield the same toString() Mockito prints extra type information. However the type information is awkwardly printed for Strings. Ive encountered this issue while working on removing hard dependency to hamcrest.", "A_clean_title": ["nicer", "textual", "print", "type", "parameterswhen", "paramet", "when", "matcher", "fail", "but", "yield", "same", "tostr", "string", "mockito", "print", "extra", "type", "inform", "howev", "type", "inform", "awkwardli", "print", "string", "ive", "encount", "thi", "issu", "while", "work", "remov", "hard", "depend", "hamcrest"], "B_title": "fix for issue 236 : mocks are injected a bit less aggressively", "B_clean_title": ["fix", "issu", "236", "mock", "are", "inject", "bit", "less", "aggress"]},
{"A_title": "StrBuilder.replaceAll and StrBuilder.deleteAll can throw ArrayIndexOutOfBoundsException.StrBuilder.replaceAll and StrBuilder.deleteAll can thrown ArrayIndexOutOfBoundsExceptions. Here are a couple of additions to the StrBuilderTest class that demonstrate this problem: StrBuilder.deleteAll() - added to testDeleteAll_String():         sb = new StrBuilder(n%BLAH%nDo more stuffneven more stuffn%BLAH%n);         sb.deleteAll(n%BLAH%);         assertEquals(nDo more stuffneven more stuffn sb.toString()); this causes the following error: java.lang.ArrayIndexOutOfBoundsException at java.lang.System.arraycopy(Native Method) at org.apache.commons.lang.text.StrBuilder.deleteImpl(StrBuilder.java:1114) at org.apache.commons.lang.text.StrBuilder.deleteAll(StrBuilder.java:1188) at org.apache.commons.lang.text.StrBuilderTest.testDeleteAll_String(StrBuilderTest.java:606) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:585) at junit.framework.TestCase.runTest(TestCase.java:154) at junit.framework.TestCase.runBare(TestCase.java:127) at junit.framework.TestResult 1.protect(TestResult.java:106) at junit.framework.TestResult.runProtected(TestResult.java:124) at junit.framework.TestResult.run(TestResult.java:109) at junit.framework.TestCase.run(TestCase.java:118) at junit.framework.TestSuite.runTest(TestSuite.java:208) at junit.framework.TestSuite.run(TestSuite.java:203) at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196) StrBuilder.replaceAll() - added to testReplaceAll_String_String():         sb = new StrBuilder(n%BLAH%nDo more stuffneven more stuffn%BLAH%n);         sb.replaceAll(n%BLAH% );         assertEquals(nDo more stuffneven more stuffn sb.toString()); this causes the exception: java.lang.ArrayIndexOutOfBoundsException at java.lang.System.arraycopy(Native Method) at org.apache.commons.lang.text.StrBuilder.replaceImpl(StrBuilder.java:1256) at org.apache.commons.lang.text.StrBuilder.replaceAll(StrBuilder.java:1339) at org.apache.commons.lang.text.StrBuilderTest.testReplaceAll_String_String(StrBuilderTest.java:763) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:585) at junit.framework.TestCase.runTest(TestCase.java:154) at junit.framework.TestCase.runBare(TestCase.java:127) at junit.framework.TestResult 1.protect(TestResult.java:106) at junit.framework.TestResult.runProtected(TestResult.java:124) at junit.framework.TestResult.run(TestResult.java:109) at junit.framework.TestCase.run(TestCase.java:118) at junit.framework.TestSuite.runTest(TestSuite.java:208) at junit.framework.TestSuite.run(TestSuite.java:203) at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)", "A_clean_title": ["strbuilder", "replaceal", "str", "builder", "replac", "all", "strbuilder", "deleteal", "str", "builder", "delet", "all", "throw", "arrayindexoutofboundsexcept", "strbuilder", "replaceal", "array", "index", "out", "bound", "except", "str", "builder", "replac", "all", "strbuilder", "deleteal", "str", "builder", "delet", "all", "thrown", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "here", "are", "coupl", "addit", "strbuildertest", "str", "builder", "test", "class", "that", "demonstr", "thi", "problem", "strbuilder", "deleteal", "str", "builder", "delet", "all", "ad", "testdeleteal", "string", "test", "delet", "all", "sb", "new", "strbuilder", "str", "builder", "blah", "ndo", "more", "stuffneven", "more", "stuffn", "blah", "sb", "deleteal", "delet", "all", "blah", "assertequ", "assert", "equal", "ndo", "more", "stuffneven", "more", "stuffn", "sb", "tostr", "string", "thi", "caus", "follow", "error", "java", "lang", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "at", "java", "lang", "system", "arraycopi", "nativ", "method", "at", "org", "apach", "common", "lang", "text", "strbuilder", "deleteimpl", "str", "builder", "delet", "impl", "strbuilder", "java:1114", "str", "builder", "at", "org", "apach", "common", "lang", "text", "strbuilder", "deleteal", "str", "builder", "delet", "all", "strbuilder", "java:1188", "str", "builder", "at", "org", "apach", "common", "lang", "text", "strbuildertest", "str", "builder", "test", "testdeleteal", "string", "test", "delet", "all", "strbuildertest", "java:606", "str", "builder", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:585", "at", "junit", "framework", "testcas", "runtest", "test", "case", "run", "test", "testcas", "java:154", "test", "case", "at", "junit", "framework", "testcas", "runbar", "test", "case", "run", "bare", "testcas", "java:127", "test", "case", "at", "junit", "framework", "testresult", "test", "result", "protect", "testresult", "java:106", "test", "result", "at", "junit", "framework", "testresult", "runprotect", "test", "result", "run", "protect", "testresult", "java:124", "test", "result", "at", "junit", "framework", "testresult", "run", "test", "result", "testresult", "java:109", "test", "result", "at", "junit", "framework", "testcas", "run", "test", "case", "testcas", "java:118", "test", "case", "at", "junit", "framework", "testsuit", "runtest", "test", "suit", "run", "test", "testsuit", "java:208", "test", "suit", "at", "junit", "framework", "testsuit", "run", "test", "suit", "testsuit", "java:203", "test", "suit", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "junit3", "junit3testrefer", "run", "unit3test", "refer", "junit3testrefer", "java:128", "unit3test", "refer", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "testexecut", "run", "test", "execut", "testexecut", "java:38", "test", "execut", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:460", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:673", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "run", "remot", "test", "runner", "remotetestrunn", "java:386", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "main", "remot", "test", "runner", "remotetestrunn", "java:196", "remot", "test", "runner", "strbuilder", "replaceal", "str", "builder", "replac", "all", "ad", "testreplaceal", "string", "string", "test", "replac", "all", "sb", "new", "strbuilder", "str", "builder", "blah", "ndo", "more", "stuffneven", "more", "stuffn", "blah", "sb", "replaceal", "replac", "all", "blah", "assertequ", "assert", "equal", "ndo", "more", "stuffneven", "more", "stuffn", "sb", "tostr", "string", "thi", "caus", "except", "java", "lang", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "at", "java", "lang", "system", "arraycopi", "nativ", "method", "at", "org", "apach", "common", "lang", "text", "strbuilder", "replaceimpl", "str", "builder", "replac", "impl", "strbuilder", "java:1256", "str", "builder", "at", "org", "apach", "common", "lang", "text", "strbuilder", "replaceal", "str", "builder", "replac", "all", "strbuilder", "java:1339", "str", "builder", "at", "org", "apach", "common", "lang", "text", "strbuildertest", "str", "builder", "test", "testreplaceal", "string", "string", "test", "replac", "all", "strbuildertest", "java:763", "str", "builder", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:585", "at", "junit", "framework", "testcas", "runtest", "test", "case", "run", "test", "testcas", "java:154", "test", "case", "at", "junit", "framework", "testcas", "runbar", "test", "case", "run", "bare", "testcas", "java:127", "test", "case", "at", "junit", "framework", "testresult", "test", "result", "protect", "testresult", "java:106", "test", "result", "at", "junit", "framework", "testresult", "runprotect", "test", "result", "run", "protect", "testresult", "java:124", "test", "result", "at", "junit", "framework", "testresult", "run", "test", "result", "testresult", "java:109", "test", "result", "at", "junit", "framework", "testcas", "run", "test", "case", "testcas", "java:118", "test", "case", "at", "junit", "framework", "testsuit", "runtest", "test", "suit", "run", "test", "testsuit", "java:208", "test", "suit", "at", "junit", "framework", "testsuit", "run", "test", "suit", "testsuit", "java:203", "test", "suit", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "junit3", "junit3testrefer", "run", "unit3test", "refer", "junit3testrefer", "java:128", "unit3test", "refer", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "testexecut", "run", "test", "execut", "testexecut", "java:38", "test", "execut", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:460", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:673", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "run", "remot", "test", "runner", "remotetestrunn", "java:386", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "main", "remot", "test", "runner", "remotetestrunn", "java:196", "remot", "test", "runner"], "B_title": "Fixing #LANG-294. The indexOf method did not take into account the size variable that limited the amount of the buffer that should be looked at.", "B_clean_title": ["fix", "lang", "294", "indexof", "index", "method", "did", "not", "take", "into", "account", "size", "variabl", "that", "limit", "amount", "buffer", "that", "look", "at"]},
{"A_title": "Line.revert() is impreciseLine.revert() only maintains ~10 digits for the direction. This becomes an issue when the lines position is evaluated far from the origin. A simple fix would be to use Vector3D.negate() for the direction. Also is there a reason why Line is not immutable? It is just comprised of two vectors.", "A_clean_title": ["line", "revert", "impreciselin", "revert", "imprecis", "line", "onli", "maintain", "~10", "digit", "direct", "thi", "becom", "issu", "when", "line", "posit", "evalu", "far", "origin", "simpl", "fix", "would", "use", "vector3d", "negat", "direct", "also", "there", "reason", "whi", "line", "not", "immut", "it", "just", "compris", "two", "vector"], "B_title": "Fixed accuracy of 3D Line.revert().", "B_clean_title": ["fix", "accuraci", "3d", "line", "revert"]},
{"A_title": "String escaping mishandles null byteNone", "A_clean_title": ["string", "escap", "mishandl", "null", "bytenon", "byte", "none"], "B_title": "Encode the null byte more correctly because we have to be careful of look ahead. Contributed by kosmo.zb Fixes issue 486", "B_clean_title": ["encod", "null", "byte", "more", "correctli", "becaus", "we", "have", "care", "look", "ahead", "contribut", "by", "kosmo", "zb", "fix", "issu", "486"]},
{"A_title": "division by zero wrongly throws JSC_DIVIDE_BY_0_ERRORNone", "A_clean_title": ["divis", "by", "zero", "wrongli", "throw", "jsc", "divid", "by", "errornon", "error", "none"], "B_title": "Delete the divide by zero error Ive never heard of this catching any real bug. It seems like if you explicitly typed 1 / 0 you meant to do that. fixes issue 381", "B_clean_title": ["delet", "divid", "by", "zero", "error", "ive", "never", "heard", "thi", "catch", "ani", "real", "bug", "it", "seem", "like", "you", "explicitli", "type", "you", "meant", "that", "fix", "issu", "381"]},
{"A_title": "Session.getItem violates JCR SpecSession.getItem(path) is supposed to first return a node for the given path and if no node is found return a property.  The oak implementation returns this in the opposite order.  see attached patch for a possible fix.", "A_clean_title": ["session", "getitem", "get", "item", "violat", "jcr", "specsess", "getitem", "spec", "session", "get", "item", "path", "suppos", "first", "return", "node", "given", "path", "no", "node", "found", "return", "properti", "oak", "implement", "return", "thi", "opposit", "order", "see", "attach", "patch", "possibl", "fix"], "B_title": "Session.getItem violates JCR Spec Applying patch. Credits to Will McGauley", "B_clean_title": ["session", "getitem", "get", "item", "violat", "jcr", "spec", "appli", "patch", "credit", "will", "mcgauley", "mc", "gauley"]},
{"A_title": "Generated urls for mounted pages contain redundant trailing /Is it OK (i.e. by design as opposed to by mistake) that the urls generated for the mounted pages end up with the /?  Provided that theres a page that expects single parameter (here: content)... public class HelpPage extends WebPage  public HelpPage(PageParameters p)  super(p); add(new DynamicContentPanel(contentPanel new Model<String>(p.getString(content))));    ...and it is mounted in the Application#init() mount(new BookmarkablePageRequestTargetUrlCodingStrategy(help HelpPage.class null));  ...and further referred to somewhere else as: add(new BookmarkablePageLink(helpPage HelpPage.class new PageParameters(content=a)));  the url in the generated markup is in the following form: http://localhost:8080/dummy-web/help/content/a/;jsessionid=11624C6125F8DF4867E3218676D79A29  While IMHO it should read: http://localhost:8080/dummy-web/help/content/a;jsessionid=11624C6125F8DF4867E3218676D79A29  It looks even more awkward when there are more parameters and part of them is encoded as a query string: http://localhost:8080/dummy-web/help/content/a/?param2=value2/;jsessionid=11624C6125F8DF4867E3218676D79A29  The page parameter for both cases is resolved correctly by the HelpPages constructor so it seems that even though theres an extra / at the end of the url it gets omitted. Then why bother generating it?  I stumbled upon an issue https://issues.apache.org/jira/browse/WICKET-765. Apart from the compatibility with wicket 1.2 I see no rationale for trailing /. Looking at implementations of IRequestTargetUrlCodingStrategy I come to the conclusion the the append(/) is being overused and redundant especially when it is preceded by the following code which makes sure that the / is in place before adding another parameter.", "A_clean_title": ["gener", "url", "mount", "page", "contain", "redund", "trail", "it", "ok", "by", "design", "as", "oppos", "by", "mistak", "that", "url", "gener", "mount", "page", "end", "up", "provid", "that", "there", "page", "that", "expect", "singl", "paramet", "here", "content", "public", "class", "helppag", "help", "page", "extend", "webpag", "web", "page", "public", "helppag", "help", "page", "pageparamet", "page", "paramet", "super", "add", "new", "dynamiccontentpanel", "dynam", "content", "panel", "contentpanel", "content", "panel", "new", "model", "string", "getstr", "get", "string", "content", "it", "mount", "applic", "init", "mount", "new", "bookmarkablepagerequesttargeturlcodingstrategi", "bookmark", "page", "request", "target", "url", "code", "strategi", "help", "helppag", "class", "help", "page", "null", "further", "refer", "somewher", "as", "add", "new", "bookmarkablepagelink", "bookmark", "page", "link", "helppag", "help", "page", "helppag", "class", "help", "page", "new", "pageparamet", "page", "paramet", "content=a", "url", "gener", "markup", "follow", "form", "http", "localhost:8080", "dummi", "web", "help", "content", "jsessionid=11624c6125f8df4867e3218676d79a29", "while", "imho", "it", "read", "http", "localhost:8080", "dummi", "web", "help", "content", "jsessionid=11624c6125f8df4867e3218676d79a29", "it", "look", "even", "more", "awkward", "when", "there", "are", "more", "paramet", "part", "them", "encod", "as", "queri", "string", "http", "localhost:8080", "dummi", "web", "help", "content", "param2=value2", "jsessionid=11624c6125f8df4867e3218676d79a29", "page", "paramet", "both", "case", "resolv", "correctli", "by", "helppag", "help", "page", "constructor", "so", "it", "seem", "that", "even", "though", "there", "extra", "at", "end", "url", "it", "get", "omit", "then", "whi", "bother", "gener", "it", "stumbl", "upon", "issu", "http", "765", "apach", "issu", "org", "jira", "brows", "wicket", "apart", "compat", "wicket", "see", "no", "rational", "trail", "look", "at", "implement", "irequesttargeturlcodingstrategi", "request", "target", "url", "code", "strategi", "come", "conclus", "append", "be", "overus", "redund", "especi", "when", "it", "preced", "by", "follow", "code", "which", "make", "sure", "that", "place", "befor", "ad", "anoth", "paramet"], "B_title": "", "B_clean_title": []},
{"A_title": "generic type Regression in being able to spoon GuavaIt seems that  #1218 introduced a regression on Guava project which is used by our CI to check the behaviour of Spoon see the trace :     See full stack trace:   https://ci.inria.fr/sos/job/Guava/262/console", "A_clean_title": ["gener", "type", "regress", "be", "abl", "spoon", "guavait", "guava", "it", "seem", "that", "1218", "introduc", "regress", "guava", "project", "which", "use", "by", "our", "ci", "check", "behaviour", "spoon", "see", "trace", "see", "full", "stack", "trace", "http", "inria", "ci", "fr", "so", "job", "guava", "262", "consol"], "B_title": "fix: fix regression regarding actual type arguments resolving (#1273)  close #1271", "B_clean_title": ["fix", "fix", "regress", "regard", "actual", "type", "argument", "resolv", "1273", "close", "1271"]},
{"A_title": "Early cancel calls can cause Tasks to not cancel properlyWhen a task receives the cancel() call before the operators are properly instantiated it can be that the operator never receives a cancel call.  In certain cases this causes the operator to hang.", "A_clean_title": ["earli", "cancel", "call", "caus", "task", "not", "cancel", "properlywhen", "properli", "when", "task", "receiv", "cancel", "call", "befor", "oper", "are", "properli", "instanti", "it", "that", "oper", "never", "receiv", "cancel", "call", "certain", "case", "thi", "caus", "oper", "hang"], "B_title": "streaming Fix case where early cancel messages do not properly cancel a stream operator.", "B_clean_title": ["stream", "fix", "case", "where", "earli", "cancel", "messag", "not", "properli", "cancel", "stream", "oper"]},
{"A_title": "Brent solver returns the wrong value if either bracket endpoint is rootThe solve(final UnivariateRealFunction f final double min final double max final double initial) function returns yMin or yMax if min or max are deemed to be roots respectively instead of min or max.", "A_clean_title": ["brent", "solver", "return", "wrong", "valu", "either", "bracket", "endpoint", "rootth", "root", "solv", "final", "univariaterealfunct", "univari", "real", "function", "final", "doubl", "min", "final", "doubl", "max", "final", "doubl", "initi", "function", "return", "ymin", "min", "or", "ymax", "max", "min", "or", "max", "are", "deem", "root", "respect", "instead", "min", "or", "max"], "B_title": "Fixed wrong return values when enpoints are roots in Brent solver with a user provided initial guess JIRA: MATH-344", "B_clean_title": ["fix", "wrong", "return", "valu", "when", "enpoint", "are", "root", "brent", "solver", "user", "provid", "initi", "guess", "jira", "math", "344"]},
{"A_title": "Improve identifier metadata detection for XML based entity mappings DATAJPA-658opened and commented I have a model in POJOs and my persistence configuration in a separated project with an orm.xml file. I want to expose my persistence API and I have detected that entities are only configured when they are annotated with persistence annotations (  @Id for example). We cannot annotate our entities as they come from a target model which we dont have the source code. It would be great that Spring Data REST were configurable using  orm.xml files or other .xml source apart from annotations. Thank you    Affects: 1.7.1 (Evans SR1) 1.8 M1 (Fowler)  Issue Links:     Referenced from: pull request #146  Backported to:  2.0.4 (Kay SR4)  1.11.11 (Ingalls SR11) 2 votes 6 watchers", "A_clean_title": ["improv", "identifi", "metadata", "detect", "xml", "base", "entiti", "map", "datajpa", "658open", "comment", "have", "model", "pojo", "poj", "os", "my", "persist", "configur", "separ", "project", "orm", "xml", "file", "want", "expos", "my", "persist", "api", "have", "detect", "that", "entiti", "are", "onli", "configur", "when", "they", "are", "annot", "persist", "annot", "id", "exampl", "we", "not", "annot", "our", "entiti", "as", "they", "come", "target", "model", "which", "we", "dont", "have", "sourc", "code", "it", "would", "great", "that", "spring", "data", "rest", "were", "configur", "orm", "xml", "file", "or", "other", "xml", "sourc", "apart", "annot", "thank", "you", "affect", "evan", "sr1", "m1", "fowler", "issu", "link", "referenc", "pull", "request", "146", "backport", "kay", "sr4", "11", "11", "ingal", "sr11", "vote", "watcher"], "B_title": "DATAJPA-658 - Fixed potential NullPointerException in JpaMetamodel.  When iterating over EntityType<?> we need to guard against ….getJavaType() returning null. That seems to be the case for Hibernate Envers which apparently registers EntityType instances without a backing type.  Original pull request: #146.", "B_clean_title": ["datajpa", "658", "fix", "potenti", "nullpointerexcept", "null", "pointer", "except", "jpametamodel", "jpa", "metamodel", "when", "iter", "over", "entitytyp", "entiti", "type", "we", "need", "guard", "against", "getjavatyp", "get", "java", "type", "return", "null", "that", "seem", "case", "hibern", "enver", "which", "appar", "regist", "entitytyp", "entiti", "type", "instanc", "without", "back", "type", "origin", "pull", "request", "146"]},
{"A_title": "TarMK compaction can create mixed segmentsAs described in http://markmail.org/message/ujkqdlthudaortxf commits that occur while the compaction operation is running can make the compacted segments contain references to older data segments which prevents old data from being reclaimed during cleanup.", "A_clean_title": ["tarmk", "tar", "mk", "compact", "creat", "mix", "segmentsa", "segment", "as", "describ", "http", "markmail", "org", "messag", "ujkqdlthudaortxf", "commit", "that", "occur", "while", "compact", "oper", "run", "make", "compact", "segment", "contain", "refer", "older", "data", "segment", "which", "prevent", "old", "data", "be", "reclaim", "dure", "cleanup"], "B_title": "TarMK compaction can create mixed segments  - allowed the compactor to take into consideration the initial state", "B_clean_title": ["tarmk", "tar", "mk", "compact", "creat", "mix", "segment", "allow", "compactor", "take", "into", "consider", "initi", "state"]},
{"A_title": "FencedFeedbackPanel is broken with RefreshingView(and its implementations)FencedFeedbackPanel doesnt work correctly if inner form(s) are in RefreshingView(or its implementations).. in this case outerform feedbackpanel just starts including messages meant for inner feedbackpanel. with ListView FencedFeedbackPanel works correctly.. actually one user(Mike Dundee) created this issue in quickview https://github.com/vineetsemwal/quickview/issues/19  so in that link he has described his problem and pasted the code you can use to reproduce ... there i have also explained why its broken with RefreshingView and its implementations currently(its a little complex so i am trying to avoid explaining all again also english is not my first language :-) )   thank you !", "A_clean_title": ["fencedfeedbackpanel", "fenc", "feedback", "panel", "broken", "refreshingview", "refresh", "view", "it", "implement", "fencedfeedbackpanel", "fenc", "feedback", "panel", "doesnt", "work", "correctli", "inner", "form", "are", "refreshingview", "refresh", "view", "or", "it", "implement", "thi", "case", "outerform", "feedbackpanel", "just", "start", "includ", "messag", "meant", "inner", "feedbackpanel", "listview", "list", "view", "fencedfeedbackpanel", "fenc", "feedback", "panel", "work", "correctli", "actual", "one", "user", "mike", "dunde", "creat", "thi", "issu", "quickview", "http", "github", "com", "vineetsemw", "quickview", "issu", "19", "so", "that", "link", "he", "ha", "describ", "hi", "problem", "past", "code", "you", "use", "reproduc", "there", "have", "also", "explain", "whi", "it", "broken", "refreshingview", "refresh", "view", "it", "implement", "current", "it", "littl", "complex", "so", "am", "tri", "avoid", "explain", "all", "again", "also", "english", "not", "my", "first", "languag", "thank", "you"], "B_title": "recreate fence mark when removing and readding a fencedfeedbackpanel", "B_clean_title": ["recreat", "fenc", "mark", "when", "remov", "read", "fencedfeedbackpanel"]},
{"A_title": "RegExFilter does not properly regex when using multi-byte charactersThe current RegExFilter class uses a ByteArrayBackedCharSequence to set the data to match against. The ByteArrayBackedCharSequence contains a line of code that prevents the matcher from properly matching multi-byte characters.  Line 49 of ByteArrayBackedCharSequence.java is: return (char) (0xff & dataoffset + index);                                                                                                This incorrectly casts a single byte from the byte array to a char which is 2 bytes in Java. This prevents the RegExFilter from properly performing Regular Expressions on multi-byte character encoded values.  A patch for the RegExFilter.java file has been created and will be submitted.", "A_clean_title": ["regexfilt", "reg", "ex", "filter", "not", "properli", "regex", "when", "multi", "byte", "charactersth", "charact", "current", "regexfilt", "reg", "ex", "filter", "class", "use", "bytearraybackedcharsequ", "byte", "array", "back", "char", "sequenc", "set", "data", "match", "against", "bytearraybackedcharsequ", "byte", "array", "back", "char", "sequenc", "contain", "line", "code", "that", "prevent", "matcher", "properli", "match", "multi", "byte", "charact", "line", "49", "bytearraybackedcharsequ", "java", "byte", "array", "back", "char", "sequenc", "return", "char", "0xff", "dataoffset", "index", "thi", "incorrectli", "cast", "singl", "byte", "byte", "array", "char", "which", "byte", "java", "thi", "prevent", "regexfilt", "reg", "ex", "filter", "properli", "perform", "regular", "express", "multi", "byte", "charact", "encod", "valu", "patch", "regexfilt", "java", "reg", "ex", "filter", "file", "ha", "been", "creat", "will", "submit"], "B_title": "applied patch", "B_clean_title": ["appli", "patch"]},
{"A_title": "ArrayUtils.add(T array T element) can create unexpected ClassCastExceptionArrayUtils.add(T array T element) can create an unexpected ClassCastException. For example the following code compiles without a warning:  String sa = ArrayUtils.add(stringArray aString);   and works fine provided at least one of the parameters is non-null. However if both parameters are null the add() method returns an Object array hence the Exception. If both parameters are null its not possible to determine the correct array type to return so it seems to me this should be disallowed. I think the method ought to be changed to throw IllegalParameterException when both parameters are null.", "A_clean_title": ["arrayutil", "add", "array", "util", "array", "element", "creat", "unexpect", "classcastexceptionarrayutil", "add", "class", "cast", "except", "array", "util", "array", "element", "creat", "unexpect", "classcastexcept", "class", "cast", "except", "exampl", "follow", "code", "compil", "without", "warn", "string", "sa", "arrayutil", "add", "array", "util", "stringarray", "string", "array", "astr", "string", "work", "fine", "provid", "at", "least", "one", "paramet", "non", "null", "howev", "both", "paramet", "are", "null", "add", "method", "return", "object", "array", "henc", "except", "both", "paramet", "are", "null", "it", "not", "possibl", "determin", "correct", "array", "type", "return", "so", "it", "seem", "me", "thi", "disallow", "think", "method", "ought", "chang", "throw", "illegalparameterexcept", "illeg", "paramet", "except", "when", "both", "paramet", "are", "null"], "B_title": "ArrayUtils.add(T array offset T element) can create unexpected ClassCastException", "B_clean_title": ["arrayutil", "add", "array", "util", "array", "offset", "element", "creat", "unexpect", "classcastexcept", "class", "cast", "except"]},
{"A_title": "delete mutations not working through the ProxyAru Sahni writes:  quote Im new to Accumulo and am still trying to wrap my head around its ways. To further that challenge Im using Pyaccumulo which doesnt present much in terms of available reference material.  Right now Im trying to understand how Accumulo manages record (key-value pair) deletions.  conn = Accumulo(host port user password) table = test_table conn.create_table(table) writer = conn.create_batch_writer(table) mut = Mutation(mut_01) mut.put(cf=item cq=name value=car) writer.add_mutation(mut) writer.close() conn.close()  Will generate a record (found via a shell scan):  mut_01 item:name     car  However the subsequent mutation...  writer = conn.create_batch_writer(table) mut = Mutation(mut_01) mut.put(cf=item cq=name is_delete=True) writer.add_mutation(mut) writer.close()  Results in:  mut_01 item:name   How should one expect the deleted row to be represented? That record sticks around even after I force a compaction of the table.  I was expecting it to not show up in any iterators or at least provide an easy way to see if the cell has been deleted. quote  ~ecn has confirmed the problem.", "A_clean_title": ["delet", "mutat", "not", "work", "through", "proxyaru", "proxi", "aru", "sahni", "write", "quot", "im", "new", "accumulo", "am", "still", "tri", "wrap", "my", "head", "around", "it", "way", "further", "that", "challeng", "im", "pyaccumulo", "which", "doesnt", "present", "much", "term", "avail", "refer", "materi", "right", "now", "im", "tri", "understand", "how", "accumulo", "manag", "record", "key", "valu", "pair", "delet", "conn", "accumulo", "host", "port", "user", "password", "tabl", "test", "tabl", "conn", "creat", "tabl", "tabl", "writer", "conn", "creat", "batch", "writer", "tabl", "mut", "mutat", "mut", "01", "mut", "put", "cf=item", "cq=name", "value=car", "writer", "add", "mutat", "mut", "writer", "close", "conn", "close", "will", "gener", "record", "found", "via", "shell", "scan", "mut", "01", "item", "name", "car", "howev", "subsequ", "mutat", "writer", "conn", "creat", "batch", "writer", "tabl", "mut", "mutat", "mut", "01", "mut", "put", "cf=item", "cq=name", "delete=tru", "writer", "add", "mutat", "mut", "writer", "close", "result", "mut", "01", "item", "name", "how", "one", "expect", "delet", "row", "repres", "that", "record", "stick", "around", "even", "after", "forc", "compact", "tabl", "wa", "expect", "it", "not", "show", "up", "ani", "iter", "or", "at", "least", "provid", "easi", "way", "see", "cell", "ha", "been", "delet", "quot", "~ecn", "ha", "confirm", "problem"], "B_title": "fix deletes added test", "B_clean_title": ["fix", "delet", "ad", "test"]},
{"A_title": "Repository upgrade does not copy default values of property definitionsThe RepositoryUpgrade class needs to copy also the default values of property definitions in the node types being upgraded. See the TODO in https://github.com/apache/jackrabbit-oak/blob/jackrabbit-oak-0.20.0/oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java#L485.", "A_clean_title": ["repositori", "upgrad", "not", "copi", "default", "valu", "properti", "definitionsth", "definit", "repositoryupgrad", "repositori", "upgrad", "class", "need", "copi", "also", "default", "valu", "properti", "definit", "node", "type", "be", "upgrad", "see", "todo", "http", "oak", "oak", "blob", "jackrabbit", "20", "java", "github", "com", "apach", "jackrabbit", "oak", "upgrad", "src", "main", "java", "org", "apach", "jackrabbit", "oak", "upgrad", "repositoryupgrad", "repositori", "upgrad", "l485"], "B_title": "Repository upgrade does not copy default values of property definitions Copy default values of property definitions during upgrade", "B_clean_title": ["repositori", "upgrad", "not", "copi", "default", "valu", "properti", "definit", "copi", "default", "valu", "properti", "definit", "dure", "upgrad"]},
{"A_title": "NumberUtils.isNumber(String)  is not right when the String is 1.1L1.1L  is not a Java Number . but NumberUtils.isNumber(String) return true. perhaps change:              if (charsi == l                 || charsi == L)                  // not allowing L with an exponent                 return foundDigit && !hasExp;                to:              if (charsi == l                 || charsi == L)                  // not allowing L with an exponent                 return foundDigit && !hasExp && !hasDecPoint;", "A_clean_title": ["numberutil", "isnumb", "number", "util", "number", "string", "not", "right", "when", "string", "1l1", "1l", "not", "java", "number", "but", "numberutil", "isnumb", "number", "util", "number", "string", "return", "true", "perhap", "chang", "charsi", "charsi", "not", "allow", "expon", "return", "founddigit", "found", "digit", "hasexp", "ha", "exp", "charsi", "charsi", "not", "allow", "expon", "return", "founddigit", "found", "digit", "hasexp", "ha", "exp", "hasdecpoint", "ha", "dec", "point"], "B_title": "Fixing NumberUtils.isNumber so that 1.1L is not considered a number. LANG-664", "B_clean_title": ["fix", "numberutil", "isnumb", "number", "util", "number", "so", "that", "1l", "not", "consid", "number", "lang", "664"]},
{"A_title": "Compiler fails to find amd module in a subdirectoryNone", "A_clean_title": ["compil", "fail", "find", "amd", "modul", "subdirectorynon", "subdirectori", "none"], "B_title": "counter DOS shell file name normalization fixes issue 824", "B_clean_title": ["counter", "do", "shell", "file", "name", "normal", "fix", "issu", "824"]},
{"A_title": "Full-text search on the traversing index fails if the condition contains a slashA full-text search on the traversing index falls back to a sort of manual evaluation of results.  This is handled by the _FullTextTerm_ class and it appears that it passes the constraint text through a cleanup process where it strips most of the characters that are neither _Character.isLetterOrDigit(c)_ not in the list _+-:&_  Im not exactly sure where this list comes from but I see the / character is missing which causes a certain type of query to fail.  Example: code //*jcr:contains(. text/plain) code", "A_clean_title": ["full", "text", "search", "travers", "index", "fail", "condit", "contain", "slasha", "slash", "full", "text", "search", "travers", "index", "fall", "back", "sort", "manual", "evalu", "result", "thi", "handl", "by", "fulltextterm", "full", "text", "term", "class", "it", "appear", "that", "it", "pass", "constraint", "text", "through", "cleanup", "process", "where", "it", "strip", "most", "charact", "that", "are", "neither", "isletterordigit", "charact", "letter", "or", "digit", "not", "list", "im", "not", "exactli", "sure", "where", "thi", "list", "come", "but", "see", "charact", "miss", "which", "caus", "certain", "type", "queri", "fail", "exampl", "code", "jcr", "contain", "text", "plain", "code"], "B_title": "Full-text search on the traversing index fails if the condition contains a slash  - added dot character to the full-text checks", "B_clean_title": ["full", "text", "search", "travers", "index", "fail", "condit", "contain", "slash", "ad", "dot", "charact", "full", "text", "check"]},
{"A_title": "Ajax buttons inside ModalWindows dont submit properlyI have a ModalWindow that contains an IndicatingAjaxButton. When I click the button I get a big Java error complaining that the form submit wasnt multipart.  Digging into the javascript in wicket-ajax.js I found this from line 1102 in the method handleMultipart  code multipart=multipart||form.enctype==multipart/form-data;  if (multipart==false)       // nothing to handle     return false;   code  When this executed multipart was false and enctype was  and therefore the submit aborted. This may be the cause.  Heres the Java stacktrace  noformat java.lang.IllegalStateException: ServletRequest does not contain multipart content at org.apache.wicket.protocol.http.servlet.MultipartServletWebRequest.<init>(MultipartServletWebRequest.java:113) at org.apache.wicket.protocol.http.servlet.MultipartServletWebRequest.<init>(MultipartServletWebRequest.java:83) at org.apache.wicket.extensions.ajax.markup.html.form.upload.MultipartRequest.<init>(MultipartRequest.java:41) at org.apache.wicket.extensions.ajax.markup.html.form.upload.UploadWebRequest.newMultipartWebRequest(UploadWebRequest.java:66) at org.apache.wicket.markup.html.form.Form.handleMultiPart(Form.java:1651) at org.apache.wicket.markup.html.form.Form.onFormSubmitted(Form.java:850) at org.apache.wicket.ajax.form.AjaxFormSubmitBehavior.onEvent(AjaxFormSubmitBehavior.java:135) at org.apache.wicket.ajax.AjaxEventBehavior.respond(AjaxEventBehavior.java:177) at org.apache.wicket.ajax.AbstractDefaultAjaxBehavior.onRequest(AbstractDefaultAjaxBehavior.java:299) at org.apache.wicket.request.target.component.listener.BehaviorRequestTarget.processEvents(BehaviorRequestTarget.java:119) at org.apache.wicket.request.AbstractRequestCycleProcessor.processEvents(AbstractRequestCycleProcessor.java:92) at org.apache.wicket.RequestCycle.processEventsAndRespond(RequestCycle.java:1250) at org.apache.wicket.RequestCycle.step(RequestCycle.java:1329) at org.apache.wicket.RequestCycle.steps(RequestCycle.java:1428) at org.apache.wicket.RequestCycle.request(RequestCycle.java:545) at org.apache.wicket.protocol.http.WicketFilter.doGet(WicketFilter.java:479) at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:312) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235) noformat", "A_clean_title": ["ajax", "button", "insid", "modalwindow", "modal", "window", "dont", "submit", "properlyi", "properli", "have", "modalwindow", "modal", "window", "that", "contain", "indicatingajaxbutton", "indic", "ajax", "button", "when", "click", "button", "get", "big", "java", "error", "complain", "that", "form", "submit", "wasnt", "multipart", "dig", "into", "javascript", "wicket", "ajax", "js", "found", "thi", "line", "1102", "method", "handlemultipart", "handl", "multipart", "code", "data", "multipart=multipart||form", "enctype==multipart", "form", "multipart==fals", "noth", "handl", "return", "fals", "code", "when", "thi", "execut", "multipart", "wa", "fals", "enctyp", "wa", "therefor", "submit", "abort", "thi", "may", "caus", "here", "java", "stacktrac", "noformat", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "servletrequest", "servlet", "request", "not", "contain", "multipart", "content", "at", "org", "apach", "wicket", "protocol", "http", "servlet", "multipartservletwebrequest", "multipart", "servlet", "web", "request", "init", "multipartservletwebrequest", "java:113", "multipart", "servlet", "web", "request", "at", "org", "apach", "wicket", "protocol", "http", "servlet", "multipartservletwebrequest", "multipart", "servlet", "web", "request", "init", "multipartservletwebrequest", "java:83", "multipart", "servlet", "web", "request", "at", "org", "apach", "wicket", "extens", "ajax", "markup", "html", "form", "upload", "multipartrequest", "multipart", "request", "init", "multipartrequest", "java:41", "multipart", "request", "at", "org", "apach", "wicket", "extens", "ajax", "markup", "html", "form", "upload", "uploadwebrequest", "newmultipartwebrequest", "upload", "web", "request", "new", "multipart", "web", "request", "uploadwebrequest", "java:66", "upload", "web", "request", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "handlemultipart", "handl", "multi", "part", "form", "java:1651", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "onformsubmit", "form", "submit", "form", "java:850", "at", "org", "apach", "wicket", "ajax", "form", "ajaxformsubmitbehavior", "onev", "ajax", "form", "submit", "behavior", "event", "ajaxformsubmitbehavior", "java:135", "ajax", "form", "submit", "behavior", "at", "org", "apach", "wicket", "ajax", "ajaxeventbehavior", "respond", "ajax", "event", "behavior", "ajaxeventbehavior", "java:177", "ajax", "event", "behavior", "at", "org", "apach", "wicket", "ajax", "abstractdefaultajaxbehavior", "onrequest", "abstract", "default", "ajax", "behavior", "request", "abstractdefaultajaxbehavior", "java:299", "abstract", "default", "ajax", "behavior", "at", "org", "apach", "wicket", "request", "target", "compon", "listen", "behaviorrequesttarget", "processev", "behavior", "request", "target", "process", "event", "behaviorrequesttarget", "java:119", "behavior", "request", "target", "at", "org", "apach", "wicket", "request", "abstractrequestcycleprocessor", "processev", "abstract", "request", "cycl", "processor", "process", "event", "abstractrequestcycleprocessor", "java:92", "abstract", "request", "cycl", "processor", "at", "org", "apach", "wicket", "requestcycl", "processeventsandrespond", "request", "cycl", "process", "event", "respond", "requestcycl", "java:1250", "request", "cycl", "at", "org", "apach", "wicket", "requestcycl", "step", "request", "cycl", "requestcycl", "java:1329", "request", "cycl", "at", "org", "apach", "wicket", "requestcycl", "step", "request", "cycl", "requestcycl", "java:1428", "request", "cycl", "at", "org", "apach", "wicket", "requestcycl", "request", "request", "cycl", "requestcycl", "java:545", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "doget", "wicket", "filter", "get", "wicketfilt", "java:479", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:312", "wicket", "filter", "at", "org", "apach", "catalina", "core", "applicationfilterchain", "internaldofilt", "applic", "filter", "chain", "intern", "filter", "applicationfilterchain", "java:235", "applic", "filter", "chain", "noformat"], "B_title": "Issue: WICKET-2621", "B_clean_title": ["issu", "wicket", "2621"]},
{"A_title": "ProxyServer does not set column information on BatchScannerThe createScanner method uses the options from the thrift request to call fetchColumn() and fetchColumnFamily(). The createBatchScanner should be doing have the same feature though the statements are absent from the code.", "A_clean_title": ["proxyserv", "proxi", "server", "not", "set", "column", "inform", "batchscannerth", "batch", "scanner", "createscann", "creat", "scanner", "method", "use", "option", "thrift", "request", "call", "fetchcolumn", "fetch", "column", "fetchcolumnfamili", "fetch", "column", "famili", "createbatchscann", "creat", "batch", "scanner", "do", "have", "same", "featur", "though", "statement", "are", "absent", "code"], "B_title": "applying patch from Corey Nolet", "B_clean_title": ["appli", "patch", "corey", "nolet"]},
{"A_title": "Dependency sorting with closurePass set to false no longer works.None", "A_clean_title": ["depend", "sort", "closurepass", "closur", "pass", "set", "fals", "no", "longer", "work", "none"], "B_title": "Allow dependency sorting even when closure pass is off. Fixes issue 768", "B_clean_title": ["allow", "depend", "sort", "even", "when", "closur", "pass", "off", "fix", "issu", "768"]},
{"A_title": "Do not use the parsed PageParameters when re-creating an expired pageWICKET-4014 and WICKET-4290 provided functionality to re-create an expired page if there is a mount path in the current requests url. There is a minor problem with that because the page parameters are passed to the freshly created page. I.e. parameters for a callback behavior are now set as page construction parameters. Since the execution of the behavior is ignored for the recreated page these parameters should be ignored too.", "A_clean_title": ["not", "use", "pars", "pageparamet", "page", "paramet", "when", "re", "creat", "expir", "pagewicket", "4014", "page", "wicket", "wicket", "4290", "provid", "function", "re", "creat", "expir", "page", "there", "mount", "path", "current", "request", "url", "there", "minor", "problem", "that", "becaus", "page", "paramet", "are", "pass", "freshli", "creat", "page", "paramet", "callback", "behavior", "are", "now", "set", "as", "page", "construct", "paramet", "sinc", "execut", "behavior", "ignor", "recreat", "page", "these", "paramet", "ignor", "too"], "B_title": "added test that stateless pages get page parameters", "B_clean_title": ["ad", "test", "that", "stateless", "page", "get", "page", "paramet"]},
{"A_title": "UrlRenderer renders invalid relative URLs if first segment contains colonSeen on Wicket 1.5.3.  If a relative url of a link starts with a path segment containing a colon then the whole uri will be regarded as absolute uri so typically browsers will complain that there is no handle for the protocol foo in foo:bar/dee/per.  See also the attached quickstart. The start page contains three links one relative with colon one absolute and one to a mounted page without colon for comparison. The application also has a static switch to add an extended urlrenderer prepending ./ if needed. This fix is merely a quick shot and there might be better alternatives.", "A_clean_title": ["urlrender", "url", "render", "render", "invalid", "rel", "url", "ur", "ls", "first", "segment", "contain", "colonseen", "colon", "seen", "wicket", "rel", "url", "link", "start", "path", "segment", "contain", "colon", "then", "whole", "uri", "will", "regard", "as", "absolut", "uri", "so", "typic", "browser", "will", "complain", "that", "there", "no", "handl", "protocol", "foo", "foo", "bar", "dee", "per", "see", "also", "attach", "quickstart", "start", "page", "contain", "three", "link", "one", "rel", "colon", "one", "absolut", "one", "mount", "page", "without", "colon", "comparison", "applic", "also", "ha", "static", "switch", "add", "extend", "urlrender", "prepend", "need", "thi", "fix", "mere", "quick", "shot", "there", "might", "better", "altern"], "B_title": "remove leading dot in sendRedirect()", "B_clean_title": ["remov", "lead", "dot", "sendredirect", "send", "redirect"]},
{"A_title": "int overflow with orderby causing huge slowdownConsider the following query: code //element(*slingevent:Job) order by @slingevent:created ascending code this query - when running with a large number of slingevent:Job around - will take a very long time due to the fact that FilterIterators.SortIterator.init() in the following loop: code if (list.size() > max * 2)    // remove tail entries right now to save memory   Collections.sort(list orderBy);   keepFirst(list max);  code does a multiplication with max which is by default set to Integer.MAX_VALUE (see FilterIterators.newCombinedFilter). This results in max *2 to overflow (result is -2) - thus that init-loop will sort the list for every additional entry. Which is definitely not the intention.", "A_clean_title": ["int", "overflow", "orderbi", "caus", "huge", "slowdownconsid", "slowdown", "consid", "follow", "queri", "code", "element", "slingev", "job", "order", "by", "slingev", "creat", "ascend", "code", "thi", "queri", "when", "run", "larg", "number", "slingev", "job", "around", "will", "take", "veri", "long", "time", "due", "fact", "that", "filteriter", "sortiter", "init", "filter", "iter", "sort", "iter", "follow", "loop", "code", "list", "size", "max", "remov", "tail", "entri", "right", "now", "save", "memori", "collect", "sort", "list", "orderbi", "order", "by", "keepfirst", "keep", "first", "list", "max", "code", "multipl", "max", "which", "by", "default", "set", "integ", "max", "valu", "see", "filteriter", "newcombinedfilt", "filter", "iter", "new", "combin", "filter", "thi", "result", "max", "overflow", "result", "thu", "that", "init", "loop", "will", "sort", "list", "everi", "addit", "entri", "which", "definit", "not", "intent"], "B_title": "int overflow with orderby causing huge slowdown", "B_clean_title": ["int", "overflow", "orderbi", "caus", "huge", "slowdown"]},
{"A_title": "@JsonIdentityReference not used when setup on class onlyI am trying to setup @JsonIdentityInfo/@JsonIdentityReference in order to serialize all references to a given class as Object Id (and deserialize them later using a custom ObjectIdResolver to retrieve the proper referenced instance)  I use @JsonIdentityReference(alwaysAsId=true) in order to enforce exporting the object id in all cases.  It does not work as expected when I define the annotation only on the class (but it works fine when I set it directly on the property). I would rather not have to define it on every property as I will probably miss some... From what I see in  BeanSerializerBase  the alwaysAsId is reset when not ObjectIdInfo is found on the accessor:   Shouldnt it be kept to the current value when no override is found ?  I tried to set it back in the default ObjectIdInfo created with NAME_FOR_OBJECT_REF but I am not sure if this is the right way to fix this. Here is test I added in  TestObjectIdSerialization for this case:", "A_clean_title": ["jsonidentityrefer", "json", "ident", "refer", "not", "use", "when", "setup", "class", "onlyi", "onli", "am", "tri", "setup", "jsonidentityinfo", "json", "ident", "info", "jsonidentityrefer", "json", "ident", "refer", "order", "serial", "all", "refer", "given", "class", "as", "object", "id", "deseri", "them", "later", "custom", "objectidresolv", "object", "id", "resolv", "retriev", "proper", "referenc", "instanc", "use", "jsonidentityrefer", "json", "ident", "refer", "alwaysasid=tru", "alway", "as", "id=tru", "order", "enforc", "export", "object", "id", "all", "case", "it", "not", "work", "as", "expect", "when", "defin", "annot", "onli", "class", "but", "it", "work", "fine", "when", "set", "it", "directli", "properti", "would", "rather", "not", "have", "defin", "it", "everi", "properti", "as", "will", "probabl", "miss", "some", "what", "see", "beanserializerbas", "bean", "serial", "base", "alwaysasid", "alway", "as", "id", "reset", "when", "not", "objectidinfo", "object", "id", "info", "found", "accessor", "shouldnt", "it", "kept", "current", "valu", "when", "no", "overrid", "found", "tri", "set", "it", "back", "default", "objectidinfo", "object", "id", "info", "creat", "name", "object", "ref", "but", "am", "not", "sure", "thi", "right", "way", "fix", "thi", "here", "test", "ad", "testobjectidseri", "test", "object", "id", "serial", "thi", "case"], "B_title": "Fix #1607", "B_clean_title": ["fix", "1607"]},
{"A_title": "math Complex Tanh for big numbersHi In Complex.java the tanh is computed with the following formula: tanh(a + bi) = sinh(2a)/(cosh(2a)+cos(2b)) + sin(2b)/(cosh(2a)+cos(2b))i The problem that Im finding is that as soon as a is a big number both sinh(2a) and cosh(2a) are infinity and then the method tanh returns in the real part NaN (infinity/infinity) when it should return 1.0. Wouldnt it be appropiate to add something as in the FastMath library??: if (real>20.0)       return createComplex(1.0 0.0);  if (real<-20.0)       return createComplex(-1.0 0.0);  Best regards JBB", "A_clean_title": ["math", "complex", "tanh", "big", "numbershi", "number", "hi", "complex", "java", "tanh", "comput", "follow", "formula", "tanh", "bi", "sinh", "2a", "cosh", "2a", "+co", "2b", "sin", "2b", "cosh", "2a", "+co", "2b", "problem", "that", "im", "find", "that", "as", "soon", "as", "big", "number", "both", "sinh", "2a", "cosh", "2a", "are", "infin", "then", "method", "tanh", "return", "real", "part", "nan", "na", "infin", "infin", "when", "it", "return", "wouldnt", "it", "appropi", "add", "someth", "as", "fastmath", "fast", "math", "librari", "real", "20", "return", "createcomplex", "creat", "complex", "real", "20", "return", "createcomplex", "creat", "complex", "best", "regard", "jbb"], "B_title": "Introduced tests to guard against overflow (MATH-722). Corrected Javadoc and updated unit tests accordingly.", "B_clean_title": ["introduc", "test", "guard", "against", "overflow", "math", "722", "correct", "javadoc", "updat", "unit", "test", "accordingli"]},
{"A_title": "Links with multiple parameters are wrongly generatedIf you have a PageParameters with multiple params then the resulting link will be something like this /url?id=123&amp;sid=456 so for some reason the & sign is encoded to &amp; which will result in the following parameters on the receiving page: id=123 amp;sid=456 See the attached quickstart for example.", "A_clean_title": ["link", "multipl", "paramet", "are", "wrongli", "generatedif", "gener", "you", "have", "pageparamet", "page", "paramet", "multipl", "param", "then", "result", "link", "will", "someth", "like", "thi", "url", "id=123", "amp", "sid=456", "so", "some", "reason", "sign", "encod", "amp", "which", "will", "result", "follow", "paramet", "receiv", "page", "id=123", "amp", "sid=456", "see", "attach", "quickstart", "exampl"], "B_title": "Links with multiple parameters are wrongly generated WICKET-2829 Tag attributes values are not escaped properly during writeOutput", "B_clean_title": ["link", "multipl", "paramet", "are", "wrongli", "gener", "wicket", "2829", "tag", "attribut", "valu", "are", "not", "escap", "properli", "dure", "writeoutput", "write", "output"]},
{"A_title": "Evaluation with restriction is not consistent with parent ACLsconsider the following ACL setup:  noformat testuser allow rep:readrep:write      /testroot testuser deny  jcr:removeNode /testroot/a  glob=*/c testuser allow jcr:removeNode /testroot/a  glob=*/b noformat  now: hasPermission(/tesroot/a/b/c jcr:removeNode) == false but the user is still able to delete the node.  * if we change the order of the ACEs with the restriction it works (i.e. the user cant delete) * if we use direct ACLs on the respective nodes it works  I think this is a bug...but Im not sure if hasPermission is wrong or the check during node deletion.", "A_clean_title": ["evalu", "restrict", "not", "consist", "parent", "aclsconsid", "ac", "lsconsid", "follow", "acl", "setup", "noformat", "testus", "allow", "rep", "readrep", "write", "testroot", "testus", "deni", "jcr", "removenod", "remov", "node", "testroot", "glob=", "testus", "allow", "jcr", "removenod", "remov", "node", "testroot", "glob=", "noformat", "now", "haspermiss", "ha", "permiss", "tesroot", "jcr", "removenod", "remov", "node", "fals", "but", "user", "still", "abl", "delet", "node", "we", "chang", "order", "ace", "ac", "es", "restrict", "it", "work", "user", "cant", "delet", "we", "use", "direct", "acl", "ac", "ls", "respect", "node", "it", "work", "think", "thi", "bug", "but", "im", "not", "sure", "haspermiss", "ha", "permiss", "wrong", "or", "check", "dure", "node", "delet"], "B_title": "Evaluation with restriction is not consistent with parent ACLs", "B_clean_title": ["evalu", "restrict", "not", "consist", "parent", "acl", "ac", "ls"]},
{"A_title": "ArrayIndexOutOfBoundsException on impossible non-static inner class constructorMinimal repro:     Fails like this:   Validation is missing for this impossible constructor. Works as expected when  InnerSomething is static.", "A_clean_title": ["arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "imposs", "non", "static", "inner", "class", "constructorminim", "constructor", "minim", "repro", "fail", "like", "thi", "valid", "miss", "thi", "imposs", "constructor", "work", "as", "expect", "when", "innersometh", "inner", "someth", "static"], "B_title": "Fix #1501", "B_clean_title": ["fix", "1501"]},
{"A_title": "Hierarchy conflict detection brokenHierarchy conflict detection is broken in 1.0.14. It may happen that a child document is created even though the parent is considered deleted.", "A_clean_title": ["hierarchi", "conflict", "detect", "brokenhierarchi", "broken", "hierarchi", "conflict", "detect", "broken", "14", "it", "may", "happen", "that", "child", "document", "creat", "even", "though", "parent", "consid", "delet"], "B_title": "Hierarchy conflict detection broken", "B_clean_title": ["hierarchi", "conflict", "detect", "broken"]},
{"A_title": "BigFraction.doubleValue() returns Double.NaN for large numerators or denominatorsThe current implementation of doubleValue() divides numerator.doubleValue() / denominator.doubleValue().  BigInteger.doubleValue() fails for any number greater than Double.MAX_VALUE.  So if the user has 308-digit numerator or denominator the resulting quotient fails even in cases where the result would be well inside Doubles range. I have a patch to fix it if I can figure out how to attach it here I will.", "A_clean_title": ["bigfract", "doublevalu", "big", "fraction", "doubl", "valu", "return", "doubl", "nan", "na", "larg", "numer", "or", "denominatorsth", "denomin", "current", "implement", "doublevalu", "doubl", "valu", "divid", "numer", "doublevalu", "doubl", "valu", "denomin", "doublevalu", "doubl", "valu", "biginteg", "doublevalu", "big", "integ", "doubl", "valu", "fail", "ani", "number", "greater", "than", "doubl", "max", "valu", "so", "user", "ha", "308", "digit", "numer", "or", "denomin", "result", "quotient", "fail", "even", "case", "where", "result", "would", "well", "insid", "doubl", "rang", "have", "patch", "fix", "it", "figur", "out", "how", "attach", "it", "here", "will"], "B_title": "Fixed doubleValue() and floatValue() when numerator and denominator are larger than the range of the corresponding primitive type.", "B_clean_title": ["fix", "doublevalu", "doubl", "valu", "floatvalu", "float", "valu", "when", "numer", "denomin", "are", "larger", "than", "rang", "correspond", "primit", "type"]},
{"A_title": "CompactCommand description is incorrectThe compact command has the following description  code root@accumulo> compact -? usage: compact <table> <table> -? -b <begin-row> --cancel -e <end-row> -nf -ns <namespace> | -p <pattern> | -t <tableName>  -pn <profile>  -w description: sets all tablets for a table to major compact as soon as possible (based on current time)   -?--help                       display this help   -b--begin-row <begin-row>      begin row (inclusive)      --cancel                     cancel user initiated compactions   -e--end-row <end-row>          end row (inclusive)   -nf--noFlush                   do not flush table data in memory before compacting.   -ns--namespace <namespace>     name of a namespace to operate on   -p--pattern <pattern>          regex pattern of table names to operate on   -pn--profile <profile>         iterator profile name   -t--table <tableName>          name of a table to operate on   -w--wait                       wait for compact to finish code  However the --begin-row is not inclusive.  Here is a simple demonstration. code createtable compacttest addsplits a b c insert a 1   insert a 2   insert b 3   insert b 4   insert c 5   insert c 6   flush -w scan -t accumulo.metadata -np compact -b a -e c -t compacttest -w scan -t accumulo.metadata -np deletetable compacttest -f code  You will see that file associated with the a split is still a F flush file which the files in the b and c split are A files.  Not sure if the fix is to update the commands description which would be easy or to make the begin row actually inclusive.", "A_clean_title": ["compactcommand", "compact", "command", "descript", "incorrectth", "incorrect", "compact", "command", "ha", "follow", "descript", "code", "root", "accumulo", "compact", "usag", "compact", "tabl", "tabl", "begin", "row", "cancel", "end", "row", "nf", "ns", "namespac", "pattern", "tablenam", "tabl", "name", "pn", "profil", "descript", "set", "all", "tablet", "tabl", "major", "compact", "as", "soon", "as", "possibl", "base", "current", "time", "help", "display", "thi", "help", "begin", "row", "begin", "row", "begin", "row", "inclus", "cancel", "cancel", "user", "initi", "compact", "end", "row", "end", "row", "end", "row", "inclus", "nf", "noflush", "no", "flush", "not", "flush", "tabl", "data", "memori", "befor", "compact", "ns", "namespac", "namespac", "name", "namespac", "oper", "pattern", "pattern", "regex", "pattern", "tabl", "name", "oper", "pn", "profil", "profil", "iter", "profil", "name", "tabl", "tablenam", "tabl", "name", "name", "tabl", "oper", "wait", "wait", "compact", "finish", "code", "howev", "begin", "row", "not", "inclus", "here", "simpl", "demonstr", "code", "createt", "compacttest", "addsplit", "insert", "insert", "insert", "insert", "insert", "insert", "flush", "scan", "accumulo", "metadata", "np", "compact", "compacttest", "scan", "accumulo", "metadata", "np", "deletet", "compacttest", "code", "you", "will", "see", "that", "file", "associ", "split", "still", "flush", "file", "which", "file", "split", "are", "file", "not", "sure", "fix", "updat", "command", "descript", "which", "would", "easi", "or", "make", "begin", "row", "actual", "inclus"], "B_title": "Fix the description of -b options", "B_clean_title": ["fix", "descript", "option"]},
{"A_title": "Troublesome ExternalIdentityRef.equals(Object) implementationin the light of OAK-3508 i looked at the ExternalIdentifyRef class and found the following implementation of Object.equals(Object):  code public boolean equals(Object o)          try              // assuming that we never compare other types of classes             return this == o || string.equals(((ExternalIdentityRef) o).string);          catch (Exception e)              return false;               code  since this class is public and exported as part of a public API i dont think the assumption made in the code is justified. also i would argue that catching Exception is bad style as is exception driven development. in this particular case it was IMHO perfectly trivial to just get rid of the catch clause altogether.", "A_clean_title": ["troublesom", "externalidentityref", "equal", "extern", "ident", "ref", "object", "implementationin", "light", "oak", "3508", "look", "at", "externalidentifyref", "extern", "identifi", "ref", "class", "found", "follow", "implement", "object", "equal", "object", "code", "public", "boolean", "equal", "object", "tri", "assum", "that", "we", "never", "compar", "other", "type", "class", "return", "thi", "string", "equal", "externalidentityref", "extern", "ident", "ref", "string", "catch", "except", "return", "fals", "code", "sinc", "thi", "class", "public", "export", "as", "part", "public", "api", "dont", "think", "assumpt", "made", "code", "justifi", "also", "would", "argu", "that", "catch", "except", "bad", "style", "as", "except", "driven", "develop", "thi", "particular", "case", "it", "wa", "imho", "perfectli", "trivial", "just", "get", "rid", "catch", "claus", "altogeth"], "B_title": ": Troublesome ExternalIdentityRef.equals(Object) implementation", "B_clean_title": ["troublesom", "externalidentityref", "equal", "extern", "ident", "ref", "object", "implement"]},
{"A_title": "Failed task deployment causes NPE on input split assignmentThe input split assignment code is returning null if the Task has failed which is causing a NPE.  We should improve our error handling / reporting in that situation.  code 13:12:31002 INFO  org.apache.flink.yarn.ApplicationMaster  anonfun 2  anon 1    - Status of job c0b47ce41e9a85a628a628a3977705ef (Flink Java Job at Tue Apr 21 13:10:36 UTC 2015) changed to FAILING Cannot deploy task - TaskManager not responding.. .... 13:12:47591 ERROR org.apache.flink.runtime.operators.RegularPactTask            - Error in task code:  CHAIN DataSource (at userMethod (org.apache.flink.api.java.io.AvroInputFormat)) -> FlatMap (FlatMap at main(UserClass.java:111)) (20/50) java.lang.RuntimeException: Requesting the next InputSplit failed. at org.apache.flink.runtime.taskmanager.TaskInputSplitProvider.getNextInputSplit(TaskInputSplitProvider.java:88) at org.apache.flink.runtime.operators.DataSourceTask 1.hasNext(DataSourceTask.java:337) at org.apache.flink.runtime.operators.DataSourceTask.invoke(DataSourceTask.java:136) at org.apache.flink.runtime.execution.RuntimeEnvironment.run(RuntimeEnvironment.java:217) at java.lang.Thread.run(Thread.java:744) Caused by: java.lang.NullPointerException at java.io.ByteArrayInputStream.<init>(ByteArrayInputStream.java:106) at org.apache.flink.util.InstantiationUtil.deserializeObject(InstantiationUtil.java:301) at org.apache.flink.runtime.taskmanager.TaskInputSplitProvider.getNextInputSplit(TaskInputSplitProvider.java:83) ... 4 more 13:12:47595 INFO  org.apache.flink.runtime.taskmanager.Task                     - CHAIN DataSource (at SomeMethod (org.apache.flink.api.java.io.AvroInputFormat)) -> FlatMap (FlatMap at main(SomeClass.java:111)) (20/50) switched to FAILED : java.lang.RuntimeException: Requesting the next InputSplit failed. at org.apache.flink.runtime.taskmanager.TaskInputSplitProvider.getNextInputSplit(TaskInputSplitProvider.java:88) at org.apache.flink.runtime.operators.DataSourceTask 1.hasNext(DataSourceTask.java:337) at org.apache.flink.runtime.operators.DataSourceTask.invoke(DataSourceTask.java:136) at org.apache.flink.runtime.execution.RuntimeEnvironment.run(RuntimeEnvironment.java:217) at java.lang.Thread.run(Thread.java:744) Caused by: java.lang.NullPointerException at java.io.ByteArrayInputStream.<init>(ByteArrayInputStream.java:106) at org.apache.flink.util.InstantiationUtil.deserializeObject(InstantiationUtil.java:301) at org.apache.flink.runtime.taskmanager.TaskInputSplitProvider.getNextInputSplit(TaskInputSplitProvider.java:83) ... 4 more code", "A_clean_title": ["fail", "task", "deploy", "caus", "npe", "input", "split", "assignmentth", "assign", "input", "split", "assign", "code", "return", "null", "task", "ha", "fail", "which", "caus", "npe", "we", "improv", "our", "error", "handl", "report", "that", "situat", "code", "13:12:31002", "info", "org", "apach", "flink", "yarn", "applicationmast", "applic", "master", "anonfun", "anon", "statu", "job", "c0b47ce41e9a85a628a628a3977705ef", "flink", "java", "job", "at", "tue", "apr", "21", "13:10:36", "utc", "2015", "chang", "fail", "not", "deploy", "task", "taskmanag", "task", "manag", "not", "respond", "13:12:47591", "error", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "regular", "pact", "task", "error", "task", "code", "chain", "datasourc", "data", "sourc", "at", "usermethod", "user", "method", "org", "apach", "flink", "api", "java", "io", "avroinputformat", "avro", "input", "format", "flatmap", "flat", "map", "flatmap", "flat", "map", "at", "main", "userclass", "java:111", "user", "class", "20", "50", "java", "lang", "runtimeexcept", "runtim", "except", "request", "next", "inputsplit", "input", "split", "fail", "at", "org", "apach", "flink", "runtim", "taskmanag", "taskinputsplitprovid", "getnextinputsplit", "task", "input", "split", "provid", "get", "next", "input", "split", "taskinputsplitprovid", "java:88", "task", "input", "split", "provid", "at", "org", "apach", "flink", "runtim", "oper", "datasourcetask", "data", "sourc", "task", "hasnext", "ha", "next", "datasourcetask", "java:337", "data", "sourc", "task", "at", "org", "apach", "flink", "runtim", "oper", "datasourcetask", "invok", "data", "sourc", "task", "datasourcetask", "java:136", "data", "sourc", "task", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "run", "runtim", "environ", "runtimeenviron", "java:217", "runtim", "environ", "at", "java", "lang", "thread", "run", "thread", "java:744", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "java", "io", "bytearrayinputstream", "byte", "array", "input", "stream", "init", "bytearrayinputstream", "java:106", "byte", "array", "input", "stream", "at", "org", "apach", "flink", "util", "instantiationutil", "deserializeobject", "instanti", "util", "deseri", "object", "instantiationutil", "java:301", "instanti", "util", "at", "org", "apach", "flink", "runtim", "taskmanag", "taskinputsplitprovid", "getnextinputsplit", "task", "input", "split", "provid", "get", "next", "input", "split", "taskinputsplitprovid", "java:83", "task", "input", "split", "provid", "more", "13:12:47595", "info", "org", "apach", "flink", "runtim", "taskmanag", "task", "chain", "datasourc", "data", "sourc", "at", "somemethod", "some", "method", "org", "apach", "flink", "api", "java", "io", "avroinputformat", "avro", "input", "format", "flatmap", "flat", "map", "flatmap", "flat", "map", "at", "main", "someclass", "java:111", "some", "class", "20", "50", "switch", "fail", "java", "lang", "runtimeexcept", "runtim", "except", "request", "next", "inputsplit", "input", "split", "fail", "at", "org", "apach", "flink", "runtim", "taskmanag", "taskinputsplitprovid", "getnextinputsplit", "task", "input", "split", "provid", "get", "next", "input", "split", "taskinputsplitprovid", "java:88", "task", "input", "split", "provid", "at", "org", "apach", "flink", "runtim", "oper", "datasourcetask", "data", "sourc", "task", "hasnext", "ha", "next", "datasourcetask", "java:337", "data", "sourc", "task", "at", "org", "apach", "flink", "runtim", "oper", "datasourcetask", "invok", "data", "sourc", "task", "datasourcetask", "java:136", "data", "sourc", "task", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "run", "runtim", "environ", "runtimeenviron", "java:217", "runtim", "environ", "at", "java", "lang", "thread", "run", "thread", "java:744", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "java", "io", "bytearrayinputstream", "byte", "array", "input", "stream", "init", "bytearrayinputstream", "java:106", "byte", "array", "input", "stream", "at", "org", "apach", "flink", "util", "instantiationutil", "deserializeobject", "instanti", "util", "deseri", "object", "instantiationutil", "java:301", "instanti", "util", "at", "org", "apach", "flink", "runtim", "taskmanag", "taskinputsplitprovid", "getnextinputsplit", "task", "input", "split", "provid", "get", "next", "input", "split", "taskinputsplitprovid", "java:83", "task", "input", "split", "provid", "more", "code"], "B_title": "runtime Fixes NPE when TM receives a null input split", "B_clean_title": ["runtim", "fix", "npe", "when", "tm", "receiv", "null", "input", "split"]},
{"A_title": "Wrong type name reported on missing property error.None", "A_clean_title": ["wrong", "type", "name", "report", "miss", "properti", "error", "none"], "B_title": "Rejigger type name printing. Fixes issue 1047 R=johnlenz", "B_clean_title": ["rejigg", "type", "name", "print", "fix", "issu", "1047", "r=johnlenz"]},
{"A_title": "Parantheses problem with UrlValidatorOne of our users got an error message when trying to add a new URL:  http://en.wikipedia.org/wiki/Genus_(mathematics) is not a valid URL  I just created very quickly a junit test and it fails:  String schemes = http; UrlValidator urlValidator = new UrlValidator(schemes); assertTrue(urlValidator.isValid(http://en.wikipedia.org/wiki/Genus_(mathematics)));", "A_clean_title": ["paranthes", "problem", "urlvalidatoron", "url", "valid", "one", "our", "user", "got", "error", "messag", "when", "tri", "add", "new", "url", "http", "wikipedia", "en", "org", "wiki", "genu", "mathemat", "not", "valid", "url", "just", "creat", "veri", "quickli", "junit", "test", "it", "fail", "string", "scheme", "http", "urlvalid", "url", "valid", "urlvalid", "url", "valid", "new", "urlvalid", "url", "valid", "scheme", "asserttru", "assert", "true", "urlvalid", "isvalid", "url", "valid", "valid", "http", "wikipedia", "en", "org", "wiki", "genu", "mathemat"], "B_title": "parentheses are valid in url path", "B_clean_title": ["parenthes", "are", "valid", "url", "path"]},
{"A_title": "InjectMocks injects mock into wrong field.When using @InjectMocks on some Android TextViews the mock is injected into the wrong field.  We have two fields txtGateView & txtNextStep in a class and our test mocks out txtNextStep then tried to inject. This field is injected wrong. From our quick testing the name txtNextView doesnt matter that can be changed. But both txtGateView and txtGateLabel messed things up. If we mock out both fields it works correctly.", "A_clean_title": ["injectmock", "inject", "mock", "inject", "mock", "into", "wrong", "field", "when", "injectmock", "inject", "mock", "some", "android", "textview", "text", "view", "mock", "inject", "into", "wrong", "field", "we", "have", "two", "field", "txtgateview", "txt", "gate", "view", "txtnextstep", "txt", "next", "step", "class", "our", "test", "mock", "out", "txtnextstep", "txt", "next", "step", "then", "tri", "inject", "thi", "field", "inject", "wrong", "our", "quick", "test", "name", "txtnextview", "txt", "next", "view", "doesnt", "matter", "that", "chang", "but", "both", "txtgateview", "txt", "gate", "view", "txtgatelabel", "txt", "gate", "label", "mess", "thing", "up", "we", "mock", "out", "both", "field", "it", "work", "correctli"], "B_title": "Fixes #205.", "B_clean_title": ["fix", "205"]},
{"A_title": "Page.checkRendering fails after setting BorderBodyContainer visiblity to falseAfter toggling visibility of the BorderBodyContainer to false the Page.checkRendering method fails in line 1157 claiming an iterator IllegalStateException. This happens because iterator.remove() is called twice for a child component in the border component if the body is not visible.  My Code:  public class TogglePanel extends Border  private boolean expanded = true;  public TogglePanel(String id IModel<String> titleModel)  super(id titleModel);  Link link = new Link(title)   @Override public void onClick()  expanded = !expanded; getBodyContainer().setVisible(expanded);  ; link.add(new Label(titleLabel titleModel));  add(link);     Markup:  <wicket:border> <h3 class=collapse wicket:id=title> <span class=label wicket:id=titleLabel>Panel Title</span> <a class=foldicon>&nbsp;</a> </h3> <wicket:body /> </wicket:border>", "A_clean_title": ["page", "checkrend", "check", "render", "fail", "after", "set", "borderbodycontain", "border", "bodi", "contain", "visibl", "falseaft", "fals", "after", "toggl", "visibl", "borderbodycontain", "border", "bodi", "contain", "fals", "page", "checkrend", "check", "render", "method", "fail", "line", "1157", "claim", "iter", "illegalstateexcept", "illeg", "state", "except", "thi", "happen", "becaus", "iter", "remov", "call", "twice", "child", "compon", "border", "compon", "bodi", "not", "visibl", "my", "code", "public", "class", "togglepanel", "toggl", "panel", "extend", "border", "privat", "boolean", "expand", "true", "public", "togglepanel", "toggl", "panel", "string", "id", "imodel", "model", "string", "titlemodel", "titl", "model", "super", "id", "titlemodel", "titl", "model", "link", "link", "new", "link", "titl", "overrid", "public", "void", "onclick", "click", "expand", "expand", "getbodycontain", "get", "bodi", "contain", "setvis", "set", "visibl", "expand", "link", "add", "new", "label", "titlelabel", "titl", "label", "titlemodel", "titl", "model", "add", "link", "markup", "wicket", "border", "h3", "class=collaps", "wicket", "id=titl", "span", "class=label", "wicket", "id=titlelabel", "id=titl", "label", "panel", "titl", "span", "class=foldicon", "nbsp", "h3", "wicket", "bodi", "wicket", "border"], "B_title": "fixed: Page.checkRendering fails after setting BorderBodyContainer visiblity to false Issue: WICKET-2368", "B_clean_title": ["fix", "page", "checkrend", "check", "render", "fail", "after", "set", "borderbodycontain", "border", "bodi", "contain", "visibl", "fals", "issu", "wicket", "2368"]},
{"A_title": "Lucene suggestions index definition cant be restricted to a specific type of nodeWhile performing a suggestor query like   code SELECT rep:suggest() as suggestion  FROM nt:unstructured WHERE suggest(foo) code  Suggestor does not provide any result. In current implementation suggestions|http://jackrabbit.apache.org/oak/docs/query/lucene.html#Suggestions in Oak work only for index definitions for nt:base nodetype. So an index definition like: code:xml     <lucene-suggest         jcr:primaryType=oak:QueryIndexDefinition         async=async         compatVersion=Long2         type=lucene>         <indexRules jcr:primaryType=nt:unstructured>             <nt:base jcr:primaryType=nt:unstructured>                 <properties jcr:primaryType=nt:unstructured>                     <description                         jcr:primaryType=nt:unstructured                         analyzed=Booleantrue                         name=description                         propertyIndex=Booleantrue                         useInSuggest=Booleantrue/>                 </properties>             </nt:base>         </indexRules>     </lucene-suggest> code works but if we change nodetype to nt:unstructured like: code:xml     <lucene-suggest         jcr:primaryType=oak:QueryIndexDefinition         async=async         compatVersion=Long2         type=lucene>         <indexRules jcr:primaryType=nt:unstructured>             <nt:unstructured jcr:primaryType=nt:unstructured>                 <properties jcr:primaryType=nt:unstructured>                     <description                         jcr:primaryType=nt:unstructured                         analyzed=Booleantrue                         name=description                         propertyIndex=Booleantrue                         useInSuggest=Booleantrue/>                 </properties>             </nt:base>         </indexRules>     </lucene-suggest> code  it wont work.  The issue is that suggestor implementation essentially is passing a pseudo row with path=/.: code:title=LucenePropertyIndex.java     private boolean loadDocs()  ...                         queue.add(new LuceneResultRow(suggestedWords)); ... code and code:title=LucenePropertyIndex.java         LuceneResultRow(Iterable<String> suggestWords)              this.path = /;             this.score = 1.0d;             this.suggestWords = suggestWords;          code Due to path being set to / SelectorImpl later filters out the result as rep:root (primary type of /) isnt a nt:unstructured.", "A_clean_title": ["lucen", "suggest", "index", "definit", "cant", "restrict", "specif", "type", "nodewhil", "node", "while", "perform", "suggestor", "queri", "like", "code", "select", "rep", "suggest", "as", "suggest", "nt", "unstructur", "where", "suggest", "foo", "code", "suggestor", "not", "provid", "ani", "result", "current", "implement", "suggestions|http", "apach", "html", "jackrabbit", "org", "oak", "doc", "queri", "lucen", "suggest", "oak", "work", "onli", "index", "definit", "nt", "base", "nodetyp", "so", "index", "definit", "like", "code", "xml", "lucen", "suggest", "jcr", "primarytype=oak", "primari", "type=oak", "queryindexdefinit", "queri", "index", "definit", "async=async", "compatversion=long2", "compat", "version=long2", "type=lucen", "indexrul", "index", "rule", "jcr", "primarytype=nt", "primari", "type=nt", "unstructur", "nt", "base", "jcr", "primarytype=nt", "primari", "type=nt", "unstructur", "properti", "jcr", "primarytype=nt", "primari", "type=nt", "unstructur", "descript", "jcr", "primarytype=nt", "primari", "type=nt", "unstructur", "analyzed=booleantru", "name=descript", "propertyindex=booleantru", "properti", "index=booleantru", "useinsuggest=booleantru", "use", "suggest=booleantru", "properti", "nt", "base", "indexrul", "index", "rule", "suggest", "lucen", "code", "work", "but", "we", "chang", "nodetyp", "nt", "unstructur", "like", "code", "xml", "lucen", "suggest", "jcr", "primarytype=oak", "primari", "type=oak", "queryindexdefinit", "queri", "index", "definit", "async=async", "compatversion=long2", "compat", "version=long2", "type=lucen", "indexrul", "index", "rule", "jcr", "primarytype=nt", "primari", "type=nt", "unstructur", "nt", "unstructur", "jcr", "primarytype=nt", "primari", "type=nt", "unstructur", "properti", "jcr", "primarytype=nt", "primari", "type=nt", "unstructur", "descript", "jcr", "primarytype=nt", "primari", "type=nt", "unstructur", "analyzed=booleantru", "name=descript", "propertyindex=booleantru", "properti", "index=booleantru", "useinsuggest=booleantru", "use", "suggest=booleantru", "properti", "nt", "base", "indexrul", "index", "rule", "suggest", "lucen", "code", "it", "wont", "work", "issu", "that", "suggestor", "implement", "essenti", "pass", "pseudo", "row", "path=", "code", "title=lucenepropertyindex", "java", "title=lucen", "properti", "index", "privat", "boolean", "loaddoc", "load", "doc", "queue", "add", "new", "luceneresultrow", "lucen", "result", "row", "suggestedword", "suggest", "word", "code", "code", "title=lucenepropertyindex", "java", "title=lucen", "properti", "index", "luceneresultrow", "lucen", "result", "row", "iter", "string", "suggestword", "suggest", "word", "thi", "path", "thi", "score", "0d", "thi", "suggestword", "suggest", "word", "suggestword", "suggest", "word", "code", "due", "path", "be", "set", "selectorimpl", "selector", "impl", "later", "filter", "out", "result", "as", "rep", "root", "primari", "type", "isnt", "nt", "unstructur"], "B_title": "- Lucene suggestions shouldnt be restricted to specific node types", "B_clean_title": ["lucen", "suggest", "shouldnt", "restrict", "specif", "node", "type"]},
{"A_title": "Identifier minus a negative number needs a space between the -sNone", "A_clean_title": ["identifi", "minu", "neg", "number", "need", "space", "between", "snone", "none"], "B_title": "Negative zero is a special case and needs to be handled differently to prevent it from getting confused with decrement fixes issue 657", "B_clean_title": ["neg", "zero", "special", "case", "need", "handl", "differ", "prevent", "it", "get", "confus", "decrement", "fix", "issu", "657"]},
{"A_title": "Cryptic error message on invalid @type function annotationNone", "A_clean_title": ["cryptic", "error", "messag", "invalid", "type", "function", "annotationnon", "annot", "none"], "B_title": "Fix a jsdoc parser bug where it was dropping the EndOfComment token Fixes issue 477", "B_clean_title": ["fix", "jsdoc", "parser", "bug", "where", "it", "wa", "drop", "endofcom", "end", "comment", "token", "fix", "issu", "477"]},
{"A_title": "Negative millis display incorrectly in Period.toStringThe last line should produce PT-0.100S instead of PT0.100S.", "A_clean_title": ["neg", "milli", "display", "incorrectli", "period", "tostringth", "string", "last", "line", "produc", "pt", "100", "instead", "pt0", "100"], "B_title": "Fix period formatter to correctly output values negative milliseconds 3564249", "B_clean_title": ["fix", "period", "formatt", "correctli", "output", "valu", "neg", "millisecond", "3564249"]},
{"A_title": "Cost per entry for Lucene index of type v1 should be higher than that of v2Currently default cost per entry for Lucene index of type # v1 - which uses query time aggregation # v2 - which uses index time aggregation  Are same. However given that query time aggregation would require more effort it should result in a higher cost per entry.  This fact impacts the result in cases like OAK-2081 (see last few comments) where with usage of limits both index are currently considered equals", "A_clean_title": ["cost", "per", "entri", "lucen", "index", "type", "v1", "higher", "than", "that", "v2current", "default", "cost", "per", "entri", "lucen", "index", "type", "v1", "which", "use", "queri", "time", "aggreg", "v2", "which", "use", "index", "time", "aggreg", "are", "same", "howev", "given", "that", "queri", "time", "aggreg", "would", "requir", "more", "effort", "it", "result", "higher", "cost", "per", "entri", "thi", "fact", "impact", "result", "case", "like", "oak", "2081", "see", "last", "few", "comment", "where", "usag", "limit", "both", "index", "are", "current", "consid", "equal"], "B_title": "- Cost per entry for Lucene index of type v1 should be higher than that of v2", "B_clean_title": ["cost", "per", "entri", "lucen", "index", "type", "v1", "higher", "than", "that", "v2"]},
{"A_title": "NPE importing EMX with abtract entity type dataHow to Reproduce  Import  this file Expected behavior  Success or if I am not allowed to add data to abstract entities I expect a message  Observed behavior  Importer hangs server logs report a null pointer exception in the  dataservice.add() method.", "A_clean_title": ["npe", "import", "emx", "abtract", "entiti", "type", "datahow", "data", "how", "reproduc", "import", "thi", "file", "expect", "behavior", "success", "or", "am", "not", "allow", "add", "data", "abstract", "entiti", "expect", "messag", "observ", "behavior", "import", "hang", "server", "log", "report", "null", "pointer", "except", "dataservic", "add", "method"], "B_title": "Merge pull request #7320 from dennishendriksen/fix/6945-emxAbstractEntityTypeData  Fix #6945 NPE importing EMX with abtract entity type data", "B_clean_title": ["merg", "pull", "request", "7320", "emxabstractentitytypedata", "dennishendriksen", "fix", "6945", "emx", "abstract", "entiti", "type", "data", "fix", "6945", "npe", "import", "emx", "abtract", "entiti", "type", "data"]},
{"A_title": "TypeUtils.getTypeArguments() misses type arguments for partially-assigned classesfailing test code to add to TypeUtilsTest.testGetTypeArguments():  typeVarAssigns = TypeUtils.getTypeArguments(Other.class This.class); Assert.assertEquals(2 typeVarAssigns.size()); Assert.assertEquals(String.class typeVarAssigns.get(This.class.getTypeParameters()0)); Assert.assertEquals(Other.class.getTypeParameters()0 typeVarAssigns.get(This.class.getTypeParameters()1));   These should pass based on:   public interface This<K V>    public class Other<T> implements This<String T>     This case fails because the current code ignores the Other class due to its specifying its own type variables which is obviously incorrect.  This report is extrapolated from an offline report received by Hen.", "A_clean_title": ["typeutil", "gettypeargu", "type", "util", "get", "type", "argument", "miss", "type", "argument", "partial", "assign", "classesfail", "test", "code", "add", "typeutilstest", "testgettypeargu", "type", "util", "test", "test", "get", "type", "argument", "typevarassign", "type", "var", "assign", "typeutil", "gettypeargu", "type", "util", "get", "type", "argument", "other", "class", "thi", "class", "assert", "assertequ", "assert", "equal", "typevarassign", "size", "type", "var", "assign", "assert", "assertequ", "assert", "equal", "string", "class", "typevarassign", "get", "type", "var", "assign", "thi", "class", "gettypeparamet", "get", "type", "paramet", "assert", "assertequ", "assert", "equal", "other", "class", "gettypeparamet", "get", "type", "paramet", "typevarassign", "get", "type", "var", "assign", "thi", "class", "gettypeparamet", "get", "type", "paramet", "these", "pass", "base", "public", "interfac", "thi", "public", "class", "other", "implement", "thi", "string", "thi", "case", "fail", "becaus", "current", "code", "ignor", "other", "class", "due", "it", "specifi", "it", "own", "type", "variabl", "which", "obvious", "incorrect", "thi", "report", "extrapol", "offlin", "report", "receiv", "by", "hen"], "B_title": "LANG-776 fix related bugs dealing with type variable inheritance", "B_clean_title": ["lang", "776", "fix", "relat", "bug", "deal", "type", "variabl", "inherit"]},
{"A_title": "Wrong results and NPE with copy operationThe following code either results in an NPE or in a wrong result depending on which Microkernel instance is used.   code     mk.commit( +/root: mk.getHeadRevision() );     mk.commit( +/root/N0:*/root/N0:/root/N1+/root/N0/N4:             mk.getHeadRevision() ); code  The wrong result is  code      :childNodeCount: 2     N0:          :childNodeCount: 1         N4:              :childNodeCount: 0                   N1:          :childNodeCount: 1         N4:              :childNodeCount: 0                code  The expected result is code      :childNodeCount: 2     N0:          :childNodeCount: 1         N4:              :childNodeCount: 0                   N1:          :childNodeCount: 0       code  simple:fs:target/temp: wrong result fs:homeDir/target: NPE http-bridge:fs:homeDir/target: NPE simple: wrong result", "A_clean_title": ["wrong", "result", "npe", "copi", "operationth", "oper", "follow", "code", "either", "result", "npe", "or", "wrong", "result", "depend", "which", "microkernel", "instanc", "use", "code", "mk", "commit", "root", "mk", "getheadrevis", "get", "head", "revis", "mk", "commit", "root", "n0", "root", "n0", "root", "n1+", "root", "n0", "n4", "mk", "getheadrevis", "get", "head", "revis", "code", "wrong", "result", "code", "childnodecount", "child", "node", "count", "n0", "childnodecount", "child", "node", "count", "n4", "childnodecount", "child", "node", "count", "n1", "childnodecount", "child", "node", "count", "n4", "childnodecount", "child", "node", "count", "code", "expect", "result", "code", "childnodecount", "child", "node", "count", "n0", "childnodecount", "child", "node", "count", "n4", "childnodecount", "child", "node", "count", "n1", "childnodecount", "child", "node", "count", "code", "simpl", "fs", "target", "temp", "wrong", "result", "fs", "homedir", "target", "home", "dir", "npe", "http", "bridg", "fs", "homedir", "target", "home", "dir", "npe", "simpl", "wrong", "result"], "B_title": "Wrong results and NPE with copy operation (support the copy operation in the Indexer and the SimpleKernel)", "B_clean_title": ["wrong", "result", "npe", "copi", "oper", "support", "copi", "oper", "index", "simplekernel", "simpl", "kernel"]},
{"A_title": "Repeated MongoMK.rebase() always adds new revisionMongoMK always adds a new revision to the branch on rebase even when the branch is already up-to-date.", "A_clean_title": ["repeat", "mongomk", "rebas", "mongo", "mk", "alway", "add", "new", "revisionmongomk", "revis", "mongo", "mk", "alway", "add", "new", "revis", "branch", "rebas", "even", "when", "branch", "alreadi", "up", "date"], "B_title": "Repeated MongoMK.rebase() always adds new revision", "B_clean_title": ["repeat", "mongomk", "rebas", "mongo", "mk", "alway", "add", "new", "revis"]},
{"A_title": "Truncation issue in KMeansPlusPlusClustererThe for loop inside KMeansPlusPlusClusterer.chooseInitialClusters defines a variable   int sum = 0; This variable should have type double rather than int.  Using an int causes the method to truncate the distances between points to (square roots of) integers.  Its especially bad when the distances between points are typically less than 1. As an aside in version 2.2 this bug manifested itself by making the clusterer return empty clusters.  I wonder if the EmptyClusterStrategy would still be necessary if this bug were fixed.", "A_clean_title": ["truncat", "issu", "kmeansplusplusclustererth", "mean", "plu", "plu", "cluster", "loop", "insid", "kmeanspluspluscluster", "chooseinitialclust", "mean", "plu", "plu", "cluster", "choos", "initi", "cluster", "defin", "variabl", "int", "sum", "thi", "variabl", "have", "type", "doubl", "rather", "than", "int", "int", "caus", "method", "truncat", "distanc", "between", "point", "squar", "root", "integ", "it", "especi", "bad", "when", "distanc", "between", "point", "are", "typic", "less", "than", "as", "asid", "version", "thi", "bug", "manifest", "itself", "by", "make", "cluster", "return", "empti", "cluster", "wonder", "emptyclusterstrategi", "empti", "cluster", "strategi", "would", "still", "necessari", "thi", "bug", "were", "fix"], "B_title": "Wrong  variable type (int instead of double).", "B_clean_title": ["wrong", "variabl", "type", "int", "instead", "doubl"]},
{"A_title": "Interval class upper and lower checkIn class Interval which is in the package org.apache.commons.math4.geometry.euclidean.oned it is possible to pass the value for variable upper  less than the value of variable lower which is logically incorrect and  also causes the method getSize() to return negative value.  For example:   @Test   public void test1()  throws Throwable         Interval interval0 = new Interval(0.0 (-1.0));       double double0 = interval0.getSize();       assertEquals((-1.0) double0 0.01D);", "A_clean_title": ["interv", "class", "upper", "lower", "checkin", "check", "class", "interv", "which", "packag", "org", "apach", "common", "math4", "geometri", "euclidean", "one", "it", "possibl", "pass", "valu", "variabl", "upper", "less", "than", "valu", "variabl", "lower", "which", "logic", "incorrect", "also", "caus", "method", "getsiz", "get", "size", "return", "neg", "valu", "exampl", "test", "public", "void", "test1", "throw", "throwabl", "interv", "interval0", "new", "interv", "doubl", "double0", "interval0", "getsiz", "get", "size", "assertequ", "assert", "equal", "double0", "01d"], "B_title": "", "B_clean_title": []},
{"A_title": "Node builder for existing node return null for base stateMemoryNodeBuilder.getBaseState() returns null on builder for an existing node.", "A_clean_title": ["node", "builder", "exist", "node", "return", "null", "base", "statememorynodebuild", "getbasest", "state", "memori", "node", "builder", "get", "base", "state", "return", "null", "builder", "exist", "node"], "B_title": " Node builder for existing node return null for base state", "B_clean_title": ["node", "builder", "exist", "node", "return", "null", "base", "state"]},
{"A_title": "--process_closure_primitives cant be set to falseNone", "A_clean_title": ["process", "closur", "primit", "cant", "set", "falsenon", "fals", "none"], "B_title": "Removing useless members variables. (Alan) R=robert DELTA=4  (0 added 4 deleted 0 changed)", "B_clean_title": ["remov", "useless", "member", "variabl", "alan", "r=robert", "delta=4", "ad", "delet", "chang"]},
{"A_title": "Path parsing must support SNS indexes irrespective of SNS supportcode Session.getNode(/foo/bar2); code  throws javax.jcr.RepositoryException: Invalid name or path: /foo/bar2  This should be an ItemNotFoundException (if the item does not exist) irrespective if the repository supports SNS or not.", "A_clean_title": ["path", "pars", "must", "support", "sn", "index", "irrespect", "sn", "supportcod", "session", "getnod", "get", "node", "foo", "bar2", "code", "throw", "javax", "jcr", "repositoryexcept", "repositori", "except", "invalid", "name", "or", "path", "foo", "bar2", "thi", "itemnotfoundexcept", "item", "not", "found", "except", "item", "not", "exist", "irrespect", "repositori", "support", "sn", "or", "not"], "B_title": "Path parsing must support SNS indexes irrespective of SNS support", "B_clean_title": ["path", "pars", "must", "support", "sn", "index", "irrespect", "sn", "support"]},
{"A_title": "Days#daysBetween throw exception for MonthDay with 29 FebruaryIs there a way to avoid this happening? I understand fiddling around with the leap year youre bound to get issues.", "A_clean_title": ["day", "daysbetween", "day", "between", "throw", "except", "monthday", "month", "day", "29", "februaryi", "februari", "there", "way", "avoid", "thi", "happen", "understand", "fiddl", "around", "leap", "year", "your", "bound", "get", "issu"], "B_title": "Days.daysBetween fails for MonthDay", "B_clean_title": ["day", "daysbetween", "day", "between", "fail", "monthday", "month", "day"]},
{"A_title": "Non-root lucene index throws exception if query constraints match root of sub-treeLucenePropetyIndexProvider returns incorrect (normalized) path for root of sub-tree if index is defined on the sub-tree. e.g. /jcr:root/test//element(* nt:base)@foo=bar would fail with following defn noformat + /test     - foo=bar     + test1           - foo=bar     + oak:index            - indexRules/nt:base/properties/foo/propertyIndex=true noformat", "A_clean_title": ["non", "root", "lucen", "index", "throw", "except", "queri", "constraint", "match", "root", "sub", "treelucenepropetyindexprovid", "tree", "lucen", "propeti", "index", "provid", "return", "incorrect", "normal", "path", "root", "sub", "tree", "index", "defin", "sub", "tree", "jcr", "root", "test", "element", "nt", "base", "foo=bar", "would", "fail", "follow", "defn", "noformat", "test", "foo=bar", "test1", "foo=bar", "oak", "index", "indexrul", "nt", "index", "rule", "base", "properti", "foo", "propertyindex=tru", "properti", "index=tru", "noformat"], "B_title": "Non-root lucene index throws exception if query constraints match root of sub-tree", "B_clean_title": ["non", "root", "lucen", "index", "throw", "except", "queri", "constraint", "match", "root", "sub", "tree"]},
{"A_title": "optimization fails with variable in catch clauseNone", "A_clean_title": ["optim", "fail", "variabl", "catch", "clausenon", "claus", "none"], "B_title": "Special case catch expressions to work around the fact that we dont module catch block as lexical scope for the exception and it doesnt belong in the function scope. Fixes issue 864.", "B_clean_title": ["special", "case", "catch", "express", "work", "around", "fact", "that", "we", "dont", "modul", "catch", "block", "as", "lexic", "scope", "except", "it", "doesnt", "belong", "function", "scope", "fix", "issu", "864"]},
{"A_title": "BrentOptimizer not always reporting the best pointBrentOptimizer (package o.a.c.m.optimization.univariate) does not check that the point it is going to return is indeed the best one it has encountered. Indeed the last evaluated point might be slightly worse than the one before last.", "A_clean_title": ["brentoptim", "brent", "optim", "not", "alway", "report", "best", "pointbrentoptim", "point", "brent", "optim", "packag", "optim", "univari", "not", "check", "that", "point", "it", "go", "return", "inde", "best", "one", "it", "ha", "encount", "inde", "last", "evalu", "point", "might", "slightli", "wors", "than", "one", "befor", "last"], "B_title": "The best point is sometimes not the last one evaluated.", "B_clean_title": ["best", "point", "sometim", "not", "last", "one", "evalu"]},
{"A_title": "ColumnVisibility parse tree nodes do not have correct location offsets for AND and OR nodesTrying to do some transformations on visibility strings and running into issues working with the parse tree:  Clojure 1.5.1 user=> (import org.apache.accumulo.core.security ColumnVisibility) org.apache.accumulo.core.security.ColumnVisibility user=> (def vis (ColumnVisibility. (W)|(U|V))) #user/vis user=> (.getTermStart (first (.getChildren (.getParseTree vis)))) 1 user=> (.getTermEnd (first (.getChildren (.getParseTree vis)))) 2 user=> (.getTermStart (second (.getChildren (.getParseTree vis)))) 0 user=> (.getTermEnd (second (.getChildren (.getParseTree vis)))) 8  Shouldnt those last two be 5 and 8?", "A_clean_title": ["columnvis", "column", "visibl", "pars", "tree", "node", "not", "have", "correct", "locat", "offset", "or", "nodestri", "node", "tri", "some", "transform", "visibl", "string", "run", "into", "issu", "work", "pars", "tree", "clojur", "user=", "import", "org", "apach", "accumulo", "core", "secur", "columnvis", "column", "visibl", "org", "apach", "accumulo", "core", "secur", "columnvis", "column", "visibl", "user=", "def", "vi", "columnvis", "column", "visibl", "u|v", "user", "vi", "user=", "gettermstart", "get", "term", "start", "first", "getchildren", "get", "children", "getparsetre", "get", "pars", "tree", "vi", "user=", "gettermend", "get", "term", "end", "first", "getchildren", "get", "children", "getparsetre", "get", "pars", "tree", "vi", "user=", "gettermstart", "get", "term", "start", "second", "getchildren", "get", "children", "getparsetre", "get", "pars", "tree", "vi", "user=", "gettermend", "get", "term", "end", "second", "getchildren", "get", "children", "getparsetre", "get", "pars", "tree", "vi", "shouldnt", "those", "last", "two"], "B_title": "Reinsert changes inadvertently lost in cherry-pick", "B_clean_title": ["reinsert", "chang", "inadvert", "lost", "cherri", "pick"]},
{"A_title": "PropertyResolver does not scan for NotNull in annotation treeWhen annotating a field of a bean with e.g. org.hibernate.validator.constraints.NotEmpty this implies javax.validation.constraints.NotNull but PropertyValidator only checks for the annotations immediately on the filed not the tree of annotations. As a result Wicket does not mark the field as required in the UI which it should.  Also PropertyResolver.findNotNullConstraints() is not even protected so cannot be patched in a simple way.  So as a solution I suggest changing findNotNullConstraints() to be protected and rather be something like findConstraints(filter) or findConstraints(clazz) and then in that method method recursively invoking getComposingConstraints to get all constraints but collecting only those of interest. Possibly some care needs to be taken to prevent infinite recursion where constraints are composed of each other (if that compiles).", "A_clean_title": ["propertyresolv", "properti", "resolv", "not", "scan", "notnul", "not", "null", "annot", "treewhen", "tree", "when", "annot", "field", "bean", "org", "hibern", "valid", "constraint", "notempti", "not", "empti", "thi", "impli", "javax", "valid", "constraint", "notnul", "not", "null", "but", "propertyvalid", "properti", "valid", "onli", "check", "annot", "immedi", "file", "not", "tree", "annot", "as", "result", "wicket", "not", "mark", "field", "as", "requir", "ui", "which", "it", "also", "propertyresolv", "findnotnullconstraint", "properti", "resolv", "find", "not", "null", "constraint", "not", "even", "protect", "so", "not", "patch", "simpl", "way", "so", "as", "solut", "suggest", "chang", "findnotnullconstraint", "find", "not", "null", "constraint", "protect", "rather", "someth", "like", "findconstraint", "find", "constraint", "filter", "or", "findconstraint", "find", "constraint", "clazz", "then", "that", "method", "method", "recurs", "invok", "getcomposingconstraint", "get", "compos", "constraint", "get", "all", "constraint", "but", "collect", "onli", "those", "interest", "possibl", "some", "care", "need", "taken", "prevent", "infinit", "recurs", "where", "constraint", "are", "compos", "each", "other", "that", "compil"], "B_title": "PropertyResolver does not scan for NotNull in annotation tree", "B_clean_title": ["propertyresolv", "properti", "resolv", "not", "scan", "notnul", "not", "null", "annot", "tree"]},
{"A_title": "TracingP6SpyListener is not computing the Tags.DB_TYPE properly.Type: bugfix  In the TracingP6SpyListener class line 112   We should take into account that a url returned by a DatabaseMetaData can be null.", "A_clean_title": ["tracingp6spylisten", "trace", "p6spi", "listen", "not", "comput", "tag", "db", "type", "properli", "type", "bugfix", "tracingp6spylisten", "trace", "p6spi", "listen", "class", "line", "112", "we", "take", "into", "account", "that", "url", "return", "by", "databasemetadata", "databas", "meta", "data", "null"], "B_title": "Fixes #4 : protect against possible contractual null values returned by different method from the jdbc interface. Update various dependencies", "B_clean_title": ["fix", "protect", "against", "possibl", "contractu", "null", "valu", "return", "by", "differ", "method", "jdbc", "interfac", "updat", "variou", "depend"]},
{"A_title": "Feedback messages not cleared for invisible/disabled form components on submit.Having:  - IFeedbackMessageFilter.NONE used as the default applications feedback message cleanup filter (in order to make feedback messages not to disappear after page refresh i.e. persistent) - form with validatable component whose enabled/visible state may be dynamically changed by user (e.g. checkbox send me email and text field email)  First user tries to submit form having invalid value - as the result validation error occurs.  Then user makes that component invisible and retries form submitting - as the result no validation errors but form wasnt submitted.  This happens because that component still has error feedback message got from first submit. Note that when using default applications feedback message cleanup filter form is successfully submitted.  Probably feedback messages should be cleared for invisible/disabled form components on submit as it done for visible/enabled components in FormComponent.validate()", "A_clean_title": ["feedback", "messag", "not", "clear", "invis", "disabl", "form", "compon", "submit", "have", "ifeedbackmessagefilt", "none", "feedback", "messag", "filter", "use", "as", "default", "applic", "feedback", "messag", "cleanup", "filter", "order", "make", "feedback", "messag", "not", "disappear", "after", "page", "refresh", "persist", "form", "validat", "compon", "whose", "enabl", "visibl", "state", "may", "dynam", "chang", "by", "user", "checkbox", "send", "me", "email", "text", "field", "email", "first", "user", "tri", "submit", "form", "have", "invalid", "valu", "as", "result", "valid", "error", "occur", "then", "user", "make", "that", "compon", "invis", "retri", "form", "submit", "as", "result", "no", "valid", "error", "but", "form", "wasnt", "submit", "thi", "happen", "becaus", "that", "compon", "still", "ha", "error", "feedback", "messag", "got", "first", "submit", "note", "that", "when", "default", "applic", "feedback", "messag", "cleanup", "filter", "form", "success", "submit", "probabl", "feedback", "messag", "clear", "invis", "disabl", "form", "compon", "submit", "as", "it", "done", "visibl", "enabl", "compon", "formcompon", "valid", "form", "compon"], "B_title": "Feedback messages not cleared for invisible/disabled form components on submit.", "B_clean_title": ["feedback", "messag", "not", "clear", "invis", "disabl", "form", "compon", "submit"]},
{"A_title": "Adding a node to a node that doesnt accept children doesnt fail with ConstraintViolationExceptionMore node type fun!  I ran into this via the tck test org.apache.jackrabbit.test.api.query.SaveTest#testConstraintViolationException.  It seems adding a node to a node that doesnt accept children (like for example nt:query) fails with a RepositoryException that wraps a CommitFailedException with a message along the lines of: Cannot add node q2 at /q1 further wrapping a weird-looking RepositoryException: No matching node definition found for org.apache.jackrabbit.oak.plugins.nodetype.ValidatingNodeTypeManager@257f1b  While this seems ok enough the tck test expects a ConstraintViolationException so thats why I created this bug.   Ill attach a test case shortly.  Trace  code javax.jcr.RepositoryException at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) at java.lang.reflect.Constructor.newInstance(Constructor.java:513) at org.apache.jackrabbit.oak.api.CommitFailedException.throwRepositoryException(CommitFailedException.java:57) at org.apache.jackrabbit.oak.jcr.SessionDelegate.save(SessionDelegate.java:244) at org.apache.jackrabbit.oak.jcr.SessionImpl.save(SessionImpl.java:283) at org.apache.jackrabbit.oak.jcr.nodetype.NodeTypeTest.illegalAddNode(NodeTypeTest.java:39) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.junit.runners.model.FrameworkMethod 1.runReflectiveCall(FrameworkMethod.java:45) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47) at org.junit.runners.ParentRunner 3.run(ParentRunner.java:231) at org.junit.runners.ParentRunner 1.schedule(ParentRunner.java:60) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229) at org.junit.runners.ParentRunner.access 000(ParentRunner.java:50) at org.junit.runners.ParentRunner 2.evaluate(ParentRunner.java:222) at org.junit.runners.ParentRunner.run(ParentRunner.java:300) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197) Caused by: org.apache.jackrabbit.oak.api.CommitFailedException: Cannot add node q2 at /q1 at org.apache.jackrabbit.oak.plugins.nodetype.TypeValidator.childNodeAdded(TypeValidator.java:134) at org.apache.jackrabbit.oak.spi.commit.CompositeValidator.childNodeAdded(CompositeValidator.java:68) at org.apache.jackrabbit.oak.spi.commit.ValidatingHook ValidatorDiff.childNodeAdded(ValidatingHook.java:155) at org.apache.jackrabbit.oak.spi.state.AbstractNodeState.compareAgainstBaseState(AbstractNodeState.java:157) at org.apache.jackrabbit.oak.kernel.KernelNodeState.compareAgainstBaseState(KernelNodeState.java:243) at org.apache.jackrabbit.oak.spi.commit.ValidatingHook ValidatorDiff.validate(ValidatingHook.java:110) at org.apache.jackrabbit.oak.spi.commit.ValidatingHook ValidatorDiff.validate(ValidatingHook.java:101) at org.apache.jackrabbit.oak.spi.commit.ValidatingHook ValidatorDiff.childNodeAdded(ValidatingHook.java:157) at org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState 3.childNodeAdded(ModifiedNodeState.java:292) at org.apache.jackrabbit.oak.spi.state.AbstractNodeState.compareAgainstBaseState(AbstractNodeState.java:157) at org.apache.jackrabbit.oak.kernel.KernelNodeState.compareAgainstBaseState(KernelNodeState.java:243) at org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:269) at org.apache.jackrabbit.oak.spi.commit.ValidatingHook ValidatorDiff.validate(ValidatingHook.java:110) at org.apache.jackrabbit.oak.spi.commit.ValidatingHook ValidatorDiff.validate(ValidatingHook.java:101) at org.apache.jackrabbit.oak.spi.commit.ValidatingHook.processCommit(ValidatingHook.java:73) at org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:59) at org.apache.jackrabbit.oak.kernel.KernelNodeStoreBranch.merge(KernelNodeStoreBranch.java:127) at org.apache.jackrabbit.oak.core.RootImpl 2.run(RootImpl.java:239) at org.apache.jackrabbit.oak.core.RootImpl 2.run(RootImpl.java:1) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:337) at org.apache.jackrabbit.oak.core.RootImpl.commit(RootImpl.java:234) at org.apache.jackrabbit.oak.jcr.SessionDelegate.save(SessionDelegate.java:241) ... 27 more Caused by: javax.jcr.RepositoryException: No matching node definition found for org.apache.jackrabbit.oak.plugins.nodetype.ValidatingNodeTypeManager@257f1b at org.apache.jackrabbit.oak.plugins.nodetype.ReadOnlyNodeTypeManager.getDefinition(ReadOnlyNodeTypeManager.java:406) at org.apache.jackrabbit.oak.plugins.nodetype.TypeValidator EffectiveNodeType.getDefinition(TypeValidator.java:302) at org.apache.jackrabbit.oak.plugins.nodetype.TypeValidator EffectiveNodeType.checkAddChildNode(TypeValidator.java:249) at org.apache.jackrabbit.oak.plugins.nodetype.TypeValidator.childNodeAdded(TypeValidator.java:127) ... 49 more code", "A_clean_title": ["ad", "node", "node", "that", "doesnt", "accept", "children", "doesnt", "fail", "constraintviolationexceptionmor", "constraint", "violat", "except", "more", "node", "type", "fun", "ran", "into", "thi", "via", "tck", "test", "org", "apach", "jackrabbit", "test", "api", "queri", "savetest", "save", "test", "testconstraintviolationexcept", "test", "constraint", "violat", "except", "it", "seem", "ad", "node", "node", "that", "doesnt", "accept", "children", "like", "exampl", "nt", "queri", "fail", "repositoryexcept", "repositori", "except", "that", "wrap", "commitfailedexcept", "commit", "fail", "except", "messag", "along", "line", "not", "add", "node", "q2", "at", "q1", "further", "wrap", "weird", "look", "repositoryexcept", "repositori", "except", "no", "match", "node", "definit", "found", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "validatingnodetypemanag", "valid", "node", "type", "manag", "257f1b", "while", "thi", "seem", "ok", "enough", "tck", "test", "expect", "constraintviolationexcept", "constraint", "violat", "except", "so", "that", "whi", "creat", "thi", "bug", "ill", "attach", "test", "case", "shortli", "trace", "code", "javax", "jcr", "repositoryexcept", "repositori", "except", "at", "sun", "reflect", "nativeconstructoraccessorimpl", "newinstance0", "nativ", "constructor", "accessor", "impl", "new", "instance0", "nativ", "method", "at", "sun", "reflect", "nativeconstructoraccessorimpl", "newinst", "nativ", "constructor", "accessor", "impl", "new", "instanc", "nativeconstructoraccessorimpl", "java:39", "nativ", "constructor", "accessor", "impl", "at", "sun", "reflect", "delegatingconstructoraccessorimpl", "newinst", "deleg", "constructor", "accessor", "impl", "new", "instanc", "delegatingconstructoraccessorimpl", "java:27", "deleg", "constructor", "accessor", "impl", "at", "java", "lang", "reflect", "constructor", "newinst", "new", "instanc", "constructor", "java:513", "at", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "throwrepositoryexcept", "commit", "fail", "except", "throw", "repositori", "except", "commitfailedexcept", "java:57", "commit", "fail", "except", "at", "org", "apach", "jackrabbit", "oak", "jcr", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:244", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "sessionimpl", "save", "session", "impl", "sessionimpl", "java:283", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "nodetyp", "nodetypetest", "illegaladdnod", "node", "type", "test", "illeg", "add", "node", "nodetypetest", "java:39", "node", "type", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:25", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:597", "at", "org", "junit", "runner", "model", "frameworkmethod", "framework", "method", "runreflectivecal", "run", "reflect", "call", "frameworkmethod", "java:45", "framework", "method", "at", "org", "junit", "intern", "runner", "model", "reflectivecal", "run", "reflect", "callabl", "reflectivecal", "java:15", "reflect", "callabl", "at", "org", "junit", "runner", "model", "frameworkmethod", "invokeexplos", "framework", "method", "invok", "explos", "frameworkmethod", "java:42", "framework", "method", "at", "org", "junit", "intern", "runner", "statement", "invokemethod", "evalu", "invok", "method", "invokemethod", "java:20", "invok", "method", "at", "org", "junit", "intern", "runner", "statement", "runbefor", "evalu", "run", "befor", "runbefor", "java:28", "run", "befor", "at", "org", "junit", "intern", "runner", "statement", "runaft", "evalu", "run", "after", "runaft", "java:30", "run", "after", "at", "org", "junit", "runner", "parentrunn", "runleaf", "parent", "runner", "run", "leaf", "parentrunn", "java:263", "parent", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:68", "block", "unit4class", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:47", "block", "unit4class", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "run", "parentrunn", "java:231", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "schedul", "parentrunn", "java:60", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "runchildren", "parent", "runner", "run", "children", "parentrunn", "java:229", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "access", "parent", "runner", "000", "parentrunn", "java:50", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "evalu", "parentrunn", "java:222", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "run", "parent", "runner", "parentrunn", "java:300", "parent", "runner", "at", "org", "eclips", "jdt", "intern", "junit4", "runner", "junit4testrefer", "run", "unit4test", "refer", "junit4testrefer", "java:50", "unit4test", "refer", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "testexecut", "run", "test", "execut", "testexecut", "java:38", "test", "execut", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:467", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "runtest", "remot", "test", "runner", "run", "test", "remotetestrunn", "java:683", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "run", "remot", "test", "runner", "remotetestrunn", "java:390", "remot", "test", "runner", "at", "org", "eclips", "jdt", "intern", "junit", "runner", "remotetestrunn", "main", "remot", "test", "runner", "remotetestrunn", "java:197", "remot", "test", "runner", "caus", "by", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "commit", "fail", "except", "not", "add", "node", "q2", "at", "q1", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typevalid", "childnodead", "type", "valid", "child", "node", "ad", "typevalid", "java:134", "type", "valid", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositevalid", "childnodead", "composit", "valid", "child", "node", "ad", "compositevalid", "java:68", "composit", "valid", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "validatinghook", "valid", "hook", "validatordiff", "childnodead", "valid", "diff", "child", "node", "ad", "validatinghook", "java:155", "valid", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "abstractnodest", "compareagainstbasest", "abstract", "node", "state", "compar", "against", "base", "state", "abstractnodest", "java:157", "abstract", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "kernel", "kernelnodest", "compareagainstbasest", "kernel", "node", "state", "compar", "against", "base", "state", "kernelnodest", "java:243", "kernel", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "validatinghook", "valid", "hook", "validatordiff", "valid", "valid", "diff", "validatinghook", "java:110", "valid", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "validatinghook", "valid", "hook", "validatordiff", "valid", "valid", "diff", "validatinghook", "java:101", "valid", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "validatinghook", "valid", "hook", "validatordiff", "childnodead", "valid", "diff", "child", "node", "ad", "validatinghook", "java:157", "valid", "hook", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "modifiednodest", "modifi", "node", "state", "childnodead", "child", "node", "ad", "modifiednodest", "java:292", "modifi", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "abstractnodest", "compareagainstbasest", "abstract", "node", "state", "compar", "against", "base", "state", "abstractnodest", "java:157", "abstract", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "kernel", "kernelnodest", "compareagainstbasest", "kernel", "node", "state", "compar", "against", "base", "state", "kernelnodest", "java:243", "kernel", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "modifiednodest", "compareagainstbasest", "modifi", "node", "state", "compar", "against", "base", "state", "modifiednodest", "java:269", "modifi", "node", "state", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "validatinghook", "valid", "hook", "validatordiff", "valid", "valid", "diff", "validatinghook", "java:110", "valid", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "validatinghook", "valid", "hook", "validatordiff", "valid", "valid", "diff", "validatinghook", "java:101", "valid", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "validatinghook", "processcommit", "valid", "hook", "process", "commit", "validatinghook", "java:73", "valid", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositehook", "processcommit", "composit", "hook", "process", "commit", "compositehook", "java:59", "composit", "hook", "at", "org", "apach", "jackrabbit", "oak", "kernel", "kernelnodestorebranch", "merg", "kernel", "node", "store", "branch", "kernelnodestorebranch", "java:127", "kernel", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "root", "impl", "run", "rootimpl", "java:239", "root", "impl", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "root", "impl", "run", "rootimpl", "java:1", "root", "impl", "at", "java", "secur", "accesscontrol", "doprivileg", "access", "control", "privileg", "nativ", "method", "at", "javax", "secur", "auth", "subject", "doa", "as", "subject", "java:337", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "commit", "root", "impl", "rootimpl", "java:234", "root", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:241", "session", "deleg", "27", "more", "caus", "by", "javax", "jcr", "repositoryexcept", "repositori", "except", "no", "match", "node", "definit", "found", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "validatingnodetypemanag", "valid", "node", "type", "manag", "257f1b", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "readonlynodetypemanag", "getdefinit", "read", "onli", "node", "type", "manag", "get", "definit", "readonlynodetypemanag", "java:406", "read", "onli", "node", "type", "manag", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typevalid", "type", "valid", "effectivenodetyp", "getdefinit", "effect", "node", "type", "get", "definit", "typevalid", "java:302", "type", "valid", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typevalid", "type", "valid", "effectivenodetyp", "checkaddchildnod", "effect", "node", "type", "check", "add", "child", "node", "typevalid", "java:249", "type", "valid", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typevalid", "childnodead", "type", "valid", "child", "node", "ad", "typevalid", "java:127", "type", "valid", "49", "more", "code"], "B_title": "Adding a node to a node that doesnt accept children doesnt fail with ConstraintViolationException", "B_clean_title": ["ad", "node", "node", "that", "doesnt", "accept", "children", "doesnt", "fail", "constraintviolationexcept", "constraint", "violat", "except"]},
{"A_title": "Wicket generates invalid HTML by expanding col tagshi  I just noticed that wicket expands col tags even though the (x)html specifications forbids it.  take this markup as an example:  <table>     <colgroup>         <col width=20% />         <col width=80% />     </colgroup>     <tbody>         <tr>             <td>I take a fifth of the available space</td>             <td>I take four fifth of the available space</td>         </tr>     </tbody> </table>  Instead of return this as-is it gets converted to:  <table>     <colgroup>         <col width=20%></col>         <col width=80%></col>     </colgroup>     <tbody>         <tr>             <td>I take a fifth of the available space</td>             <td>I take four fifth of the available space</td>         </tr>     </tbody> </table>  But the specifications mention that col tags must not have end tags. This may be related to WICKET-2765 as this seems to be the point when col was added to the OpenCloseTagExpander class. Note that it is ok to have a non closing col tag in html (self-closing in xhtml). Its all about generating a separated end tag.  This happens in wicket 6.8 but I guess its relevant to all versions down to wicket 1.4.  Specs for reference:  http://www.w3.org/TR/1999/REC-html401-19991224/struct/tables.html#edef-COL http://www.w3.org/TR/html-markup/col.html  Kind regards  Konrad", "A_clean_title": ["wicket", "gener", "invalid", "html", "by", "expand", "col", "tagshi", "just", "notic", "that", "wicket", "expand", "col", "tag", "even", "though", "html", "specif", "forbid", "it", "take", "thi", "markup", "as", "exampl", "tabl", "colgroup", "col", "width=20", "col", "width=80", "colgroup", "tbodi", "tr", "td", "take", "fifth", "avail", "space", "td", "td", "take", "four", "fifth", "avail", "space", "td", "tr", "tbodi", "tabl", "instead", "return", "thi", "as", "it", "get", "convert", "tabl", "colgroup", "col", "width=20", "col", "col", "width=80", "col", "colgroup", "tbodi", "tr", "td", "take", "fifth", "avail", "space", "td", "td", "take", "four", "fifth", "avail", "space", "td", "tr", "tbodi", "tabl", "but", "specif", "mention", "that", "col", "tag", "must", "not", "have", "end", "tag", "thi", "may", "relat", "wicket", "2765", "as", "thi", "seem", "point", "when", "col", "wa", "ad", "openclosetagexpand", "open", "close", "tag", "expand", "class", "note", "that", "it", "ok", "have", "non", "close", "col", "tag", "html", "self", "close", "xhtml", "it", "all", "about", "gener", "separ", "end", "tag", "thi", "happen", "wicket", "but", "guess", "it", "relev", "all", "version", "down", "wicket", "spec", "refer", "http", "html401", "w3", "html", "www", "org", "tr", "1999", "rec", "19991224", "struct", "tabl", "edef", "col", "http", "w3", "html", "www", "org", "tr", "html", "markup", "col", "kind", "regard", "konrad"], "B_title": "Wicket generates invalid HTML by expanding col tags", "B_clean_title": ["wicket", "gener", "invalid", "html", "by", "expand", "col", "tag"]},
{"A_title": "g/apache/wicket/protocol/http/request/UserAgent matches method is not correctIn the UserAgent Enum matches method the loop over detectionStrings is at most executed once:      for (List<String> detectionGroup : detectionStrings)            for (String detectionString : detectionGroup)                if (!userAgent.contains(detectionString))                    return false;                        return true;       It returns true after only processing the first element in the detectionStrings list. It never looks at any of the other elements of the list.", "A_clean_title": ["apach", "wicket", "protocol", "http", "request", "userag", "user", "agent", "match", "method", "not", "correctin", "correct", "userag", "user", "agent", "enum", "match", "method", "loop", "over", "detectionstr", "detect", "string", "at", "most", "execut", "onc", "list", "string", "detectiongroup", "detect", "group", "detectionstr", "detect", "string", "string", "detectionstr", "detect", "string", "detectiongroup", "detect", "group", "userag", "contain", "user", "agent", "detectionstr", "detect", "string", "return", "fals", "return", "true", "it", "return", "true", "after", "onli", "process", "first", "element", "detectionstr", "detect", "string", "list", "it", "never", "look", "at", "ani", "other", "element", "list"], "B_title": "org/apache/wicket/protocol/http/request/UserAgent matches method is not correct", "B_clean_title": ["org", "apach", "wicket", "protocol", "http", "request", "userag", "user", "agent", "match", "method", "not", "correct"]},
{"A_title": "ClusterNodeInfo does not pick an existing entry on startupWhen the DocumentNodeStore starts up it attempts to find an entry that matches the current instance (which is defined by something based on network interface address and the current working directory).  However an additional check is done when the cluster lease end time hasnt been reached in which case the entry is skipped (assuming it belongs to a different instance) and the scan continues. When no other entry is found a new one is created.  So why would we *ever* consider instances with matching instance information to be different? As far as I can tell the answer is: for unit testing.  But...  With the current assignment very weird things can happen and I believe I see exactly this happening in a customer problem Im investigating. The sequence is:  1) First system startup cluster node id 1 is assigned  2) System crashes or was crashed  3) System restarts within the lease time (120s?) a new cluster node id is assigned  4) System shuts down and gets restarted after a longer interval: cluster id 1 is used again and system starts MissingLastRevRecovery despite the previous shutdown having been clean  So what we see is that the system starts up with varying cluster node ids and recovery processes may run with no correlation to what happened before.  Proposal:  a) Make ClusterNodeInfo.createInstance() much more verbose so that the default system log contains sufficient information to understand why a certain cluster node id was picked.  b) Drop the logic that skips entries with non-expired leases so that we get a one-to-one relation between instance ids and cluster node ids. For the unit tests that currently rely on this logic switch to APIs where the test setup picks the cluster node id.", "A_clean_title": ["clusternodeinfo", "cluster", "node", "info", "not", "pick", "exist", "entri", "startupwhen", "startup", "when", "documentnodestor", "document", "node", "store", "start", "up", "it", "attempt", "find", "entri", "that", "match", "current", "instanc", "which", "defin", "by", "someth", "base", "network", "interfac", "address", "current", "work", "directori", "howev", "addit", "check", "done", "when", "cluster", "leas", "end", "time", "hasnt", "been", "reach", "which", "case", "entri", "skip", "assum", "it", "belong", "differ", "instanc", "scan", "continu", "when", "no", "other", "entri", "found", "new", "one", "creat", "so", "whi", "would", "we", "ever", "consid", "instanc", "match", "instanc", "inform", "differ", "as", "far", "as", "tell", "answer", "unit", "test", "but", "current", "assign", "veri", "weird", "thing", "happen", "believ", "see", "exactli", "thi", "happen", "custom", "problem", "im", "investig", "sequenc", "first", "system", "startup", "cluster", "node", "id", "assign", "system", "crash", "or", "wa", "crash", "system", "restart", "within", "leas", "time", "120", "new", "cluster", "node", "id", "assign", "system", "shut", "down", "get", "restart", "after", "longer", "interv", "cluster", "id", "use", "again", "system", "start", "missinglastrevrecoveri", "miss", "last", "rev", "recoveri", "despit", "previou", "shutdown", "have", "been", "clean", "so", "what", "we", "see", "that", "system", "start", "up", "vari", "cluster", "node", "id", "recoveri", "process", "may", "run", "no", "correl", "what", "happen", "befor", "propos", "make", "clusternodeinfo", "createinst", "cluster", "node", "info", "creat", "instanc", "much", "more", "verbos", "so", "that", "default", "system", "log", "contain", "suffici", "inform", "understand", "whi", "certain", "cluster", "node", "id", "wa", "pick", "drop", "logic", "that", "skip", "entri", "non", "expir", "leas", "so", "that", "we", "get", "one", "one", "relat", "between", "instanc", "id", "cluster", "node", "id", "unit", "test", "that", "current", "reli", "thi", "logic", "switch", "api", "ap", "where", "test", "setup", "pick", "cluster", "node", "id"], "B_title": "change ClusterNodeInfo to potentially wait for an abandoned cluster id to become available", "B_clean_title": ["chang", "clusternodeinfo", "cluster", "node", "info", "potenti", "wait", "abandon", "cluster", "id", "becom", "avail"]},
{"A_title": "Not expected UnboundedSolutionExceptionSimplexSolver throws UnboundedSolutionException when trying to solve minimization linear programming problem. The number of exception thrown depends on the number of variables.  In order to see that behavior of SimplexSolver first try to run JUnit test setting a final variable ENTITIES_COUNT = 2 and that will give almost good result and then set it to 15 and youll get a massive of unbounded exceptions. First iteration is runned with predefined set of input data with which the Solver gives back an appropriate result.  The problem itself is well tested by its authors (mathematicians who I believe know what they developed) using Matlab 10 with no unbounded solutions on the same rules of creatnig random variables values.  What is strange to me is the dependence of the number of UnboundedSolutionException exceptions on the number of variables in the problem.  The problem is formulated as min(1*t + 0*L) (for every r-th subject) s.t. -q(r) + QL >= 0 x(r)t - XL >= 0 L >= 0 where  r = 1..R  L = l(1) l(2) ... l(R) (vector of R rows and 1 column) Q - coefficients matrix MxR X - coefficients matrix NxR", "A_clean_title": ["not", "expect", "unboundedsolutionexceptionsimplexsolv", "unbound", "solut", "except", "simplex", "solver", "throw", "unboundedsolutionexcept", "unbound", "solut", "except", "when", "tri", "solv", "minim", "linear", "program", "problem", "number", "except", "thrown", "depend", "number", "variabl", "order", "see", "that", "behavior", "simplexsolv", "simplex", "solver", "first", "tri", "run", "junit", "unit", "test", "set", "final", "variabl", "entiti", "count", "that", "will", "give", "almost", "good", "result", "then", "set", "it", "15", "youll", "get", "massiv", "unbound", "except", "first", "iter", "run", "predefin", "set", "input", "data", "which", "solver", "give", "back", "appropri", "result", "problem", "itself", "well", "test", "by", "it", "author", "mathematician", "who", "believ", "know", "what", "they", "develop", "matlab", "10", "no", "unbound", "solut", "same", "rule", "creatnig", "random", "variabl", "valu", "what", "strang", "me", "depend", "number", "unboundedsolutionexcept", "unbound", "solut", "except", "except", "number", "variabl", "problem", "problem", "formul", "as", "min", "everi", "th", "subject", "ql", "xl", "where", "vector", "row", "column", "coeffici", "matrix", "mxr", "mx", "coeffici", "matrix", "nxr", "nx"], "B_title": "Add additional heuristic for rare cases in pivotRow selection.", "B_clean_title": ["add", "addit", "heurist", "rare", "case", "pivotrow", "pivot", "row", "select"]},
{"A_title": "@SpringBean(name=something required=false) still throws org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named something is definedExample:  code public class TwitterLoginLink extends StatelessLink<Void>   @SpringBean(name=twitterMgr required=false) private TwitterManager twitterMgr; code  still throws:  code org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named twitterMgr is defined at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanDefinition(DefaultListableBeanFactory.java:641) at org.springframework.beans.factory.support.AbstractBeanFactory.getMergedLocalBeanDefinition(AbstractBeanFactory.java:1159) at org.springframework.beans.factory.support.AbstractBeanFactory.isSingleton(AbstractBeanFactory.java:418) at org.springframework.context.support.AbstractApplicationContext.isSingleton(AbstractApplicationContext.java:1002) at org.apache.wicket.spring.SpringBeanLocator.isSingletonBean(SpringBeanLocator.java) at org.apache.wicket.spring.injection.annot.AnnotProxyFieldValueFactory.getFieldValue(AnnotProxyFieldValueFactory.java:141) at org.apache.wicket.injection.Injector.inject(Injector.java:111) at org.apache.wicket.spring.injection.annot.SpringComponentInjector.inject(SpringComponentInjector.java:124) at org.apache.wicket.spring.injection.annot.SpringComponentInjector.onInstantiation(SpringComponentInjector.java:130) at org.apache.wicket.application.ComponentInstantiationListenerCollection 1.notify(ComponentInstantiationListenerCollection.java:38) at org.apache.wicket.application.ComponentInstantiationListenerCollection 1.notify(ComponentInstantiationListenerCollection.java:34) at org.apache.wicket.util.listener.ListenerCollection.notify(ListenerCollection.java:80) at org.apache.wicket.application.ComponentInstantiationListenerCollection.onInstantiation(ComponentInstantiationListenerCollection.java:33) at org.apache.wicket.Component.<init>(Component.java:686) at org.apache.wicket.MarkupContainer.<init>(MarkupContainer.java:121) at org.apache.wicket.markup.html.WebMarkupContainer.<init>(WebMarkupContainer.java:52) at org.apache.wicket.markup.html.link.AbstractLink.<init>(AbstractLink.java:57) at org.apache.wicket.markup.html.link.AbstractLink.<init>(AbstractLink.java:44) at org.apache.wicket.markup.html.link.Link.<init>(Link.java:105) at org.apache.wicket.markup.html.link.StatelessLink.<init>(StatelessLink.java:42) at org.soluvas.web.login.twitter.TwitterLoginLink.<init>(TwitterLoginLink.java:40) at org.soluvas.web.login.DedicatedLoginPanel FormSignIn.<init>(DedicatedLoginPanel.java:90) at org.soluvas.web.login.DedicatedLoginPanel.onInitialize(DedicatedLoginPanel.java:58) at org.apache.wicket.Component.fireInitialize(Component.java:876) at org.apache.wicket.MarkupContainer 3.component(MarkupContainer.java:967) at org.apache.wicket.MarkupContainer 3.component(MarkupContainer.java:963) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:192) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:875) at org.apache.wicket.MarkupContainer.internalInitialize(MarkupContainer.java:962) at org.apache.wicket.Page.isPageStateless(Page.java:463) at org.apache.wicket.core.request.mapper.AbstractBookmarkableMapper.getPageInfo(AbstractBookmarkableMapper.java:447) at org.apache.wicket.core.request.mapper.AbstractBookmarkableMapper.mapHandler(AbstractBookmarkableMapper.java:391) at org.apache.wicket.core.request.mapper.MountedMapper.mapHandler(MountedMapper.java:395) at org.apache.wicket.request.mapper.CompoundRequestMapper.mapHandler(CompoundRequestMapper.java:215) at org.apache.wicket.request.cycle.RequestCycle.mapUrlFor(RequestCycle.java:429) at org.apache.wicket.request.handler.render.WebPageRenderer.respond(WebPageRenderer.java:273) at org.apache.wicket.core.request.handler.RenderPageRequestHandler.respond(RenderPageRequestHandler.java:175) at org.apache.wicket.request.cycle.RequestCycle HandlerExecutor.respond(RequestCycle.java:862) at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:64) at org.apache.wicket.request.cycle.RequestCycle.execute(RequestCycle.java:261) at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:218) at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:289) at org.apache.wicket.protocol.http.WicketFilter.processRequestCycle(WicketFilter.java:259) at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:201) at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:282) at org.soluvas.web.site.SecuredWicketAtmosphereHandler CustomFilterChain.doFilter(SecuredWicketAtmosphereHandler.java:199) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter 1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:344) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:261) at org.soluvas.web.site.SecuredWicketAtmosphereHandler CustomFilterChain.doFilter(SecuredWicketAtmosphereHandler.java:199) at org.soluvas.web.site.SecuredWicketAtmosphereHandler CustomFilterChain.invokeFilterChain(SecuredWicketAtmosphereHandler.java:185) at org.soluvas.web.site.SecuredWicketAtmosphereHandler.onRequest(SecuredWicketAtmosphereHandler.java:91) at org.atmosphere.cpr.AsynchronousProcessor.action(AsynchronousProcessor.java:187) at org.atmosphere.cpr.AsynchronousProcessor.suspended(AsynchronousProcessor.java:98) at org.atmosphere.container.Tomcat7CometSupport.service(Tomcat7CometSupport.java:96) at org.atmosphere.cpr.AtmosphereFramework.doCometSupport(AtmosphereFramework.java:1809) at org.atmosphere.cpr.AtmosphereServlet.event(AtmosphereServlet.java:255) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilterEvent(ApplicationFilterChain.java:484) at org.apache.catalina.core.ApplicationFilterChain.doFilterEvent(ApplicationFilterChain.java:377) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220) at org.apache.catalina.core.StandardContextValve.__invoke(StandardContextValve.java:123) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502) at org.apache.catalina.core.StandardHostValve.__invoke(StandardHostValve.java:171) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99) at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:953) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408) at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1023) at org.apache.coyote.AbstractProtocol AbstractConnectionHandler.process(AbstractProtocol.java:589) at org.apache.tomcat.util.net.AprEndpoint SocketWithOptionsProcessor.run(AprEndpoint.java:1810) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) code  Workaround:  code     @Autowire(required=false)     private TwitterManager twitterMgr; code", "A_clean_title": ["springbean", "spring", "bean", "name=someth", "required=fals", "still", "throw", "org", "springframework", "bean", "factori", "nosuchbeandefinitionexcept", "no", "such", "bean", "definit", "except", "no", "bean", "name", "someth", "definedexampl", "defin", "exampl", "code", "public", "class", "twitterloginlink", "twitter", "login", "link", "extend", "statelesslink", "stateless", "link", "void", "springbean", "spring", "bean", "name=twittermgr", "name=twitt", "mgr", "required=fals", "privat", "twittermanag", "twitter", "manag", "twittermgr", "twitter", "mgr", "code", "still", "throw", "code", "org", "springframework", "bean", "factori", "nosuchbeandefinitionexcept", "no", "such", "bean", "definit", "except", "no", "bean", "name", "twittermgr", "twitter", "mgr", "defin", "at", "org", "springframework", "bean", "factori", "support", "defaultlistablebeanfactori", "getbeandefinit", "default", "listabl", "bean", "factori", "get", "bean", "definit", "defaultlistablebeanfactori", "java:641", "default", "listabl", "bean", "factori", "at", "org", "springframework", "bean", "factori", "support", "abstractbeanfactori", "getmergedlocalbeandefinit", "abstract", "bean", "factori", "get", "merg", "local", "bean", "definit", "abstractbeanfactori", "java:1159", "abstract", "bean", "factori", "at", "org", "springframework", "bean", "factori", "support", "abstractbeanfactori", "issingleton", "abstract", "bean", "factori", "singleton", "abstractbeanfactori", "java:418", "abstract", "bean", "factori", "at", "org", "springframework", "context", "support", "abstractapplicationcontext", "issingleton", "abstract", "applic", "context", "singleton", "abstractapplicationcontext", "java:1002", "abstract", "applic", "context", "at", "org", "apach", "wicket", "spring", "springbeanloc", "issingletonbean", "spring", "bean", "locat", "singleton", "bean", "springbeanloc", "java", "spring", "bean", "locat", "at", "org", "apach", "wicket", "spring", "inject", "annot", "annotproxyfieldvaluefactori", "getfieldvalu", "annot", "proxi", "field", "valu", "factori", "get", "field", "valu", "annotproxyfieldvaluefactori", "java:141", "annot", "proxi", "field", "valu", "factori", "at", "org", "apach", "wicket", "inject", "injector", "inject", "injector", "java:111", "at", "org", "apach", "wicket", "spring", "inject", "annot", "springcomponentinjector", "inject", "spring", "compon", "injector", "springcomponentinjector", "java:124", "spring", "compon", "injector", "at", "org", "apach", "wicket", "spring", "inject", "annot", "springcomponentinjector", "oninstanti", "spring", "compon", "injector", "instanti", "springcomponentinjector", "java:130", "spring", "compon", "injector", "at", "org", "apach", "wicket", "applic", "componentinstantiationlistenercollect", "compon", "instanti", "listen", "collect", "notifi", "componentinstantiationlistenercollect", "java:38", "compon", "instanti", "listen", "collect", "at", "org", "apach", "wicket", "applic", "componentinstantiationlistenercollect", "compon", "instanti", "listen", "collect", "notifi", "componentinstantiationlistenercollect", "java:34", "compon", "instanti", "listen", "collect", "at", "org", "apach", "wicket", "util", "listen", "listenercollect", "notifi", "listen", "collect", "listenercollect", "java:80", "listen", "collect", "at", "org", "apach", "wicket", "applic", "componentinstantiationlistenercollect", "oninstanti", "compon", "instanti", "listen", "collect", "instanti", "componentinstantiationlistenercollect", "java:33", "compon", "instanti", "listen", "collect", "at", "org", "apach", "wicket", "compon", "init", "compon", "java:686", "at", "org", "apach", "wicket", "markupcontain", "markup", "contain", "init", "markupcontain", "java:121", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "webmarkupcontain", "web", "markup", "contain", "init", "webmarkupcontain", "java:52", "web", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "link", "abstractlink", "abstract", "link", "init", "abstractlink", "java:57", "abstract", "link", "at", "org", "apach", "wicket", "markup", "html", "link", "abstractlink", "abstract", "link", "init", "abstractlink", "java:44", "abstract", "link", "at", "org", "apach", "wicket", "markup", "html", "link", "link", "init", "link", "java:105", "at", "org", "apach", "wicket", "markup", "html", "link", "statelesslink", "stateless", "link", "init", "statelesslink", "java:42", "stateless", "link", "at", "org", "soluva", "web", "login", "twitter", "twitterloginlink", "twitter", "login", "link", "init", "twitterloginlink", "java:40", "twitter", "login", "link", "at", "org", "soluva", "web", "login", "dedicatedloginpanel", "dedic", "login", "panel", "formsignin", "form", "sign", "init", "dedicatedloginpanel", "java:90", "dedic", "login", "panel", "at", "org", "soluva", "web", "login", "dedicatedloginpanel", "oniniti", "dedic", "login", "panel", "initi", "dedicatedloginpanel", "java:58", "dedic", "login", "panel", "at", "org", "apach", "wicket", "compon", "fireiniti", "fire", "initi", "compon", "java:876", "at", "org", "apach", "wicket", "markupcontain", "markup", "contain", "compon", "markupcontain", "java:967", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "markup", "contain", "compon", "markupcontain", "java:963", "markup", "contain", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:192", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:875", "markup", "contain", "at", "org", "apach", "wicket", "markupcontain", "internaliniti", "markup", "contain", "intern", "initi", "markupcontain", "java:962", "markup", "contain", "at", "org", "apach", "wicket", "page", "ispagestateless", "page", "stateless", "page", "java:463", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractbookmarkablemapp", "getpageinfo", "abstract", "bookmark", "mapper", "get", "page", "info", "abstractbookmarkablemapp", "java:447", "abstract", "bookmark", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractbookmarkablemapp", "maphandl", "abstract", "bookmark", "mapper", "map", "handler", "abstractbookmarkablemapp", "java:391", "abstract", "bookmark", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "mountedmapp", "maphandl", "mount", "mapper", "map", "handler", "mountedmapp", "java:395", "mount", "mapper", "at", "org", "apach", "wicket", "request", "mapper", "compoundrequestmapp", "maphandl", "compound", "request", "mapper", "map", "handler", "compoundrequestmapp", "java:215", "compound", "request", "mapper", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "mapurlfor", "request", "cycl", "map", "url", "requestcycl", "java:429", "request", "cycl", "at", "org", "apach", "wicket", "request", "handler", "render", "webpagerender", "respond", "web", "page", "render", "webpagerender", "java:273", "web", "page", "render", "at", "org", "apach", "wicket", "core", "request", "handler", "renderpagerequesthandl", "respond", "render", "page", "request", "handler", "renderpagerequesthandl", "java:175", "render", "page", "request", "handler", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "request", "cycl", "handlerexecutor", "respond", "handler", "executor", "requestcycl", "java:862", "request", "cycl", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:64", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "execut", "request", "cycl", "requestcycl", "java:261", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:218", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:289", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequestcycl", "wicket", "filter", "process", "request", "cycl", "wicketfilt", "java:259", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:201", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:282", "wicket", "filter", "at", "org", "soluva", "web", "site", "securedwicketatmospherehandl", "secur", "wicket", "atmospher", "handler", "customfilterchain", "dofilt", "custom", "filter", "chain", "filter", "securedwicketatmospherehandl", "java:199", "secur", "wicket", "atmospher", "handler", "at", "org", "apach", "shiro", "web", "servlet", "abstractshirofilt", "executechain", "abstract", "shiro", "filter", "execut", "chain", "abstractshirofilt", "java:449", "abstract", "shiro", "filter", "at", "org", "apach", "shiro", "web", "servlet", "abstractshirofilt", "abstract", "shiro", "filter", "call", "abstractshirofilt", "java:365", "abstract", "shiro", "filter", "at", "org", "apach", "shiro", "subject", "support", "subjectcal", "docal", "subject", "callabl", "call", "subjectcal", "java:90", "subject", "callabl", "at", "org", "apach", "shiro", "subject", "support", "subjectcal", "call", "subject", "callabl", "subjectcal", "java:83", "subject", "callabl", "at", "org", "apach", "shiro", "subject", "support", "delegatingsubject", "execut", "deleg", "subject", "delegatingsubject", "java:383", "deleg", "subject", "at", "org", "apach", "shiro", "web", "servlet", "abstractshirofilt", "dofilterintern", "abstract", "shiro", "filter", "filter", "intern", "abstractshirofilt", "java:362", "abstract", "shiro", "filter", "at", "org", "apach", "shiro", "web", "servlet", "onceperrequestfilt", "dofilt", "onc", "per", "request", "filter", "filter", "onceperrequestfilt", "java:125", "onc", "per", "request", "filter", "at", "org", "springframework", "web", "filter", "delegatingfilterproxi", "invokedeleg", "deleg", "filter", "proxi", "invok", "deleg", "delegatingfilterproxi", "java:344", "deleg", "filter", "proxi", "at", "org", "springframework", "web", "filter", "delegatingfilterproxi", "dofilt", "deleg", "filter", "proxi", "filter", "delegatingfilterproxi", "java:261", "deleg", "filter", "proxi", "at", "org", "soluva", "web", "site", "securedwicketatmospherehandl", "secur", "wicket", "atmospher", "handler", "customfilterchain", "dofilt", "custom", "filter", "chain", "filter", "securedwicketatmospherehandl", "java:199", "secur", "wicket", "atmospher", "handler", "at", "org", "soluva", "web", "site", "securedwicketatmospherehandl", "secur", "wicket", "atmospher", "handler", "customfilterchain", "invokefilterchain", "custom", "filter", "chain", "invok", "filter", "chain", "securedwicketatmospherehandl", "java:185", "secur", "wicket", "atmospher", "handler", "at", "org", "soluva", "web", "site", "securedwicketatmospherehandl", "onrequest", "secur", "wicket", "atmospher", "handler", "request", "securedwicketatmospherehandl", "java:91", "secur", "wicket", "atmospher", "handler", "at", "org", "atmospher", "cpr", "asynchronousprocessor", "action", "asynchron", "processor", "asynchronousprocessor", "java:187", "asynchron", "processor", "at", "org", "atmospher", "cpr", "asynchronousprocessor", "suspend", "asynchron", "processor", "asynchronousprocessor", "java:98", "asynchron", "processor", "at", "org", "atmospher", "contain", "tomcat7cometsupport", "servic", "tomcat7comet", "support", "tomcat7cometsupport", "java:96", "tomcat7comet", "support", "at", "org", "atmospher", "cpr", "atmosphereframework", "docometsupport", "atmospher", "framework", "comet", "support", "atmosphereframework", "java:1809", "atmospher", "framework", "at", "org", "atmospher", "cpr", "atmosphereservlet", "event", "atmospher", "servlet", "atmosphereservlet", "java:255", "atmospher", "servlet", "at", "org", "apach", "catalina", "core", "applicationfilterchain", "internaldofilterev", "applic", "filter", "chain", "intern", "filter", "event", "applicationfilterchain", "java:484", "applic", "filter", "chain", "at", "org", "apach", "catalina", "core", "applicationfilterchain", "dofilterev", "applic", "filter", "chain", "filter", "event", "applicationfilterchain", "java:377", "applic", "filter", "chain", "at", "org", "apach", "catalina", "core", "standardwrappervalv", "invok", "standard", "wrapper", "valv", "standardwrappervalv", "java:220", "standard", "wrapper", "valv", "at", "org", "apach", "catalina", "core", "standardcontextvalv", "standard", "context", "valv", "invok", "standardcontextvalv", "java:123", "standard", "context", "valv", "at", "org", "apach", "catalina", "core", "standardcontextvalv", "invok", "standard", "context", "valv", "standardcontextvalv", "java", "standard", "context", "valv", "at", "org", "apach", "catalina", "authent", "authenticatorbas", "invok", "authent", "base", "authenticatorbas", "java:502", "authent", "base", "at", "org", "apach", "catalina", "core", "standardhostvalv", "standard", "host", "valv", "invok", "standardhostvalv", "java:171", "standard", "host", "valv", "at", "org", "apach", "catalina", "core", "standardhostvalv", "invok", "standard", "host", "valv", "standardhostvalv", "java", "standard", "host", "valv", "at", "org", "apach", "catalina", "valv", "errorreportvalv", "invok", "error", "report", "valv", "errorreportvalv", "java:99", "error", "report", "valv", "at", "org", "apach", "catalina", "valv", "accesslogvalv", "invok", "access", "log", "valv", "accesslogvalv", "java:953", "access", "log", "valv", "at", "org", "apach", "catalina", "core", "standardenginevalv", "invok", "standard", "engin", "valv", "standardenginevalv", "java:118", "standard", "engin", "valv", "at", "org", "apach", "catalina", "connector", "coyoteadapt", "servic", "coyot", "adapt", "coyoteadapt", "java:408", "coyot", "adapt", "at", "org", "apach", "coyot", "http11", "abstracthttp11processor", "process", "abstract", "http11processor", "abstracthttp11processor", "java:1023", "abstract", "http11processor", "at", "org", "apach", "coyot", "abstractprotocol", "abstract", "protocol", "abstractconnectionhandl", "process", "abstract", "connect", "handler", "abstractprotocol", "java:589", "abstract", "protocol", "at", "org", "apach", "tomcat", "util", "net", "aprendpoint", "apr", "endpoint", "socketwithoptionsprocessor", "run", "socket", "option", "processor", "aprendpoint", "java:1810", "apr", "endpoint", "at", "java", "util", "concurr", "threadpoolexecutor", "runwork", "thread", "pool", "executor", "run", "worker", "threadpoolexecutor", "java:1142", "thread", "pool", "executor", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:617", "thread", "pool", "executor", "at", "java", "lang", "thread", "run", "thread", "java:745", "code", "workaround", "code", "autowir", "required=fals", "privat", "twittermanag", "twitter", "manag", "twittermgr", "twitter", "mgr", "code"], "B_title": "@SpringBean(name=something required=false) still throws org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named something is defined", "B_clean_title": ["springbean", "spring", "bean", "name=someth", "required=fals", "still", "throw", "org", "springframework", "bean", "factori", "nosuchbeandefinitionexcept", "no", "such", "bean", "definit", "except", "no", "bean", "name", "someth", "defin"]},
{"A_title": "The default exception mapper is replying cacheable exceptional responsesThe problem is that some common URLs in the application like to a page instance are responding the cached exception page rather than hitting the server for the page instance being requested. It happens because at some moment in the past a exception page were replied and cached for a request in this URL.", "A_clean_title": ["default", "except", "mapper", "repli", "cacheabl", "except", "responsesth", "respons", "problem", "that", "some", "common", "url", "ur", "ls", "applic", "like", "page", "instanc", "are", "respond", "cach", "except", "page", "rather", "than", "hit", "server", "page", "instanc", "be", "request", "it", "happen", "becaus", "at", "some", "moment", "past", "except", "page", "were", "repli", "cach", "request", "thi", "url"], "B_title": "preventing exceptional responses from being cached and overlay next requests replay on the same address", "B_clean_title": ["prevent", "except", "respons", "be", "cach", "overlay", "next", "request", "replay", "same", "address"]},
{"A_title": "A mapping service mapping error has its toString value inserted into an integrated datasetHow to Reproduce     Go to the mapping service  Create a new mapping project with  Add TypeTestRef as new source  Edit label attribute  Fill in  Create integrated dataset  Expected behaviour  Mapping fails because the validation for the label to label mapping contains script errors  Observed behaviour  The mapping is executed and the toString() value of the error is inserted as a label", "A_clean_title": ["map", "servic", "map", "error", "ha", "it", "tostr", "string", "valu", "insert", "into", "integr", "datasethow", "dataset", "how", "reproduc", "go", "map", "servic", "creat", "new", "map", "project", "add", "typetestref", "type", "test", "ref", "as", "new", "sourc", "edit", "label", "attribut", "fill", "creat", "integr", "dataset", "expect", "behaviour", "map", "fail", "becaus", "valid", "label", "label", "map", "contain", "script", "error", "observ", "behaviour", "map", "execut", "tostr", "string", "valu", "error", "insert", "as", "label"], "B_title": "Merge pull request #7125 from Mark-de-Haan/fix/7110  Fix #7110 A mapping service mapping error has its toString value inserted into an integrated dataset", "B_clean_title": ["merg", "pull", "request", "7125", "mark", "de", "haan", "fix", "7110", "fix", "7110", "map", "servic", "map", "error", "ha", "it", "tostr", "string", "valu", "insert", "into", "integr", "dataset"]},
{"A_title": "Fix case-insensitive string handlingString.to*Case() is locale-sensitive this is usually not intended for case-insensitive comparisions. Please see Common Bug #3 for details.", "A_clean_title": ["fix", "case", "insensit", "string", "handlingstr", "handl", "string", "case", "local", "sensit", "thi", "usual", "not", "intend", "case", "insensit", "comparis", "pleas", "see", "common", "bug", "detail"], "B_title": "Applying the final part of Benjamin Bentmanns patch to LANG-432 improving our handling of case-insensitive Strings", "B_clean_title": ["appli", "final", "part", "benjamin", "bentmann", "patch", "lang", "432", "improv", "our", "handl", "case", "insensit", "string"]},
{"A_title": "Allow @private top-level functions in goog.scopeNone", "A_clean_title": ["allow", "privat", "top", "level", "function", "goog", "scopenon", "scope", "none"], "B_title": "Handle function declarations in ScopedAliases. Fixes issue 1111 R=johnlenz", "B_clean_title": ["handl", "function", "declar", "scopedalias", "scope", "alias", "fix", "issu", "1111", "r=johnlenz"]},
{"A_title": "FastDateFormat.format() outputs incorrect week of year because locale isnt respectedFastDateFormat apparently doesnt respect the locale it was sent on creation when outputting week in year (e.g. ww) in format(). It seems to use the settings of the system locale for firstDayOfWeek and minimalDaysInFirstWeek which (depending on the year) may result in the incorrect week number being output. Here is a simple test program to demonstrate the problem by comparing with SimpleDateFormat which gets the week number right:  import java.util.Calendar; import java.util.Date; import java.util.Locale; import java.text.SimpleDateFormat;  import org.apache.commons.lang.time.FastDateFormat;  public class FastDateFormatWeekBugDemo      public static void main(String args)          Locale.setDefault(new Locale(en US));         Locale locale = new Locale(sv SE);          Calendar cal = Calendar.getInstance(); // setting locale here doesnt change outcome         cal.set(2010 0 1 12 0 0);         Date d = cal.getTime();         System.out.println(Target date:  + d);          FastDateFormat fdf = FastDateFormat.getInstance(EEEE week ww locale);         SimpleDateFormat sdf = new SimpleDateFormat(EEEE week ww locale);         System.out.println(FastDateFormat:    + fdf.format(d)); // will output FastDateFormat:   fredag week 01         System.out.println(SimpleDateFormat:  + sdf.format(d)); // will output SimpleDateFormat: fredag week 53         If sv/SE is passed to Locale.setDefault() instead of en/US both FastDateFormat and SimpleDateFormat output the correct week number.", "A_clean_title": ["fastdateformat", "format", "fast", "date", "format", "output", "incorrect", "week", "year", "becaus", "local", "isnt", "respectedfastdateformat", "respect", "fast", "date", "format", "appar", "doesnt", "respect", "local", "it", "wa", "sent", "creation", "when", "output", "week", "year", "ww", "format", "it", "seem", "use", "set", "system", "local", "firstdayofweek", "first", "day", "week", "minimaldaysinfirstweek", "minim", "day", "first", "week", "which", "depend", "year", "may", "result", "incorrect", "week", "number", "be", "output", "here", "simpl", "test", "program", "demonstr", "problem", "by", "compar", "simpledateformat", "simpl", "date", "format", "which", "get", "week", "number", "right", "import", "java", "util", "calendar", "import", "java", "util", "date", "import", "java", "util", "local", "import", "java", "text", "simpledateformat", "simpl", "date", "format", "import", "org", "apach", "common", "lang", "time", "fastdateformat", "fast", "date", "format", "public", "class", "fastdateformatweekbugdemo", "fast", "date", "format", "week", "bug", "demo", "public", "static", "void", "main", "string", "arg", "local", "setdefault", "set", "default", "new", "local", "en", "us", "local", "local", "new", "local", "sv", "se", "calendar", "cal", "calendar", "getinst", "get", "instanc", "set", "local", "here", "doesnt", "chang", "outcom", "cal", "set", "2010", "12", "date", "cal", "gettim", "get", "time", "system", "out", "println", "target", "date", "fastdateformat", "fast", "date", "format", "fdf", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "eeee", "week", "ww", "local", "simpledateformat", "simpl", "date", "format", "sdf", "new", "simpledateformat", "simpl", "date", "format", "eeee", "week", "ww", "local", "system", "out", "println", "fastdateformat", "fast", "date", "format", "fdf", "format", "will", "output", "fastdateformat", "fast", "date", "format", "fredag", "week", "01", "system", "out", "println", "simpledateformat", "simpl", "date", "format", "sdf", "format", "will", "output", "simpledateformat", "simpl", "date", "format", "fredag", "week", "53", "sv", "se", "pass", "local", "setdefault", "set", "default", "instead", "en", "us", "both", "fastdateformat", "fast", "date", "format", "simpledateformat", "simpl", "date", "format", "output", "correct", "week", "number"], "B_title": "Applying my fix to LANG-645 and Mikaels test case; fixing the FastDateFormat to properly include the locale when formatting a Date", "B_clean_title": ["appli", "my", "fix", "lang", "645", "mikael", "test", "case", "fix", "fastdateformat", "fast", "date", "format", "properli", "includ", "local", "when", "format", "date"]},
{"A_title": "WizardStep FormValidatorWrapper.isActiveStep(WizardStep.java) causes NullPointerExceptionUsing the Wizard with a nested WizardModel (see RecursiveWizardModel implementation at the attached quickstart application) causes a NullPointerException. I was able to run the same test application with wicket 1.4.18 without any problems.  Caused by: java.lang.NullPointerException         at org.apache.wicket.extensions.wizard.WizardStep FormValidatorWrapper.isActiveStep(WizardStep.java:145)         at org.apache.wicket.extensions.wizard.WizardStep FormValidatorWrapper.getDependentFormComponents(WizardStep.java:109)         at org.apache.wicket.markup.html.form.validation.FormValidatorAdapter.getDependentFormComponents(FormValidatorAdapter.java:47)         at org.apache.wicket.markup.html.form.Form.validateFormValidator(Form.java:1782)         at org.apache.wicket.markup.html.form.Form.validateFormValidators(Form.java:1828)         at org.apache.wicket.markup.html.form.Form.validate(Form.java:1706)         at org.apache.wicket.markup.html.form.Form.process(Form.java:773)         at org.apache.wicket.markup.html.form.Form.onFormSubmitted(Form.java:728)         at org.apache.wicket.markup.html.form.Form.onFormSubmitted(Form.java:670)", "A_clean_title": ["wizardstep", "wizard", "step", "formvalidatorwrapp", "isactivestep", "form", "valid", "wrapper", "activ", "step", "wizardstep", "java", "wizard", "step", "caus", "nullpointerexceptionus", "null", "pointer", "except", "wizard", "nest", "wizardmodel", "wizard", "model", "see", "recursivewizardmodel", "recurs", "wizard", "model", "implement", "at", "attach", "quickstart", "applic", "caus", "nullpointerexcept", "null", "pointer", "except", "wa", "abl", "run", "same", "test", "applic", "wicket", "18", "without", "ani", "problem", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "wicket", "extens", "wizard", "wizardstep", "wizard", "step", "formvalidatorwrapp", "isactivestep", "form", "valid", "wrapper", "activ", "step", "wizardstep", "java:145", "wizard", "step", "at", "org", "apach", "wicket", "extens", "wizard", "wizardstep", "wizard", "step", "formvalidatorwrapp", "getdependentformcompon", "form", "valid", "wrapper", "get", "depend", "form", "compon", "wizardstep", "java:109", "wizard", "step", "at", "org", "apach", "wicket", "markup", "html", "form", "valid", "formvalidatoradapt", "getdependentformcompon", "form", "valid", "adapt", "get", "depend", "form", "compon", "formvalidatoradapt", "java:47", "form", "valid", "adapt", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "validateformvalid", "valid", "form", "valid", "form", "java:1782", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "validateformvalid", "valid", "form", "valid", "form", "java:1828", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "valid", "form", "java:1706", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "process", "form", "java:773", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "onformsubmit", "form", "submit", "form", "java:728", "at", "org", "apach", "wicket", "markup", "html", "form", "form", "onformsubmit", "form", "submit", "form", "java:670"], "B_title": "let wizard initialize its own steps", "B_clean_title": ["let", "wizard", "initi", "it", "own", "step"]},
{"A_title": "Error trying to build try-catch block (AST)None", "A_clean_title": ["error", "tri", "build", "tri", "catch", "block", "ast", "none"], "B_title": "Correct IR helpers for TRY nodes. Fixes issue 727.", "B_clean_title": ["correct", "ir", "helper", "tri", "node", "fix", "issu", "727"]},
{"A_title": "Oak Analyzer cant tokenize chinese phrasesIt looks like the _WhitespaceTokenizer_ cannot properly split Chinese phrases for example 美女衬衫. I could not find a reference to this issue other than LUCENE-5096.  The fix is to switch to the _ClassicTokenizer_ which seems better equipped for this kind of task.", "A_clean_title": ["oak", "analyz", "cant", "token", "chines", "phrasesit", "phrase", "it", "look", "like", "whitespacetoken", "whitespac", "token", "not", "properli", "split", "chines", "phrase", "exampl", "could", "not", "find", "refer", "thi", "issu", "other", "than", "lucen", "5096", "fix", "switch", "classictoken", "classic", "token", "which", "seem", "better", "equip", "thi", "kind", "task"], "B_title": "Oak Analyzer cant tokenize chinese phrases", "B_clean_title": ["oak", "analyz", "cant", "token", "chines", "phrase"]},
{"A_title": "Casting a function before calling it produces bad code and breaks plugin codeNone", "A_clean_title": ["cast", "function", "befor", "call", "it", "produc", "bad", "code", "break", "plugin", "codenon", "code", "none"], "B_title": "Look through CAST nodes when annotating CALL nodes as free calls. Fixes issue 937 ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=44143144", "B_clean_title": ["look", "through", "cast", "node", "when", "annot", "call", "node", "as", "free", "call", "fix", "issu", "937", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=44143144"]},
{"A_title": "Multiple events in AjaxEventBehavior with prefix onif multiple events are used and one starts with on it only works if it is the first one because of:  code if (event.startsWith(on))  event = event.substring(2);  code  Why are events possible to start with on ?   Is this legacy? Perhaps should be removed for Wicket 7 ?", "A_clean_title": ["multipl", "event", "ajaxeventbehavior", "ajax", "event", "behavior", "prefix", "onif", "multipl", "event", "are", "use", "one", "start", "it", "onli", "work", "it", "first", "one", "becaus", "code", "event", "startswith", "start", "event", "event", "substr", "code", "whi", "are", "event", "possibl", "start", "thi", "legaci", "perhap", "remov", "wicket"], "B_title": "Multiple events in AjaxEventBehavior with prefix on", "B_clean_title": ["multipl", "event", "ajaxeventbehavior", "ajax", "event", "behavior", "prefix"]},
{"A_title": "NPE in the TypeValidator when using the Lucene IndexNone", "A_clean_title": ["npe", "typevalid", "type", "valid", "when", "lucen", "indexnon", "index", "none"], "B_title": "NPE in the TypeValidator when using the Lucene Index", "B_clean_title": ["npe", "typevalid", "type", "valid", "when", "lucen", "index"]},
{"A_title": "When using Servlet 3.0 filter Wicket calculates filter path wrongWhen using a servlet 3.0 filter with annotations Wicket calculates the filter path wrong causing it to not match any pages other than the home page.  e.g.  code @WebFilter(value = /web/* initParams = @WebInitParam(name = applicationClassName value = com.example.CheesrApplication)) public class CheesrFilter extends WicketFilter   code  Will cause Wicket to create a filter path of /web/*/ instead of the expected /web.", "A_clean_title": ["when", "servlet", "filter", "wicket", "calcul", "filter", "path", "wrongwhen", "wrong", "when", "servlet", "filter", "annot", "wicket", "calcul", "filter", "path", "wrong", "caus", "it", "not", "match", "ani", "page", "other", "than", "home", "page", "code", "webfilt", "web", "filter", "valu", "web", "initparam", "init", "param", "webinitparam", "web", "init", "param", "name", "applicationclassnam", "applic", "class", "name", "valu", "com", "exampl", "cheesrappl", "cheesr", "applic", "public", "class", "cheesrfilt", "cheesr", "filter", "extend", "wicketfilt", "wicket", "filter", "code", "will", "caus", "wicket", "creat", "filter", "path", "web", "instead", "expect", "web"], "B_title": "Servlet 3 Filter path calculated wrong", "B_clean_title": ["servlet", "filter", "path", "calcul", "wrong"]},
{"A_title": "PropertyStates#createProperty ignores namespace mappings when creating states of type NAME and PATHas far as i saw we use PropertyStates#createProperty to create and set an OAK property from a given JCR value or a list of JCR values.  this works well for all types of values except for NAME PATH which  may contain values with remapped namespaces which will not be converted back to oak-values during the state creation:  code      List<String> vals = Lists.newArrayList();      for (Value value : values)           vals.add(value.getString());            return new MultiGenericPropertyState(name vals Type.fromTag(type true)); code  if am not mistaken codevalue.getString()code will return the JCR representation of the value instead of the oak representation as it would be needed here.  possible solutions include: - passing namepathmapper to the create method - only accept oak Value implementation that allows to retrieve the   internal representation which is present in the ValueImpl afaik.", "A_clean_title": ["propertyst", "properti", "state", "createproperti", "creat", "properti", "ignor", "namespac", "map", "when", "creat", "state", "type", "name", "patha", "pat", "ha", "far", "as", "saw", "we", "use", "propertyst", "properti", "state", "createproperti", "creat", "properti", "creat", "set", "oak", "properti", "given", "jcr", "valu", "or", "list", "jcr", "valu", "thi", "work", "well", "all", "type", "valu", "except", "name", "path", "which", "may", "contain", "valu", "remap", "namespac", "which", "will", "not", "convert", "back", "oak", "valu", "dure", "state", "creation", "code", "list", "string", "val", "list", "newarraylist", "new", "array", "list", "valu", "valu", "valu", "val", "add", "valu", "getstr", "get", "string", "return", "new", "multigenericpropertyst", "multi", "gener", "properti", "state", "name", "val", "type", "fromtag", "tag", "type", "true", "code", "am", "not", "mistaken", "codevalu", "getstr", "get", "string", "code", "will", "return", "jcr", "represent", "valu", "instead", "oak", "represent", "as", "it", "would", "need", "here", "possibl", "solut", "includ", "pass", "namepathmapp", "creat", "method", "onli", "accept", "oak", "valu", "implement", "that", "allow", "retriev", "intern", "represent", "which", "present", "valueimpl", "valu", "impl", "afaik"], "B_title": "PropertyStates#createProperty ignores namespace mappings when creating states of type NAME and PATH", "B_clean_title": ["propertyst", "properti", "state", "createproperti", "creat", "properti", "ignor", "namespac", "map", "when", "creat", "state", "type", "name", "path"]},
{"A_title": "Inconsistent result from Levenberg-MarquardtLevenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However the class holds the optimum point the vector of the objective function the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost", "A_clean_title": ["inconsist", "result", "levenberg", "marquardtlevenberg", "marquardt", "marquardt", "levenberg", "it", "method", "dooptim", "optim", "return", "vectorialpointvaluepair", "vectori", "point", "valu", "pair", "howev", "class", "hold", "optimum", "point", "vector", "object", "function", "cost", "residu", "valu", "return", "by", "dooptim", "optim", "not", "alway", "correspond", "point", "which", "lead", "residu", "cost"], "B_title": "corrected", "B_clean_title": ["correct"]},
{"A_title": "Query: UnsupportedOperationException for some combinations of or and and conditionsThe following query throws an UnsupportedOperationException:  noformat select * from nt:base    where a = 1 and b = 2 and b = 3 or c = 4 noformat", "A_clean_title": ["queri", "unsupportedoperationexcept", "unsupport", "oper", "except", "some", "combin", "or", "conditionsth", "condit", "follow", "queri", "throw", "unsupportedoperationexcept", "unsupport", "oper", "except", "noformat", "select", "nt", "base", "where", "or", "noformat"], "B_title": "Query: UnsupportedOperationException for some combinations of or and and conditions", "B_clean_title": ["queri", "unsupportedoperationexcept", "unsupport", "oper", "except", "some", "combin", "or", "condit"]},
{"A_title": "QueryParse exception when fulltext search performed with term having /Running the below query results in Exception pointed by 1  /jcr:root/content/dam//element(*dam:Asset)jcr:contains(jcr:content/metadata/@cq:tags stockphotography:business/business_abstract) order by @jcr:created descending  Also if you remove the node at /oak:index/damAssetLucene/indexRules/dam:Asset/properties/cqTags  and re-index the /oak:index/damAssetLucene index the query works.  Seems / is special character and needs to be escaped by Oak.  1 noformat Caused by: org.apache.lucene.queryparser.flexible.core.QueryNodeParseException: Syntax Error cannot parse stockphotography:business/business_abstract: Lexical error at line 1 column 45.  Encountered: <EOF> after : /business_abstract  at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.parse(StandardSyntaxParser.java:74) at org.apache.lucene.queryparser.flexible.core.QueryParserHelper.parse(QueryParserHelper.java:250) at org.apache.lucene.queryparser.flexible.standard.StandardQueryParser.parse(StandardQueryParser.java:168) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex.tokenToQuery(LucenePropertyIndex.java:1260) ... 138 common frames omitted Caused by: org.apache.lucene.queryparser.flexible.standard.parser.TokenMgrError: Lexical error at line 1 column 45.  Encountered: <EOF> after : /business_abstract at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParserTokenManager.getNextToken(StandardSyntaxParserTokenManager.java:937) at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.jj_scan_token(StandardSyntaxParser.java:945) at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.jj_3R_4(StandardSyntaxParser.java:827) at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.jj_3_2(StandardSyntaxParser.java:739) at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.jj_2_2(StandardSyntaxParser.java:730) at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.Clause(StandardSyntaxParser.java:318) at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.ModClause(StandardSyntaxParser.java:303) at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.ConjQuery(StandardSyntaxParser.java:234) at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.DisjQuery(StandardSyntaxParser.java:204) at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.Query(StandardSyntaxParser.java:166) at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.TopLevelQuery(StandardSyntaxParser.java:147) at org.apache.lucene.queryparser.flexible.standard.parser.StandardSyntaxParser.parse(StandardSyntaxParser.java:65) ... 141 common frames omitted noformat", "A_clean_title": ["querypars", "queri", "pars", "except", "when", "fulltext", "search", "perform", "term", "have", "run", "below", "queri", "result", "except", "point", "by", "jcr", "root", "content", "dam", "element", "dam", "asset", "jcr", "contain", "jcr", "content", "metadata", "cq", "tag", "stockphotographi", "abstract", "busi", "busi", "order", "by", "jcr", "creat", "descend", "also", "you", "remov", "node", "at", "oak", "index", "damassetlucen", "indexrul", "dam", "dam", "asset", "lucen", "index", "rule", "asset", "properti", "cqtag", "cq", "tag", "re", "index", "oak", "index", "damassetlucen", "dam", "asset", "lucen", "index", "queri", "work", "seem", "special", "charact", "need", "escap", "by", "oak", "noformat", "caus", "by", "org", "apach", "lucen", "querypars", "flexibl", "core", "querynodeparseexcept", "queri", "node", "pars", "except", "syntax", "error", "not", "pars", "stockphotographi", "abstract", "busi", "busi", "lexic", "error", "at", "line", "column", "45", "encount", "eof", "after", "abstract", "busi", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "pars", "standard", "syntax", "parser", "standardsyntaxpars", "java:74", "standard", "syntax", "parser", "at", "org", "apach", "lucen", "querypars", "flexibl", "core", "queryparserhelp", "pars", "queri", "parser", "helper", "queryparserhelp", "java:250", "queri", "parser", "helper", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "standardquerypars", "pars", "standard", "queri", "parser", "standardquerypars", "java:168", "standard", "queri", "parser", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "tokentoqueri", "lucen", "properti", "index", "token", "queri", "lucenepropertyindex", "java:1260", "lucen", "properti", "index", "138", "common", "frame", "omit", "caus", "by", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "tokenmgrerror", "token", "mgr", "error", "lexic", "error", "at", "line", "column", "45", "encount", "eof", "after", "abstract", "busi", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxparsertokenmanag", "getnexttoken", "standard", "syntax", "parser", "token", "manag", "get", "next", "token", "standardsyntaxparsertokenmanag", "java:937", "standard", "syntax", "parser", "token", "manag", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "standard", "syntax", "parser", "jj", "scan", "token", "standardsyntaxpars", "java:945", "standard", "syntax", "parser", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "standard", "syntax", "parser", "jj", "3r", "standardsyntaxpars", "java:827", "standard", "syntax", "parser", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "standard", "syntax", "parser", "jj", "standardsyntaxpars", "java:739", "standard", "syntax", "parser", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "standard", "syntax", "parser", "jj", "standardsyntaxpars", "java:730", "standard", "syntax", "parser", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "claus", "standard", "syntax", "parser", "standardsyntaxpars", "java:318", "standard", "syntax", "parser", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "modclaus", "standard", "syntax", "parser", "mod", "claus", "standardsyntaxpars", "java:303", "standard", "syntax", "parser", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "conjqueri", "standard", "syntax", "parser", "conj", "queri", "standardsyntaxpars", "java:234", "standard", "syntax", "parser", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "disjqueri", "standard", "syntax", "parser", "disj", "queri", "standardsyntaxpars", "java:204", "standard", "syntax", "parser", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "queri", "standard", "syntax", "parser", "standardsyntaxpars", "java:166", "standard", "syntax", "parser", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "toplevelqueri", "standard", "syntax", "parser", "top", "level", "queri", "standardsyntaxpars", "java:147", "standard", "syntax", "parser", "at", "org", "apach", "lucen", "querypars", "flexibl", "standard", "parser", "standardsyntaxpars", "pars", "standard", "syntax", "parser", "standardsyntaxpars", "java:65", "standard", "syntax", "parser", "141", "common", "frame", "omit", "noformat"], "B_title": "- QueryParse exception when fulltext search performed with term having /", "B_clean_title": ["querypars", "queri", "pars", "except", "when", "fulltext", "search", "perform", "term", "have"]},
{"A_title": "CryptoMapper encrypts external URLs in ResourceReferences making the resources inaccessibleShort Description:   CryptoMapper encrypts links to resources with URLs of the form:  - http://domain/path/script.js  - /local/absolute/path/script.js  Additionally there might be some inconsistencies in handling URLs in instances of ResourceReference.  The problem occurs when JavaScript resources are included in the following way:  @Override public void renderHead(IHeaderResponse response)  super.renderHead(response);  UrlResourceReference reference = new UrlResourceReference(Url.parse(http://domain/path/script.js)); response.render(reference);   The resulting JavaScript links cant be loaded (404 is returned) when CryptoMapper is used.  This is a minor problem because the following always works for JavaScript files not served by Wicket (external JavaScript files):  response.render(new StringHeaderItem(<script type=text/javascript src=//domain/myPath/manual.js></script>);   Ways to reproduce:     A code example for wicket-examples is attached (example.zip)   Local URLs:      http://localhost:8080/enc/index      http://localhost:8080/unenc/index   Possible fix:    - disable encryption for URLs beginning with / <schema>:// and // and not served/filtered by Wicket   (  - define different reference classes for external files and files served/filtered by Wicket issue warnings when a wrong URL type is supplied by the user or treat URLs beginning with / <schema>:// and // differently  )  Thank you", "A_clean_title": ["cryptomapp", "crypto", "mapper", "encrypt", "extern", "url", "ur", "ls", "resourcerefer", "resourc", "refer", "make", "resourc", "inaccessibleshort", "inaccess", "short", "descript", "cryptomapp", "crypto", "mapper", "encrypt", "link", "resourc", "url", "ur", "ls", "form", "http", "js", "domain", "path", "script", "js", "local", "absolut", "path", "script", "addit", "there", "might", "some", "inconsist", "handl", "url", "ur", "ls", "instanc", "resourcerefer", "resourc", "refer", "problem", "occur", "when", "javascript", "java", "script", "resourc", "are", "includ", "follow", "way", "overrid", "public", "void", "renderhead", "render", "head", "iheaderrespons", "header", "respons", "respons", "super", "renderhead", "render", "head", "respons", "urlresourcerefer", "url", "resourc", "refer", "refer", "new", "urlresourcerefer", "url", "resourc", "refer", "url", "pars", "http", "js", "domain", "path", "script", "respons", "render", "refer", "result", "javascript", "java", "script", "link", "cant", "load", "404", "return", "when", "cryptomapp", "crypto", "mapper", "use", "thi", "minor", "problem", "becaus", "follow", "alway", "work", "javascript", "java", "script", "file", "not", "serv", "by", "wicket", "extern", "javascript", "java", "script", "file", "respons", "render", "new", "stringheaderitem", "string", "header", "item", "script", "type=text", "javascript", "js", "src=", "domain", "mypath", "manual", "my", "path", "script", "way", "reproduc", "code", "exampl", "wicket", "exampl", "attach", "exampl", "zip", "local", "url", "ur", "ls", "http", "localhost:8080", "enc", "index", "http", "localhost:8080", "unenc", "index", "possibl", "fix", "disabl", "encrypt", "url", "ur", "ls", "begin", "schema", "not", "serv", "filter", "by", "wicket", "defin", "differ", "refer", "class", "extern", "file", "file", "serv", "filter", "by", "wicket", "issu", "warn", "when", "wrong", "url", "type", "suppli", "by", "user", "or", "treat", "url", "ur", "ls", "begin", "schema", "differ", "thank", "you"], "B_title": "do not encrypt full urls", "B_clean_title": ["not", "encrypt", "full", "url"]},
{"A_title": "ShutdownTServer never sets requestedShutdownACCUMULO-1259 made ShutdownTServer a bit more sane WRT to what it was doing and the FATE repo interface.  One attempt it makes it to not repeatedly invoke shutdownTServer on the master..  Except requestedShutdown is never set to true.", "A_clean_title": ["shutdowntserv", "shutdown", "server", "never", "set", "requestedshutdownaccumulo", "1259", "request", "shutdown", "accumulo", "made", "shutdowntserv", "shutdown", "server", "bit", "more", "sane", "wrt", "what", "it", "wa", "do", "fate", "repo", "interfac", "one", "attempt", "it", "make", "it", "not", "repeatedli", "invok", "shutdowntserv", "shutdown", "server", "master", "except", "requestedshutdown", "request", "shutdown", "never", "set", "true"], "B_title": "Only request shutdown to master once for tserver", "B_clean_title": ["onli", "request", "shutdown", "master", "onc", "tserver"]},
{"A_title": "CancelTaskException leads to FAILED task stateThe CancelTaskException is thrown to trigger canceling of the executing task. It is intended to cause a cancelled status rather than a failed status.  Currently it leads to a FAILED state instead of the expected CANCELED state.", "A_clean_title": ["canceltaskexcept", "cancel", "task", "except", "lead", "fail", "task", "stateth", "state", "canceltaskexcept", "cancel", "task", "except", "thrown", "trigger", "cancel", "execut", "task", "it", "intend", "caus", "cancel", "statu", "rather", "than", "fail", "statu", "current", "it", "lead", "fail", "state", "instead", "expect", "cancel", "state"], "B_title": "runtime Fix CancelTaskException handling", "B_clean_title": ["runtim", "fix", "canceltaskexcept", "cancel", "task", "except", "handl"]},
{"A_title": "Lucene index not created if no node is indexedIf a Lucene property index is defined for a property which is not present in any of the nodes then LuceneIndexWriter would create any lucene index for that.  For eg if we have an index of foo and none of the node has property foo set in that case LuceneIndexWriter would not create an IndexWriter and hence no directory would be created. Later when system performs a query like select jcr:path from nt:base where foo = bar then LucenePropertyIndex would not participate in the query as no Lucene index would be found and system would revert to traversal.  As a fix Lucene index should still be created even if it does not contain any document", "A_clean_title": ["lucen", "index", "not", "creat", "no", "node", "indexedif", "index", "lucen", "properti", "index", "defin", "properti", "which", "not", "present", "ani", "node", "then", "luceneindexwrit", "lucen", "index", "writer", "would", "creat", "ani", "lucen", "index", "that", "eg", "we", "have", "index", "foo", "none", "node", "ha", "properti", "foo", "set", "that", "case", "luceneindexwrit", "lucen", "index", "writer", "would", "not", "creat", "indexwrit", "index", "writer", "henc", "no", "directori", "would", "creat", "later", "when", "system", "perform", "queri", "like", "select", "jcr", "path", "nt", "base", "where", "foo", "bar", "then", "lucenepropertyindex", "lucen", "properti", "index", "would", "not", "particip", "queri", "as", "no", "lucen", "index", "would", "found", "system", "would", "revert", "travers", "as", "fix", "lucen", "index", "still", "creat", "even", "it", "not", "contain", "ani", "document"], "B_title": "- Lucene index not created if no node is indexed", "B_clean_title": ["lucen", "index", "not", "creat", "no", "node", "index"]},
{"A_title": "Codepoint U+007f appears raw in outputNone", "A_clean_title": ["codepoint", "u+007f", "appear", "raw", "outputnon", "output", "none"], "B_title": "Codepoint U+007f should not appear raw in output Fixes issue 416 http://code.google.com/p/closure-compiler/issues/detail?id=416", "B_clean_title": ["codepoint", "u+007f", "not", "appear", "raw", "output", "fix", "issu", "416", "http", "googl", "compil", "issu", "detail", "code", "com", "closur", "id=416"]},
{"A_title": "NPE when calling SubLine.intersection() with non-intersecting linesWhen calling SubLine.intersection() with two lines that not intersect then a NullPointerException is thrown in Line.toSubSpace(). This bug is in the twod and threed implementations. The attached patch fixes both implementations and adds the required test cases.", "A_clean_title": ["npe", "when", "call", "sublin", "intersect", "sub", "line", "non", "intersect", "lineswhen", "line", "when", "call", "sublin", "intersect", "sub", "line", "two", "line", "that", "not", "intersect", "then", "nullpointerexcept", "null", "pointer", "except", "thrown", "line", "tosubspac", "sub", "space", "thi", "bug", "twod", "threed", "implement", "attach", "patch", "fix", "both", "implement", "add", "requir", "test", "case"], "B_title": "Fixed NullPointerException in 2D and 3D sub-line intersections.", "B_clean_title": ["fix", "nullpointerexcept", "null", "pointer", "except", "2d", "3d", "sub", "line", "intersect"]},
{"A_title": "&amp; instead of & in javascriptthe non httpsessionstore part of: https://issues.apache.org/jira/browse/WICKET-1971  is that   in the  wicket:ignoreIfNotActive actually becomes  amp;wicket:ignoreIfNotActive=true  in:  protected CharSequence encode(RequestCycle requestCycle IListenerInterfaceRequestTarget requestTarget)  of WebRequestCodingStrategy on the line:  url.append(url.indexOf(?) > -1 ? &amp; : ?).append( IGNORE_IF_NOT_ACTIVE_PARAMETER_NAME).append(=true);   so when this happens in  public final RequestParameters decode(final Request request)   --- if (request.getParameter(IGNORE_IF_NOT_ACTIVE_PARAMETER_NAME) != null)  parameters.setOnlyProcessIfPathActive(true);  ---  this never actually happens.   then if you have a throttle ajaxlazyloadpanel etc with onlyprocessifpathactive set to true and you logout but go to another wicket page then the original session is destroyed and a new one is created  if this is worked around in the way the  guys on WICKET-1971 suggest WebRequestCycleProcessor  method  public IRequestTarget resolve(final RequestCycle requestCycle final RequestParameters requestParameters)   if (requestParameters.isOnlyProcessIfPathActive()) last branch falls through: else  // TODO also this should work..    and it throws PageExpiredException because the request component/page/behavior does not exist in this new session.   even though onlyprocessifpathactive was set to true and its purpose is precisely to avoid pageexpiredexception.", "A_clean_title": ["amp", "instead", "javascriptth", "non", "httpsessionstor", "part", "http", "1971", "apach", "issu", "org", "jira", "brows", "wicket", "that", "wicket", "ignoreifnotact", "ignor", "not", "activ", "actual", "becom", "amp", "wicket", "ignoreifnotactive=tru", "ignor", "not", "active=tru", "protect", "charsequ", "char", "sequenc", "encod", "requestcycl", "request", "cycl", "requestcycl", "request", "cycl", "ilistenerinterfacerequesttarget", "listen", "interfac", "request", "target", "requesttarget", "request", "target", "webrequestcodingstrategi", "web", "request", "code", "strategi", "line", "url", "append", "url", "indexof", "index", "amp", "append", "ignor", "not", "activ", "paramet", "name", "append", "=true", "so", "when", "thi", "happen", "public", "final", "requestparamet", "request", "paramet", "decod", "final", "request", "request", "request", "getparamet", "get", "paramet", "ignor", "not", "activ", "paramet", "name", "null", "paramet", "setonlyprocessifpathact", "set", "onli", "process", "path", "activ", "true", "thi", "never", "actual", "happen", "then", "you", "have", "throttl", "ajaxlazyloadpanel", "etc", "onlyprocessifpathact", "set", "true", "you", "logout", "but", "go", "anoth", "wicket", "page", "then", "origin", "session", "destroy", "new", "one", "creat", "thi", "work", "around", "way", "guy", "wicket", "1971", "suggest", "webrequestcycleprocessor", "web", "request", "cycl", "processor", "method", "public", "irequesttarget", "request", "target", "resolv", "final", "requestcycl", "request", "cycl", "requestcycl", "request", "cycl", "final", "requestparamet", "request", "paramet", "requestparamet", "request", "paramet", "requestparamet", "isonlyprocessifpathact", "request", "paramet", "onli", "process", "path", "activ", "last", "branch", "fall", "through", "todo", "also", "thi", "work", "it", "throw", "pageexpiredexcept", "page", "expir", "except", "becaus", "request", "compon", "page", "behavior", "not", "exist", "thi", "new", "session", "even", "though", "onlyprocessifpathact", "wa", "set", "true", "it", "purpos", "precis", "avoid", "pageexpiredexcept"], "B_title": "&amp; instead of & in javascript Issue: WICKET-2033", "B_clean_title": ["amp", "instead", "javascript", "issu", "wicket", "2033"]},
{"A_title": "SecuritySettings.setEnforceMounts() does not work when the mounted mapper is not in the root compound mapperBookmarkableMapper.isPageMounted() assumes that all mounted mappers are in Application.getRootRequestMapperAsCompound(). Sometimes the mappers make a tree structure with multiple compounds existing sometimes separated by wrappers like HttpsMapper and CryptoMapper.  Because of this BookmarkableMapper fails to realise that a page is mounted and so does not enforce mounting.", "A_clean_title": ["securityset", "setenforcemount", "secur", "set", "set", "enforc", "mount", "not", "work", "when", "mount", "mapper", "not", "root", "compound", "mapperbookmarkablemapp", "ispagemount", "mapper", "bookmark", "mapper", "page", "mount", "assum", "that", "all", "mount", "mapper", "are", "applic", "getrootrequestmapperascompound", "get", "root", "request", "mapper", "as", "compound", "sometim", "mapper", "make", "tree", "structur", "multipl", "compound", "exist", "sometim", "separ", "by", "wrapper", "like", "httpsmapper", "http", "mapper", "cryptomapp", "crypto", "mapper", "becaus", "thi", "bookmarkablemapp", "bookmark", "mapper", "fail", "realis", "that", "page", "mount", "so", "not", "enforc", "mount"], "B_title": "SecuritySettings.setEnforceMounts() does not work when the mounted mapper is not in the root compound mapper", "B_clean_title": ["securityset", "setenforcemount", "secur", "set", "set", "enforc", "mount", "not", "work", "when", "mount", "mapper", "not", "root", "compound", "mapper"]},
{"A_title": "Garbage collector deleted everything when given bad inputPatch v3 of the upgrade from ACCUMULO-2145 had a test that did the following before upgrade.  noformat root@testUp> table !METADATA root@testUp !METADATA> grant Table.WRITE -u root  root@testUp !METADATA> insert ~del testDel test valueTest noformat  This is a malformed delete entry.  Accumulo code should not delete such entries.  When the 1.5.1 garbage collector saw this it did the following.  noformat 2014-03-20 18:20:05359 gc.SimpleGarbageCollector DEBUG: Deleting /accumuloTest/tables 2014-03-20 18:20:05359 gc.SimpleGarbageCollector DEBUG: Deleting /accumuloTest/tables/!0/default_tablet/F0000009.rf 2014-03-20 18:20:05360 gc.SimpleGarbageCollector DEBUG: Deleting /accumuloTest/tables/!0/table_info/F000000b.rf noformat  GC should validate that delete entries are paths of the expected length.  I have confirmed this bug exist in 1.5.1.  I am assuming it exist in 1.4 and 1.6 branches.", "A_clean_title": ["garbag", "collector", "delet", "everyth", "when", "given", "bad", "inputpatch", "input", "patch", "v3", "upgrad", "accumulo", "2145", "had", "test", "that", "did", "follow", "befor", "upgrad", "noformat", "root", "testup", "test", "up", "tabl", "metadata", "root", "testup", "test", "up", "metadata", "grant", "tabl", "write", "root", "root", "testup", "test", "up", "metadata", "insert", "~del", "testdel", "test", "del", "test", "valuetest", "valu", "test", "noformat", "thi", "malform", "delet", "entri", "accumulo", "code", "not", "delet", "such", "entri", "when", "garbag", "collector", "saw", "thi", "it", "did", "follow", "noformat", "2014", "03", "20", "18:20:05359", "gc", "simplegarbagecollector", "simpl", "garbag", "collector", "debug", "delet", "accumulotest", "tabl", "accumulo", "test", "2014", "03", "20", "18:20:05359", "gc", "simplegarbagecollector", "simpl", "garbag", "collector", "debug", "delet", "accumulotest", "tabl", "accumulo", "test", "rf", "default", "tablet", "f0000009", "2014", "03", "20", "18:20:05360", "gc", "simplegarbagecollector", "simpl", "garbag", "collector", "debug", "delet", "accumulotest", "tabl", "accumulo", "test", "rf", "tabl", "info", "f000000b", "noformat", "gc", "valid", "that", "delet", "entri", "are", "path", "expect", "length", "have", "confirm", "thi", "bug", "exist", "am", "assum", "it", "exist", "branch"], "B_title": "GC changes : disallow a delete marker of hdfs://nn/ log a warning about invalid delete and add test for bad delete markers", "B_clean_title": ["gc", "chang", "disallow", "delet", "marker", "hdf", "nn", "log", "warn", "about", "invalid", "delet", "add", "test", "bad", "delet", "marker"]},
{"A_title": "Mounted bookmarkable Page not recreated on Session ExpiryWith the default true of org.apache.wicket.settings.IPageSettings#getRecreateMountedPagesAfterExpiry() PageExpiryException is thrown when a Link on a page is clicked.  I find it very useful and in fact indispensible to rely on RecreateMountedPagesAfterExpiry especially on logout links.  But it doesnt seem to work for me in 6.4.0. I think this is because Link#getUrl() calls Component#utlFor() which requires a stateless page for this to work:  if (page.isPageStateless())  handler = new BookmarkableListenerInterfaceRequestHandler(provider listener);  else  handler = new ListenerInterfaceRequestHandler(provider listener);   With a stateless page a url is:  http://localhost:8080/wicket/HomePage?-1.ILinkListener-toolBar-signout  With a non stateless but bookmarkable page a url is:  http://localhost:8080/wicket/page?1-1.ILinkListener-toolBar-signout  So I guess that a stateful page cannot be recovered because after session expiry Wicket cannot find out what the page is. It is not coded in the URL.  Looking at the semantics of UrlFor() I thought this might be a bug and I copied and changed the code in my Link subclass from  //if (page.isPageStateless())  to:         if (page.isBookmarkable())   It works as expected but I dont know whether it would break other things if implemented in Wicket.  I guess I am not the only one who needs recovery for bookmarkable pages in this way. Would it be possible to change Wicket to fix this so it becomes possible?", "A_clean_title": ["mount", "bookmark", "page", "not", "recreat", "session", "expirywith", "expiri", "default", "true", "org", "apach", "wicket", "set", "ipageset", "page", "set", "getrecreatemountedpagesafterexpiri", "get", "recreat", "mount", "page", "after", "expiri", "pageexpiryexcept", "page", "expiri", "except", "thrown", "when", "link", "page", "click", "find", "it", "veri", "use", "fact", "indispens", "reli", "recreatemountedpagesafterexpiri", "recreat", "mount", "page", "after", "expiri", "especi", "logout", "link", "but", "it", "doesnt", "seem", "work", "me", "think", "thi", "becaus", "link", "geturl", "get", "url", "call", "compon", "utlfor", "utl", "which", "requir", "stateless", "page", "thi", "work", "page", "ispagestateless", "page", "stateless", "handler", "new", "bookmarkablelistenerinterfacerequesthandl", "bookmark", "listen", "interfac", "request", "handler", "provid", "listen", "handler", "new", "listenerinterfacerequesthandl", "listen", "interfac", "request", "handler", "provid", "listen", "stateless", "page", "url", "http", "localhost:8080", "wicket", "homepag", "home", "page", "toolbar", "signout", "ilinklisten", "tool", "bar", "link", "listen", "non", "stateless", "but", "bookmark", "page", "url", "http", "localhost:8080", "wicket", "page", "toolbar", "signout", "ilinklisten", "tool", "bar", "link", "listen", "so", "guess", "that", "state", "page", "not", "recov", "becaus", "after", "session", "expiri", "wicket", "not", "find", "out", "what", "page", "it", "not", "code", "url", "look", "at", "semant", "urlfor", "url", "thought", "thi", "might", "bug", "copi", "chang", "code", "my", "link", "subclass", "page", "ispagestateless", "page", "stateless", "page", "isbookmark", "bookmark", "it", "work", "as", "expect", "but", "dont", "know", "whether", "it", "would", "break", "other", "thing", "implement", "wicket", "guess", "am", "not", "onli", "one", "who", "need", "recoveri", "bookmark", "page", "thi", "way", "would", "it", "possibl", "chang", "wicket", "fix", "thi", "so", "it", "becom", "possibl"], "B_title": "more restrictive condition for using bookmarkable urls", "B_clean_title": ["more", "restrict", "condit", "bookmark", "url"]},
{"A_title": "Lucene index / compatVersion 2: search for abc! does not workWhen using a Lucene fulltext index with compatVersion 2 then the following query does not return any results. When using compatVersion 1 the correct result is returned.  noformat SELECT * FROM nt:unstructured AS c  WHERE CONTAINS(c.jcr:description abc!)  AND ISDESCENDANTNODE(c /content) noformat  With compatVersion 1 and 2 searching for just abc works. Also searching with = instead of contains works.", "A_clean_title": ["lucen", "index", "compatvers", "compat", "version", "search", "abc", "not", "workwhen", "work", "when", "lucen", "fulltext", "index", "compatvers", "compat", "version", "then", "follow", "queri", "not", "return", "ani", "result", "when", "compatvers", "compat", "version", "correct", "result", "return", "noformat", "select", "nt", "unstructur", "as", "where", "contain", "jcr", "descript", "abc", "isdescendantnod", "content", "noformat", "compatvers", "compat", "version", "search", "just", "abc", "work", "also", "search", "instead", "contain", "work"], "B_title": "- Lucene index / compatVersion 2: search for abc! does not work", "B_clean_title": ["lucen", "index", "compatvers", "compat", "version", "search", "abc", "not", "work"]},
{"A_title": "Branch conflicts not detected by MongoMKMongoMK does not correctly detect conflicts when changes are committed into multiple branches concurrently and then merged back.  ConflictTest already covers conflict detection for non-branch commits and mixed branch/non-branch changes but is missing tests for conflicting branches. Ill commit an ignored test to illustrate the problem.", "A_clean_title": ["branch", "conflict", "not", "detect", "by", "mongomkmongomk", "mongo", "mk", "mongo", "mk", "not", "correctli", "detect", "conflict", "when", "chang", "are", "commit", "into", "multipl", "branch", "concurr", "then", "merg", "back", "conflicttest", "conflict", "test", "alreadi", "cover", "conflict", "detect", "non", "branch", "commit", "mix", "branch", "branch", "non", "chang", "but", "miss", "test", "conflict", "branch", "ill", "commit", "ignor", "test", "illustr", "problem"], "B_title": "Branch conflicts not detected by MongoMK", "B_clean_title": ["branch", "conflict", "not", "detect", "by", "mongomk", "mongo", "mk"]},
{"A_title": "fixed a verify() call example in @Captor javadoc.None", "A_clean_title": ["fix", "verifi", "call", "exampl", "captor", "javadoc", "none"], "B_title": "Fix for issue 229 in the describeTo phase of the Same matcher when match is failing", "B_clean_title": ["fix", "issu", "229", "describeto", "describ", "phase", "same", "matcher", "when", "match", "fail"]},
{"A_title": "Variable called java messes with the importsHello  Im Spooning the JUnit4 source code and in the following class  a variable has been named java:  String java = System.getProperty(java.home) + File.separator + bin + File.separator + java; I configured my launcher with  launcher.getEnvironment().setAutoImports(false);  after running the launcher the following code is generated:  java.lang.String java = ((((java.lang.System.getProperty(java.home)) + (java.io.File.separator)) + bin) + (java.io.File.separator)) + java; Which is completely normal but the compilation will fail because java.lang.System refers to the java String declared earlier which has no lang attribute (obviously).  Since my previous issue Im running Spoon using  launcher.getEnvironment().setAutoImports(false); . Since it is quite specific Im renaming the Java variable in the source code but it can be a bit time-consuming when theres multiple classes with a similar variable.  Thibault", "A_clean_title": ["variabl", "call", "java", "mess", "importshello", "import", "hello", "im", "spoon", "junit4", "unit4", "sourc", "code", "follow", "class", "variabl", "ha", "been", "name", "java", "string", "java", "system", "getproperti", "get", "properti", "java", "home", "file", "separ", "bin", "file", "separ", "java", "configur", "my", "launcher", "launcher", "getenviron", "get", "environ", "setautoimport", "set", "auto", "import", "fals", "after", "run", "launcher", "follow", "code", "gener", "java", "lang", "string", "java", "java", "lang", "system", "getproperti", "get", "properti", "java", "home", "java", "io", "file", "separ", "bin", "java", "io", "file", "separ", "java", "which", "complet", "normal", "but", "compil", "will", "fail", "becaus", "java", "lang", "system", "refer", "java", "string", "declar", "earlier", "which", "ha", "no", "lang", "attribut", "obvious", "sinc", "my", "previou", "issu", "im", "run", "spoon", "launcher", "getenviron", "get", "environ", "setautoimport", "set", "auto", "import", "fals", "sinc", "it", "quit", "specif", "im", "renam", "java", "variabl", "sourc", "code", "but", "it", "bit", "time", "consum", "when", "there", "multipl", "class", "similar", "variabl", "thibault"], "B_title": "fix: improve ImportScanner to support variables called java (#1321)  fix #1320", "B_clean_title": ["fix", "improv", "importscann", "import", "scanner", "support", "variabl", "call", "java", "1321", "fix", "1320"]},
{"A_title": "ConvergenceException in NormalDistributionImpl.cumulativeProbability()I get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity -Infinity. For instance in the following code:  @Test public void testCumulative()  final NormalDistribution nd = new NormalDistributionImpl(); for (int i = 0; i < 500; i++)  final double val = Math.exp(i); try  System.out.println(val =  + val +  cumulative =  + nd.cumulativeProbability(val));  catch (MathException e)  e.printStackTrace(); fail();     In version 2.0 I get no exception.   My suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values) not just MaxIterationsExceededException.", "A_clean_title": ["convergenceexcept", "converg", "except", "normaldistributionimpl", "cumulativeprob", "normal", "distribut", "impl", "cumul", "probabl", "get", "convergenceexcept", "converg", "except", "normaldistributionimpl", "cumulativeprob", "normal", "distribut", "impl", "cumul", "probabl", "veri", "larg", "small", "paramet", "includ", "infin", "infin", "instanc", "follow", "code", "test", "public", "void", "testcumul", "test", "cumul", "final", "normaldistribut", "normal", "distribut", "nd", "new", "normaldistributionimpl", "normal", "distribut", "impl", "int", "500", "i++", "final", "doubl", "val", "math", "exp", "tri", "system", "out", "println", "val", "val", "cumul", "nd", "cumulativeprob", "cumul", "probabl", "val", "catch", "mathexcept", "math", "except", "printstacktrac", "print", "stack", "trace", "fail", "version", "get", "no", "except", "my", "suggest", "chang", "implement", "cumulativeprob", "cumul", "probabl", "doubl", "catch", "all", "convergenceexcept", "converg", "except", "return", "veri", "larg", "veri", "small", "valu", "not", "just", "maxiterationsexceededexcept", "max", "iter", "exceed", "except"], "B_title": "Modified NormalDistributionImpl.cumulativeProbability to return 0 or 1 respectively for values more than 40 standard deviations from the mean. For these values the actual probability is indistinguishable from 0 or 1 as a double.  Top coding improves performance for extreme values and prevents convergence exceptions.", "B_clean_title": ["modifi", "normaldistributionimpl", "cumulativeprob", "normal", "distribut", "impl", "cumul", "probabl", "return", "or", "respect", "valu", "more", "than", "40", "standard", "deviat", "mean", "these", "valu", "actual", "probabl", "indistinguish", "or", "as", "doubl", "top", "code", "improv", "perform", "extrem", "valu", "prevent", "converg", "except"]},
{"A_title": "RandomStringUtils.random(count 0 0 false false universe random) always throws java.lang.ArrayIndexOutOfBoundsExceptionIn commons-lang 2.6 line 250 :  ch = charsrandom.nextInt(gap) + start;  This line of code takes a random int to fetch a char in the chars array regardless of its size. (Besides start is useless here) Fixed version would be :  //ch = charsrandom.nextInt(gap)%chars.length;  When user pass 0 as end or when the array is not null but empty this line ends up with an exception", "A_clean_title": ["randomstringutil", "random", "random", "string", "util", "count", "fals", "fals", "univers", "random", "alway", "throw", "java", "lang", "arrayindexoutofboundsexceptionin", "array", "index", "out", "bound", "except", "common", "lang", "line", "250", "ch", "charsrandom", "nextint", "next", "int", "gap", "start", "thi", "line", "code", "take", "random", "int", "fetch", "char", "char", "array", "regardless", "it", "size", "besid", "start", "useless", "here", "fix", "version", "would", "ch", "charsrandom", "nextint", "next", "int", "gap", "char", "length", "when", "user", "pass", "as", "end", "or", "when", "array", "not", "null", "but", "empti", "thi", "line", "end", "up", "except"], "B_title": "RandomStringUtils.random(count 0 0 false false universe random) always throws java.lang.ArrayIndexOutOfBoundsException", "B_clean_title": ["randomstringutil", "random", "random", "string", "util", "count", "fals", "fals", "univers", "random", "alway", "throw", "java", "lang", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except"]},
{"A_title": "Fixed DelegatingMethod.equals() so that its easier to extend Mockito by custom verification modesCurrently if you create a DelegatingMethod and compare it to itself using .equals() it will show as not equal because the .equals() method expects a java.lang.reflect.Method (without explicitly stating such). This has a knock on effect on the evaluation of InvocationImpl.equals() which at runtime may be using a DelegatingMethod in its .equals().", "A_clean_title": ["fix", "delegatingmethod", "equal", "deleg", "method", "so", "that", "it", "easier", "extend", "mockito", "by", "custom", "verif", "modescurr", "mode", "current", "you", "creat", "delegatingmethod", "deleg", "method", "compar", "it", "itself", "equal", "it", "will", "show", "as", "not", "equal", "becaus", "equal", "method", "expect", "java", "lang", "reflect", "method", "without", "explicitli", "state", "such", "thi", "ha", "knock", "effect", "evalu", "invocationimpl", "equal", "invoc", "impl", "which", "at", "runtim", "may", "delegatingmethod", "deleg", "method", "it", "equal"], "B_title": "Merge pull request #87 from hughwphamill/master", "B_clean_title": ["merg", "pull", "request", "87", "hughwphamil", "master"]},
{"A_title": "Bug propgated from v1.0.5 on to presentThe method getRowCount() in class org.jfree.data.category.DefaultIntervalCategoryDataset says that it Returns the number of series in the dataset (possibly zero).  The implementation from v1.0.5 on no longer checks for a null condition (which would then return a zero) on the seriesKeys as it did in v1.0.4 and previous. This now throws a Null Pointer if seriesKeys never got initialized and the getRowCount() method is called.", "A_clean_title": ["bug", "propgat", "v1", "presentth", "present", "method", "getrowcount", "get", "row", "count", "class", "org", "jfree", "data", "categori", "defaultintervalcategorydataset", "default", "interv", "categori", "dataset", "say", "that", "it", "return", "number", "seri", "dataset", "possibl", "zero", "implement", "v1", "no", "longer", "check", "null", "condit", "which", "would", "then", "return", "zero", "serieskey", "seri", "key", "as", "it", "did", "v1", "previou", "thi", "now", "throw", "null", "pointer", "serieskey", "seri", "key", "never", "got", "initi", "getrowcount", "get", "row", "count", "method", "call"], "B_title": " source/org/jfree/data/DefaultIntervalCategoryDataset.java (DefaultIntervalCategoryDataset(Comparable Comparable Number Number): Initialise seriesKeys and categoryKeys to empty arrays instead of null for empty dataset(setCategoryKeys): Fixed argument check to handle empty dataset.", "B_clean_title": ["java", "sourc", "org", "jfree", "data", "defaultintervalcategorydataset", "default", "interv", "categori", "dataset", "defaultintervalcategorydataset", "default", "interv", "categori", "dataset", "compar", "compar", "number", "number", "initialis", "serieskey", "seri", "key", "categorykey", "categori", "key", "empti", "array", "instead", "null", "empti", "dataset", "setcategorykey", "set", "categori", "key", "fix", "argument", "check", "handl", "empti", "dataset"]},
{"A_title": "Upgraded version history has UUIDs as jcr:frozenUuid of non-referenceable nodesIn Jackrabbit Classic each node even non-referenceable ones has a UUID as its identifier and thus the jcr:frozenUuid properties of frozen nodes are always UUIDs. In contrast Oak uses path identifiers for non-referenceable frozen nodes (see OAK-1009) which presents a problem when dealing with version histories migrated from Jackrabbit Classic.  To avoid this mismatch the upgrade code should check each frozen node for referenceability and replace the frozen UUID with a path identifier if needed.", "A_clean_title": ["upgrad", "version", "histori", "ha", "uuid", "uui", "ds", "as", "jcr", "frozenuuid", "frozen", "uuid", "non", "referenc", "nodesin", "node", "jackrabbit", "classic", "each", "node", "even", "non", "referenc", "one", "ha", "uuid", "as", "it", "identifi", "thu", "jcr", "frozenuuid", "frozen", "uuid", "properti", "frozen", "node", "are", "alway", "uuid", "uui", "ds", "contrast", "oak", "use", "path", "identifi", "non", "referenc", "frozen", "node", "see", "oak", "1009", "which", "present", "problem", "when", "deal", "version", "histori", "migrat", "jackrabbit", "classic", "avoid", "thi", "mismatch", "upgrad", "code", "check", "each", "frozen", "node", "referenc", "replac", "frozen", "uuid", "path", "identifi", "need"], "B_title": "Upgraded version history has UUIDs as jcr:frozenUuid of non-referenceable nodes", "B_clean_title": ["upgrad", "version", "histori", "ha", "uuid", "uui", "ds", "as", "jcr", "frozenuuid", "frozen", "uuid", "non", "referenc", "node"]},
{"A_title": "History command incorrectly numbers commandsWhen you use the history command it will provide you with a list of previous commands that have been executed each with a command number. However if you try to use history expansion by number to invoke one of those commands you will be off by one.  I think this is because the history command in added to the list after it shows you the list and pushes everything else up by one. Uncertain if this is something we do wrong or if this is an upstream JLine bug.", "A_clean_title": ["histori", "command", "incorrectli", "number", "commandswhen", "command", "when", "you", "use", "histori", "command", "it", "will", "provid", "you", "list", "previou", "command", "that", "have", "been", "execut", "each", "command", "number", "howev", "you", "tri", "use", "histori", "expans", "by", "number", "invok", "one", "those", "command", "you", "will", "off", "by", "one", "think", "thi", "becaus", "histori", "command", "ad", "list", "after", "it", "show", "you", "list", "push", "everyth", "up", "by", "one", "uncertain", "thi", "someth", "we", "wrong", "or", "thi", "upstream", "jline", "line", "bug"], "B_title": "offset history command by one", "B_clean_title": ["offset", "histori", "command", "by", "one"]},
{"A_title": "IllegalStateException for ValueMap on _revisionsAn IllegalStateException may be thrown by the MergeSortedIterator when _revisions on the root document are read with the ValueMap implementation. It only happens when the local _revisions map has entries that are lower than the most recent split document.", "A_clean_title": ["illegalstateexcept", "illeg", "state", "except", "valuemap", "valu", "map", "revisionsan", "revis", "illegalstateexcept", "illeg", "state", "except", "may", "thrown", "by", "mergesortediter", "merg", "sort", "iter", "when", "revis", "root", "document", "are", "read", "valuemap", "valu", "map", "implement", "it", "onli", "happen", "when", "local", "revis", "map", "ha", "entri", "that", "are", "lower", "than", "most", "recent", "split", "document"], "B_title": "IllegalStateException for ValueMap on _revisions", "B_clean_title": ["illegalstateexcept", "illeg", "state", "except", "valuemap", "valu", "map", "revis"]},
{"A_title": "Division by zeroIn class Complex division by zero always returns NaN. I think that it should return NaN only when the numerator is also ZERO otherwise the result should be INF. See here.", "A_clean_title": ["divis", "by", "zeroin", "zero", "class", "complex", "divis", "by", "zero", "alway", "return", "nan", "na", "think", "that", "it", "return", "nan", "na", "onli", "when", "numer", "also", "zero", "otherwis", "result", "inf", "see", "here"], "B_title": "Reverting to previous behaviour as requested by P. Steitz.", "B_clean_title": ["revert", "previou", "behaviour", "as", "request", "by", "steitz"]},
{"A_title": "IllegalArgumentException on Row.getValues()Calling row.getValues() is throwing an IllegalArgumentException when called on the QueryResult of the query SELECT properties FROM nt:base WHERE sling:resourceType=cq/personalization/components/contextstores/surferinfo  quote java.lang.IllegalArgumentException at com.google.common.base.Preconditions.checkArgument(Preconditions.java:76) at org.apache.jackrabbit.oak.plugins.value.ValueImpl.checkSingleValued(ValueImpl.java:85) at org.apache.jackrabbit.oak.plugins.value.ValueImpl.<init>(ValueImpl.java:72) at org.apache.jackrabbit.oak.plugins.value.ValueFactoryImpl.createValue(ValueFactoryImpl.java:95) at org.apache.jackrabbit.oak.jcr.query.QueryResultImpl.createValue(QueryResultImpl.java:266) at org.apache.jackrabbit.oak.jcr.query.RowImpl.getValues(RowImpl.java:99) at com.day.cq.analytics.sitecatalyst.impl.FrameworkComponentImpl.getListProperty(FrameworkComponentImpl.java:128) at com.day.cq.analytics.sitecatalyst.impl.FrameworkComponentImpl.<init>(FrameworkComponentImpl.java:91) quote", "A_clean_title": ["illegalargumentexcept", "illeg", "argument", "except", "row", "getvalu", "get", "valu", "call", "row", "getvalu", "get", "valu", "throw", "illegalargumentexcept", "illeg", "argument", "except", "when", "call", "queryresult", "queri", "result", "queri", "select", "properti", "nt", "base", "where", "sling", "resourcetype=cq", "person", "compon", "contextstor", "surferinfo", "resourc", "type=cq", "quot", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "at", "com", "googl", "common", "base", "precondit", "checkargu", "check", "argument", "precondit", "java:76", "at", "org", "apach", "jackrabbit", "oak", "plugin", "valu", "valueimpl", "checksinglevalu", "valu", "impl", "check", "singl", "valu", "valueimpl", "java:85", "valu", "impl", "at", "org", "apach", "jackrabbit", "oak", "plugin", "valu", "valueimpl", "valu", "impl", "init", "valueimpl", "java:72", "valu", "impl", "at", "org", "apach", "jackrabbit", "oak", "plugin", "valu", "valuefactoryimpl", "createvalu", "valu", "factori", "impl", "creat", "valu", "valuefactoryimpl", "java:95", "valu", "factori", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "queri", "queryresultimpl", "createvalu", "queri", "result", "impl", "creat", "valu", "queryresultimpl", "java:266", "queri", "result", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "queri", "rowimpl", "getvalu", "row", "impl", "get", "valu", "rowimpl", "java:99", "row", "impl", "at", "com", "day", "cq", "analyt", "sitecatalyst", "impl", "frameworkcomponentimpl", "getlistproperti", "framework", "compon", "impl", "get", "list", "properti", "frameworkcomponentimpl", "java:128", "framework", "compon", "impl", "at", "com", "day", "cq", "analyt", "sitecatalyst", "impl", "frameworkcomponentimpl", "framework", "compon", "impl", "init", "frameworkcomponentimpl", "java:91", "framework", "compon", "impl", "quot"], "B_title": "IllegalArgumentException on Row.getValues()  - null guard", "B_clean_title": ["illegalargumentexcept", "illeg", "argument", "except", "row", "getvalu", "get", "valu", "null", "guard"]},
{"A_title": "NodeDocument _modified may go back in timeIn a cluster with multiple DocumentMK instances the _modified field of a NodeDocument may go back in time. This will result in incorrect diff calculations when the DocumentNodeStore uses the _modified field to find changed nodes for a given revision range.", "A_clean_title": ["nodedocu", "node", "document", "modifi", "may", "go", "back", "timein", "time", "cluster", "multipl", "documentmk", "document", "mk", "instanc", "modifi", "field", "nodedocu", "node", "document", "may", "go", "back", "time", "thi", "will", "result", "incorrect", "diff", "calcul", "when", "documentnodestor", "document", "node", "store", "use", "modifi", "field", "find", "chang", "node", "given", "revis", "rang"], "B_title": "NodeDocument _modified may go back in time", "B_clean_title": ["nodedocu", "node", "document", "modifi", "may", "go", "back", "time"]},
{"A_title": "QueryManager does not have autorefreshHaving two sessions A and B. A writes something for example /content/page/text = text Accessing Bs QueryManager and exexcute a query for text nothing will be found. Triggering an explicit refresh on B before the query and the hit is found.  I assume that the autorefresh is missed for that case", "A_clean_title": ["querymanag", "queri", "manag", "not", "have", "autorefreshhav", "autorefresh", "have", "two", "session", "write", "someth", "exampl", "content", "page", "text", "text", "access", "bs", "querymanag", "queri", "manag", "exexcut", "queri", "text", "noth", "will", "found", "trigger", "explicit", "refresh", "befor", "queri", "hit", "found", "assum", "that", "autorefresh", "miss", "that", "case"], "B_title": "QueryManager does not have autorefresh  - fix and test", "B_clean_title": ["querymanag", "queri", "manag", "not", "have", "autorefresh", "fix", "test"]},
{"A_title": "Advanced compilations renames a function and then deletes it leaving a reference to a renamed but non-existent functionNone", "A_clean_title": ["advanc", "compil", "renam", "function", "then", "delet", "it", "leav", "refer", "renam", "but", "non", "exist", "functionnon", "function", "none"], "B_title": "Only remove prototype properties defined with simple assigment statements. Fixes issue 459.", "B_clean_title": ["onli", "remov", "prototyp", "properti", "defin", "simpl", "assig", "statement", "fix", "issu", "459"]},
{"A_title": "AbstractTransformerBehavior sets wrong namespaceAbstractTransformerBehaviour adds a wicket namespace (http://wicket.apache.org) to its tag which is different from that of the whole page (http://wicket.apache.org/dtds.data/wicket-xhtml1.4-strict.dtd).  This causes (at least) XPath queries for Wicket nodes to fail when matching the contents of components with an AbstractTransformerBehavior.", "A_clean_title": ["abstracttransformerbehavior", "abstract", "transform", "behavior", "set", "wrong", "namespaceabstracttransformerbehaviour", "namespac", "abstract", "transform", "behaviour", "add", "wicket", "namespac", "http", "apach", "org", "wicket", "it", "tag", "which", "differ", "that", "whole", "page", "http", "apach", "xhtml1", "strict", "dtd", "wicket", "org", "dtd", "data", "wicket", "thi", "caus", "at", "least", "xpath", "path", "queri", "wicket", "node", "fail", "when", "match", "content", "compon", "abstracttransformerbehavior", "abstract", "transform", "behavior"], "B_title": "fixed: AbstractTransformerBehavior sets wrong namespace Issue: WICKET-3861", "B_clean_title": ["fix", "abstracttransformerbehavior", "abstract", "transform", "behavior", "set", "wrong", "namespac", "issu", "wicket", "3861"]},
{"A_title": "String conversion optimization is incorrectNone", "A_clean_title": ["string", "convers", "optim", "incorrectnon", "incorrect", "none"], "B_title": "fix a bad String() optimization fixes issue 759", "B_clean_title": ["fix", "bad", "string", "optim", "fix", "issu", "759"]},
{"A_title": "CMAESOptimizer does not enforce boundsThe CMAESOptimizer can exceed the bounds passed to optimize.  Looking at the generationLoop in doOptimize() it does a bounds check by calling isFeasible() but if checkFeasableCount is zero (the default) then isFeasible() is never even called.  Also even with non-zero checkFeasableCount it may give up before finding an in-bounds offspring and go forward with an out-of-bounds offspring.  This is against svn revision 1387637.  I can provide an example program where the optimizer ends up with a fit outside the prescribed bounds if that would help.", "A_clean_title": ["cmaesoptim", "cmae", "optim", "not", "enforc", "boundsth", "bound", "cmaesoptim", "cmae", "optim", "exceed", "bound", "pass", "optim", "look", "at", "generationloop", "gener", "loop", "dooptim", "optim", "it", "bound", "check", "by", "call", "isfeas", "feasibl", "but", "checkfeasablecount", "check", "feasabl", "count", "zero", "default", "then", "isfeas", "feasibl", "never", "even", "call", "also", "even", "non", "zero", "checkfeasablecount", "check", "feasabl", "count", "it", "may", "give", "up", "befor", "find", "bound", "offspr", "go", "forward", "out", "bound", "offspr", "thi", "against", "svn", "revis", "1387637", "provid", "exampl", "program", "where", "optim", "end", "up", "fit", "outsid", "prescrib", "bound", "that", "would", "help"], "B_title": "Fixed missing repair of a point that lies outside the boundaries. Thanks to Frank Hessen for the report and for pinpointing the cause of the problem.", "B_clean_title": ["fix", "miss", "repair", "point", "that", "lie", "outsid", "boundari", "thank", "frank", "hessen", "report", "pinpoint", "caus", "problem"]},
{"A_title": "Potential NPE in AbstractCategoryItemRender.getLegendItems()Setting up a working copy of the current JFreeChart trunk in Eclipse I got a warning about a null pointer access in this bit of code from AbstractCategoryItemRender.java. The warning is in the last code line where seriesCount is assigned. The variable dataset is guaranteed to be null in this location I suppose that the check before that should actually read if (dataset == null) not if (dataset != null).", "A_clean_title": ["potenti", "npe", "abstractcategoryitemrend", "getlegenditem", "abstract", "categori", "item", "render", "get", "legend", "item", "set", "up", "work", "copi", "current", "jfreechart", "free", "chart", "trunk", "eclips", "got", "warn", "about", "null", "pointer", "access", "thi", "bit", "code", "abstractcategoryitemrend", "java", "abstract", "categori", "item", "render", "warn", "last", "code", "line", "where", "seriescount", "seri", "count", "assign", "variabl", "dataset", "guarante", "null", "thi", "locat", "suppos", "that", "check", "befor", "that", "actual", "read", "dataset", "null", "not", "dataset", "null"], "B_title": "source/org/jfree/chart/renderer/category/AbstractCategoryRenderer.java (getLegendItems): Fix null check.", "B_clean_title": ["java", "sourc", "org", "jfree", "chart", "render", "categori", "abstractcategoryrender", "abstract", "categori", "render", "getlegenditem", "get", "legend", "item", "fix", "null", "check"]},
{"A_title": "Overzealous optimization confuses variablesNone", "A_clean_title": ["overzeal", "optim", "confus", "variablesnon", "variabl", "none"], "B_title": "Fix inlining bug in https://code.google.com/p/closure-compiler/issues/detail?id=1053 ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=50726739", "B_clean_title": ["fix", "inlin", "bug", "http", "googl", "compil", "issu", "detail", "code", "com", "closur", "id=1053", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=50726739"]},
{"A_title": "When i use the parameters configured in the dubbo provider in the routing rules the rules can not be matched如果将参数添加到dubbo provider中，例如：   <dubbo:provider  serialization=fastjson /> 这样生成的url中会带有 default.serialization=fastjson 这样的参数。 如果路由规则设置为 => serialization=fastjson，是无法过滤出带有 default.serialization=fastjson 的提供者的。", "A_clean_title": ["when", "use", "paramet", "configur", "dubbo", "provid", "rout", "rule", "rule", "not", "matched如果将参数添加到dubbo", "provider中，例如：", "dubbo", "provid", "serialization=fastjson", "这样生成的url中会带有", "default", "serialization=fastjson", "serialization=fastjson，是无法过滤出带有", "default", "serialization=fastjson"], "B_title": "Merge pull request #1204 condition router match `default.xxx  Fixes #1201", "B_clean_title": ["merg", "pull", "request", "1204", "condit", "router", "match", "default", "xxx", "fix", "1201"]},
{"A_title": "Inconsistent result from Levenberg-MarquardtLevenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However the class holds the optimum point the vector of the objective function the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost", "A_clean_title": ["inconsist", "result", "levenberg", "marquardtlevenberg", "marquardt", "marquardt", "levenberg", "it", "method", "dooptim", "optim", "return", "vectorialpointvaluepair", "vectori", "point", "valu", "pair", "howev", "class", "hold", "optimum", "point", "vector", "object", "function", "cost", "residu", "valu", "return", "by", "dooptim", "optim", "not", "alway", "correspond", "point", "which", "lead", "residu", "cost"], "B_title": "corrected", "B_clean_title": ["correct"]},
{"A_title": "Dfp Dfp.multiply(int x) does not comply with the general contract FieldElement.multiply(int n)In class org.apache.commons.math3.Dfp  the method multiply(int n) is limited to 0 <= n <= 9999. This is not consistent with the general contract of FieldElement.multiply(int n) where there should be no limitation on the values of n.", "A_clean_title": ["dfp", "dfp", "multipli", "int", "not", "compli", "gener", "contract", "fieldel", "multipli", "field", "element", "int", "class", "org", "apach", "common", "math3", "dfp", "method", "multipli", "int", "limit", "9999", "thi", "not", "consist", "gener", "contract", "fieldel", "multipli", "field", "element", "int", "where", "there", "no", "limit", "valu"], "B_title": "Allow unlimited input values for Dfp#multiply.", "B_clean_title": ["allow", "unlimit", "input", "valu", "dfp", "multipli"]},
{"A_title": "Can not Return deep stubs from generic method that returns generic type.if I try to mock a generic method which a generic returntype where the returntype is derived from the generic type of the method using deep stubs I get a ClassCastException when calling when on it. When you dont use deep stubs and a raw Supplier mock to pass around it works:", "A_clean_title": ["not", "return", "deep", "stub", "gener", "method", "that", "return", "gener", "type", "tri", "mock", "gener", "method", "which", "gener", "returntyp", "where", "returntyp", "deriv", "gener", "type", "method", "deep", "stub", "get", "classcastexcept", "class", "cast", "except", "when", "call", "when", "it", "when", "you", "dont", "use", "deep", "stub", "raw", "supplier", "mock", "pass", "around", "it", "work"], "B_title": "Merge branch issue484-fix of git://github.com/MajA7jHbJYW2N/mockito into MajA7jHbJYW2N-issue484-fix", "B_clean_title": ["merg", "branch", "issue484", "fix", "git", "github", "com", "maja7jhbjyw2n", "mockito", "maj", "a7j", "hb", "jyw2n", "into", "maja7jhbjyw2n", "issue484", "fix", "maj", "a7j", "hb", "jyw2n"]},
{"A_title": "Matrixs OutOfBoundException in SimplexSolverHi all This bug is somehow related to incident MATH-286 but not necessarily...  Lets say I have an LP and I solve it using SimplexSolver. Then I create a second LP similar to the first one but with stronger constraints. The second LP has the following properties: * the only point in the feasible region for the second LP is the solution returned for the first LP * the solution returned for the first LP is also the (only possible) solution to the second LP  This shows the problem:  code:borderStyle=solid LinearObjectiveFunction f = new LinearObjectiveFunction(new double  0.8 0.2 0.7 0.3 0.4 0.6 0 ); Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>(); constraints.add(new LinearConstraint(new double  1 0 1 0 1 0  Relationship.EQ 30.0)); constraints.add(new LinearConstraint(new double  0 1 0 1 0 1  Relationship.EQ 30.0)); constraints.add(new LinearConstraint(new double  0.8 0.2 0.0 0.0 0.0 0.0  Relationship.GEQ 10.0)); constraints.add(new LinearConstraint(new double  0.0 0.0 0.7 0.3 0.0 0.0  Relationship.GEQ 10.0)); constraints.add(new LinearConstraint(new double  0.0 0.0 0.0 0.0 0.4 0.6  Relationship.GEQ 10.0));  RealPointValuePair solution = new SimplexSolver().optimize(f constraints GoalType.MAXIMIZE true);  double valA = 0.8 * solution.getPoint()0 + 0.2 * solution.getPoint()1; double valB = 0.7 * solution.getPoint()2 + 0.3 * solution.getPoint()3; double valC = 0.4 * solution.getPoint()4 + 0.6 * solution.getPoint()5;  f = new LinearObjectiveFunction(new double  0.8 0.2 0.7 0.3 0.4 0.6 0 ); constraints = new ArrayList<LinearConstraint>(); constraints.add(new LinearConstraint(new double  1 0 1 0 1 0  Relationship.EQ 30.0)); constraints.add(new LinearConstraint(new double  0 1 0 1 0 1  Relationship.EQ 30.0)); constraints.add(new LinearConstraint(new double  0.8 0.2 0.0 0.0 0.0 0.0  Relationship.GEQ valA)); constraints.add(new LinearConstraint(new double  0.0 0.0 0.7 0.3 0.0 0.0  Relationship.GEQ valB)); constraints.add(new LinearConstraint(new double  0.0 0.0 0.0 0.0 0.4 0.6  Relationship.GEQ valC));  solution = new SimplexSolver().optimize(f constraints GoalType.MAXIMIZE true); code   Instead of returning the solution SimplexSolver throws an Exception:  noformat Exception in thread main org.apache.commons.math.linear.MatrixIndexException: no entry at indices (0 7) in a 6x7 matrix at org.apache.commons.math.linear.Array2DRowRealMatrix.getEntry(Array2DRowRealMatrix.java:356) at org.apache.commons.math.optimization.linear.SimplexTableau.getEntry(SimplexTableau.java:408) at org.apache.commons.math.optimization.linear.SimplexTableau.getBasicRow(SimplexTableau.java:258) at org.apache.commons.math.optimization.linear.SimplexTableau.getSolution(SimplexTableau.java:336) at org.apache.commons.math.optimization.linear.SimplexSolver.doOptimize(SimplexSolver.java:182) at org.apache.commons.math.optimization.linear.AbstractLinearOptimizer.optimize(AbstractLinearOptimizer.java:106)noformat   I was too optimistic with the bug MATH-286 ;-)", "A_clean_title": ["matrix", "outofboundexcept", "out", "bound", "except", "simplexsolverhi", "simplex", "solver", "hi", "all", "thi", "bug", "somehow", "relat", "incid", "math", "286", "but", "not", "necessarili", "let", "say", "have", "lp", "solv", "it", "simplexsolv", "simplex", "solver", "then", "creat", "second", "lp", "similar", "first", "one", "but", "stronger", "constraint", "second", "lp", "ha", "follow", "properti", "onli", "point", "feasibl", "region", "second", "lp", "solut", "return", "first", "lp", "solut", "return", "first", "lp", "also", "onli", "possibl", "solut", "second", "lp", "thi", "show", "problem", "code", "borderstyle=solid", "border", "style=solid", "linearobjectivefunct", "linear", "object", "function", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "constraint", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "30", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "30", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "10", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "10", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "10", "realpointvaluepair", "real", "point", "valu", "pair", "solut", "new", "simplexsolv", "simplex", "solver", "optim", "constraint", "goaltyp", "maxim", "goal", "type", "true", "doubl", "vala", "val", "solut", "getpoint", "get", "point", "solut", "getpoint", "get", "point", "doubl", "valb", "val", "solut", "getpoint", "get", "point", "solut", "getpoint", "get", "point", "doubl", "valc", "val", "solut", "getpoint", "get", "point", "solut", "getpoint", "get", "point", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "constraint", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "30", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "30", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "vala", "val", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "valb", "val", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "valc", "val", "solut", "new", "simplexsolv", "simplex", "solver", "optim", "constraint", "goaltyp", "maxim", "goal", "type", "true", "code", "instead", "return", "solut", "simplexsolv", "simplex", "solver", "throw", "except", "noformat", "except", "thread", "main", "org", "apach", "common", "math", "linear", "matrixindexexcept", "matrix", "index", "except", "no", "entri", "at", "indic", "6x7", "matrix", "at", "org", "apach", "common", "math", "linear", "array2drowrealmatrix", "getentri", "array2d", "row", "real", "matrix", "get", "entri", "array2drowrealmatrix", "java:356", "array2d", "row", "real", "matrix", "at", "org", "apach", "common", "math", "optim", "linear", "simplextableau", "getentri", "simplex", "tableau", "get", "entri", "simplextableau", "java:408", "simplex", "tableau", "at", "org", "apach", "common", "math", "optim", "linear", "simplextableau", "getbasicrow", "simplex", "tableau", "get", "basic", "row", "simplextableau", "java:258", "simplex", "tableau", "at", "org", "apach", "common", "math", "optim", "linear", "simplextableau", "getsolut", "simplex", "tableau", "get", "solut", "simplextableau", "java:336", "simplex", "tableau", "at", "org", "apach", "common", "math", "optim", "linear", "simplexsolv", "dooptim", "simplex", "solver", "optim", "simplexsolv", "java:182", "simplex", "solver", "at", "org", "apach", "common", "math", "optim", "linear", "abstractlinearoptim", "optim", "abstract", "linear", "optim", "abstractlinearoptim", "java:106", "abstract", "linear", "optim", "noformat", "wa", "too", "optimist", "bug", "math", "286"], "B_title": "Fixed a OutOfBoundException in simplex solver when some constraints are tight JIRA: MATH-293", "B_clean_title": ["fix", "outofboundexcept", "out", "bound", "except", "simplex", "solver", "when", "some", "constraint", "are", "tight", "jira", "math", "293"]},
{"A_title": "java.lang.ClassCastException: java.lang.Class cannot be cast to java.lang.StringException throws on verifyZeroInteractions when using mock with default answer.", "A_clean_title": ["java", "lang", "classcastexcept", "class", "cast", "except", "java", "lang", "class", "not", "cast", "java", "lang", "stringexcept", "string", "except", "throw", "verifyzerointeract", "verifi", "zero", "interact", "when", "mock", "default", "answer"], "B_title": "Fixes #187 : print mock name even when default answer is bogus", "B_clean_title": ["fix", "187", "print", "mock", "name", "even", "when", "default", "answer", "bogu"]},
{"A_title": "ACE merging not behaving correctly if not using managed principalsorg.apache.jackrabbit.api.security.JackrabbitAccessControlList#addEntry() does not work correctly if the given principal is not retrieved from the PrincipalManager.  Exception: noformat Caused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakAccessControl0013: Duplicate ACE found in policy at org.apache.jackrabbit.oak.security.authorization.accesscontrol.AccessControlValidator.accessViolation(AccessControlValidator.java:278) at org.apache.jackrabbit.oak.security.authorization.accesscontrol.AccessControlValidator.checkValidPolicy(AccessControlValidator.java:188) noformat  this used to work in jackrabbit 2.x.  the problem is probably in org.apache.jackrabbit.oak.security.authorization.accesscontrol.ACL#internalAddEntry where the principals are equalled instead of comparing their names.  note that adding an ACE with such a principal works just the merging/overwriting detection doesnt.  test: code   Principal p1 = new Principal()  getName()return foo;   Principal p2 = new Principal()  getName()return foo;   acl.addEntry(p1 privileges true);   acl.addEntry(p2 privileges false);   ...   save(); // throws code", "A_clean_title": ["ace", "merg", "not", "behav", "correctli", "not", "manag", "principalsorg", "apach", "jackrabbit", "api", "secur", "jackrabbitaccesscontrollist", "jackrabbit", "access", "control", "list", "addentri", "add", "entri", "not", "work", "correctli", "given", "princip", "not", "retriev", "principalmanag", "princip", "manag", "except", "noformat", "caus", "by", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "commit", "fail", "except", "oakaccesscontrol0013", "oak", "access", "control0013", "duplic", "ace", "found", "polici", "at", "org", "apach", "jackrabbit", "oak", "secur", "author", "accesscontrol", "accesscontrolvalid", "accessviol", "access", "control", "valid", "access", "violat", "accesscontrolvalid", "java:278", "access", "control", "valid", "at", "org", "apach", "jackrabbit", "oak", "secur", "author", "accesscontrol", "accesscontrolvalid", "checkvalidpolici", "access", "control", "valid", "check", "valid", "polici", "accesscontrolvalid", "java:188", "access", "control", "valid", "noformat", "thi", "use", "work", "jackrabbit", "problem", "probabl", "org", "apach", "jackrabbit", "oak", "secur", "author", "accesscontrol", "acl", "internaladdentri", "intern", "add", "entri", "where", "princip", "are", "equal", "instead", "compar", "their", "name", "note", "that", "ad", "ace", "such", "princip", "work", "just", "merg", "overwrit", "detect", "doesnt", "test", "code", "princip", "p1", "new", "princip", "getnam", "get", "name", "return", "foo", "princip", "p2", "new", "princip", "getnam", "get", "name", "return", "foo", "acl", "addentri", "add", "entri", "p1", "privileg", "true", "acl", "addentri", "add", "entri", "p2", "privileg", "fals", "save", "throw", "code"], "B_title": ": ACE merging not behaving correctly if not using managed principals", "B_clean_title": ["ace", "merg", "not", "behav", "correctli", "not", "manag", "princip"]},
{"A_title": "@const dumps type cast informationNone", "A_clean_title": ["const", "dump", "type", "cast", "informationnon", "inform", "none"], "B_title": "When declaring @const vars initialized to a type-casted value prefer the type-cast as the declared type. fixes issue 688", "B_clean_title": ["when", "declar", "const", "var", "initi", "type", "cast", "valu", "prefer", "type", "cast", "as", "declar", "type", "fix", "issu", "688"]},
{"A_title": "HttpSession getSession() in MockHttpServletRequest is not compliant with the j2ee servlet specThe implementation of httpRequest.getSession(); for MockHttpServletRequest seems not correct since it can return null when the servler api specs (http://docs.oracle.com/javaee/1.4/api/) says:  public HttpSession getSession() Returns the current session associated with this request or if the request does not have a session creates one.  So as far as I understand httpRequest.getSession(); and httpRequest.getSession(true); are equivalent  The MockHttpServletRequest implementation is     public HttpSession getSession()            if (session instanceof MockHttpSession && ((MockHttpSession)session).isTemporary())                    return null;                return session;      I think it should be     public HttpSession getSession()            return getSession(true);", "A_clean_title": ["httpsession", "http", "session", "getsess", "get", "session", "mockhttpservletrequest", "mock", "http", "servlet", "request", "not", "compliant", "j2ee", "servlet", "specth", "spec", "implement", "httprequest", "getsess", "http", "request", "get", "session", "mockhttpservletrequest", "mock", "http", "servlet", "request", "seem", "not", "correct", "sinc", "it", "return", "null", "when", "servler", "api", "spec", "http", "oracl", "doc", "com", "javae", "api", "say", "public", "httpsession", "http", "session", "getsess", "get", "session", "return", "current", "session", "associ", "thi", "request", "or", "request", "not", "have", "session", "creat", "one", "so", "as", "far", "as", "understand", "httprequest", "getsess", "http", "request", "get", "session", "httprequest", "getsess", "http", "request", "get", "session", "true", "are", "equival", "mockhttpservletrequest", "mock", "http", "servlet", "request", "implement", "public", "httpsession", "http", "session", "getsess", "get", "session", "session", "instanceof", "mockhttpsess", "mock", "http", "session", "mockhttpsess", "mock", "http", "session", "session", "istemporari", "temporari", "return", "null", "return", "session", "think", "it", "public", "httpsession", "http", "session", "getsess", "get", "session", "return", "getsess", "get", "session", "true"], "B_title": "HttpSession getSession() in MockHttpServletRequest is not compliant with the j2ee servlet spec", "B_clean_title": ["httpsession", "http", "session", "getsess", "get", "session", "mockhttpservletrequest", "mock", "http", "servlet", "request", "not", "compliant", "j2ee", "servlet", "spec"]},
{"A_title": "RangeInputSplit doesnt serialize table nameFound another missed member in the serialization of RangeInputSplit: the table name.  Not a huge deal because the table information should still be in the Configuration for most users but this does break in advanced uses of mapreduce. Work around is to re-set the table in the RangeInputSplit in your overridden InputFormat.getRecordReader or make sure the Configuration is consistent from getRecordReader and getSplits.", "A_clean_title": ["rangeinputsplit", "rang", "input", "split", "doesnt", "serial", "tabl", "namefound", "name", "found", "anoth", "miss", "member", "serial", "rangeinputsplit", "rang", "input", "split", "tabl", "name", "not", "huge", "deal", "becaus", "tabl", "inform", "still", "configur", "most", "user", "but", "thi", "break", "advanc", "use", "mapreduc", "work", "around", "re", "set", "tabl", "rangeinputsplit", "rang", "input", "split", "your", "overridden", "inputformat", "getrecordread", "input", "format", "get", "record", "reader", "or", "make", "sure", "configur", "consist", "getrecordread", "get", "record", "reader", "getsplit", "get", "split"], "B_title": "Ensure table name is serialized in RangeInputSplit.", "B_clean_title": ["ensur", "tabl", "name", "serial", "rangeinputsplit", "rang", "input", "split"]},
{"A_title": "LevenburgMaquardt switched evaluation and iterationsNone", "A_clean_title": ["levenburgmaquardt", "levenburg", "maquardt", "switch", "evalu", "iterationsnon", "iter", "none"], "B_title": "Fix switched iterations and evaluations", "B_clean_title": ["fix", "switch", "iter", "evalu"]},
{"A_title": "EigenDecomposition.Solver should consider tiny values 0 for purposes of determining singularityEigenDecomposition.Solver tests for singularity by comparing eigenvalues to 0 for exact equality. Elsewhere in the class and in the code of course very small values are considered 0. This causes the solver to consider some singular matrices as non-singular.  The patch here includes a test as well showing the behavior -- the matrix is clearly singular but isnt considered as such since one eigenvalue are ~1e-14 rather than exactly 0.  (What I am not sure of is whether we should really be evaluating the *norm* of the imaginary eigenvalues rather than real/imag components separately. But the javadoc says the solver only supports real eigenvalues anyhow so its kind of moot since imag=0 for all eigenvalues.)", "A_clean_title": ["eigendecomposit", "solver", "eigen", "decomposit", "consid", "tini", "valu", "purpos", "determin", "singularityeigendecomposit", "solver", "singular", "eigen", "decomposit", "test", "singular", "by", "compar", "eigenvalu", "exact", "equal", "elsewher", "class", "code", "cours", "veri", "small", "valu", "are", "consid", "thi", "caus", "solver", "consid", "some", "singular", "matric", "as", "non", "singular", "patch", "here", "includ", "test", "as", "well", "show", "behavior", "matrix", "clearli", "singular", "but", "isnt", "consid", "as", "such", "sinc", "one", "eigenvalu", "are", "~1e", "14", "rather", "than", "exactli", "what", "am", "not", "sure", "whether", "we", "realli", "evalu", "norm", "imaginari", "eigenvalu", "rather", "than", "real", "imag", "compon", "separ", "but", "javadoc", "say", "solver", "onli", "support", "real", "eigenvalu", "anyhow", "so", "it", "kind", "moot", "sinc", "imag=0", "all", "eigenvalu"], "B_title": "Singular matrices were considered non-singular due to strict comparison with zero. Reported and fixed by Sean Owen.", "B_clean_title": ["singular", "matric", "were", "consid", "non", "singular", "due", "strict", "comparison", "zero", "report", "fix", "by", "sean", "owen"]},
{"A_title": "Fix and then deprecate isSupportXxxInclusive in RealDistribution interfaceThe conclusion from 1 was never implemented. We should deprecate these properties from the RealDistribution interface but since removal will have to wait until 4.0 we should agree on a precise definition and fix the code to match it in the mean time. The definition that I propose is that isSupportXxxInclusive means that when the density function is applied to the upper or lower bound of support returned by getSupportXxxBound a finite (i.e. not infinite) not NaN value is returned. 1 http://markmail.org/message/dxuxh7eybl7xejde", "A_clean_title": ["fix", "then", "deprec", "issupportxxxinclus", "support", "xxx", "inclus", "realdistribut", "real", "distribut", "interfaceth", "interfac", "conclus", "wa", "never", "implement", "we", "deprec", "these", "properti", "realdistribut", "real", "distribut", "interfac", "but", "sinc", "remov", "will", "have", "wait", "until", "we", "agre", "precis", "definit", "fix", "code", "match", "it", "mean", "time", "definit", "that", "propos", "that", "issupportxxxinclus", "support", "xxx", "inclus", "mean", "that", "when", "densiti", "function", "appli", "upper", "or", "lower", "bound", "support", "return", "by", "getsupportxxxbound", "get", "support", "xxx", "bound", "finit", "not", "infinit", "not", "nan", "na", "valu", "return", "http", "markmail", "org", "messag", "dxuxh7eybl7xejd"], "B_title": "Clarified definition of isSupportXxxBoundInclusive in RealDistribution interface made code consistent with the definition and deprecated these methods marking for removal in 4.0. JIRA: MATH-859", "B_clean_title": ["clarifi", "definit", "issupportxxxboundinclus", "support", "xxx", "bound", "inclus", "realdistribut", "real", "distribut", "interfac", "made", "code", "consist", "definit", "deprec", "these", "method", "mark", "remov", "jira", "math", "859"]},
{"A_title": "Stat calculation of STDEV may be inaccurateThe math is sound but it is susceptible to rounding errors. We should address that.  See http://www.strchr.com/standard_deviation_in_one_pass and http://www.cs.berkeley.edu/~mhoemmen/cs194/Tutorials/variance.pdf", "A_clean_title": ["stat", "calcul", "stdev", "may", "inaccurateth", "inaccur", "math", "sound", "but", "it", "suscept", "round", "error", "we", "address", "that", "see", "http", "strchr", "www", "deviat", "one", "pass", "com", "standard", "http", "cs", "berkeley", "pdf", "www", "edu", "~mhoemmen", "cs194", "tutori", "varianc"], "B_title": "Delegate math to commons-math", "B_clean_title": ["deleg", "math", "common", "math"]},
{"A_title": "ClassGeneratingPropertyAccessorFactory needs custom ClassLoader for defineClass() DATACMNS-1422opened and commented The  ClassGeneratingPropertyAccessorFactory fails to generate classes in an OSGi environment where the ClassLoader for the model project the store implementation and Spring Data is different. Here is the error we are facing:  The problem seems to be that  PropertyAccessorClassGenerator.generateBytecode() adds the interface PersistentPropertyAccessor which lives in Spring Data. In generateCustomAccessorClass() the ClassLoader of the model entity is used. Therefore the ClassLoader of the custom model project needs access to all classes which are added by the factory (especially the package org.springframework.data.mapping ). To resolve this problem a child ClassLoader of the entity should be used that is able to access both projects: Spring Data and the custom entity model. Else this has to fail because different classes are mixed which cannot be accessed by a single ClassLoader    Affects: 2.1.2 (Lovelace SR2)  Attachments:      Referenced from: pull request #324  Backported to:  2.1.3 (Lovelace SR3)", "A_clean_title": ["classgeneratingpropertyaccessorfactori", "class", "gener", "properti", "accessor", "factori", "need", "custom", "classload", "class", "loader", "defineclass", "defin", "class", "datacmn", "1422open", "comment", "classgeneratingpropertyaccessorfactori", "class", "gener", "properti", "accessor", "factori", "fail", "gener", "class", "osgi", "os", "gi", "environ", "where", "classload", "class", "loader", "model", "project", "store", "implement", "spring", "data", "differ", "here", "error", "we", "are", "face", "problem", "seem", "that", "propertyaccessorclassgener", "generatebytecod", "properti", "accessor", "class", "gener", "gener", "bytecod", "add", "interfac", "persistentpropertyaccessor", "persist", "properti", "accessor", "which", "live", "spring", "data", "generatecustomaccessorclass", "gener", "custom", "accessor", "class", "classload", "class", "loader", "model", "entiti", "use", "therefor", "classload", "class", "loader", "custom", "model", "project", "need", "access", "all", "class", "which", "are", "ad", "by", "factori", "especi", "packag", "org", "springframework", "data", "map", "resolv", "thi", "problem", "child", "classload", "class", "loader", "entiti", "use", "that", "abl", "access", "both", "project", "spring", "data", "custom", "entiti", "model", "thi", "ha", "fail", "becaus", "differ", "class", "are", "mix", "which", "not", "access", "by", "singl", "classload", "class", "loader", "affect", "lovelac", "sr2", "attach", "referenc", "pull", "request", "324", "backport", "lovelac", "sr3"], "B_title": "DATACMNS-1422 - Fall back to reflection-based PropertyAccessor/EntityInstantiator on inaccessible framework types.  We now fall back to reflection-based PropertyAccessor/EntityInstantiator strategies when framework types are not visible by the entitys ClassLoader.  Typically we use class generation to create and load PropertyAccessor and EntityInstantiator classes to bypass reflection. Generated types are injected into the ClassLoader that has loaded the actual entity. Generated classes implement framework types such as ObjectInstantiator and these interfaces must be visible to the ClassLoader that hosts the generated class. Some arrangements such as OSGi isolate class repositories so the OSGi class loader cannot load our own types which prevents loading the generated class.  Original pull request: #324.", "B_clean_title": ["datacmn", "1422", "fall", "back", "reflect", "base", "propertyaccessor", "entityinstanti", "properti", "accessor", "entiti", "instanti", "inaccess", "framework", "type", "we", "now", "fall", "back", "reflect", "base", "propertyaccessor", "entityinstanti", "properti", "accessor", "entiti", "instanti", "strategi", "when", "framework", "type", "are", "not", "visibl", "by", "entiti", "classload", "class", "loader", "typic", "we", "use", "class", "gener", "creat", "load", "propertyaccessor", "properti", "accessor", "entityinstanti", "entiti", "instanti", "class", "bypass", "reflect", "gener", "type", "are", "inject", "into", "classload", "class", "loader", "that", "ha", "load", "actual", "entiti", "gener", "class", "implement", "framework", "type", "such", "as", "objectinstanti", "object", "instanti", "these", "interfac", "must", "visibl", "classload", "class", "loader", "that", "host", "gener", "class", "some", "arrang", "such", "as", "osgi", "os", "gi", "isol", "class", "repositori", "so", "osgi", "os", "gi", "class", "loader", "not", "load", "our", "own", "type", "which", "prevent", "load", "gener", "class", "origin", "pull", "request", "324"]},
{"A_title": "DefaultLoadBalancer takes a long time when tablets are highly unbalancedAfter creating a thousand splits on a large cluster I noticed the master was only moving tablets to one server at a time.", "A_clean_title": ["defaultloadbalanc", "default", "load", "balanc", "take", "long", "time", "when", "tablet", "are", "highli", "unbalancedaft", "unbalanc", "after", "creat", "thousand", "split", "larg", "cluster", "notic", "master", "wa", "onli", "move", "tablet", "one", "server", "at", "time"], "B_title": "keep better info on what tablet counts will be after balancing", "B_clean_title": ["keep", "better", "info", "what", "tablet", "count", "will", "after", "balanc"]},
{"A_title": "WicketSessionFilter and HttpSessionStore use different attribute name for Wicket Sessionfrom this topic  http://apache-wicket.1842946.n4.nabble.com/WicketSessionFilter-and-ignorePaths-in-WicketFilter-td3570291.html Please look at the second post (the ignorePaths param is not linked with this issue as the title suggests).  How to reproduce with the quickstart: 1. open localhost:8080 - a wicket test page is displayed. 2. open localhost:8080/external - this is the external servlet that tries to access the wicket session. An exception is thrown.", "A_clean_title": ["wicketsessionfilt", "wicket", "session", "filter", "httpsessionstor", "http", "session", "store", "use", "differ", "attribut", "name", "wicket", "sessionfrom", "thi", "topic", "http", "ignorepath", "wicketfilt", "apach", "wicket", "1842946", "n4", "nabbl", "ignor", "path", "wicket", "filter", "td3570291", "html", "com", "wicketsessionfilt", "wicket", "session", "filter", "pleas", "look", "at", "second", "post", "ignorepath", "ignor", "path", "param", "not", "link", "thi", "issu", "as", "titl", "suggest", "how", "reproduc", "quickstart", "open", "localhost:8080", "wicket", "test", "page", "display", "open", "localhost:8080", "extern", "thi", "extern", "servlet", "that", "tri", "access", "wicket", "session", "except", "thrown"], "B_title": "WicketSessionFilter and HttpSessionStore use different attribute name for Wicket Session", "B_clean_title": ["wicketsessionfilt", "wicket", "session", "filter", "httpsessionstor", "http", "session", "store", "use", "differ", "attribut", "name", "wicket", "session"]},
{"A_title": "Do not use the parsed PageParameters when re-creating an expired pageWICKET-4014 and WICKET-4290 provided functionality to re-create an expired page if there is a mount path in the current requests url. There is a minor problem with that because the page parameters are passed to the freshly created page. I.e. parameters for a callback behavior are now set as page construction parameters. Since the execution of the behavior is ignored for the recreated page these parameters should be ignored too.", "A_clean_title": ["not", "use", "pars", "pageparamet", "page", "paramet", "when", "re", "creat", "expir", "pagewicket", "4014", "page", "wicket", "wicket", "4290", "provid", "function", "re", "creat", "expir", "page", "there", "mount", "path", "current", "request", "url", "there", "minor", "problem", "that", "becaus", "page", "paramet", "are", "pass", "freshli", "creat", "page", "paramet", "callback", "behavior", "are", "now", "set", "as", "page", "construct", "paramet", "sinc", "execut", "behavior", "ignor", "recreat", "page", "these", "paramet", "ignor", "too"], "B_title": "Do not use the parsed PageParameters when re-creating an expired page", "B_clean_title": ["not", "use", "pars", "pageparamet", "page", "paramet", "when", "re", "creat", "expir", "page"]},
{"A_title": "Session should be bound when adding messages to itWhen using the Sessions info() error() and success() methods and the session is temporary the messages can be dropped silently. This happens when on stateless pages and a redirect happens in the same request during which a session message is added.  The fix for this could be to make sure the session is bound and call Session#bind() automatically when a session message is added.  Email thread: http://wicket-users.markmail.org/thread/zd72s4gwnlp5d7ch", "A_clean_title": ["session", "bound", "when", "ad", "messag", "itwhen", "it", "when", "session", "info", "error", "success", "method", "session", "temporari", "messag", "drop", "silent", "thi", "happen", "when", "stateless", "page", "redirect", "happen", "same", "request", "dure", "which", "session", "messag", "ad", "fix", "thi", "could", "make", "sure", "session", "bound", "call", "session", "bind", "automat", "when", "session", "messag", "ad", "email", "thread", "http", "wicket", "user", "markmail", "org", "thread", "zd72s4gwnlp5d7ch"], "B_title": "Session should be bound when adding messages to it", "B_clean_title": ["session", "bound", "when", "ad", "messag", "it"]},
{"A_title": "MongoMK: split documents when they are too largeCurrently the MongoMK stores all revisions of a node in the same document. Once there are many revisions the document gets very large.  The plan is to split the document when it gets big.  It looks like this isnt just a nice to have but also a problem for some use cases. Example stack trace:  code 21.07.2013 12:35:47.554 *ERROR* ... Caused by: java.lang.IllegalArgumentException: ok should never be null... at com.mongodb.CommandResult.ok(CommandResult.java:48) at com.mongodb.DBCollection.findAndModify(DBCollection.java:375) at org.apache.jackrabbit.oak.plugins.mongomk.MongoDocumentStore.findAndModify(MongoDocumentStore.java:302) ... 32 more code  at the same time in the MongoDB log:  code Sun Jul 21 12:35:47.334 conn7 warning: log line attempted (159k) over max size(10k)  printing beginning and end ...  Assertion: 10334:BSONObj size: 16795219 (0x53460001) is invalid.  Size must be between 0 and 16793600(16MB)  First element: :childOrder:  r1400279f22d-0-1:  ... code", "A_clean_title": ["mongomk", "mongo", "mk", "split", "document", "when", "they", "are", "too", "largecurr", "larg", "current", "mongomk", "mongo", "mk", "store", "all", "revis", "node", "same", "document", "onc", "there", "are", "mani", "revis", "document", "get", "veri", "larg", "plan", "split", "document", "when", "it", "get", "big", "it", "look", "like", "thi", "isnt", "just", "nice", "have", "but", "also", "problem", "some", "use", "case", "exampl", "stack", "trace", "code", "21", "07", "2013", "12:35:47", "554", "error", "caus", "by", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "ok", "never", "null", "at", "com", "mongodb", "commandresult", "ok", "command", "result", "commandresult", "java:48", "command", "result", "at", "com", "mongodb", "dbcollect", "findandmodifi", "db", "collect", "find", "modifi", "dbcollect", "java:375", "db", "collect", "at", "org", "apach", "jackrabbit", "oak", "plugin", "mongomk", "mongodocumentstor", "findandmodifi", "mongo", "document", "store", "find", "modifi", "mongodocumentstor", "java:302", "mongo", "document", "store", "32", "more", "code", "at", "same", "time", "mongodb", "mongo", "db", "log", "code", "sun", "jul", "21", "12:35:47", "334", "conn7", "warn", "log", "line", "attempt", "159k", "over", "max", "size", "10k", "print", "begin", "end", "assert", "10334", "bsonobj", "bson", "obj", "size", "16795219", "0x53460001", "invalid", "size", "must", "between", "16793600", "16mb", "first", "element", "childord", "child", "order", "r1400279f22d", "code"], "B_title": "MongoMK: split documents when they are too large - Parse PREVIOUS into Revision/Range on demand - More tests", "B_clean_title": ["mongomk", "mongo", "mk", "split", "document", "when", "they", "are", "too", "larg", "pars", "previou", "into", "revis", "rang", "demand", "more", "test"]},
{"A_title": "FastMath.exp may return NaN for non-NaN argumentsI have observed that FastMath.exp(709.8125) returns NaN. However the exponential function must never return NaN (if the argument is not NaN). The result must always be non-negative or positive infinity.", "A_clean_title": ["fastmath", "exp", "fast", "math", "may", "return", "nan", "na", "non", "nan", "na", "argumentsi", "argument", "have", "observ", "that", "fastmath", "exp", "fast", "math", "709", "8125", "return", "nan", "na", "howev", "exponenti", "function", "must", "never", "return", "nan", "na", "argument", "not", "nan", "na", "result", "must", "alway", "non", "neg", "or", "posit", "infin"], "B_title": "fixed FastMath.exp returning NaN for non-NaN arguments", "B_clean_title": ["fix", "fastmath", "exp", "fast", "math", "return", "nan", "na", "non", "nan", "na", "argument"]},
{"A_title": "inverseCumulativeDistribution fails with cumulative distribution having a plateauThis bug report follows MATH-692. The attached unit test fails. As required by the definition in MATH-692 the lower-bound of the interval on which the cdf is constant should be returned. This is not so at the moment.", "A_clean_title": ["inversecumulativedistribut", "invers", "cumul", "distribut", "fail", "cumul", "distribut", "have", "plateauthi", "plateau", "thi", "bug", "report", "follow", "math", "692", "attach", "unit", "test", "fail", "as", "requir", "by", "definit", "math", "692", "lower", "bound", "interv", "which", "cdf", "constant", "return", "thi", "not", "so", "at", "moment"], "B_title": "New implementation of AbstractRealDistribution.inverseCumulativeProbability(double). Solves MATH-699 and leads to slightly smaller execution times.", "B_clean_title": ["new", "implement", "abstractrealdistribut", "inversecumulativeprob", "abstract", "real", "distribut", "invers", "cumul", "probabl", "doubl", "solv", "math", "699", "lead", "slightli", "smaller", "execut", "time"]},
{"A_title": "Checkpoint stats show ghost numbers~StephanEwen reported an issue with the display of checkpoint stats. A pipeline with a stateful source and stateless intermediate operator shows stats for the stateless intermediate operator. The numbers are most likely the same as for the source operator.", "A_clean_title": ["checkpoint", "stat", "show", "ghost", "numbers~stephanewen", "numbers~stephan", "ewen", "report", "issu", "display", "checkpoint", "stat", "pipelin", "state", "sourc", "stateless", "intermedi", "oper", "show", "stat", "stateless", "intermedi", "oper", "number", "are", "most", "like", "same", "as", "sourc", "oper"], "B_title": "runtime Return empty stats for unknown operator", "B_clean_title": ["runtim", "return", "empti", "stat", "unknown", "oper"]},
{"A_title": "Ajax behavior on component with setRenderBodyOnly(true) dont get called - improve warningWhen you put AJAX behavior on component with setRenderBodyOnly(true) and try to call it with callback script it wont get called and no error / warning is displayed. See attached quickstart sample. Just unzipp and run with: mvn jetty:run  Navigate browser to http://localhost:8080/ When you try to click on labels AJAX behavior should get called. But it wont. This kind of behavior is correct (i assume). But i think user should be warned that behavior cant be called. I think proper place is somewhere on server side? But I dont know where exactly put the warning.  Now only message is in Wicket Ajax Debug window - Ajax request stopped because of precondition check. I had to debug wicket javascript to find what precondition check failed. Maybe more detailed message in default precondition check would be useful too?", "A_clean_title": ["ajax", "behavior", "compon", "setrenderbodyonli", "set", "render", "bodi", "onli", "true", "dont", "get", "call", "improv", "warningwhen", "warn", "when", "you", "put", "ajax", "behavior", "compon", "setrenderbodyonli", "set", "render", "bodi", "onli", "true", "tri", "call", "it", "callback", "script", "it", "wont", "get", "call", "no", "error", "warn", "display", "see", "attach", "quickstart", "sampl", "just", "unzipp", "run", "mvn", "jetti", "run", "navig", "browser", "http", "localhost:8080", "when", "you", "tri", "click", "label", "ajax", "behavior", "get", "call", "but", "it", "wont", "thi", "kind", "behavior", "correct", "assum", "but", "think", "user", "warn", "that", "behavior", "cant", "call", "think", "proper", "place", "somewher", "server", "side", "but", "dont", "know", "where", "exactli", "put", "warn", "now", "onli", "messag", "wicket", "ajax", "debug", "window", "ajax", "request", "stop", "becaus", "precondit", "check", "had", "debug", "wicket", "javascript", "find", "what", "precondit", "check", "fail", "mayb", "more", "detail", "messag", "default", "precondit", "check", "would", "use", "too"], "B_title": "dont request a groups markup since this will result in a log warning if the group does render its body only (the default) - formerly encoding of the groups markup id in the check/radios CSS class is no longer needed with WICKET-4797 anyway", "B_clean_title": ["dont", "request", "group", "markup", "sinc", "thi", "will", "result", "log", "warn", "group", "render", "it", "bodi", "onli", "default", "formerli", "encod", "group", "markup", "id", "check", "radio", "css", "class", "no", "longer", "need", "wicket", "4797", "anyway"]},
{"A_title": "Invalid left-hand side of assignment not detectedNone", "A_clean_title": ["invalid", "left", "hand", "side", "assign", "not", "detectednon", "detect", "none"], "B_title": "Dont let invalid LHS assignments to slip through. Fixes issue 215. Fixes issue 214.", "B_clean_title": ["dont", "let", "invalid", "lh", "assign", "slip", "through", "fix", "issu", "215", "fix", "issu", "214"]},
{"A_title": "FormTester throws an exception when a Palette component is added to a Form associated with a compound property modelFormTester throws an exception when a Palette component is added to a Form associated with a compound property model: org.apache.wicket.WicketRuntimeException: No get method defined for class ... expression: choices  It worked fine in Wicket 6.5.0 and works fine if the form is not associated with a compound property model.", "A_clean_title": ["formtest", "form", "tester", "throw", "except", "when", "palett", "compon", "ad", "form", "associ", "compound", "properti", "modelformtest", "model", "form", "tester", "throw", "except", "when", "palett", "compon", "ad", "form", "associ", "compound", "properti", "model", "org", "apach", "wicket", "wicketruntimeexcept", "wicket", "runtim", "except", "no", "get", "method", "defin", "class", "express", "choic", "it", "work", "fine", "wicket", "work", "fine", "form", "not", "associ", "compound", "properti", "model"], "B_title": "AbstractOptions does not use its model", "B_clean_title": ["abstractopt", "abstract", "option", "not", "use", "it", "model"]},
{"A_title": "Lucene index / compatVersion 2: search for a=b=c does not workSimilar to OAK-3879 we need to escape = (althoug lucene escape()|https://github.com/apache/lucene-solr/blob/releases/lucene-solr/4.7.1/lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase.java#L988 apparently doesnt escape it).  Due to this searching for a=b=c throws parse exception from lucene query parser. Also searching for a=b gives incorrect result.", "A_clean_title": ["lucen", "index", "compatvers", "compat", "version", "search", "a=b=c", "not", "worksimilar", "work", "similar", "oak", "3879", "we", "need", "escap", "althoug", "lucen", "escap", "|http", "solr", "blob", "releas", "lucen", "java", "github", "com", "apach", "lucen", "solr", "lucen", "querypars", "src", "java", "org", "apach", "lucen", "querypars", "classic", "queryparserbas", "queri", "parser", "base", "l988", "appar", "doesnt", "escap", "it", "due", "thi", "search", "a=b=c", "throw", "pars", "except", "lucen", "queri", "parser", "also", "search", "a=b", "give", "incorrect", "result"], "B_title": "Lucene query fails if search string contains = symbol", "B_clean_title": ["lucen", "queri", "fail", "search", "string", "contain", "symbol"]},
{"A_title": "NPE when calling SubLine.intersection() with non-intersecting linesWhen calling SubLine.intersection() with two lines that not intersect then a NullPointerException is thrown in Line.toSubSpace(). This bug is in the twod and threed implementations.  The attached patch fixes both implementations and adds the required test cases.", "A_clean_title": ["npe", "when", "call", "sublin", "intersect", "sub", "line", "non", "intersect", "lineswhen", "line", "when", "call", "sublin", "intersect", "sub", "line", "two", "line", "that", "not", "intersect", "then", "nullpointerexcept", "null", "pointer", "except", "thrown", "line", "tosubspac", "sub", "space", "thi", "bug", "twod", "threed", "implement", "attach", "patch", "fix", "both", "implement", "add", "requir", "test", "case"], "B_title": "Fixed NullPointerException in 2D and 3D sub-line intersections.", "B_clean_title": ["fix", "nullpointerexcept", "null", "pointer", "except", "2d", "3d", "sub", "line", "intersect"]},
{"A_title": "CryptoMapper ignores original queryString parametersWhen an AjaxRequest with parameters (e.g.: Autocomplete.getChoices()) arrives and CryptoMapper decrypts it original queryString parameters dissapears.  Debugging CryptoMapper Ive checked that this method: private Url decryptUrl(final Request request final Url encryptedUrl)          ...   receives querystrings parameters (on field url.parameter from request parameter) and the new Url returned by the method never adds them to its own list.", "A_clean_title": ["cryptomapp", "crypto", "mapper", "ignor", "origin", "querystr", "queri", "string", "parameterswhen", "paramet", "when", "ajaxrequest", "ajax", "request", "paramet", "autocomplet", "getchoic", "get", "choic", "arriv", "cryptomapp", "crypto", "mapper", "decrypt", "it", "origin", "querystr", "queri", "string", "paramet", "dissapear", "debug", "cryptomapp", "crypto", "mapper", "ive", "check", "that", "thi", "method", "privat", "url", "decrypturl", "decrypt", "url", "final", "request", "request", "final", "url", "encryptedurl", "encrypt", "url", "receiv", "querystr", "paramet", "field", "url", "paramet", "request", "paramet", "new", "url", "return", "by", "method", "never", "add", "them", "it", "own", "list"], "B_title": "additional query parameters have to be added to the new url", "B_clean_title": ["addit", "queri", "paramet", "have", "ad", "new", "url"]},
{"A_title": "addDays(0) changes value of MutableDateTimeUpon DST transition from summer to winter time zone adding the amount of zero days to a mutable date time object changes the value of the object. The methods addMonths and addYears show the same problem; addSeconds addMinutes and addHours are ok.  I have tested with version 2.3. However if I repeat the test with Joda 1.5.2 the invocation of addDays(0) does not change the dates value.", "A_clean_title": ["addday", "add", "day", "chang", "valu", "mutabledatetimeupon", "mutabl", "date", "time", "upon", "dst", "transit", "summer", "winter", "time", "zone", "ad", "amount", "zero", "day", "mutabl", "date", "time", "object", "chang", "valu", "object", "method", "addmonth", "add", "month", "addyear", "add", "year", "show", "same", "problem", "addsecond", "add", "second", "addminut", "add", "minut", "addhour", "add", "hour", "are", "ok", "have", "test", "version", "howev", "repeat", "test", "joda", "invoc", "addday", "add", "day", "not", "chang", "date", "valu"], "B_title": "Adding zero no longer changes the offset during DST overlap", "B_clean_title": ["ad", "zero", "no", "longer", "chang", "offset", "dure", "dst", "overlap"]},
{"A_title": "discrepancy between JavaDoc and code in MarkupContainer#visitChildren()The JavaDoc for  MarkupContainer#visitChildren() states that  @param clazz The class of child to visit or null to visit all children  The parameter clazz is used to create a new ClassVisitFilter which in its visitObject() does not check for clazz == null leading to a NPE.", "A_clean_title": ["discrep", "between", "javadoc", "java", "doc", "code", "markupcontain", "markup", "contain", "visitchildren", "visit", "children", "javadoc", "java", "doc", "markupcontain", "markup", "contain", "visitchildren", "visit", "children", "state", "that", "param", "clazz", "class", "child", "visit", "or", "null", "visit", "all", "children", "paramet", "clazz", "use", "creat", "new", "classvisitfilt", "class", "visit", "filter", "which", "it", "visitobject", "visit", "object", "not", "check", "clazz", "null", "lead", "npe"], "B_title": "discrepancy between JavaDoc and code in MarkupContainer#visitChildren()", "B_clean_title": ["discrep", "between", "javadoc", "java", "doc", "code", "markupcontain", "markup", "contain", "visitchildren", "visit", "children"]},
{"A_title": "Custom Kryo Serializer fails in itertation scenarioWhen using iterations with a custom serializer for a domain object the iteration will fail.  code:java org.apache.flink.runtime.client.JobExecutionException: com.esotericsoftware.kryo.KryoException: Buffer underflow at org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.require(NoFetchingInput.java:76) at com.esotericsoftware.kryo.io.Input.readVarInt(Input.java:355) at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:109) at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:641) at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:752) at org.apache.flink.api.java.typeutils.runtime.KryoSerializer.deserialize(KryoSerializer.java:198) at org.apache.flink.api.java.typeutils.runtime.KryoSerializer.deserialize(KryoSerializer.java:203) at org.apache.flink.runtime.io.disk.InputViewIterator.next(InputViewIterator.java:43) at org.apache.flink.runtime.iterative.task.IterationHeadPactTask.streamOutFinalOutputBulk(IterationHeadPactTask.java:404) at org.apache.flink.runtime.iterative.task.IterationHeadPactTask.run(IterationHeadPactTask.java:377) at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:360) at org.apache.flink.runtime.execution.RuntimeEnvironment.run(RuntimeEnvironment.java:204) at java.lang.Thread.run(Thread.java:745) code", "A_clean_title": ["custom", "kryo", "serial", "fail", "itert", "scenariowhen", "scenario", "when", "iter", "custom", "serial", "domain", "object", "iter", "will", "fail", "code", "java", "org", "apach", "flink", "runtim", "client", "jobexecutionexcept", "job", "execut", "except", "com", "esotericsoftwar", "kryo", "kryoexcept", "kryo", "except", "buffer", "underflow", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "nofetchinginput", "requir", "no", "fetch", "input", "nofetchinginput", "java:76", "no", "fetch", "input", "at", "com", "esotericsoftwar", "kryo", "io", "input", "readvarint", "read", "var", "int", "input", "java:355", "at", "com", "esotericsoftwar", "kryo", "util", "defaultclassresolv", "readclass", "default", "class", "resolv", "read", "class", "defaultclassresolv", "java:109", "default", "class", "resolv", "at", "com", "esotericsoftwar", "kryo", "kryo", "readclass", "read", "class", "kryo", "java:641", "at", "com", "esotericsoftwar", "kryo", "kryo", "readclassandobject", "read", "class", "object", "kryo", "java:752", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "kryoseri", "deseri", "kryo", "serial", "kryoseri", "java:198", "kryo", "serial", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "kryoseri", "deseri", "kryo", "serial", "kryoseri", "java:203", "kryo", "serial", "at", "org", "apach", "flink", "runtim", "io", "disk", "inputviewiter", "next", "input", "view", "iter", "inputviewiter", "java:43", "input", "view", "iter", "at", "org", "apach", "flink", "runtim", "iter", "task", "iterationheadpacttask", "streamoutfinaloutputbulk", "iter", "head", "pact", "task", "stream", "out", "final", "output", "bulk", "iterationheadpacttask", "java:404", "iter", "head", "pact", "task", "at", "org", "apach", "flink", "runtim", "iter", "task", "iterationheadpacttask", "run", "iter", "head", "pact", "task", "iterationheadpacttask", "java:377", "iter", "head", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "invok", "regular", "pact", "task", "regularpacttask", "java:360", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "run", "runtim", "environ", "runtimeenviron", "java:204", "runtim", "environ", "at", "java", "lang", "thread", "run", "thread", "java:745", "code"], "B_title": "runtime Adds proper EOFException forwarding to KryoSerializer.", "B_clean_title": ["runtim", "add", "proper", "eofexcept", "eof", "except", "forward", "kryoseri", "kryo", "serial"]},
{"A_title": "if statementNone", "A_clean_title": ["statementnon", "statement", "none"], "B_title": "Dont reorder if condition expressions if they contain side-effects. Fixes issue 925. ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=43060270", "B_clean_title": ["dont", "reorder", "condit", "express", "they", "contain", "side", "effect", "fix", "issu", "925", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=43060270"]},
{"A_title": "Parallel execution of SimpleSearchTest fails with MongoMKAt some point in the benchmark run one MongoMK instance will fail to read a node created by another instance. The exception is very similar to *E1* reported in OAK-1204.", "A_clean_title": ["parallel", "execut", "simplesearchtest", "simpl", "search", "test", "fail", "mongomkat", "mongo", "mk", "at", "some", "point", "benchmark", "run", "one", "mongomk", "mongo", "mk", "instanc", "will", "fail", "read", "node", "creat", "by", "anoth", "instanc", "except", "veri", "similar", "e1", "report", "oak", "1204"], "B_title": "Parallel execution of SimpleSearchTest fails with MongoMK - publish current head revision first to revision comparator - enable tests", "B_clean_title": ["parallel", "execut", "simplesearchtest", "simpl", "search", "test", "fail", "mongomk", "mongo", "mk", "publish", "current", "head", "revis", "first", "revis", "compar", "enabl", "test"]},
{"A_title": "Url.canonical() breaks when there are two consecutive parent segments followed by a normal segmentassertEquals(a/d Url.parse(a/b/c/../../d).canonical().getPath());   breaks with : Expected :a/d Actual   :a/b/../d", "A_clean_title": ["url", "canon", "break", "when", "there", "are", "two", "consecut", "parent", "segment", "follow", "by", "normal", "segmentassertequ", "segmentassert", "equal", "url", "pars", "canon", "getpath", "get", "path", "break", "expect", "actual"], "B_title": "Url.canonical() breaks when there are two consecutive parent segments followed by a normal segment", "B_clean_title": ["url", "canon", "break", "when", "there", "are", "two", "consecut", "parent", "segment", "follow", "by", "normal", "segment"]},
{"A_title": "File never picked up for replicationI was running some tests and noticed that a single file was getting ignored. The logs were warning that the Status message that was written to accumulo.metadata didnt have a createdTime on the Status record.  The odd part is that all other Status messages had a createdTime and were successfully replicated. Looking at the writes from the TabletServer logs the expected record *was* written by the TabletServer and writing a test with the full series of Status records written does net the correct Status (which was different than what was observed in the actual table).  Looking into it the log which was subject to this error was the first WAL that was used when the instance was started. Because the table configurations are lazily configured when they are actually used I believe that the StatusCombiner that is set on accumulo.metadata was not seen by the TabletServer and the VersioningIterator ate the first record.  I need to come up with a way that I can be sure that all tservers will have seen the Combiner set on accumulo.metadata before any data is written to it to avoid losing a record like this.", "A_clean_title": ["file", "never", "pick", "up", "replicationi", "replic", "wa", "run", "some", "test", "notic", "that", "singl", "file", "wa", "get", "ignor", "log", "were", "warn", "that", "statu", "messag", "that", "wa", "written", "accumulo", "metadata", "didnt", "have", "createdtim", "creat", "time", "statu", "record", "odd", "part", "that", "all", "other", "statu", "messag", "had", "createdtim", "creat", "time", "were", "success", "replic", "look", "at", "write", "tabletserv", "tablet", "server", "log", "expect", "record", "wa", "written", "by", "tabletserv", "tablet", "server", "write", "test", "full", "seri", "statu", "record", "written", "net", "correct", "statu", "which", "wa", "differ", "than", "what", "wa", "observ", "actual", "tabl", "look", "into", "it", "log", "which", "wa", "subject", "thi", "error", "wa", "first", "wal", "that", "wa", "use", "when", "instanc", "wa", "start", "becaus", "tabl", "configur", "are", "lazili", "configur", "when", "they", "are", "actual", "use", "believ", "that", "statuscombin", "statu", "combin", "that", "set", "accumulo", "metadata", "wa", "not", "seen", "by", "tabletserv", "tablet", "server", "versioningiter", "version", "iter", "ate", "first", "record", "need", "come", "up", "way", "that", "sure", "that", "all", "tserver", "will", "have", "seen", "combin", "set", "accumulo", "metadata", "befor", "ani", "data", "written", "it", "avoid", "lose", "record", "like", "thi"], "B_title": "Set StatusCombiner on accumulo.metadata during initialize.", "B_clean_title": ["set", "statuscombin", "statu", "combin", "accumulo", "metadata", "dure", "initi"]},
{"A_title": "new multivariate vector optimizers cannot be used with large number of weightsWhen using the Weigth class to pass a large number of weights to multivariate vector optimizers an nxn full matrix is created (and copied) when a n elements vector is used. This exhausts memory when n is large.  This happens for example when using curve fitters (even simple curve fitters like polynomial ones for low degree) with large number of points. I encountered this with curve fitting on 41200 points which created a matrix with 1.7 billion elements.", "A_clean_title": ["new", "multivari", "vector", "optim", "not", "use", "larg", "number", "weightswhen", "weight", "when", "weigth", "class", "pass", "larg", "number", "weight", "multivari", "vector", "optim", "nxn", "full", "matrix", "creat", "copi", "when", "element", "vector", "use", "thi", "exhaust", "memori", "when", "larg", "thi", "happen", "exampl", "when", "curv", "fitter", "even", "simpl", "curv", "fitter", "like", "polynomi", "one", "low", "degre", "larg", "number", "point", "encount", "thi", "curv", "fit", "41200", "point", "which", "creat", "matrix", "billion", "element"], "B_title": "Avoid memory exhaustion for large number of unclorrelated observations.", "B_clean_title": ["avoid", "memori", "exhaust", "larg", "number", "unclorrel", "observ"]},
{"A_title": "Accumulo Shell does not respect exit when executing fileIf there is an exit statement in the file given via accumulo shell -f file the execution seems to skip it and go on to the next command instead of terminating.  To recreate: noformat mike@home ~ cat bug.accumulo exit scan -np -t !METADATA mike@home ~ bin/accumulo shell -f /home/mike/bug.accumulo noformat  Expected output: None Actual output: A full scan of the !METADATA", "A_clean_title": ["accumulo", "shell", "not", "respect", "exit", "when", "execut", "fileif", "file", "there", "exit", "statement", "file", "given", "via", "accumulo", "shell", "file", "execut", "seem", "skip", "it", "go", "next", "command", "instead", "termin", "recreat", "noformat", "mike", "home", "cat", "bug", "accumulo", "exit", "scan", "np", "metadata", "mike", "home", "bin", "accumulo", "shell", "accumulo", "home", "mike", "bug", "noformat", "expect", "output", "none", "actual", "output", "full", "scan", "metadata"], "B_title": "merged patch to trunk", "B_clean_title": ["merg", "patch", "trunk"]},
{"A_title": "MarkupContainer.toString(true) fails with MarkupNotFoundException if the call is made in the component constructororg.apache.wicket.MarkupContainer.toString(boolean) uses if (getMarkup() != null) to decide whether to write something for the markup but since recently Component#getMarkup() throws MarkupNotFoundException when there is no markup and doesnt return null.", "A_clean_title": ["markupcontain", "tostr", "markup", "contain", "string", "true", "fail", "markupnotfoundexcept", "markup", "not", "found", "except", "call", "made", "compon", "constructororg", "apach", "wicket", "markupcontain", "tostr", "markup", "contain", "string", "boolean", "use", "getmarkup", "get", "markup", "null", "decid", "whether", "write", "someth", "markup", "but", "sinc", "recent", "compon", "getmarkup", "get", "markup", "throw", "markupnotfoundexcept", "markup", "not", "found", "except", "when", "there", "no", "markup", "doesnt", "return", "null"], "B_title": "MarkupContainer.toString(true) fails with MarkupNotFoundException if the call is made in the component constructor", "B_clean_title": ["markupcontain", "tostr", "markup", "contain", "string", "true", "fail", "markupnotfoundexcept", "markup", "not", "found", "except", "call", "made", "compon", "constructor"]},
{"A_title": "PageParametersEncoder should not decode parameters with no nameFrom dev@ mailing list: http://markmail.org/message/khuc2v37aakzyfth  PageParametersEncoder should ignore query parameters like &=& and &=value because they make no sene and lead to exceptions later at PageParameters#add() call.", "A_clean_title": ["pageparametersencod", "page", "paramet", "encod", "not", "decod", "paramet", "no", "namefrom", "name", "dev", "mail", "list", "http", "markmail", "org", "messag", "khuc2v37aakzyfth", "pageparametersencod", "page", "paramet", "encod", "ignor", "queri", "paramet", "like", "=valu", "becaus", "they", "make", "no", "sene", "lead", "except", "later", "at", "pageparamet", "page", "paramet", "add", "call"], "B_title": "PageParametersEncoder should not decode parameters with no name", "B_clean_title": ["pageparametersencod", "page", "paramet", "encod", "not", "decod", "paramet", "no", "name"]},
{"A_title": "Hidden properties (one prefixed with :) in lucenes analyzer configuration fail to construct analyzersThis is similar to OAK-2524 in the sense that lucene doesnt like extra arguments sent its way while constructing analyzers. In some cases (like node move adds :source-path) we have hidden properties added to index definition nodes and they get passed along to lucene analyzer factories which complaint and fail.", "A_clean_title": ["hidden", "properti", "one", "prefix", "lucen", "analyz", "configur", "fail", "construct", "analyzersthi", "analyz", "thi", "similar", "oak", "2524", "sens", "that", "lucen", "doesnt", "like", "extra", "argument", "sent", "it", "way", "while", "construct", "analyz", "some", "case", "like", "node", "move", "add", "sourc", "path", "we", "have", "hidden", "properti", "ad", "index", "definit", "node", "they", "get", "pass", "along", "lucen", "analyz", "factori", "which", "complaint", "fail"], "B_title": "Hidden properties in lucene analyzer configuration fail to construct analyzers", "B_clean_title": ["hidden", "properti", "lucen", "analyz", "configur", "fail", "construct", "analyz"]},
{"A_title": "Remove assert from MathUtils.equalsThe assert in methods equals(doubledoubleint) and equals(floatfloatint) is not necessary.", "A_clean_title": ["remov", "assert", "mathutil", "equalsth", "math", "util", "equal", "assert", "method", "equal", "doubledoubleint", "equal", "floatfloatint", "not", "necessari"], "B_title": "Removed assert statements.", "B_clean_title": ["remov", "assert", "statement"]},
{"A_title": "getKernel fails for buckets with only multiple instances of the same value in random.EmpiricalDistributionAfter loading a set of values into an EmpericalDistribution assume that theres a case where a single bin ONLY contains multiple instances of the same value.  In this case the standard deviation will equal zero.  This will fail when getKernel attempts to create a NormalDistribution.  The other case where stddev=0 is when there is only a single value in the bin and this is handled by returning a ConstantRealDistribution rather than a NormalDistrbution.  See: https://issues.apache.org/jira/browse/MATH-984", "A_clean_title": ["getkernel", "get", "kernel", "fail", "bucket", "onli", "multipl", "instanc", "same", "valu", "random", "empiricaldistributionaft", "empir", "distribut", "after", "load", "set", "valu", "into", "empericaldistribut", "emper", "distribut", "assum", "that", "there", "case", "where", "singl", "bin", "onli", "contain", "multipl", "instanc", "same", "valu", "thi", "case", "standard", "deviat", "will", "equal", "zero", "thi", "will", "fail", "when", "getkernel", "get", "kernel", "attempt", "creat", "normaldistribut", "normal", "distribut", "other", "case", "where", "stddev=0", "when", "there", "onli", "singl", "valu", "bin", "thi", "handl", "by", "return", "constantrealdistribut", "constant", "real", "distribut", "rather", "than", "normaldistrbut", "normal", "distrbut", "see", "http", "984", "apach", "issu", "org", "jira", "brows", "math"], "B_title": "Made getKernel return a constant distribution for zero variance bins.  JIRA: MATH-1203.", "B_clean_title": ["made", "getkernel", "get", "kernel", "return", "constant", "distribut", "zero", "varianc", "bin", "jira", "math", "1203"]},
{"A_title": "Trailing slash not removed for simple path in JCR to Oak path conversionWhile converting from JCR path to Oak path the trailing slashes are not removed for simple paths. They are removed for complex path  code assertEquals(/oak-foo:bar/oak-quu:quxnpMapper.getOakPath(/foo:bar/quu:qux/)); assertEquals(/a/b/cnpMapper.getOakPath(/a/b/c/));      code  Of the two cases above the first one passes while the second one fails", "A_clean_title": ["trail", "slash", "not", "remov", "simpl", "path", "jcr", "oak", "path", "conversionwhil", "convers", "while", "convert", "jcr", "path", "oak", "path", "trail", "slash", "are", "not", "remov", "simpl", "path", "they", "are", "remov", "complex", "path", "code", "assertequ", "assert", "equal", "foo", "oak", "quu", "bar", "oak", "quxnpmapp", "getoakpath", "quxnp", "mapper", "get", "oak", "path", "foo", "bar", "quu", "qux", "assertequ", "assert", "equal", "getoakpath", "cnpmapper", "get", "oak", "path", "cnp", "mapper", "code", "two", "case", "abov", "first", "one", "pass", "while", "second", "one", "fail"], "B_title": "Trailing slash not removed for simple path in JCR to Oak path conversion Thanks Chetan for the patch", "B_clean_title": ["trail", "slash", "not", "remov", "simpl", "path", "jcr", "oak", "path", "convers", "thank", "chetan", "patch"]},
{"A_title": "Array Join Munged IncorrectlyNone", "A_clean_title": ["array", "join", "mung", "incorrectlynon", "incorrectli", "none"], "B_title": "Fix an edge case in how Array.prototype.join is collapsed. Fixes issue 106.", "B_clean_title": ["fix", "edg", "case", "how", "array", "prototyp", "join", "collaps", "fix", "issu", "106"]},
{"A_title": "NodeType index doesnt respect the declaringNodeTypes settingFollowing the OAK-1150 discussion Ive noticed that the node type index doesnt respect the declaringNodeTypes setting. Setting a restriction on the node type index definition breaks the index - there are 0 query hits.", "A_clean_title": ["nodetyp", "node", "type", "index", "doesnt", "respect", "declaringnodetyp", "declar", "node", "type", "settingfollow", "set", "follow", "oak", "1150", "discuss", "ive", "notic", "that", "node", "type", "index", "doesnt", "respect", "declaringnodetyp", "declar", "node", "type", "set", "set", "restrict", "node", "type", "index", "definit", "break", "index", "there", "are", "queri", "hit"], "B_title": "NodeType index doesnt respect the declaringNodeTypes setting", "B_clean_title": ["nodetyp", "node", "type", "index", "doesnt", "respect", "declaringnodetyp", "declar", "node", "type", "set"]},
{"A_title": "Stack overflow when render malformed html.Stack overflow when render malformed html.  Please note that </HEAD> element is inserted after </body>.  HTML: <html> <head> <body> Malformed HTML </body> </head> </html>  Java: package com.mycompany;  import org.apache.wicket.markup.html.WebPage; public class Test1 extends WebPage  private static final long serialVersionUID = -4267477971499123852L;     Thanks.", "A_clean_title": ["stack", "overflow", "when", "render", "malform", "html", "stack", "overflow", "when", "render", "malform", "html", "pleas", "note", "that", "head", "element", "insert", "after", "bodi", "html", "html", "head", "bodi", "malform", "html", "bodi", "head", "html", "java", "packag", "com", "mycompani", "import", "org", "apach", "wicket", "markup", "html", "webpag", "web", "page", "public", "class", "test1", "extend", "webpag", "web", "page", "privat", "static", "final", "long", "serialversionuid", "serial", "version", "uid", "4267477971499123852l", "thank"], "B_title": "Stack overflow when render malformed html.", "B_clean_title": ["stack", "overflow", "when", "render", "malform", "html"]},
{"A_title": "Make org.mockito.asm.signature package optional in Import-Packages.None", "A_clean_title": ["make", "org", "mockito", "asm", "signatur", "packag", "option", "import", "packag", "none"], "B_title": "Fixed issue 151. Merged from trunk. Mockito should not be so defensive and clear potential stubbed call on creation of new mock", "B_clean_title": ["fix", "issu", "151", "merg", "trunk", "mockito", "not", "so", "defens", "clear", "potenti", "stub", "call", "creation", "new", "mock"]},
{"A_title": "Mockito 1.10.x timeout verification needs JUnit classes (VerifyError NoClassDefFoundError).If JUnit is not on the classpath and mockito is version 1.10.x (as of now 1.10.1 up to 1.10.19) and the code is using the timeout verification which is not supposed to be related to JUnit then the JVM may fail with a VerifyError or a NoClassDefFoundError.", "A_clean_title": ["mockito", "10", "timeout", "verif", "need", "junit", "unit", "class", "verifyerror", "verifi", "error", "noclassdeffounderror", "no", "class", "def", "found", "error", "junit", "unit", "not", "classpath", "mockito", "version", "10", "as", "now", "10", "up", "10", "19", "code", "timeout", "verif", "which", "not", "suppos", "relat", "junit", "unit", "then", "jvm", "may", "fail", "verifyerror", "verifi", "error", "or", "noclassdeffounderror", "no", "class", "def", "found", "error"], "B_title": "Fixed issue 152 User should be able to configure the mock to be serializable and have extra interfaces", "B_clean_title": ["fix", "issu", "152", "user", "abl", "configur", "mock", "serializ", "have", "extra", "interfac"]},
{"A_title": "TypeExtractor returns wrong type info when a Tuple has two fields of the same POJO typeConsider the following code:  DataSet<FooBarPojo> d1 = env.fromElements(new FooBarPojo()); DataSet<Tuple2<FooBarPojo FooBarPojo>> d2 = d1.map(new MapFunction<FooBarPojo Tuple2<FooBarPojo FooBarPojo>>()  @Override public Tuple2<FooBarPojo FooBarPojo> map(FooBarPojo value) throws Exception  return null;  );  where FooBarPojo is the following type: public class FooBarPojo  public int foo bar; public FooBarPojo()    This should print a tuple type with two identical fields: Java Tuple2<PojoType<FooBarPojo fields = bar: Integer foo: Integer> PojoType<FooBarPojo fields = bar: Integer foo: Integer>>  But it prints the following instead: Java Tuple2<PojoType<FooBarPojo fields = bar: Integer foo: Integer> GenericType<FooBarPojo>>  Note that this problem causes some co-groups in Gelly to crash with org.apache.flink.api.common.InvalidProgramException: The pair of co-group keys are not compatible with each other when the vertex ID type is a POJO because the second field of the Edge type gets to be a generic type but the POJO gets recognized in the Vertex type and getNumberOfKeyFields returns different numbers for the POJO and the generic type.  The source of the problem is the mechanism in TypeExtractor that would detect recursive types (see the alreadySeen field in TypeExtractor) as it mistakes the second appearance of FooBarPojo with a recursive field.  Specifically the following happens: createTypeInfoWithTypeHierarchy starts to process the Tuple2<FooBarPojo FooBarPojo> type and in line 434 it calls itself for the first field which proceeds into the privateGetForClass case which correctly detects that it is a POJO and correctly returns a PojoTypeInfo; but in the meantime in line 1191 privateGetForClass adds PojoTypeInfo to alreadySeen. Then the outer createTypeInfoWithTypeHierarchy approaches the second field goes into privateGetForClass which mistakenly returns a GenericTypeInfo as it thinks in line 1187 that a recursive type is being processed.  (Note that if we comment out the recursive type detection (the lines that do their thing with the alreadySeen field) then the output is correct.)", "A_clean_title": ["typeextractor", "type", "extractor", "return", "wrong", "type", "info", "when", "tupl", "ha", "two", "field", "same", "pojo", "typeconsid", "type", "consid", "follow", "code", "dataset", "data", "set", "foobarpojo", "foo", "bar", "pojo", "d1", "env", "fromel", "element", "new", "foobarpojo", "foo", "bar", "pojo", "dataset", "data", "set", "tuple2", "foobarpojo", "foo", "bar", "pojo", "foobarpojo", "foo", "bar", "pojo", "d2", "d1", "map", "new", "mapfunct", "map", "function", "foobarpojo", "foo", "bar", "pojo", "tuple2", "foobarpojo", "foo", "bar", "pojo", "foobarpojo", "foo", "bar", "pojo", "overrid", "public", "tuple2", "foobarpojo", "foo", "bar", "pojo", "foobarpojo", "foo", "bar", "pojo", "map", "foobarpojo", "foo", "bar", "pojo", "valu", "throw", "except", "return", "null", "where", "foobarpojo", "foo", "bar", "pojo", "follow", "type", "public", "class", "foobarpojo", "foo", "bar", "pojo", "public", "int", "foo", "bar", "public", "foobarpojo", "foo", "bar", "pojo", "thi", "print", "tupl", "type", "two", "ident", "field", "java", "tuple2", "pojotyp", "pojo", "type", "foobarpojo", "foo", "bar", "pojo", "field", "bar", "integ", "foo", "integ", "pojotyp", "pojo", "type", "foobarpojo", "foo", "bar", "pojo", "field", "bar", "integ", "foo", "integ", "but", "it", "print", "follow", "instead", "java", "tuple2", "pojotyp", "pojo", "type", "foobarpojo", "foo", "bar", "pojo", "field", "bar", "integ", "foo", "integ", "generictyp", "gener", "type", "foobarpojo", "foo", "bar", "pojo", "note", "that", "thi", "problem", "caus", "some", "co", "group", "gelli", "crash", "org", "apach", "flink", "api", "common", "invalidprogramexcept", "invalid", "program", "except", "pair", "co", "group", "key", "are", "not", "compat", "each", "other", "when", "vertex", "id", "type", "pojo", "becaus", "second", "field", "edg", "type", "get", "gener", "type", "but", "pojo", "get", "recogn", "vertex", "type", "getnumberofkeyfield", "get", "number", "key", "field", "return", "differ", "number", "pojo", "gener", "type", "sourc", "problem", "mechan", "typeextractor", "type", "extractor", "that", "would", "detect", "recurs", "type", "see", "alreadyseen", "alreadi", "seen", "field", "typeextractor", "type", "extractor", "as", "it", "mistak", "second", "appear", "foobarpojo", "foo", "bar", "pojo", "recurs", "field", "specif", "follow", "happen", "createtypeinfowithtypehierarchi", "creat", "type", "info", "type", "hierarchi", "start", "process", "tuple2", "foobarpojo", "foo", "bar", "pojo", "foobarpojo", "foo", "bar", "pojo", "type", "line", "434", "it", "call", "itself", "first", "field", "which", "proce", "into", "privategetforclass", "privat", "get", "class", "case", "which", "correctli", "detect", "that", "it", "pojo", "correctli", "return", "pojotypeinfo", "pojo", "type", "info", "but", "meantim", "line", "1191", "privategetforclass", "privat", "get", "class", "add", "pojotypeinfo", "pojo", "type", "info", "alreadyseen", "alreadi", "seen", "then", "outer", "createtypeinfowithtypehierarchi", "creat", "type", "info", "type", "hierarchi", "approach", "second", "field", "goe", "into", "privategetforclass", "privat", "get", "class", "which", "mistakenli", "return", "generictypeinfo", "gener", "type", "info", "as", "it", "think", "line", "1187", "that", "recurs", "type", "be", "process", "note", "that", "we", "comment", "out", "recurs", "type", "detect", "line", "that", "their", "thing", "alreadyseen", "alreadi", "seen", "field", "then", "output", "correct"], "B_title": "java api TypeExtractor returns wrong type info when a Tuple has two fields of the same POJO type", "B_clean_title": ["java", "api", "typeextractor", "type", "extractor", "return", "wrong", "type", "info", "when", "tupl", "ha", "two", "field", "same", "pojo", "type"]},
{"A_title": "A random crash of MersenneTwister random generatorThere is a very small probability that MersenneTwister generator gives a following error:  java.lang.ArrayIndexOutOfBoundsException: 624 in MersenneTwister.java line 253 The error is completely random and its probability is about 1e-8.  UPD: The problem most probably arises only in multy-thread mode.", "A_clean_title": ["random", "crash", "mersennetwist", "mersenn", "twister", "random", "generatorther", "gener", "there", "veri", "small", "probabl", "that", "mersennetwist", "mersenn", "twister", "gener", "give", "follow", "error", "java", "lang", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "624", "mersennetwist", "java", "mersenn", "twister", "line", "253", "error", "complet", "random", "it", "probabl", "about", "1e", "upd", "problem", "most", "probabl", "aris", "onli", "multi", "thread", "mode"], "B_title": "Fixed copy/paste bug.", "B_clean_title": ["fix", "copi", "past", "bug"]},
{"A_title": "Incomplete reinitialization with some events handlingI get a bug with event handling: I track 2 events that occur in the same step when the first one is accepted it resets the state but the reinitialization is not complete and the second one becomes unable to find its way. I cant give my context which is rather large but I tried a patch that works for me unfortunately it breaks the unit tests.", "A_clean_title": ["incomplet", "reiniti", "some", "event", "handlingi", "handl", "get", "bug", "event", "handl", "track", "event", "that", "occur", "same", "step", "when", "first", "one", "accept", "it", "reset", "state", "but", "reiniti", "not", "complet", "second", "one", "becom", "unabl", "find", "it", "way", "cant", "give", "my", "context", "which", "rather", "larg", "but", "tri", "patch", "that", "work", "me", "unfortun", "it", "break", "unit", "test"], "B_title": "Fixed an event resetting issue in ODE.", "B_clean_title": ["fix", "event", "reset", "issu", "ode"]},
{"A_title": "TreeTypeProvider treats optimized node type definition info as Ac-Contentwhile investigating a bug reported by ~teofili and ~mpetria that cause group-import with policy node to fail when run with non-administrative session i found that the TreeTypeProvider wrongly identifies the optimized item definition information stored with the node types (e.g. /jcr:system/jcr:nodeTypes/rep:AccessControllable/rep:namedChildNodeDefinitions/rep:policy ) as access control content and thus doesnt read it properly when using a session that doesnt have jcr:readAccessControl privilege at /jcr:system/jcr:nodeTypes.  the effect of this bug is as follows: the internal calculation of the effective node type and thus item definitions will not work properly for rep:policy nodes (and similar) as the editing session cannot read the full (oak internal) node type definition as stored below /jcr:system/jcr:nodeTypes.", "A_clean_title": ["treetypeprovid", "tree", "type", "provid", "treat", "optim", "node", "type", "definit", "info", "as", "ac", "contentwhil", "investig", "bug", "report", "by", "~teofili", "~mpetria", "that", "caus", "group", "import", "polici", "node", "fail", "when", "run", "non", "administr", "session", "found", "that", "treetypeprovid", "tree", "type", "provid", "wrongli", "identifi", "optim", "item", "definit", "inform", "store", "node", "type", "jcr", "system", "jcr", "nodetyp", "rep", "node", "type", "accesscontrol", "rep", "access", "control", "namedchildnodedefinit", "rep", "name", "child", "node", "definit", "polici", "as", "access", "control", "content", "thu", "doesnt", "read", "it", "properli", "when", "session", "that", "doesnt", "have", "jcr", "readaccesscontrol", "read", "access", "control", "privileg", "at", "jcr", "system", "jcr", "nodetyp", "node", "type", "effect", "thi", "bug", "as", "follow", "intern", "calcul", "effect", "node", "type", "thu", "item", "definit", "will", "not", "work", "properli", "rep", "polici", "node", "similar", "as", "edit", "session", "not", "read", "full", "oak", "intern", "node", "type", "definit", "as", "store", "below", "jcr", "system", "jcr", "nodetyp", "node", "type"], "B_title": ": TreeTypeProvider treates optimized node type definition info as Ac-Content", "B_clean_title": ["treetypeprovid", "tree", "type", "provid", "treat", "optim", "node", "type", "definit", "info", "as", "ac", "content"]},
{"A_title": "bad variable inlining in closureNone", "A_clean_title": ["bad", "variabl", "inlin", "closurenon", "closur", "none"], "B_title": "Change on 2010/06/09 by nicksantos", "B_clean_title": ["chang", "2010", "06", "09", "by", "nicksanto"]},
{"A_title": "DownloadLink doesnt wrap the String model used for file name nor does it detachComponent DownloadLink doesnt call method wrap of class Component on parameter fileNameModel. This causes models like StringResourceModel to not resolve resource bundles correctly. See the discussion here: http://stackoverflow.com/questions/12196533/how-to-use-wicket-stringresourcemodel-in-downloadlink  The patch seems quite trivial.   Detachment is also missing.", "A_clean_title": ["downloadlink", "download", "link", "doesnt", "wrap", "string", "model", "use", "file", "name", "nor", "it", "detachcompon", "detach", "compon", "downloadlink", "download", "link", "doesnt", "call", "method", "wrap", "class", "compon", "paramet", "filenamemodel", "file", "name", "model", "thi", "caus", "model", "like", "stringresourcemodel", "string", "resourc", "model", "not", "resolv", "resourc", "bundl", "correctli", "see", "discuss", "here", "http", "use", "wicket", "stringresourcemodel", "downloadlink", "stackoverflow", "com", "question", "12196533", "how", "patch", "seem", "quit", "trivial", "detach", "also", "miss"], "B_title": "fileNameModel wrapOnAssignment and detach", "B_clean_title": ["filenamemodel", "file", "name", "model", "wraponassign", "wrap", "assign", "detach"]},
{"A_title": "Type refining of this raises IllegalArgumentExceptionNone", "A_clean_title": ["type", "refin", "thi", "rais", "illegalargumentexceptionnon", "illeg", "argument", "except", "none"], "B_title": "Handle this properly in the RAI. fixes issue 769", "B_clean_title": ["handl", "thi", "properli", "rai", "fix", "issu", "769"]},
{"A_title": "setResponsePage in AjaxLink goes always to localhost:8080 instead to the right host and portsetResponsePage in an AjaxLink in Wicket 1.4 redirects with a relative path to the response page. Wicket 1.5 takes the absolute path localhost:8080/path to the response page even when the host and port are different. (e.g. with Apache2 a virtual host is created with server name www.mycompany.com setResponce wil go to localhost:8080/path to page instead of  www.mycompany.com/path to page)", "A_clean_title": ["setresponsepag", "set", "respons", "page", "ajaxlink", "ajax", "link", "goe", "alway", "localhost:8080", "instead", "right", "host", "portsetresponsepag", "portset", "respons", "page", "ajaxlink", "ajax", "link", "wicket", "redirect", "rel", "path", "respons", "page", "wicket", "take", "absolut", "path", "localhost:8080", "path", "respons", "page", "even", "when", "host", "port", "are", "differ", "apache2", "virtual", "host", "creat", "server", "name", "www", "mycompani", "com", "setresponc", "set", "responc", "wil", "go", "localhost:8080", "path", "page", "instead", "www", "mycompani", "com", "path", "page"], "B_title": "setResponsePage in AjaxLink goes always to localhost:8080 instead to the right host and port", "B_clean_title": ["setresponsepag", "set", "respons", "page", "ajaxlink", "ajax", "link", "goe", "alway", "localhost:8080", "instead", "right", "host", "port"]},
{"A_title": "MutableHashTable fails when spilling partitions without overflow segmentsWhen one performs a join operation with many and large records then the join operation fails with the following exception when it tries to spill a HashPartition.  code java.lang.RuntimeException: Bug in Hybrid Hash Join: Request to spill a partition with less than two buffers. at org.apache.flink.runtime.operators.hash.HashPartition.spillPartition(HashPartition.java:302) at org.apache.flink.runtime.operators.hash.MutableHashTable.spillPartition(MutableHashTable.java:1108) at org.apache.flink.runtime.operators.hash.MutableHashTable.nextSegment(MutableHashTable.java:1277) at org.apache.flink.runtime.operators.hash.HashPartition BuildSideBuffer.nextSegment(HashPartition.java:524) at org.apache.flink.runtime.memory.AbstractPagedOutputView.advance(AbstractPagedOutputView.java:140) at org.apache.flink.runtime.memory.AbstractPagedOutputView.write(AbstractPagedOutputView.java:201) at org.apache.flink.runtime.memory.AbstractPagedOutputView.write(AbstractPagedOutputView.java:178) at org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.serialize(BytePrimitiveArraySerializer.java:74) at org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.serialize(BytePrimitiveArraySerializer.java:30) at org.apache.flink.runtime.operators.hash.HashPartition.insertIntoBuildBuffer(HashPartition.java:257) at org.apache.flink.runtime.operators.hash.MutableHashTable.insertIntoTable(MutableHashTable.java:856) at org.apache.flink.runtime.operators.hash.MutableHashTable.buildInitialTable(MutableHashTable.java:685) at org.apache.flink.runtime.operators.hash.MutableHashTable.open(MutableHashTable.java:443) at org.apache.flink.runtime.operators.hash.HashTableTest.testSpillingWhenBuildingTableWithoutOverflow(HashTableTest.java:234) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at org.junit.runners.model.FrameworkMethod 1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) at org.junit.runners.ParentRunner 3.run(ParentRunner.java:238) at org.junit.runners.ParentRunner 1.schedule(ParentRunner.java:63) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) at org.junit.runners.ParentRunner.access 000(ParentRunner.java:53) at org.junit.runners.ParentRunner 2.evaluate(ParentRunner.java:229) at org.junit.runners.ParentRunner.run(ParentRunner.java:309) at org.junit.runner.JUnitCore.run(JUnitCore.java:160) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:78) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:212) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140) code  The reason is that the HashPartition does not include the number of used memory segments by the BuildSideBuffer when it counts the currently occupied memory segments.", "A_clean_title": ["mutablehasht", "mutabl", "hash", "tabl", "fail", "when", "spill", "partit", "without", "overflow", "segmentswhen", "segment", "when", "one", "perform", "join", "oper", "mani", "larg", "record", "then", "join", "oper", "fail", "follow", "except", "when", "it", "tri", "spill", "hashpartit", "hash", "partit", "code", "java", "lang", "runtimeexcept", "runtim", "except", "bug", "hybrid", "hash", "join", "request", "spill", "partit", "less", "than", "two", "buffer", "at", "org", "apach", "flink", "runtim", "oper", "hash", "hashpartit", "spillpartit", "hash", "partit", "spill", "partit", "hashpartit", "java:302", "hash", "partit", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "spillpartit", "mutabl", "hash", "tabl", "spill", "partit", "mutablehasht", "java:1108", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "nextseg", "mutabl", "hash", "tabl", "next", "segment", "mutablehasht", "java:1277", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "hashpartit", "hash", "partit", "buildsidebuff", "nextseg", "build", "side", "buffer", "next", "segment", "hashpartit", "java:524", "hash", "partit", "at", "org", "apach", "flink", "runtim", "memori", "abstractpagedoutputview", "advanc", "abstract", "page", "output", "view", "abstractpagedoutputview", "java:140", "abstract", "page", "output", "view", "at", "org", "apach", "flink", "runtim", "memori", "abstractpagedoutputview", "write", "abstract", "page", "output", "view", "abstractpagedoutputview", "java:201", "abstract", "page", "output", "view", "at", "org", "apach", "flink", "runtim", "memori", "abstractpagedoutputview", "write", "abstract", "page", "output", "view", "abstractpagedoutputview", "java:178", "abstract", "page", "output", "view", "at", "org", "apach", "flink", "api", "common", "typeutil", "base", "array", "byteprimitivearrayseri", "serial", "byte", "primit", "array", "serial", "byteprimitivearrayseri", "java:74", "byte", "primit", "array", "serial", "at", "org", "apach", "flink", "api", "common", "typeutil", "base", "array", "byteprimitivearrayseri", "serial", "byte", "primit", "array", "serial", "byteprimitivearrayseri", "java:30", "byte", "primit", "array", "serial", "at", "org", "apach", "flink", "runtim", "oper", "hash", "hashpartit", "insertintobuildbuff", "hash", "partit", "insert", "into", "build", "buffer", "hashpartit", "java:257", "hash", "partit", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "insertintot", "mutabl", "hash", "tabl", "insert", "into", "tabl", "mutablehasht", "java:856", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "buildinitialt", "mutabl", "hash", "tabl", "build", "initi", "tabl", "mutablehasht", "java:685", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "open", "mutabl", "hash", "tabl", "mutablehasht", "java:443", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "hashtabletest", "testspillingwhenbuildingtablewithoutoverflow", "hash", "tabl", "test", "test", "spill", "when", "build", "tabl", "without", "overflow", "hashtabletest", "java:234", "hash", "tabl", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:62", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:43", "deleg", "method", "accessor", "impl", "at", "org", "junit", "runner", "model", "frameworkmethod", "framework", "method", "runreflectivecal", "run", "reflect", "call", "frameworkmethod", "java:47", "framework", "method", "at", "org", "junit", "intern", "runner", "model", "reflectivecal", "run", "reflect", "callabl", "reflectivecal", "java:12", "reflect", "callabl", "at", "org", "junit", "runner", "model", "frameworkmethod", "invokeexplos", "framework", "method", "invok", "explos", "frameworkmethod", "java:44", "framework", "method", "at", "org", "junit", "intern", "runner", "statement", "invokemethod", "evalu", "invok", "method", "invokemethod", "java:17", "invok", "method", "at", "org", "junit", "runner", "parentrunn", "runleaf", "parent", "runner", "run", "leaf", "parentrunn", "java:271", "parent", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:70", "block", "unit4class", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:50", "block", "unit4class", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "run", "parentrunn", "java:238", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "schedul", "parentrunn", "java:63", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "runchildren", "parent", "runner", "run", "children", "parentrunn", "java:236", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "access", "parent", "runner", "000", "parentrunn", "java:53", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "evalu", "parentrunn", "java:229", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "run", "parent", "runner", "parentrunn", "java:309", "parent", "runner", "at", "org", "junit", "runner", "junitcor", "run", "unit", "core", "junitcor", "java:160", "unit", "core", "at", "com", "intellij", "junit4", "junit4ideatestrunn", "startrunnerwitharg", "unit4idea", "test", "runner", "start", "runner", "arg", "junit4ideatestrunn", "java:78", "unit4idea", "test", "runner", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "preparestreamsandstart", "unit", "starter", "prepar", "stream", "start", "junitstart", "java:212", "unit", "starter", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "main", "unit", "starter", "junitstart", "java:68", "unit", "starter", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:62", "nativ", "method", "accessor", "impl", "at", "com", "intellij", "rt", "execut", "applic", "appmain", "main", "app", "main", "appmain", "java:140", "app", "main", "code", "reason", "that", "hashpartit", "hash", "partit", "not", "includ", "number", "use", "memori", "segment", "by", "buildsidebuff", "build", "side", "buffer", "when", "it", "count", "current", "occupi", "memori", "segment"], "B_title": "runtime Fix broken spilling of MutableHashTable", "B_clean_title": ["runtim", "fix", "broken", "spill", "mutablehasht", "mutabl", "hash", "tabl"]},
{"A_title": "Importing an entitytype with several columns with the same name import without errorsHow to Reproduce  Import a datasheet with multiple columns that have the same name.  Expected behavior  An error telling me to only use the name of every attribute once per entitytype  Observed behavior  Everything imports fine and I have issues much later then one would expect.", "A_clean_title": ["import", "entitytyp", "sever", "column", "same", "name", "import", "without", "errorshow", "error", "how", "reproduc", "import", "datasheet", "multipl", "column", "that", "have", "same", "name", "expect", "behavior", "error", "tell", "me", "onli", "use", "name", "everi", "attribut", "onc", "per", "entitytyp", "observ", "behavior", "everyth", "import", "fine", "have", "issu", "much", "later", "then", "one", "would", "expect"], "B_title": "Merge pull request #7277 from dennishendriksen/fix/6906-emxDuplicateColIds  Fix #6906 Duplicate col header exception for CSV and Excel repository", "B_clean_title": ["merg", "pull", "request", "7277", "emxduplicatecolid", "dennishendriksen", "fix", "6906", "emx", "duplic", "col", "id", "fix", "6906", "duplic", "col", "header", "except", "csv", "excel", "repositori"]},
{"A_title": "AppendingStringBuffer.insert  infinite loopWhen trying to insert a StringBuffer into an AppendingStringBuffer the method   public AppendingStringBuffer insert(final int offset final Object obj)  will call itself repeatedly generating an infinite loop.  The fix would be to call toString() method if the object is a StringBuffer   public AppendingStringBuffer insert(final int offset final Object obj)  if (obj instanceof AppendingStringBuffer)  AppendingStringBuffer asb = (AppendingStringBuffer)obj; return insert(offset asb.value 0 asb.count);  else if (obj instanceof StringBuffer)  //return insert(offset obj);                        return insert(offset obj.toString());   return insert(offset String.valueOf(obj));", "A_clean_title": ["appendingstringbuff", "insert", "append", "string", "buffer", "infinit", "loopwhen", "loop", "when", "tri", "insert", "stringbuff", "string", "buffer", "into", "appendingstringbuff", "append", "string", "buffer", "method", "public", "appendingstringbuff", "append", "string", "buffer", "insert", "final", "int", "offset", "final", "object", "obj", "will", "call", "itself", "repeatedli", "gener", "infinit", "loop", "fix", "would", "call", "tostr", "string", "method", "object", "stringbuff", "string", "buffer", "public", "appendingstringbuff", "append", "string", "buffer", "insert", "final", "int", "offset", "final", "object", "obj", "obj", "instanceof", "appendingstringbuff", "append", "string", "buffer", "appendingstringbuff", "append", "string", "buffer", "asb", "appendingstringbuff", "append", "string", "buffer", "obj", "return", "insert", "offset", "asb", "valu", "asb", "count", "obj", "instanceof", "stringbuff", "string", "buffer", "return", "insert", "offset", "obj", "return", "insert", "offset", "obj", "tostr", "string", "return", "insert", "offset", "string", "valueof", "valu", "obj"], "B_title": "", "B_clean_title": []},
{"A_title": "possible NPE exception when class cannot be mocked via PowerMockitoIn version 1.10.5 the catch block needs to guard against a null proxyInstance.", "A_clean_title": ["possibl", "npe", "except", "when", "class", "not", "mock", "via", "powermockitoin", "power", "mockito", "version", "10", "catch", "block", "need", "guard", "against", "null", "proxyinst", "proxi", "instanc"], "B_title": "Fixed issue 98 In order to avoid NPE in some very rare cases.", "B_clean_title": ["fix", "issu", "98", "order", "avoid", "npe", "some", "veri", "rare", "case"]},
{"A_title": "NaN in equals methodsIn MathUtils some equals methods will return true if both argument are NaN. Unless Im mistaken this contradicts the IEEE standard. If nobody objects Im going to make the changes.", "A_clean_title": ["nan", "na", "equal", "methodsin", "method", "mathutil", "math", "util", "some", "equal", "method", "will", "return", "true", "both", "argument", "are", "nan", "na", "unless", "im", "mistaken", "thi", "contradict", "ieee", "standard", "nobodi", "object", "im", "go", "make", "chang"], "B_title": "Removed deprecated methods.", "B_clean_title": ["remov", "deprec", "method"]},
{"A_title": "AjaxFormChoiceComponentUpdatingBehavior affects checkboxes even if component uses radios and vice-versaI have a form with two radio buttons.  Depending which radio the user selects I show one form or another form.  Im using an AjaxFormChoiceComponentUpdatingBehavior attached to the RadioGroup.  One of the forms has a checkbox.  The checkbox triggers an ajax update--even though the AjaxFormChoiceComponentUpdatingBehavior is attached to a RadioGroup.  AjaxFormChoiceComponentUpdatingBehavior should only affect the appropriate controls based on whether it is attached to a choice component that uses radios or checkboxes.  If a developer really wants both then he can use two AjaxFormChoiceComponentUpdatingBehavior instances.  Ive attached a patch.", "A_clean_title": ["ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "affect", "checkbox", "even", "compon", "use", "radio", "vice", "versai", "versa", "have", "form", "two", "radio", "button", "depend", "which", "radio", "user", "select", "show", "one", "form", "or", "anoth", "form", "im", "ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "attach", "radiogroup", "radio", "group", "one", "form", "ha", "checkbox", "checkbox", "trigger", "ajax", "updat", "even", "though", "ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "attach", "radiogroup", "radio", "group", "ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "onli", "affect", "appropri", "control", "base", "whether", "it", "attach", "choic", "compon", "that", "use", "radio", "or", "checkbox", "develop", "realli", "want", "both", "then", "he", "use", "two", "ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "instanc", "ive", "attach", "patch"], "B_title": "", "B_clean_title": []},
{"A_title": "AutoLabelTextResolver fails to pick up locale changes in the sessionWhen using <wicket:label key=...> AutoLabelTextResolver correctly picks up the localized message identified by the key. However if the Session locale is changed neither the printed label nor the FormComponents label model get updated - both will still contain the initial message. This is inconsistent with the behavior of <wicket:message> and StringResourceModel. The principle of least surprise (and in my opinion also that of highest usefulness ;-) ) suggests that AutoLabelTextResolver should dynamically get the localized string whenever it deals with something that can be localized. That includes the <wicket:label key=...> case mentioned above as well as when using FormComponent#getDefaultLabel.  I have only tested this in trunk 1.5 (since it recently came up during a training I gave on Wicket 1.5). I suspect it also affects 1.4.x.", "A_clean_title": ["autolabeltextresolv", "auto", "label", "text", "resolv", "fail", "pick", "up", "local", "chang", "sessionwhen", "session", "when", "wicket", "label", "key=", "autolabeltextresolv", "auto", "label", "text", "resolv", "correctli", "pick", "up", "local", "messag", "identifi", "by", "key", "howev", "session", "local", "chang", "neither", "print", "label", "nor", "formcompon", "form", "compon", "label", "model", "get", "updat", "both", "will", "still", "contain", "initi", "messag", "thi", "inconsist", "behavior", "wicket", "messag", "stringresourcemodel", "string", "resourc", "model", "principl", "least", "surpris", "my", "opinion", "also", "that", "highest", "use", "suggest", "that", "autolabeltextresolv", "auto", "label", "text", "resolv", "dynam", "get", "local", "string", "whenev", "it", "deal", "someth", "that", "local", "that", "includ", "wicket", "label", "key=", "case", "mention", "abov", "as", "well", "as", "when", "formcompon", "form", "compon", "getdefaultlabel", "get", "default", "label", "have", "onli", "test", "thi", "trunk", "sinc", "it", "recent", "came", "up", "dure", "train", "gave", "wicket", "suspect", "it", "also", "affect"], "B_title": "Issue: WICKET-4102", "B_clean_title": ["issu", "wicket", "4102"]},
{"A_title": "FastMath.cosh sinh do not support the same range of values as the Math counterpartsAs reported by Jeff Hain: cosh(double) and sinh(double): Math.cosh(709.783) = 8.991046692770538E307 FastMath.cosh(709.783) = Infinity Math.sinh(709.783) = 8.991046692770538E307 FastMath.sinh(709.783) = Infinity ===> This is due to using exp( x )/2 for values of |x| above 20: the result sometimes should not overflow but exp( x ) does so we end up with some infinity. ===> for values of |x| >= StrictMath.log(Double.MAX_VALUE) exp will overflow so you need to use that instead: for x positive: double t = exp(x*0.5); return (0.5*t)*t; for x negative: double t = exp(-x*0.5); return (-0.5*t)*t;", "A_clean_title": ["fastmath", "cosh", "fast", "math", "sinh", "not", "support", "same", "rang", "valu", "as", "math", "counterpartsa", "counterpart", "as", "report", "by", "jeff", "hain", "cosh", "doubl", "sinh", "doubl", "math", "cosh", "709", "783", "991046692770538e307", "fastmath", "cosh", "fast", "math", "709", "783", "infin", "math", "sinh", "709", "783", "991046692770538e307", "fastmath", "sinh", "fast", "math", "709", "783", "infin", "thi", "due", "exp", "valu", "|x|", "abov", "20", "result", "sometim", "not", "overflow", "but", "exp", "so", "we", "end", "up", "some", "infin", "valu", "|x|", "strictmath", "log", "strict", "math", "doubl", "max", "valu", "exp", "will", "overflow", "so", "you", "need", "use", "that", "instead", "posit", "doubl", "exp", "return", "neg", "doubl", "exp", "return"], "B_title": "Avoid overflow on the whole range covered by the equivalent functions in the standard Math class.", "B_clean_title": ["avoid", "overflow", "whole", "rang", "cover", "by", "equival", "function", "standard", "math", "class"]},
{"A_title": "FixedLengthRecordSorter can not write to output cross MemorySegments.FixedLengthRecordSorter can not write to output cross MemorySegments it works well as its only called to write a single record before. Should fix it and add more unit test.", "A_clean_title": ["fixedlengthrecordsort", "fix", "length", "record", "sorter", "not", "write", "output", "cross", "memoryseg", "fixedlengthrecordsort", "memori", "segment", "fix", "length", "record", "sorter", "not", "write", "output", "cross", "memoryseg", "memori", "segment", "it", "work", "well", "as", "it", "onli", "call", "write", "singl", "record", "befor", "fix", "it", "add", "more", "unit", "test"], "B_title": "Fixed FixedLengthRecordSorter write to multi memory pages issue and add more unit tests.", "B_clean_title": ["fix", "fixedlengthrecordsort", "fix", "length", "record", "sorter", "write", "multi", "memori", "page", "issu", "add", "more", "unit", "test"]},
{"A_title": "EigenDecomposition.Solver should consider tiny values 0 for purposes of determining singularityEigenDecomposition.Solver tests for singularity by comparing eigenvalues to 0 for exact equality. Elsewhere in the class and in the code of course very small values are considered 0. This causes the solver to consider some singular matrices as non-singular.  The patch here includes a test as well showing the behavior -- the matrix is clearly singular but isnt considered as such since one eigenvalue are ~1e-14 rather than exactly 0.  (What I am not sure of is whether we should really be evaluating the *norm* of the imaginary eigenvalues rather than real/imag components separately. But the javadoc says the solver only supports real eigenvalues anyhow so its kind of moot since imag=0 for all eigenvalues.)", "A_clean_title": ["eigendecomposit", "solver", "eigen", "decomposit", "consid", "tini", "valu", "purpos", "determin", "singularityeigendecomposit", "solver", "singular", "eigen", "decomposit", "test", "singular", "by", "compar", "eigenvalu", "exact", "equal", "elsewher", "class", "code", "cours", "veri", "small", "valu", "are", "consid", "thi", "caus", "solver", "consid", "some", "singular", "matric", "as", "non", "singular", "patch", "here", "includ", "test", "as", "well", "show", "behavior", "matrix", "clearli", "singular", "but", "isnt", "consid", "as", "such", "sinc", "one", "eigenvalu", "are", "~1e", "14", "rather", "than", "exactli", "what", "am", "not", "sure", "whether", "we", "realli", "evalu", "norm", "imaginari", "eigenvalu", "rather", "than", "real", "imag", "compon", "separ", "but", "javadoc", "say", "solver", "onli", "support", "real", "eigenvalu", "anyhow", "so", "it", "kind", "moot", "sinc", "imag=0", "all", "eigenvalu"], "B_title": "Loop added to ensure that the largest norm is used in the singularity check. Patch provided by Sean Owen.", "B_clean_title": ["loop", "ad", "ensur", "that", "largest", "norm", "use", "singular", "check", "patch", "provid", "by", "sean", "owen"]},
{"A_title": "Invalid execution graph cleanup for jobs with colocation groupsCurrently upon restarting an execution graph we clean-up the colocation constraints for each group present in an ExecutionJobVertex respectively.  This can lead to invalid reconfiguration upon a restart or any other activity that relies on state cleanup of the execution graph. For example upon restarting a DataStream job with iterations the following steps are executed:  1) IterationSource colgroup constraints are reset 2) IterationSource execution vertices reset and create new colocation constraints 3) IterationSink colgroup constraints are reset 4) IterationSink execution vertices reset and create different colocation constraints.  This can be trivially fixed by reseting colocation groups independently from ExecutionJobVertices thus updating them once per reconfiguration.", "A_clean_title": ["invalid", "execut", "graph", "cleanup", "job", "coloc", "groupscurr", "group", "current", "upon", "restart", "execut", "graph", "we", "clean", "up", "coloc", "constraint", "each", "group", "present", "executionjobvertex", "execut", "job", "vertex", "respect", "thi", "lead", "invalid", "reconfigur", "upon", "restart", "or", "ani", "other", "activ", "that", "reli", "state", "cleanup", "execut", "graph", "exampl", "upon", "restart", "datastream", "data", "stream", "job", "iter", "follow", "step", "are", "execut", "iterationsourc", "iter", "sourc", "colgroup", "constraint", "are", "reset", "iterationsourc", "iter", "sourc", "execut", "vertic", "reset", "creat", "new", "coloc", "constraint", "iterationsink", "iter", "sink", "colgroup", "constraint", "are", "reset", "iterationsink", "iter", "sink", "execut", "vertic", "reset", "creat", "differ", "coloc", "constraint", "thi", "trivial", "fix", "by", "reset", "coloc", "group", "independ", "executionjobvertic", "execut", "job", "vertic", "thu", "updat", "them", "onc", "per", "reconfigur"], "B_title": "Fix colocation group re-instantiation", "B_clean_title": ["fix", "coloc", "group", "re", "instanti"]},
{"A_title": "Allow convenient spying on abstract classes.Mockito is easy to use when the test needs to provide canned values for a certain method. But it gets harder when a canned value isnt sufficient.", "A_clean_title": ["allow", "conveni", "spi", "abstract", "class", "mockito", "easi", "use", "when", "test", "need", "provid", "can", "valu", "certain", "method", "but", "it", "get", "harder", "when", "can", "valu", "isnt", "suffici"], "B_title": "Fixed problem with type testing of outer classes", "B_clean_title": ["fix", "problem", "type", "test", "outer", "class"]},
{"A_title": "HeaderResponse.renderCSSReference does not render context path relative url but wicket filter url-pattern relative urlIn an application with a wicket filter url-pattern different than /* if you use HeaderResponse.renderCSSReference(String url) where url is a context-path-relative url (css/main.css for example) the generated css link is not context relative but wicket url-pattern relative.", "A_clean_title": ["headerrespons", "rendercssrefer", "header", "respons", "render", "css", "refer", "not", "render", "context", "path", "rel", "url", "but", "wicket", "filter", "url", "pattern", "rel", "urlin", "url", "applic", "wicket", "filter", "url", "pattern", "differ", "than", "you", "use", "headerrespons", "rendercssrefer", "header", "respons", "render", "css", "refer", "string", "url", "where", "url", "context", "path", "rel", "url", "css", "css", "main", "exampl", "gener", "css", "link", "not", "context", "rel", "but", "wicket", "url", "pattern", "rel"], "B_title": "Issue: WICKET-4030", "B_clean_title": ["issu", "wicket", "4030"]},
{"A_title": "StackOverflowError after form submit with a validation errorI was not able to find a cause or make a small quickstart but it has something to do with a form validation my workaround was to setDefaultFormProcessing(false) or not use required TextFields.  It can be reproduced on https://github.com/krasa/DevSupportApp/tree/stackOverflow  1) run StartVojtitkoDummy 2) go to http://localhost:8765/wicket/bookmarkable/krasa.release.frontend.TokenizationPage 3) click on Generate Release json button  - instead of SOE it should give a validation error probably even on fields which I would not want to validate but thats just because Ive made the page badly...     code java.lang.StackOverflowError: null ... at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.Component.internalRender(Component.java:2344) at org.apache.wicket.Component.render(Component.java:2307) at org.apache.wicket.ajax.XmlAjaxResponse.writeComponent(XmlAjaxResponse.java:128) at org.apache.wicket.ajax.AbstractAjaxResponse.writeComponents(AbstractAjaxResponse.java:218) at org.apache.wicket.ajax.AbstractAjaxResponse.writeTo(AbstractAjaxResponse.java:150) at org.apache.wicket.ajax.AjaxRequestHandler.respond(AjaxRequestHandler.java:359) at org.apache.wicket.request.cycle.RequestCycle HandlerExecutor.respond(RequestCycle.java:865) at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:64) at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:97) at org.apache.wicket.request.cycle.RequestCycle.execute(RequestCycle.java:265) at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:222) at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:293) at org.apache.wicket.protocol.ws.AbstractUpgradeFilter.processRequestCycle(AbstractUpgradeFilter.java:59) at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:203) at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:284) at org.eclipse.jetty.servlet.ServletHandler CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1125) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1059) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:497) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:248) at org.eclipse.jetty.io.AbstractConnection 2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:620) at org.eclipse.jetty.util.thread.QueuedThreadPool 3.ru code", "A_clean_title": ["stackoverflowerror", "stack", "overflow", "error", "after", "form", "submit", "valid", "errori", "error", "wa", "not", "abl", "find", "caus", "or", "make", "small", "quickstart", "but", "it", "ha", "someth", "form", "valid", "my", "workaround", "wa", "setdefaultformprocess", "set", "default", "form", "process", "fals", "or", "not", "use", "requir", "textfield", "text", "field", "it", "reproduc", "http", "github", "com", "krasa", "devsupportapp", "tree", "stackoverflow", "dev", "support", "app", "stack", "overflow", "run", "startvojtitkodummi", "start", "vojtitko", "dummi", "go", "http", "releas", "frontend", "tokenizationpag", "localhost:8765", "wicket", "bookmark", "krasa", "token", "page", "click", "gener", "releas", "json", "button", "instead", "soe", "it", "give", "valid", "error", "probabl", "even", "field", "which", "would", "not", "want", "valid", "but", "that", "just", "becaus", "ive", "made", "page", "badli", "code", "java", "lang", "stackoverflowerror", "stack", "overflow", "error", "null", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "compon", "internalrend", "intern", "render", "compon", "java:2344", "at", "org", "apach", "wicket", "compon", "render", "compon", "java:2307", "at", "org", "apach", "wicket", "ajax", "xmlajaxrespons", "writecompon", "xml", "ajax", "respons", "write", "compon", "xmlajaxrespons", "java:128", "xml", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "abstractajaxrespons", "writecompon", "abstract", "ajax", "respons", "write", "compon", "abstractajaxrespons", "java:218", "abstract", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "abstractajaxrespons", "writeto", "abstract", "ajax", "respons", "write", "abstractajaxrespons", "java:150", "abstract", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "ajaxrequesthandl", "respond", "ajax", "request", "handler", "ajaxrequesthandl", "java:359", "ajax", "request", "handler", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "request", "cycl", "handlerexecutor", "respond", "handler", "executor", "requestcycl", "java:865", "request", "cycl", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:64", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:97", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "execut", "request", "cycl", "requestcycl", "java:265", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:222", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:293", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "ws", "abstractupgradefilt", "processrequestcycl", "abstract", "upgrad", "filter", "process", "request", "cycl", "abstractupgradefilt", "java:59", "abstract", "upgrad", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:203", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:284", "wicket", "filter", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "servlet", "handler", "cachedchain", "dofilt", "cach", "chain", "filter", "servlethandl", "java:1652", "servlet", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "dohandl", "servlet", "handler", "handl", "servlethandl", "java:585", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:143", "scope", "handler", "at", "org", "eclips", "jetti", "secur", "securityhandl", "handl", "secur", "handler", "securityhandl", "java:577", "secur", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "dohandl", "session", "handler", "handl", "sessionhandl", "java:223", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "dohandl", "context", "handler", "handl", "contexthandl", "java:1125", "context", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "doscop", "servlet", "handler", "scope", "servlethandl", "java:515", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "doscop", "session", "handler", "scope", "sessionhandl", "java:185", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "doscop", "context", "handler", "scope", "contexthandl", "java:1059", "context", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:141", "scope", "handler", "at", "org", "eclips", "jetti", "server", "handler", "handlerwrapp", "handl", "handler", "wrapper", "handlerwrapp", "java:97", "handler", "wrapper", "at", "org", "eclips", "jetti", "server", "server", "handl", "server", "java:497", "at", "org", "eclips", "jetti", "server", "httpchannel", "handl", "http", "channel", "httpchannel", "java:310", "http", "channel", "at", "org", "eclips", "jetti", "server", "httpconnect", "onfil", "http", "connect", "fillabl", "httpconnect", "java:248", "http", "connect", "at", "org", "eclips", "jetti", "io", "abstractconnect", "abstract", "connect", "run", "abstractconnect", "java:540", "abstract", "connect", "at", "org", "eclips", "jetti", "util", "thread", "queuedthreadpool", "runjob", "queu", "thread", "pool", "run", "job", "queuedthreadpool", "java:620", "queu", "thread", "pool", "at", "org", "eclips", "jetti", "util", "thread", "queuedthreadpool", "queu", "thread", "pool", "ru", "code"], "B_title": "method searchMarkupInTransparentResolversrewritten to use container markup fragment", "B_clean_title": ["method", "searchmarkupintransparentresolversrewritten", "search", "markup", "transpar", "resolversrewritten", "use", "contain", "markup", "fragment"]},
{"A_title": "Inconsistent state in Mongo/KernelRootBuilderThe state of Kernel- and MongoRootBuilder may turn inconsistent when a NodeStoreBranch.merge() performs a rebase followed by a failed merge on the underlying storage. The head and base are not properly updated to reflect the successful rebase.", "A_clean_title": ["inconsist", "state", "mongo", "kernelrootbuilderth", "kernel", "root", "builder", "state", "kernel", "mongorootbuild", "mongo", "root", "builder", "may", "turn", "inconsist", "when", "nodestorebranch", "merg", "node", "store", "branch", "perform", "rebas", "follow", "by", "fail", "merg", "underli", "storag", "head", "base", "are", "not", "properli", "updat", "reflect", "success", "rebas"], "B_title": "Inconsistent state in Mongo/KernelRootBuilder", "B_clean_title": ["inconsist", "state", "mongo", "kernelrootbuild", "kernel", "root", "builder"]},
{"A_title": "Date converters should use a new instance of DateFormat to be thread safePlease consider the linked issue WICKET-4833.  I had to open a new issue because I cannot attach the quickstart project Ive prepared to a closed issue.", "A_clean_title": ["date", "convert", "use", "new", "instanc", "dateformat", "date", "format", "thread", "safepleas", "safe", "pleas", "consid", "link", "issu", "wicket", "4833", "had", "open", "new", "issu", "becaus", "not", "attach", "quickstart", "project", "ive", "prepar", "close", "issu"], "B_title": "ConverterLocator should create a new instance for all date based converters", "B_clean_title": ["converterloc", "convert", "locat", "creat", "new", "instanc", "all", "date", "base", "convert"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Fix bug in MinimizeExitPoints with removing breaks inside finally blocks.", "B_clean_title": ["fix", "bug", "minimizeexitpoint", "minim", "exit", "point", "remov", "break", "insid", "final", "block"]},
{"A_title": "Dfp Dfp.multiply(int x) does not comply with the general contract FieldElement.multiply(int n)In class org.apache.commons.math3.Dfp  the method multiply(int n) is limited to 0 <= n <= 9999. This is not consistent with the general contract of FieldElement.multiply(int n) where there should be no limitation on the values of n.", "A_clean_title": ["dfp", "dfp", "multipli", "int", "not", "compli", "gener", "contract", "fieldel", "multipli", "field", "element", "int", "class", "org", "apach", "common", "math3", "dfp", "method", "multipli", "int", "limit", "9999", "thi", "not", "consist", "gener", "contract", "fieldel", "multipli", "field", "element", "int", "where", "there", "no", "limit", "valu"], "B_title": "Allow unlimited input values for Dfp#multiply.", "B_clean_title": ["allow", "unlimit", "input", "valu", "dfp", "multipli"]},
{"A_title": "Paths containing a Windows drive letter cannot be used in FileOutputFormatsPaths that contain a Windows drive letter such as file:///c:/my/directory cannot be used as output path for FileOutputFormat.  If done the following exception is thrown:  code Caused by: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: file:c:         at org.apache.flink.core.fs.Path.initialize(Path.java:242)         at org.apache.flink.core.fs.Path.<init>(Path.java:225)         at org.apache.flink.core.fs.Path.<init>(Path.java:138)         at org.apache.flink.core.fs.local.LocalFileSystem.pathToFile(LocalFileSystem.java:147)         at org.apache.flink.core.fs.local.LocalFileSystem.mkdirs(LocalFileSystem.java:232)         at org.apache.flink.core.fs.local.LocalFileSystem.mkdirs(LocalFileSystem.java:233)         at org.apache.flink.core.fs.local.LocalFileSystem.mkdirs(LocalFileSystem.java:233)         at org.apache.flink.core.fs.local.LocalFileSystem.mkdirs(LocalFileSystem.java:233)         at org.apache.flink.core.fs.local.LocalFileSystem.mkdirs(LocalFileSystem.java:233)         at org.apache.flink.core.fs.FileSystem.initOutPathLocalFS(FileSystem.java:603)         at org.apache.flink.api.common.io.FileOutputFormat.open(FileOutputFormat.java:233)         at org.apache.flink.api.java.io.CsvOutputFormat.open(CsvOutputFormat.java:158)         at org.apache.flink.runtime.operators.DataSinkTask.invoke(DataSinkTask.java:183)         at org.apache.flink.runtime.execution.RuntimeEnvironment.run(RuntimeEnvironment.java:217)         at java.lang.Thread.run(Unknown Source) Caused by: java.net.URISyntaxException: Relative path in absolute URI: file:c:         at java.net.URI.checkPath(Unknown Source)         at java.net.URI.<init>(Unknown Source)         at org.apache.flink.core.fs.Path.initialize(Path.java:240)         ... 14 more code", "A_clean_title": ["path", "contain", "window", "drive", "letter", "not", "use", "fileoutputformatspath", "file", "output", "format", "path", "that", "contain", "window", "drive", "letter", "such", "as", "file", "my", "directori", "not", "use", "as", "output", "path", "fileoutputformat", "file", "output", "format", "done", "follow", "except", "thrown", "code", "caus", "by", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "java", "net", "urisyntaxexcept", "uri", "syntax", "except", "rel", "path", "absolut", "uri", "file", "at", "org", "apach", "flink", "core", "fs", "path", "initi", "path", "java:242", "at", "org", "apach", "flink", "core", "fs", "path", "init", "path", "java:225", "at", "org", "apach", "flink", "core", "fs", "path", "init", "path", "java:138", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "pathtofil", "local", "file", "system", "path", "file", "localfilesystem", "java:147", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "mkdir", "local", "file", "system", "localfilesystem", "java:232", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "mkdir", "local", "file", "system", "localfilesystem", "java:233", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "mkdir", "local", "file", "system", "localfilesystem", "java:233", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "mkdir", "local", "file", "system", "localfilesystem", "java:233", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "mkdir", "local", "file", "system", "localfilesystem", "java:233", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "filesystem", "initoutpathlocalf", "file", "system", "init", "out", "path", "local", "fs", "filesystem", "java:603", "file", "system", "at", "org", "apach", "flink", "api", "common", "io", "fileoutputformat", "open", "file", "output", "format", "fileoutputformat", "java:233", "file", "output", "format", "at", "org", "apach", "flink", "api", "java", "io", "csvoutputformat", "open", "csv", "output", "format", "csvoutputformat", "java:158", "csv", "output", "format", "at", "org", "apach", "flink", "runtim", "oper", "datasinktask", "invok", "data", "sink", "task", "datasinktask", "java:183", "data", "sink", "task", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "run", "runtim", "environ", "runtimeenviron", "java:217", "runtim", "environ", "at", "java", "lang", "thread", "run", "unknown", "sourc", "caus", "by", "java", "net", "urisyntaxexcept", "uri", "syntax", "except", "rel", "path", "absolut", "uri", "file", "at", "java", "net", "uri", "checkpath", "check", "path", "unknown", "sourc", "at", "java", "net", "uri", "init", "unknown", "sourc", "at", "org", "apach", "flink", "core", "fs", "path", "initi", "path", "java:240", "14", "more", "code"], "B_title": "Fix for file paths with Windows drive letters", "B_clean_title": ["fix", "file", "path", "window", "drive", "letter"]},
{"A_title": "NullPointerException in org.apache.wicket.markup.html.form.ValidationErrorFeedbackorg.apache.wicket.markup.html.form.ValidationErrorFeedback throws a NPE in the following situation:  - Form with a TextField<Integer> that has a RangeValidator - value outside range is entered - form is submitted  See attached quickstart.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "org", "apach", "wicket", "markup", "html", "form", "validationerrorfeedbackorg", "apach", "wicket", "markup", "html", "form", "validationerrorfeedback", "valid", "error", "feedbackorg", "valid", "error", "feedback", "throw", "npe", "follow", "situat", "form", "textfield", "text", "field", "integ", "that", "ha", "rangevalid", "rang", "valid", "valu", "outsid", "rang", "enter", "form", "submit", "see", "attach", "quickstart"], "B_title": "NullPointerException in org.apache.wicket.markup.html.form.ValidationErrorFeedback", "B_clean_title": ["nullpointerexcept", "null", "pointer", "except", "org", "apach", "wicket", "markup", "html", "form", "validationerrorfeedback", "valid", "error", "feedback"]},
{"A_title": "bug in Duration.toString(Locale locale)Duration.toString(Locale locale) misses milliseconds in line 529", "A_clean_title": ["bug", "durat", "tostr", "string", "local", "local", "durat", "tostr", "string", "local", "local", "miss", "millisecond", "line", "529"], "B_title": "bug in Duration.toString(Locale locale)", "B_clean_title": ["bug", "durat", "tostr", "string", "local", "local"]},
{"A_title": "ListPopulation Iterator allows you to remove chromosomes from the population.Calling the iterator method of ListPopulation returns an iterator of the protected modifiable list. Before returning the iterator we should wrap it in an unmodifiable list.", "A_clean_title": ["listpopul", "list", "popul", "iter", "allow", "you", "remov", "chromosom", "popul", "call", "iter", "method", "listpopul", "list", "popul", "return", "iter", "protect", "modifi", "list", "befor", "return", "iter", "we", "wrap", "it", "unmodifi", "list"], "B_title": "Fixed iterator() method in ListPopulation to return an iterator of the unmodifiable list thanks to Reid Hochstedler.", "B_clean_title": ["fix", "iter", "method", "listpopul", "list", "popul", "return", "iter", "unmodifi", "list", "thank", "reid", "hochstedl"]},
{"A_title": "o.a.j.o.spi.query.Filter exposes unexported class o.a.j.o.query.ast.SelectorImplThe interface o.a.j.o.spi.query.Filter uses in its public API the class o.a.j.o.query.ast.SelectorImpl but while the former is contained in an exported package the latter is not.", "A_clean_title": ["spi", "queri", "filter", "expos", "unexport", "class", "queri", "ast", "selectorimplth", "selector", "impl", "interfac", "spi", "queri", "filter", "use", "it", "public", "api", "class", "queri", "ast", "selectorimpl", "selector", "impl", "but", "while", "former", "contain", "export", "packag", "latter", "not"], "B_title": "o.a.j.o.spi.query.Filter exposes unexported class o.a.j.o.query.ast.SelectorImpl", "B_clean_title": ["spi", "queri", "filter", "expos", "unexport", "class", "queri", "ast", "selectorimpl", "selector", "impl"]},
{"A_title": "LIRS cache: zero size cache causes IllegalArgumentExceptionThe LIRS cache does not support a zero size cache currently. Such a configuration causes an IllegalArgumentException.  Instead no exception should be thrown and no or a minimum size cache should be used.", "A_clean_title": ["lir", "cach", "zero", "size", "cach", "caus", "illegalargumentexceptionth", "illeg", "argument", "except", "lir", "cach", "not", "support", "zero", "size", "cach", "current", "such", "configur", "caus", "illegalargumentexcept", "illeg", "argument", "except", "instead", "no", "except", "thrown", "no", "or", "minimum", "size", "cach", "use"], "B_title": "LIRS cache: zero size cache causes IllegalArgumentException", "B_clean_title": ["lir", "cach", "zero", "size", "cach", "caus", "illegalargumentexcept", "illeg", "argument", "except"]},
{"A_title": "Document split suppressed with steady load on many cluster nodesDocument split is suppressed when there is a steady write load on many cluster nodes. The document grows bigger over time and leads to poor performance.", "A_clean_title": ["document", "split", "suppress", "steadi", "load", "mani", "cluster", "nodesdocu", "node", "document", "split", "suppress", "when", "there", "steadi", "write", "load", "mani", "cluster", "node", "document", "grow", "bigger", "over", "time", "lead", "poor", "perform"], "B_title": "Document split suppressed with steady load on many cluster nodes", "B_clean_title": ["document", "split", "suppress", "steadi", "load", "mani", "cluster", "node"]},
{"A_title": "Ajax behaviors are failing in stateless pagesStateless ajax behaviors are not working in stateless pages in 1.5-RC4.2. I verified it with the stateless demo project of Martin Grigorov (https://github.com/martin-g/wicket-stateless) when changing the dropdown on the start page an exception is thrown (clicking the increment link causes a similar exception):   org.apache.wicket.behavior.InvalidBehaviorIdException: Cannot find behavior with id: 0 on component: DropDownChoice Component id = c  At first glance the reason may be located in org.apache.wicket.Behaviors.getBehaviorById() which does not create the ID list if missing (getBehaviorsIdList(false) in line 286 instead of getBehaviorsIdList(true)) because this error does not occur when getBehaviorId() was manually called in the page constructor to force creation of the list.", "A_clean_title": ["ajax", "behavior", "are", "fail", "stateless", "pagesstateless", "page", "stateless", "ajax", "behavior", "are", "not", "work", "stateless", "page", "rc4", "verifi", "it", "stateless", "demo", "project", "martin", "grigorov", "http", "stateless", "wicket", "github", "com", "martin", "when", "chang", "dropdown", "start", "page", "except", "thrown", "click", "increment", "link", "caus", "similar", "except", "org", "apach", "wicket", "behavior", "invalidbehavioridexcept", "invalid", "behavior", "id", "except", "not", "find", "behavior", "id", "compon", "dropdownchoic", "drop", "down", "choic", "compon", "id", "at", "first", "glanc", "reason", "may", "locat", "org", "apach", "wicket", "behavior", "getbehaviorbyid", "get", "behavior", "by", "id", "which", "not", "creat", "id", "list", "miss", "getbehaviorsidlist", "get", "behavior", "id", "list", "fals", "line", "286", "instead", "getbehaviorsidlist", "get", "behavior", "id", "list", "true", "becaus", "thi", "error", "not", "occur", "when", "getbehaviorid", "get", "behavior", "id", "wa", "manual", "call", "page", "constructor", "forc", "creation", "list"], "B_title": "Ajax behaviors are failing in stateless pages", "B_clean_title": ["ajax", "behavior", "are", "fail", "stateless", "page"]},
{"A_title": "cGuard protocol decoding issueIve got a pair of cGuard Atom devices  one of the them is 2015 and another one - 2016. Im trying to install and configure the Traccar server (inside Docker) to acquire data from the devices.  Traccar version: 3.10  cGuard Atom fw: 3.2.3 (the latest available) The server successfully detects a new device (2017-04-09 03:06:43  WARN: Unknown device - 35338606530**** (***)) and after a couple of minutes begins to decode gps-data. However the navi data seem to be being decoded incorrectly. All the testing time coordinates are zeroes the datetime mark correspond to Unix epoch time etc.. (see below).   The hex-decoder on the Trackar site correctly decodes HEX-parts of the data:", "A_clean_title": ["cguard", "guard", "protocol", "decod", "issueiv", "issu", "ive", "got", "pair", "cguard", "guard", "atom", "devic", "one", "them", "2015", "anoth", "one", "2016", "im", "tri", "instal", "configur", "traccar", "server", "insid", "docker", "acquir", "data", "devic", "traccar", "version", "10", "cguard", "guard", "atom", "fw", "latest", "avail", "server", "success", "detect", "new", "devic", "2017", "04", "09", "03:06:43", "warn", "unknown", "devic", "35338606530", "after", "coupl", "minut", "begin", "decod", "gp", "data", "howev", "navi", "data", "seem", "be", "decod", "incorrectli", "all", "test", "time", "coordin", "are", "zero", "datetim", "mark", "correspond", "unix", "epoch", "time", "etc", "see", "below", "hex", "decod", "trackar", "site", "correctli", "decod", "hex", "part", "data"], "B_title": "Import cGuard protocol decoder (fix #3080)", "B_clean_title": ["import", "cguard", "guard", "protocol", "decod", "fix", "3080"]},
{"A_title": "OnChangeAjaxBehavior should listen for both inputchange and change events for TextField and TextAreaWICKET-5603 introduced a regression that a TextField using OnChangeAjaxBehavior doesnt work anymore when used as date picker or Select2. The problem is that usually extensions like DatePicker and Select2 will fire change event when they update the text input.  OnChangeAjaxBehavior should use both inputchange and change events for TextField and TextArea components.", "A_clean_title": ["onchangeajaxbehavior", "chang", "ajax", "behavior", "listen", "both", "inputchang", "chang", "event", "textfield", "text", "field", "textareawicket", "5603", "text", "area", "wicket", "introduc", "regress", "that", "textfield", "text", "field", "onchangeajaxbehavior", "chang", "ajax", "behavior", "doesnt", "work", "anymor", "when", "use", "as", "date", "picker", "or", "select2", "problem", "that", "usual", "extens", "like", "datepick", "date", "picker", "select2", "will", "fire", "chang", "event", "when", "they", "updat", "text", "input", "onchangeajaxbehavior", "chang", "ajax", "behavior", "use", "both", "inputchang", "chang", "event", "textfield", "text", "field", "textarea", "text", "area", "compon"], "B_title": "OnChangeAjaxBehavior should listen for both inputchange and change events for TextField and TextArea", "B_clean_title": ["onchangeajaxbehavior", "chang", "ajax", "behavior", "listen", "both", "inputchang", "chang", "event", "textfield", "text", "field", "textarea", "text", "area"]},
{"A_title": "Off-by-one error in FamilyIntersectingIteratorIn the buildDocKey() function within the FamilyIntersectingIterator there is a bug that shortens the docID by 1.  This causes the wrong docs data to be returned in the results of a query using this Iterator.", "A_clean_title": ["off", "by", "one", "error", "familyintersectingiteratorin", "famili", "intersect", "iter", "builddockey", "build", "doc", "key", "function", "within", "familyintersectingiter", "famili", "intersect", "iter", "there", "bug", "that", "shorten", "docid", "doc", "id", "by", "thi", "caus", "wrong", "doc", "data", "return", "result", "queri", "thi", "iter"], "B_title": "merge to trunk", "B_clean_title": ["merg", "trunk"]},
{"A_title": "Errors creating/parsing dates with specific time zones.The results are out of 572 time zones 130 fail and 30 throw exceptions.  The failures are the most interesting. When I query DateTimeZone to get its time zone ids I will get a time zone like America/Atka. When I take that id and create a date time with it its time zone id is America/Adak. It is like there are multiple list of time zones in Joda time and they are out of sync.", "A_clean_title": ["error", "creat", "pars", "date", "specif", "time", "zone", "result", "are", "out", "572", "time", "zone", "130", "fail", "30", "throw", "except", "failur", "are", "most", "interest", "when", "queri", "datetimezon", "date", "time", "zone", "get", "it", "time", "zone", "id", "will", "get", "time", "zone", "like", "america", "atka", "when", "take", "that", "id", "creat", "date", "time", "it", "it", "time", "zone", "id", "america", "adak", "it", "like", "there", "are", "multipl", "list", "time", "zone", "joda", "time", "they", "are", "out", "sync"], "B_title": "Fix zone id parsing for ids like America/Dawson_Creek 3427389", "B_clean_title": ["fix", "zone", "id", "pars", "id", "like", "creek", "america", "dawson", "3427389"]},
{"A_title": "Missing commit hooks in upgradeTheres a TODO in the RepositoryUpgrade class about missing commit hooks. For example the PermissionHook isnt currently run as a part of the upgrade which breaks permission evaluation even though the actual ACL nodes are present after the upgrade.", "A_clean_title": ["miss", "commit", "hook", "upgradether", "upgrad", "there", "todo", "repositoryupgrad", "repositori", "upgrad", "class", "about", "miss", "commit", "hook", "exampl", "permissionhook", "permiss", "hook", "isnt", "current", "run", "as", "part", "upgrad", "which", "break", "permiss", "evalu", "even", "though", "actual", "acl", "node", "are", "present", "after", "upgrad"], "B_title": "Missing commit hooks in upgrade", "B_clean_title": ["miss", "commit", "hook", "upgrad"]},
{"A_title": "SegmentWriter saves references to external blobsThe new SegmentWriteOperation#internalWriteStream method checks whether the input stream to write is a SegmentStream. If its writer will reuse existing block ids rather than storing the whole stream.  It should also check whether the blocks in SegmentStream comes from the same tracker / segment store. Otherwise this will create invalid references if someone invokes the internalWriteStream() method with a SegmentStream created externally.", "A_clean_title": ["segmentwrit", "segment", "writer", "save", "refer", "extern", "blobsth", "blob", "new", "segmentwriteoper", "segment", "write", "oper", "internalwritestream", "intern", "write", "stream", "method", "check", "whether", "input", "stream", "write", "segmentstream", "segment", "stream", "it", "writer", "will", "reus", "exist", "block", "id", "rather", "than", "store", "whole", "stream", "it", "also", "check", "whether", "block", "segmentstream", "segment", "stream", "come", "same", "tracker", "segment", "store", "otherwis", "thi", "will", "creat", "invalid", "refer", "someon", "invok", "internalwritestream", "intern", "write", "stream", "method", "segmentstream", "segment", "stream", "creat", "extern"], "B_title": "SegmentWriter saves references to external blobs", "B_clean_title": ["segmentwrit", "segment", "writer", "save", "refer", "extern", "blob"]},
{"A_title": "Fraction.comparTo returns 0 for some differente fractionsIf two different fractions evaluate to the same double due to limited precision the compareTo methode returns 0 as if they were identical.  // value is roughly PI - 3.07e-18 Fraction pi1 = new Fraction(1068966896 340262731);  // value is roughly PI + 1.936e-17 Fraction pi2 = new Fraction( 411557987 131002976);  System.out.println(pi1.doubleValue() - pi2.doubleValue()); // exactly 0.0 due to limited IEEE754 precision System.out.println(pi1.compareTo(pi2)); // display 0 instead of a negative value", "A_clean_title": ["fraction", "comparto", "compar", "return", "some", "different", "fractionsif", "fraction", "two", "differ", "fraction", "evalu", "same", "doubl", "due", "limit", "precis", "compareto", "compar", "method", "return", "as", "they", "were", "ident", "valu", "roughli", "pi", "18", "07e", "fraction", "pi1", "new", "fraction", "1068966896", "340262731", "valu", "roughli", "pi", "17", "936e", "fraction", "pi2", "new", "fraction", "411557987", "131002976", "system", "out", "println", "pi1", "doublevalu", "doubl", "valu", "pi2", "doublevalu", "doubl", "valu", "exactli", "due", "limit", "ieee754", "precis", "system", "out", "println", "pi1", "compareto", "compar", "pi2", "display", "instead", "neg", "valu"], "B_title": "Fixed a comparison error when two different fractions evaluate to the same double due to limited precision. Jira: MATH-252", "B_clean_title": ["fix", "comparison", "error", "when", "two", "differ", "fraction", "evalu", "same", "doubl", "due", "limit", "precis", "jira", "math", "252"]},
{"A_title": "Incorrect Kendall Tau calc due to data type mistmatchThe Kendall Tau calculation returns a number from -1.0 to 1.0  due to a mixing of ints and longs a mistake occurs on large size columns (arrays) passed to the function. an array size of > 50350 triggers the condition in my case - although it may be data dependent  the ver 3.5 library returns 2.6 as a result (outside of the defined range of Kendall Tau)  with the cast to long below - the result reutns to its expected value   commons.math3.stat.correlation.KendallsCorrelation.correlation   heres the sample code I used: I added the cast to long of swaps in the   int swaps = 1077126315;  final long numPairs = sum(50350 - 1);     long tiedXPairs = 0;         long tiedXYPairs = 0;         long tiedYPairs = 0;            final long concordantMinusDiscordant = numPairs - tiedXPairs - tiedYPairs + tiedXYPairs - 2 * (long) swaps;         final double nonTiedPairsMultiplied = 1.6e18;         double myTest = concordantMinusDiscordant / FastMath.sqrt(nonTiedPairsMultiplied);", "A_clean_title": ["incorrect", "kendal", "tau", "calc", "due", "data", "type", "mistmatchth", "mistmatch", "kendal", "tau", "calcul", "return", "number", "due", "mix", "int", "long", "mistak", "occur", "larg", "size", "column", "array", "pass", "function", "array", "size", "50350", "trigger", "condit", "my", "case", "although", "it", "may", "data", "depend", "ver", "librari", "return", "as", "result", "outsid", "defin", "rang", "kendal", "tau", "cast", "long", "below", "result", "reutn", "it", "expect", "valu", "common", "math3", "stat", "correl", "kendallscorrel", "correl", "kendal", "correl", "here", "sampl", "code", "use", "ad", "cast", "long", "swap", "int", "swap", "1077126315", "final", "long", "numpair", "num", "pair", "sum", "50350", "long", "tiedxpair", "tie", "pair", "long", "tiedxypair", "tie", "xy", "pair", "long", "tiedypair", "tie", "pair", "final", "long", "concordantminusdiscord", "concord", "minu", "discord", "numpair", "num", "pair", "tiedxpair", "tie", "pair", "tiedypair", "tie", "pair", "tiedxypair", "tie", "xy", "pair", "long", "swap", "final", "doubl", "nontiedpairsmultipli", "non", "tie", "pair", "multipli", "6e18", "doubl", "mytest", "my", "test", "concordantminusdiscord", "concord", "minu", "discord", "fastmath", "sqrt", "fast", "math", "nontiedpairsmultipli", "non", "tie", "pair", "multipli"], "B_title": "Fixed incorrect Kendalls tau coefficient calculation due to internal integer overflow. Thanks to Marc Rosen.", "B_clean_title": ["fix", "incorrect", "kendal", "tau", "coeffici", "calcul", "due", "intern", "integ", "overflow", "thank", "marc", "rosen"]},
{"A_title": "XmlPullParser doesnt parse correctly attributes with complex namespaceHaving a markup like: <a class=addthis_button_google_plusone_badge g:plusone:size=smallbadge  g:plusone:href=https://plus.google.com/25252/></a> causes XmlPullParser to throw the following exception:  java.text.ParseException: Same attribute found twice: g:plusone (line 19 column 100)      at org.apache.wicket.markup.parser.XmlPullParser.parseTagText(XmlPullParser.java:673)      at org.apache.wicket.markup.parser.XmlPullParser.next(XmlPullParser.java:294)      at org.apache.wicket.markup.parser.filter.RootMarkupFilter.nextElement(RootMarkupFilter.java:58) .....", "A_clean_title": ["xmlpullpars", "xml", "pull", "parser", "doesnt", "pars", "correctli", "attribut", "complex", "namespacehav", "namespac", "have", "markup", "like", "class=addthi", "button", "googl", "pluson", "badg", "pluson", "size=smallbadg", "pluson", "href=http", "googl", "plu", "com", "25252", "caus", "xmlpullpars", "xml", "pull", "parser", "throw", "follow", "except", "java", "text", "parseexcept", "pars", "except", "same", "attribut", "found", "twice", "pluson", "line", "19", "column", "100", "at", "org", "apach", "wicket", "markup", "parser", "xmlpullpars", "parsetagtext", "xml", "pull", "parser", "pars", "tag", "text", "xmlpullpars", "java:673", "xml", "pull", "parser", "at", "org", "apach", "wicket", "markup", "parser", "xmlpullpars", "next", "xml", "pull", "parser", "xmlpullpars", "java:294", "xml", "pull", "parser", "at", "org", "apach", "wicket", "markup", "parser", "filter", "rootmarkupfilt", "nextel", "root", "markup", "filter", "next", "element", "rootmarkupfilt", "java:58", "root", "markup", "filter"], "B_title": "XmlPullParser doesnt parse correctly attributes with complex namespace", "B_clean_title": ["xmlpullpars", "xml", "pull", "parser", "doesnt", "pars", "correctli", "attribut", "complex", "namespac"]},
{"A_title": "Compiler removes function properties that it should notNone", "A_clean_title": ["compil", "remov", "function", "properti", "that", "it", "notnon", "not", "none"], "B_title": "Turn off collapsing for non-constructor function properties. Fixes issue 289.", "B_clean_title": ["turn", "off", "collaps", "non", "constructor", "function", "properti", "fix", "issu", "289"]},
{"A_title": "Test failure: CompactionMapTest.removeSomeSaid test fails sporadically:  noformat at org.junit.Assert.assertNull(Assert.java:562) at org.apache.jackrabbit.oak.plugins.segment.CompactionMapTest.removeSome(CompactionMapTest.java:156) noformat  This is a regression introduced with OAK-3501: the recent map gets not cleared when segmentIdMap is empty. This can happen when a recent key is removed again while there are no other changes.", "A_clean_title": ["test", "failur", "compactionmaptest", "removesomesaid", "compact", "map", "test", "remov", "some", "said", "test", "fail", "sporad", "noformat", "at", "org", "junit", "assert", "assertnul", "assert", "null", "assert", "java:562", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactionmaptest", "removesom", "compact", "map", "test", "remov", "some", "compactionmaptest", "java:156", "compact", "map", "test", "noformat", "thi", "regress", "introduc", "oak", "3501", "recent", "map", "get", "not", "clear", "when", "segmentidmap", "segment", "id", "map", "empti", "thi", "happen", "when", "recent", "key", "remov", "again", "while", "there", "are", "no", "other", "chang"], "B_title": "Test failure: CompactionMapTest.removeSome Unconditionally clear recent keys on compress", "B_clean_title": ["test", "failur", "compactionmaptest", "removesom", "compact", "map", "test", "remov", "some", "uncondit", "clear", "recent", "key", "compress"]},
{"A_title": "SmartLinkLabel failing to process email with +Using SmartLinkLabel with an email address that includes a + generates a link only on the right-most part of the address.  Example: - my+test@example.com Will generate a link like: - my+<a href=mailto:test@example.com>test@example.com@pappin.ca</a>  THe addition of the + char is a valid email address format.", "A_clean_title": ["smartlinklabel", "smart", "link", "label", "fail", "process", "email", "+use", "smartlinklabel", "smart", "link", "label", "email", "address", "that", "includ", "gener", "link", "onli", "right", "most", "part", "address", "exampl", "my+test", "exampl", "com", "will", "gener", "link", "like", "my+", "href=mailto", "test", "exampl", "com", "test", "exampl", "com", "pappin", "ca", "he", "addit", "char", "valid", "email", "address", "format"], "B_title": "Issue: WICKET-3174", "B_clean_title": ["issu", "wicket", "3174"]},
{"A_title": "FileStore.flush prone to races leading to corruptionThere is a small window in FileStore.flush that could lead to data corruption: if we crash right after setting the persisted head but before any delay-flushed SegmentBufferWriter instance flushes (see SegmentBufferWriterPool.returnWriter()) then that data is lost although it might already be referenced from the persisted head.  We need to come up with a test case for this.   A possible fix would be to return a future from SegmentWriter.flush and rely on a completion callback. Such a change would most likely also be useful for OAK-3690.", "A_clean_title": ["filestor", "flush", "file", "store", "prone", "race", "lead", "corruptionther", "corrupt", "there", "small", "window", "filestor", "flush", "file", "store", "that", "could", "lead", "data", "corrupt", "we", "crash", "right", "after", "set", "persist", "head", "but", "befor", "ani", "delay", "flush", "segmentbufferwrit", "segment", "buffer", "writer", "instanc", "flush", "see", "segmentbufferwriterpool", "returnwrit", "segment", "buffer", "writer", "pool", "return", "writer", "then", "that", "data", "lost", "although", "it", "might", "alreadi", "referenc", "persist", "head", "we", "need", "come", "up", "test", "case", "thi", "possibl", "fix", "would", "return", "futur", "segmentwrit", "flush", "segment", "writer", "reli", "complet", "callback", "such", "chang", "would", "most", "like", "also", "use", "oak", "3690"], "B_title": "FileStore.flush prone to races leading to corruption Make SegmentBufferWriterPool.flush synchrnous again but avoid flusing segments while holding locks", "B_clean_title": ["filestor", "flush", "file", "store", "prone", "race", "lead", "corrupt", "make", "segmentbufferwriterpool", "flush", "segment", "buffer", "writer", "pool", "synchrnou", "again", "but", "avoid", "fluse", "segment", "while", "hold", "lock"]},
{"A_title": "NPE trying to add a node to an nt:folder nodeThe following code throws a NPE:  code Session s = getAdminSession(); s.getRootNode().addNode(a nt:folder).addNode(b); s.save();         code  Stack trace: code java.lang.NullPointerException at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:191) at org.apache.jackrabbit.oak.namepath.LocalNameMapper.getOakNameOrNull(LocalNameMapper.java:82) at org.apache.jackrabbit.oak.namepath.GlobalNameMapper.getOakName(GlobalNameMapper.java:64) at org.apache.jackrabbit.oak.namepath.NamePathMapperImpl.getOakName(NamePathMapperImpl.java:62) at org.apache.jackrabbit.oak.plugins.nodetype.ReadOnlyNodeTypeManager.getOakName(ReadOnlyNodeTypeManager.java:92) at org.apache.jackrabbit.oak.plugins.nodetype.ReadOnlyNodeTypeManager.getNodeType(ReadOnlyNodeTypeManager.java:186) at org.apache.jackrabbit.oak.jcr.NodeImpl 5.perform(NodeImpl.java:265) at org.apache.jackrabbit.oak.jcr.NodeImpl 5.perform(NodeImpl.java:1) at org.apache.jackrabbit.oak.jcr.SessionDelegate.perform(SessionDelegate.java:136) at org.apache.jackrabbit.oak.jcr.NodeImpl.addNode(NodeImpl.java:219) at org.apache.jackrabbit.oak.jcr.NodeImpl.addNode(NodeImpl.java:210) at org.apache.jackrabbit.oak.jcr.CRUDTest.nodeType(CRUDTest.java:122) code", "A_clean_title": ["npe", "tri", "add", "node", "nt", "folder", "nodeth", "node", "follow", "code", "throw", "npe", "code", "session", "getadminsess", "get", "admin", "session", "getrootnod", "get", "root", "node", "addnod", "add", "node", "nt", "folder", "addnod", "add", "node", "save", "code", "stack", "trace", "code", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "com", "googl", "common", "base", "precondit", "checknotnul", "check", "not", "null", "precondit", "java:191", "at", "org", "apach", "jackrabbit", "oak", "namepath", "localnamemapp", "getoaknameornul", "local", "name", "mapper", "get", "oak", "name", "or", "null", "localnamemapp", "java:82", "local", "name", "mapper", "at", "org", "apach", "jackrabbit", "oak", "namepath", "globalnamemapp", "getoaknam", "global", "name", "mapper", "get", "oak", "name", "globalnamemapp", "java:64", "global", "name", "mapper", "at", "org", "apach", "jackrabbit", "oak", "namepath", "namepathmapperimpl", "getoaknam", "name", "path", "mapper", "impl", "get", "oak", "name", "namepathmapperimpl", "java:62", "name", "path", "mapper", "impl", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "readonlynodetypemanag", "getoaknam", "read", "onli", "node", "type", "manag", "get", "oak", "name", "readonlynodetypemanag", "java:92", "read", "onli", "node", "type", "manag", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "readonlynodetypemanag", "getnodetyp", "read", "onli", "node", "type", "manag", "get", "node", "type", "readonlynodetypemanag", "java:186", "read", "onli", "node", "type", "manag", "at", "org", "apach", "jackrabbit", "oak", "jcr", "nodeimpl", "node", "impl", "perform", "nodeimpl", "java:265", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "nodeimpl", "node", "impl", "perform", "nodeimpl", "java:1", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "sessiondeleg", "perform", "session", "deleg", "sessiondeleg", "java:136", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "nodeimpl", "addnod", "node", "impl", "add", "node", "nodeimpl", "java:219", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "nodeimpl", "addnod", "node", "impl", "add", "node", "nodeimpl", "java:210", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "crudtest", "nodetyp", "crud", "test", "node", "type", "crudtest", "java:122", "crud", "test", "code"], "B_title": "NPE trying to add a node to an nt:folder node", "B_clean_title": ["npe", "tri", "add", "node", "nt", "folder", "node"]},
{"A_title": "Verify all methods in the ProxyService that take table names actually throw TableNotFoundException when the table is missing.None", "A_clean_title": ["verifi", "all", "method", "proxyservic", "proxi", "servic", "that", "take", "tabl", "name", "actual", "throw", "tablenotfoundexcept", "tabl", "not", "found", "except", "when", "tabl", "miss", "none"], "B_title": "mode some more methods in proxy throw table not found exception.  cleaned up proxy formatting.  made proxy throw more specific exceptions.", "B_clean_title": ["mode", "some", "more", "method", "proxi", "throw", "tabl", "not", "found", "except", "clean", "up", "proxi", "format", "made", "proxi", "throw", "more", "specif", "except"]},
{"A_title": "DefaultSyncContext.syncMembership may sync group of a foreign IDPWith the following scenario the DefaultSyncContext.syncMembership may end up synchronizing (i.e. updating) a group defined by an foreign IDP and even add the user to be synchronized as a new member:  - configuration with different IDPs - foreign IDP synchronizes a given external group groupA => rep:externalID points to foreign-IDP (e.g. rep:externalId = groupA;foreignIDP) - my-IDP contains a group with the same ID (but obviously with a different rep:externalID) and user that has declared group membership pointing to groupA from my IDP  if synchronizing my user first the groupA will be created with a rep:externalId = groupA;myIDP. however if the group has been synced before by the foreignIDP the code fails to verify that an existing group groupA really belongs to the same IDP and thus may end up synchronizing the group and updating its members.  IMHO thats a critical issue as it violates the IDP boundaries. the fix is pretty trivial as it only requires testing for the IDP of the existing group as we do it in other places (even in the same method).", "A_clean_title": ["defaultsynccontext", "syncmembership", "default", "sync", "context", "sync", "membership", "may", "sync", "group", "foreign", "idpwith", "idp", "follow", "scenario", "defaultsynccontext", "syncmembership", "default", "sync", "context", "sync", "membership", "may", "end", "up", "synchron", "updat", "group", "defin", "by", "foreign", "idp", "even", "add", "user", "synchron", "as", "new", "member", "configur", "differ", "idp", "id", "ps", "foreign", "idp", "synchron", "given", "extern", "group", "groupa", "group", "rep", "externalid", "extern", "id", "point", "foreign", "idp", "rep", "externalid", "extern", "id", "groupa", "group", "foreignidp", "foreign", "idp", "my", "idp", "contain", "group", "same", "id", "but", "obvious", "differ", "rep", "externalid", "extern", "id", "user", "that", "ha", "declar", "group", "membership", "point", "groupa", "group", "my", "idp", "synchron", "my", "user", "first", "groupa", "group", "will", "creat", "rep", "externalid", "extern", "id", "groupa", "group", "myidp", "my", "idp", "howev", "group", "ha", "been", "sync", "befor", "by", "foreignidp", "foreign", "idp", "code", "fail", "verifi", "that", "exist", "group", "groupa", "group", "realli", "belong", "same", "idp", "thu", "may", "end", "up", "synchron", "group", "updat", "it", "member", "imho", "that", "critic", "issu", "as", "it", "violat", "idp", "boundari", "fix", "pretti", "trivial", "as", "it", "onli", "requir", "test", "idp", "exist", "group", "as", "we", "it", "other", "place", "even", "same", "method"], "B_title": ": DefaultSyncContext.syncMembership may sync group of a foreign IDP", "B_clean_title": ["defaultsynccontext", "syncmembership", "default", "sync", "context", "sync", "membership", "may", "sync", "group", "foreign", "idp"]},
{"A_title": "Division by zeroIn class Complex division by zero always returns NaN. I think that it should return NaN only when the numerator is also ZERO otherwise the result should be INF. See here|http://en.wikipedia.org/wiki/Riemann_sphere#Arithmetic_operations.", "A_clean_title": ["divis", "by", "zeroin", "zero", "class", "complex", "divis", "by", "zero", "alway", "return", "nan", "na", "think", "that", "it", "return", "nan", "na", "onli", "when", "numer", "also", "zero", "otherwis", "result", "inf", "see", "here|http", "wikipedia", "en", "sphere", "org", "wiki", "riemann", "arithmet", "oper"], "B_title": "Reverting to previous behaviour as requested by P. Steitz.", "B_clean_title": ["revert", "previou", "behaviour", "as", "request", "by", "steitz"]},
{"A_title": "SimpleTree example not working with CryptoMapperAdding the following lines to WicketExampleApplication.java causes the SimpleTree example to break. There are no expand icons anymore and there is no way to expand the tree. Even the expand link will not work.  Add to WicketExampleApplication.java   IRequestMapper cryptoMapper = new CryptoMapper(getRootRequestMapper() this); setRootRequestMapper(cryptoMapper);   Comment out in WicketExampleApplication.java   //getSecuritySettings().setCryptFactory(new ClassCryptFactory(NoCrypt.class ISecuritySettings.DEFAULT_ENCRYPTION_KEY));  Without the CryptoMapper everythings works fine.", "A_clean_title": ["simpletre", "simpl", "tree", "exampl", "not", "work", "cryptomapperad", "crypto", "mapper", "ad", "follow", "line", "wicketexampleappl", "java", "wicket", "exampl", "applic", "caus", "simpletre", "simpl", "tree", "exampl", "break", "there", "are", "no", "expand", "icon", "anymor", "there", "no", "way", "expand", "tree", "even", "expand", "link", "will", "not", "work", "add", "wicketexampleappl", "java", "wicket", "exampl", "applic", "irequestmapp", "request", "mapper", "cryptomapp", "crypto", "mapper", "new", "cryptomapp", "crypto", "mapper", "getrootrequestmapp", "get", "root", "request", "mapper", "thi", "setrootrequestmapp", "set", "root", "request", "mapper", "cryptomapp", "crypto", "mapper", "comment", "out", "wicketexampleappl", "java", "wicket", "exampl", "applic", "getsecurityset", "get", "secur", "set", "setcryptfactori", "set", "crypt", "factori", "new", "classcryptfactori", "class", "crypt", "factori", "nocrypt", "class", "no", "crypt", "isecurityset", "secur", "set", "default", "encrypt", "key", "without", "cryptomapp", "crypto", "mapper", "everyth", "work", "fine"], "B_title": "SimpleTree example not working with CryptoMapper", "B_clean_title": ["simpletre", "simpl", "tree", "exampl", "not", "work", "cryptomapp", "crypto", "mapper"]},
{"A_title": "Select component loses its valueSelect component loses selected option and shows the first option in some situations (one example is when you try to submit a form but there are validation errors).  It was working fine in 1.4.18 but its broken in 1.4.19.This must be caused by the solution from this issue https://issues.apache.org/jira/browse/WICKET-3962 I think the problem is likely in Select.isSelected method where String paths = getInputAsArray() is actually an array of uuid-s so uuid-s are compared to paths.  I havent tested wicket 1.5 but this problem may also affect 1.5 versions.", "A_clean_title": ["select", "compon", "lose", "it", "valueselect", "valu", "select", "compon", "lose", "select", "option", "show", "first", "option", "some", "situat", "one", "exampl", "when", "you", "tri", "submit", "form", "but", "there", "are", "valid", "error", "it", "wa", "work", "fine", "18", "but", "it", "broken", "19", "thi", "must", "caus", "by", "solut", "thi", "issu", "http", "3962", "apach", "issu", "org", "jira", "brows", "wicket", "think", "problem", "like", "select", "isselect", "select", "method", "where", "string", "path", "getinputasarray", "get", "input", "as", "array", "actual", "array", "uuid", "so", "uuid", "are", "compar", "path", "havent", "test", "wicket", "but", "thi", "problem", "may", "also", "affect", "version"], "B_title": "Select keep selection on form error", "B_clean_title": ["select", "keep", "select", "form", "error"]},
{"A_title": "XPath query failures for mvpsAdding some cases related to mvps that are not currently covered by the existing (jackrabbit) tests.", "A_clean_title": ["xpath", "path", "queri", "failur", "mvpsad", "mvp", "ad", "some", "case", "relat", "mvp", "that", "are", "not", "current", "cover", "by", "exist", "jackrabbit", "test"], "B_title": "XPath query failures for mvps", "B_clean_title": ["xpath", "path", "queri", "failur", "mvp"]},
{"A_title": "AjaxFormChoiceComponentUpdatingBehavior fails for choices containing other invalid FormComponentsIf a TextField inside a RadioGroup has a ValidationError processing of AjaxFormChoiceComponentUpdatingBehavior will erroneously update the groups model:  - RadioGroup#validate() does not convert the input because #isValid() returns false (since the nested textfield has an error message) - the behavior tests #hasErrorMessage() on the group which returns false (since the group itself doesnt have an error message) - the behavior continues processing with a null value", "A_clean_title": ["ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "fail", "choic", "contain", "other", "invalid", "formcomponentsif", "form", "compon", "textfield", "text", "field", "insid", "radiogroup", "radio", "group", "ha", "validationerror", "valid", "error", "process", "ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "will", "erron", "updat", "group", "model", "radiogroup", "radio", "group", "valid", "not", "convert", "input", "becaus", "isvalid", "valid", "return", "fals", "sinc", "nest", "textfield", "ha", "error", "messag", "behavior", "test", "haserrormessag", "ha", "error", "messag", "group", "which", "return", "fals", "sinc", "group", "itself", "doesnt", "have", "error", "messag", "behavior", "continu", "process", "null", "valu"], "B_title": "use #isValid() instead of #hasErrorMessage() as the FormComponent does too", "B_clean_title": ["use", "isvalid", "valid", "instead", "haserrormessag", "ha", "error", "messag", "as", "formcompon", "form", "compon", "too"]},
{"A_title": "Wrong code generated if mixing types in ternary operatorNone", "A_clean_title": ["wrong", "code", "gener", "mix", "type", "ternari", "operatornon", "oper", "none"], "B_title": "Properly determine if any possible results may be a string. Fixes issue 821", "B_clean_title": ["properli", "determin", "ani", "possibl", "result", "may", "string", "fix", "issu", "821"]},
{"A_title": "Problem with setting of IComponentInheritedModel and FLAG_INHERITABLE_MODELDescribed in the mailing list: http://mail-archives.apache.org/mod_mbox/wicket-users/201407.mbox/%3CCAF2_608c8TOZjprV8Md15KJpRET6YQdXHe%3DwRzF-y5G_zAXcDg%40mail.gmail.com%3E  Im aware of the another issue (https://issues.apache.org/jira/browse/WICKET-3413) which dealt with the exact same code - and I believe there was a mistake in the solution that leads to this issue.  Please see the attached quickstart (including a JUnit test) to reproduce the error.", "A_clean_title": ["problem", "set", "icomponentinheritedmodel", "compon", "inherit", "model", "flag", "inherit", "modeldescrib", "model", "describ", "mail", "list", "http", "mail", "archiv", "apach", "user", "201407", "mbox", "org", "mod", "mbox", "wicket", "3ccaf2", "608c8tozjprv8md15kjpret6yqdxh", "608c8to", "zjpr", "v8md15k", "jp", "ret6i", "qd", "he", "3dwrzf", "3dw", "rz", "y5g", "zaxcdg", "xc", "dg", "40mail", "gmail", "com", "3e", "im", "awar", "anoth", "issu", "http", "3413", "apach", "issu", "org", "jira", "brows", "wicket", "which", "dealt", "exact", "same", "code", "believ", "there", "wa", "mistak", "solut", "that", "lead", "thi", "issu", "pleas", "see", "attach", "quickstart", "includ", "junit", "unit", "test", "reproduc", "error"], "B_title": "clear FLAG_INHERITABLE_MODEL reliably", "B_clean_title": ["clear", "flag", "inherit", "model", "reliabl"]},
{"A_title": "MutableTree#isNew: replace implementation by NodeBuilder#isNewSimilar to the issue described in OAK-1177 we may consider replacing the implementation of MutableTree#isNew by the corresponding call on the NodeBuilder.  See also OAK-947.", "A_clean_title": ["mutabletre", "mutabl", "tree", "isnew", "new", "replac", "implement", "by", "nodebuild", "node", "builder", "isnewsimilar", "new", "similar", "issu", "describ", "oak", "1177", "we", "may", "consid", "replac", "implement", "mutabletre", "mutabl", "tree", "isnew", "new", "by", "correspond", "call", "nodebuild", "node", "builder", "see", "also", "oak", "947"], "B_title": "MutableTree#isNew: replace implementation by NodeBuilder#isNew - Rebasing should correctly set the base state of the KernelNodeBuilder and the MongoNodeBuilder - MongoNodeBuilder needs to calculate its base state instead of relying on that of the MemoryNodeBuilder backing it", "B_clean_title": ["mutabletre", "mutabl", "tree", "isnew", "new", "replac", "implement", "by", "nodebuild", "node", "builder", "isnew", "new", "rebas", "correctli", "set", "base", "state", "kernelnodebuild", "kernel", "node", "builder", "mongonodebuild", "mongo", "node", "builder", "mongonodebuild", "mongo", "node", "builder", "need", "calcul", "it", "base", "state", "instead", "reli", "that", "memorynodebuild", "memori", "node", "builder", "back", "it"]},
{"A_title": "CompilerException caused by NullPointerExceptionRun into it during working on my code. Seems not caused by my plan or anyway the compiler should have a NullPointer isssue:  org.apache.flink.compiler.CompilerException: An error occurred while translating the optimized plan to a nephele JobGraph: Error translating node Union Union : UNION  GlobalProperties partitioning=HASH_PARTITIONED on fields 0   LocalProperties ordering=null grouped=null unique=null : null at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.postVisit(NepheleJobGraphGenerator.java:543) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.postVisit(NepheleJobGraphGenerator.java:95) at org.apache.flink.compiler.plan.DualInputPlanNode.accept(DualInputPlanNode.java:170) at org.apache.flink.compiler.plan.SingleInputPlanNode.accept(SingleInputPlanNode.java:196) at org.apache.flink.compiler.plan.SingleInputPlanNode.accept(SingleInputPlanNode.java:196) at org.apache.flink.compiler.plan.OptimizedPlan.accept(OptimizedPlan.java:165) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.compileJobGraph(NepheleJobGraphGenerator.java:163) at org.apache.flink.client.program.Client.getJobGraph(Client.java:218) at org.apache.flink.client.program.Client.run(Client.java:290) at org.apache.flink.client.program.Client.run(Client.java:285) at org.apache.flink.client.program.Client.run(Client.java:230) at org.apache.flink.client.CliFrontend.executeProgram(CliFrontend.java:347) at org.apache.flink.client.CliFrontend.run(CliFrontend.java:334) at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:1001) at org.apache.flink.client.CliFrontend.main(CliFrontend.java:1025) Caused by: org.apache.flink.compiler.CompilerException: Error translating node Union Union : UNION  GlobalProperties partitioning=HASH_PARTITIONED on fields 0   LocalProperties ordering=null grouped=null unique=null : null at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.preVisit(NepheleJobGraphGenerator.java:338) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.preVisit(NepheleJobGraphGenerator.java:95) at org.apache.flink.compiler.plan.DualInputPlanNode.accept(DualInputPlanNode.java:162) at org.apache.flink.compiler.plan.WorksetIterationPlanNode.acceptForStepFunction(WorksetIterationPlanNode.java:196) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.postVisit(NepheleJobGraphGenerator.java:398) ... 14 more Caused by: java.lang.NullPointerException at org.apache.flink.runtime.operators.util.TaskConfig.setDriver(TaskConfig.java:307) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.createDualInputVertex(NepheleJobGraphGenerator.java:793) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.preVisit(NepheleJobGraphGenerator.java:286) ... 18 more", "A_clean_title": ["compilerexcept", "compil", "except", "caus", "by", "nullpointerexceptionrun", "null", "pointer", "except", "run", "into", "it", "dure", "work", "my", "code", "seem", "not", "caus", "by", "my", "plan", "or", "anyway", "compil", "have", "nullpoint", "null", "pointer", "isssu", "org", "apach", "flink", "compil", "compilerexcept", "compil", "except", "error", "occur", "while", "translat", "optim", "plan", "nephel", "jobgraph", "job", "graph", "error", "translat", "node", "union", "union", "union", "globalproperti", "global", "properti", "partitioning=hash", "partit", "field", "localproperti", "local", "properti", "ordering=nul", "grouped=nul", "unique=nul", "null", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "postvisit", "nephel", "job", "graph", "gener", "post", "visit", "nephelejobgraphgener", "java:543", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "postvisit", "nephel", "job", "graph", "gener", "post", "visit", "nephelejobgraphgener", "java:95", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "compil", "plan", "dualinputplannod", "accept", "dual", "input", "plan", "node", "dualinputplannod", "java:170", "dual", "input", "plan", "node", "at", "org", "apach", "flink", "compil", "plan", "singleinputplannod", "accept", "singl", "input", "plan", "node", "singleinputplannod", "java:196", "singl", "input", "plan", "node", "at", "org", "apach", "flink", "compil", "plan", "singleinputplannod", "accept", "singl", "input", "plan", "node", "singleinputplannod", "java:196", "singl", "input", "plan", "node", "at", "org", "apach", "flink", "compil", "plan", "optimizedplan", "accept", "optim", "plan", "optimizedplan", "java:165", "optim", "plan", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "compilejobgraph", "nephel", "job", "graph", "gener", "compil", "job", "graph", "nephelejobgraphgener", "java:163", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "client", "program", "client", "getjobgraph", "get", "job", "graph", "client", "java:218", "at", "org", "apach", "flink", "client", "program", "client", "run", "client", "java:290", "at", "org", "apach", "flink", "client", "program", "client", "run", "client", "java:285", "at", "org", "apach", "flink", "client", "program", "client", "run", "client", "java:230", "at", "org", "apach", "flink", "client", "clifrontend", "executeprogram", "cli", "frontend", "execut", "program", "clifrontend", "java:347", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "run", "cli", "frontend", "clifrontend", "java:334", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "parseparamet", "cli", "frontend", "pars", "paramet", "clifrontend", "java:1001", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "main", "cli", "frontend", "clifrontend", "java:1025", "cli", "frontend", "caus", "by", "org", "apach", "flink", "compil", "compilerexcept", "compil", "except", "error", "translat", "node", "union", "union", "union", "globalproperti", "global", "properti", "partitioning=hash", "partit", "field", "localproperti", "local", "properti", "ordering=nul", "grouped=nul", "unique=nul", "null", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "previsit", "nephel", "job", "graph", "gener", "pre", "visit", "nephelejobgraphgener", "java:338", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "previsit", "nephel", "job", "graph", "gener", "pre", "visit", "nephelejobgraphgener", "java:95", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "compil", "plan", "dualinputplannod", "accept", "dual", "input", "plan", "node", "dualinputplannod", "java:162", "dual", "input", "plan", "node", "at", "org", "apach", "flink", "compil", "plan", "worksetiterationplannod", "acceptforstepfunct", "workset", "iter", "plan", "node", "accept", "step", "function", "worksetiterationplannod", "java:196", "workset", "iter", "plan", "node", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "postvisit", "nephel", "job", "graph", "gener", "post", "visit", "nephelejobgraphgener", "java:398", "nephel", "job", "graph", "gener", "14", "more", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "flink", "runtim", "oper", "util", "taskconfig", "setdriv", "task", "config", "set", "driver", "taskconfig", "java:307", "task", "config", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "createdualinputvertex", "nephel", "job", "graph", "gener", "creat", "dual", "input", "vertex", "nephelejobgraphgener", "java:793", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "previsit", "nephel", "job", "graph", "gener", "pre", "visit", "nephelejobgraphgener", "java:286", "nephel", "job", "graph", "gener", "18", "more"], "B_title": "Handle unions at the root of the iteration", "B_clean_title": ["handl", "union", "at", "root", "iter"]},
{"A_title": "Compiler gives false error with respect to unreachable codeNone", "A_clean_title": ["compil", "give", "fals", "error", "respect", "unreach", "codenon", "code", "none"], "B_title": "Make the CFA recognize possible ON_EX edges for instanceof operations. Fixes issue 113. (Alan)", "B_clean_title": ["make", "cfa", "recogn", "possibl", "ex", "edg", "instanceof", "oper", "fix", "issu", "113", "alan"]},
{"A_title": "EigenDecomposition fails for certain matricesThe Schurtransformation of the following matrix fails which is a preliminary step for the Eigendecomposition:  RealMatrix m = MatrixUtils.DEFAULT_FORMAT.parse(0.184944928-0.06469710460.0774755812-0.0969651755-0.06926488060.3282344352-0.01774230740.206313634-0.0742700134-0.028906303-0.001726946-0.0375550146-0.0487737922-0.2616837868-0.0821201295-0.25300001670.25499101270.0995733692-0.00097183880.01492828080.1791878897-0.08231828160.05826292560.3219545182-0.0694747557-0.1880649148-0.27406309110.0720096468-0.1800836914-0.35189964250.24867478330.62579381670.0536360918-0.13392977780.2241579764-0.0195327484-0.00541038080.03475645180.5120802482-0.0329902864-0.5933332356-0.24887210820.23571736290.01772854730.0856630593-0.35671263-0.1600668126-0.1010899621-0.0514349819-0.08543194350.11250500610.006345356-0.2250000688-0.2209343090.1964623477-0.15123299240.0197395947-0.1997170581-0.1425959019-0.274947791-0.09694670730.060368852-0.28269051920.1794315473);", "A_clean_title": ["eigendecomposit", "eigen", "decomposit", "fail", "certain", "matricesth", "matric", "schurtransform", "follow", "matrix", "fail", "which", "preliminari", "step", "eigendecomposit", "realmatrix", "real", "matrix", "matrixutil", "pars", "matrix", "util", "default", "format", "184944928", "06469710460", "0774755812", "0969651755", "06926488060", "3282344352", "01774230740", "206313634", "0742700134", "028906303", "001726946", "0375550146", "0487737922", "2616837868", "0821201295", "25300001670", "25499101270", "0995733692", "00097183880", "01492828080", "1791878897", "08231828160", "05826292560", "3219545182", "0694747557", "1880649148", "27406309110", "0720096468", "1800836914", "35189964250", "24867478330", "62579381670", "0536360918", "13392977780", "2241579764", "0195327484", "00541038080", "03475645180", "5120802482", "0329902864", "5933332356", "24887210820", "23571736290", "01772854730", "0856630593", "35671263", "1600668126", "1010899621", "0514349819", "08543194350", "11250500610", "006345356", "2250000688", "2209343090", "1964623477", "15123299240", "0197395947", "1997170581", "1425959019", "274947791", "09694670730", "060368852", "28269051920", "1794315473"], "B_title": "Fixed Schur transformation for certain input matrices changed index parameter names to indicate their purpose.", "B_clean_title": ["fix", "schur", "transform", "certain", "input", "matric", "chang", "index", "paramet", "name", "indic", "their", "purpos"]},
{"A_title": "Unexpected expression nodeDELPROP 1None", "A_clean_title": ["unexpect", "express", "nodedelprop", "node", "delprop", "1none"], "B_title": "delete operator with a boolean result. Fixes issue 364", "B_clean_title": ["delet", "oper", "boolean", "result", "fix", "issu", "364"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Nerf direct function inlining when the function be inlined has side-effects and the call arguments can be effected. Fixes issue 1101 ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=53511956", "B_clean_title": ["nerf", "direct", "function", "inlin", "when", "function", "inlin", "ha", "side", "effect", "call", "argument", "effect", "fix", "issu", "1101", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=53511956"]},
{"A_title": "Obfuscated code triggers TypeError in FirefoxNone", "A_clean_title": ["obfusc", "code", "trigger", "typeerror", "type", "error", "firefoxnon", "firefox", "none"], "B_title": "Dont collapse assignments into var declarations if it would cause a redeclarion of a named parameter.", "B_clean_title": ["dont", "collaps", "assign", "into", "var", "declar", "it", "would", "caus", "redeclarion", "name", "paramet"]},
{"A_title": "Condition check broken in MemoryDocumentStoreThe Operation.CONTAINS_MAP_ENTRY condition check does not work correctly in the MemoryDocumentStore and may return false even when the condition is not met.", "A_clean_title": ["condit", "check", "broken", "memorydocumentstoreth", "memori", "document", "store", "oper", "contain", "map", "entri", "condit", "check", "not", "work", "correctli", "memorydocumentstor", "memori", "document", "store", "may", "return", "fals", "even", "when", "condit", "not", "met"], "B_title": "Condition check broken in MemoryDocumentStore", "B_clean_title": ["condit", "check", "broken", "memorydocumentstor", "memori", "document", "store"]},
{"A_title": "class Dfp toDouble method return -inf whan Dfp value is 0 zeroI found a bug in the toDouble() method of the Dfp class. If the Dfps value is 0 zero the toDouble() method returns a  negative infini. This is because the double value returned has an exposant equal to 0xFFF  and a significand is equal to 0. In the IEEE754 this is a -inf. To be equal to zero the exposant and the significand must be equal to zero. A simple test case is : ---------------------------------------------- import org.apache.commons.math.dfp.DfpField; public class test  /**  @param args  */ public static void main(String args)   DfpField field = new DfpField(100); System.out.println(toDouble value of getZero() =+field.getZero().toDouble()+ ntoDouble value of newDfp(0.0) =+ field.newDfp(0.0).toDouble());    May be the simplest way to fix it is to test the zero equality at the begin of the toDouble() method to be able to return the correctly signed zero ?", "A_clean_title": ["class", "dfp", "todoubl", "doubl", "method", "return", "inf", "whan", "dfp", "valu", "zeroi", "zero", "found", "bug", "todoubl", "doubl", "method", "dfp", "class", "dfp", "valu", "zero", "todoubl", "doubl", "method", "return", "neg", "infini", "thi", "becaus", "doubl", "valu", "return", "ha", "expos", "equal", "0xfff", "0x", "fff", "significand", "equal", "ieee754", "thi", "inf", "equal", "zero", "expos", "significand", "must", "equal", "zero", "simpl", "test", "case", "import", "org", "apach", "common", "math", "dfp", "dfpfield", "dfp", "field", "public", "class", "test", "param", "arg", "public", "static", "void", "main", "string", "arg", "dfpfield", "dfp", "field", "field", "new", "dfpfield", "dfp", "field", "100", "system", "out", "println", "todoubl", "doubl", "valu", "getzero", "get", "zero", "=+field", "getzero", "get", "zero", "todoubl", "doubl", "ntodoubl", "nto", "doubl", "valu", "newdfp", "new", "dfp", "field", "newdfp", "new", "dfp", "todoubl", "doubl", "may", "simplest", "way", "fix", "it", "test", "zero", "equal", "at", "begin", "todoubl", "doubl", "method", "abl", "return", "correctli", "sign", "zero"], "B_title": "Fixed conversion problems to/from 0 in Decimal Floating Point (Dfp) class.", "B_clean_title": ["fix", "convers", "problem", "decim", "float", "point", "dfp", "class"]},
{"A_title": "PolyhedronsSet.firstIntersection(Vector3D point Line line) sometimes reports intersections on wrong end of lineI constructed a PolyhedronsSet from a list of triangular faces representing an icosphere (using the instructions found at https://mail-archives.apache.org/mod_mbox/commons-user/201208.mbox/<5039FE35.2090307@free.fr>).  This seems to produce correct INSIDE/OUTSIDE results for randomly chosen points.  I think my mesh triangles are defined appropriately.  However using PolyhedronsSet.firstIntersection(Vector3D point Line line) to shoot randomly oriented rays from the origin sometimes gives a wrong mesh intersection point behind the origin.  The intersection algorithm is sometimes picking up faces of the sphere-shaped mesh on the wrong semi-infinite portion of the line i.e. meshIntersectionPoint.subtract(point).dotProduct(line.getDirection())<0 where point is the Vector3D at center of the sphere and line extends outward through the mesh.  I think the dot product above should always be positive. If multiple intersections exist along a whole line then the first one in front of the lines origin should be returned. This makes ray tracing with a PolyhedronsSet possible.", "A_clean_title": ["polyhedronsset", "firstintersect", "polyhedron", "set", "first", "intersect", "vector3d", "point", "line", "line", "sometim", "report", "intersect", "wrong", "end", "linei", "line", "construct", "polyhedronsset", "polyhedron", "set", "list", "triangular", "face", "repres", "icospher", "instruct", "found", "at", "http", "mail", "archiv", "apach", "user", "201208", "mbox", "org", "mod", "mbox", "common", "5039fe35", "2090307", "free", "fr", "thi", "seem", "produc", "correct", "insid", "outsid", "result", "randomli", "chosen", "point", "think", "my", "mesh", "triangl", "are", "defin", "appropri", "howev", "polyhedronsset", "firstintersect", "polyhedron", "set", "first", "intersect", "vector3d", "point", "line", "line", "shoot", "randomli", "orient", "ray", "origin", "sometim", "give", "wrong", "mesh", "intersect", "point", "behind", "origin", "intersect", "algorithm", "sometim", "pick", "up", "face", "sphere", "shape", "mesh", "wrong", "semi", "infinit", "portion", "line", "meshintersectionpoint", "subtract", "mesh", "intersect", "point", "point", "dotproduct", "dot", "product", "line", "getdirect", "get", "direct", "where", "point", "vector3d", "at", "center", "sphere", "line", "extend", "outward", "through", "mesh", "think", "dot", "product", "abov", "alway", "posit", "multipl", "intersect", "exist", "along", "whole", "line", "then", "first", "one", "front", "line", "origin", "return", "thi", "make", "ray", "trace", "polyhedronsset", "polyhedron", "set", "possibl"], "B_title": "Fixed wrong intersection selection in polyhedrons sets.", "B_clean_title": ["fix", "wrong", "intersect", "select", "polyhedron", "set"]},
{"A_title": "Inconsistent read on DocumentNodeStore startupThis is a regression introduced with OAK-2929. On DocumentNodeStore startup the RevisionComparator of the local instance is initialized with the current _lastRev entries from the other cluster nodes. The external _lastRev entries are seenAt the same revision which means for those revisions the RevisionComparator will use the clusterId to compare them. This is also described in OAK-3388.  OAK-2929 changed the sequence of revisions to check for conflicts from StableRevisionComparator to RevisionComparator. This makes the conflict check susceptible to the RevisionComparison behaviour described in OAK-3388. Commits may be rejected with a conflict when there isnt really a conflict.", "A_clean_title": ["inconsist", "read", "documentnodestor", "document", "node", "store", "startupthi", "startup", "thi", "regress", "introduc", "oak", "2929", "documentnodestor", "document", "node", "store", "startup", "revisioncompar", "revis", "compar", "local", "instanc", "initi", "current", "lastrev", "last", "rev", "entri", "other", "cluster", "node", "extern", "lastrev", "last", "rev", "entri", "are", "seenat", "seen", "at", "same", "revis", "which", "mean", "those", "revis", "revisioncompar", "revis", "compar", "will", "use", "clusterid", "cluster", "id", "compar", "them", "thi", "also", "describ", "oak", "3388", "oak", "2929", "chang", "sequenc", "revis", "check", "conflict", "stablerevisioncompar", "stabl", "revis", "compar", "revisioncompar", "revis", "compar", "thi", "make", "conflict", "check", "suscept", "revisioncomparison", "revis", "comparison", "behaviour", "describ", "oak", "3388", "commit", "may", "reject", "conflict", "when", "there", "isnt", "realli", "conflict"], "B_title": "Inconsistent read on DocumentNodeStore startup", "B_clean_title": ["inconsist", "read", "documentnodestor", "document", "node", "store", "startup"]},
{"A_title": "Lucene should not serve queries for what it doesnt indexIf a query is asked and Lucene is chosen as index for serving it it will try to serve all the restrictions of the query even the one that are not indexed.", "A_clean_title": ["lucen", "not", "serv", "queri", "what", "it", "doesnt", "indexif", "index", "queri", "ask", "lucen", "chosen", "as", "index", "serv", "it", "it", "will", "tri", "serv", "all", "restrict", "queri", "even", "one", "that", "are", "not", "index"], "B_title": "Lucene should not serve queries for what it doesnt index", "B_clean_title": ["lucen", "not", "serv", "queri", "what", "it", "doesnt", "index"]},
{"A_title": "Inline enclosure doesnt work if wicket:message attribute is used on the same tagMarkup like:          <div wicket:enclosure=child wicket:message=title:something>         <div>Inner div         <span wicket:id=child>Blah</span>         </div>         </div>  doesnt work (Inner div is visible no matter whether child is visible or not) because the auto component created for wicket:message breaks somehow wicket:enclosure.", "A_clean_title": ["inlin", "enclosur", "doesnt", "work", "wicket", "messag", "attribut", "use", "same", "tagmarkup", "tag", "markup", "like", "div", "wicket", "enclosure=child", "wicket", "message=titl", "someth", "div", "inner", "div", "span", "wicket", "id=child", "blah", "span", "div", "div", "doesnt", "work", "inner", "div", "visibl", "no", "matter", "whether", "child", "visibl", "or", "not", "becaus", "auto", "compon", "creat", "wicket", "messag", "break", "somehow", "wicket", "enclosur"], "B_title": "Inline enclosure doesnt work if wicket:message attribute is used on the same tag", "B_clean_title": ["inlin", "enclosur", "doesnt", "work", "wicket", "messag", "attribut", "use", "same", "tag"]},
{"A_title": "One-to-many with integer ids retrieval brokenHow to Reproduce  Upload:   string-id.xlsx Go to dataexplorer select Subjects table  I dont like the order of the samples so I want to change the ID attribute datatype of the samples to int Upload:  int-id.xlsx Go to your table again Expected behavior  My beautiful table nicely int sorted --> happy datamanager  Observed behavior    --> Sad datamanager", "A_clean_title": ["one", "mani", "integ", "id", "retriev", "brokenhow", "broken", "how", "reproduc", "upload", "string", "id", "xlsx", "go", "dataexplor", "select", "subject", "tabl", "dont", "like", "order", "sampl", "so", "want", "chang", "id", "attribut", "datatyp", "sampl", "int", "upload", "int", "id", "xlsx", "go", "your", "tabl", "again", "expect", "behavior", "my", "beauti", "tabl", "nice", "int", "sort", "happi", "datamanag", "observ", "behavior", "sad", "datamanag"], "B_title": "Merge pull request #7303 from dennishendriksen/fix/7297-oneToManyIntIds  Fix #7297 One-to-many with integer ids retrieval", "B_clean_title": ["merg", "pull", "request", "7303", "onetomanyintid", "dennishendriksen", "fix", "7297", "one", "mani", "int", "id", "fix", "7297", "one", "mani", "integ", "id", "retriev"]},
{"A_title": "IRequestCycleListener: RequestCycle.get() is null inside onBeginRequestI expect the request cycle that is supplied as an argument to onBeginRequest to be the same as RequestCycle.get.  == == == CODE == == ==      @Override     public void onBeginRequest(RequestCycle cycle)          Session session = Session.get(); // throws IllegalArgumentException         if (session.getMetaData(REDIRECTED_JSESSIONID) == null)              logger.debug(first application request - redirecting to loading page);             session.setMetaData(REDIRECTED_JSESSIONID Boolean.TRUE);             String url = getServletRequestContextPath() + / + cycle.getRequest().getUrl();             throw new RestartResponseException(newLoadingPage(url));               == == == == == == == ==   == == == STACK TRACE == == ==  java.lang.IllegalArgumentException: Argument requestCycle may not be null.     at org.apache.wicket.util.lang.Args.notNull(Args.java:37)     at org.apache.wicket.Application.fetchCreateAndSetSession(Application.java:1436)     at org.apache.wicket.Session.get(Session.java:154)     at com.joynit.tuv.common.view.request.SessionIdRemoveListener.onBeginRequest(SessionIdRemoveListener.java:30)  ... snipped -other part is not relevant  == == == == == == == == == == ==", "A_clean_title": ["irequestcyclelisten", "request", "cycl", "listen", "requestcycl", "get", "request", "cycl", "null", "insid", "onbeginrequesti", "begin", "request", "expect", "request", "cycl", "that", "suppli", "as", "argument", "onbeginrequest", "begin", "request", "same", "as", "requestcycl", "get", "request", "cycl", "code", "overrid", "public", "void", "onbeginrequest", "begin", "request", "requestcycl", "request", "cycl", "cycl", "session", "session", "session", "get", "throw", "illegalargumentexcept", "illeg", "argument", "except", "session", "getmetadata", "get", "meta", "data", "redirect", "jsessionid", "null", "logger", "debug", "first", "applic", "request", "redirect", "load", "page", "session", "setmetadata", "set", "meta", "data", "redirect", "jsessionid", "boolean", "true", "string", "url", "getservletrequestcontextpath", "get", "servlet", "request", "context", "path", "cycl", "getrequest", "get", "request", "geturl", "get", "url", "throw", "new", "restartresponseexcept", "restart", "respons", "except", "newloadingpag", "new", "load", "page", "url", "stack", "trace", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "argument", "requestcycl", "request", "cycl", "may", "not", "null", "at", "org", "apach", "wicket", "util", "lang", "arg", "notnul", "not", "null", "arg", "java:37", "at", "org", "apach", "wicket", "applic", "fetchcreateandsetsess", "fetch", "creat", "set", "session", "applic", "java:1436", "at", "org", "apach", "wicket", "session", "get", "session", "java:154", "at", "com", "joynit", "tuv", "common", "view", "request", "sessionidremovelisten", "onbeginrequest", "session", "id", "remov", "listen", "begin", "request", "sessionidremovelisten", "java:30", "session", "id", "remov", "listen", "snip", "other", "part", "not", "relev"], "B_title": "Issue: WICKET-3428", "B_clean_title": ["issu", "wicket", "3428"]},
{"A_title": "Fix interplay of automatic Operator UID and Changing name of WindowOperatorWindowOperator can have a changing name because it has the TypeSerializer .toString() output in its name. For some type serializers that dont implement toString() this means that the name changes.  This means that savepoint restore does not work for the automatically generated UID.", "A_clean_title": ["fix", "interplay", "automat", "oper", "uid", "chang", "name", "windowoperatorwindowoper", "window", "oper", "window", "oper", "have", "chang", "name", "becaus", "it", "ha", "typeseri", "type", "serial", "tostr", "string", "output", "it", "name", "some", "type", "serial", "that", "dont", "implement", "tostr", "string", "thi", "mean", "that", "name", "chang", "thi", "mean", "that", "savepoint", "restor", "not", "work", "automat", "gener", "uid"], "B_title": "runtime Fix interplay of automatic Operator UID and Changing name of WindowOperator", "B_clean_title": ["runtim", "fix", "interplay", "automat", "oper", "uid", "chang", "name", "windowoper", "window", "oper"]},
{"A_title": "function arguments should not be optimized awayNone", "A_clean_title": ["function", "argument", "not", "optim", "awaynon", "away", "none"], "B_title": "In simple mode do not remove unreferenced function arguments. Fixes issue 253", "B_clean_title": ["simpl", "mode", "not", "remov", "unreferenc", "function", "argument", "fix", "issu", "253"]},
{"A_title": "TextField ingnores convertEmptyInputStringToNull = true property when the String type is setI posted this patch on WICKET-3269 but the discussion on this ticket is about an improvement request not a bug. I opened this one for the bug.", "A_clean_title": ["textfield", "text", "field", "ingnor", "convertemptyinputstringtonul", "convert", "empti", "input", "string", "null", "true", "properti", "when", "string", "type", "seti", "set", "post", "thi", "patch", "wicket", "3269", "but", "discuss", "thi", "ticket", "about", "improv", "request", "not", "bug", "open", "thi", "one", "bug"], "B_title": "Issue: WICKET-3304", "B_clean_title": ["issu", "wicket", "3304"]},
{"A_title": "DiscreteDistribution.sample(int) may throw an exception if first element of singletons of sub-class typeCreating an array with Array.newInstance(singletons.get(0).getClass() sampleSize) in DiscreteDistribution.sample(int) is risky. An exception will be thrown if:  singleons.get(0) is of type T1 an sub-class of T and DiscreteDistribution.sample() returns an object which is of type T but not of type T1.  To reproduce:  List<Pair<ObjectDouble>> list = new ArrayList<Pair<Object Double>>(); list.add(new Pair<Object Double>(new Object()  new Double(0))); list.add(new Pair<Object Double>(new Object()  new Double(1))); new DiscreteDistribution<Object>(list).sample(1);   Attaching a patch.", "A_clean_title": ["discretedistribut", "sampl", "discret", "distribut", "int", "may", "throw", "except", "first", "element", "singleton", "sub", "class", "typecr", "type", "creat", "array", "array", "newinst", "new", "instanc", "singleton", "get", "getclass", "get", "class", "samples", "sampl", "size", "discretedistribut", "sampl", "discret", "distribut", "int", "riski", "except", "will", "thrown", "singleon", "get", "type", "t1", "sub", "class", "discretedistribut", "sampl", "discret", "distribut", "return", "object", "which", "type", "but", "not", "type", "t1", "reproduc", "list", "pair", "objectdoubl", "object", "doubl", "list", "new", "arraylist", "array", "list", "pair", "object", "doubl", "list", "add", "new", "pair", "object", "doubl", "new", "object", "new", "doubl", "list", "add", "new", "pair", "object", "doubl", "new", "object", "new", "doubl", "new", "discretedistribut", "discret", "distribut", "object", "list", "sampl", "attach", "patch"], "B_title": "Fixed creation of generic array.", "B_clean_title": ["fix", "creation", "gener", "array"]},
{"A_title": "XPath queries with certain combinations of or conditions dont use an indexXPath queries with the following conditions are not converted to union SQL-2 queries and therefore dont use an index:  noformat /jcr:root/content//*((@i = 1 or @i = 2) or (@s = x)) and (@t = a or @t = b) noformat", "A_clean_title": ["xpath", "path", "queri", "certain", "combin", "or", "condit", "dont", "use", "indexxpath", "index", "path", "queri", "follow", "condit", "are", "not", "convert", "union", "sql", "queri", "therefor", "dont", "use", "index", "noformat", "jcr", "root", "content", "or", "or", "or", "noformat"], "B_title": "XPath queries with certain combinations of or conditions dont use an index OAK-2022 XPath queries with order by are never converted to union", "B_clean_title": ["xpath", "path", "queri", "certain", "combin", "or", "condit", "dont", "use", "index", "oak", "2022", "xpath", "path", "queri", "order", "by", "are", "never", "convert", "union"]},
{"A_title": "Windowed fold operation fails because the initial value was not serializedThe windowed fold operation currently fails because the initial value was not serialized. The reason for this is that the fold operation is realized as a WindowFunction within an AbstractUdfStreamOperator and does not get the output type information forwarded (which is necessary for the serialization).   The solution is to let the AbstractUdfStreamOperator forward the output type information to the WindowFunction if it implements the OutputTypeConfigurable interface.", "A_clean_title": ["window", "fold", "oper", "fail", "becaus", "initi", "valu", "wa", "not", "serializedth", "serial", "window", "fold", "oper", "current", "fail", "becaus", "initi", "valu", "wa", "not", "serial", "reason", "thi", "that", "fold", "oper", "realiz", "as", "windowfunct", "window", "function", "within", "abstractudfstreamoper", "abstract", "udf", "stream", "oper", "not", "get", "output", "type", "inform", "forward", "which", "necessari", "serial", "solut", "let", "abstractudfstreamoper", "abstract", "udf", "stream", "oper", "forward", "output", "type", "inform", "windowfunct", "window", "function", "it", "implement", "outputtypeconfigur", "output", "type", "configur", "interfac"], "B_title": "streaming Let AbstractUdfStreamOperator forward output type information to WindowFunction", "B_clean_title": ["stream", "let", "abstractudfstreamoper", "abstract", "udf", "stream", "oper", "forward", "output", "type", "inform", "windowfunct", "window", "function"]},
{"A_title": "Cookies#isEqual(Cookie Cookie) may fail with NullPointerExceptionIf c1.getPath == null but c2.getPath != null then a NPE will occur. Same is valid for the domain property.", "A_clean_title": ["cooki", "isequ", "equal", "cooki", "cooki", "may", "fail", "nullpointerexceptionif", "null", "pointer", "except", "c1", "getpath", "get", "path", "null", "but", "c2", "getpath", "get", "path", "null", "then", "npe", "will", "occur", "same", "valid", "domain", "properti"], "B_title": "Cookies#isEqual(Cookie Cookie) may fail with NullPointerException", "B_clean_title": ["cooki", "isequ", "equal", "cooki", "cooki", "may", "fail", "nullpointerexcept", "null", "pointer", "except"]},
{"A_title": "Header contributions order is not stableIn the last RCs I started to experience problems with the contributions order. For example I add jQuery and until 1.5RC5 it worked well but now the call to the jQuery script has been moved to the bottom of the page head and this disables all my other scripts that are expecting jQuerys   to be defined.  I attach a quickstart to demonstrate the problem. Maybe the order in the quickstart is not the expected one but what it shows is that the order does not make real sense (at least to me) : In the quickstart the wicket:head tag contributions are in the order 3 - 8 - 9 - 5 and the renderHead methods contributions are in the order 4 - 1 - 2 - 6 - 7.", "A_clean_title": ["header", "contribut", "order", "not", "stablein", "stabl", "last", "rc", "cs", "start", "experi", "problem", "contribut", "order", "exampl", "add", "jqueri", "queri", "until", "5rc5", "it", "work", "well", "but", "now", "call", "jqueri", "queri", "script", "ha", "been", "move", "bottom", "page", "head", "thi", "disabl", "all", "my", "other", "script", "that", "are", "expect", "jqueri", "queri", "defin", "attach", "quickstart", "demonstr", "problem", "mayb", "order", "quickstart", "not", "expect", "one", "but", "what", "it", "show", "that", "order", "not", "make", "real", "sens", "at", "least", "me", "quickstart", "wicket", "head", "tag", "contribut", "are", "order", "renderhead", "render", "head", "method", "contribut", "are", "order"], "B_title": "Header contributions order is not stable", "B_clean_title": ["header", "contribut", "order", "not", "stabl"]},
{"A_title": "AjaxPreprocessingCallDecorator calls the delegate decorator before itself (same behavior as AjaxPostprocessingCallDecorator)AjaxPreprocessingCallDecorator calls the delegate decorator before itself (same behavior as AjaxPostprocessingCallDecorator) when it should call itself before the delegate.", "A_clean_title": ["ajaxpreprocessingcalldecor", "ajax", "preprocess", "call", "decor", "call", "deleg", "decor", "befor", "itself", "same", "behavior", "as", "ajaxpostprocessingcalldecor", "ajax", "postprocess", "call", "decor", "ajaxpreprocessingcalldecor", "ajax", "preprocess", "call", "decor", "call", "deleg", "decor", "befor", "itself", "same", "behavior", "as", "ajaxpostprocessingcalldecor", "ajax", "postprocess", "call", "decor", "when", "it", "call", "itself", "befor", "deleg"], "B_title": "", "B_clean_title": []},
{"A_title": "Division by zeroIn class Complex division by zero always returns NaN. I think that it should return NaN only when the numerator is also ZERO otherwise the result should be INF. See here.", "A_clean_title": ["divis", "by", "zeroin", "zero", "class", "complex", "divis", "by", "zero", "alway", "return", "nan", "na", "think", "that", "it", "return", "nan", "na", "onli", "when", "numer", "also", "zero", "otherwis", "result", "inf", "see", "here"], "B_title": "Complex division by zero:  z / 0 = INF if z is not ZERO  0 / 0 = NaN", "B_clean_title": ["complex", "divis", "by", "zero", "inf", "not", "zero", "nan", "na"]},
{"A_title": "TarMK compaction can create mixed segmentsAs described in http://markmail.org/message/ujkqdlthudaortxf commits that occur while the compaction operation is running can make the compacted segments contain references to older data segments which prevents old data from being reclaimed during cleanup.", "A_clean_title": ["tarmk", "tar", "mk", "compact", "creat", "mix", "segmentsa", "segment", "as", "describ", "http", "markmail", "org", "messag", "ujkqdlthudaortxf", "commit", "that", "occur", "while", "compact", "oper", "run", "make", "compact", "segment", "contain", "refer", "older", "data", "segment", "which", "prevent", "old", "data", "be", "reclaim", "dure", "cleanup"], "B_title": "TarMK compaction can create mixed segments", "B_clean_title": ["tarmk", "tar", "mk", "compact", "creat", "mix", "segment"]},
{"A_title": "smartNameRemoval causing compiler crashNone", "A_clean_title": ["smartnameremov", "smart", "name", "remov", "caus", "compil", "crashnon", "crash", "none"], "B_title": "fix smartNameRemoval crash Fixes issue 284", "B_clean_title": ["fix", "smartnameremov", "smart", "name", "remov", "crash", "fix", "issu", "284"]},
{"A_title": "Gamma function computationIn the gamma method when handling the case absX > 20 the computation of gammaAbs should replace x (see code below with x in bold) by absX. For large negative values of x the function returns with the wrong sign.  final double gammaAbs = SQRT_TWO_PI / *x* *                                      FastMath.pow(y absX + 0.5) *                                      FastMath.exp(-y) * lanczos(absX);", "A_clean_title": ["gamma", "function", "computationin", "comput", "gamma", "method", "when", "handl", "case", "absx", "ab", "20", "comput", "gammaab", "gamma", "ab", "replac", "see", "code", "below", "bold", "by", "absx", "ab", "larg", "neg", "valu", "function", "return", "wrong", "sign", "final", "doubl", "gammaab", "gamma", "ab", "sqrt", "two", "pi", "fastmath", "pow", "fast", "math", "absx", "ab", "fastmath", "exp", "fast", "math", "lanczo", "absx", "ab"], "B_title": "Fixed Gamma#gamma function for values smaller than -20. Thanks to Jean Noel Delavalade", "B_clean_title": ["fix", "gamma", "gamma", "function", "valu", "smaller", "than", "20", "thank", "jean", "noel", "delavalad"]},
{"A_title": "Use of ThreadLocals in ToStringStyle and HashCodeBuilder trigger memory leaks in container environmentsThe thread local in org.apache.commons.lang3.builder.ToStringStyle is created but never removed and no API is provided to remove it. If a webapps use of LANG triggers the loading of this class a reference chain will be created that will cause a memory leak on web application reload. See http://markmail.org/thread/uetw2fdrsqgbh2cv for more info.", "A_clean_title": ["use", "threadloc", "thread", "local", "tostringstyl", "string", "style", "hashcodebuild", "hash", "code", "builder", "trigger", "memori", "leak", "contain", "environmentsth", "environ", "thread", "local", "org", "apach", "common", "lang3", "builder", "tostringstyl", "string", "style", "creat", "but", "never", "remov", "no", "api", "provid", "remov", "it", "webapp", "use", "lang", "trigger", "load", "thi", "class", "refer", "chain", "will", "creat", "that", "will", "caus", "memori", "leak", "web", "applic", "reload", "see", "http", "markmail", "org", "thread", "uetw2fdrsqgbh2cv", "more", "info"], "B_title": "Clear ThreadLocal for HashCodeBuilder as well", "B_clean_title": ["clear", "threadloc", "thread", "local", "hashcodebuild", "hash", "code", "builder", "as", "well"]}]