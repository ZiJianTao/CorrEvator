[{"A_title": "ODE integrator goes past specified end of integration rangeEnd of integration range in ODE solving is handled as an event. In some cases numerical accuracy in events detection leads to error in events location. The following test case shows the end event is not handled properly and an integration that should cover a 60s range in fact covers a 160s range more than twice the specified range.    public void testMissedEvent() throws IntegratorException DerivativeException            final double t0 = 1878250320.0000029;           final double t =  1878250379.9999986;           FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations()                           public int getDimension()                  return 1;                                       public void computeDerivatives(double t double y double yDot)                 throws DerivativeException                  yDot0 = y0 * 1.0e-6;                      ;          DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0 100.0                                                                                1.0e-10 1.0e-10);          double y =  1.0 ;         integrator.setInitialStepSize(60.0);         double finalT = integrator.integrate(ode t0 y t y);         Assert.assertEquals(t finalT 1.0e-6);     ", "A_clean_title": ["ode", "integr", "goe", "past", "specifi", "end", "integr", "rangeend", "rang", "end", "integr", "rang", "ode", "solv", "handl", "as", "event", "some", "case", "numer", "accuraci", "event", "detect", "lead", "error", "event", "locat", "follow", "test", "case", "show", "end", "event", "not", "handl", "properli", "integr", "that", "cover", "60", "rang", "fact", "cover", "160", "rang", "more", "than", "twice", "specifi", "rang", "public", "void", "testmissedev", "test", "miss", "event", "throw", "integratorexcept", "integr", "except", "derivativeexcept", "deriv", "except", "final", "doubl", "t0", "1878250320", "0000029", "final", "doubl", "1878250379", "9999986", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "ode", "new", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "public", "int", "getdimens", "get", "dimens", "return", "public", "void", "computederiv", "comput", "deriv", "doubl", "doubl", "doubl", "ydot", "dot", "throw", "derivativeexcept", "deriv", "except", "ydot0", "dot0", "y0", "0e", "dormandprince853integr", "dormand", "prince853integr", "integr", "new", "dormandprince853integr", "dormand", "prince853integr", "100", "10", "0e", "10", "0e", "doubl", "integr", "setinitialsteps", "set", "initi", "step", "size", "60", "doubl", "finalt", "final", "integr", "integr", "ode", "t0", "assert", "assertequ", "assert", "equal", "finalt", "final", "0e"], "B_title": "Fix the artificial 0 size step for EmbeddedRungeKuttaIntegator .. Fix the nonstiff test .. ", "B_clean_title": ["fix", "artifici", "size", "step", "embeddedrungekuttainteg", "embed", "rung", "kutta", "integ", "fix", "nonstiff", "test"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));   ", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Reset timeZone on parse ( ) .. ", "B_clean_title": ["reset", "timezon", "time", "zone", "pars"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));   ", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Fixed formatting of date with timeZone. ", "B_clean_title": ["fix", "format", "date", "timezon", "time", "zone"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));   ", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Reset the calendar time to GMT on Sunday .. ", "B_clean_title": ["reset", "calendar", "time", "gmt", "sunday"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));   ", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Fix null pointer check in FastDateFormat. ", "B_clean_title": ["fix", "null", "pointer", "check", "fastdateformat", "fast", "date", "format"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));   ", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Fix null pointer check in FastDateFormat. ", "B_clean_title": ["fix", "null", "pointer", "check", "fastdateformat", "fast", "date", "format"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "Fix NPE triggered by nullability exception. ", "B_clean_title": ["fix", "npe", "trigger", "by", "nullabl", "except"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed null check. ", "B_clean_title": ["remov", "null", "check"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed null check. ", "B_clean_title": ["remov", "null", "check"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "added null check in Hercules . fixed. null check in Hercules for fixed. fix null pointer check. ", "B_clean_title": ["ad", "null", "check", "hercul", "fix", "null", "check", "hercul", "fix", "fix", "null", "pointer", "check"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed null check. ", "B_clean_title": ["remov", "null", "check"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed unnecessary loop. ", "B_clean_title": ["remov", "unnecessari", "loop"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed unnecessary copy of ClassUtils. ", "B_clean_title": ["remov", "unnecessari", "copi", "classutil", "class", "util"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed null check. ", "B_clean_title": ["remov", "null", "check"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "removed null check. ", "B_clean_title": ["remov", "null", "check"]},
{"A_title": "side-effects analysis incorrectly removing function calls with side effectsNone", "A_clean_title": ["side", "effect", "analysi", "incorrectli", "remov", "function", "call", "side", "effectsnon", "effect", "none"], "B_title": "Updated lookahead for the NEW value keyword. ", "B_clean_title": ["updat", "lookahead", "new", "valu", "keyword"]},
{"A_title": "side-effects analysis incorrectly removing function calls with side effectsNone", "A_clean_title": ["side", "effect", "analysi", "incorrectli", "remov", "function", "call", "side", "effectsnon", "effect", "none"], "B_title": "fix broken patch. ", "B_clean_title": ["fix", "broken", "patch"]},
{"A_title": "MultivariateNormalDistribution.density(double) returns wrong value when the dimension is oddTo reproduce:  Assert.assertEquals(0.398942280401433 new MultivariateNormalDistribution(new double0 new double1).density(new double0) 1e-15);", "A_clean_title": ["multivariatenormaldistribut", "densiti", "multivari", "normal", "distribut", "doubl", "return", "wrong", "valu", "when", "dimens", "oddto", "odd", "reproduc", "assert", "assertequ", "assert", "equal", "398942280401433", "new", "multivariatenormaldistribut", "multivari", "normal", "distribut", "new", "double0", "new", "double1", "densiti", "new", "double0", "1e", "15"], "B_title": "Fix MultivariateNormalDistribution precision thingie in 1 . 6 . 2. ", "B_clean_title": ["fix", "multivariatenormaldistribut", "multivari", "normal", "distribut", "precis", "thingi"]},
{"A_title": "ListPopulation Iterator allows you to remove chromosomes from the population.Calling the iterator method of ListPopulation returns an iterator of the protected modifiable list. Before returning the iterator we should wrap it in an unmodifiable list.", "A_clean_title": ["listpopul", "list", "popul", "iter", "allow", "you", "remov", "chromosom", "popul", "call", "iter", "method", "listpopul", "list", "popul", "return", "iter", "protect", "modifi", "list", "befor", "return", "iter", "we", "wrap", "it", "unmodifi", "list"], "B_title": "Fix ListPopulation . iterator ( ). ", "B_clean_title": ["fix", "listpopul", "list", "popul", "iter"]},
{"A_title": "ListPopulation Iterator allows you to remove chromosomes from the population.Calling the iterator method of ListPopulation returns an iterator of the protected modifiable list. Before returning the iterator we should wrap it in an unmodifiable list.", "A_clean_title": ["listpopul", "list", "popul", "iter", "allow", "you", "remov", "chromosom", "popul", "call", "iter", "method", "listpopul", "list", "popul", "return", "iter", "protect", "modifi", "list", "befor", "return", "iter", "we", "wrap", "it", "unmodifi", "list"], "B_title": "Fix # 12. ", "B_clean_title": ["fix", "12"]},
{"A_title": "ListPopulation Iterator allows you to remove chromosomes from the population.Calling the iterator method of ListPopulation returns an iterator of the protected modifiable list. Before returning the iterator we should wrap it in an unmodifiable list.", "A_clean_title": ["listpopul", "list", "popul", "iter", "allow", "you", "remov", "chromosom", "popul", "call", "iter", "method", "listpopul", "list", "popul", "return", "iter", "protect", "modifi", "list", "befor", "return", "iter", "we", "wrap", "it", "unmodifi", "list"], "B_title": "added iterator on non - empty chromosomes list. ", "B_clean_title": ["ad", "iter", "non", "empti", "chromosom", "list"]},
{"A_title": "ExtendedMessageFormat: OutOfMemory with custom format registry and a pattern containing single quotesWhen using ExtendedMessageFormat with a custom format registry and a pattern conatining single quotes an OutOfMemoryError will occur. Example that will cause error: ExtendedMessageFormatTest.java  private static Map<String Object> formatRegistry = new HashMap<String Object>();         static          formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT new DummyFormatFactory());               public static void main(String args)          ExtendedMessageFormat mf = new ExtendedMessageFormat(its a dummy test! formatRegistry);         String formattedPattern = mf.format(new String great);         System.out.println(formattedPattern);          The following change starting at line 421 on the 2.4 release seems to fix the problem: ExtendedMessageFormat.java CURRENT (Broken): if (escapingOn && cstart == QUOTE)          return appendTo == null ? null : appendTo.append(QUOTE);   WORKING: if (escapingOn && cstart == QUOTE)          next(pos);         return appendTo == null ? null : appendTo.append(QUOTE); ", "A_clean_title": ["extendedmessageformat", "extend", "messag", "format", "outofmemori", "out", "memori", "custom", "format", "registri", "pattern", "contain", "singl", "quoteswhen", "quot", "when", "extendedmessageformat", "extend", "messag", "format", "custom", "format", "registri", "pattern", "conatin", "singl", "quot", "outofmemoryerror", "out", "memori", "error", "will", "occur", "exampl", "that", "will", "caus", "error", "extendedmessageformattest", "java", "extend", "messag", "format", "test", "privat", "static", "map", "string", "object", "formatregistri", "format", "registri", "new", "hashmap", "hash", "map", "string", "object", "static", "formatregistri", "put", "format", "registri", "dummyformatfactori", "dummi", "format", "factori", "dummi", "format", "new", "dummyformatfactori", "dummi", "format", "factori", "public", "static", "void", "main", "string", "arg", "extendedmessageformat", "extend", "messag", "format", "mf", "new", "extendedmessageformat", "extend", "messag", "format", "it", "dummi", "test", "formatregistri", "format", "registri", "string", "formattedpattern", "format", "pattern", "mf", "format", "new", "string", "great", "system", "out", "println", "formattedpattern", "format", "pattern", "follow", "chang", "start", "at", "line", "421", "releas", "seem", "fix", "problem", "extendedmessageformat", "java", "extend", "messag", "format", "current", "broken", "escapingon", "escap", "cstart", "quot", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot", "work", "escapingon", "escap", "cstart", "quot", "next", "po", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot"], "B_title": "don  t append QUOTE if escaping is on. ", "B_clean_title": ["don", "append", "quot", "escap"]},
{"A_title": "ExtendedMessageFormat: OutOfMemory with custom format registry and a pattern containing single quotesWhen using ExtendedMessageFormat with a custom format registry and a pattern conatining single quotes an OutOfMemoryError will occur. Example that will cause error: ExtendedMessageFormatTest.java  private static Map<String Object> formatRegistry = new HashMap<String Object>();         static          formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT new DummyFormatFactory());               public static void main(String args)          ExtendedMessageFormat mf = new ExtendedMessageFormat(its a dummy test! formatRegistry);         String formattedPattern = mf.format(new String great);         System.out.println(formattedPattern);          The following change starting at line 421 on the 2.4 release seems to fix the problem: ExtendedMessageFormat.java CURRENT (Broken): if (escapingOn && cstart == QUOTE)          return appendTo == null ? null : appendTo.append(QUOTE);   WORKING: if (escapingOn && cstart == QUOTE)          next(pos);         return appendTo == null ? null : appendTo.append(QUOTE); ", "A_clean_title": ["extendedmessageformat", "extend", "messag", "format", "outofmemori", "out", "memori", "custom", "format", "registri", "pattern", "contain", "singl", "quoteswhen", "quot", "when", "extendedmessageformat", "extend", "messag", "format", "custom", "format", "registri", "pattern", "conatin", "singl", "quot", "outofmemoryerror", "out", "memori", "error", "will", "occur", "exampl", "that", "will", "caus", "error", "extendedmessageformattest", "java", "extend", "messag", "format", "test", "privat", "static", "map", "string", "object", "formatregistri", "format", "registri", "new", "hashmap", "hash", "map", "string", "object", "static", "formatregistri", "put", "format", "registri", "dummyformatfactori", "dummi", "format", "factori", "dummi", "format", "new", "dummyformatfactori", "dummi", "format", "factori", "public", "static", "void", "main", "string", "arg", "extendedmessageformat", "extend", "messag", "format", "mf", "new", "extendedmessageformat", "extend", "messag", "format", "it", "dummi", "test", "formatregistri", "format", "registri", "string", "formattedpattern", "format", "pattern", "mf", "format", "new", "string", "great", "system", "out", "println", "formattedpattern", "format", "pattern", "follow", "chang", "start", "at", "line", "421", "releas", "seem", "fix", "problem", "extendedmessageformat", "java", "extend", "messag", "format", "current", "broken", "escapingon", "escap", "cstart", "quot", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot", "work", "escapingon", "escap", "cstart", "quot", "next", "po", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot"], "B_title": "Fix format. ", "B_clean_title": ["fix", "format"]},
{"A_title": "bug with implicit namespaces across modulesNone", "A_clean_title": ["bug", "implicit", "namespac", "across", "modulesnon", "modul", "none"], "B_title": "Fix up whitespace. ", "B_clean_title": ["fix", "up", "whitespac"]},
{"A_title": "NumberUtils does not handle upper-case hex: 0X and -0XNumberUtils.createNumber() should work equally for 0x1234 and 0X1234; currently 0X1234 generates a NumberFormatException Integer.decode() handles both upper and lower case hex.", "A_clean_title": ["numberutil", "number", "util", "not", "handl", "upper", "case", "hex", "0x", "0xnumberutil", "createnumb", "0x", "number", "util", "creat", "number", "work", "equal", "0x1234", "0x1234", "current", "0x1234", "gener", "numberformatexcept", "number", "format", "except", "integ", "decod", "handl", "both", "upper", "lower", "case", "hex"], "B_title": "convert string to lower case since it  s a number. ", "B_clean_title": ["convert", "string", "lower", "case", "sinc", "it", "number"]},
{"A_title": "TraceProxy.trace should not throw InvocationTargetExceptionIn TraceProxy.trace there is the following code snippet: code         try            return method.invoke(instance args);          catch (Throwable ex)            ex.printStackTrace();           throw ex;          code When this is an InvocationTargetException it can really mess with the calling codes exception handling logic.", "A_clean_title": ["traceproxi", "trace", "trace", "proxi", "not", "throw", "invocationtargetexceptionin", "invoc", "target", "except", "traceproxi", "trace", "trace", "proxi", "there", "follow", "code", "snippet", "code", "tri", "return", "method", "invok", "instanc", "arg", "catch", "throwabl", "ex", "ex", "printstacktrac", "print", "stack", "trace", "throw", "ex", "code", "when", "thi", "invocationtargetexcept", "invoc", "target", "except", "it", "realli", "mess", "call", "code", "except", "handl", "logic"], "B_title": "InvocationTargetEx in TraceProxy", "B_clean_title": ["invocationtargetex", "invoc", "target", "ex", "traceproxi", "trace", "proxi"]},
{"A_title": "DataStoreBlobStore does not take into maxLastModifiedTime when fetching all chunksCurrently the DataStoreBlobStore has a pending TODO  code  @Override     public Iterator<String> getAllChunkIds(long maxLastModifiedTime) throws Exception          //TODO Ignores the maxLastModifiedTime currently.         return Iterators.transform(delegate.getAllIdentifiers() new Function<DataIdentifier String>()              @Nullable             @Override             public String apply(@Nullable DataIdentifier input)                  return input.toString();                      );      code  Due to this it currently returns all blobId. This would issue when new binary gets created while a blob gc is running as such binaries might be considered orphan and deleted", "A_clean_title": ["datastoreblobstor", "data", "store", "blob", "store", "not", "take", "into", "maxlastmodifiedtim", "max", "last", "modifi", "time", "when", "fetch", "all", "chunkscurr", "chunk", "current", "datastoreblobstor", "data", "store", "blob", "store", "ha", "pend", "todo", "code", "overrid", "public", "iter", "string", "getallchunkid", "get", "all", "chunk", "id", "long", "maxlastmodifiedtim", "max", "last", "modifi", "time", "throw", "except", "todo", "ignor", "maxlastmodifiedtim", "max", "last", "modifi", "time", "current", "return", "iter", "transform", "deleg", "getallidentifi", "get", "all", "identifi", "new", "function", "dataidentifi", "data", "identifi", "string", "nullabl", "overrid", "public", "string", "appli", "nullabl", "dataidentifi", "data", "identifi", "input", "return", "input", "tostr", "string", "code", "due", "thi", "it", "current", "return", "all", "blobid", "blob", "id", "thi", "would", "issu", "when", "new", "binari", "get", "creat", "while", "blob", "gc", "run", "as", "such", "binari", "might", "consid", "orphan", "delet"], "B_title": "- DataStoreBlobStore does not take into maxLastModifiedTime when fetching all chunks", "B_clean_title": ["datastoreblobstor", "data", "store", "blob", "store", "not", "take", "into", "maxlastmodifiedtim", "max", "last", "modifi", "time", "when", "fetch", "all", "chunk"]},
{"A_title": "Streaming iteration heads cannot be instantiatedIt looks that streaming jobs with iterations and dop > 1 do not work currently. From what I see when the TaskManager tries to instantiate a new RuntimeEnvironment for the iteration head tasks it fails since the following exception is being thrown:  java.lang.Exception: Failed to deploy the task Map (2/8) - execution #0 to slot SimpleSlot (0)(1) - 0e39fcabcab3e8543cc2d8320f9de783 - ALLOCATED/ALIVE: java.lang.Exception: Error setting up runtime environment: java.lang.RuntimeException: Could not register the given element broker slot is already occupied. at org.apache.flink.runtime.execution.RuntimeEnvironment.<init>(RuntimeEnvironment.java:174) at org.apache.flink.runtime.taskmanager.TaskManager.org apache flink runtime taskmanager TaskManager  submitTask(TaskManager.scala:432) ..... ..... Caused by: java.lang.RuntimeException: java.lang.RuntimeException: Could not register the given element broker slot is already occupied. at org.apache.flink.streaming.api.streamvertex.StreamIterationHead.setInputsOutputs(StreamIterationHead.java:64) at org.apache.flink.streaming.api.streamvertex.StreamVertex.registerInputOutput(StreamVertex.java:86) at org.apache.flink.runtime.execution.RuntimeEnvironment.<init>(RuntimeEnvironment.java:171) ... 20 more Caused by: java.lang.RuntimeException: Could not register the given element broker slot is already occupied. at org.apache.flink.runtime.iterative.concurrent.Broker.handIn(Broker.java:39) at org.apache.flink.streaming.api.streamvertex.StreamIterationHead.setInputsOutputs(StreamIterationHead.java:62)  The IterateTest passed since it is using a dop of 1 but for higher parallelism it fails. Also the IterateExample fails as well if you try to run it.   I will debug this once I find some time so any ideas of what could possible cause this are more than welcome.", "A_clean_title": ["stream", "iter", "head", "not", "instantiatedit", "instanti", "it", "look", "that", "stream", "job", "iter", "dop", "not", "work", "current", "what", "see", "when", "taskmanag", "task", "manag", "tri", "instanti", "new", "runtimeenviron", "runtim", "environ", "iter", "head", "task", "it", "fail", "sinc", "follow", "except", "be", "thrown", "java", "lang", "except", "fail", "deploy", "task", "map", "execut", "slot", "simpleslot", "simpl", "slot", "0e39fcabcab3e8543cc2d8320f9de783", "alloc", "aliv", "java", "lang", "except", "error", "set", "up", "runtim", "environ", "java", "lang", "runtimeexcept", "runtim", "except", "could", "not", "regist", "given", "element", "broker", "slot", "alreadi", "occupi", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "runtim", "environ", "init", "runtimeenviron", "java:174", "runtim", "environ", "at", "org", "apach", "flink", "runtim", "taskmanag", "taskmanag", "org", "task", "manag", "apach", "flink", "runtim", "taskmanag", "taskmanag", "task", "manag", "submittask", "submit", "task", "taskmanag", "scala:432", "task", "manag", "caus", "by", "java", "lang", "runtimeexcept", "runtim", "except", "java", "lang", "runtimeexcept", "runtim", "except", "could", "not", "regist", "given", "element", "broker", "slot", "alreadi", "occupi", "at", "org", "apach", "flink", "stream", "api", "streamvertex", "streamiterationhead", "setinputsoutput", "stream", "iter", "head", "set", "input", "output", "streamiterationhead", "java:64", "stream", "iter", "head", "at", "org", "apach", "flink", "stream", "api", "streamvertex", "streamvertex", "registerinputoutput", "stream", "vertex", "regist", "input", "output", "streamvertex", "java:86", "stream", "vertex", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "runtim", "environ", "init", "runtimeenviron", "java:171", "runtim", "environ", "20", "more", "caus", "by", "java", "lang", "runtimeexcept", "runtim", "except", "could", "not", "regist", "given", "element", "broker", "slot", "alreadi", "occupi", "at", "org", "apach", "flink", "runtim", "iter", "concurr", "broker", "handin", "hand", "broker", "java:39", "at", "org", "apach", "flink", "stream", "api", "streamvertex", "streamiterationhead", "setinputsoutput", "stream", "iter", "head", "set", "input", "output", "streamiterationhead", "java:62", "stream", "iter", "head", "iteratetest", "iter", "test", "pass", "sinc", "it", "dop", "but", "higher", "parallel", "it", "fail", "also", "iterateexampl", "iter", "exampl", "fail", "as", "well", "you", "tri", "run", "it", "will", "debug", "thi", "onc", "find", "some", "time", "so", "ani", "idea", "what", "could", "possibl", "caus", "thi", "are", "more", "than", "welcom"], "B_title": "streaming add parallel iteration test", "B_clean_title": ["stream", "add", "parallel", "iter", "test"]},
{"A_title": "UUID collision check is not does not work in transient spaceI think OAK-1037 broke the system view import.  test case: 1. create a new node with a uuid (referenceable or new user) 2. import systemview with IMPORT_UUID_COLLISION_REPLACE_EXISTING 3. save()  result: noformat javax.jcr.nodetype.ConstraintViolationException: OakConstraint0030: Uniqueness constraint violated at path / for one of the property in jcr:uuid having value e358efa4-89f5-3062-b10d-d7316b65649e noformat  expected: * imported content should replace the existing node - even in transient space.  note: * if you perform a save() after step 1 everything works.", "A_clean_title": ["uuid", "collis", "check", "not", "not", "work", "transient", "spacei", "space", "think", "oak", "1037", "broke", "system", "view", "import", "test", "case", "creat", "new", "node", "uuid", "referenc", "or", "new", "user", "import", "systemview", "import", "uuid", "collis", "replac", "exist", "save", "result", "noformat", "javax", "jcr", "nodetyp", "constraintviolationexcept", "constraint", "violat", "except", "oakconstraint0030", "oak", "constraint0030", "uniqu", "constraint", "violat", "at", "path", "one", "properti", "jcr", "uuid", "have", "valu", "e358efa4", "89f5", "3062", "b10d", "d7316b65649e", "noformat", "expect", "import", "content", "replac", "exist", "node", "even", "transient", "space", "note", "you", "perform", "save", "after", "step", "everyth", "work"], "B_title": ": UUID collision check is not does not work in transient space", "B_clean_title": ["uuid", "collis", "check", "not", "not", "work", "transient", "space"]},
{"A_title": "DiscreteDistribution.sample(int) may throw an exception if first element of singletons of sub-class typeCreating an array with Array.newInstance(singletons.get(0).getClass() sampleSize) in DiscreteDistribution.sample(int) is risky. An exception will be thrown if: * singleons.get(0) is of type T1 an sub-class of T and * DiscreteDistribution.sample() returns an object which is of type T but not of type T1.  To reproduce: code List<Pair<ObjectDouble>> list = new ArrayList<Pair<Object Double>>(); list.add(new Pair<Object Double>(new Object()  new Double(0))); list.add(new Pair<Object Double>(new Object()  new Double(1))); new DiscreteDistribution<Object>(list).sample(1); code  Attaching a patch.", "A_clean_title": ["discretedistribut", "sampl", "discret", "distribut", "int", "may", "throw", "except", "first", "element", "singleton", "sub", "class", "typecr", "type", "creat", "array", "array", "newinst", "new", "instanc", "singleton", "get", "getclass", "get", "class", "samples", "sampl", "size", "discretedistribut", "sampl", "discret", "distribut", "int", "riski", "except", "will", "thrown", "singleon", "get", "type", "t1", "sub", "class", "discretedistribut", "sampl", "discret", "distribut", "return", "object", "which", "type", "but", "not", "type", "t1", "reproduc", "code", "list", "pair", "objectdoubl", "object", "doubl", "list", "new", "arraylist", "array", "list", "pair", "object", "doubl", "list", "add", "new", "pair", "object", "doubl", "new", "object", "new", "doubl", "list", "add", "new", "pair", "object", "doubl", "new", "object", "new", "doubl", "new", "discretedistribut", "discret", "distribut", "object", "list", "sampl", "code", "attach", "patch"], "B_title": "Fixed creation of generic array.", "B_clean_title": ["fix", "creation", "gener", "array"]},
{"A_title": "StackOverflowError after form submit with a validation errorI was not able to find a cause or make a small quickstart but it has something to do with a form validation my workaround was to setDefaultFormProcessing(false) or not use required TextFields.  It can be reproduced on https://github.com/krasa/DevSupportApp/tree/stackOverflow  1) run StartVojtitkoDummy 2) go to http://localhost:8765/wicket/bookmarkable/krasa.release.frontend.TokenizationPage 3) click on Generate Release json button  - instead of SOE it should give a validation error probably even on fields which I would not want to validate but thats just because Ive made the page badly...     code java.lang.StackOverflowError: null ... at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.Component.internalRender(Component.java:2344) at org.apache.wicket.Component.render(Component.java:2307) at org.apache.wicket.ajax.XmlAjaxResponse.writeComponent(XmlAjaxResponse.java:128) at org.apache.wicket.ajax.AbstractAjaxResponse.writeComponents(AbstractAjaxResponse.java:218) at org.apache.wicket.ajax.AbstractAjaxResponse.writeTo(AbstractAjaxResponse.java:150) at org.apache.wicket.ajax.AjaxRequestHandler.respond(AjaxRequestHandler.java:359) at org.apache.wicket.request.cycle.RequestCycle HandlerExecutor.respond(RequestCycle.java:865) at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:64) at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:97) at org.apache.wicket.request.cycle.RequestCycle.execute(RequestCycle.java:265) at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:222) at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:293) at org.apache.wicket.protocol.ws.AbstractUpgradeFilter.processRequestCycle(AbstractUpgradeFilter.java:59) at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:203) at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:284) at org.eclipse.jetty.servlet.ServletHandler CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1125) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1059) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:497) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:248) at org.eclipse.jetty.io.AbstractConnection 2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:620) at org.eclipse.jetty.util.thread.QueuedThreadPool 3.ru code", "A_clean_title": ["stackoverflowerror", "stack", "overflow", "error", "after", "form", "submit", "valid", "errori", "error", "wa", "not", "abl", "find", "caus", "or", "make", "small", "quickstart", "but", "it", "ha", "someth", "form", "valid", "my", "workaround", "wa", "setdefaultformprocess", "set", "default", "form", "process", "fals", "or", "not", "use", "requir", "textfield", "text", "field", "it", "reproduc", "http", "github", "com", "krasa", "devsupportapp", "tree", "stackoverflow", "dev", "support", "app", "stack", "overflow", "run", "startvojtitkodummi", "start", "vojtitko", "dummi", "go", "http", "releas", "frontend", "tokenizationpag", "localhost:8765", "wicket", "bookmark", "krasa", "token", "page", "click", "gener", "releas", "json", "button", "instead", "soe", "it", "give", "valid", "error", "probabl", "even", "field", "which", "would", "not", "want", "valid", "but", "that", "just", "becaus", "ive", "made", "page", "badli", "code", "java", "lang", "stackoverflowerror", "stack", "overflow", "error", "null", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "compon", "internalrend", "intern", "render", "compon", "java:2344", "at", "org", "apach", "wicket", "compon", "render", "compon", "java:2307", "at", "org", "apach", "wicket", "ajax", "xmlajaxrespons", "writecompon", "xml", "ajax", "respons", "write", "compon", "xmlajaxrespons", "java:128", "xml", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "abstractajaxrespons", "writecompon", "abstract", "ajax", "respons", "write", "compon", "abstractajaxrespons", "java:218", "abstract", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "abstractajaxrespons", "writeto", "abstract", "ajax", "respons", "write", "abstractajaxrespons", "java:150", "abstract", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "ajaxrequesthandl", "respond", "ajax", "request", "handler", "ajaxrequesthandl", "java:359", "ajax", "request", "handler", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "request", "cycl", "handlerexecutor", "respond", "handler", "executor", "requestcycl", "java:865", "request", "cycl", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:64", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:97", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "execut", "request", "cycl", "requestcycl", "java:265", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:222", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:293", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "ws", "abstractupgradefilt", "processrequestcycl", "abstract", "upgrad", "filter", "process", "request", "cycl", "abstractupgradefilt", "java:59", "abstract", "upgrad", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:203", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:284", "wicket", "filter", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "servlet", "handler", "cachedchain", "dofilt", "cach", "chain", "filter", "servlethandl", "java:1652", "servlet", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "dohandl", "servlet", "handler", "handl", "servlethandl", "java:585", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:143", "scope", "handler", "at", "org", "eclips", "jetti", "secur", "securityhandl", "handl", "secur", "handler", "securityhandl", "java:577", "secur", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "dohandl", "session", "handler", "handl", "sessionhandl", "java:223", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "dohandl", "context", "handler", "handl", "contexthandl", "java:1125", "context", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "doscop", "servlet", "handler", "scope", "servlethandl", "java:515", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "doscop", "session", "handler", "scope", "sessionhandl", "java:185", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "doscop", "context", "handler", "scope", "contexthandl", "java:1059", "context", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:141", "scope", "handler", "at", "org", "eclips", "jetti", "server", "handler", "handlerwrapp", "handl", "handler", "wrapper", "handlerwrapp", "java:97", "handler", "wrapper", "at", "org", "eclips", "jetti", "server", "server", "handl", "server", "java:497", "at", "org", "eclips", "jetti", "server", "httpchannel", "handl", "http", "channel", "httpchannel", "java:310", "http", "channel", "at", "org", "eclips", "jetti", "server", "httpconnect", "onfil", "http", "connect", "fillabl", "httpconnect", "java:248", "http", "connect", "at", "org", "eclips", "jetti", "io", "abstractconnect", "abstract", "connect", "run", "abstractconnect", "java:540", "abstract", "connect", "at", "org", "eclips", "jetti", "util", "thread", "queuedthreadpool", "runjob", "queu", "thread", "pool", "run", "job", "queuedthreadpool", "java:620", "queu", "thread", "pool", "at", "org", "eclips", "jetti", "util", "thread", "queuedthreadpool", "queu", "thread", "pool", "ru", "code"], "B_title": "avoid to search component resolvers inside transparent containers", "B_clean_title": ["avoid", "search", "compon", "resolv", "insid", "transpar", "contain"]},
{"A_title": "Component queuing breaks with html tags that dont require close tag.Component queuing try to skip to close tag also for those tags that dont have one. This leads to a EmptyStackException (see ArrayListStack#peek).", "A_clean_title": ["compon", "queu", "break", "html", "tag", "that", "dont", "requir", "close", "tag", "compon", "queu", "tri", "skip", "close", "tag", "also", "those", "tag", "that", "dont", "have", "one", "thi", "lead", "emptystackexcept", "empti", "stack", "except", "see", "arrayliststack", "array", "list", "stack", "peek"], "B_title": "Component queuing breaks with html tags that dont require close tag.", "B_clean_title": ["compon", "queu", "break", "html", "tag", "that", "dont", "requir", "close", "tag"]},
{"A_title": "SimplexSolver not working as expected?I guess (but I could be wrong) that SimplexSolver does not always return the optimal solution nor satisfies all the constraints... Consider this LP: max: 0.8 x0 + 0.2 x1 + 0.7 x2 + 0.3 x3 + 0.6 x4 + 0.4 x5; r1: x0 + x2 + x4 = 23.0; r2: x1 + x3 + x5 = 23.0; r3: x0 >= 10.0; r4: x2 >= 8.0; r5: x4 >= 5.0; LPSolve returns 25.8 with x0 = 10.0 x1 = 0.0 x2 = 8.0 x3 = 0.0 x4 = 5.0 x5 = 23.0; The same LP expressed in Apache commons math is: LinearObjectiveFunction f = new LinearObjectiveFunction(new double   0.8 0.2 0.7 0.3 0.6 0.4   0 ); Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>(); constraints.add(new LinearConstraint(new double   1 0 1 0 1 0   Relationship.EQ 23.0)); constraints.add(new LinearConstraint(new double   0 1 0 1 0 1   Relationship.EQ 23.0)); constraints.add(new LinearConstraint(new double   1 0 0 0 0 0   Relationship.GEQ 10.0)); constraints.add(new LinearConstraint(new double   0 0 1 0 0 0   Relationship.GEQ 8.0)); constraints.add(new LinearConstraint(new double   0 0 0 0 1 0   Relationship.GEQ 5.0)); RealPointValuePair solution = new SimplexSolver().optimize(f constraints GoalType.MAXIMIZE true); that returns 22.20 with x0 = 15.0 x1 = 23.0 x2 = 8.0 x3 = 0.0 x4 = 0.0 x5 = 0.0; Is it possible SimplexSolver is buggy that way? The returned value is 22.20 instead of 25.8 and the last constraint (x4 >= 5.0) is not satisfied... Am I using the interface wrongly?", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "guess", "but", "could", "wrong", "that", "simplexsolv", "simplex", "solver", "not", "alway", "return", "optim", "solut", "nor", "satisfi", "all", "constraint", "consid", "thi", "lp", "max", "x0", "x1", "x2", "x3", "x4", "x5", "r1", "x0", "x2", "x4", "23", "r2", "x1", "x3", "x5", "23", "r3", "x0", "10", "r4", "x2", "r5", "x4", "lpsolv", "lp", "solv", "return", "25", "x0", "10", "x1", "x2", "x3", "x4", "x5", "23", "same", "lp", "express", "apach", "common", "math", "linearobjectivefunct", "linear", "object", "function", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "constraint", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "23", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "23", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "10", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "realpointvaluepair", "real", "point", "valu", "pair", "solut", "new", "simplexsolv", "simplex", "solver", "optim", "constraint", "goaltyp", "maxim", "goal", "type", "true", "that", "return", "22", "20", "x0", "15", "x1", "23", "x2", "x3", "x4", "x5", "it", "possibl", "simplexsolv", "simplex", "solver", "buggi", "that", "way", "return", "valu", "22", "20", "instead", "25", "last", "constraint", "x4", "not", "satisfi", "am", "interfac", "wrongli"], "B_title": "fixed an error leading the simplex solver to compute the right solution but return another one JIRA: MATH-286", "B_clean_title": ["fix", "error", "lead", "simplex", "solver", "comput", "right", "solut", "but", "return", "anoth", "one", "jira", "math", "286"]},
{"A_title": "ArgumentCaptor.fromClasss return type should match a parameterized typeArgumentCaptor.fromClasss return type should match a parameterized type. I.e. the expression ArgumentCaptor.fromClass(Class<S>) should be of type ArgumentCaptor<U> where S is a subtype of U. It should type check.", "A_clean_title": ["argumentcaptor", "fromclasss", "argument", "captor", "classs", "return", "type", "match", "parameter", "typeargumentcaptor", "fromclasss", "type", "argument", "captor", "classs", "return", "type", "match", "parameter", "type", "express", "argumentcaptor", "fromclass", "argument", "captor", "class", "class", "type", "argumentcaptor", "argument", "captor", "where", "subtyp", "it", "type", "check"], "B_title": "Fixed issue 200 For some weird reason when we had inherited generics sometimes the cglib proxy does not behave like java proxy would. Fixed in Mockito code.", "B_clean_title": ["fix", "issu", "200", "some", "weird", "reason", "when", "we", "had", "inherit", "gener", "sometim", "cglib", "proxi", "not", "behav", "like", "java", "proxi", "would", "fix", "mockito", "code"]},
{"A_title": "Url cant parse urls with username and passwordUrl tries to parse the password as the portnumber because its after the : resulting in the following exception: java.lang.NumberFormatException: For input string: 23dc429c-4ffa-4e99-8e24-984571f4c3b6@digdag-rest-dev2.topicusonderwijs.nl java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) java.lang.Integer.parseInt(Integer.java:492) java.lang.Integer.parseInt(Integer.java:527) org.apache.wicket.request.Url.parse(Url.java:276) org.apache.wicket.request.Url.parse(Url.java:192) org.apache.wicket.protocol.http.servlet.ServletWebResponse.encodeRedirectURL(ServletWebResponse.java:212) org.apache.wicket.protocol.http.servlet.ServletWebResponse.sendRedirect(ServletWebResponse.java:236) org.apache.wicket.protocol.http.BufferedWebResponse SendRedirectAction.invoke(BufferedWebResponse.java:400) org.apache.wicket.protocol.http.BufferedWebResponse.writeTo(BufferedWebResponse.java:588) org.apache.wicket.protocol.http.HeaderBufferingWebResponse.stopBuffering(HeaderBufferingWebResponse.java:60) org.apache.wicket.protocol.http.HeaderBufferingWebResponse.flush(HeaderBufferingWebResponse.java:97) org.apache.wicket.protocol.http.WicketFilter.processRequestCycle(WicketFilter.java:269) org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:201) org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:282)", "A_clean_title": ["url", "cant", "pars", "url", "usernam", "passwordurl", "password", "url", "tri", "pars", "password", "as", "portnumb", "becaus", "it", "after", "result", "follow", "except", "java", "lang", "numberformatexcept", "number", "format", "except", "input", "string", "23dc429c", "4ffa", "4e99", "8e24", "984571f4c3b6", "digdag", "rest", "dev2", "topicusonderwij", "nl", "java", "lang", "numberformatexcept", "forinputstr", "number", "format", "except", "input", "string", "numberformatexcept", "java:65", "number", "format", "except", "java", "lang", "integ", "parseint", "pars", "int", "integ", "java:492", "java", "lang", "integ", "parseint", "pars", "int", "integ", "java:527", "org", "apach", "wicket", "request", "url", "pars", "url", "java:276", "org", "apach", "wicket", "request", "url", "pars", "url", "java:192", "org", "apach", "wicket", "protocol", "http", "servlet", "servletwebrespons", "encoderedirecturl", "servlet", "web", "respons", "encod", "redirect", "url", "servletwebrespons", "java:212", "servlet", "web", "respons", "org", "apach", "wicket", "protocol", "http", "servlet", "servletwebrespons", "sendredirect", "servlet", "web", "respons", "send", "redirect", "servletwebrespons", "java:236", "servlet", "web", "respons", "org", "apach", "wicket", "protocol", "http", "bufferedwebrespons", "buffer", "web", "respons", "sendredirectact", "invok", "send", "redirect", "action", "bufferedwebrespons", "java:400", "buffer", "web", "respons", "org", "apach", "wicket", "protocol", "http", "bufferedwebrespons", "writeto", "buffer", "web", "respons", "write", "bufferedwebrespons", "java:588", "buffer", "web", "respons", "org", "apach", "wicket", "protocol", "http", "headerbufferingwebrespons", "stopbuff", "header", "buffer", "web", "respons", "stop", "buffer", "headerbufferingwebrespons", "java:60", "header", "buffer", "web", "respons", "org", "apach", "wicket", "protocol", "http", "headerbufferingwebrespons", "flush", "header", "buffer", "web", "respons", "headerbufferingwebrespons", "java:97", "header", "buffer", "web", "respons", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequestcycl", "wicket", "filter", "process", "request", "cycl", "wicketfilt", "java:269", "wicket", "filter", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:201", "wicket", "filter", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:282", "wicket", "filter"], "B_title": "Fix WICKET-5259: skip username+password when searching for portnumber", "B_clean_title": ["fix", "wicket", "5259", "skip", "username+password", "when", "search", "portnumb"]},
{"A_title": "IllegalStateException when using lowerCase/lower on a array propertyif query contain lowerCase on array property then QueryResult.getRows() throwing  IllegalStateException.  Query which causing issue   select selector_1.* from nt:unstructured AS selector_1 where ((selector_1.lcc:className = com.adobe.icc.dbforms.obj.ConditionalDataModule)) AND (LOWER(selector_1.dataDictionaryRefs) = employeedd)  If we remove LOWER function then it is working    select selector_1.* from nt:unstructured AS selector_1 where ((selector_1.lcc:className = com.adobe.icc.dbforms.obj.ConditionalDataModule)) AND (selector_1.dataDictionaryRefs = EmployeeDD)", "A_clean_title": ["illegalstateexcept", "illeg", "state", "except", "when", "lowercas", "lower", "lower", "case", "array", "propertyif", "queri", "contain", "lowercas", "lower", "case", "array", "properti", "then", "queryresult", "getrow", "queri", "result", "get", "row", "throw", "illegalstateexcept", "illeg", "state", "except", "queri", "which", "caus", "issu", "select", "selector", "nt", "unstructur", "as", "selector", "where", "lcc", "selector", "classnam", "class", "name", "com", "adob", "icc", "dbform", "obj", "conditionaldatamodul", "condit", "data", "modul", "lower", "datadictionaryref", "selector", "data", "dictionari", "ref", "employeedd", "we", "remov", "lower", "function", "then", "it", "work", "select", "selector", "nt", "unstructur", "as", "selector", "where", "lcc", "selector", "classnam", "class", "name", "com", "adob", "icc", "dbform", "obj", "conditionaldatamodul", "condit", "data", "modul", "datadictionaryref", "selector", "data", "dictionari", "ref", "employeedd", "employe", "dd"], "B_title": "IllegalStateException while trying retrieve rows information from QueryResult", "B_clean_title": ["illegalstateexcept", "illeg", "state", "except", "while", "tri", "retriev", "row", "inform", "queryresult", "queri", "result"]},
{"A_title": "missing base64/ URL encodingyesterday i showed the concept of omponents to a friend and stumled into something i dont understand and think it might be a bug.    I have a small panelcompoment that holds a searchform (textfield + submit) nothing special here the code behind looks like:     @Override         public void onSubmit()                       String suchFeld = getSuchfeld();             if(suchFeld.length()>0)                              PageParameters params = new PageParameters();                 params.add(findesuchFeld);                 setResponsePage(Suche.classparams);                          else                              setResponsePage(getPage().getClass());                         the component is put into a BasePage:    public BasePage()          ....             add(bar);         add(new SuchPanel(SuchPanel));         .....    wich is then extended by the real page:   public class Foo extends BasePage          /** Creates a new instance of Zigarren */     public Foo()             wich works all fine however if the class name contains non ascii letters (e.g:    etc.) it gives me a bug if nothing is entered into the search and the part   public class Zubehr extends BasePage          /** Creates a new instance of Zubehr */     public Zubehr()         setResponsePage(getPage().getClass()); comes to action the trouble is that the page might have the URL: ?wicket:bookmarkablePage=:de.pages.Zubeh%C3%B6r but the form tries to go to :  wicket:bookmarkablePage=:de.pages.Zubeh%F6r   wich results in a CODE 404 in the App Server", "A_clean_title": ["miss", "base64", "url", "encodingyesterday", "show", "concept", "ompon", "friend", "stuml", "into", "someth", "dont", "understand", "think", "it", "might", "bug", "have", "small", "panelcompo", "that", "hold", "searchform", "textfield", "submit", "noth", "special", "here", "code", "behind", "look", "like", "overrid", "public", "void", "onsubmit", "submit", "string", "suchfeld", "such", "feld", "getsuchfeld", "get", "suchfeld", "suchfeld", "length", "such", "feld", "pageparamet", "page", "paramet", "param", "new", "pageparamet", "page", "paramet", "param", "add", "findesuchfeld", "findesuch", "feld", "setresponsepag", "set", "respons", "page", "such", "classparam", "setresponsepag", "set", "respons", "page", "getpag", "get", "page", "getclass", "get", "class", "compon", "put", "into", "basepag", "base", "page", "public", "basepag", "base", "page", "add", "bar", "add", "new", "suchpanel", "such", "panel", "suchpanel", "such", "panel", "wich", "then", "extend", "by", "real", "page", "public", "class", "foo", "extend", "basepag", "base", "page", "creat", "new", "instanc", "zigarren", "public", "foo", "wich", "work", "all", "fine", "howev", "class", "name", "contain", "non", "ascii", "letter", "etc", "it", "give", "me", "bug", "noth", "enter", "into", "search", "part", "public", "class", "zubehr", "extend", "basepag", "base", "page", "creat", "new", "instanc", "zubehr", "public", "zubehr", "setresponsepag", "set", "respons", "page", "getpag", "get", "page", "getclass", "get", "class", "come", "action", "troubl", "that", "page", "might", "have", "url", "wicket", "bookmarkablepage=", "bookmark", "page=", "de", "page", "zubeh", "c3", "b6r", "but", "form", "tri", "go", "wicket", "bookmarkablepage=", "bookmark", "page=", "de", "page", "zubeh", "f6r", "wich", "result", "code", "404", "app", "server"], "B_title": "Make sure that bookmarkable urls for classes containing non-ascii characters is encoded properly.", "B_clean_title": ["make", "sure", "that", "bookmark", "url", "class", "contain", "non", "ascii", "charact", "encod", "properli"]},
{"A_title": "The LinearConstraintSet shall return its constraints in a deterministic wayAs previously discussed on the mailinglist the LinearConstraintSet should return its internally stored LinearConstraints in the same iteration order as they have been provided via its constructor.  This ensures that the execution of the same linear problem results in the same results each time it is executed. This is especially important when linear problems are loaded from a file e.g. mps format and makes it simpler to debug problems and compare with other solvers which do the same thing.", "A_clean_title": ["linearconstraintset", "linear", "constraint", "set", "shall", "return", "it", "constraint", "determinist", "waya", "way", "as", "previous", "discuss", "mailinglist", "linearconstraintset", "linear", "constraint", "set", "return", "it", "intern", "store", "linearconstraint", "linear", "constraint", "same", "iter", "order", "as", "they", "have", "been", "provid", "via", "it", "constructor", "thi", "ensur", "that", "execut", "same", "linear", "problem", "result", "same", "result", "each", "time", "it", "execut", "thi", "especi", "import", "when", "linear", "problem", "are", "load", "file", "mp", "format", "make", "it", "simpler", "debug", "problem", "compar", "other", "solver", "which", "same", "thing"], "B_title": "LinearConstraintSet returns now the LinearConstraints in the same order as they have been added.", "B_clean_title": ["linearconstraintset", "linear", "constraint", "set", "return", "now", "linearconstraint", "linear", "constraint", "same", "order", "as", "they", "have", "been", "ad"]},
{"A_title": "Sysview import of single valued mv property creates sv propertySee test in filevault 0.  it imports a multivalue property that only has 1 value via 1. the same test succeeds in jackrabbit 2.0 but fails in oak 1.3.14  0 https://github.com/apache/jackrabbit-filevault/blob/jackrabbit-filevault-3.1.26/vault-core/src/test/java/org/apache/jackrabbit/vault/packaging/integration/TestUserContentPackage.java#L297-L326 1 https://github.com/apache/jackrabbit-filevault/blob/jackrabbit-filevault-3.1.26/vault-core/src/main/java/org/apache/jackrabbit/vault/fs/impl/io/JcrSysViewTransformer.java#L146-L148", "A_clean_title": ["sysview", "import", "singl", "valu", "mv", "properti", "creat", "sv", "propertyse", "properti", "see", "test", "filevault", "it", "import", "multivalu", "properti", "that", "onli", "ha", "valu", "via", "same", "test", "succe", "jackrabbit", "but", "fail", "oak", "14", "http", "filevault", "filevault", "blob", "jackrabbit", "java", "github", "com", "apach", "jackrabbit", "26", "vault", "core", "src", "test", "java", "org", "apach", "jackrabbit", "vault", "packag", "integr", "testusercontentpackag", "test", "user", "content", "packag", "l297", "l326", "http", "filevault", "filevault", "blob", "jackrabbit", "java", "github", "com", "apach", "jackrabbit", "26", "vault", "core", "src", "main", "java", "org", "apach", "jackrabbit", "vault", "fs", "impl", "io", "jcrsysviewtransform", "jcr", "sy", "view", "transform", "l146", "l148"], "B_title": ": Sysview import of single valued mv property creates sv property", "B_clean_title": ["sysview", "import", "singl", "valu", "mv", "properti", "creat", "sv", "properti"]},
{"A_title": "ODE integrator goes past specified end of integration rangeEnd of integration range in ODE solving is handled as an event. In some cases numerical accuracy in events detection leads to error in events location. The following test case shows the end event is not handled properly and an integration that should cover a 60s range in fact covers a 160s range more than twice the specified range.    public void testMissedEvent() throws IntegratorException DerivativeException            final double t0 = 1878250320.0000029;           final double t =  1878250379.9999986;           FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations()                           public int getDimension()                  return 1;                                       public void computeDerivatives(double t double y double yDot)                 throws DerivativeException                  yDot0 = y0 * 1.0e-6;                      ;          DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0 100.0                                                                                1.0e-10 1.0e-10);          double y =  1.0 ;         integrator.setInitialStepSize(60.0);         double finalT = integrator.integrate(ode t0 y t y);         Assert.assertEquals(t finalT 1.0e-6);", "A_clean_title": ["ode", "integr", "goe", "past", "specifi", "end", "integr", "rangeend", "rang", "end", "integr", "rang", "ode", "solv", "handl", "as", "event", "some", "case", "numer", "accuraci", "event", "detect", "lead", "error", "event", "locat", "follow", "test", "case", "show", "end", "event", "not", "handl", "properli", "integr", "that", "cover", "60", "rang", "fact", "cover", "160", "rang", "more", "than", "twice", "specifi", "rang", "public", "void", "testmissedev", "test", "miss", "event", "throw", "integratorexcept", "integr", "except", "derivativeexcept", "deriv", "except", "final", "doubl", "t0", "1878250320", "0000029", "final", "doubl", "1878250379", "9999986", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "ode", "new", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "public", "int", "getdimens", "get", "dimens", "return", "public", "void", "computederiv", "comput", "deriv", "doubl", "doubl", "doubl", "ydot", "dot", "throw", "derivativeexcept", "deriv", "except", "ydot0", "dot0", "y0", "0e", "dormandprince853integr", "dormand", "prince853integr", "integr", "new", "dormandprince853integr", "dormand", "prince853integr", "100", "10", "0e", "10", "0e", "doubl", "integr", "setinitialsteps", "set", "initi", "step", "size", "60", "doubl", "finalt", "final", "integr", "integr", "ode", "t0", "assert", "assertequ", "assert", "equal", "finalt", "final", "0e"], "B_title": "Fixed an error in events handling in ODE solvers. In some rare cases events occurring close to a step start were handled without truncating the step making them appear as is they occurred close to the step end JIRA: MATH-358", "B_clean_title": ["fix", "error", "event", "handl", "ode", "solver", "some", "rare", "case", "event", "occur", "close", "step", "start", "were", "handl", "without", "truncat", "step", "make", "them", "appear", "as", "they", "occur", "close", "step", "end", "jira", "math", "358"]},
{"A_title": "XsltOutputTransformerContainer incorrectly claims markup type xslXsltOutputTransformerContainer return xsl from getMarkupType() forcing is on all contained components.  If the components in org.apache.wicket.markup.outputTransformer.Page_1 are reordered (XsltOutputTransformerContainer coming first) the test fails because no markup for SimpleBorder can be found.", "A_clean_title": ["xsltoutputtransformercontain", "xslt", "output", "transform", "contain", "incorrectli", "claim", "markup", "type", "xslxsltoutputtransformercontain", "xsl", "xslt", "output", "transform", "contain", "return", "xsl", "getmarkuptyp", "get", "markup", "type", "forc", "all", "contain", "compon", "compon", "org", "apach", "wicket", "markup", "outputtransform", "output", "transform", "page", "are", "reorder", "xsltoutputtransformercontain", "xslt", "output", "transform", "contain", "come", "first", "test", "fail", "becaus", "no", "markup", "simplebord", "simpl", "border", "found"], "B_title": "XsltOutputTransformerContainer not necessarily has xsl markup type", "B_clean_title": ["xsltoutputtransformercontain", "xslt", "output", "transform", "contain", "not", "necessarili", "ha", "xsl", "markup", "type"]},
{"A_title": "org.apache.wicket.util.string.StringValue#equals brokenThe #equals implementation for org.apache.wicket.util.string.StringValue is broken. The following throws an exception instead of just printing false:  StringValue val = StringValue.valueOf(bla Locale.FRANCE); StringValue val2 = StringValue.valueOf(bla Locale.CANADA); System.out.println(val.equals(val2));   This part of #equals Objects.isEqual(locale stringValue.locale)  should probably be replaced with something like (locale == stringValue.locale || (locale != null && locale.equals(stringValue.locale))  -> Objects.isEqual is not suitable to determine equality of Locale", "A_clean_title": ["org", "apach", "wicket", "util", "string", "stringvalu", "string", "valu", "equal", "brokenth", "broken", "equal", "implement", "org", "apach", "wicket", "util", "string", "stringvalu", "string", "valu", "broken", "follow", "throw", "except", "instead", "just", "print", "fals", "stringvalu", "string", "valu", "val", "stringvalu", "valueof", "string", "valu", "valu", "bla", "local", "franc", "stringvalu", "string", "valu", "val2", "stringvalu", "valueof", "string", "valu", "valu", "bla", "local", "canada", "system", "out", "println", "val", "equal", "val2", "thi", "part", "equal", "object", "isequ", "equal", "local", "stringvalu", "local", "string", "valu", "probabl", "replac", "someth", "like", "local", "stringvalu", "local", "string", "valu", "local", "null", "local", "equal", "stringvalu", "local", "string", "valu", "object", "isequ", "equal", "not", "suitabl", "determin", "equal", "local"], "B_title": "fixed equals for different locales", "B_clean_title": ["fix", "equal", "differ", "local"]},
{"A_title": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situationsIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK it would be nice if DateFormatUtils was smart enough to detect/resolve this problem. For example the following unit test fails:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;      // more commonly constructed with: cal = new GregorianCalendar(2009 9 16 8 42 16)     // for the unit test to work in any time zone constructing with GMT-8 rather than default locale time zone     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);       FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));      However this unit test passes:    public void testFormat_CalendarIsoMsZulu()      final String dateTime = 2009-10-16T16:42:16.000Z;     GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(GMT-8));     cal.clear();     cal.set(2009 9 16 8 42 16);     cal.getTime();      FastDateFormat format = FastDateFormat.getInstance(yyyy-MM-ddTHH:mm:ss.SSSZ TimeZone.getTimeZone(GMT));     assertEquals(dateTime dateTime format.format(cal));", "A_clean_title": ["dateformatutil", "format", "date", "format", "util", "not", "correctli", "chang", "calendar", "timezon", "time", "zone", "certain", "situationsif", "situat", "calendar", "object", "construct", "certain", "way", "call", "calendar", "settimezon", "set", "time", "zone", "not", "correctli", "chang", "calendar", "field", "call", "calenar", "gettim", "get", "time", "seem", "fix", "thi", "problem", "while", "thi", "probabl", "bug", "jdk", "it", "would", "nice", "dateformatutil", "date", "format", "util", "wa", "smart", "enough", "detect", "resolv", "thi", "problem", "exampl", "follow", "unit", "test", "fail", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "more", "commonli", "construct", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "2009", "16", "42", "16", "unit", "test", "work", "ani", "time", "zone", "construct", "gmt", "rather", "than", "default", "local", "time", "zone", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal", "howev", "thi", "unit", "test", "pass", "public", "void", "testformat", "calendarisomszulu", "test", "format", "calendar", "iso", "ms", "zulu", "final", "string", "datetim", "date", "time", "2009", "10", "16t16:42:16", "000z", "gregoriancalendar", "gregorian", "calendar", "cal", "new", "gregoriancalendar", "gregorian", "calendar", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "cal", "clear", "cal", "set", "2009", "16", "42", "16", "cal", "gettim", "get", "time", "fastdateformat", "fast", "date", "format", "format", "fastdateformat", "getinst", "fast", "date", "format", "get", "instanc", "yyyi", "mm", "ddthh", "dd", "thh", "mm", "ss", "sssz", "timezon", "gettimezon", "time", "zone", "get", "time", "zone", "gmt", "assertequ", "assert", "equal", "datetim", "date", "time", "datetim", "date", "time", "format", "format", "cal"], "B_title": "Fixing LANG-538 - you need to call getTime() on a calendar sometimes to get it in the right state otherwise the timezone gets out of whack.", "B_clean_title": ["fix", "lang", "538", "you", "need", "call", "gettim", "get", "time", "calendar", "sometim", "get", "it", "right", "state", "otherwis", "timezon", "get", "out", "whack"]},
{"A_title": "MockTableOperations.deleteRow does not handle null for start or end keysThe deleteRow function does not check for null values for start or end keys. These null values are passed down into key constructor which will throw a NullPointerException: java.lang.NullPointerException at org.apache.accumulo.core.data.Key.<init>(Key.java:103) at org.apache.accumulo.core.client.mock.MockTableOperations.deleteRows(MockTableOperations.java:315)  The API semantics dictate: if (start == null ) then start == Text() if (end == null ) then end == maxKey()", "A_clean_title": ["mocktableoper", "deleterow", "mock", "tabl", "oper", "delet", "row", "not", "handl", "null", "start", "or", "end", "keysth", "key", "deleterow", "delet", "row", "function", "not", "check", "null", "valu", "start", "or", "end", "key", "these", "null", "valu", "are", "pass", "down", "into", "key", "constructor", "which", "will", "throw", "nullpointerexcept", "null", "pointer", "except", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "accumulo", "core", "data", "key", "init", "key", "java:103", "at", "org", "apach", "accumulo", "core", "client", "mock", "mocktableoper", "deleterow", "mock", "tabl", "oper", "delet", "row", "mocktableoper", "java:315", "mock", "tabl", "oper", "api", "semant", "dictat", "start", "null", "then", "start", "text", "end", "null", "then", "end", "maxkey", "max", "key"], "B_title": "added logic to handle null keys for MockTableOperations.deleteRow", "B_clean_title": ["ad", "logic", "handl", "null", "key", "mocktableoper", "deleterow", "mock", "tabl", "oper", "delet", "row"]},
{"A_title": "IE8 error: Object doesnt support this actionNone", "A_clean_title": ["ie8", "error", "object", "doesnt", "support", "thi", "actionnon", "action", "none"], "B_title": "a really terrible fix for issue 291 fixes issue 291", "B_clean_title": ["realli", "terribl", "fix", "issu", "291", "fix", "issu", "291"]},
{"A_title": "AsyncIndexUpdate unable to cope with missing checkpoint refThe async index uses a checkpoint reference stored under the _:async_ hidden node as a base for running the index diff. It might happen that this reference is stale (pointing to checkpoints that no longer exist) so the async indexer logs a warning that it will reindex everything and will start its work. The trouble is with the #mergeWithConcurrencyCheck which does not cope well with this scenario. Even if the ref checkpoint is null it will throw a concurrent update exception which will be logged as a misleading debug log _Concurrent update detected in the async index update_.  Overall the code looks stuck in an endless reindexing loop.  code *WARN* pool-9-thread-1 org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate Failed to retrieve previously indexed checkpoint 569d8847-ebb6-4832-a55f-2b0b1a32ae71; re-running the initial async index update *DEBUG* pool-9-thread-1 org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate Concurrent update detected in the async index update code", "A_clean_title": ["asyncindexupd", "async", "index", "updat", "unabl", "cope", "miss", "checkpoint", "refth", "ref", "async", "index", "use", "checkpoint", "refer", "store", "under", "async", "hidden", "node", "as", "base", "run", "index", "diff", "it", "might", "happen", "that", "thi", "refer", "stale", "point", "checkpoint", "that", "no", "longer", "exist", "so", "async", "index", "log", "warn", "that", "it", "will", "reindex", "everyth", "will", "start", "it", "work", "troubl", "mergewithconcurrencycheck", "merg", "concurr", "check", "which", "not", "cope", "well", "thi", "scenario", "even", "ref", "checkpoint", "null", "it", "will", "throw", "concurr", "updat", "except", "which", "will", "log", "as", "mislead", "debug", "log", "concurr", "updat", "detect", "async", "index", "updat", "overal", "code", "look", "stuck", "endless", "reindex", "loop", "code", "warn", "pool", "thread", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "async", "index", "updat", "fail", "retriev", "previous", "index", "checkpoint", "569d8847", "ebb6", "4832", "a55f", "2b0b1a32ae71", "re", "run", "initi", "async", "index", "updat", "debug", "pool", "thread", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "async", "index", "updat", "concurr", "updat", "detect", "async", "index", "updat", "code"], "B_title": "AsyncIndexUpdate unable to cope with missing checkpoint ref", "B_clean_title": ["asyncindexupd", "async", "index", "updat", "unabl", "cope", "miss", "checkpoint", "ref"]},
{"A_title": "Possibility of overflow in file length calculationIn OakDirectory the length of a file is calculated in following way  code:title=OakDirectory|linenumbers=true         public OakIndexFile(String name NodeBuilder file)              ...             this.blobSize = determineBlobSize(file);             this.blob = new byteblobSize;              PropertyState property = file.getProperty(JCR_DATA);             if (property != null && property.getType() == BINARIES)                  this.data = newArrayList(property.getValue(BINARIES));              else                  this.data = newArrayList();                           this.length = data.size() * blobSize;             if (!data.isEmpty())                  Blob last = data.get(data.size() - 1);                 this.length -= blobSize - last.length();              code  In above calculation its possible to have an overflow in  bq. this.length = data.size() * blobSize;  As multiplication of two integers result in an integer 1  1 http://stackoverflow.com/questions/12861893/casting-result-of-multiplication-two-positive-integers-to-long-is-negative-value", "A_clean_title": ["possibl", "overflow", "file", "length", "calculationin", "calcul", "oakdirectori", "oak", "directori", "length", "file", "calcul", "follow", "way", "code", "title=oakdirectory|linenumbers=tru", "title=oak", "directory|linenumbers=tru", "public", "oakindexfil", "oak", "index", "file", "string", "name", "nodebuild", "node", "builder", "file", "thi", "blobsiz", "blob", "size", "determineblobs", "determin", "blob", "size", "file", "thi", "blob", "new", "byteblobs", "byteblob", "size", "propertyst", "properti", "state", "properti", "file", "getproperti", "get", "properti", "jcr", "data", "properti", "null", "properti", "gettyp", "get", "type", "binari", "thi", "data", "newarraylist", "new", "array", "list", "properti", "getvalu", "get", "valu", "binari", "thi", "data", "newarraylist", "new", "array", "list", "thi", "length", "data", "size", "blobsiz", "blob", "size", "data", "isempti", "empti", "blob", "last", "data", "get", "data", "size", "thi", "length", "blobsiz", "blob", "size", "last", "length", "code", "abov", "calcul", "it", "possibl", "have", "overflow", "bq", "thi", "length", "data", "size", "blobsiz", "blob", "size", "as", "multipl", "two", "integ", "result", "integ", "http", "result", "multipl", "two", "posit", "integ", "long", "neg", "valu", "stackoverflow", "com", "question", "12861893", "cast"], "B_title": "- Possibility of overflow in file length calculation", "B_clean_title": ["possibl", "overflow", "file", "length", "calcul"]},
{"A_title": "address-controller: NPE when required parameters (address plan or type) are not setDescription:  When required parameter (addressplan or type) in address definition is not set then it cause NPE in address-controller.  https://github.com/EnMasseProject/enmasse/blob/master/address-model-lib/src/main/java/io/enmasse/address/model/v1/AddressV1Deserializer.java#L36 Steps to reproduce:    create brokered address-space brokered-space  create address without required parameter: brokered_incorrect_address.json    Automated test:  we have no automated test for that yet output from address-controller log:", "A_clean_title": ["address", "control", "npe", "when", "requir", "paramet", "address", "plan", "or", "type", "are", "not", "setdescript", "set", "descript", "when", "requir", "paramet", "addressplan", "or", "type", "address", "definit", "not", "set", "then", "it", "caus", "npe", "address", "control", "http", "model", "java", "github", "com", "enmasseproject", "enmass", "blob", "master", "address", "lib", "src", "main", "java", "io", "enmass", "address", "model", "v1", "addressv1deseri", "en", "mass", "project", "address", "v1deseri", "l36", "step", "reproduc", "creat", "broker", "address", "space", "broker", "space", "creat", "address", "without", "requir", "paramet", "json", "broker", "incorrect", "address", "autom", "test", "we", "have", "no", "autom", "test", "that", "yet", "output", "address", "control", "log"], "B_title": "Validate required fields and provide correct HTTP response on validation errors  Fixes #1082", "B_clean_title": ["valid", "requir", "field", "provid", "correct", "http", "respons", "valid", "error", "fix", "1082"]},
{"A_title": "issues with JsopBuilder.encode and .escape1) escape() escapes many characters that do not need to be escaped (>127)  2) encode() does not encode many control characters that would need to be escaped when read through a JSON parser.", "A_clean_title": ["issu", "jsopbuild", "encod", "jsop", "builder", "escape1", "escap", "escap", "mani", "charact", "that", "not", "need", "escap", "127", "encod", "not", "encod", "mani", "control", "charact", "that", "would", "need", "escap", "when", "read", "through", "json", "parser"], "B_title": "- add handling for broken surrogate pairs because they wont round-trip through UTF-8 (and some databases) otherwise", "B_clean_title": ["add", "handl", "broken", "surrog", "pair", "becaus", "they", "wont", "round", "trip", "through", "utf", "some", "databas", "otherwis"]},
{"A_title": "MockTableOperations.tableIdMap always returns tableName as IDNoticed and fixed this during ACCUMULO-378.  An exception was thrown unexpectedly when trying to use tableIdMap with a MockInstance. Lift fix from 93c8bddc71d1ee190649eeab263205185d75421c into main tree.", "A_clean_title": ["mocktableoper", "tableidmap", "mock", "tabl", "oper", "tabl", "id", "map", "alway", "return", "tablenam", "tabl", "name", "as", "idnot", "id", "notic", "fix", "thi", "dure", "accumulo", "378", "except", "wa", "thrown", "unexpectedli", "when", "tri", "use", "tableidmap", "tabl", "id", "map", "mockinst", "mock", "instanc", "lift", "fix", "93c8bddc71d1ee190649eeab263205185d75421c", "into", "main", "tree"], "B_title": "Return a more real tableID", "B_clean_title": ["return", "more", "real", "tableid", "tabl", "id"]},
{"A_title": "FromStringDeserializer ignores registered DeserializationProblemHandler for java.util.UUIDCulprit appears to be  lines 155-161 of FromStringDeserializer :  The above lines appear to show that the exception will be thrown regardless of any problem handling logic.  Test Case:   The handler handles the issue properly; but an exception is thrown anyway:", "A_clean_title": ["fromstringdeseri", "string", "deseri", "ignor", "regist", "deserializationproblemhandl", "deseri", "problem", "handler", "java", "util", "uuidculprit", "uuid", "culprit", "appear", "line", "155", "161", "fromstringdeseri", "string", "deseri", "abov", "line", "appear", "show", "that", "except", "will", "thrown", "regardless", "ani", "problem", "handl", "logic", "test", "case", "handler", "handl", "issu", "properli", "but", "except", "thrown", "anyway"], "B_title": "Fix #1629", "B_clean_title": ["fix", "1629"]},
{"A_title": "StackOverflowError in Dynamic StdKeySerializerThere seem to be a problem (checked and doesnt seem to be fixed in latest version) with the serialize method of the Dynamic static class of the StdKeySerializer.   The problem comes from the fact that when  ser is null  the new ser returned by _findAndAddDynamic is incorrectly filled.  So say we are in  ser#1  ser#1._dynamicSerializers now has the correct PropertySerializerMap$Single . However result.serializer._dynamicSerializers has PropertySerializerMap$Empty . Therefore a new call with that result ser#2 is made which ends up creating an infinite loop. Possible fix:    replace  If Im mistaken please let me know but It seems obvious when debugging that somethings is not working as intended", "A_clean_title": ["stackoverflowerror", "stack", "overflow", "error", "dynam", "stdkeyserializerther", "std", "key", "serial", "there", "seem", "problem", "check", "doesnt", "seem", "fix", "latest", "version", "serial", "method", "dynam", "static", "class", "stdkeyseri", "std", "key", "serial", "problem", "come", "fact", "that", "when", "ser", "null", "new", "ser", "return", "by", "findandadddynam", "find", "add", "dynam", "incorrectli", "fill", "so", "say", "we", "are", "ser", "ser", "dynamicseri", "dynam", "serial", "now", "ha", "correct", "propertyserializermap", "properti", "serial", "map", "singl", "howev", "result", "serial", "dynamicseri", "dynam", "serial", "ha", "propertyserializermap", "properti", "serial", "map", "empti", "therefor", "new", "call", "that", "result", "ser", "made", "which", "end", "up", "creat", "infinit", "loop", "possibl", "fix", "replac", "im", "mistaken", "pleas", "let", "me", "know", "but", "it", "seem", "obviou", "when", "debug", "that", "someth", "not", "work", "as", "intend"], "B_title": "Fix #1679", "B_clean_title": ["fix", "1679"]},
{"A_title": "MountedMapper.mapHandler ruins Links inside mounted pages appending parameters wicket-ajax and wicket-ajax-baseurlWith the last commit n 1166194 method mapHandler has been added to MountedMapper class in order to solve WICKET-4014. Unfortunately this method seems to ruin Link url inside mounted page (for example home page) if this page uses AJAX. mapHandler modifies Link url appending parameters wicket-ajax and wicket-ajax-baseurl to it. In this way when we click Link we get an error from browser like this:          This XML file does not appear to have any style information associated with it. The document tree is shown below.       <ajax-response><redirect>wicket/page?41</redirect></ajax-response>   The error message is the same for Firefox and Chromium. See attached quickstart.  Warning: as Im writing this issue Wicket snapshot is not affected yet by this bug so you have to run quickstart with the last source from repository.", "A_clean_title": ["mountedmapp", "maphandl", "mount", "mapper", "map", "handler", "ruin", "link", "insid", "mount", "page", "append", "paramet", "wicket", "ajax", "wicket", "ajax", "baseurlwith", "baseurl", "last", "commit", "n", "1166194", "method", "maphandl", "map", "handler", "ha", "been", "ad", "mountedmapp", "mount", "mapper", "class", "order", "solv", "wicket", "4014", "unfortun", "thi", "method", "seem", "ruin", "link", "url", "insid", "mount", "page", "exampl", "home", "page", "thi", "page", "use", "ajax", "maphandl", "map", "handler", "modifi", "link", "url", "append", "paramet", "wicket", "ajax", "wicket", "ajax", "baseurl", "it", "thi", "way", "when", "we", "click", "link", "we", "get", "error", "browser", "like", "thi", "thi", "xml", "file", "not", "appear", "have", "ani", "style", "inform", "associ", "it", "document", "tree", "shown", "below", "ajax", "respons", "redirect", "wicket", "page", "41", "redirect", "respons", "ajax", "error", "messag", "same", "firefox", "chromium", "see", "attach", "quickstart", "warn", "as", "im", "write", "thi", "issu", "wicket", "snapshot", "not", "affect", "yet", "by", "thi", "bug", "so", "you", "have", "run", "quickstart", "last", "sourc", "repositori"], "B_title": "Dont create an empty PageParameters if the original is null.", "B_clean_title": ["dont", "creat", "empti", "pageparamet", "page", "paramet", "origin", "null"]},
{"A_title": "during ODE integration the last event in a pair of very close event may not be detectedWhen an events follows a previous one very closely it may be ignored. The occurrence of the bug depends on the side of the bracketing interval that was selected. For example consider a switching function that is increasing around first event around t = 90 reaches its maximum and is decreasing around the second event around t = 135. If an integration step spans from 67.5 and 112.5 the switching function values at start and end of step will  have opposite signs so the first event will be detected. The solver will find the event really occurs at 90.0 and will therefore truncate the step at 90.0. The next step will start from where the first step ends i.e. it will start at 90.0. Lets say this step spans from 90.0 to 153.0. The switching function switches once again in this step. If the solver for the first event converged to a value slightly before 90.0 (say 89.9999999) then the switch will not be detected because g(89.9999999) and g(153.0) are both negative. This bug was introduced as of r781157 (2009-06-02) when special handling of events very close to step start was added.", "A_clean_title": ["dure", "ode", "integr", "last", "event", "pair", "veri", "close", "event", "may", "not", "detectedwhen", "detect", "when", "event", "follow", "previou", "one", "veri", "close", "it", "may", "ignor", "occurr", "bug", "depend", "side", "bracket", "interv", "that", "wa", "select", "exampl", "consid", "switch", "function", "that", "increas", "around", "first", "event", "around", "90", "reach", "it", "maximum", "decreas", "around", "second", "event", "around", "135", "integr", "step", "span", "67", "112", "switch", "function", "valu", "at", "start", "end", "step", "will", "have", "opposit", "sign", "so", "first", "event", "will", "detect", "solver", "will", "find", "event", "realli", "occur", "at", "90", "will", "therefor", "truncat", "step", "at", "90", "next", "step", "will", "start", "where", "first", "step", "end", "it", "will", "start", "at", "90", "let", "say", "thi", "step", "span", "90", "153", "switch", "function", "switch", "onc", "again", "thi", "step", "solver", "first", "event", "converg", "valu", "slightli", "befor", "90", "say", "89", "9999999", "then", "switch", "will", "not", "detect", "becaus", "89", "9999999", "153", "are", "both", "neg", "thi", "bug", "wa", "introduc", "as", "r781157", "2009", "06", "02", "when", "special", "handl", "event", "veri", "close", "step", "start", "wa", "ad"], "B_title": "Fixed an error in handling of very close events during ODE integration JIRA: MATH-322", "B_clean_title": ["fix", "error", "handl", "veri", "close", "event", "dure", "ode", "integr", "jira", "math", "322"]},
{"A_title": "ResizableDoubleArray is not thread-safe yet has some synch. methodsResizableDoubleArray has several synchronised methods but is not thread-safe because class variables are not always accessed using the lock.  Is the class supposed to be thread-safe?  If so all accesses (read and write) need to be synch.  If not the synch. qualifiers could be dropped.  In any case the protected fields need to be made private.", "A_clean_title": ["resizabledoublearray", "resiz", "doubl", "array", "not", "thread", "safe", "yet", "ha", "some", "synch", "methodsresizabledoublearray", "method", "resiz", "doubl", "array", "ha", "sever", "synchronis", "method", "but", "not", "thread", "safe", "becaus", "class", "variabl", "are", "not", "alway", "access", "lock", "class", "suppos", "thread", "safe", "so", "all", "access", "read", "write", "need", "synch", "not", "synch", "qualifi", "could", "drop", "ani", "case", "protect", "field", "need", "made", "privat"], "B_title": "Removed broken and deprecated synchronization support in ResizableDoubleArray.", "B_clean_title": ["remov", "broken", "deprec", "synchron", "support", "resizabledoublearray", "resiz", "doubl", "array"]},
{"A_title": "NPE in RecordIdMapRecordIdMap is not properly guarded against NPEs when calling accessors on an empty map (which is represented by keys == null.   noformat testRecordIdMap(org.apache.jackrabbit.oak.plugins.segment.RecordIdMapTest)  Time elapsed: 0.019 sec  <<< ERROR! java.lang.NullPointerException at org.apache.jackrabbit.oak.plugins.segment.RecordIdMap.size(RecordIdMap.java:100) at org.apache.jackrabbit.oak.plugins.segment.RecordIdMapTest.testRecordIdMap(RecordIdMapTest.java:64) noformat", "A_clean_title": ["npe", "recordidmaprecordidmap", "record", "id", "map", "record", "id", "map", "not", "properli", "guard", "against", "npe", "np", "es", "when", "call", "accessor", "empti", "map", "which", "repres", "by", "key", "null", "noformat", "testrecordidmap", "test", "record", "id", "map", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "recordidmaptest", "record", "id", "map", "test", "time", "elaps", "019", "sec", "error", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "recordidmap", "size", "record", "id", "map", "recordidmap", "java:100", "record", "id", "map", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "recordidmaptest", "testrecordidmap", "record", "id", "map", "test", "test", "record", "id", "map", "recordidmaptest", "java:64", "record", "id", "map", "test", "noformat"], "B_title": "NPE in RecordIdMap * Properly guard against NPE * Added test case for empty map", "B_clean_title": ["npe", "recordidmap", "record", "id", "map", "properli", "guard", "against", "npe", "ad", "test", "case", "empti", "map"]},
{"A_title": "Failing generic type resolution of generic types within nested generic fields DATACMNS-1196opened and commented It seems that the type resolution is not working properly when having nested object composition with generic type.  Example of model: constructors getters... ommited  And create instance of  Outer with  When we create an instance of  Outer which has reference to instance of Generic whose generic type is MyEnum then if we save Outer instance using MongoTemplate its persisted in db correctly converted to mongos document.   But when we try to read it from db it is mapped incorrectly back to  Outer . Field myList in instance of Inner contains a List which contains instances of String  but field elem in instance of Inner is mapped correctly and it really contains an instance of MyEnum . Seems that problem is in MongoConverter . Im attaching a simple project which is able to reproduce problem described above. In tests Im not actually storing an instance to mongo collection but rather using only MongoConverter to convert an instance to Document and than back to Outer . I dont know if workaround for this cold be writing a custom Converter . My workaround for this (in real project) was to manually convert a Document to some domain specific instance but that is really annoying.  I know that mapping from mongo types back can be tricky and sometimes type information is lost but that is not case here. For comparison Ive tried Jackson s ObjectMapper to do serialization of instance of Outer to JSON string and than de-serialize JSON on back to Outer and it seems that Jackson resolves  generic types correctly.   Affects: 1.13.8 (Ingalls SR8) 2.0 GA (Kay)  Attachments:     Backported to:  2.0.1 (Kay SR1)  1.13.9 (Ingalls SR9)", "A_clean_title": ["fail", "gener", "type", "resolut", "gener", "type", "within", "nest", "gener", "field", "datacmn", "1196open", "comment", "it", "seem", "that", "type", "resolut", "not", "work", "properli", "when", "have", "nest", "object", "composit", "gener", "type", "exampl", "model", "constructor", "getter", "ommit", "creat", "instanc", "outer", "when", "we", "creat", "instanc", "outer", "which", "ha", "refer", "instanc", "gener", "whose", "gener", "type", "myenum", "my", "enum", "then", "we", "save", "outer", "instanc", "mongotempl", "mongo", "templat", "it", "persist", "db", "correctli", "convert", "mongo", "document", "but", "when", "we", "tri", "read", "it", "db", "it", "map", "incorrectli", "back", "outer", "field", "mylist", "my", "list", "instanc", "inner", "contain", "list", "which", "contain", "instanc", "string", "but", "field", "elem", "instanc", "inner", "map", "correctli", "it", "realli", "contain", "instanc", "myenum", "my", "enum", "seem", "that", "problem", "mongoconvert", "mongo", "convert", "im", "attach", "simpl", "project", "which", "abl", "reproduc", "problem", "describ", "abov", "test", "im", "not", "actual", "store", "instanc", "mongo", "collect", "but", "rather", "onli", "mongoconvert", "mongo", "convert", "convert", "instanc", "document", "than", "back", "outer", "dont", "know", "workaround", "thi", "cold", "write", "custom", "convert", "my", "workaround", "thi", "real", "project", "wa", "manual", "convert", "document", "some", "domain", "specif", "instanc", "but", "that", "realli", "annoy", "know", "that", "map", "mongo", "type", "back", "tricki", "sometim", "type", "inform", "lost", "but", "that", "not", "case", "here", "comparison", "ive", "tri", "jackson", "objectmapp", "object", "mapper", "serial", "instanc", "outer", "json", "string", "than", "de", "serial", "json", "back", "outer", "it", "seem", "that", "jackson", "resolv", "gener", "type", "correctli", "affect", "13", "ingal", "sr8", "ga", "kay", "attach", "backport", "kay", "sr1", "13", "ingal", "sr9"], "B_title": "DATACMNS-1196 - Fixed generics lookup for nested generics in ParameterizedTypeInformation.  We now eagerly resolve a generics declaration chain which we previously - erroneously - expected GenericTypeResolver to do for us. Simplified TypeVariableTypeInformation implementation. Renamed ParameterizedTypeUnitTests to ParameterizedTypeInformationUnitTests.", "B_clean_title": ["datacmn", "1196", "fix", "gener", "lookup", "nest", "gener", "parameterizedtypeinform", "parameter", "type", "inform", "we", "now", "eagerli", "resolv", "gener", "declar", "chain", "which", "we", "previous", "erron", "expect", "generictyperesolv", "gener", "type", "resolv", "us", "simplifi", "typevariabletypeinform", "type", "variabl", "type", "inform", "implement", "renam", "parameterizedtypeunittest", "parameter", "type", "unit", "test", "parameterizedtypeinformationunittest", "parameter", "type", "inform", "unit", "test"]},
{"A_title": "StringUtils methods do not handle Unicode 2.0+ supplementary characters correctly.StringUtils.containsAny methods incorrectly matches Unicode 2.0+ supplementary characters. For example define a test fixture to be the Unicode character U+20000 where U+20000 is written in Java source as uD840uDC00 private static final String CharU20000 = uD840uDC00; private static final String CharU20001 = uD840uDC01; You can see Unicode supplementary characters correctly implemented in the JRE call: assertEquals(-1 CharU20000.indexOf(CharU20001)); But this is broken: assertEquals(false StringUtils.containsAny(CharU20000 CharU20001)); assertEquals(false StringUtils.containsAny(CharU20001 CharU20000)); This is fine: assertEquals(true StringUtils.contains(CharU20000 + CharU20001 CharU20000)); assertEquals(true StringUtils.contains(CharU20000 + CharU20001 CharU20001)); assertEquals(true StringUtils.contains(CharU20000 CharU20000)); assertEquals(false StringUtils.contains(CharU20000 CharU20001)); because the method calls the JRE to perform the match. More than you want to know:  http://java.sun.com/developer/technicalArticles/Intl/Supplementary/", "A_clean_title": ["stringutil", "string", "util", "method", "not", "handl", "unicod", "0+", "supplementari", "charact", "correctli", "stringutil", "containsani", "string", "util", "contain", "ani", "method", "incorrectli", "match", "unicod", "0+", "supplementari", "charact", "exampl", "defin", "test", "fixtur", "unicod", "charact", "u+20000", "where", "u+20000", "written", "java", "sourc", "as", "ud840udc00", "d840u", "dc00", "privat", "static", "final", "string", "charu20000", "char", "u20000", "ud840udc00", "d840u", "dc00", "privat", "static", "final", "string", "charu20001", "char", "u20001", "ud840udc01", "d840u", "dc01", "you", "see", "unicod", "supplementari", "charact", "correctli", "implement", "jre", "call", "assertequ", "assert", "equal", "charu20000", "indexof", "char", "u20000", "index", "charu20001", "char", "u20001", "but", "thi", "broken", "assertequ", "assert", "equal", "fals", "stringutil", "containsani", "string", "util", "contain", "ani", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "assertequ", "assert", "equal", "fals", "stringutil", "containsani", "string", "util", "contain", "ani", "charu20001", "char", "u20001", "charu20000", "char", "u20000", "thi", "fine", "assertequ", "assert", "equal", "true", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "charu20000", "char", "u20000", "assertequ", "assert", "equal", "true", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "charu20001", "char", "u20001", "assertequ", "assert", "equal", "true", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20000", "char", "u20000", "assertequ", "assert", "equal", "fals", "stringutil", "contain", "string", "util", "charu20000", "char", "u20000", "charu20001", "char", "u20001", "becaus", "method", "call", "jre", "perform", "match", "more", "than", "you", "want", "know", "http", "sun", "java", "com", "develop", "technicalarticl", "intl", "supplementari", "technic", "articl"], "B_title": "StringUtils methods do not handle Unicode 2.0+ supplementary characters correctly.", "B_clean_title": ["stringutil", "string", "util", "method", "not", "handl", "unicod", "0+", "supplementari", "charact", "correctli"]},
{"A_title": "ClassUtils.toClass(Object) throws NPE on null array elementsee summary", "A_clean_title": ["classutil", "toclass", "class", "util", "class", "object", "throw", "npe", "null", "array", "elementse", "summari"], "B_title": "avoid NPE in ClassUtils.toClass(Object)", "B_clean_title": ["avoid", "npe", "classutil", "toclass", "class", "util", "class", "object"]},
{"A_title": "StringResourceModel doesnt detach model in some casesWe have come across an issue with StringResourceModel not detaching the model it holds under a certain condition.  The problem is the case where the StringResourceModel is created but it is not used - for example when it is on a tab that is not displayed.  StringResourceModel is a subclass of LoadableDetachableModel and it simply implements onDetach() letting the superclass decide whether it is attached or not. The problem is that when StringResourceModel is created LoadableDetachableModel.attached will be false.  If the StringResourceModel is never read (i.e. getObject() is not called) the LoadableDetachableModel will not be marked as attached and when detach() is called onDetach() will not be called.  Therefore StringResourceModel will not call detach() on the model that it holds.", "A_clean_title": ["stringresourcemodel", "string", "resourc", "model", "doesnt", "detach", "model", "some", "casesw", "case", "we", "have", "come", "across", "issu", "stringresourcemodel", "string", "resourc", "model", "not", "detach", "model", "it", "hold", "under", "certain", "condit", "problem", "case", "where", "stringresourcemodel", "string", "resourc", "model", "creat", "but", "it", "not", "use", "exampl", "when", "it", "tab", "that", "not", "display", "stringresourcemodel", "string", "resourc", "model", "subclass", "loadabledetachablemodel", "loadabl", "detach", "model", "it", "simpli", "implement", "ondetach", "detach", "let", "superclass", "decid", "whether", "it", "attach", "or", "not", "problem", "that", "when", "stringresourcemodel", "string", "resourc", "model", "creat", "loadabledetachablemodel", "attach", "loadabl", "detach", "model", "will", "fals", "stringresourcemodel", "string", "resourc", "model", "never", "read", "getobject", "get", "object", "not", "call", "loadabledetachablemodel", "loadabl", "detach", "model", "will", "not", "mark", "as", "attach", "when", "detach", "call", "ondetach", "detach", "will", "not", "call", "therefor", "stringresourcemodel", "string", "resourc", "model", "will", "not", "call", "detach", "model", "that", "it", "hold"], "B_title": "StringResourceModel doesnt detach model in some cases", "B_clean_title": ["stringresourcemodel", "string", "resourc", "model", "doesnt", "detach", "model", "some", "case"]},
{"A_title": "Prototypes declared with quotes produce a JSC_USED_GLOBAL_THIS warning.None", "A_clean_title": ["prototyp", "declar", "quot", "produc", "jsc", "use", "global", "thi", "warn", "none"], "B_title": "Change on 2010/06/03 by nicksantos", "B_clean_title": ["chang", "2010", "06", "03", "by", "nicksanto"]},
{"A_title": "ODE integrator goes past specified end of integration rangeEnd of integration range in ODE solving is handled as an event. In some cases numerical accuracy in events detection leads to error in events location. The following test case shows the end event is not handled properly and an integration that should cover a 60s range in fact covers a 160s range more than twice the specified range. code   public void testMissedEvent() throws IntegratorException DerivativeException            final double t0 = 1878250320.0000029;           final double t =  1878250379.9999986;           FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations()                           public int getDimension()                  return 1;                                       public void computeDerivatives(double t double y double yDot)                 throws DerivativeException                  yDot0 = y0 * 1.0e-6;                      ;          DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0 100.0                                                                                1.0e-10 1.0e-10);          double y =  1.0 ;         integrator.setInitialStepSize(60.0);         double finalT = integrator.integrate(ode t0 y t y);         Assert.assertEquals(t finalT 1.0e-6);       code", "A_clean_title": ["ode", "integr", "goe", "past", "specifi", "end", "integr", "rangeend", "rang", "end", "integr", "rang", "ode", "solv", "handl", "as", "event", "some", "case", "numer", "accuraci", "event", "detect", "lead", "error", "event", "locat", "follow", "test", "case", "show", "end", "event", "not", "handl", "properli", "integr", "that", "cover", "60", "rang", "fact", "cover", "160", "rang", "more", "than", "twice", "specifi", "rang", "code", "public", "void", "testmissedev", "test", "miss", "event", "throw", "integratorexcept", "integr", "except", "derivativeexcept", "deriv", "except", "final", "doubl", "t0", "1878250320", "0000029", "final", "doubl", "1878250379", "9999986", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "ode", "new", "firstorderdifferentialequ", "first", "order", "differenti", "equat", "public", "int", "getdimens", "get", "dimens", "return", "public", "void", "computederiv", "comput", "deriv", "doubl", "doubl", "doubl", "ydot", "dot", "throw", "derivativeexcept", "deriv", "except", "ydot0", "dot0", "y0", "0e", "dormandprince853integr", "dormand", "prince853integr", "integr", "new", "dormandprince853integr", "dormand", "prince853integr", "100", "10", "0e", "10", "0e", "doubl", "integr", "setinitialsteps", "set", "initi", "step", "size", "60", "doubl", "finalt", "final", "integr", "integr", "ode", "t0", "assert", "assertequ", "assert", "equal", "finalt", "final", "0e", "code"], "B_title": "Fixed an error in events handling in ODE solvers. In some rare cases events occurring close to a step start were handled without truncating the step making them appear as is they occurred close to the step end JIRA: MATH-358", "B_clean_title": ["fix", "error", "event", "handl", "ode", "solver", "some", "rare", "case", "event", "occur", "close", "step", "start", "were", "handl", "without", "truncat", "step", "make", "them", "appear", "as", "they", "occur", "close", "step", "end", "jira", "math", "358"]},
{"A_title": "SimplexSolver not working as expected?I guess (but I could be wrong) that SimplexSolver does not always return the optimal solution nor satisfies all the constraints...  Consider this LP:  max: 0.8 x0 + 0.2 x1 + 0.7 x2 + 0.3 x3 + 0.6 x4 + 0.4 x5; r1: x0 + x2 + x4 = 23.0; r2: x1 + x3 + x5 = 23.0; r3: x0 >= 10.0; r4: x2 >= 8.0; r5: x4 >= 5.0;  LPSolve returns 25.8 with x0 = 10.0 x1 = 0.0 x2 = 8.0 x3 = 0.0 x4 = 5.0 x5 = 23.0;  The same LP expressed in Apache commons math is:  LinearObjectiveFunction f = new LinearObjectiveFunction(new double  0.8 0.2 0.7 0.3 0.6 0.4  0 ); Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>(); constraints.add(new LinearConstraint(new double  1 0 1 0 1 0  Relationship.EQ 23.0)); constraints.add(new LinearConstraint(new double  0 1 0 1 0 1  Relationship.EQ 23.0)); constraints.add(new LinearConstraint(new double  1 0 0 0 0 0  Relationship.GEQ 10.0)); constraints.add(new LinearConstraint(new double  0 0 1 0 0 0  Relationship.GEQ 8.0)); constraints.add(new LinearConstraint(new double  0 0 0 0 1 0  Relationship.GEQ 5.0));  RealPointValuePair solution = new SimplexSolver().optimize(f constraints GoalType.MAXIMIZE true);  that returns 22.20 with x0 = 15.0 x1 = 23.0 x2 = 8.0 x3 = 0.0 x4 = 0.0 x5 = 0.0;  Is it possible SimplexSolver is buggy that way? The returned value is 22.20 instead of 25.8 and the last constraint (x4 >= 5.0) is not satisfied...  Am I using the interface wrongly?", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "guess", "but", "could", "wrong", "that", "simplexsolv", "simplex", "solver", "not", "alway", "return", "optim", "solut", "nor", "satisfi", "all", "constraint", "consid", "thi", "lp", "max", "x0", "x1", "x2", "x3", "x4", "x5", "r1", "x0", "x2", "x4", "23", "r2", "x1", "x3", "x5", "23", "r3", "x0", "10", "r4", "x2", "r5", "x4", "lpsolv", "lp", "solv", "return", "25", "x0", "10", "x1", "x2", "x3", "x4", "x5", "23", "same", "lp", "express", "apach", "common", "math", "linearobjectivefunct", "linear", "object", "function", "new", "linearobjectivefunct", "linear", "object", "function", "new", "doubl", "collect", "linearconstraint", "linear", "constraint", "constraint", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "23", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "eq", "23", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "10", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "constraint", "add", "new", "linearconstraint", "linear", "constraint", "new", "doubl", "relationship", "geq", "realpointvaluepair", "real", "point", "valu", "pair", "solut", "new", "simplexsolv", "simplex", "solver", "optim", "constraint", "goaltyp", "maxim", "goal", "type", "true", "that", "return", "22", "20", "x0", "15", "x1", "23", "x2", "x3", "x4", "x5", "it", "possibl", "simplexsolv", "simplex", "solver", "buggi", "that", "way", "return", "valu", "22", "20", "instead", "25", "last", "constraint", "x4", "not", "satisfi", "am", "interfac", "wrongli"], "B_title": "fixed an error leading the simplex solver to compute the right solution but return another one JIRA: MATH-286", "B_clean_title": ["fix", "error", "lead", "simplex", "solver", "comput", "right", "solut", "but", "return", "anoth", "one", "jira", "math", "286"]},
{"A_title": "ResourceMapper throws IllegalStateException when attempting to map a request to a URL ending in a empty segment (directory)ResourceMapper.mapRequest() calls ResourceMapper.removeCachingDecoration() which throws IllegalStateException if the URLs last segment is an empty string.  URLs like: path/to/my/non/wicket/directory/ end in a empty segment.   We must change the behaviour to not attempt to undecorate a URL ending in an empty segment.", "A_clean_title": ["resourcemapp", "resourc", "mapper", "throw", "illegalstateexcept", "illeg", "state", "except", "when", "attempt", "map", "request", "url", "end", "empti", "segment", "directori", "resourcemapp", "maprequest", "resourc", "mapper", "map", "request", "call", "resourcemapp", "removecachingdecor", "resourc", "mapper", "remov", "cach", "decor", "which", "throw", "illegalstateexcept", "illeg", "state", "except", "url", "ur", "ls", "last", "segment", "empti", "string", "url", "ur", "ls", "like", "path", "my", "non", "wicket", "directori", "end", "empti", "segment", "we", "must", "chang", "behaviour", "not", "attempt", "undecor", "url", "end", "empti", "segment"], "B_title": "ResourceMapper throws IllegalStateException when attempting to map a request to a URL ending in a empty segment (directory)", "B_clean_title": ["resourcemapp", "resourc", "mapper", "throw", "illegalstateexcept", "illeg", "state", "except", "when", "attempt", "map", "request", "url", "end", "empti", "segment", "directori"]},
{"A_title": "404 Error on Nested ModalWindows in IE7 and IE8When opening a ModalWindow inside a ModalWindow the inner ModalWindow generates a 404 error.  Both windows use a PageCreator for content.  To replicate you must use an actual IE 7 or IE 8 browser as this does not replicate using developer tools and setting the document and brower to IE 7.  The problem can be seen at http://www.wicket-library.com/wicket-examples/ajax/modal-window.  I will attach a Quickstart as well.", "A_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8when", "open", "modalwindow", "modal", "window", "insid", "modalwindow", "modal", "window", "inner", "modalwindow", "modal", "window", "gener", "404", "error", "both", "window", "use", "pagecr", "page", "creator", "content", "replic", "you", "must", "use", "actual", "ie", "or", "ie", "browser", "as", "thi", "not", "replic", "develop", "tool", "set", "document", "brower", "ie", "problem", "seen", "at", "http", "window", "wicket", "librari", "exampl", "ajax", "modal", "www", "com", "wicket", "will", "attach", "quickstart", "as", "well"], "B_title": "404 Error on Nested ModalWindows in IE7 and IE8", "B_clean_title": ["404", "error", "nest", "modalwindow", "modal", "window", "ie7", "ie8"]},
{"A_title": "Ordered Index Indexing on large content is slowIndexing large number of ordered properties is quite slow.  Explore ways of making it faster. The current skip list implementation uses 4 lanes with a probability of 10%. It should be made configurable and the defaults changed.", "A_clean_title": ["order", "index", "index", "larg", "content", "slowindex", "slow", "index", "larg", "number", "order", "properti", "quit", "slow", "explor", "way", "make", "it", "faster", "current", "skip", "list", "implement", "use", "lane", "probabl", "10", "it", "made", "configur", "default", "chang"], "B_title": "Ordered Index Indexing on large content is slow", "B_clean_title": ["order", "index", "index", "larg", "content", "slow"]},
{"A_title": "side-effects analysis incorrectly removing function calls with side effectsNone", "A_clean_title": ["side", "effect", "analysi", "incorrectli", "remov", "function", "call", "side", "effectsnon", "effect", "none"], "B_title": "Fix improper analysis of NEW the bad way: by assuming NEW always returns a non-local result. Fixes issue 303.", "B_clean_title": ["fix", "improp", "analysi", "new", "bad", "way", "by", "assum", "new", "alway", "return", "non", "local", "result", "fix", "issu", "303"]},
{"A_title": "NormalDistribution.cumulativeProbability() suffers from cancellationI see the following around line 194: noformat         return 0.5 * (1 + Erf.erf(dev / (standardDeviation * SQRT2))); noformat  When erf() returns a very small value this cancels in the addition with the 1.0 which leads to poor precision in the results.  I would suggest changing this line to read more like: noformat return 0.5 * Erf.erfc( -dev / standardDeviation * SQRT2 ); noformat   Should you want some test cases for extreme values (one might argue that within 10 standard deviations isnt all that extreme) then you can check the following: http://www.jstatsoft.org/v52/i07/ then look in the v52i07-xls.zip at replication-01-distribution-standard-normal.xls  I think you will also find that evaluation of expressions such as noformatNormalDistribution( 0 1 ).cumulativeProbability( -10.0 );noformat are pretty far off.", "A_clean_title": ["normaldistribut", "cumulativeprob", "normal", "distribut", "cumul", "probabl", "suffer", "cancellationi", "cancel", "see", "follow", "around", "line", "194", "noformat", "return", "erf", "erf", "dev", "standarddevi", "standard", "deviat", "sqrt2", "noformat", "when", "erf", "return", "veri", "small", "valu", "thi", "cancel", "addit", "which", "lead", "poor", "precis", "result", "would", "suggest", "chang", "thi", "line", "read", "more", "like", "noformat", "return", "erf", "erfc", "dev", "standarddevi", "standard", "deviat", "sqrt2", "noformat", "you", "want", "some", "test", "case", "extrem", "valu", "one", "might", "argu", "that", "within", "10", "standard", "deviat", "isnt", "all", "that", "extrem", "then", "you", "check", "follow", "http", "jstatsoft", "www", "org", "v52", "i07", "then", "look", "v52i07", "xl", "zip", "at", "replic", "01", "distribut", "standard", "normal", "xl", "think", "you", "will", "also", "find", "that", "evalu", "express", "such", "as", "noformatnormaldistribut", "noformat", "normal", "distribut", "cumulativeprob", "cumul", "probabl", "10", "noformat", "are", "pretti", "far", "off"], "B_title": "", "B_clean_title": []},
{"A_title": "alert(/ / / / /)None", "A_clean_title": ["alert", "none"], "B_title": "Fix issue 620", "B_clean_title": ["fix", "issu", "620"]},
{"A_title": "Redundent entries in effective policies per principal-setwhen retrieving the effective policies for a given set of principals the resulting array of policies contains redundant entries if a given policy contains multiple ACEs for the given set of principals.", "A_clean_title": ["redund", "entri", "effect", "polici", "per", "princip", "setwhen", "retriev", "effect", "polici", "given", "set", "princip", "result", "array", "polici", "contain", "redund", "entri", "given", "polici", "contain", "multipl", "ace", "ac", "es", "given", "set", "princip"], "B_title": ": Redundent entries in effective policies per principal-set", "B_clean_title": ["redund", "entri", "effect", "polici", "per", "princip", "set"]},
{"A_title": "precondition crash: goog.scope local with aliased in the type declarationNone", "A_clean_title": ["precondit", "crash", "goog", "scope", "local", "alias", "type", "declarationnon", "declar", "none"], "B_title": "Dont try to process jsdoc nodes twice. Fixes issue 1144 R=blickly", "B_clean_title": ["dont", "tri", "process", "jsdoc", "node", "twice", "fix", "issu", "1144", "r=blickli"]},
{"A_title": "CsvParser: Quotes cannot be escaped inside quoted fieldsWe should allow users to escape the quote character inside a quoted field.  Quoting could be realized through the  character like in: This is an escaped quotation.  Mailing list thread: http://apache-flink-mailing-list-archive.1008284.n3.nabble.com/jira-Created-FLINK-2567-CsvParser-Quotes-cannot-be-escaped-inside-quoted-fields-td7654.html", "A_clean_title": ["csvparser", "csv", "parser", "quot", "not", "escap", "insid", "quot", "fieldsw", "field", "we", "allow", "user", "escap", "quot", "charact", "insid", "quot", "field", "quot", "could", "realiz", "through", "charact", "like", "thi", "escap", "quotat", "mail", "list", "thread", "http", "flink", "mail", "list", "creat", "flink", "2567", "csvparser", "quot", "apach", "archiv", "1008284", "n3", "nabbl", "csv", "parser", "com", "jira", "not", "escap", "insid", "quot", "field", "td7654", "html"], "B_title": "core Allow quoted strings in CSV fields to contain quotation character inside of the field as long as its escaped Ex: Hi my name is Flink", "B_clean_title": ["core", "allow", "quot", "string", "csv", "field", "contain", "quotat", "charact", "insid", "field", "as", "long", "as", "it", "escap", "ex", "hi", "my", "name", "flink"]},
{"A_title": "URL rendering regressionThe way URLs are encoded was changed (WICKET-4645) and now the first request (with ;jsessionid in path) generates invalid internal links: My page is mounted to /Home/ and I get redirected to /Home/;jsessionid=1234?0 (fine). Theres a Link  on the page and the generated URL for it is ../Home;jsessionid=1234?0-1.ILinkListener-link. Note the missing /. This results in a 404 and breaks basically all of my system tests.  Ill attach a simple quickstart which demonstrates the problem. Its important to delete the jsessionid cookie before accessing the page.", "A_clean_title": ["url", "render", "regressionth", "regress", "way", "url", "ur", "ls", "are", "encod", "wa", "chang", "wicket", "4645", "now", "first", "request", "jsessionid", "path", "gener", "invalid", "intern", "link", "my", "page", "mount", "home", "get", "redirect", "home", "jsessionid=1234", "fine", "there", "link", "page", "gener", "url", "it", "home", "jsessionid=1234", "link", "ilinklisten", "link", "listen", "note", "miss", "thi", "result", "404", "break", "basic", "all", "my", "system", "test", "ill", "attach", "simpl", "quickstart", "which", "demonstr", "problem", "it", "import", "delet", "jsessionid", "cooki", "befor", "access", "page"], "B_title": "url rendering regression: keep trailing empty segment if base still has segments but relative has not", "B_clean_title": ["url", "render", "regress", "keep", "trail", "empti", "segment", "base", "still", "ha", "segment", "but", "rel", "ha", "not"]},
{"A_title": "Redirect to HTTPS is using wrong port 80 if HttpsConfig with default ports 80/443 is usedHttpsMapper#mapHandler() doesnt set the Urls port if the desired protocol uses the standard port.  This leads to UrlRenderer choosing to the requests port as fallback (which is 80 before switching to https).", "A_clean_title": ["redirect", "http", "wrong", "port", "80", "httpsconfig", "http", "config", "default", "port", "80", "443", "usedhttpsmapp", "use", "http", "mapper", "maphandl", "map", "handler", "doesnt", "set", "url", "port", "desir", "protocol", "use", "standard", "port", "thi", "lead", "urlrender", "url", "render", "choos", "request", "port", "as", "fallback", "which", "80", "befor", "switch", "http"], "B_title": "set port explicitly it wont be rendered by UrlRenderer if not required", "B_clean_title": ["set", "port", "explicitli", "it", "wont", "render", "by", "urlrender", "url", "render", "not", "requir"]},
{"A_title": "PropertyValidator ignoring groups with the @NotNull annotation onlyWhen using groups in your JSR303 compliant classes Wicket does not honor the groups for the @NotNull annotation.", "A_clean_title": ["propertyvalid", "properti", "valid", "ignor", "group", "notnul", "not", "null", "annot", "onlywhen", "onli", "when", "group", "your", "jsr303", "compliant", "class", "wicket", "not", "honor", "group", "notnul", "not", "null", "annot"], "B_title": "properly handle groups in NonNull constraint", "B_clean_title": ["properli", "handl", "group", "nonnul", "non", "null", "constraint"]},
{"A_title": "XPath backwards compatibility issue with false() and true()In JR2 (actually CRX 2) both of the following queries for nodes with a boolean property can be parsed however only query (a) returns search results. noformat     (a) /jcr:root/test//*@foo = true()     (b) /jcr:root/test//*@foo = true noformat  On Oak 1.2 query (a) results in an exception0 and query (b) returns search results.  See discussion at http://markmail.org/thread/kpews55jpdwm62ds", "A_clean_title": ["xpath", "path", "backward", "compat", "issu", "fals", "true", "jr2", "actual", "crx", "both", "follow", "queri", "node", "boolean", "properti", "pars", "howev", "onli", "queri", "return", "search", "result", "noformat", "jcr", "root", "test", "foo", "true", "jcr", "root", "test", "foo", "true", "noformat", "oak", "queri", "result", "exception0", "queri", "return", "search", "result", "see", "discuss", "at", "http", "markmail", "org", "thread", "kpews55jpdwm62d"], "B_title": "XPath backwards compatibility issue with false() and true()", "B_clean_title": ["xpath", "path", "backward", "compat", "issu", "fals", "true"]},
{"A_title": "UrlAttributes are encoded incorrectly when style is null but variation is notAbstractResourceReferenceMapper.encodeResourceReferenceAttributes() method generates the same -foo output for these two different inputs: locale = null style = foo variation = null and locale = null style = null variation = foo. For the second input it should generate --foo (double dash prefix).", "A_clean_title": ["urlattribut", "url", "attribut", "are", "encod", "incorrectli", "when", "style", "null", "but", "variat", "notabstractresourcereferencemapp", "encoderesourcereferenceattribut", "not", "abstract", "resourc", "refer", "mapper", "encod", "resourc", "refer", "attribut", "method", "gener", "same", "foo", "output", "these", "two", "differ", "input", "local", "null", "style", "foo", "variat", "null", "local", "null", "style", "null", "variat", "foo", "second", "input", "it", "gener", "foo", "doubl", "dash", "prefix"], "B_title": "UrlAttributes are encoded incorrectly when style is null but variation is not", "B_clean_title": ["urlattribut", "url", "attribut", "are", "encod", "incorrectli", "when", "style", "null", "but", "variat", "not"]},
{"A_title": "Index updation fails on updating multivalued propertyOn emptying a multivalued property fulltext index updation fails and one can search on old values. Following test demonstrates the issue. Added below test in LuceneIndexQueryTest.java|https://github.com/apache/jackrabbit-oak/blob/trunk/oak-lucene/src/test/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexQueryTest.java which should pass -  code     @Test     public void testMultiValuedPropUpdate() throws Exception          Tree test = root.getTree(/).addChild(test);         String child = child;         String mulValuedProp = prop;         test.addChild(child).setProperty(mulValuedProp of(foobar) Type.STRINGS);         root.commit();         assertQuery(                 /jcr:root//*jcr:contains(@ + mulValuedProp +  foo)                 xpath ImmutableList.of(/test/ + child));         test.getChild(child).setProperty(mulValuedProp new ArrayList<String>() Type.STRINGS);         root.commit();         assertQuery(                 /jcr:root//*jcr:contains(@ + mulValuedProp +  foo)                 xpath new ArrayList<String>());          test.getChild(child).setProperty(mulValuedProp of(bar) Type.STRINGS);         root.commit();         assertQuery(                 /jcr:root//*jcr:contains(@ + mulValuedProp +  foo)                 xpath new ArrayList<String>());       code", "A_clean_title": ["index", "updat", "fail", "updat", "multivalu", "propertyon", "properti", "empti", "multivalu", "properti", "fulltext", "index", "updat", "fail", "one", "search", "old", "valu", "follow", "test", "demonstr", "issu", "ad", "below", "test", "luceneindexquerytest", "java|http", "lucen", "index", "queri", "test", "oak", "blob", "trunk", "oak", "java", "github", "com", "apach", "jackrabbit", "lucen", "src", "test", "java", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexquerytest", "lucen", "index", "queri", "test", "which", "pass", "code", "test", "public", "void", "testmultivaluedpropupd", "test", "multi", "valu", "prop", "updat", "throw", "except", "tree", "test", "root", "gettre", "get", "tree", "addchild", "add", "child", "test", "string", "child", "child", "string", "mulvaluedprop", "mul", "valu", "prop", "prop", "test", "addchild", "add", "child", "child", "setproperti", "set", "properti", "mulvaluedprop", "mul", "valu", "prop", "foobar", "type", "string", "root", "commit", "assertqueri", "assert", "queri", "jcr", "root", "jcr", "contain", "mulvaluedprop", "mul", "valu", "prop", "foo", "xpath", "immutablelist", "immut", "list", "test", "child", "test", "getchild", "get", "child", "child", "setproperti", "set", "properti", "mulvaluedprop", "mul", "valu", "prop", "new", "arraylist", "array", "list", "string", "type", "string", "root", "commit", "assertqueri", "assert", "queri", "jcr", "root", "jcr", "contain", "mulvaluedprop", "mul", "valu", "prop", "foo", "xpath", "new", "arraylist", "array", "list", "string", "test", "getchild", "get", "child", "child", "setproperti", "set", "properti", "mulvaluedprop", "mul", "valu", "prop", "bar", "type", "string", "root", "commit", "assertqueri", "assert", "queri", "jcr", "root", "jcr", "contain", "mulvaluedprop", "mul", "valu", "prop", "foo", "xpath", "new", "arraylist", "array", "list", "string", "code"], "B_title": "Index updation fails on updating multivalued property", "B_clean_title": ["index", "updat", "fail", "updat", "multivalu", "properti"]},
{"A_title": "Certain Avro generated getters/setters not recognizedFor Avro schemas where value null is not allowed the field is unboxed e.g. int but the getter/setter methods provide the boxed Integer as interface:  code   fields:        type: double     name: time      code  This results in Java  code   private double time;    public java.lang.Double getTime()      return time;       public void setTime(java.lang.Double value)      this.time = value;    code  There is also a problem when there is an underscore in the Avro schema e.g.:  code       default: null     type:      null      long         name: conn_id     code  This results in Java:  code private java.lang.Long conn_id;    public java.lang.Long getConnId()      return conn_id;       public void setConnId(java.lang.Long value)      this.conn_id = value;    code", "A_clean_title": ["certain", "avro", "gener", "getter", "setter", "not", "recognizedfor", "recogn", "avro", "schema", "where", "valu", "null", "not", "allow", "field", "unbox", "int", "but", "getter", "setter", "method", "provid", "box", "integ", "as", "interfac", "code", "field", "type", "doubl", "name", "time", "code", "thi", "result", "java", "code", "privat", "doubl", "time", "public", "java", "lang", "doubl", "gettim", "get", "time", "return", "time", "public", "void", "settim", "set", "time", "java", "lang", "doubl", "valu", "thi", "time", "valu", "code", "there", "also", "problem", "when", "there", "underscor", "avro", "schema", "code", "default", "null", "type", "null", "long", "name", "conn", "id", "code", "thi", "result", "java", "code", "privat", "java", "lang", "long", "conn", "id", "public", "java", "lang", "long", "getconnid", "get", "conn", "id", "return", "conn", "id", "public", "void", "setconnid", "set", "conn", "id", "java", "lang", "long", "valu", "thi", "conn", "id", "valu", "code"], "B_title": "Fix Avro getter/setter recognition", "B_clean_title": ["fix", "avro", "getter", "setter", "recognit"]},
{"A_title": "Upgraded version history has UUIDs as jcr:frozenUuid of non-referenceable nodesIn Jackrabbit Classic each node even non-referenceable ones has a UUID as its identifier and thus the jcr:frozenUuid properties of frozen nodes are always UUIDs. In contrast Oak uses path identifiers for non-referenceable frozen nodes (see OAK-1009) which presents a problem when dealing with version histories migrated from Jackrabbit Classic.  To avoid this mismatch the upgrade code should check each frozen node for referenceability and replace the frozen UUID with a path identifier if needed.", "A_clean_title": ["upgrad", "version", "histori", "ha", "uuid", "uui", "ds", "as", "jcr", "frozenuuid", "frozen", "uuid", "non", "referenc", "nodesin", "node", "jackrabbit", "classic", "each", "node", "even", "non", "referenc", "one", "ha", "uuid", "as", "it", "identifi", "thu", "jcr", "frozenuuid", "frozen", "uuid", "properti", "frozen", "node", "are", "alway", "uuid", "uui", "ds", "contrast", "oak", "use", "path", "identifi", "non", "referenc", "frozen", "node", "see", "oak", "1009", "which", "present", "problem", "when", "deal", "version", "histori", "migrat", "jackrabbit", "classic", "avoid", "thi", "mismatch", "upgrad", "code", "check", "each", "frozen", "node", "referenc", "replac", "frozen", "uuid", "path", "identifi", "need"], "B_title": "Upgraded version history has UUIDs as jcr:frozenUuid of non-referenceable nodes", "B_clean_title": ["upgrad", "version", "histori", "ha", "uuid", "uui", "ds", "as", "jcr", "frozenuuid", "frozen", "uuid", "non", "referenc", "node"]},
{"A_title": "ConvergenceException in normal CDFNormalDistributionImpl::cumulativeProbability(double x) throws ConvergenceException if x deviates too much from the mean. For example when x=+/-100 mean=0 sd=1. Of course the value of the CDF is hard to evaluate in these cases but effectively it should be either zero or one.", "A_clean_title": ["convergenceexcept", "converg", "except", "normal", "cdfnormaldistributionimpl", "cdf", "normal", "distribut", "impl", ":cumulativeprob", ":cumul", "probabl", "doubl", "throw", "convergenceexcept", "converg", "except", "deviat", "too", "much", "mean", "exampl", "when", "100", "x=+", "mean=0", "sd=1", "cours", "valu", "cdf", "hard", "evalu", "these", "case", "but", "effect", "it", "either", "zero", "or", "one"], "B_title": "Modified NormalDistributionImpl.cumulativeProbablity to catch MaxIterationsExceededException and return 0 or 1 resp. if the argument is more than 20 standard deviations from the mean.", "B_clean_title": ["modifi", "normaldistributionimpl", "cumulativeprobabl", "normal", "distribut", "impl", "cumul", "probabl", "catch", "maxiterationsexceededexcept", "max", "iter", "exceed", "except", "return", "or", "resp", "argument", "more", "than", "20", "standard", "deviat", "mean"]},
{"A_title": "Url#getQueryString(charset) method returns quesrystring with ? prefixed to iti have just pointed out 6.0.0-beta3/6.x but it must be same in 1.5.x too afaik ? is not considered part of querystring ? is considered separator see http://tools.ietf.org/html/rfc3986#section-3 this method is used in Url#toString() too which can be easily fixed but it may be used at other places too so i dont know if removing ? will break things now.  so how things break currently RequestUtils.decodeParameters(url.getQueryString()parameters); decodeparameters will considered first key to be ?key  so may be requestutils#decodeparameters method should strip away ? if its present in the query string before populating pageparameters  thanks!", "A_clean_title": ["url", "getquerystr", "get", "queri", "string", "charset", "method", "return", "quesrystr", "prefix", "iti", "have", "just", "point", "out", "beta3", "but", "it", "must", "same", "too", "afaik", "not", "consid", "part", "querystr", "consid", "separ", "see", "http", "ietf", "tool", "org", "html", "rfc3986", "section", "thi", "method", "use", "url", "tostr", "string", "too", "which", "easili", "fix", "but", "it", "may", "use", "at", "other", "place", "too", "so", "dont", "know", "remov", "will", "break", "thing", "now", "so", "how", "thing", "break", "current", "requestutil", "decodeparamet", "request", "util", "decod", "paramet", "url", "getquerystr", "get", "queri", "string", "paramet", "decodeparamet", "will", "consid", "first", "key", "key", "so", "may", "requestutil", "decodeparamet", "method", "strip", "away", "it", "present", "queri", "string", "befor", "popul", "pageparamet", "thank"], "B_title": "Complement for WICKET-4664", "B_clean_title": ["complement", "wicket", "4664"]},
{"A_title": "delete mutations not working through the ProxyAru Sahni writes:  quote Im new to Accumulo and am still trying to wrap my head around its ways. To further that challenge Im using Pyaccumulo which doesnt present much in terms of available reference material.  Right now Im trying to understand how Accumulo manages record (key-value pair) deletions.  conn = Accumulo(host port user password) table = test_table conn.create_table(table) writer = conn.create_batch_writer(table) mut = Mutation(mut_01) mut.put(cf=item cq=name value=car) writer.add_mutation(mut) writer.close() conn.close()  Will generate a record (found via a shell scan):  mut_01 item:name     car  However the subsequent mutation...  writer = conn.create_batch_writer(table) mut = Mutation(mut_01) mut.put(cf=item cq=name is_delete=True) writer.add_mutation(mut) writer.close()  Results in:  mut_01 item:name   How should one expect the deleted row to be represented? That record sticks around even after I force a compaction of the table.  I was expecting it to not show up in any iterators or at least provide an easy way to see if the cell has been deleted. quote  ~ecn has confirmed the problem.", "A_clean_title": ["delet", "mutat", "not", "work", "through", "proxyaru", "proxi", "aru", "sahni", "write", "quot", "im", "new", "accumulo", "am", "still", "tri", "wrap", "my", "head", "around", "it", "way", "further", "that", "challeng", "im", "pyaccumulo", "which", "doesnt", "present", "much", "term", "avail", "refer", "materi", "right", "now", "im", "tri", "understand", "how", "accumulo", "manag", "record", "key", "valu", "pair", "delet", "conn", "accumulo", "host", "port", "user", "password", "tabl", "test", "tabl", "conn", "creat", "tabl", "tabl", "writer", "conn", "creat", "batch", "writer", "tabl", "mut", "mutat", "mut", "01", "mut", "put", "cf=item", "cq=name", "value=car", "writer", "add", "mutat", "mut", "writer", "close", "conn", "close", "will", "gener", "record", "found", "via", "shell", "scan", "mut", "01", "item", "name", "car", "howev", "subsequ", "mutat", "writer", "conn", "creat", "batch", "writer", "tabl", "mut", "mutat", "mut", "01", "mut", "put", "cf=item", "cq=name", "delete=tru", "writer", "add", "mutat", "mut", "writer", "close", "result", "mut", "01", "item", "name", "how", "one", "expect", "delet", "row", "repres", "that", "record", "stick", "around", "even", "after", "forc", "compact", "tabl", "wa", "expect", "it", "not", "show", "up", "ani", "iter", "or", "at", "least", "provid", "easi", "way", "see", "cell", "ha", "been", "delet", "quot", "~ecn", "ha", "confirm", "problem"], "B_title": "fix deletes added test", "B_clean_title": ["fix", "delet", "ad", "test"]},
{"A_title": "Queuing a component in headQueuing a component which is in the head section doesnt work : <head> <meta charset=utf-8 /> <title wicket:id=titre>Test</title> </head>", "A_clean_title": ["queu", "compon", "headqueu", "head", "queu", "compon", "which", "head", "section", "doesnt", "work", "head", "meta", "charset=utf", "titl", "wicket", "id=titr", "test", "titl", "head"], "B_title": "Queuing a component in head", "B_clean_title": ["queu", "compon", "head"]},
{"A_title": "Duration.toPeriod with fixed time zones.I have a question concerning the conversion of a Duration to Period. Im not sure if this is a bug or if there is a different way to do this.  The basis of the problem is that using Duration.toPeriod() uses the chronology of the default time zone to do the conversion. This can cause different results from a timezone with DST and one without. This can be reproduced easily with this test. In the joda code Duration.toPeriod() uses a period constructor that takes the chronology but null is passed in so the chronology of the default time zone is used which leads to this behavior.  The javadoc of toPeriod() states that only precise fields of hours minutes seconds and millis will be converted. But for a fixed timezone days and weeks are also precise which is stated in the javadoc for toPeriod(Chronology chrono). In our app we need consistent behavior regardless of the default time zone which is to have all the extra hours put into the hours bucket. Since Duration is supposed to be a time zone independent length of time I dont think we should have to do any chronology manipulation to get this to work.", "A_clean_title": ["durat", "toperiod", "period", "fix", "time", "zone", "have", "question", "concern", "convers", "durat", "period", "im", "not", "sure", "thi", "bug", "or", "there", "differ", "way", "thi", "basi", "problem", "that", "durat", "toperiod", "period", "use", "chronolog", "default", "time", "zone", "convers", "thi", "caus", "differ", "result", "timezon", "dst", "one", "without", "thi", "reproduc", "easili", "thi", "test", "joda", "code", "durat", "toperiod", "period", "use", "period", "constructor", "that", "take", "chronolog", "but", "null", "pass", "so", "chronolog", "default", "time", "zone", "use", "which", "lead", "thi", "behavior", "javadoc", "toperiod", "period", "state", "that", "onli", "precis", "field", "hour", "minut", "second", "milli", "will", "convert", "but", "fix", "timezon", "day", "week", "are", "also", "precis", "which", "state", "javadoc", "toperiod", "period", "chronolog", "chrono", "our", "app", "we", "need", "consist", "behavior", "regardless", "default", "time", "zone", "which", "have", "all", "extra", "hour", "put", "into", "hour", "bucket", "sinc", "durat", "suppos", "time", "zone", "independ", "length", "time", "dont", "think", "we", "have", "ani", "chronolog", "manipul", "get", "thi", "work"], "B_title": "Duraton.toPeriod() new Period(long) new MutablePeriod(long) 3264409 Fixed to obey Javadoc. Previously they didnt obey the Javadoc if the default time-zone had no daylight savings.", "B_clean_title": ["duraton", "toperiod", "period", "new", "period", "long", "new", "mutableperiod", "mutabl", "period", "long", "3264409", "fix", "obey", "javadoc", "previous", "they", "didnt", "obey", "javadoc", "default", "time", "zone", "had", "no", "daylight", "save"]},
{"A_title": "Failing tests on Windows machineNone", "A_clean_title": ["fail", "test", "window", "machinenon", "machin", "none"], "B_title": "printing args on smart nulls toString (Issue #225)", "B_clean_title": ["print", "arg", "smart", "null", "tostr", "string", "issu", "225"]},
{"A_title": "Nested Redirects and REDIRECT_TO_BUFFERWhen the render strategy is REDIRECT_TO_BUFFER redirects cannot be nested. After the second redirect Wicket renders the buffered first page in preference to the second page. The relevant code is in WebPageRenderer.respond:  noformat if (bufferedResponse != null)  logger.warn(The Buffered response should be handled by BufferedResponseRequestHandler); // if there is saved response for this URL render it bufferedResponse.writeTo((WebResponse)requestCycle.getResponse());  noformat  The attached quickstart demonstrates the issue. Simply navigate to the home page. The observed behavior is that Page1 is displayed but I expect Page2 to be displayed.  I can work around the issue by calling WebApplication.getAndRemoveBufferedResponse() to clear the render buffer but I am uneasy with this solution since it seems like I am playing with Wicket internals; albeit the function is public.", "A_clean_title": ["nest", "redirect", "redirect", "bufferwhen", "buffer", "when", "render", "strategi", "redirect", "buffer", "redirect", "not", "nest", "after", "second", "redirect", "wicket", "render", "buffer", "first", "page", "prefer", "second", "page", "relev", "code", "webpagerender", "respond", "web", "page", "render", "noformat", "bufferedrespons", "buffer", "respons", "null", "logger", "warn", "buffer", "respons", "handl", "by", "bufferedresponserequesthandl", "buffer", "respons", "request", "handler", "there", "save", "respons", "thi", "url", "render", "it", "bufferedrespons", "writeto", "buffer", "respons", "write", "webrespons", "web", "respons", "requestcycl", "getrespons", "request", "cycl", "get", "respons", "noformat", "attach", "quickstart", "demonstr", "issu", "simpli", "navig", "home", "page", "observ", "behavior", "that", "page1", "display", "but", "expect", "page2", "display", "work", "around", "issu", "by", "call", "webappl", "getandremovebufferedrespons", "web", "applic", "get", "remov", "buffer", "respons", "clear", "render", "buffer", "but", "am", "uneasi", "thi", "solut", "sinc", "it", "seem", "like", "am", "play", "wicket", "intern", "albeit", "function", "public"], "B_title": "Nested Redirects and REDIRECT_TO_BUFFER", "B_clean_title": ["nest", "redirect", "redirect", "buffer"]},
{"A_title": "Incorrect assignment removal from expression in simple mode.None", "A_clean_title": ["incorrect", "assign", "remov", "express", "simpl", "mode", "none"], "B_title": "Fix checks for variable reads in expressions with assignments. Fixes issue 297.", "B_clean_title": ["fix", "check", "variabl", "read", "express", "assign", "fix", "issu", "297"]},
{"A_title": "Correlated random vector generator fails (silently) when faced with zero rows in covariance matrixThe following three matrices (which are basically permutations of each other) produce different results when sampling a multi-variate Gaussian with the help of CorrelatedRandomVectorGenerator (sample covariances calculated in R based on 10000 samples):  Array2DRowRealMatrix 0.00.00.00.00.0 0.00.0134455320.010394690.0098811560.010499559 0.00.010394690.0230066160.0081968560.010732709 0.00.0098811560.0081968560.0190238660.009210099 0.00.0104995590.0107327090.0092100990.019107243  > cov(data1)    V1 V2 V3 V4 V5 V1 0 0.000000000 0.00000000 0.000000000 0.000000000 V2 0 0.013383931 0.01034401 0.009913271 0.010506733 V3 0 0.010344006 0.02309479 0.008374730 0.010759306 V4 0 0.009913271 0.00837473 0.019005488 0.009187287 V5 0 0.010506733 0.01075931 0.009187287 0.019021483  Array2DRowRealMatrix 0.0134455320.010394690.00.0098811560.010499559 0.010394690.0230066160.00.0081968560.010732709 0.00.00.00.00.0 0.0098811560.0081968560.00.0190238660.009210099 0.0104995590.0107327090.00.0092100990.019107243  > cov(data2)             V1 V2 V3 V4 V5 V1 0.006922905 0.010507692 0 0.005817399 0.010330529 V2 0.010507692 0.023428918 0 0.008273152 0.010735568 V3 0.000000000 0.000000000 0 0.000000000 0.000000000 V4 0.005817399 0.008273152 0 0.004929843 0.009048759 V5 0.010330529 0.010735568 0 0.009048759 0.018683544   Array2DRowRealMatrix 0.0134455320.010394690.0098811560.010499559 0.010394690.0230066160.0081968560.010732709 0.0098811560.0081968560.0190238660.009210099 0.0104995590.0107327090.0092100990.019107243  > cov(data3)             V1          V2          V3          V4 V1 0.013445047 0.010478862 0.009955904 0.010529542 V2 0.010478862 0.022910522 0.008610113 0.011046353 V3 0.009955904 0.008610113 0.019250975 0.009464442 V4 0.010529542 0.011046353 0.009464442 0.019260317   Ive traced this back to the RectangularCholeskyDecomposition which does not seem to handle the second matrix very well (decompositions in the same order as the matrices above):  CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.00.00.00.00.00.07595774181220630.08761251884742390.00.00.00.077644436225135050.051328212214607520.119763818217912350.00.00.066629305279094040.055016617441145850.00166625065193079970.107493242076536320.00.138228951381394770.00.00.00.0 CorrelatedRandomVectorGenerator.getRank() = 5  CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.07595774181220630.0345127513794487240.00.077644436225135050.130299491646287460.00.00.00.00.066629305279094040.0232039366948556740.00.138228951381394770.00.0 CorrelatedRandomVectorGenerator.getRank() = 3  CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.07595774181220630.0345127513794487240.0339137482263482250.073038901499477850.077644436225135050.130299491646287460.00.00.066629305279094040.0232039366948556740.118515733132299450.00.138228951381394770.00.00.0 CorrelatedRandomVectorGenerator.getRank() = 4  Clearly the rank of each of these matrices should be 4. The first matrix does not lead to incorrect results but the second one does. Unfortunately I dont know enough about the Cholesky decomposition to find the flaw in the implementation and I could not find documentation for the rectangular variant (also not at the links provided in the javadoc).", "A_clean_title": ["correl", "random", "vector", "gener", "fail", "silent", "when", "face", "zero", "row", "covari", "matrixth", "matrix", "follow", "three", "matric", "which", "are", "basic", "permut", "each", "other", "produc", "differ", "result", "when", "sampl", "multi", "variat", "gaussian", "help", "correlatedrandomvectorgener", "correl", "random", "vector", "gener", "sampl", "covari", "calcul", "base", "10000", "sampl", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "00", "00", "00", "00", "00", "0134455320", "010394690", "0098811560", "010499559", "00", "010394690", "0230066160", "0081968560", "010732709", "00", "0098811560", "0081968560", "0190238660", "009210099", "00", "0104995590", "0107327090", "0092100990", "019107243", "cov", "data1", "v1", "v2", "v3", "v4", "v5", "v1", "000000000", "00000000", "000000000", "000000000", "v2", "013383931", "01034401", "009913271", "010506733", "v3", "010344006", "02309479", "008374730", "010759306", "v4", "009913271", "00837473", "019005488", "009187287", "v5", "010506733", "01075931", "009187287", "019021483", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "0134455320", "010394690", "00", "0098811560", "010499559", "010394690", "0230066160", "00", "0081968560", "010732709", "00", "00", "00", "00", "0098811560", "0081968560", "00", "0190238660", "009210099", "0104995590", "0107327090", "00", "0092100990", "019107243", "cov", "data2", "v1", "v2", "v3", "v4", "v5", "v1", "006922905", "010507692", "005817399", "010330529", "v2", "010507692", "023428918", "008273152", "010735568", "v3", "000000000", "000000000", "000000000", "000000000", "v4", "005817399", "008273152", "004929843", "009048759", "v5", "010330529", "010735568", "009048759", "018683544", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "0134455320", "010394690", "0098811560", "010499559", "010394690", "0230066160", "0081968560", "010732709", "0098811560", "0081968560", "0190238660", "009210099", "0104995590", "0107327090", "0092100990", "019107243", "cov", "data3", "v1", "v2", "v3", "v4", "v1", "013445047", "010478862", "009955904", "010529542", "v2", "010478862", "022910522", "008610113", "011046353", "v3", "009955904", "008610113", "019250975", "009464442", "v4", "010529542", "011046353", "009464442", "019260317", "ive", "trace", "thi", "back", "rectangularcholeskydecomposit", "rectangular", "choleski", "decomposit", "which", "not", "seem", "handl", "second", "matrix", "veri", "well", "decomposit", "same", "order", "as", "matric", "abov", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "00", "00", "00", "00", "00", "07595774181220630", "08761251884742390", "00", "00", "00", "077644436225135050", "051328212214607520", "119763818217912350", "00", "00", "066629305279094040", "055016617441145850", "00166625065193079970", "107493242076536320", "00", "138228951381394770", "00", "00", "00", "array2d", "row", "real", "matrix0", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "07595774181220630", "0345127513794487240", "00", "077644436225135050", "130299491646287460", "00", "00", "00", "00", "066629305279094040", "0232039366948556740", "00", "138228951381394770", "00", "array2d", "row", "real", "matrix0", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "07595774181220630", "0345127513794487240", "0339137482263482250", "073038901499477850", "077644436225135050", "130299491646287460", "00", "00", "066629305279094040", "0232039366948556740", "118515733132299450", "00", "138228951381394770", "00", "00", "array2d", "row", "real", "matrix0", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "clearli", "rank", "each", "these", "matric", "first", "matrix", "not", "lead", "incorrect", "result", "but", "second", "one", "unfortun", "dont", "know", "enough", "about", "choleski", "decomposit", "find", "flaw", "implement", "could", "not", "find", "document", "rectangular", "variant", "also", "not", "at", "link", "provid", "javadoc"], "B_title": "Fixed an error in rectangular Cholesky decomposition.", "B_clean_title": ["fix", "error", "rectangular", "choleski", "decomposit"]},
{"A_title": "FormComponents remain invalid forever if there is no feedback panelif there is no feedback panel the error messages are not removed in ondetach and form component re-validation is skipped so the form component once marked as invalid will remain invalid forever or at least until its error messages are rendered.  the error messages should be dropped and the form component should be re-validated on every form submit.", "A_clean_title": ["formcompon", "form", "compon", "remain", "invalid", "forev", "there", "no", "feedback", "panelif", "there", "no", "feedback", "panel", "error", "messag", "are", "not", "remov", "ondetach", "form", "compon", "re", "valid", "skip", "so", "form", "compon", "onc", "mark", "as", "invalid", "will", "remain", "invalid", "forev", "or", "at", "least", "until", "it", "error", "messag", "are", "render", "error", "messag", "drop", "form", "compon", "re", "valid", "everi", "form", "submit"], "B_title": "fix form validation bug where form components would remain invalid until their error messages were rendered", "B_clean_title": ["fix", "form", "valid", "bug", "where", "form", "compon", "would", "remain", "invalid", "until", "their", "error", "messag", "were", "render"]},
{"A_title": "ISecuritySettings#getEnforceMounts(true) prevents access to *all* non-mounted bookmarkable pagesISecuritySettings#setEnforceMounts(true) is meant to be used to prevent access to mounted-pages via BookmarkableMapper e.g. when Page1.class is mounted:     http://localhost:8080/niceurl/a/nice/path/to/the/first/page  ... then the following url will not be accepted:     http://localhost:8080/niceurl/wicket/bookmarkable/org.apache.wicket.examples.niceurl.Page1  But starting with Wicket 1.5.x access to *all* non-mounted pages via BookmarkableMapper is prevented i.e. no url http://localhost:8080/niceurl/wicket/bookmarkable/* is matched.", "A_clean_title": ["isecurityset", "secur", "set", "getenforcemount", "get", "enforc", "mount", "true", "prevent", "access", "all", "non", "mount", "bookmark", "pagesisecurityset", "page", "secur", "set", "setenforcemount", "set", "enforc", "mount", "true", "meant", "use", "prevent", "access", "mount", "page", "via", "bookmarkablemapp", "bookmark", "mapper", "when", "page1", "class", "mount", "http", "localhost:8080", "niceurl", "nice", "path", "first", "page", "then", "follow", "url", "will", "not", "accept", "http", "apach", "wicket", "exampl", "niceurl", "page1", "localhost:8080", "niceurl", "wicket", "bookmark", "org", "but", "start", "wicket", "access", "all", "non", "mount", "page", "via", "bookmarkablemapp", "bookmark", "mapper", "prevent", "no", "url", "http", "localhost:8080", "niceurl", "wicket", "bookmark", "match"], "B_title": "enforce mount for mounted pages only", "B_clean_title": ["enforc", "mount", "mount", "page", "onli"]},
{"A_title": "Instance secret written out with other configuration items to RFiles and WALogs when encryption is turned onThe encryption at rest feature records configuration information in order to encrypted RFiles and WALogs so that if the configuration changes the files can be read back.  The code that does this recording hovers up all the instance.* entries and does not pick out the instance.secret as a special one not to write.  Thus the instance secret goes into each file in the clear which is non-ideal to say the least.  Patch forthcoming.", "A_clean_title": ["instanc", "secret", "written", "out", "other", "configur", "item", "rfile", "file", "walog", "wa", "log", "when", "encrypt", "turn", "onth", "encrypt", "at", "rest", "featur", "record", "configur", "inform", "order", "encrypt", "rfile", "file", "walog", "wa", "log", "so", "that", "configur", "chang", "file", "read", "back", "code", "that", "thi", "record", "hover", "up", "all", "instanc", "entri", "not", "pick", "out", "instanc", "secret", "as", "special", "one", "not", "write", "thu", "instanc", "secret", "goe", "into", "each", "file", "clear", "which", "non", "ideal", "say", "least", "patch", "forthcom"], "B_title": "fixing Michael Allens patch and adding test", "B_clean_title": ["fix", "michael", "allen", "patch", "ad", "test"]},
{"A_title": "Sometimes hierarchy conflict between concurrent add/delete isnt detectedIm not sure of exact set of event that led to an incident on one of our test clusters. The cluster is running 3 AEM instances based on oak build at 1.3.10.r1713699 backed by a single mongo 3 instance.  Unfortunately we found the issue too late and logs had rolled over. Heres the exception that showed over and over as workflow jobs were (trying to) being processed: noformat ....         at java.lang.Thread.run(Thread.java:745) Caused by: javax.jcr.InvalidItemStateException: OakMerge0004: OakMerge0004: The node 8:/oak:index/event.job.topic/:index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel/var/eventing/jobs/assigned was already added in revision r151233e54e1-0-4 before r15166378b6a-0-2 (retries 5 6830 ms)         at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:239)         at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:212)         at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.newRepositoryException(SessionDelegate.java:669)         at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:495)         at org.apache.jackrabbit.oak.jcr.session.SessionImpl 8.performVoid(SessionImpl.java:419)         at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.performVoid(SessionDelegate.java:273)         at org.apache.jackrabbit.oak.jcr.session.SessionImpl.save(SessionImpl.java:416)         at org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProvider.commit(JcrResourceProvider.java:634)         ... 16 common frames omitted Caused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakMerge0004: OakMerge0004: The node 8:/oak:index/event.job.topic/:index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel/var/eventing/jobs/assigned was already added in revision r151233e54e1-0-4 before r15166378b6a-0-2 (retries 5 6830 ms)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge0(DocumentNodeStoreBranch.java:200)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge(DocumentNodeStoreBranch.java:123)         at org.apache.jackrabbit.oak.plugins.document.DocumentRootBuilder.merge(DocumentRootBuilder.java:158)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.merge(DocumentNodeStore.java:1497)         at org.apache.jackrabbit.oak.core.MutableRoot.commit(MutableRoot.java:247)         at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.commit(SessionDelegate.java:346)         at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:493)         ... 20 common frames omitted Caused by: org.apache.jackrabbit.oak.plugins.document.ConflictException: The node 8:/oak:index/event.job.topic/:index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel/var/eventing/jobs/assigned was already added in revision r151233e54e1-0-4 before r15166378b6a-0-2         at org.apache.jackrabbit.oak.plugins.document.Commit.checkConflicts(Commit.java:582)         at org.apache.jackrabbit.oak.plugins.document.Commit.createOrUpdateNode(Commit.java:487)         at org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:371)         at org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:265)         at org.apache.jackrabbit.oak.plugins.document.Commit.applyInternal(Commit.java:234)         at org.apache.jackrabbit.oak.plugins.document.Commit.apply(Commit.java:219)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:290)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:260)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.access 300(DocumentNodeStoreBranch.java:54)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch InMemory.merge(DocumentNodeStoreBranch.java:498)         at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge0(DocumentNodeStoreBranch.java:180)         ... 26 common frames omitted .... noformat  Doing following removed repo corruption and restored w/f processing: noformat oak.removeDescendantsAndSelf(/oak:index/event.job.topic/:index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel/var/eventing/jobs/assigned) noformat  Attaching mongoexport output|^mongoexport.zip for /oak:index/event.job.topic/:index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel/var/eventing/jobs/assigned/6a389a6a-a8bf-4038-b57b-cb441c6ac557/com.adobe.granite.workflow.transient.job.etc.workflow.models.dam-xmp-writeback.jcr_content.model/2015/11/19/23/54/6a389a6a-a8bf-4038-b57b-cb441c6ac557_10 (the hierarchy created at r151233e54e1-0-4). Ive renamed a few path elements to make it more reable though (e.g. :index/com%2Fadobe%2Fgranite%2Fworkflow%2Ftransient%2Fjob%2Fetc%2Fworkflow%2Fmodels%2Fdam-xmp-writeback%2Fjcr_content%2Fmodel -> enc_value).  ~mreutegg Im assigning it to myself for now but I think this would require your expertise all the way :).", "A_clean_title": ["sometim", "hierarchi", "conflict", "between", "concurr", "add", "delet", "isnt", "detectedim", "detect", "im", "not", "sure", "exact", "set", "event", "that", "led", "incid", "one", "our", "test", "cluster", "cluster", "run", "aem", "instanc", "base", "oak", "build", "at", "10", "r1713699", "back", "by", "singl", "mongo", "instanc", "unfortun", "we", "found", "issu", "too", "late", "log", "had", "roll", "over", "here", "except", "that", "show", "over", "over", "as", "workflow", "job", "were", "tri", "be", "process", "noformat", "at", "java", "lang", "thread", "run", "thread", "java:745", "caus", "by", "javax", "jcr", "invaliditemstateexcept", "invalid", "item", "state", "except", "oakmerge0004", "oak", "merge0004", "oakmerge0004", "oak", "merge0004", "node", "oak", "job", "index", "event", "topic", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "2fmodel", "var", "event", "job", "assign", "wa", "alreadi", "ad", "revis", "r151233e54e1", "befor", "r15166378b6a", "retri", "6830", "ms", "at", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "asrepositoryexcept", "commit", "fail", "except", "as", "repositori", "except", "commitfailedexcept", "java:239", "commit", "fail", "except", "at", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "asrepositoryexcept", "commit", "fail", "except", "as", "repositori", "except", "commitfailedexcept", "java:212", "commit", "fail", "except", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "newrepositoryexcept", "session", "deleg", "new", "repositori", "except", "sessiondeleg", "java:669", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:495", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "session", "impl", "performvoid", "perform", "void", "sessionimpl", "java:419", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "performvoid", "session", "deleg", "perform", "void", "sessiondeleg", "java:273", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "save", "session", "impl", "sessionimpl", "java:416", "session", "impl", "at", "org", "apach", "sling", "jcr", "resourc", "intern", "helper", "jcr", "jcrresourceprovid", "commit", "jcr", "resourc", "provid", "jcrresourceprovid", "java:634", "jcr", "resourc", "provid", "16", "common", "frame", "omit", "caus", "by", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "commit", "fail", "except", "oakmerge0004", "oak", "merge0004", "oakmerge0004", "oak", "merge0004", "node", "oak", "job", "index", "event", "topic", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "2fmodel", "var", "event", "job", "assign", "wa", "alreadi", "ad", "revis", "r151233e54e1", "befor", "r15166378b6a", "retri", "6830", "ms", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "merge0", "document", "node", "store", "branch", "documentnodestorebranch", "java:200", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "merg", "document", "node", "store", "branch", "documentnodestorebranch", "java:123", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentrootbuild", "merg", "document", "root", "builder", "documentrootbuild", "java:158", "document", "root", "builder", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "merg", "document", "node", "store", "documentnodestor", "java:1497", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "core", "mutableroot", "commit", "mutabl", "root", "mutableroot", "java:247", "mutabl", "root", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "commit", "session", "deleg", "sessiondeleg", "java:346", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:493", "session", "deleg", "20", "common", "frame", "omit", "caus", "by", "org", "apach", "jackrabbit", "oak", "plugin", "document", "conflictexcept", "conflict", "except", "node", "oak", "job", "index", "event", "topic", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "2fmodel", "var", "event", "job", "assign", "wa", "alreadi", "ad", "revis", "r151233e54e1", "befor", "r15166378b6a", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "checkconflict", "check", "conflict", "commit", "java:582", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "createorupdatenod", "creat", "or", "updat", "node", "commit", "java:487", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "applytodocumentstor", "appli", "document", "store", "commit", "java:371", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "applytodocumentstor", "appli", "document", "store", "commit", "java:265", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "applyintern", "appli", "intern", "commit", "java:234", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "commit", "appli", "commit", "java:219", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "persist", "document", "node", "store", "branch", "documentnodestorebranch", "java:290", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "persist", "document", "node", "store", "branch", "documentnodestorebranch", "java:260", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "access", "document", "node", "store", "branch", "300", "documentnodestorebranch", "java:54", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "document", "node", "store", "branch", "inmemori", "merg", "memori", "documentnodestorebranch", "java:498", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "merge0", "document", "node", "store", "branch", "documentnodestorebranch", "java:180", "document", "node", "store", "branch", "26", "common", "frame", "omit", "noformat", "do", "follow", "remov", "repo", "corrupt", "restor", "process", "noformat", "oak", "removedescendantsandself", "remov", "descend", "self", "oak", "job", "index", "event", "topic", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "2fmodel", "var", "event", "job", "assign", "noformat", "attach", "mongoexport", "output|^mongoexport", "zip", "oak", "job", "index", "event", "topic", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "a8bf", "4038", "b57b", "xmp", "a8bf", "4038", "b57b", "2fmodel", "var", "event", "job", "assign", "6a389a6a", "adob", "granit", "workflow", "transient", "job", "etc", "workflow", "model", "dam", "writeback", "cb441c6ac557", "10", "cb441c6ac557", "com", "jcr", "content", "model", "2015", "11", "19", "23", "54", "6a389a6a", "hierarchi", "creat", "at", "r151233e54e1", "ive", "renam", "few", "path", "element", "make", "it", "more", "reabl", "though", "index", "com", "2fadob", "2fgranit", "2fworkflow", "2ftransient", "2fjob", "2fetc", "2fworkflow", "2fmodel", "2fdam", "xmp", "writeback", "2fjcr", "content", "2fmodel", "enc", "valu", "~mreutegg", "im", "assign", "it", "myself", "now", "but", "think", "thi", "would", "requir", "your", "expertis", "all", "way"], "B_title": "Sometimes hierarchy conflict between concurrent add/delete isnt detected", "B_clean_title": ["sometim", "hierarchi", "conflict", "between", "concurr", "add", "delet", "isnt", "detect"]},
{"A_title": "Shells setiter is not informative when using a bad class nameIn the shell I did setiter using a class that wasnt found. Rather then a message about it not being found I just get told that I have an invalid argument. Even turning on debug I had to use the stack trace to figure out why it was erroring.", "A_clean_title": ["shell", "setit", "not", "inform", "when", "bad", "class", "namein", "name", "shell", "did", "setit", "class", "that", "wasnt", "found", "rather", "then", "messag", "about", "it", "not", "be", "found", "just", "get", "told", "that", "have", "invalid", "argument", "even", "turn", "debug", "had", "use", "stack", "trace", "figur", "out", "whi", "it", "wa", "error"], "B_title": "Appled patch from Mike Drob with modification to delete table in unit test.", "B_clean_title": ["appl", "patch", "mike", "drob", "modif", "delet", "tabl", "unit", "test"]},
{"A_title": "Wicket example forminput is broken due to bad url for IOnChangeListenerhttp://localhost:8080/forminput (wicket-examples) doesnt change the locale of the labels when the locale select is changed. The reason seems to be the produced url: ./.?5-1.IOnChangeListener-inputForm-localeSelect  This is parsed to a Url with one empty segment and thus HomePageMapper doesnt match it and doesnt handle it.", "A_clean_title": ["wicket", "exampl", "forminput", "broken", "due", "bad", "url", "ionchangelistenerhttp", "chang", "listenerhttp", "localhost:8080", "forminput", "wicket", "exampl", "doesnt", "chang", "local", "label", "when", "local", "select", "chang", "reason", "seem", "produc", "url", "inputform", "localeselect", "ionchangelisten", "input", "form", "local", "select", "chang", "listen", "thi", "pars", "url", "one", "empti", "segment", "thu", "homepagemapp", "home", "page", "mapper", "doesnt", "match", "it", "doesnt", "handl", "it"], "B_title": "remove empty segments when resolving relative url", "B_clean_title": ["remov", "empti", "segment", "when", "resolv", "rel", "url"]},
{"A_title": "CtFieldReference.getDefaultExpression() returns initializer from a field of another classHi Im trying to collect and evaluate certain strings in the source repository.  I tried VisitorPartialEvaluator but it runs into an infinite loop. The reason of this is that fields get mixed up. The code setup is like this:   Now if you try to read the return value of the  getKey() method the CtFieldReference object will return the default value of ClassB.PREFIX  not BaseClass.PREFIX .", "A_clean_title": ["ctfieldrefer", "getdefaultexpress", "ct", "field", "refer", "get", "default", "express", "return", "initi", "field", "anoth", "classhi", "class", "hi", "im", "tri", "collect", "evalu", "certain", "string", "sourc", "repositori", "tri", "visitorpartialevalu", "visitor", "partial", "evalu", "but", "it", "run", "into", "infinit", "loop", "reason", "thi", "that", "field", "get", "mix", "up", "code", "setup", "like", "thi", "now", "you", "tri", "read", "return", "valu", "getkey", "get", "key", "method", "ctfieldrefer", "ct", "field", "refer", "object", "will", "return", "default", "valu", "classb", "prefix", "class", "not", "baseclass", "prefix", "base", "class"], "B_title": "fix: fix bug in getDeclaration(). Closes #1213. (PR #1215)  This change impacts declaration lookup of field references after clone.", "B_clean_title": ["fix", "fix", "bug", "getdeclar", "get", "declar", "close", "1213", "pr", "1215", "thi", "chang", "impact", "declar", "lookup", "field", "refer", "after", "clone"]},
{"A_title": "Slow event listeners do not scale as expectedorg.apache.jackrabbit.oak.jcr.LargeOperationIT#slowListener does not scale to O n log n on the document node store.", "A_clean_title": ["slow", "event", "listen", "not", "scale", "as", "expectedorg", "apach", "jackrabbit", "oak", "jcr", "largeoperationit", "larg", "oper", "it", "slowlisten", "slow", "listen", "not", "scale", "log", "document", "node", "store"], "B_title": "Slow event listeners do not scale as expected", "B_clean_title": ["slow", "event", "listen", "not", "scale", "as", "expect"]},
{"A_title": "Internal Compiler Error on BulletNone", "A_clean_title": ["intern", "compil", "error", "bulletnon", "bullet", "none"], "B_title": "Label names must be made unique when inlining a function. Fixes issue 435", "B_clean_title": ["label", "name", "must", "made", "uniqu", "when", "inlin", "function", "fix", "issu", "435"]},
{"A_title": "RandomDataImpl.nextPoisson fails for means in range 6.0 - 19.99math.random.RandomDataImpl.nextPoisson(double mean) fails frequently (but not always) for values of mean between 6.0 and 19.99 inclusive. For values below 6.0 (where I see there is a branch in the logic) and above 20.0 it seems to be okay (though Ive only randomly sampled the space and run a million trials for the values Ive tried)  When it fails the exception is as follows (this for a mean of 6.0)  org.apache.commons.math.MathRuntimeException 4: must have n >= 0 for n! got n = -2 at org.apache.commons.math.MathRuntimeException.createIllegalArgumentException(MathRuntimeException.java:282) at org.apache.commons.math.util.MathUtils.factorialLog(MathUtils.java:561) at org.apache.commons.math.random.RandomDataImpl.nextPoisson(RandomDataImpl.java:434)   ie MathUtils.factorialLog is being called with a negative input  To reproduce:      JDKRandomGenerator random = new JDKRandomGenerator();     random.setSeed(123456);     RandomData randomData = new RandomDataImpl(random);      for (int i=0; i< 1000000; i++)         randomData.nextPoisson(6.0);", "A_clean_title": ["randomdataimpl", "nextpoisson", "random", "data", "impl", "next", "poisson", "fail", "mean", "rang", "19", "99math", "random", "randomdataimpl", "nextpoisson", "random", "data", "impl", "next", "poisson", "doubl", "mean", "fail", "frequent", "but", "not", "alway", "valu", "mean", "between", "19", "99", "inclus", "valu", "below", "where", "see", "there", "branch", "logic", "abov", "20", "it", "seem", "okay", "though", "ive", "onli", "randomli", "sampl", "space", "run", "million", "trial", "valu", "ive", "tri", "when", "it", "fail", "except", "as", "follow", "thi", "mean", "org", "apach", "common", "math", "mathruntimeexcept", "math", "runtim", "except", "must", "have", "got", "at", "org", "apach", "common", "math", "mathruntimeexcept", "createillegalargumentexcept", "math", "runtim", "except", "creat", "illeg", "argument", "except", "mathruntimeexcept", "java:282", "math", "runtim", "except", "at", "org", "apach", "common", "math", "util", "mathutil", "factoriallog", "math", "util", "factori", "log", "mathutil", "java:561", "math", "util", "at", "org", "apach", "common", "math", "random", "randomdataimpl", "nextpoisson", "random", "data", "impl", "next", "poisson", "randomdataimpl", "java:434", "random", "data", "impl", "ie", "mathutil", "factoriallog", "math", "util", "factori", "log", "be", "call", "neg", "input", "reproduc", "jdkrandomgener", "jdk", "random", "gener", "random", "new", "jdkrandomgener", "jdk", "random", "gener", "random", "setse", "set", "seed", "123456", "randomdata", "random", "data", "randomdata", "random", "data", "new", "randomdataimpl", "random", "data", "impl", "random", "int", "i=0", "1000000", "i++", "randomdata", "nextpoisson", "random", "data", "next", "poisson"], "B_title": "Implemented alternative algorithm for generating poisson deviates when the mean is large. JIRA: MATH-294.", "B_clean_title": ["implement", "altern", "algorithm", "gener", "poisson", "deviat", "when", "mean", "larg", "jira", "math", "294"]},
{"A_title": "NPE in DocumentNodeStore#retrieve for non existing checkpointSaid method throws a NPE when passing it a valid revision identifier from a non existing checkpoint.", "A_clean_title": ["npe", "documentnodestor", "document", "node", "store", "retriev", "non", "exist", "checkpointsaid", "checkpoint", "said", "method", "throw", "npe", "when", "pass", "it", "valid", "revis", "identifi", "non", "exist", "checkpoint"], "B_title": "NPE in DocumentNodeStore#retrieve for non existing checkpoint Add null check and test case", "B_clean_title": ["npe", "documentnodestor", "document", "node", "store", "retriev", "non", "exist", "checkpoint", "add", "null", "check", "test", "case"]},
{"A_title": "MockBatchScanner inappropriately filters on rangesI believe I have a legitimate case where an iterator will return something outside of the seeked-to range.  This appears to work in a live system but fails to work in test cases using the MockBatchScanner.  I believe this is because the MockBatchScanner filters on the supplied ranges in addition to seeking the iterators to each range.  Either we need to remove this range filter or fix the real system to do the same thing.  I prefer the former of course.", "A_clean_title": ["mockbatchscann", "mock", "batch", "scanner", "inappropri", "filter", "rangesi", "rang", "believ", "have", "legitim", "case", "where", "iter", "will", "return", "someth", "outsid", "seek", "rang", "thi", "appear", "work", "live", "system", "but", "fail", "work", "test", "case", "mockbatchscann", "mock", "batch", "scanner", "believ", "thi", "becaus", "mockbatchscann", "mock", "batch", "scanner", "filter", "suppli", "rang", "addit", "seek", "iter", "each", "rang", "either", "we", "need", "remov", "thi", "rang", "filter", "or", "fix", "real", "system", "same", "thing", "prefer", "former", "cours"], "B_title": "unit test out-of-range keys returned from an iterator stack", "B_clean_title": ["unit", "test", "out", "rang", "key", "return", "iter", "stack"]},
{"A_title": "The DateTimeField.onBeforeRender() method does not format the fields correctly.The current implementation relies on the org.joda.time.MutableDateTime instance to format the date hours amOrPm and minutes fields. Unfortunately the MutableDateTime constructor is not provided with the clients TimeZone value (assuming it is set). As a result the joda library uses the JVMs default timezone. If the defaul timezone differs from the clients timezone the formatted fields may turn out to be incorrect.", "A_clean_title": ["datetimefield", "onbeforerend", "date", "time", "field", "befor", "render", "method", "not", "format", "field", "correctli", "current", "implement", "reli", "org", "joda", "time", "mutabledatetim", "mutabl", "date", "time", "instanc", "format", "date", "hour", "amorpm", "am", "or", "pm", "minut", "field", "unfortun", "mutabledatetim", "mutabl", "date", "time", "constructor", "not", "provid", "client", "timezon", "time", "zone", "valu", "assum", "it", "set", "as", "result", "joda", "librari", "use", "jvm", "jv", "ms", "default", "timezon", "defaul", "timezon", "differ", "client", "timezon", "format", "field", "may", "turn", "out", "incorrect"], "B_title": "The DateTimeField.onBeforeRender() method does not format the fields correctly.", "B_clean_title": ["datetimefield", "onbeforerend", "date", "time", "field", "befor", "render", "method", "not", "format", "field", "correctli"]},
{"A_title": "Item names with trailing spaces should not be allowedthe following should fail:  code         Node hello = session.getRootNode().addNode(hello);         session.save();          Node illegal = hello.addNode(test ); <-- here         session.save();          assertEquals(/hello/test  illegal.getPath()); <-- and here          Node other = session.getNode(/hello/test ); <-- and here         assertTrue(other.isSame(illegal));         assertTrue(session.nodeExists(/hello/test )); <-- and here code", "A_clean_title": ["item", "name", "trail", "space", "not", "allowedth", "follow", "fail", "code", "node", "hello", "session", "getrootnod", "get", "root", "node", "addnod", "add", "node", "hello", "session", "save", "node", "illeg", "hello", "addnod", "add", "node", "test", "here", "session", "save", "assertequ", "assert", "equal", "hello", "test", "illeg", "getpath", "get", "path", "here", "node", "other", "session", "getnod", "get", "node", "hello", "test", "here", "asserttru", "assert", "true", "other", "issam", "same", "illeg", "asserttru", "assert", "true", "session", "nodeexist", "node", "exist", "hello", "test", "here", "code"], "B_title": "Item names with trailing spaces should not be allowed", "B_clean_title": ["item", "name", "trail", "space", "not", "allow"]},
{"A_title": "IllegalStateException in MemoryNodeBuilderAuthorizablePropertyTest.testSetPropertyByRelPath() sometimes causes an IllegalStateException in MemoryNodeBuilder. This might be a problem with the latter uncovered by the recent switch to the p2 index mechanism (OAK-511).  code java.lang.IllegalStateException     at com.google.common.base.Preconditions.checkState(Preconditions.java:133)     at org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.read(MemoryNodeBuilder.java:205)     at org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.getChildNodeNames(MemoryNodeBuilder.java:379)     at org.apache.jackrabbit.oak.plugins.index.p2.strategy.ContentMirrorStoreStrategy.remove(ContentMirrorStoreStrategy.java:66)     at org.apache.jackrabbit.oak.plugins.index.p2.Property2IndexUpdate.apply(Property2IndexUpdate.java:143)     at org.apache.jackrabbit.oak.plugins.index.p2.Property2IndexDiff.apply(Property2IndexDiff.java:232)     at org.apache.jackrabbit.oak.plugins.index.IndexHookManager.apply(IndexHookManager.java:71)     at org.apache.jackrabbit.oak.plugins.index.IndexHookManager.processCommit(IndexHookManager.java:61)     at org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:59)     at org.apache.jackrabbit.oak.kernel.KernelNodeStoreBranch.merge(KernelNodeStoreBranch.java:127)     at org.apache.jackrabbit.oak.core.RootImpl 2.run(RootImpl.java:240)     at org.apache.jackrabbit.oak.core.RootImpl 2.run(RootImpl.java:236)     at java.security.AccessController.doPrivileged(Native Method)     at javax.security.auth.Subject.doAs(Subject.java:337)     at org.apache.jackrabbit.oak.core.RootImpl.commit(RootImpl.java:235)     at org.apache.jackrabbit.oak.jcr.SessionDelegate.save(SessionDelegate.java:255)     at org.apache.jackrabbit.oak.jcr.SessionImpl.save(SessionImpl.java:283)     at org.apache.jackrabbit.oak.jcr.security.user.AbstractUserTest.tearDown(AbstractUserTest.java:72)     at org.apache.jackrabbit.test.AbstractJCRTest.run(AbstractJCRTest.java:456)     at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)     at org.junit.runner.JUnitCore.run(JUnitCore.java:157)     at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:76)     at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:195)     at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:63)     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)     at com.intellij.rt.execution.application.AppMain.main(AppMain.java:120)  code", "A_clean_title": ["illegalstateexcept", "illeg", "state", "except", "memorynodebuilderauthorizablepropertytest", "testsetpropertybyrelpath", "memori", "node", "builder", "authoriz", "properti", "test", "test", "set", "properti", "by", "rel", "path", "sometim", "caus", "illegalstateexcept", "illeg", "state", "except", "memorynodebuild", "memori", "node", "builder", "thi", "might", "problem", "latter", "uncov", "by", "recent", "switch", "p2", "index", "mechan", "oak", "511", "code", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "at", "com", "googl", "common", "base", "precondit", "checkstat", "check", "state", "precondit", "java:133", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "memorynodebuild", "read", "memori", "node", "builder", "memorynodebuild", "java:205", "memori", "node", "builder", "at", "org", "apach", "jackrabbit", "oak", "plugin", "memori", "memorynodebuild", "getchildnodenam", "memori", "node", "builder", "get", "child", "node", "name", "memorynodebuild", "java:379", "memori", "node", "builder", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "p2", "strategi", "contentmirrorstorestrategi", "remov", "content", "mirror", "store", "strategi", "contentmirrorstorestrategi", "java:66", "content", "mirror", "store", "strategi", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "p2", "property2indexupd", "appli", "property2index", "updat", "property2indexupd", "java:143", "property2index", "updat", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "p2", "property2indexdiff", "appli", "property2index", "diff", "property2indexdiff", "java:232", "property2index", "diff", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "indexhookmanag", "appli", "index", "hook", "manag", "indexhookmanag", "java:71", "index", "hook", "manag", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "indexhookmanag", "processcommit", "index", "hook", "manag", "process", "commit", "indexhookmanag", "java:61", "index", "hook", "manag", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositehook", "processcommit", "composit", "hook", "process", "commit", "compositehook", "java:59", "composit", "hook", "at", "org", "apach", "jackrabbit", "oak", "kernel", "kernelnodestorebranch", "merg", "kernel", "node", "store", "branch", "kernelnodestorebranch", "java:127", "kernel", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "root", "impl", "run", "rootimpl", "java:240", "root", "impl", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "root", "impl", "run", "rootimpl", "java:236", "root", "impl", "at", "java", "secur", "accesscontrol", "doprivileg", "access", "control", "privileg", "nativ", "method", "at", "javax", "secur", "auth", "subject", "doa", "as", "subject", "java:337", "at", "org", "apach", "jackrabbit", "oak", "core", "rootimpl", "commit", "root", "impl", "rootimpl", "java:235", "root", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:255", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "sessionimpl", "save", "session", "impl", "sessionimpl", "java:283", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "secur", "user", "abstractusertest", "teardown", "abstract", "user", "test", "tear", "down", "abstractusertest", "java:72", "abstract", "user", "test", "at", "org", "apach", "jackrabbit", "test", "abstractjcrtest", "run", "abstract", "jcr", "test", "abstractjcrtest", "java:456", "abstract", "jcr", "test", "at", "org", "junit", "intern", "runner", "junit38classrunn", "run", "unit38class", "runner", "junit38classrunn", "java:83", "unit38class", "runner", "at", "org", "junit", "runner", "junitcor", "run", "unit", "core", "junitcor", "java:157", "unit", "core", "at", "com", "intellij", "junit4", "junit4ideatestrunn", "startrunnerwitharg", "unit4idea", "test", "runner", "start", "runner", "arg", "junit4ideatestrunn", "java:76", "unit4idea", "test", "runner", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "preparestreamsandstart", "unit", "starter", "prepar", "stream", "start", "junitstart", "java:195", "unit", "starter", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "main", "unit", "starter", "junitstart", "java:63", "unit", "starter", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:39", "nativ", "method", "accessor", "impl", "at", "com", "intellij", "rt", "execut", "applic", "appmain", "main", "app", "main", "appmain", "java:120", "app", "main", "code"], "B_title": "IllegalStateException in MemoryNodeBuilder", "B_clean_title": ["illegalstateexcept", "illeg", "state", "except", "memorynodebuild", "memori", "node", "builder"]},
{"A_title": "Incorrect handling of multivalued comparisons in queriesSection 6.7.14|http://www.day.com/specs/jcr/2.0/6_Query.html#6.7.16 Comparison of the JCR 2.0 spec says:  bq. ... operand1 may evaluate to an array of values (for example the values of a multi-valued property) in which case the comparison is separately performed for each element of the array and the Comparison constraint is satisfied as a whole if the comparison against any element of the array is satisfied.  This is currently not the case in Oak. Instead only the first value of the array is used in the comparison.", "A_clean_title": ["incorrect", "handl", "multivalu", "comparison", "queriessect", "queri", "section", "14|http", "day", "html", "www", "com", "spec", "jcr", "queri", "16", "comparison", "jcr", "spec", "say", "bq", "operand1", "may", "evalu", "array", "valu", "exampl", "valu", "multi", "valu", "properti", "which", "case", "comparison", "separ", "perform", "each", "element", "array", "comparison", "constraint", "satisfi", "as", "whole", "comparison", "against", "ani", "element", "array", "satisfi", "thi", "current", "not", "case", "oak", "instead", "onli", "first", "valu", "array", "use", "comparison"], "B_title": "Incorrect handling of multivalued comparisons in queries", "B_clean_title": ["incorrect", "handl", "multivalu", "comparison", "queri"]},
{"A_title": "Mockito 1.10.x timeout verification needs JUnit classes (VerifyError NoClassDefFoundError)If JUnit is not on the classpath and mockito is version 1.10.x (as of now 1.10.1 up to 1.10.19) and the code is using the timeout verification which is not supposed to be related to JUnit then the JVM may fail with a VerifyError or a NoClassDefFoundError.", "A_clean_title": ["mockito", "10", "timeout", "verif", "need", "junit", "unit", "class", "verifyerror", "verifi", "error", "noclassdeffounderror", "no", "class", "def", "found", "error", "junit", "unit", "not", "classpath", "mockito", "version", "10", "as", "now", "10", "up", "10", "19", "code", "timeout", "verif", "which", "not", "suppos", "relat", "junit", "unit", "then", "jvm", "may", "fail", "verifyerror", "verifi", "error", "or", "noclassdeffounderror", "no", "class", "def", "found", "error"], "B_title": "Merge branch issue-152-incorrect-junit-dependencies", "B_clean_title": ["merg", "branch", "issu", "152", "incorrect", "junit", "depend"]},
{"A_title": "A 404 error occurs when using a CryptoMapperUnder certain prerequisites a 404 error occurs.  The prerequisites are: - A _CryptoMapper_ is used as _RequestMapper_ - _SecuritySettings.enforceMounts_ is set to true - Class _SomePage_ is *not* annotated with _@MountPath_  Reason: In _BookmarkableMapper.parseRequest_ (called indirectly by _CryptoMapper.mapRequest_) the method _matches_ returns _false_ as _reverseUrl_ is the *encrypted URL* (_rootRequestMapper_ is a _CryptoMapper_) but _BookmarkableMapper.matches_ expects a *decrypted URL*.  _BookmarkableMapper_ - lines 132 ff.: code Url reverseUrl = application.getRootRequestMapper().mapHandler( new RenderPageRequestHandler(new PageProvider(pageClass))); if (!matches(request.cloneWithUrl(reverseUrl)))  return null;  code  As a result _BookmarkableMapper.mapRequest_ and hence _CryptoMapper.mapRequest_ returns _null_ resulting in a 404 error.", "A_clean_title": ["404", "error", "occur", "when", "cryptomapperund", "crypto", "mapper", "under", "certain", "prerequisit", "404", "error", "occur", "prerequisit", "are", "cryptomapp", "crypto", "mapper", "use", "as", "requestmapp", "request", "mapper", "securityset", "enforcemount", "secur", "set", "enforc", "mount", "set", "true", "class", "somepag", "some", "page", "not", "annot", "mountpath", "mount", "path", "reason", "bookmarkablemapp", "parserequest", "bookmark", "mapper", "pars", "request", "call", "indirectli", "by", "cryptomapp", "maprequest", "crypto", "mapper", "map", "request", "method", "match", "return", "fals", "as", "reverseurl", "revers", "url", "encrypt", "url", "rootrequestmapp", "root", "request", "mapper", "cryptomapp", "crypto", "mapper", "but", "bookmarkablemapp", "match", "bookmark", "mapper", "expect", "decrypt", "url", "bookmarkablemapp", "bookmark", "mapper", "line", "132", "ff", "code", "url", "reverseurl", "revers", "url", "applic", "getrootrequestmapp", "get", "root", "request", "mapper", "maphandl", "map", "handler", "new", "renderpagerequesthandl", "render", "page", "request", "handler", "new", "pageprovid", "page", "provid", "pageclass", "page", "class", "match", "request", "clonewithurl", "clone", "url", "reverseurl", "revers", "url", "return", "null", "code", "as", "result", "bookmarkablemapp", "maprequest", "bookmark", "mapper", "map", "request", "henc", "cryptomapp", "maprequest", "crypto", "mapper", "map", "request", "return", "null", "result", "404", "error"], "B_title": "BookmarkableMapper now checks if a page is mounted to work properly if we use CryptoMapper and we are enforce page mounting", "B_clean_title": ["bookmarkablemapp", "bookmark", "mapper", "now", "check", "page", "mount", "work", "properli", "we", "use", "cryptomapp", "crypto", "mapper", "we", "are", "enforc", "page", "mount"]},
{"A_title": "NodeBuilder deleted child nodes can come backWhile working on OAK-520 Ive noticed a problem with the NodeBuilder: when we delete an entire hierarchy of nodes and then recreate a part of it some of the previously deleted nodes can come back.  This only happens when there are more than 3 levels of nodes.  So given a hierarchy of nodes: /x/y/z deleted x and simply use the NodeBuilder to traverse down on the same path: .child(x).child(y). At this point the z child reappears even though it was deleted before.   Ill attach a test case shortly.", "A_clean_title": ["nodebuild", "node", "builder", "delet", "child", "node", "come", "backwhil", "back", "while", "work", "oak", "520", "ive", "notic", "problem", "nodebuild", "node", "builder", "when", "we", "delet", "entir", "hierarchi", "node", "then", "recreat", "part", "it", "some", "previous", "delet", "node", "come", "back", "thi", "onli", "happen", "when", "there", "are", "more", "than", "level", "node", "so", "given", "hierarchi", "node", "delet", "simpli", "use", "nodebuild", "node", "builder", "travers", "down", "same", "path", "child", "child", "at", "thi", "point", "child", "reappear", "even", "though", "it", "wa", "delet", "befor", "ill", "attach", "test", "case", "shortli"], "B_title": "NodeBuilder deleted child nodes can come back", "B_clean_title": ["nodebuild", "node", "builder", "delet", "child", "node", "come", "back"]},
{"A_title": "Commit fails even though change made it to the DocumentStoreIn some rare cases it may happen that the DocumentNodeStore considers a commit as failed even though the changes were applied entirely to the DocumentStore. The issue happens when the update of the commit root is applied to the storage of a DocumentStore but then shortly after the communication between Oak the the storage system fails. On the Oak side the call will be considered as failed but the change was actually applied.  The issue can be reproduced with the test attached to OAK-1641 and a replica-set with 3 nodes. Killing the primary node and restarting it a after a while in a loop will eventually lead to a commit that conflicts itself.", "A_clean_title": ["commit", "fail", "even", "though", "chang", "made", "it", "documentstorein", "document", "store", "some", "rare", "case", "it", "may", "happen", "that", "documentnodestor", "document", "node", "store", "consid", "commit", "as", "fail", "even", "though", "chang", "were", "appli", "entir", "documentstor", "document", "store", "issu", "happen", "when", "updat", "commit", "root", "appli", "storag", "documentstor", "document", "store", "but", "then", "shortli", "after", "commun", "between", "oak", "storag", "system", "fail", "oak", "side", "call", "will", "consid", "as", "fail", "but", "chang", "wa", "actual", "appli", "issu", "reproduc", "test", "attach", "oak", "1641", "replica", "set", "node", "kill", "primari", "node", "restart", "it", "after", "while", "loop", "will", "eventu", "lead", "commit", "that", "conflict", "itself"], "B_title": "Commit fails even though change made it to the DocumentStore", "B_clean_title": ["commit", "fail", "even", "though", "chang", "made", "it", "documentstor", "document", "store"]},
{"A_title": "MultivariateNormalDistribution.density(double) returns wrong value when the dimension is oddTo reproduce:  Assert.assertEquals(0.398942280401433 new MultivariateNormalDistribution(new double0 new double1).density(new double0) 1e-15);", "A_clean_title": ["multivariatenormaldistribut", "densiti", "multivari", "normal", "distribut", "doubl", "return", "wrong", "valu", "when", "dimens", "oddto", "odd", "reproduc", "assert", "assertequ", "assert", "equal", "398942280401433", "new", "multivariatenormaldistribut", "multivari", "normal", "distribut", "new", "double0", "new", "double1", "densiti", "new", "double0", "1e", "15"], "B_title": "Fixed truncated value. Thanks to Piotr Wydrych. Added unit test: comparing density values with univariate normal distribution.", "B_clean_title": ["fix", "truncat", "valu", "thank", "piotr", "wydrych", "ad", "unit", "test", "compar", "densiti", "valu", "univari", "normal", "distribut"]},
{"A_title": "FastMath.pow(double long) enters an infinite loop with Long.MIN_VALUEFastMath.pow(double long) enters an infinite loop with Long.MIN_VALUE. It cannot be negated so unsigned shift (>>>) is required instead of a signed one (>>).", "A_clean_title": ["fastmath", "pow", "fast", "math", "doubl", "long", "enter", "infinit", "loop", "long", "pow", "min", "valuefastmath", "valu", "fast", "math", "doubl", "long", "enter", "infinit", "loop", "long", "min", "valu", "it", "not", "negat", "so", "unsign", "shift", "requir", "instead", "sign", "one"], "B_title": "Fixed infinite loop in FastMath.pow(double long) with Long.MIN_VALUE.", "B_clean_title": ["fix", "infinit", "loop", "fastmath", "pow", "fast", "math", "doubl", "long", "long", "min", "valu"]},
{"A_title": "Make sure iterators handle deletion entries properlyIn minor compaction scope and in non-full major compaction scopes the iterator may see deletion entries. These entries should be preserved by all iterators except ones that are strictly scan-time iterators that will never be configured for the minc or majc scopes. Deletion entries are only removed during full major compactions.", "A_clean_title": ["make", "sure", "iter", "handl", "delet", "entri", "properlyin", "properli", "minor", "compact", "scope", "non", "full", "major", "compact", "scope", "iter", "may", "see", "delet", "entri", "these", "entri", "preserv", "by", "all", "iter", "except", "one", "that", "are", "strictli", "scan", "time", "iter", "that", "will", "never", "configur", "minc", "or", "majc", "scope", "delet", "entri", "are", "onli", "remov", "dure", "full", "major", "compact"], "B_title": "made GrepIterator a Filter to handle deletions - trunk", "B_clean_title": ["made", "grepiter", "grep", "iter", "filter", "handl", "delet", "trunk"]},
{"A_title": "MapSerializer._orderEntries() throws NPE when operating on ConcurrentHashMapIt seems that the fix introduced for  #1411 in 2.8 can be problematic for ConcurrentSkipListMap (and possibly other map data structures).  doc for ConcurrentSkipListMap.doGet()", "A_clean_title": ["mapseri", "map", "serial", "orderentri", "order", "entri", "throw", "npe", "when", "oper", "concurrenthashmapit", "concurr", "hash", "map", "it", "seem", "that", "fix", "introduc", "1411", "problemat", "concurrentskiplistmap", "concurr", "skip", "list", "map", "possibl", "other", "map", "data", "structur", "doc", "concurrentskiplistmap", "doget", "concurr", "skip", "list", "map", "get"], "B_title": "Fixed #1513", "B_clean_title": ["fix", "1513"]},
{"A_title": "element.toString() crashes with a NP in DefaultJavaPrettyPrinter.visitCtTypeReference()When analyzing elasticsearch we get a NP when calling element.toString().  As this has something to do with type references I cant give you a concrete source file with this problem but rather a part of the project as tar archive. (  elasticsearch.tar.gz )", "A_clean_title": ["element", "tostr", "string", "crash", "np", "defaultjavaprettyprint", "visitcttyperefer", "default", "java", "pretti", "printer", "visit", "ct", "type", "refer", "when", "analyz", "elasticsearch", "we", "get", "np", "when", "call", "element", "tostr", "string", "as", "thi", "ha", "someth", "type", "refer", "cant", "give", "you", "concret", "sourc", "file", "thi", "problem", "but", "rather", "part", "project", "as", "tar", "archiv", "elasticsearch", "tar", "gz"], "B_title": "fix: visibility detection issue in CtElement #1099 (#1102)  * reproduce ElasticSearch access path problem #1099    * fix access path problem    * fix other tests    * Add one more assert on tests to check behaviour when overriding inner class. Replace some assertTrue by assertEquals to help debug test.", "B_clean_title": ["fix", "visibl", "detect", "issu", "ctelement", "ct", "element", "1099", "1102", "reproduc", "elasticsearch", "elast", "search", "access", "path", "problem", "1099", "fix", "access", "path", "problem", "fix", "other", "test", "add", "one", "more", "assert", "test", "check", "behaviour", "when", "overrid", "inner", "class", "replac", "some", "asserttru", "assert", "true", "by", "assertequ", "assert", "equal", "help", "debug", "test"]},
{"A_title": "RestartResponseAtInterceptPageException.InterceptData is never clearedRestartResponseAtInterceptPageException.InterceptData is supposed to be cleared after continueToOriginalDestination() is called. This is accomplished via RestartResponseAtInterceptPageException.MAPPER which is registered in the SystemMapper.  However there seems to be a serious bug here. The MAPPER always returns a compatibilityScore of 0 and thus is never actually invoked. The InterceptData is thus never cleared. Furthermore even if the MAPPER did return a Integer.MAX_VALUE score it would still not be invoked in many scenarios since other mappers in the SystemMapper are registered later and therefore have higher priority.  In practice this can lead to very odd login behavior in Wicket applications (which is where RestartResponseAtInterceptPageException is typically used). For example if the user clicks a login link they may end up on a totally unexpected page due to stale InterceptData that is hanging around in the session.  I am attaching a quick start that demonstrates the problem as well as a patch the fixes the compatibilityScore and moves the MAPPER to a higher priority in the SystemMapper.", "A_clean_title": ["restartresponseatinterceptpageexcept", "interceptdata", "restart", "respons", "at", "intercept", "page", "except", "intercept", "data", "never", "clearedrestartresponseatinterceptpageexcept", "interceptdata", "clear", "restart", "respons", "at", "intercept", "page", "except", "intercept", "data", "suppos", "clear", "after", "continuetooriginaldestin", "continu", "origin", "destin", "call", "thi", "accomplish", "via", "restartresponseatinterceptpageexcept", "mapper", "restart", "respons", "at", "intercept", "page", "except", "which", "regist", "systemmapp", "system", "mapper", "howev", "there", "seem", "seriou", "bug", "here", "mapper", "alway", "return", "compatibilityscor", "compat", "score", "thu", "never", "actual", "invok", "interceptdata", "intercept", "data", "thu", "never", "clear", "furthermor", "even", "mapper", "did", "return", "integ", "max", "valu", "score", "it", "would", "still", "not", "invok", "mani", "scenario", "sinc", "other", "mapper", "systemmapp", "system", "mapper", "are", "regist", "later", "therefor", "have", "higher", "prioriti", "practic", "thi", "lead", "veri", "odd", "login", "behavior", "wicket", "applic", "which", "where", "restartresponseatinterceptpageexcept", "restart", "respons", "at", "intercept", "page", "except", "typic", "use", "exampl", "user", "click", "login", "link", "they", "may", "end", "up", "total", "unexpect", "page", "due", "stale", "interceptdata", "intercept", "data", "that", "hang", "around", "session", "am", "attach", "quick", "start", "that", "demonstr", "problem", "as", "well", "as", "patch", "fix", "compatibilityscor", "compat", "score", "move", "mapper", "higher", "prioriti", "systemmapp", "system", "mapper"], "B_title": "RestartResponseAtInterceptPageException.InterceptData is never cleared", "B_clean_title": ["restartresponseatinterceptpageexcept", "interceptdata", "restart", "respons", "at", "intercept", "page", "except", "intercept", "data", "never", "clear"]},
{"A_title": "FileOutputFormat writes to wrong path if path ends with /The FileOutputFormat duplicates the last directory of a path if the path ends  with a slash /. For example if the output path is specified as /home/myuser/outputPath/ the output is written to /home/myuser/outputPath/outputPath/.  This bug was introduced by commit 8fc04e4da8a36866e10564205c3f900894f4f6e0", "A_clean_title": ["fileoutputformat", "file", "output", "format", "write", "wrong", "path", "path", "end", "fileoutputformat", "file", "output", "format", "duplic", "last", "directori", "path", "path", "end", "slash", "exampl", "output", "path", "specifi", "as", "home", "myuser", "outputpath", "output", "path", "output", "written", "home", "myuser", "outputpath", "outputpath", "output", "path", "output", "path", "thi", "bug", "wa", "introduc", "by", "commit", "8fc04e4da8a36866e10564205c3f900894f4f6e0"], "B_title": "Remove tailing slash from paths. Add tests for Path and FileOutputFormat.", "B_clean_title": ["remov", "tail", "slash", "path", "add", "test", "path", "fileoutputformat", "file", "output", "format"]},
{"A_title": "TreeTypeProvider returns wrong type for version related node type definitionsthe following paths with result in type VERSION instead of DEFAULT and might lead to unexpected results wrt read access:  - /jcr:system/jcr:nodeTypes/rep:system/rep:namedChildNodeDefinitions/jcr:versionStorage - /jcr:system/jcr:nodeTypes/rep:system/rep:namedChildNodeDefinitions/jcr:activities - /jcr:system/jcr:nodeTypes/rep:system/rep:namedChildNodeDefinitions/jcr:configurations", "A_clean_title": ["treetypeprovid", "tree", "type", "provid", "return", "wrong", "type", "version", "relat", "node", "type", "definitionsth", "follow", "path", "result", "type", "version", "instead", "default", "might", "lead", "unexpect", "result", "wrt", "read", "access", "jcr", "system", "jcr", "nodetyp", "rep", "node", "type", "system", "rep", "namedchildnodedefinit", "jcr", "name", "child", "node", "definit", "versionstorag", "version", "storag", "jcr", "system", "jcr", "nodetyp", "rep", "node", "type", "system", "rep", "namedchildnodedefinit", "jcr", "name", "child", "node", "definit", "activ", "jcr", "system", "jcr", "nodetyp", "rep", "node", "type", "system", "rep", "namedchildnodedefinit", "jcr", "name", "child", "node", "definit", "configur"], "B_title": ": TreeTypeProvider returns wrong type for version related node type definitions", "B_clean_title": ["treetypeprovid", "tree", "type", "provid", "return", "wrong", "type", "version", "relat", "node", "type", "definit"]},
{"A_title": "Multipart Form and AjaxSubmitLink will result in invalid redirect after user session expiresHi  I have hit an issue similar to this one:  https://issues.apache.org/jira/browse/WICKET-3141  I do not receive any errors from Wicket itself to help clarify so I will try to explain using an example.  The example below with which I could recreate the issue uses the default SignInPanel (in my LoginPage.clas) and AuthenticatedWebSession to authenticate the user and store the session:  protected Class<? extends WebPage> getSignInPageClass()  return LoginPage.class;   If the authentiation is succesfull then the user is redirect back to the test page:  protected void onSignInSucceeded()  setResponsePage(Test.class);   So far so good. However if I use a form with setMultiPart(true) in combination with an AjaxSubmitLink as shown in the following piece of code:  import org.apache.wicket.ajax.AjaxRequestTarget; import org.apache.wicket.ajax.markup.html.form.AjaxSubmitLink; import org.apache.wicket.authroles.authorization.strategies.role.annotations.AuthorizeInstantiation; import org.apache.wicket.markup.html.WebPage; import org.apache.wicket.markup.html.form.Form;  @AuthorizeInstantiation(USER) public class Test extends WebPage   public Test()  super();  final Form testForm =  new Form(testForm);  testForm.setMultiPart(true);  testForm.add(new AjaxSubmitLink(testButton testForm)   @Override protected void onSubmit(AjaxRequestTarget target Form form)  super.onSubmit(); ;  @Override protected void onError(AjaxRequestTarget target Form form)   ; );  add(testForm);    And have selected the option Remember credentials in the SignInPanel clicking on the testButton AFTER the session has expired will result in:  http://localhost:8080/PaladinWicket/?3-1.IBehaviorListener.0-testForm-testButton&wicket-ajax=true&wicket-ajax-baseurl=.  which displays this in the browser:  This XML file does not appear to have any style information associated with it. The document tree is shown below. <ajax-response> <redirect> <!CDATA .?1 > </redirect> </ajax-response>", "A_clean_title": ["multipart", "form", "ajaxsubmitlink", "ajax", "submit", "link", "will", "result", "invalid", "redirect", "after", "user", "session", "expireshi", "expir", "hi", "have", "hit", "issu", "similar", "thi", "one", "http", "3141", "apach", "issu", "org", "jira", "brows", "wicket", "not", "receiv", "ani", "error", "wicket", "itself", "help", "clarifi", "so", "will", "tri", "explain", "exampl", "exampl", "below", "which", "could", "recreat", "issu", "use", "default", "signinpanel", "sign", "panel", "my", "loginpag", "cla", "login", "page", "authenticatedwebsess", "authent", "web", "session", "authent", "user", "store", "session", "protect", "class", "extend", "webpag", "web", "page", "getsigninpageclass", "get", "sign", "page", "class", "return", "loginpag", "class", "login", "page", "authenti", "succesful", "then", "user", "redirect", "back", "test", "page", "protect", "void", "onsigninsucceed", "sign", "succeed", "setresponsepag", "set", "respons", "page", "test", "class", "so", "far", "so", "good", "howev", "use", "form", "setmultipart", "set", "multi", "part", "true", "combin", "ajaxsubmitlink", "ajax", "submit", "link", "as", "shown", "follow", "piec", "code", "import", "org", "apach", "wicket", "ajax", "ajaxrequesttarget", "ajax", "request", "target", "import", "org", "apach", "wicket", "ajax", "markup", "html", "form", "ajaxsubmitlink", "ajax", "submit", "link", "import", "org", "apach", "wicket", "authrol", "author", "strategi", "role", "annot", "authorizeinstanti", "author", "instanti", "import", "org", "apach", "wicket", "markup", "html", "webpag", "web", "page", "import", "org", "apach", "wicket", "markup", "html", "form", "form", "authorizeinstanti", "author", "instanti", "user", "public", "class", "test", "extend", "webpag", "web", "page", "public", "test", "super", "final", "form", "testform", "test", "form", "new", "form", "testform", "test", "form", "testform", "setmultipart", "test", "form", "set", "multi", "part", "true", "testform", "add", "test", "form", "new", "ajaxsubmitlink", "ajax", "submit", "link", "testbutton", "test", "button", "testform", "test", "form", "overrid", "protect", "void", "onsubmit", "submit", "ajaxrequesttarget", "ajax", "request", "target", "target", "form", "form", "super", "onsubmit", "submit", "overrid", "protect", "void", "onerror", "error", "ajaxrequesttarget", "ajax", "request", "target", "target", "form", "form", "add", "testform", "test", "form", "have", "select", "option", "rememb", "credenti", "signinpanel", "sign", "panel", "click", "testbutton", "test", "button", "after", "session", "ha", "expir", "will", "result", "http", "localhost:8080", "paladinwicket", "paladin", "wicket", "testform", "testbutton", "ibehaviorlisten", "test", "form", "test", "button", "behavior", "listen", "wicket", "ajax=tru", "wicket", "ajax", "baseurl=", "which", "display", "thi", "browser", "thi", "xml", "file", "not", "appear", "have", "ani", "style", "inform", "associ", "it", "document", "tree", "shown", "below", "ajax", "respons", "redirect", "cdata", "redirect", "respons", "ajax"], "B_title": "Multipart Form and AjaxSubmitLink will result in invalid redirect after user session expires", "B_clean_title": ["multipart", "form", "ajaxsubmitlink", "ajax", "submit", "link", "will", "result", "invalid", "redirect", "after", "user", "session", "expir"]},
{"A_title": "SimplexSolver not working as expected 2SimplexSolver didnt find the optimal solution.  Program for Lpsolve: ===================== /* Objective function */ max: 7 a 3 b;  /* Constraints */ R1: +3 a -5 c <= 0; R2: +2 a -5 d <= 0; R3: +2 b -5 c <= 0; R4: +3 b -5 d <= 0; R5: +3 a +2 b <= 5; R6: +2 a +3 b <= 5;  /* Variable bounds */ a <= 1; b <= 1; ===================== Results(correct): a = 1 b = 1 value = 10   Program for SimplexSolve: ===================== LinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double7 3 0 0 0); Collection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>(); podmienky.add(new LinearConstraint(new double1 0 0 0 Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double0 1 0 0 Relationship.LEQ 1)); podmienky.add(new LinearConstraint(new double3 0 -5 0 Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double2 0 0 -5 Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double0 2 -5 0 Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double0 3 0 -5 Relationship.LEQ 0)); podmienky.add(new LinearConstraint(new double3 2 0 0 Relationship.LEQ 5)); podmienky.add(new LinearConstraint(new double2 3 0 0 Relationship.LEQ 5)); SimplexSolver solver = new SimplexSolver(); RealPointValuePair result = solver.optimize(kritFcia podmienky GoalType.MAXIMIZE true); ===================== Results(incorrect): a = 1 b = 0.5 value = 8.5  P.S. I used the latest software from the repository (including MATH-286 fix).", "A_clean_title": ["simplexsolv", "simplex", "solver", "not", "work", "as", "expect", "2simplexsolv", "2simplex", "solver", "didnt", "find", "optim", "solut", "program", "lpsolv", "object", "function", "max", "constraint", "r1", "+3", "r2", "+2", "r3", "+2", "r4", "+3", "r5", "+3", "+2", "r6", "+2", "+3", "variabl", "bound", "result", "correct", "valu", "10", "program", "simplexsolv", "simplex", "solv", "linearobjectivefunct", "linear", "object", "function", "kritfcia", "krit", "fcia", "new", "linearobjectivefunct", "linear", "object", "function", "new", "double7", "collect", "linearconstraint", "linear", "constraint", "podmienki", "new", "arraylist", "array", "list", "linearconstraint", "linear", "constraint", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double1", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double0", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double3", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double2", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double0", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double0", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double3", "relationship", "leq", "podmienki", "add", "new", "linearconstraint", "linear", "constraint", "new", "double2", "relationship", "leq", "simplexsolv", "simplex", "solver", "solver", "new", "simplexsolv", "simplex", "solver", "realpointvaluepair", "real", "point", "valu", "pair", "result", "solver", "optim", "kritfcia", "krit", "fcia", "podmienki", "goaltyp", "maxim", "goal", "type", "true", "result", "incorrect", "valu", "use", "latest", "softwar", "repositori", "includ", "math", "286", "fix"], "B_title": "fixed an error induced by zero entries in simplex solver JIRA: MATH-288", "B_clean_title": ["fix", "error", "induc", "by", "zero", "entri", "simplex", "solver", "jira", "math", "288"]},
{"A_title": "Released checkpoint can still be retrievedThe following fails on the 2nd assertion on the MongoMK  code assertTrue(store.release(cp)); assertNull(store.retrieve(cp)); code  The JavaDoc on the release method is a bit vague but I assume it is safe to assume that when it returns true the checkpoint should be gone. If not we should update the JavaDoc.", "A_clean_title": ["releas", "checkpoint", "still", "retrievedth", "retriev", "follow", "fail", "2nd", "assert", "mongomk", "mongo", "mk", "code", "asserttru", "assert", "true", "store", "releas", "cp", "assertnul", "assert", "null", "store", "retriev", "cp", "code", "javadoc", "java", "doc", "releas", "method", "bit", "vagu", "but", "assum", "it", "safe", "assum", "that", "when", "it", "return", "true", "checkpoint", "gone", "not", "we", "updat", "javadoc", "java", "doc"], "B_title": "Released checkpoint can still be retrieved", "B_clean_title": ["releas", "checkpoint", "still", "retriev"]},
{"A_title": "Type extractor cannot determine type of functionThis function fails in the type extractor.  code public static final class DuplicateValue<T> implements MapFunction<Tuple1<T> Tuple2<T T>>   @Override public Tuple2<T T> map(Tuple1<T> vertex)  return new Tuple2<T T>(vertex.f0 vertex.f0);   code", "A_clean_title": ["type", "extractor", "not", "determin", "type", "functionthi", "function", "thi", "function", "fail", "type", "extractor", "code", "public", "static", "final", "class", "duplicatevalu", "duplic", "valu", "implement", "mapfunct", "map", "function", "tuple1", "tuple2", "overrid", "public", "tuple2", "map", "tuple1", "vertex", "return", "new", "tuple2", "vertex", "f0", "vertex", "f0", "code"], "B_title": "TypeExtractor resolves also variables inside Tuple-input", "B_clean_title": ["typeextractor", "type", "extractor", "resolv", "also", "variabl", "insid", "tupl", "input"]},
{"A_title": "A (stateless) page immediately disappears after the first renderUsing setResponsePage(new SomeStatelessNonBookmarkablePage(aParameter)) renders the page but trying to reload the page in the browser fails with PageExpiredException.  The reason is that the page is stateless and thus it is not saved in the page stores. Since it was scheduled for render with setResponsePage(Page) method its Url is created by PageInstanceMapper (i.e. something like: wicket/page?1). An attempt to refresh such page fails with Page with id 1 is not found => PageExpiredException.  Igor suggested to call page.setStatelessHint(false) for all pages passed to PageProvider(IRequestablePage) constructor i.e. such pages must be stored. This solved the problem but exposed few more problems: - MockPageManager (used in WicketTester) until now always touched/stored pages no matter their statelessness - org.apache.wicket.markup.html.internal.EnclosureTest.testRender10() was wrong for some unknown reason. All expectations against EnclosurePageExpectedResult_10-2.html should not have the enclosure rendered because input component is invisible", "A_clean_title": ["stateless", "page", "immedi", "disappear", "after", "first", "renderus", "render", "setresponsepag", "set", "respons", "page", "new", "somestatelessnonbookmarkablepag", "some", "stateless", "non", "bookmark", "page", "aparamet", "paramet", "render", "page", "but", "tri", "reload", "page", "browser", "fail", "pageexpiredexcept", "page", "expir", "except", "reason", "that", "page", "stateless", "thu", "it", "not", "save", "page", "store", "sinc", "it", "wa", "schedul", "render", "setresponsepag", "set", "respons", "page", "page", "method", "it", "url", "creat", "by", "pageinstancemapp", "page", "instanc", "mapper", "someth", "like", "wicket", "page", "attempt", "refresh", "such", "page", "fail", "page", "id", "not", "found", "pageexpiredexcept", "page", "expir", "except", "igor", "suggest", "call", "page", "setstatelesshint", "set", "stateless", "hint", "fals", "all", "page", "pass", "pageprovid", "page", "provid", "irequestablepag", "request", "page", "constructor", "such", "page", "must", "store", "thi", "solv", "problem", "but", "expos", "few", "more", "problem", "mockpagemanag", "mock", "page", "manag", "use", "wickettest", "wicket", "tester", "until", "now", "alway", "touch", "store", "page", "no", "matter", "their", "stateless", "org", "apach", "wicket", "markup", "html", "intern", "enclosuretest", "testrender10", "enclosur", "test", "test", "render10", "wa", "wrong", "some", "unknown", "reason", "all", "expect", "against", "enclosurepageexpectedresult", "10", "html", "enclosur", "page", "expect", "result", "not", "have", "enclosur", "render", "becaus", "input", "compon", "invis"], "B_title": "A (stateless) page immediately disappears after the first render", "B_clean_title": ["stateless", "page", "immedi", "disappear", "after", "first", "render"]},
{"A_title": "KeySelectorUtil.getSelectorForKeys and TypeExtractor.getKeySelectorTypes are incompatibleThe following code snippet fails because KeySelectorUtil.getSelectorForKeys returns the base Tuple type.  ```java TypeInformation<Tuple2<Integer Integer>> typeInfo = TypeExtractor .getForObject(Tuple2.of(0 0));  ExecutionConfig config = new ExecutionConfig();  KeySelector<Tuple2<Integer Integer> ?> keySelector = KeySelectorUtil.getSelectorForKeys( new Keys.ExpressionKeys<>(new int0 typeInfo) typeInfo config);  // fails with InvalidTypesException TypeExtractor.getKeySelectorTypes(keySelector typeInfo);  ```  However if I manually define the key selector as follows the snippet works fine due to the key type being an integer.  ```java KeySelector<Tuple2<Integer Integer> Integer> keySelector =  new KeySelector<Tuple2<Integer Integer> Integer>()  @Override public Integer getKey(Tuple2<Integer Integer> value) throws Exception  return value.f0;  ; ```  The error message looks like this: org.apache.flink.api.common.functions.InvalidTypesException: Usage of class Tuple as a type is not allowed. Use a concrete subclass (e.g. Tuple1 Tuple2 etc.) instead. at org.apache.flink.api.java.typeutils.TypeExtractor.createTypeInfoWithTypeHierarchy(TypeExtractor.java:401) at org.apache.flink.api.java.typeutils.TypeExtractor.privateCreateTypeInfo(TypeExtractor.java:379) at org.apache.flink.api.java.typeutils.TypeExtractor.getUnaryOperatorReturnType(TypeExtractor.java:279) at org.apache.flink.api.java.typeutils.TypeExtractor.getKeySelectorTypes(TypeExtractor.java:229) at org.apache.flink.api.java.typeutils.TypeExtractor.getKeySelectorTypes(TypeExtractor.java:223)", "A_clean_title": ["keyselectorutil", "getselectorforkey", "key", "selector", "util", "get", "selector", "key", "typeextractor", "getkeyselectortyp", "type", "extractor", "get", "key", "selector", "type", "are", "incompatibleth", "incompat", "follow", "code", "snippet", "fail", "becaus", "keyselectorutil", "getselectorforkey", "key", "selector", "util", "get", "selector", "key", "return", "base", "tupl", "type", "java", "typeinform", "type", "inform", "tuple2", "integ", "integ", "typeinfo", "type", "info", "typeextractor", "type", "extractor", "getforobject", "get", "object", "tuple2", "executionconfig", "execut", "config", "config", "new", "executionconfig", "execut", "config", "keyselector", "key", "selector", "tuple2", "integ", "integ", "keyselector", "key", "selector", "keyselectorutil", "getselectorforkey", "key", "selector", "util", "get", "selector", "key", "new", "key", "expressionkey", "express", "key", "new", "int0", "typeinfo", "type", "info", "typeinfo", "type", "info", "config", "fail", "invalidtypesexcept", "invalid", "type", "except", "typeextractor", "getkeyselectortyp", "type", "extractor", "get", "key", "selector", "type", "keyselector", "key", "selector", "typeinfo", "type", "info", "howev", "manual", "defin", "key", "selector", "as", "follow", "snippet", "work", "fine", "due", "key", "type", "be", "integ", "java", "keyselector", "key", "selector", "tuple2", "integ", "integ", "integ", "keyselector", "key", "selector", "new", "keyselector", "key", "selector", "tuple2", "integ", "integ", "integ", "overrid", "public", "integ", "getkey", "get", "key", "tuple2", "integ", "integ", "valu", "throw", "except", "return", "valu", "f0", "error", "messag", "look", "like", "thi", "org", "apach", "flink", "api", "common", "function", "invalidtypesexcept", "invalid", "type", "except", "usag", "class", "tupl", "as", "type", "not", "allow", "use", "concret", "subclass", "tuple1", "tuple2", "etc", "instead", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "createtypeinfowithtypehierarchi", "type", "extractor", "creat", "type", "info", "type", "hierarchi", "typeextractor", "java:401", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "privatecreatetypeinfo", "type", "extractor", "privat", "creat", "type", "info", "typeextractor", "java:379", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "getunaryoperatorreturntyp", "type", "extractor", "get", "unari", "oper", "return", "type", "typeextractor", "java:279", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "getkeyselectortyp", "type", "extractor", "get", "key", "selector", "type", "typeextractor", "java:229", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "getkeyselectortyp", "type", "extractor", "get", "key", "selector", "type", "typeextractor", "java:223", "type", "extractor"], "B_title": "streaming KeySelectorUtil interacts well with type extraction", "B_clean_title": ["stream", "keyselectorutil", "key", "selector", "util", "interact", "well", "type", "extract"]},
{"A_title": "Different output from RestAPI and command line jarNone", "A_clean_title": ["differ", "output", "restapi", "rest", "api", "command", "line", "jarnon", "jar", "none"], "B_title": "Fixes issue 1017 ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=47616701", "B_clean_title": ["fix", "issu", "1017", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=47616701"]},
{"A_title": "BackgroundLeaseUpdate not scheduled when asyncDelay=0The BackgroundLeaseUpdate extends from NodeStoreTask which returns from the run() method when asyncDelay is 0. This is fine for the background read and update tasks. However the lease update task must run even when asyncDelay is set to zero.", "A_clean_title": ["backgroundleaseupd", "background", "leas", "updat", "not", "schedul", "when", "asyncdelay=0th", "async", "delay=0th", "backgroundleaseupd", "background", "leas", "updat", "extend", "nodestoretask", "node", "store", "task", "which", "return", "run", "method", "when", "asyncdelay", "async", "delay", "thi", "fine", "background", "read", "updat", "task", "howev", "leas", "updat", "task", "must", "run", "even", "when", "asyncdelay", "async", "delay", "set", "zero"], "B_title": "BackgroundLeaseUpdate not scheduled when asyncDelay=0", "B_clean_title": ["backgroundleaseupd", "background", "leas", "updat", "not", "schedul", "when", "asyncdelay=0", "async", "delay=0"]},
{"A_title": "CacheLIRS concurrency issueSome of the methods of the cache can throw a NullPointerException when the cache is used concurrently. Example stack trace:  code java.lang.NullPointerException: null org.apache.jackrabbit.oak.cache.CacheLIRS.values(CacheLIRS.java:470)  org.apache.jackrabbit.oak.cache.CacheLIRS 1.values(CacheLIRS.java:1432) org.apache.jackrabbit.oak.plugins.segment.file.FileStore.flush(FileStore.java:205) code", "A_clean_title": ["cachelir", "cach", "lir", "concurr", "issuesom", "issu", "some", "method", "cach", "throw", "nullpointerexcept", "null", "pointer", "except", "when", "cach", "use", "concurr", "exampl", "stack", "trace", "code", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "null", "org", "apach", "jackrabbit", "oak", "cach", "cachelir", "valu", "cach", "lir", "cachelir", "java:470", "cach", "lir", "org", "apach", "jackrabbit", "oak", "cach", "cachelir", "cach", "lir", "valu", "cachelir", "java:1432", "cach", "lir", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "file", "filestor", "flush", "file", "store", "filestor", "java:205", "file", "store", "code"], "B_title": "CacheLIRS concurrency issue (allow concurrent clear and refresh without loader)", "B_clean_title": ["cachelir", "cach", "lir", "concurr", "issu", "allow", "concurr", "clear", "refresh", "without", "loader"]},
{"A_title": "weight versus sigma in AbstractLeastSquaresIn AbstractLeastSquares residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS() these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation it should multiply the square of the residual even in the computation of the chi2.   Once corrected getRMS() can even reduce   public double getRMS() return Math.sqrt(getChiSquare()/rows);", "A_clean_title": ["weight", "versu", "sigma", "abstractleastsquaresin", "abstract", "least", "squar", "abstractleastsquar", "abstract", "least", "squar", "residualsweight", "residu", "weight", "contain", "weight", "assign", "each", "observ", "method", "getrm", "get", "rm", "these", "weight", "are", "multipl", "as", "they", "unlik", "getchisquar", "get", "chi", "squar", "where", "it", "appear", "at", "denomin", "weight", "realli", "weight", "observ", "it", "multipli", "squar", "residu", "even", "comput", "chi2", "onc", "correct", "getrm", "get", "rm", "even", "reduc", "public", "doubl", "getrm", "get", "rm", "return", "math", "sqrt", "getchisquar", "get", "chi", "squar", "row"], "B_title": "fixed", "B_clean_title": ["fix"]},
{"A_title": "ClassGeneratingPropertyAccessorFactory.isTypeInjectable() fails with NPE for entities in default packages DATACMNS-1201opened and commented Introspecting ClassGeneratingPropertyAccessorFactory support for an entity fails with an NPE if the entity resides in the default package.     Affects: 1.13.8 (Ingalls SR8) 2.0 GA (Kay)  Referenced from: pull request #256  Backported to:  2.0.1 (Kay SR1)  1.13.9 (Ingalls SR9)", "A_clean_title": ["classgeneratingpropertyaccessorfactori", "istypeinject", "class", "gener", "properti", "accessor", "factori", "type", "inject", "fail", "npe", "entiti", "default", "packag", "datacmn", "1201open", "comment", "introspect", "classgeneratingpropertyaccessorfactori", "class", "gener", "properti", "accessor", "factori", "support", "entiti", "fail", "npe", "entiti", "resid", "default", "packag", "affect", "13", "ingal", "sr8", "ga", "kay", "referenc", "pull", "request", "256", "backport", "kay", "sr1", "13", "ingal", "sr9"], "B_title": "DATACMNS-1201 - Support generated property accessors for types in default packages.  We now support generated property accessors for types that reside in the default package.  Original pull request: #256.", "B_clean_title": ["datacmn", "1201", "support", "gener", "properti", "accessor", "type", "default", "packag", "we", "now", "support", "gener", "properti", "accessor", "type", "that", "resid", "default", "packag", "origin", "pull", "request", "256"]},
{"A_title": "RDB/MongoDocumentStore may return stale documentsIt appears that the implementations of the update method sometimes populate the memory cache with documents that do not reflect any current or previous state in the persistence (that is miss changes made by another node).  (will attach test)", "A_clean_title": ["rdb", "mongodocumentstor", "mongo", "document", "store", "may", "return", "stale", "documentsit", "document", "it", "appear", "that", "implement", "updat", "method", "sometim", "popul", "memori", "cach", "document", "that", "not", "reflect", "ani", "current", "or", "previou", "state", "persist", "that", "miss", "chang", "made", "by", "anoth", "node", "will", "attach", "test"], "B_title": "RDB/MongoDocumentStore may return stale documents", "B_clean_title": ["rdb", "mongodocumentstor", "mongo", "document", "store", "may", "return", "stale", "document"]},
{"A_title": "TabbedPanel CSS last is wrong if last step is not visibleTabbedPanel renders a last CSS class for the last tab this fails however if the last tab is not visible.", "A_clean_title": ["tabbedpanel", "tab", "panel", "css", "last", "wrong", "last", "step", "not", "visibletabbedpanel", "visibl", "tab", "panel", "render", "last", "css", "class", "last", "tab", "thi", "fail", "howev", "last", "tab", "not", "visibl"], "B_title": "last visible tabs css", "B_clean_title": ["last", "visibl", "tab", "css"]},
{"A_title": "Failing tests on Windows machineNone", "A_clean_title": ["fail", "test", "window", "machinenon", "machin", "none"], "B_title": "printing args on smart nulls NullPointerException message (Issue #225)", "B_clean_title": ["print", "arg", "smart", "null", "nullpointerexcept", "null", "pointer", "except", "messag", "issu", "225"]},
{"A_title": "NPE with nested property modelsAfter updated from 1.4.8 to 1.4.14 I got this bug.  The problem is with nested property models where the top model has a null model object that is bound to a TextField. You get a NPE when the page is rendered. There is a quick workaround by overriding getOjbectClass() on the property model.  I provide a running example of the problem.", "A_clean_title": ["npe", "nest", "properti", "modelsaft", "model", "after", "updat", "14", "got", "thi", "bug", "problem", "nest", "properti", "model", "where", "top", "model", "ha", "null", "model", "object", "that", "bound", "textfield", "text", "field", "you", "get", "npe", "when", "page", "render", "there", "quick", "workaround", "by", "overrid", "getojbectclass", "get", "ojbect", "class", "properti", "model", "provid", "run", "exampl", "problem"], "B_title": "- Preventing the attempt to resolve the property class for a null target at AbstractPropertyModel - Test asserting that there is no problem in working with an AbstractPropertyModel targeting an IObjectClassAwareModel not initialized with an known class. Issue: WICKET-3253", "B_clean_title": ["prevent", "attempt", "resolv", "properti", "class", "null", "target", "at", "abstractpropertymodel", "abstract", "properti", "model", "test", "assert", "that", "there", "no", "problem", "work", "abstractpropertymodel", "abstract", "properti", "model", "target", "iobjectclassawaremodel", "object", "class", "awar", "model", "not", "initi", "known", "class", "issu", "wicket", "3253"]},
{"A_title": "Ordered index fails with old index contentWith the latest changes the ordered index no longer works with old index data. When running the latest Oak 1.0.2 snapshot run against an Oak 1.0.0 repository with an existing ordered index the index fails with the exception below.  As a workaround the ordered index can be manually re-built. Either the index re-build needs to be automatic or the ordered index needs to work with the old index content.  noformat java.lang.IndexOutOfBoundsException: index (3) must be less than size (1)     at com.google.common.base.Preconditions.checkElementIndex(Preconditions.java:306)     at com.google.common.base.Preconditions.checkElementIndex(Preconditions.java:285)     at org.apache.jackrabbit.oak.plugins.segment.SegmentPropertyState.getValue(SegmentPropertyState.java:157)     at org.apache.jackrabbit.oak.plugins.index.property.strategy.OrderedContentMirrorStoreStrategy.getPropertyNext(OrderedContentMirrorStoreStrategy.java:1024) noformat", "A_clean_title": ["order", "index", "fail", "old", "index", "contentwith", "content", "latest", "chang", "order", "index", "no", "longer", "work", "old", "index", "data", "when", "run", "latest", "oak", "snapshot", "run", "against", "oak", "repositori", "exist", "order", "index", "index", "fail", "except", "below", "as", "workaround", "order", "index", "manual", "re", "built", "either", "index", "re", "build", "need", "automat", "or", "order", "index", "need", "work", "old", "index", "content", "noformat", "java", "lang", "indexoutofboundsexcept", "index", "out", "bound", "except", "index", "must", "less", "than", "size", "at", "com", "googl", "common", "base", "precondit", "checkelementindex", "check", "element", "index", "precondit", "java:306", "at", "com", "googl", "common", "base", "precondit", "checkelementindex", "check", "element", "index", "precondit", "java:285", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "segmentpropertyst", "getvalu", "segment", "properti", "state", "get", "valu", "segmentpropertyst", "java:157", "segment", "properti", "state", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "properti", "strategi", "orderedcontentmirrorstorestrategi", "getpropertynext", "order", "content", "mirror", "store", "strategi", "get", "properti", "next", "orderedcontentmirrorstorestrategi", "java:1024", "order", "content", "mirror", "store", "strategi", "noformat"], "B_title": "Ordered index fails with old index content", "B_clean_title": ["order", "index", "fail", "old", "index", "content"]},
{"A_title": "NullPointerException while translating union nodeThe NepheleJobGraphGenerator throws a NullPointerException when translating a binary union operator. The BinaryUnionPlanNode is not replaced by a NAryUnionPlanNode and thus is still treated as a DualInputVertex. Accessing the driver code of the BinaryUnionPlanNode causes then the NullPointerException.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "while", "translat", "union", "nodeth", "node", "nephelejobgraphgener", "nephel", "job", "graph", "gener", "throw", "nullpointerexcept", "null", "pointer", "except", "when", "translat", "binari", "union", "oper", "binaryunionplannod", "binari", "union", "plan", "node", "not", "replac", "by", "naryunionplannod", "ari", "union", "plan", "node", "thu", "still", "treat", "as", "dualinputvertex", "dual", "input", "vertex", "access", "driver", "code", "binaryunionplannod", "binari", "union", "plan", "node", "caus", "then", "nullpointerexcept", "null", "pointer", "except"], "B_title": "Fix for bug in union replacement", "B_clean_title": ["fix", "bug", "union", "replac"]},
{"A_title": "LocaleUtils.toLocale does not parse strings starting with an underscoreHi Javadocs of Locale.toString() states that If the language is missing the string will begin with an underbar.. This is not handled in the LocaleUtils.toLocale method if it is meant to be the inversion method of Locale.toString(). The fix for the ticket 328 does not handle well the case fr__P which I found out during fixing the first bug. I am attaching the patch for both problems.", "A_clean_title": ["localeutil", "tolocal", "local", "util", "local", "not", "pars", "string", "start", "underscorehi", "underscor", "hi", "javadoc", "local", "tostr", "string", "state", "that", "languag", "miss", "string", "will", "begin", "underbar", "thi", "not", "handl", "localeutil", "tolocal", "local", "util", "local", "method", "it", "meant", "invers", "method", "local", "tostr", "string", "fix", "ticket", "328", "not", "handl", "well", "case", "fr", "which", "found", "out", "dure", "fix", "first", "bug", "am", "attach", "patch", "both", "problem"], "B_title": "LocaleUtils.toLocale does not parse strings starting with an underscore.", "B_clean_title": ["localeutil", "tolocal", "local", "util", "local", "not", "pars", "string", "start", "underscor"]},
{"A_title": "AccumuloVFSClassloader creates conflicting local cache directory names when vfs.cache.dir property is set.When the vfs.cache.dir property is not set the AccumuloVFSClassloader will use java.io.tmpdir as a base directory for the local cache of jars and then generate a unique directory name using a combination of the processid hostname and userid executing the JVM.  When the vfs.cache.dir property is set that value is used as the base directory and  an attempt to generate a unique directory is made using an AtomicInteger. This isnt suitable because for non-long lived processes this will always be 1 - and theres a good chance that directory already exists and is owned by another user and not writable to by the user in question.   This leads to a failure of the invoked accumulo component to start.  Modify the behavior of the unique directory creation when vfs.cache.dir is set so that it employs the same mechanism for unique directory naming that is used when it is not set.", "A_clean_title": ["accumulovfsclassload", "accumulo", "vf", "classload", "creat", "conflict", "local", "cach", "directori", "name", "when", "vf", "cach", "dir", "properti", "set", "when", "vf", "cach", "dir", "properti", "not", "set", "accumulovfsclassload", "accumulo", "vf", "classload", "will", "use", "java", "io", "tmpdir", "as", "base", "directori", "local", "cach", "jar", "then", "gener", "uniqu", "directori", "name", "combin", "processid", "hostnam", "userid", "execut", "jvm", "when", "vf", "cach", "dir", "properti", "set", "that", "valu", "use", "as", "base", "directori", "attempt", "gener", "uniqu", "directori", "made", "atomicinteg", "atom", "integ", "thi", "isnt", "suitabl", "becaus", "non", "long", "live", "process", "thi", "will", "alway", "there", "good", "chanc", "that", "directori", "alreadi", "exist", "own", "by", "anoth", "user", "not", "writabl", "by", "user", "question", "thi", "lead", "failur", "invok", "accumulo", "compon", "start", "modifi", "behavior", "uniqu", "directori", "creation", "when", "vf", "cach", "dir", "set", "so", "that", "it", "employ", "same", "mechan", "uniqu", "directori", "name", "that", "use", "when", "it", "not", "set"], "B_title": "Fix for AccumuloVFSClassloader conflicting cache directories", "B_clean_title": ["fix", "accumulovfsclassload", "accumulo", "vf", "classload", "conflict", "cach", "directori"]},
{"A_title": "Bug in Hybrid Hash Join: Request to spill a partition with less than two buffers.The following exception is thrown when running the example triangle listing with an unmodified master build (4cadc3d6).  noformat ./bin/flink run ~/flink-examples/flink-java-examples/target/flink-java-examples-0.10-SNAPSHOT-EnumTrianglesOpt.jar ~/rmat/undirected/s19_e8.ssv output noformat  The only changes to flink-conf.yaml are taskmanager.numberOfTaskSlots: 8 and parallelism.default: 8.  I have confirmed with input files s19_e8.ssv|https://drive.google.com/file/d/0B6TrSsnHj2HxR2lnMHR4amdyTnM/view?usp=sharing (40 MB) and s20_e8.ssv|https://drive.google.com/file/d/0B6TrSsnHj2HxNi1HbmptU29MTm8/view?usp=sharing (83 MB). On a second machine only the larger file caused the exception.  noformat org.apache.flink.client.program.ProgramInvocationException: The program execution failed: Job execution failed. at org.apache.flink.client.program.Client.runBlocking(Client.java:407) at org.apache.flink.client.program.Client.runBlocking(Client.java:386) at org.apache.flink.client.program.Client.runBlocking(Client.java:353) at org.apache.flink.client.program.ContextEnvironment.execute(ContextEnvironment.java:64) at org.apache.flink.examples.java.graph.EnumTrianglesOpt.main(EnumTrianglesOpt.java:125) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:434) at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:350) at org.apache.flink.client.program.Client.runBlocking(Client.java:290) at org.apache.flink.client.CliFrontend.executeProgramBlocking(CliFrontend.java:675) at org.apache.flink.client.CliFrontend.run(CliFrontend.java:324) at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:977) at org.apache.flink.client.CliFrontend.main(CliFrontend.java:1027) Caused by: org.apache.flink.runtime.client.JobExecutionException: Job execution failed. at org.apache.flink.runtime.jobmanager.JobManager  anonfun handleMessage 1.applyOrElse(JobManager.scala:425) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LeaderSessionMessageFilter  anonfun receive 1.applyOrElse(LeaderSessionMessageFilter.scala:36) at scala.runtime.AbstractPartialFunction mcVL sp.apply mcVL sp(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:33) at scala.runtime.AbstractPartialFunction mcVL sp.apply(AbstractPartialFunction.scala:25) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:33) at org.apache.flink.runtime.LogMessages  anon 1.apply(LogMessages.scala:28) at scala.PartialFunction class.applyOrElse(PartialFunction.scala:118) at org.apache.flink.runtime.LogMessages  anon 1.applyOrElse(LogMessages.scala:28) at akka.actor.Actor class.aroundReceive(Actor.scala:465) at org.apache.flink.runtime.jobmanager.JobManager.aroundReceive(JobManager.scala:107) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) at akka.actor.ActorCell.invoke(ActorCell.scala:487) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:254) at akka.dispatch.Mailbox.run(Mailbox.scala:221) at akka.dispatch.Mailbox.exec(Mailbox.scala:231) at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at scala.concurrent.forkjoin.ForkJoinPool WorkQueue.runTask(ForkJoinPool.java:1339) at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) Caused by: java.lang.RuntimeException: Bug in Hybrid Hash Join: Request to spill a partition with less than two buffers. at org.apache.flink.runtime.operators.hash.HashPartition.spillPartition(HashPartition.java:288) at org.apache.flink.runtime.operators.hash.MutableHashTable.spillPartition(MutableHashTable.java:1108) at org.apache.flink.runtime.operators.hash.MutableHashTable.insertBucketEntry(MutableHashTable.java:934) at org.apache.flink.runtime.operators.hash.MutableHashTable.insertIntoTable(MutableHashTable.java:859) at org.apache.flink.runtime.operators.hash.MutableHashTable.buildTableFromSpilledPartition(MutableHashTable.java:819) at org.apache.flink.runtime.operators.hash.MutableHashTable.prepareNextPartition(MutableHashTable.java:517) at org.apache.flink.runtime.operators.hash.MutableHashTable.nextRecord(MutableHashTable.java:556) at org.apache.flink.runtime.operators.hash.NonReusingBuildFirstHashMatchIterator.callWithNextKey(NonReusingBuildFirstHashMatchIterator.java:104) at org.apache.flink.runtime.operators.JoinDriver.run(JoinDriver.java:208) at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:489) at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:354) at org.apache.flink.runtime.taskmanager.Task.run(Task.java:579) at java.lang.Thread.run(Thread.java:745) noformat", "A_clean_title": ["bug", "hybrid", "hash", "join", "request", "spill", "partit", "less", "than", "two", "buffer", "follow", "except", "thrown", "when", "run", "exampl", "triangl", "list", "unmodifi", "master", "build", "4cadc3d6", "noformat", "bin", "flink", "run", "java", "java", "exampl", "snapshot", "flink", "exampl", "flink", "exampl", "target", "flink", "10", "enumtrianglesopt", "jar", "enum", "triangl", "opt", "ssv", "e8", "rmat", "undirect", "s19", "output", "noformat", "onli", "chang", "flink", "conf", "yaml", "are", "taskmanag", "numberoftaskslot", "number", "task", "slot", "parallel", "default", "have", "confirm", "input", "file", "ssv|http", "s19", "e8", "googl", "drive", "com", "file", "0b6trssnhj2hxr2lnmhr4amdytnm", "view", "0b6tr", "ssn", "hj2hx", "r2ln", "mhr4amdi", "tn", "usp=shar", "40", "mb", "ssv|http", "s20", "e8", "googl", "drive", "com", "file", "0b6trssnhj2hxni1hbmptu29mtm8", "view", "0b6tr", "ssn", "hj2hx", "ni1hbmpt", "u29m", "tm8", "usp=shar", "83", "mb", "second", "machin", "onli", "larger", "file", "caus", "except", "noformat", "org", "apach", "flink", "client", "program", "programinvocationexcept", "program", "invoc", "except", "program", "execut", "fail", "job", "execut", "fail", "at", "org", "apach", "flink", "client", "program", "client", "runblock", "run", "block", "client", "java:407", "at", "org", "apach", "flink", "client", "program", "client", "runblock", "run", "block", "client", "java:386", "at", "org", "apach", "flink", "client", "program", "client", "runblock", "run", "block", "client", "java:353", "at", "org", "apach", "flink", "client", "program", "contextenviron", "execut", "context", "environ", "contextenviron", "java:64", "context", "environ", "at", "org", "apach", "flink", "exampl", "java", "graph", "enumtrianglesopt", "main", "enum", "triangl", "opt", "enumtrianglesopt", "java:125", "enum", "triangl", "opt", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:62", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:43", "deleg", "method", "accessor", "impl", "at", "java", "lang", "reflect", "method", "invok", "method", "java:497", "at", "org", "apach", "flink", "client", "program", "packagedprogram", "callmainmethod", "packag", "program", "call", "main", "method", "packagedprogram", "java:434", "packag", "program", "at", "org", "apach", "flink", "client", "program", "packagedprogram", "invokeinteractivemodeforexecut", "packag", "program", "invok", "interact", "mode", "execut", "packagedprogram", "java:350", "packag", "program", "at", "org", "apach", "flink", "client", "program", "client", "runblock", "run", "block", "client", "java:290", "at", "org", "apach", "flink", "client", "clifrontend", "executeprogramblock", "cli", "frontend", "execut", "program", "block", "clifrontend", "java:675", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "run", "cli", "frontend", "clifrontend", "java:324", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "parseparamet", "cli", "frontend", "pars", "paramet", "clifrontend", "java:977", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "main", "cli", "frontend", "clifrontend", "java:1027", "cli", "frontend", "caus", "by", "org", "apach", "flink", "runtim", "client", "jobexecutionexcept", "job", "execut", "except", "job", "execut", "fail", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "anonfun", "handlemessag", "handl", "messag", "applyorels", "appli", "or", "jobmanag", "scala:425", "job", "manag", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "leadersessionmessagefilt", "leader", "session", "messag", "filter", "anonfun", "receiv", "applyorels", "appli", "or", "leadersessionmessagefilt", "scala:36", "leader", "session", "messag", "filter", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "mcvl", "mc", "vl", "sp", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:33", "abstract", "partial", "function", "at", "scala", "runtim", "abstractpartialfunct", "abstract", "partial", "function", "mcvl", "mc", "vl", "sp", "appli", "abstractpartialfunct", "scala:25", "abstract", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:33", "log", "messag", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "appli", "logmessag", "scala:28", "log", "messag", "at", "scala", "partialfunct", "partial", "function", "class", "applyorels", "appli", "or", "partialfunct", "scala:118", "partial", "function", "at", "org", "apach", "flink", "runtim", "logmessag", "log", "messag", "anon", "applyorels", "appli", "or", "logmessag", "scala:28", "log", "messag", "at", "akka", "actor", "actor", "class", "aroundrec", "around", "receiv", "actor", "scala:465", "at", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "aroundrec", "job", "manag", "around", "receiv", "jobmanag", "scala:107", "job", "manag", "at", "akka", "actor", "actorcel", "receivemessag", "actor", "cell", "receiv", "messag", "actorcel", "scala:516", "actor", "cell", "at", "akka", "actor", "actorcel", "invok", "actor", "cell", "actorcel", "scala:487", "actor", "cell", "at", "akka", "dispatch", "mailbox", "processmailbox", "process", "mailbox", "mailbox", "scala:254", "at", "akka", "dispatch", "mailbox", "run", "mailbox", "scala:221", "at", "akka", "dispatch", "mailbox", "exec", "mailbox", "scala:231", "at", "scala", "concurr", "forkjoin", "forkjointask", "doexec", "fork", "join", "task", "exec", "forkjointask", "java:260", "fork", "join", "task", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "fork", "join", "pool", "workqueu", "runtask", "work", "queue", "run", "task", "forkjoinpool", "java:1339", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinpool", "runwork", "fork", "join", "pool", "run", "worker", "forkjoinpool", "java:1979", "fork", "join", "pool", "at", "scala", "concurr", "forkjoin", "forkjoinworkerthread", "run", "fork", "join", "worker", "thread", "forkjoinworkerthread", "java:107", "fork", "join", "worker", "thread", "caus", "by", "java", "lang", "runtimeexcept", "runtim", "except", "bug", "hybrid", "hash", "join", "request", "spill", "partit", "less", "than", "two", "buffer", "at", "org", "apach", "flink", "runtim", "oper", "hash", "hashpartit", "spillpartit", "hash", "partit", "spill", "partit", "hashpartit", "java:288", "hash", "partit", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "spillpartit", "mutabl", "hash", "tabl", "spill", "partit", "mutablehasht", "java:1108", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "insertbucketentri", "mutabl", "hash", "tabl", "insert", "bucket", "entri", "mutablehasht", "java:934", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "insertintot", "mutabl", "hash", "tabl", "insert", "into", "tabl", "mutablehasht", "java:859", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "buildtablefromspilledpartit", "mutabl", "hash", "tabl", "build", "tabl", "spill", "partit", "mutablehasht", "java:819", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "preparenextpartit", "mutabl", "hash", "tabl", "prepar", "next", "partit", "mutablehasht", "java:517", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "nextrecord", "mutabl", "hash", "tabl", "next", "record", "mutablehasht", "java:556", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "nonreusingbuildfirsthashmatchiter", "callwithnextkey", "non", "reus", "build", "first", "hash", "match", "iter", "call", "next", "key", "nonreusingbuildfirsthashmatchiter", "java:104", "non", "reus", "build", "first", "hash", "match", "iter", "at", "org", "apach", "flink", "runtim", "oper", "joindriv", "run", "join", "driver", "joindriv", "java:208", "join", "driver", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "run", "regular", "pact", "task", "regularpacttask", "java:489", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "invok", "regular", "pact", "task", "regularpacttask", "java:354", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "taskmanag", "task", "run", "task", "java:579", "at", "java", "lang", "thread", "run", "thread", "java:745", "noformat"], "B_title": "runtime Fix hash table spilling partition selection.", "B_clean_title": ["runtim", "fix", "hash", "tabl", "spill", "partit", "select"]},
{"A_title": "Folder containing an admin user should not be removedThe action of removing a folder that contains the admin user should fail.  This is already the case if it is tried to remove the admin node .  Attaching unit test", "A_clean_title": ["folder", "contain", "admin", "user", "not", "removedth", "remov", "action", "remov", "folder", "that", "contain", "admin", "user", "fail", "thi", "alreadi", "case", "it", "tri", "remov", "admin", "node", "attach", "unit", "test"], "B_title": ": Folder containing an admin user should not be removed", "B_clean_title": ["folder", "contain", "admin", "user", "not", "remov"]},
{"A_title": "SegmentNodeStore rebase operation assumes wrong child node orderThis popped up during the async merge process. The merge first does a rebase which can fail making some index files look like they disappeared 0 wrapping the actual root cause.  The problem is that the rebase failed and removed the missing file. This can be seen by analyzing the :conflict marker info: bq. addExistingNode _b_Lucene41_0.doc _b.fdx _b.fdt _b_4.del  so it points to something trying to add some index related files twice almost like a concurrent commit exception.  Digging even deeper I found that the rebase operation during the state comparison phase assumes a certain order of child nodes 1 and based on that tries to read the mentioned nodes again thinking that they are new ones when if fact they are already present in the list 2. This causes a conflict which fails the entire async update process but also any lucene search as the index files are now gone and the index is in a corrupted state.   0  noformat *WARN* pool-5-thread-2 org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate Index update async failed org.apache.jackrabbit.oak.api.CommitFailedException: OakLucene0004: Failed to close the Lucene index at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.leave(LuceneIndexEditor.java:122) at org.apache.jackrabbit.oak.spi.commit.VisibleEditor.leave(VisibleEditor.java:64) at org.apache.jackrabbit.oak.spi.commit.VisibleEditor.leave(VisibleEditor.java:64) at org.apache.jackrabbit.oak.plugins.index.IndexUpdate.leave(IndexUpdate.java:129) at org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(EditorDiff.java:56) at org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:100) at org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:105) at org.quartz.core.JobRunShell.run(JobRunShell.java:207) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:724) Caused by: java.io.FileNotFoundException: _b_Lucene41_0.doc at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory.openInput(OakDirectory.java:145) noformat  1 http://svn.apache.org/viewvc/jackrabbit/oak/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/MapRecord.java?view=markup#l329  2 before child list noformat _b_Lucene41_0.doc _b.fdx _b.fdt segments_34 _b_4.del _b_Lucene41_0.pos _b.nvm _b.nvd _b.fnm _3n.si _b_Lucene41_0.tip _b_Lucene41_0.tim _3n.cfe segments.gen _3n.cfs _b.si noformat  after list noformat _b_Lucene41_0.pos _3k.cfs _3j_1.del _b.nvm _b.nvd _3d.cfe _3d.cfs _b.fnm _3j.si _3h.si _3i.cfe _3i.cfs _3e_2.del _3f.si _b_Lucene41_0.tip _b_Lucene41_0.tim segments.gen _3e.cfe _3e.cfs _b.si_3g.si _3l.si _3i_1.del _3d_3.del _3e.si _3d.si _b_Lucene41_0.doc _3h_2.del _3i.si _3k_1.del _3j.cfe _3j.cfs _b.fdx _b.fdt _3g_1.del _3k.si _3l.cfe _3l.cfs segments_33 _3f_1.del _3h.cfe _3h.cfs _b_4.del _3f.cfe _3f.cfs _3g.cfe _3g.cfs noformat", "A_clean_title": ["segmentnodestor", "segment", "node", "store", "rebas", "oper", "assum", "wrong", "child", "node", "orderthi", "order", "thi", "pop", "up", "dure", "async", "merg", "process", "merg", "first", "rebas", "which", "fail", "make", "some", "index", "file", "look", "like", "they", "disappear", "wrap", "actual", "root", "caus", "problem", "that", "rebas", "fail", "remov", "miss", "file", "thi", "seen", "by", "analyz", "conflict", "marker", "info", "bq", "addexistingnod", "add", "exist", "node", "doc", "lucene41", "fdx", "fdt", "del", "so", "it", "point", "someth", "tri", "add", "some", "index", "relat", "file", "twice", "almost", "like", "concurr", "commit", "except", "dig", "even", "deeper", "found", "that", "rebas", "oper", "dure", "state", "comparison", "phase", "assum", "certain", "order", "child", "node", "base", "that", "tri", "read", "mention", "node", "again", "think", "that", "they", "are", "new", "one", "when", "fact", "they", "are", "alreadi", "present", "list", "thi", "caus", "conflict", "which", "fail", "entir", "async", "updat", "process", "but", "also", "ani", "lucen", "search", "as", "index", "file", "are", "now", "gone", "index", "corrupt", "state", "noformat", "warn", "pool", "thread", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "async", "index", "updat", "index", "updat", "async", "fail", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "commit", "fail", "except", "oaklucene0004", "oak", "lucene0004", "fail", "close", "lucen", "index", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "luceneindexeditor", "leav", "lucen", "index", "editor", "luceneindexeditor", "java:122", "lucen", "index", "editor", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "visibleeditor", "leav", "visibl", "editor", "visibleeditor", "java:64", "visibl", "editor", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "visibleeditor", "leav", "visibl", "editor", "visibleeditor", "java:64", "visibl", "editor", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "indexupd", "leav", "index", "updat", "indexupd", "java:129", "index", "updat", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "editordiff", "process", "editor", "diff", "editordiff", "java:56", "editor", "diff", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "asyncindexupd", "run", "async", "index", "updat", "asyncindexupd", "java:100", "async", "index", "updat", "at", "org", "apach", "sling", "common", "schedul", "impl", "quartzjobexecutor", "execut", "quartz", "job", "executor", "quartzjobexecutor", "java:105", "quartz", "job", "executor", "at", "org", "quartz", "core", "jobrunshel", "run", "job", "run", "shell", "jobrunshel", "java:207", "job", "run", "shell", "at", "java", "util", "concurr", "threadpoolexecutor", "runwork", "thread", "pool", "executor", "run", "worker", "threadpoolexecutor", "java:1145", "thread", "pool", "executor", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:615", "thread", "pool", "executor", "at", "java", "lang", "thread", "run", "thread", "java:724", "caus", "by", "java", "io", "filenotfoundexcept", "file", "not", "found", "except", "doc", "lucene41", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "oakdirectori", "openinput", "oak", "directori", "open", "input", "oakdirectori", "java:145", "oak", "directori", "noformat", "http", "apach", "java", "svn", "org", "viewvc", "jackrabbit", "oak", "trunk", "oak", "core", "src", "main", "java", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "maprecord", "map", "record", "view=markup", "l329", "befor", "child", "list", "noformat", "doc", "lucene41", "fdx", "fdt", "segment", "34", "del", "po", "lucene41", "nvm", "nvd", "fnm", "si", "3n", "tip", "lucene41", "tim", "lucene41", "cfe", "3n", "segment", "gen", "cf", "3n", "si", "noformat", "after", "list", "noformat", "po", "lucene41", "cf", "3k", "del", "3j", "nvm", "nvd", "cfe", "3d", "cf", "3d", "fnm", "si", "3j", "si", "3h", "cfe", "3i", "cf", "3i", "del", "3e", "si", "3f", "tip", "lucene41", "tim", "lucene41", "segment", "gen", "cfe", "3e", "cf", "3e", "si", "si", "3g", "si", "3l", "del", "3i", "del", "3d", "si", "3e", "si", "3d", "doc", "lucene41", "del", "3h", "si", "3i", "del", "3k", "cfe", "3j", "cf", "3j", "fdx", "fdt", "del", "3g", "si", "3k", "cfe", "3l", "cf", "3l", "segment", "33", "del", "3f", "cfe", "3h", "cf", "3h", "del", "cfe", "3f", "cf", "3f", "cfe", "3g", "cf", "3g", "noformat"], "B_title": "SegmentNodeStore rebase operation assumes wrong child node order", "B_clean_title": ["segmentnodestor", "segment", "node", "store", "rebas", "oper", "assum", "wrong", "child", "node", "order"]},
{"A_title": "missing base64/ URL encodingyesterday i showed the concept of omponents to a friend and stumled into something i dont understand and think it might be a bug.    I have a small panelcompoment that holds a searchform (textfield + submit) nothing special here the code behind looks like:     @Override         public void onSubmit()                       String suchFeld = getSuchfeld();             if(suchFeld.length()>0)                              PageParameters params = new PageParameters();                 params.add(findesuchFeld);                 setResponsePage(Suche.classparams);                          else                              setResponsePage(getPage().getClass());                         the component is put into a BasePage:    public BasePage()          ....             add(bar);         add(new SuchPanel(SuchPanel));         .....    wich is then extended by the real page:   public class Foo extends BasePage          /** Creates a new instance of Zigarren */     public Foo()             wich works all fine however if the class name contains non ascii letters (e.g:    etc.) it gives me a bug if nothing is entered into the search and the part   public class Zubehr extends BasePage          /** Creates a new instance of Zubehr */     public Zubehr()         setResponsePage(getPage().getClass()); comes to action the trouble is that the page might have the URL: ?wicket:bookmarkablePage=:de.pages.Zubeh%C3%B6r but the form tries to go to :  wicket:bookmarkablePage=:de.pages.Zubeh%F6r   wich results in a CODE 404 in the App Server", "A_clean_title": ["miss", "base64", "url", "encodingyesterday", "show", "concept", "ompon", "friend", "stuml", "into", "someth", "dont", "understand", "think", "it", "might", "bug", "have", "small", "panelcompo", "that", "hold", "searchform", "textfield", "submit", "noth", "special", "here", "code", "behind", "look", "like", "overrid", "public", "void", "onsubmit", "submit", "string", "suchfeld", "such", "feld", "getsuchfeld", "get", "suchfeld", "suchfeld", "length", "such", "feld", "pageparamet", "page", "paramet", "param", "new", "pageparamet", "page", "paramet", "param", "add", "findesuchfeld", "findesuch", "feld", "setresponsepag", "set", "respons", "page", "such", "classparam", "setresponsepag", "set", "respons", "page", "getpag", "get", "page", "getclass", "get", "class", "compon", "put", "into", "basepag", "base", "page", "public", "basepag", "base", "page", "add", "bar", "add", "new", "suchpanel", "such", "panel", "suchpanel", "such", "panel", "wich", "then", "extend", "by", "real", "page", "public", "class", "foo", "extend", "basepag", "base", "page", "creat", "new", "instanc", "zigarren", "public", "foo", "wich", "work", "all", "fine", "howev", "class", "name", "contain", "non", "ascii", "letter", "etc", "it", "give", "me", "bug", "noth", "enter", "into", "search", "part", "public", "class", "zubehr", "extend", "basepag", "base", "page", "creat", "new", "instanc", "zubehr", "public", "zubehr", "setresponsepag", "set", "respons", "page", "getpag", "get", "page", "getclass", "get", "class", "come", "action", "troubl", "that", "page", "might", "have", "url", "wicket", "bookmarkablepage=", "bookmark", "page=", "de", "page", "zubeh", "c3", "b6r", "but", "form", "tri", "go", "wicket", "bookmarkablepage=", "bookmark", "page=", "de", "page", "zubeh", "f6r", "wich", "result", "code", "404", "app", "server"], "B_title": "Make sure that bookmarkable urls for classes containing non-ascii characters is encoded properly.", "B_clean_title": ["make", "sure", "that", "bookmark", "url", "class", "contain", "non", "ascii", "charact", "encod", "properli"]},
{"A_title": "TokenLoginModule does not set userId on auth infothe token login module does not set the userid in the authinfo (because it does not know it). and the LoginModuleImpl does not overwrite the AuthInfo if it already exists.  the consequence: Session.getUserID() returns NULL for logins that create a token.  I think that the authinfos should be added even if they already exist. and all users of the public credentials need to be aware that authinfos can exist that are not complete.", "A_clean_title": ["tokenloginmodul", "token", "login", "modul", "not", "set", "userid", "user", "id", "auth", "infoth", "token", "login", "modul", "not", "set", "userid", "authinfo", "becaus", "it", "not", "know", "it", "loginmoduleimpl", "login", "modul", "impl", "not", "overwrit", "authinfo", "auth", "info", "it", "alreadi", "exist", "consequ", "session", "getuserid", "get", "user", "id", "return", "null", "login", "that", "creat", "token", "think", "that", "authinfo", "ad", "even", "they", "alreadi", "exist", "all", "user", "public", "credenti", "need", "awar", "that", "authinfo", "exist", "that", "are", "not", "complet"], "B_title": "    OAK-1363", "B_clean_title": ["oak", "1363"]},
{"A_title": "Lucene index rules should be case insensitiveFollowing the lucene index definitions update the ignored properties are upgraded as a lower case version but the rest of the lucene bits (indexing) still take the case into account resulting in the exclude rules being ignored and properties being indexed.", "A_clean_title": ["lucen", "index", "rule", "case", "insensitivefollow", "insensit", "follow", "lucen", "index", "definit", "updat", "ignor", "properti", "are", "upgrad", "as", "lower", "case", "version", "but", "rest", "lucen", "bit", "index", "still", "take", "case", "into", "account", "result", "exclud", "rule", "be", "ignor", "properti", "be", "index"], "B_title": "- Lucene index rules should be case insensitive", "B_clean_title": ["lucen", "index", "rule", "case", "insensit"]},
{"A_title": "@JsonEnumDefaultValue should take precedence over FAIL_ON_NUMBERS_FOR_ENUMSConsider the following  ObjectMapper definition:  With this  ObjectMapper  when one attempts to deserialize an enum value V for an enum with an @JsonEnumDefaultValue element the deserialization will:   Pass if  Pass if  Fail if  To me this seems highly unintuitive. I would have expected the  READ_UNKNOWN_ENUM_VALUES_USING_DEFAULT_VALUE feature to take precedence over the FAIL_ON_NUMBERS_FOR_ENUMS feature in those cases where it applies (i.e. when deserializing an enum with a default element). Ive put together a test class enumerating the relevant cases. See the inline comments towards the bottom. In four cases I feel that Jacksons current behavior is not as one might expect.   Would love to hear your thoughts on this. (If there is some other feature I should enable to get the behavior Im looking for let me know :).)", "A_clean_title": ["jsonenumdefaultvalu", "json", "enum", "default", "valu", "take", "preced", "over", "fail", "number", "enumsconsid", "enum", "consid", "follow", "objectmapp", "object", "mapper", "definit", "thi", "objectmapp", "object", "mapper", "when", "one", "attempt", "deseri", "enum", "valu", "enum", "jsonenumdefaultvalu", "json", "enum", "default", "valu", "element", "deseri", "will", "pass", "pass", "fail", "me", "thi", "seem", "highli", "unintuit", "would", "have", "expect", "read", "unknown", "enum", "valu", "default", "valu", "featur", "take", "preced", "over", "fail", "number", "enum", "featur", "those", "case", "where", "it", "appli", "when", "deseri", "enum", "default", "element", "ive", "put", "togeth", "test", "class", "enumer", "relev", "case", "see", "inlin", "comment", "toward", "bottom", "four", "case", "feel", "that", "jackson", "current", "behavior", "not", "as", "one", "might", "expect", "would", "love", "hear", "your", "thought", "thi", "there", "some", "other", "featur", "enabl", "get", "behavior", "im", "look", "let", "me", "know"], "B_title": "Fixed #1505", "B_clean_title": ["fix", "1505"]},
{"A_title": "Component reAttach and versioningIm reAttaching a component doing something like:   MyFooPanel p1 = new MyFooPanel(this panel;);  MyBarPanel p2 = new MyBarPanel(this panel);  p1.reAttach();   When I try to restore to the initial page version I found that the component with id panel is not a children component of the page.   I have investigated it and I think it is because when the component is reAttached the order in which the changes are added to the ChangesList is:  - Add p2.  - Remove p1.   When the initial version is restored the undo functionality is done in reverse mode like  - Add p1.  - Remove p2.   The problem is p1 and p2 have the same id so when p2 is removed what is removing is p1 that has just added.   Oscar.", "A_clean_title": ["compon", "reattach", "re", "attach", "versioningim", "version", "im", "reattach", "re", "attach", "compon", "do", "someth", "like", "myfoopanel", "my", "foo", "panel", "p1", "new", "myfoopanel", "my", "foo", "panel", "thi", "panel", "mybarpanel", "my", "bar", "panel", "p2", "new", "mybarpanel", "my", "bar", "panel", "thi", "panel", "p1", "reattach", "re", "attach", "when", "tri", "restor", "initi", "page", "version", "found", "that", "compon", "id", "panel", "not", "children", "compon", "page", "have", "investig", "it", "think", "it", "becaus", "when", "compon", "reattach", "re", "attach", "order", "which", "chang", "are", "ad", "changeslist", "chang", "list", "add", "p2", "remov", "p1", "when", "initi", "version", "restor", "undo", "function", "done", "revers", "mode", "like", "add", "p1", "remov", "p2", "problem", "p1", "p2", "have", "same", "id", "so", "when", "p2", "remov", "what", "remov", "p1", "that", "ha", "just", "ad", "oscar"], "B_title": "bug fix for http://issues.apache.org/jira/browse/WICKET-172 1> remove(child) would only look at the id not at the instance. 2> addedComponent was first called before removedComponent (switched) some code cleanup.", "B_clean_title": ["bug", "fix", "http", "172", "apach", "issu", "org", "jira", "brows", "wicket", "remov", "child", "would", "onli", "look", "at", "id", "not", "at", "instanc", "addedcompon", "ad", "compon", "wa", "first", "call", "befor", "removedcompon", "remov", "compon", "switch", "some", "code", "cleanup"]},
{"A_title": "anonymous object type inference behavior is different when calling constructorsNone", "A_clean_title": ["anonym", "object", "type", "infer", "behavior", "differ", "when", "call", "constructorsnon", "constructor", "none"], "B_title": "Fix some bugs in new inference: - traverse children before the parent - do backwards inference on params like we do for CALL Fixes issue 729", "B_clean_title": ["fix", "some", "bug", "new", "infer", "travers", "children", "befor", "parent", "backward", "infer", "param", "like", "we", "call", "fix", "issu", "729"]},
{"A_title": "ExtendedMessageFormat: OutOfMemory with custom format registry and a pattern containing single quotesWhen using ExtendedMessageFormat with a custom format registry and a pattern conatining single quotes an OutOfMemoryError will occur. Example that will cause error: ExtendedMessageFormatTest.java  private static Map<String Object> formatRegistry = new HashMap<String Object>();         static          formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT new DummyFormatFactory());               public static void main(String args)          ExtendedMessageFormat mf = new ExtendedMessageFormat(its a dummy test! formatRegistry);         String formattedPattern = mf.format(new String great);         System.out.println(formattedPattern);          The following change starting at line 421 on the 2.4 release seems to fix the problem: ExtendedMessageFormat.java CURRENT (Broken): if (escapingOn && cstart == QUOTE)          return appendTo == null ? null : appendTo.append(QUOTE);   WORKING: if (escapingOn && cstart == QUOTE)          next(pos);         return appendTo == null ? null : appendTo.append(QUOTE);", "A_clean_title": ["extendedmessageformat", "extend", "messag", "format", "outofmemori", "out", "memori", "custom", "format", "registri", "pattern", "contain", "singl", "quoteswhen", "quot", "when", "extendedmessageformat", "extend", "messag", "format", "custom", "format", "registri", "pattern", "conatin", "singl", "quot", "outofmemoryerror", "out", "memori", "error", "will", "occur", "exampl", "that", "will", "caus", "error", "extendedmessageformattest", "java", "extend", "messag", "format", "test", "privat", "static", "map", "string", "object", "formatregistri", "format", "registri", "new", "hashmap", "hash", "map", "string", "object", "static", "formatregistri", "put", "format", "registri", "dummyformatfactori", "dummi", "format", "factori", "dummi", "format", "new", "dummyformatfactori", "dummi", "format", "factori", "public", "static", "void", "main", "string", "arg", "extendedmessageformat", "extend", "messag", "format", "mf", "new", "extendedmessageformat", "extend", "messag", "format", "it", "dummi", "test", "formatregistri", "format", "registri", "string", "formattedpattern", "format", "pattern", "mf", "format", "new", "string", "great", "system", "out", "println", "formattedpattern", "format", "pattern", "follow", "chang", "start", "at", "line", "421", "releas", "seem", "fix", "problem", "extendedmessageformat", "java", "extend", "messag", "format", "current", "broken", "escapingon", "escap", "cstart", "quot", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot", "work", "escapingon", "escap", "cstart", "quot", "next", "po", "return", "appendto", "append", "null", "null", "appendto", "append", "append", "quot"], "B_title": "Fix for LANG-477 OutOfMemory with custom format registry and a pattern containing single quotes - thanks to Duncan Eley", "B_clean_title": ["fix", "lang", "477", "outofmemori", "out", "memori", "custom", "format", "registri", "pattern", "contain", "singl", "quot", "thank", "duncan", "eley"]},
{"A_title": "SmartLinkLabel failing to process email with -In a similar vein to WICKET-3174 - using SmartLinkLabel with an email address that includes a - generates a link only on the right-most part of the address.   Example:  - my-test@example.com  Will generate a link like:  - my-<a href=mailto:test@example.com>test@example.com</a>   The addition of the - char is a valid email address format.", "A_clean_title": ["smartlinklabel", "smart", "link", "label", "fail", "process", "email", "similar", "vein", "wicket", "3174", "smartlinklabel", "smart", "link", "label", "email", "address", "that", "includ", "gener", "link", "onli", "right", "most", "part", "address", "exampl", "my", "test", "exampl", "com", "will", "gener", "link", "like", "my", "href=mailto", "test", "exampl", "com", "test", "exampl", "com", "addit", "char", "valid", "email", "address", "format"], "B_title": "SmartLinkLabel escape minus in pattern", "B_clean_title": ["smartlinklabel", "smart", "link", "label", "escap", "minu", "pattern"]},
{"A_title": "bug with implicit namespaces across modulesNone", "A_clean_title": ["bug", "implicit", "namespac", "across", "modulesnon", "modul", "none"], "B_title": "Fix bug with implicit namespaces across modules. Contributed by bolinfest Fixes issue 261", "B_clean_title": ["fix", "bug", "implicit", "namespac", "across", "modul", "contribut", "by", "bolinfest", "fix", "issu", "261"]},
{"A_title": "Access to disconnected MemoryNodeBuilder should throw IllegalStateExceptionNone", "A_clean_title": ["access", "disconnect", "memorynodebuild", "memori", "node", "builder", "throw", "illegalstateexceptionnon", "illeg", "state", "except", "none"], "B_title": "Access to disconnected MemoryNodeBuilder should throw IllegalStateException", "B_clean_title": ["access", "disconnect", "memorynodebuild", "memori", "node", "builder", "throw", "illegalstateexcept", "illeg", "state", "except"]},
{"A_title": "AccumuloInputFormat cannot fetch empty column familyThe following fails: code:java Job job = new Job(); HashSet<Pair<TextText>> cols = new HashSet<Pair<TextText>>(); cols.add(new Pair<TextText>(new Text() null)); AccumuloInputFormat.fetchColumns(job cols); Set<Pair<TextText>> setCols = AccumuloInputFormat.getFetchedColumns(job); assertEquals(cols.size() setCols.size()); code", "A_clean_title": ["accumuloinputformat", "accumulo", "input", "format", "not", "fetch", "empti", "column", "familyth", "famili", "follow", "fail", "code", "java", "job", "job", "new", "job", "hashset", "hash", "set", "pair", "texttext", "text", "text", "col", "new", "hashset", "hash", "set", "pair", "texttext", "text", "text", "col", "add", "new", "pair", "texttext", "text", "text", "new", "text", "null", "accumuloinputformat", "fetchcolumn", "accumulo", "input", "format", "fetch", "column", "job", "col", "set", "pair", "texttext", "text", "text", "setcol", "set", "col", "accumuloinputformat", "getfetchedcolumn", "accumulo", "input", "format", "get", "fetch", "column", "job", "assertequ", "assert", "equal", "col", "size", "setcol", "size", "set", "col", "code"], "B_title": "Handle empty column family correctly for AccumuloInputFormat", "B_clean_title": ["handl", "empti", "column", "famili", "correctli", "accumuloinputformat", "accumulo", "input", "format"]},
{"A_title": "Brent optimizer doesnt use the Base optimizer iteration counterBrentOptimizer uses iter defined in doOptimize  to count iterations. It should ideally use the iteration counter defined for the BaseOptimizer.", "A_clean_title": ["brent", "optim", "doesnt", "use", "base", "optim", "iter", "counterbrentoptim", "counter", "brent", "optim", "use", "iter", "defin", "dooptim", "optim", "count", "iter", "it", "ideal", "use", "iter", "counter", "defin", "baseoptim", "base", "optim"], "B_title": "Use base class iteration counter. Reported by Ajo Fod.", "B_clean_title": ["use", "base", "class", "iter", "counter", "report", "by", "ajo", "fod"]},
{"A_title": "Enum key for Map ignores SerializationFeature.WRITE_ENUMS_USING_INDEXVersion: latest 2.8  Failing unit tests added here:   https://github.com/SolaKun/jackson-databind/commit/6e095f75edd1de3eb33be5950c56d562bd6d584a Only java.util.Map test case provided but doesnt work with EnumMap as well..", "A_clean_title": ["enum", "key", "map", "ignor", "serializationfeatur", "serial", "featur", "write", "enum", "indexvers", "index", "version", "latest", "fail", "unit", "test", "ad", "here", "http", "databind", "commit", "6e095f75edd1de3eb33be5950c56d562bd6d584a", "github", "com", "solakun", "jackson", "sola", "kun", "onli", "java", "util", "map", "test", "case", "provid", "but", "doesnt", "work", "enummap", "enum", "map", "as", "well"], "B_title": "Fixed #1570", "B_clean_title": ["fix", "1570"]},
{"A_title": "NumberUtils does not handle upper-case hex: 0X and -0XNumberUtils.createNumber() should work equally for 0x1234 and 0X1234; currently 0X1234 generates a NumberFormatException Integer.decode() handles both upper and lower case hex.", "A_clean_title": ["numberutil", "number", "util", "not", "handl", "upper", "case", "hex", "0x", "0xnumberutil", "createnumb", "0x", "number", "util", "creat", "number", "work", "equal", "0x1234", "0x1234", "current", "0x1234", "gener", "numberformatexcept", "number", "format", "except", "integ", "decod", "handl", "both", "upper", "lower", "case", "hex"], "B_title": "NumberUtils does not handle upper-case hex: 0X and -0X", "B_clean_title": ["numberutil", "number", "util", "not", "handl", "upper", "case", "hex", "0x", "0x"]},
{"A_title": "Processor is not using templated type when process method is in an abstract classWe define an abstract spoon Processor declaring a process method on a templated type:     And create a concrete class extending the previous one:      The problem is that both the concrete processors are receiving every classes that matches the  upper bound of our template.", "A_clean_title": ["processor", "not", "templat", "type", "when", "process", "method", "abstract", "classw", "class", "we", "defin", "abstract", "spoon", "processor", "declar", "process", "method", "templat", "type", "creat", "concret", "class", "extend", "previou", "one", "problem", "that", "both", "concret", "processor", "are", "receiv", "everi", "class", "that", "match", "upper", "bound", "our", "templat"], "B_title": "fix: fix issue related to processing generic types (#1504)  fix #1503", "B_clean_title": ["fix", "fix", "issu", "relat", "process", "gener", "type", "1504", "fix", "1503"]},
{"A_title": "Revision GC fails when split documents with very long paths are presentMy company is using the MongoDB microkernel with Oak and weve noticed that the daily revision GC is failing with errors like this: code 13.07.2015 13:06:16.261 *ERROR* pool-7-thread-1-Maintenance Queue(com/adobe/granite/maintenance/job/RevisionCleanupTask) org.apache.jackrabbit.oak.management.ManagementOperation Revision garbage collection failed java.lang.IllegalArgumentException: 13:h113f9d0fe7ac0f87fa06397c37b9ffd4b372eeb1ec93e0818bb4024a32587820 at org.apache.jackrabbit.oak.plugins.document.Revision.fromString(Revision.java:236) at org.apache.jackrabbit.oak.plugins.document.SplitDocumentCleanUp.disconnect(SplitDocumentCleanUp.java:84) at org.apache.jackrabbit.oak.plugins.document.SplitDocumentCleanUp.disconnect(SplitDocumentCleanUp.java:56) at org.apache.jackrabbit.oak.plugins.document.VersionGCSupport.deleteSplitDocuments(VersionGCSupport.java:53) at org.apache.jackrabbit.oak.plugins.document.VersionGarbageCollector.collectSplitDocuments(VersionGarbageCollector.java:117) at org.apache.jackrabbit.oak.plugins.document.VersionGarbageCollector.gc(VersionGarbageCollector.java:105) at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreService 2.run(DocumentNodeStoreService.java:511) at org.apache.jackrabbit.oak.spi.state.RevisionGC 1.call(RevisionGC.java:68) at org.apache.jackrabbit.oak.spi.state.RevisionGC 1.call(RevisionGC.java:64) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745) code  Ive narrowed the issue down to the disconnect(NodeDocument) method of the SplitDocumentCleanUp class|https://svn.apache.org/repos/asf/jackrabbit/oak/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitDocumentCleanUp.java. The method always tries to extract the path of the node from its ID but this wont work for documents whose path is very long because those documents will have the hash of their path in the ID.  I believe this code should fix the issue but I havent had a chance to actually try it: code     private void disconnect(NodeDocument splitDoc)          String mainId = Utils.getIdFromPath(splitDoc.getMainPath());         NodeDocument doc = store.find(NODES mainId);         if (doc == null)              LOG.warn(Main document  already removed. Split document is                      mainId splitId);             return;                  String path = splitDoc.getPath();         int slashIdx = path.lastIndexOf(/);         int height = Integer.parseInt(path.substring(slashIdx + 1));         Revision rev = Revision.fromString(                 path.substring(path.lastIndexOf(/ slashIdx - 1) + 1 slashIdx));         doc = doc.findPrevReferencingDoc(rev height);         if (doc == null)              LOG.warn(Split document  not referenced anymore. Main document is                      splitId mainId);             return;                  // remove reference         if (doc.getSplitDocType() == INTERMEDIATE)              disconnectFromIntermediate(doc rev);          else              markStaleOnMain(doc rev height);               code By using getPath() the code should automatically use either the ID or the _path property whichever is right for the document.", "A_clean_title": ["revis", "gc", "fail", "when", "split", "document", "veri", "long", "path", "are", "presentmi", "present", "my", "compani", "mongodb", "mongo", "db", "microkernel", "oak", "weve", "notic", "that", "daili", "revis", "gc", "fail", "error", "like", "thi", "code", "13", "07", "2015", "13:06:16", "261", "error", "pool", "thread", "mainten", "queue", "com", "adob", "granit", "mainten", "job", "revisioncleanuptask", "revis", "cleanup", "task", "org", "apach", "jackrabbit", "oak", "manag", "managementoper", "manag", "oper", "revis", "garbag", "collect", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "13", "h113f9d0fe7ac0f87fa06397c37b9ffd4b372eeb1ec93e0818bb4024a32587820", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "revis", "fromstr", "string", "revis", "java:236", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "splitdocumentcleanup", "disconnect", "split", "document", "clean", "up", "splitdocumentcleanup", "java:84", "split", "document", "clean", "up", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "splitdocumentcleanup", "disconnect", "split", "document", "clean", "up", "splitdocumentcleanup", "java:56", "split", "document", "clean", "up", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "versiongcsupport", "deletesplitdocu", "version", "gc", "support", "delet", "split", "document", "versiongcsupport", "java:53", "version", "gc", "support", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "versiongarbagecollector", "collectsplitdocu", "version", "garbag", "collector", "collect", "split", "document", "versiongarbagecollector", "java:117", "version", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "versiongarbagecollector", "gc", "version", "garbag", "collector", "versiongarbagecollector", "java:105", "version", "garbag", "collector", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestoreservic", "document", "node", "store", "servic", "run", "documentnodestoreservic", "java:511", "document", "node", "store", "servic", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "revisiongc", "revis", "gc", "call", "revisiongc", "java:68", "revis", "gc", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "revisiongc", "revis", "gc", "call", "revisiongc", "java:64", "revis", "gc", "at", "java", "util", "concurr", "futuretask", "run", "futur", "task", "futuretask", "java:262", "futur", "task", "at", "java", "util", "concurr", "threadpoolexecutor", "runwork", "thread", "pool", "executor", "run", "worker", "threadpoolexecutor", "java:1145", "thread", "pool", "executor", "at", "java", "util", "concurr", "threadpoolexecutor", "thread", "pool", "executor", "worker", "run", "threadpoolexecutor", "java:615", "thread", "pool", "executor", "at", "java", "lang", "thread", "run", "thread", "java:745", "code", "ive", "narrow", "issu", "down", "disconnect", "nodedocu", "node", "document", "method", "splitdocumentcleanup", "split", "document", "clean", "up", "class|http", "apach", "java", "svn", "org", "repo", "asf", "jackrabbit", "oak", "trunk", "oak", "core", "src", "main", "java", "org", "apach", "jackrabbit", "oak", "plugin", "document", "splitdocumentcleanup", "split", "document", "clean", "up", "method", "alway", "tri", "extract", "path", "node", "it", "id", "but", "thi", "wont", "work", "document", "whose", "path", "veri", "long", "becaus", "those", "document", "will", "have", "hash", "their", "path", "id", "believ", "thi", "code", "fix", "issu", "but", "havent", "had", "chanc", "actual", "tri", "it", "code", "privat", "void", "disconnect", "nodedocu", "node", "document", "splitdoc", "split", "doc", "string", "mainid", "main", "id", "util", "getidfrompath", "get", "id", "path", "splitdoc", "getmainpath", "split", "doc", "get", "main", "path", "nodedocu", "node", "document", "doc", "store", "find", "node", "mainid", "main", "id", "doc", "null", "log", "warn", "main", "document", "alreadi", "remov", "split", "document", "mainid", "main", "id", "splitid", "split", "id", "return", "string", "path", "splitdoc", "getpath", "split", "doc", "get", "path", "int", "slashidx", "slash", "idx", "path", "lastindexof", "last", "index", "int", "height", "integ", "parseint", "pars", "int", "path", "substr", "slashidx", "slash", "idx", "revis", "rev", "revis", "fromstr", "string", "path", "substr", "path", "lastindexof", "last", "index", "slashidx", "slash", "idx", "slashidx", "slash", "idx", "doc", "doc", "findprevreferencingdoc", "find", "prev", "referenc", "doc", "rev", "height", "doc", "null", "log", "warn", "split", "document", "not", "referenc", "anymor", "main", "document", "splitid", "split", "id", "mainid", "main", "id", "return", "remov", "refer", "doc", "getsplitdoctyp", "get", "split", "doc", "type", "intermedi", "disconnectfromintermedi", "disconnect", "intermedi", "doc", "rev", "markstaleonmain", "mark", "stale", "main", "doc", "rev", "height", "code", "by", "getpath", "get", "path", "code", "automat", "use", "either", "id", "or", "path", "properti", "whichev", "right", "document"], "B_title": "Revision GC fails when split documents with very long paths are present", "B_clean_title": ["revis", "gc", "fail", "when", "split", "document", "veri", "long", "path", "are", "present"]}]