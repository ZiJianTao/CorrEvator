[{"A_title": "XYSeries.addOrUpdate() should add if duplicates are allowedIve found a bug in jfreechart-1.0.9 code for org.jfree.data.xy.XYSeries. There was a change some time ago which introduced the notion of allowing duplicate X values in XYSeries data. The method addOrUpdate(Number x Number y) was never modified to support this and therefore duplicate data were overwriting existing data.", "A_clean_title": ["xyseri", "addorupd", "xy", "seri", "add", "or", "updat", "add", "duplic", "are", "allowed", "allow", "ive", "found", "bug", "jfreechart", "code", "org", "jfree", "data", "xy", "xyseri", "xy", "seri", "there", "wa", "chang", "some", "time", "ago", "which", "introduc", "notion", "allow", "duplic", "valu", "xyseri", "xy", "seri", "data", "method", "addorupd", "add", "or", "updat", "number", "number", "wa", "never", "modifi", "support", "thi", "therefor", "duplic", "data", "were", "overwrit", "exist", "data"], "B_title": "Use the method provided for sorting XYSeries. ", "B_clean_title": ["use", "method", "provid", "sort", "xyseri", "xy", "seri"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Fix NaN - > org . apache . commons . math3 . complex . Complex. ", "B_clean_title": ["fix", "nan", "na", "org", "apach", "common", "math3", "complex", "complex"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Extend the definition of INF .. ", "B_clean_title": ["extend", "definit", "inf"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Add 0 . 0 equals to Complex. ", "B_clean_title": ["add", "equal", "complex"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Add the inverse of Complex . INF to check for 0 . 0 precision .. ", "B_clean_title": ["add", "invers", "complex", "inf", "check", "precis"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Add the inverse of Complex . INF as well .. ", "B_clean_title": ["add", "invers", "complex", "inf", "as", "well"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Fixed a minor typo in Complex . reciprocal ( ). ", "B_clean_title": ["fix", "minor", "typo", "complex", "reciproc"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "NaN - > Complex . INF. ", "B_clean_title": ["nan", "na", "complex", "inf"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "disable side effects check for functions with side effects. ", "B_clean_title": ["disabl", "side", "effect", "check", "function", "side", "effect"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "@@ start = 0 ; for the better coding experience. ", "B_clean_title": ["start", "better", "code", "experi"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Updated function injector copy. ", "B_clean_title": ["updat", "function", "injector", "copi"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Allow side effects in function arguments .. ", "B_clean_title": ["allow", "side", "effect", "function", "argument"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Fixing the function infusion of side effects in JS stylesheet. ", "B_clean_title": ["fix", "function", "infus", "side", "effect", "js", "stylesheet"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Allow null arguments for static closures .. ", "B_clean_title": ["allow", "null", "argument", "static", "closur"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Allow side effects for closure arguments. ", "B_clean_title": ["allow", "side", "effect", "closur", "argument"]},
{"A_title": "Statistics.setVarianceImpl makes getStandardDeviation produce NaNInvoking SummaryStatistics.setVarianceImpl(new Variance(true/false) makes getStandardDeviation produce NaN. The code to reproduce it:  int scores = 1 2 3 4; SummaryStatistics stats = new SummaryStatistics(); stats.setVarianceImpl(new Variance(false)); //use population variance for(int i : scores)    stats.addValue(i);  double sd = stats.getStandardDeviation(); System.out.println(sd);   A workaround suggested by Mikkel is:    double sd = FastMath.sqrt(stats.getSecondMoment() / stats.getN());", "A_clean_title": ["statist", "setvarianceimpl", "set", "varianc", "impl", "make", "getstandarddevi", "get", "standard", "deviat", "produc", "naninvok", "na", "invok", "summarystatist", "setvarianceimpl", "summari", "statist", "set", "varianc", "impl", "new", "varianc", "true", "fals", "make", "getstandarddevi", "get", "standard", "deviat", "produc", "nan", "na", "code", "reproduc", "it", "int", "score", "summarystatist", "summari", "statist", "stat", "new", "summarystatist", "summari", "statist", "stat", "setvarianceimpl", "set", "varianc", "impl", "new", "varianc", "fals", "use", "popul", "varianc", "int", "score", "stat", "addvalu", "add", "valu", "doubl", "sd", "stat", "getstandarddevi", "get", "standard", "deviat", "system", "out", "println", "sd", "workaround", "suggest", "by", "mikkel", "doubl", "sd", "fastmath", "sqrt", "fast", "math", "stat", "getsecondmo", "get", "second", "moment", "stat", "getn", "get"], "B_title": "updated hercules patch. Fix bug in secondMoment of mean implementation. fixed case. ", "B_clean_title": ["updat", "hercul", "patch", "fix", "bug", "secondmo", "second", "moment", "mean", "implement", "fix", "case"]},
{"A_title": "StrBuilder contains usages of thisBuf.length when they should use sizeWhile fixing LANG-294 I noticed that there are two other places in StrBuilder that reference thisBuf.length and unless Im mistaken they shouldnt.", "A_clean_title": ["strbuilder", "str", "builder", "contain", "usag", "thisbuf", "length", "thi", "buf", "when", "they", "use", "sizewhil", "size", "while", "fix", "lang", "294", "notic", "that", "there", "are", "two", "other", "place", "strbuilder", "str", "builder", "that", "refer", "thisbuf", "length", "thi", "buf", "unless", "im", "mistaken", "they", "shouldnt"], "B_title": "added missing patch. updated hercules bugfix. ", "B_clean_title": ["ad", "miss", "patch", "updat", "hercul", "bugfix"]},
{"A_title": "StrBuilder contains usages of thisBuf.length when they should use sizeWhile fixing LANG-294 I noticed that there are two other places in StrBuilder that reference thisBuf.length and unless Im mistaken they shouldnt.", "A_clean_title": ["strbuilder", "str", "builder", "contain", "usag", "thisbuf", "length", "thi", "buf", "when", "they", "use", "sizewhil", "size", "while", "fix", "lang", "294", "notic", "that", "there", "are", "two", "other", "place", "strbuilder", "str", "builder", "that", "refer", "thisbuf", "length", "thi", "buf", "unless", "im", "mistaken", "they", "shouldnt"], "B_title": "StrBuilder . contains ( ) now uses the same level of storage as ArrayList .. ", "B_clean_title": ["strbuilder", "str", "builder", "contain", "now", "use", "same", "level", "storag", "as", "arraylist", "array", "list"]},
{"A_title": "unexpected typed coverage of less than 100%None", "A_clean_title": ["unexpect", "type", "coverag", "less", "than", "100", "none"], "B_title": "Fix jsDoc parameter definition for function parameters .. ", "B_clean_title": ["fix", "jsdoc", "js", "doc", "paramet", "definit", "function", "paramet"]},
{"A_title": "unexpected typed coverage of less than 100%None", "A_clean_title": ["unexpect", "type", "coverag", "less", "than", "100", "none"], "B_title": "Fix typed scope creator for parameter types .. ", "B_clean_title": ["fix", "type", "scope", "creator", "paramet", "type"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "Fix empty range in TimeSeries. ", "B_clean_title": ["fix", "empti", "rang", "timeseri", "time", "seri"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "Fix an issue with time series end index < startIndex. ", "B_clean_title": ["fix", "issu", "time", "seri", "end", "index", "startindex", "start", "index"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "Fix an issue with TimeSeries . isEmpty ( ) .. ", "B_clean_title": ["fix", "issu", "timeseri", "time", "seri", "isempti", "empti"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "Fix an issue with TimeSeries . isEmptyRange ( ). ", "B_clean_title": ["fix", "issu", "timeseri", "time", "seri", "isemptyrang", "empti", "rang"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "Fix an issue with time series end index < startIndex. ", "B_clean_title": ["fix", "issu", "time", "seri", "end", "index", "startindex", "start", "index"]},
{"A_title": "One of Variance.evaluate() methods does not work correctlyThe method org.apache.commons.math.stat.descriptive.moment.Variance.evaluate(double values double weights double mean int begin int length) does not work properly. Looks loke it ignores the length parameter and grabs the whole dataset. Similar method in Mean class seems to work. I did not check other methods taking the part of the array; they may have the same problem. Workaround: I had to shrink my arrays and use the method without the length.", "A_clean_title": ["one", "varianc", "evalu", "method", "not", "work", "correctlyth", "correctli", "method", "org", "apach", "common", "math", "stat", "descript", "moment", "varianc", "evalu", "doubl", "valu", "doubl", "weight", "doubl", "mean", "int", "begin", "int", "length", "not", "work", "properli", "look", "loke", "it", "ignor", "length", "paramet", "grab", "whole", "dataset", "similar", "method", "mean", "class", "seem", "work", "did", "not", "check", "other", "method", "take", "part", "array", "they", "may", "have", "same", "problem", "workaround", "had", "shrink", "my", "array", "use", "method", "without", "length"], "B_title": "Added missing range in Variance copy constructor. ", "B_clean_title": ["ad", "miss", "rang", "varianc", "copi", "constructor"]},
{"A_title": "One of Variance.evaluate() methods does not work correctlyThe method org.apache.commons.math.stat.descriptive.moment.Variance.evaluate(double values double weights double mean int begin int length) does not work properly. Looks loke it ignores the length parameter and grabs the whole dataset. Similar method in Mean class seems to work. I did not check other methods taking the part of the array; they may have the same problem. Workaround: I had to shrink my arrays and use the method without the length.", "A_clean_title": ["one", "varianc", "evalu", "method", "not", "work", "correctlyth", "correctli", "method", "org", "apach", "common", "math", "stat", "descript", "moment", "varianc", "evalu", "doubl", "valu", "doubl", "weight", "doubl", "mean", "int", "begin", "int", "length", "not", "work", "properli", "look", "loke", "it", "ignor", "length", "paramet", "grab", "whole", "dataset", "similar", "method", "mean", "class", "seem", "work", "did", "not", "check", "other", "method", "take", "part", "array", "they", "may", "have", "same", "problem", "workaround", "had", "shrink", "my", "array", "use", "method", "without", "length"], "B_title": "Fix the for loop. ", "B_clean_title": ["fix", "loop"]},
{"A_title": "StringUtils replaceEach - Bug or Missing DocumentationThe following Test Case for replaceEach fails with a null pointer exception. I have expected that all StringUtils methods are null-friendly The use case is that i will stuff Values into the replacementList of which I do not want to check whether they are null. I admit the use case is not perfect because it is unclear what happens on the replace. I outlined three expectations in the test case of course only one should be met. If it is decided that none of them should be possible I propose to update the documentation with what happens when null is passed as replacement string  import static org.junit.Assert.assertEquals;  import org.apache.commons.lang.StringUtils; import org.junit.Test;   public class StringUtilsTest   @Test public void replaceEach() String original = Hello World!; String searchList = Hello World; String replacementList = Greetings null; String result = StringUtils.replaceEach(original searchList replacementList); assertEquals(Greetings ! result); //perhaps this is ok as well                 //assertEquals(Greetings World! result);                 //or even //assertEquals(Greetings null! result);    ", "A_clean_title": ["stringutil", "string", "util", "replaceeach", "replac", "each", "bug", "or", "miss", "documentationth", "document", "follow", "test", "case", "replaceeach", "replac", "each", "fail", "null", "pointer", "except", "have", "expect", "that", "all", "stringutil", "string", "util", "method", "are", "null", "friendli", "use", "case", "that", "will", "stuff", "valu", "into", "replacementlist", "replac", "list", "which", "not", "want", "check", "whether", "they", "are", "null", "admit", "use", "case", "not", "perfect", "becaus", "it", "unclear", "what", "happen", "replac", "outlin", "three", "expect", "test", "case", "cours", "onli", "one", "met", "it", "decid", "that", "none", "them", "possibl", "propos", "updat", "document", "what", "happen", "when", "null", "pass", "as", "replac", "string", "import", "static", "org", "junit", "assert", "assertequ", "assert", "equal", "import", "org", "apach", "common", "lang", "stringutil", "string", "util", "import", "org", "junit", "test", "public", "class", "stringutilstest", "string", "util", "test", "test", "public", "void", "replaceeach", "replac", "each", "string", "origin", "hello", "world", "string", "searchlist", "search", "list", "hello", "world", "string", "replacementlist", "replac", "list", "greet", "null", "string", "result", "stringutil", "replaceeach", "string", "util", "replac", "each", "origin", "searchlist", "search", "list", "replacementlist", "replac", "list", "assertequ", "assert", "equal", "greet", "result", "perhap", "thi", "ok", "as", "well", "assertequ", "assert", "equal", "greet", "world", "result", "or", "even", "assertequ", "assert", "equal", "greet", "null", "result"], "B_title": "still need more matches in StringUtils. ", "B_clean_title": ["still", "need", "more", "match", "stringutil", "string", "util"]},
{"A_title": "StringUtils replaceEach - Bug or Missing DocumentationThe following Test Case for replaceEach fails with a null pointer exception. I have expected that all StringUtils methods are null-friendly The use case is that i will stuff Values into the replacementList of which I do not want to check whether they are null. I admit the use case is not perfect because it is unclear what happens on the replace. I outlined three expectations in the test case of course only one should be met. If it is decided that none of them should be possible I propose to update the documentation with what happens when null is passed as replacement string  import static org.junit.Assert.assertEquals;  import org.apache.commons.lang.StringUtils; import org.junit.Test;   public class StringUtilsTest   @Test public void replaceEach() String original = Hello World!; String searchList = Hello World; String replacementList = Greetings null; String result = StringUtils.replaceEach(original searchList replacementList); assertEquals(Greetings ! result); //perhaps this is ok as well                 //assertEquals(Greetings World! result);                 //or even //assertEquals(Greetings null! result);    ", "A_clean_title": ["stringutil", "string", "util", "replaceeach", "replac", "each", "bug", "or", "miss", "documentationth", "document", "follow", "test", "case", "replaceeach", "replac", "each", "fail", "null", "pointer", "except", "have", "expect", "that", "all", "stringutil", "string", "util", "method", "are", "null", "friendli", "use", "case", "that", "will", "stuff", "valu", "into", "replacementlist", "replac", "list", "which", "not", "want", "check", "whether", "they", "are", "null", "admit", "use", "case", "not", "perfect", "becaus", "it", "unclear", "what", "happen", "replac", "outlin", "three", "expect", "test", "case", "cours", "onli", "one", "met", "it", "decid", "that", "none", "them", "possibl", "propos", "updat", "document", "what", "happen", "when", "null", "pass", "as", "replac", "string", "import", "static", "org", "junit", "assert", "assertequ", "assert", "equal", "import", "org", "apach", "common", "lang", "stringutil", "string", "util", "import", "org", "junit", "test", "public", "class", "stringutilstest", "string", "util", "test", "test", "public", "void", "replaceeach", "replac", "each", "string", "origin", "hello", "world", "string", "searchlist", "search", "list", "hello", "world", "string", "replacementlist", "replac", "list", "greet", "null", "string", "result", "stringutil", "replaceeach", "string", "util", "replac", "each", "origin", "searchlist", "search", "list", "replacementlist", "replac", "list", "assertequ", "assert", "equal", "greet", "result", "perhap", "thi", "ok", "as", "well", "assertequ", "assert", "equal", "greet", "world", "result", "or", "even", "assertequ", "assert", "equal", "greet", "null", "result"], "B_title": "fix bug. ", "B_clean_title": ["fix", "bug"]},
{"A_title": "GaussianFitter Unexpectedly Throws NotStrictlyPositiveExceptionRunning the following:     double observations =         1.1143831578403364E-29       4.95281403484594E-28       1.1171347211930288E-26       1.7044813962636277E-25       1.9784716574832164E-24       1.8630236407866774E-23       1.4820532905097742E-22       1.0241963854632831E-21       6.275077366673128E-21       3.461808994532493E-20       1.7407124684715706E-19       8.056687953553974E-19       3.460193945992071E-18       1.3883326374011525E-17       5.233894983671116E-17       1.8630791465263745E-16       6.288759227922111E-16       2.0204433920597856E-15       6.198768938576155E-15       1.821419346860626E-14       5.139176445538471E-14       1.3956427429045787E-13       3.655705706448139E-13       9.253753324779779E-13       2.267636001476696E-12       5.3880460095836855E-12       1.2431632654852931E-11       ;     GaussianFitter g =      new GaussianFitter(new LevenbergMarquardtOptimizer());     for (int index = 0; index < 27; index++)          g.addObservedPoint(index observationsindex);             g.fit(); Results in: org.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than or equal to the minimum (0) at org.apache.commons.math.analysis.function.Gaussian Parametric.validateParameters(Gaussian.java:184) at org.apache.commons.math.analysis.function.Gaussian Parametric.value(Gaussian.java:129) Im guessing the initial guess for sigma is off.", "A_clean_title": ["gaussianfitt", "gaussian", "fitter", "unexpectedli", "throw", "notstrictlypositiveexceptionrun", "not", "strictli", "posit", "except", "run", "follow", "doubl", "observ", "29", "1143831578403364e", "28", "95281403484594e", "26", "1171347211930288e", "25", "7044813962636277e", "24", "9784716574832164e", "23", "8630236407866774e", "22", "4820532905097742e", "21", "0241963854632831e", "21", "275077366673128e", "20", "461808994532493e", "19", "7407124684715706e", "19", "056687953553974e", "18", "460193945992071e", "17", "3883326374011525e", "17", "233894983671116e", "16", "8630791465263745e", "16", "288759227922111e", "15", "0204433920597856e", "15", "198768938576155e", "14", "821419346860626e", "14", "139176445538471e", "13", "3956427429045787e", "13", "655705706448139e", "13", "253753324779779e", "12", "267636001476696e", "12", "3880460095836855e", "11", "2431632654852931e", "gaussianfitt", "gaussian", "fitter", "new", "gaussianfitt", "gaussian", "fitter", "new", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "int", "index", "index", "27", "index++", "addobservedpoint", "add", "observ", "point", "index", "observationsindex", "fit", "result", "org", "apach", "common", "math", "except", "notstrictlypositiveexcept", "not", "strictli", "posit", "except", "277", "smaller", "than", "or", "equal", "minimum", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "validateparamet", "valid", "paramet", "gaussian", "java:184", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "valu", "gaussian", "java:129", "im", "guess", "initi", "guess", "sigma", "off"], "B_title": "fit ( ) now uses Gaussian . Parametric ( ). ", "B_clean_title": ["fit", "now", "use", "gaussian", "parametr"]},
{"A_title": "GaussianFitter Unexpectedly Throws NotStrictlyPositiveExceptionRunning the following:     double observations =         1.1143831578403364E-29       4.95281403484594E-28       1.1171347211930288E-26       1.7044813962636277E-25       1.9784716574832164E-24       1.8630236407866774E-23       1.4820532905097742E-22       1.0241963854632831E-21       6.275077366673128E-21       3.461808994532493E-20       1.7407124684715706E-19       8.056687953553974E-19       3.460193945992071E-18       1.3883326374011525E-17       5.233894983671116E-17       1.8630791465263745E-16       6.288759227922111E-16       2.0204433920597856E-15       6.198768938576155E-15       1.821419346860626E-14       5.139176445538471E-14       1.3956427429045787E-13       3.655705706448139E-13       9.253753324779779E-13       2.267636001476696E-12       5.3880460095836855E-12       1.2431632654852931E-11       ;     GaussianFitter g =      new GaussianFitter(new LevenbergMarquardtOptimizer());     for (int index = 0; index < 27; index++)          g.addObservedPoint(index observationsindex);             g.fit(); Results in: org.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than or equal to the minimum (0) at org.apache.commons.math.analysis.function.Gaussian Parametric.validateParameters(Gaussian.java:184) at org.apache.commons.math.analysis.function.Gaussian Parametric.value(Gaussian.java:129) Im guessing the initial guess for sigma is off.", "A_clean_title": ["gaussianfitt", "gaussian", "fitter", "unexpectedli", "throw", "notstrictlypositiveexceptionrun", "not", "strictli", "posit", "except", "run", "follow", "doubl", "observ", "29", "1143831578403364e", "28", "95281403484594e", "26", "1171347211930288e", "25", "7044813962636277e", "24", "9784716574832164e", "23", "8630236407866774e", "22", "4820532905097742e", "21", "0241963854632831e", "21", "275077366673128e", "20", "461808994532493e", "19", "7407124684715706e", "19", "056687953553974e", "18", "460193945992071e", "17", "3883326374011525e", "17", "233894983671116e", "16", "8630791465263745e", "16", "288759227922111e", "15", "0204433920597856e", "15", "198768938576155e", "14", "821419346860626e", "14", "139176445538471e", "13", "3956427429045787e", "13", "655705706448139e", "13", "253753324779779e", "12", "267636001476696e", "12", "3880460095836855e", "11", "2431632654852931e", "gaussianfitt", "gaussian", "fitter", "new", "gaussianfitt", "gaussian", "fitter", "new", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "int", "index", "index", "27", "index++", "addobservedpoint", "add", "observ", "point", "index", "observationsindex", "fit", "result", "org", "apach", "common", "math", "except", "notstrictlypositiveexcept", "not", "strictli", "posit", "except", "277", "smaller", "than", "or", "equal", "minimum", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "validateparamet", "valid", "paramet", "gaussian", "java:184", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "valu", "gaussian", "java:129", "im", "guess", "initi", "guess", "sigma", "off"], "B_title": "GaussianFitter . fit ( ) now uses parameter guesser. ", "B_clean_title": ["gaussianfitt", "gaussian", "fitter", "fit", "now", "use", "paramet", "guesser"]},
{"A_title": "Need range checks for elitismRate in ElitisticListPopulation constructors.There is a range check for setting the elitismRate via ElitisticListPopulations setElitismRate method but not via the constructors.", "A_clean_title": ["need", "rang", "check", "elitismr", "elit", "rate", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "there", "rang", "check", "set", "elitismr", "elit", "rate", "via", "elitisticlistpopul", "elitist", "list", "popul", "setelitismr", "set", "elit", "rate", "method", "but", "not", "via", "constructor"], "B_title": "ElitisticListPopulation can throw exception if elitism rate is too high. ElitisticListPopulation ( ) throws outOfRangeException if elitismRate is not 1 .. ", "B_clean_title": ["elitisticlistpopul", "elitist", "list", "popul", "throw", "except", "elit", "rate", "too", "high", "elitisticlistpopul", "elitist", "list", "popul", "throw", "outofrangeexcept", "out", "rang", "except", "elitismr", "elit", "rate", "not"]},
{"A_title": "Need range checks for elitismRate in ElitisticListPopulation constructors.There is a range check for setting the elitismRate via ElitisticListPopulations setElitismRate method but not via the constructors.", "A_clean_title": ["need", "rang", "check", "elitismr", "elit", "rate", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "there", "rang", "check", "set", "elitismr", "elit", "rate", "via", "elitisticlistpopul", "elitist", "list", "popul", "setelitismr", "set", "elit", "rate", "method", "but", "not", "via", "constructor"], "B_title": "added fix .. ElitisticListPopulation constructor should set the elitism rate before setting the population .. ", "B_clean_title": ["ad", "fix", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "set", "elit", "rate", "befor", "set", "popul"]},
{"A_title": "Need range checks for elitismRate in ElitisticListPopulation constructors.There is a range check for setting the elitismRate via ElitisticListPopulations setElitismRate method but not via the constructors.", "A_clean_title": ["need", "rang", "check", "elitismr", "elit", "rate", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "there", "rang", "check", "set", "elitismr", "elit", "rate", "via", "elitisticlistpopul", "elitist", "list", "popul", "setelitismr", "set", "elit", "rate", "method", "but", "not", "via", "constructor"], "B_title": "Missing license header. ElitisticListPopulation can throw exception if elitismRate is not 1 . 0. ElitisticListPopulation constructor should throw exception if elitismRate is not 1 . 0. ", "B_clean_title": ["miss", "licens", "header", "elitisticlistpopul", "elitist", "list", "popul", "throw", "except", "elitismr", "elit", "rate", "not", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "throw", "except", "elitismr", "elit", "rate", "not"]},
{"A_title": "Need range checks for elitismRate in ElitisticListPopulation constructors.There is a range check for setting the elitismRate via ElitisticListPopulations setElitismRate method but not via the constructors.", "A_clean_title": ["need", "rang", "check", "elitismr", "elit", "rate", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "there", "rang", "check", "set", "elitismr", "elit", "rate", "via", "elitisticlistpopul", "elitist", "list", "popul", "setelitismr", "set", "elit", "rate", "method", "but", "not", "via", "constructor"], "B_title": "Add a exception check. Add a exception check. ", "B_clean_title": ["add", "except", "check", "add", "except", "check"]},
{"A_title": "MathUtils.factorial(n) fails for n >= 17The result of MathUtils.factorial( n ) for n = 17 18 19 is wrong probably because of rounding errors in the double calculations. Replace the first line of MathUtilsTest.testFactorial() by         for (int i = 1; i <= 20; i++)  to check all valid arguments for the long result and see the failure. I suggest implementing a simple loop to multiply the long result - or even using a precomputed long - instead of adding logarithms.", "A_clean_title": ["mathutil", "factori", "math", "util", "fail", "17the", "result", "mathutil", "factori", "math", "util", "17", "18", "19", "wrong", "probabl", "becaus", "round", "error", "doubl", "calcul", "replac", "first", "line", "mathutilstest", "testfactori", "math", "util", "test", "test", "factori", "by", "int", "20", "i++", "check", "all", "valid", "argument", "long", "result", "see", "failur", "suggest", "implement", "simpl", "loop", "multipli", "long", "result", "or", "even", "precomput", "long", "instead", "ad", "logarithm"], "B_title": "Added patch method for MathUtils .. Added patch_method ( ) for n = 20 . 0 .. ", "B_clean_title": ["ad", "patch", "method", "mathutil", "math", "util", "ad", "patch", "method", "20"]},
{"A_title": "Jackson Deserializer security vulnerability via default typing (CVE-2017-7525)I have send email to  info@fasterxml.com", "A_clean_title": ["jackson", "deseri", "secur", "vulner", "via", "default", "type", "cve", "2017", "7525", "have", "send", "email", "info", "fasterxml", "com"], "B_title": "Fix #1599 for 2.7(.10)", "B_clean_title": ["fix", "1599", "10"]},
{"A_title": "Brent solver doesnt throw IllegalArgumentException when initial guess has the wrong signJavadoc for public double solve(final UnivariateRealFunction f final double min final double max final double initial) claims that if the values of the function at the three points have the same sign an IllegalArgumentException is thrown. This case isnt even checked.", "A_clean_title": ["brent", "solver", "doesnt", "throw", "illegalargumentexcept", "illeg", "argument", "except", "when", "initi", "guess", "ha", "wrong", "signjavadoc", "sign", "javadoc", "public", "doubl", "solv", "final", "univariaterealfunct", "univari", "real", "function", "final", "doubl", "min", "final", "doubl", "max", "final", "doubl", "initi", "claim", "that", "valu", "function", "at", "three", "point", "have", "same", "sign", "illegalargumentexcept", "illeg", "argument", "except", "thrown", "thi", "case", "isnt", "even", "check"], "B_title": "Fixed a missing bracketing check of initial interval in Brent solver JIRA: MATH-343", "B_clean_title": ["fix", "miss", "bracket", "check", "initi", "interv", "brent", "solver", "jira", "math", "343"]},
{"A_title": "importdirectory failing on split tablebulk import for the wikisearch example isnt working properly: files are not being assigned to partitions if there are splits.", "A_clean_title": ["importdirectori", "fail", "split", "tablebulk", "import", "wikisearch", "exampl", "isnt", "work", "properli", "file", "are", "not", "be", "assign", "partit", "there", "are", "split"], "B_title": "fix index search", "B_clean_title": ["fix", "index", "search"]},
{"A_title": "EntityInstantiators deallocate params required for instantiation of parent object DATACMNS-1175opened and commented Fetching nested document from MongoDB into Kotlin data class structure will sometimes result in NullPointerException. This is caused by  DefaultingKotlinClassInstantiatorAdapter.createInstance(..) calling ClassGeneratingEntityInstantiator.deallocateArguments(..) method cleaning up the shared params array. Doing this while instantiating a child object will clean up all previously prepared arguments for parents constructor and thus causing NPEs on non-null parameters. Note that everything was fine while using version of Spring Data bundled with Spring Boot 2.0.0.M3    Affects: 2.0 RC3 (Kay)  Referenced from: pull request #247  and commits", "A_clean_title": ["entityinstanti", "entiti", "instanti", "dealloc", "param", "requir", "instanti", "parent", "object", "datacmn", "1175open", "comment", "fetch", "nest", "document", "mongodb", "mongo", "db", "into", "kotlin", "data", "class", "structur", "will", "sometim", "result", "nullpointerexcept", "null", "pointer", "except", "thi", "caus", "by", "defaultingkotlinclassinstantiatoradapt", "createinst", "default", "kotlin", "class", "instanti", "adapt", "creat", "instanc", "call", "classgeneratingentityinstanti", "deallocateargu", "class", "gener", "entiti", "instanti", "dealloc", "argument", "method", "clean", "up", "share", "param", "array", "do", "thi", "while", "instanti", "child", "object", "will", "clean", "up", "all", "previous", "prepar", "argument", "parent", "constructor", "thu", "caus", "npe", "np", "es", "non", "null", "paramet", "note", "that", "everyth", "wa", "fine", "while", "version", "spring", "data", "bundl", "spring", "boot", "m3", "affect", "rc3", "kay", "referenc", "pull", "request", "247", "commit"], "B_title": "DATACMNS-1175 - Remove argument array caching from EntityInstantiators.  We no longer cache argument arrays in our EntityInstantiators to prevent changes to shared mutable state caused by reentrant calls.  Previously a re-entrant call requesting an argument array of the same size as a previous call in the call stack reused the same array instance. Changes to this shared mutable state by multiple invocations caused an invalid state rendering wrong parameters for object instantiation. Removing the caching and only reusing an empty array for zero-arg constructors is the only safe approach for now.  Re-instantiation of object allocations results in a higher GC pressure but guarantee side effect-free instantiation and should be on-par with previous versions performance profile.  Original pull request: #247.", "B_clean_title": ["datacmn", "1175", "remov", "argument", "array", "cach", "entityinstanti", "entiti", "instanti", "we", "no", "longer", "cach", "argument", "array", "our", "entityinstanti", "entiti", "instanti", "prevent", "chang", "share", "mutabl", "state", "caus", "by", "reentrant", "call", "previous", "re", "entrant", "call", "request", "argument", "array", "same", "size", "as", "previou", "call", "call", "stack", "reus", "same", "array", "instanc", "chang", "thi", "share", "mutabl", "state", "by", "multipl", "invoc", "caus", "invalid", "state", "render", "wrong", "paramet", "object", "instanti", "remov", "cach", "onli", "reus", "empti", "array", "zero", "arg", "constructor", "onli", "safe", "approach", "now", "re", "instanti", "object", "alloc", "result", "higher", "gc", "pressur", "but", "guarante", "side", "effect", "free", "instanti", "par", "previou", "version", "perform", "profil", "origin", "pull", "request", "247"]},
{"A_title": "Persist fails on entity without id and version field if @EnableAuditing DATACMNS-957opened and commented Follow domain should be persist:   It works as long as auditing is turned off. After putting  @EnableAuditing to application follows exception is thrown:   Description: If auditing is enabled those steps are executed:    Determine strategy to fill auditing fields  Find fields that should be filled via auditing  Fill found fields  If strategy cant be determined (because id and version is not available in domain) exception is thrown and object isnt persisted.  This exception is also thrown if you dont have any fields in model that are filled via auditing.  There is no need to throw this exception if no fields are filled via auditing. Some code to make it clear:     Ive patch for this ticket.  PR: #189   Issue Links:     Referenced from: pull request #189  Backported to:  1.13 GA (Ingalls)  1.12.7 (Hopper SR7)  1.11.7 (Gosling SR7)", "A_clean_title": ["persist", "fail", "entiti", "without", "id", "version", "field", "enableaudit", "enabl", "audit", "datacmn", "957open", "comment", "follow", "domain", "persist", "it", "work", "as", "long", "as", "audit", "turn", "off", "after", "put", "enableaudit", "enabl", "audit", "applic", "follow", "except", "thrown", "descript", "audit", "enabl", "those", "step", "are", "execut", "determin", "strategi", "fill", "audit", "field", "find", "field", "that", "fill", "via", "audit", "fill", "found", "field", "strategi", "cant", "determin", "becaus", "id", "version", "not", "avail", "domain", "except", "thrown", "object", "isnt", "persist", "thi", "except", "also", "thrown", "you", "dont", "have", "ani", "field", "model", "that", "are", "fill", "via", "audit", "there", "no", "need", "throw", "thi", "except", "no", "field", "are", "fill", "via", "audit", "some", "code", "make", "it", "clear", "ive", "patch", "thi", "ticket", "pr", "189", "issu", "link", "referenc", "pull", "request", "189", "backport", "13", "ga", "ingal", "12", "hopper", "sr7", "11", "gosl", "sr7"], "B_title": "DATACMNS-957 - AuditingHandler now works with entities without an identifier.  Entities without an identifier previously an exception because the IsNewStrategyFactory wasnt able to determine a strategy even if there was no auditing to be applied in the first place.  We now eagerly check for auditability and skip the lookup for an IsNewStrategy completely in case that check returns false.  Related pull request: #189.", "B_clean_title": ["datacmn", "957", "auditinghandl", "audit", "handler", "now", "work", "entiti", "without", "identifi", "entiti", "without", "identifi", "previous", "except", "becaus", "isnewstrategyfactori", "new", "strategi", "factori", "wasnt", "abl", "determin", "strategi", "even", "there", "wa", "no", "audit", "appli", "first", "place", "we", "now", "eagerli", "check", "audit", "skip", "lookup", "isnewstrategi", "new", "strategi", "complet", "case", "that", "check", "return", "fals", "relat", "pull", "request", "189"]},
{"A_title": "TreeImpl#*Location: unable retrieve child location if access to parent is deniedas a consequence of OAK-709 we now have an issue with the way SessionDelegate and Root#getLocation access a node in the hierarchy which has an ancestor which is not accessible.  specifically RootImpl#getLocation will be served a NullLocation for the first ancestor which is not accessible and consequently any accessible child node cannot be accessed.  in order to reproduce the issue you may:  - change AccessControlConfigurationImpl to use PermissionProviderImpl instead   of the tmp solution - and run o.a.j.oak.jcr.security.authorization.ReadTest#testReadDenied", "A_clean_title": ["treeimpl", "tree", "impl", "locat", "unabl", "retriev", "child", "locat", "access", "parent", "denieda", "consequ", "oak", "709", "we", "now", "have", "issu", "way", "sessiondeleg", "session", "deleg", "root", "getloc", "get", "locat", "access", "node", "hierarchi", "which", "ha", "ancestor", "which", "not", "access", "specif", "rootimpl", "root", "impl", "getloc", "get", "locat", "will", "serv", "nullloc", "null", "locat", "first", "ancestor", "which", "not", "access", "consequ", "ani", "access", "child", "node", "not", "access", "order", "reproduc", "issu", "you", "may", "chang", "accesscontrolconfigurationimpl", "access", "control", "configur", "impl", "use", "permissionproviderimpl", "permiss", "provid", "impl", "instead", "tmp", "solut", "run", "oak", "jcr", "secur", "author", "readtest", "read", "test", "testreaddeni", "test", "read", "deni"], "B_title": "TreeImpl#*Location: unable retrieve child location if access to parent is denied tentative fix", "B_clean_title": ["treeimpl", "tree", "impl", "locat", "unabl", "retriev", "child", "locat", "access", "parent", "deni", "tent", "fix"]},
{"A_title": "Behaviors#internalAdd(Behavior) erroneously gets id for stateless behaviorssee http://markmail.org/thread/jtd4zn527r343jbm", "A_clean_title": ["behavior", "internaladd", "intern", "add", "behavior", "erron", "get", "id", "stateless", "behaviorsse", "http", "markmail", "org", "thread", "jtd4zn527r343jbm"], "B_title": "Behaviors#internalAdd(Behavior) erroneously gets id for stateless behaviors", "B_clean_title": ["behavior", "internaladd", "intern", "add", "behavior", "erron", "get", "id", "stateless", "behavior"]},
{"A_title": "Cannot cancel failing/restarting streaming job from the command lineI cannot seem to be able to cancel a failing/restarting job from the command line client. The job cannot be rescheduled so it keeps failing:  The exception I get: 13:58:11240 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Status of job 0c895d22c632de5dfe16c42a9ba818d5 (player-id) changed to RESTARTING. 13:58:25234 INFO  org.apache.flink.runtime.jobmanager.JobManager                - Trying to cancel job with ID 0c895d22c632de5dfe16c42a9ba818d5. 13:58:25561 WARN  akka.remote.ReliableDeliverySupervisor                        - Association with remote system akka.tcp://flink@127.0.0.1:42012 has failed address is now gated for 5000 ms. Reason is: Disassociated.", "A_clean_title": ["not", "cancel", "fail", "restart", "stream", "job", "command", "linei", "line", "not", "seem", "abl", "cancel", "fail", "restart", "job", "command", "line", "client", "job", "not", "reschedul", "so", "it", "keep", "fail", "except", "get", "13:58:11240", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "statu", "job", "0c895d22c632de5dfe16c42a9ba818d5", "player", "id", "chang", "restart", "13:58:25234", "info", "org", "apach", "flink", "runtim", "jobmanag", "jobmanag", "job", "manag", "tri", "cancel", "job", "id", "0c895d22c632de5dfe16c42a9ba818d5", "13:58:25561", "warn", "akka", "remot", "reliabledeliverysupervisor", "reliabl", "deliveri", "supervisor", "associ", "remot", "system", "akka", "tcp", "flink", "127", "1:42012", "ha", "fail", "address", "now", "gate", "5000", "ms", "reason", "disassoci"], "B_title": "runtime Fix cancel during restart", "B_clean_title": ["runtim", "fix", "cancel", "dure", "restart"]},
{"A_title": "IndexPlanner returning plan for queries involving jcr:scoreConsider a query like   noformat /jcr:root//element(* cq:Taggable) (@cq:tags = geometrixx-outdoors:activity/biking or @cq:tags = /etc/tags/geometrixx-outdoors/activity/biking)  order by @jcr:score descending  noformat  And a seemingly non related index like  noformat /oak:index/assetType   ...   - type = lucene   + indexRules     + nt:base       + properties         + assetType           - propertyIndex = true           - name = assetType noformat  Then currently IndexPlanner would return a plan because even when it cannot evaluate any of property restrictions because it thinks it can sort on jcr:score. This later results in an exception like  noformat 14.01.2015 16:16:35.866 *ERROR* 0:0:0:0:0:0:0:1 1421248595863 POST /bin/tagcommand HTTP/1.1 org.apache.sling.engine.impl.SlingRequestProcessorImpl service: Uncaught Throwable java.lang.IllegalStateException: No query created for filter Filter(query=select jcr:path jcr:score * from cq:Taggable as a where cq:tags in(geometrixx-outdoors:activity/swimming /etc/tags/geometrixx-outdoors/activity/swimming) and isdescendantnode(a /) order by jcr:score desc /* xpath: /jcr:root//element(* cq:Taggable) (@cq:tags = geometrixx-outdoors:activity/swimming or @cq:tags = /etc/tags/geometrixx-outdoors/activity/swimming)  order by @jcr:score descending */ path=//* property=cq:tags=in(geometrixx-outdoors:activity/swimming /etc/tags/geometrixx-outdoors/activity/swimming)) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex.getQuery(LucenePropertyIndex.java:505) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex.access 200(LucenePropertyIndex.java:158) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex 1.loadDocs(LucenePropertyIndex.java:303) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex 1.computeNext(LucenePropertyIndex.java:261) at org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex 1.computeNext(LucenePropertyIndex.java:253) at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143) noformat", "A_clean_title": ["indexplann", "index", "planner", "return", "plan", "queri", "involv", "jcr", "scoreconsid", "score", "consid", "queri", "like", "noformat", "jcr", "root", "element", "cq", "taggabl", "cq", "tag", "geometrixx", "outdoor", "activ", "bike", "or", "cq", "tag", "etc", "tag", "geometrixx", "outdoor", "activ", "bike", "order", "by", "jcr", "score", "descend", "noformat", "seemingli", "non", "relat", "index", "like", "noformat", "oak", "index", "assettyp", "asset", "type", "type", "lucen", "indexrul", "index", "rule", "nt", "base", "properti", "assettyp", "asset", "type", "propertyindex", "properti", "index", "true", "name", "assettyp", "asset", "type", "noformat", "then", "current", "indexplann", "index", "planner", "would", "return", "plan", "becaus", "even", "when", "it", "not", "evalu", "ani", "properti", "restrict", "becaus", "it", "think", "it", "sort", "jcr", "score", "thi", "later", "result", "except", "like", "noformat", "14", "01", "2015", "16:16:35", "866", "error", "0:0:0:0:0:0:0:1", "1421248595863", "post", "bin", "tagcommand", "http", "org", "apach", "sling", "engin", "impl", "slingrequestprocessorimpl", "sling", "request", "processor", "impl", "servic", "uncaught", "throwabl", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "no", "queri", "creat", "filter", "filter", "query=select", "jcr", "path", "jcr", "score", "cq", "taggabl", "as", "where", "cq", "tag", "geometrixx", "outdoor", "activ", "swim", "etc", "tag", "geometrixx", "outdoor", "activ", "swim", "isdescendantnod", "order", "by", "jcr", "score", "desc", "xpath", "jcr", "root", "element", "cq", "taggabl", "cq", "tag", "geometrixx", "outdoor", "activ", "swim", "or", "cq", "tag", "etc", "tag", "geometrixx", "outdoor", "activ", "swim", "order", "by", "jcr", "score", "descend", "path=", "property=cq", "tags=in", "geometrixx", "outdoor", "activ", "swim", "etc", "tag", "geometrixx", "outdoor", "activ", "swim", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "getqueri", "lucen", "properti", "index", "get", "queri", "lucenepropertyindex", "java:505", "lucen", "properti", "index", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "access", "lucen", "properti", "index", "200", "lucenepropertyindex", "java:158", "lucen", "properti", "index", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "lucen", "properti", "index", "loaddoc", "load", "doc", "lucenepropertyindex", "java:303", "lucen", "properti", "index", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "lucen", "properti", "index", "computenext", "comput", "next", "lucenepropertyindex", "java:261", "lucen", "properti", "index", "at", "org", "apach", "jackrabbit", "oak", "plugin", "index", "lucen", "lucenepropertyindex", "lucen", "properti", "index", "computenext", "comput", "next", "lucenepropertyindex", "java:253", "lucen", "properti", "index", "at", "com", "googl", "common", "collect", "abstractiter", "trytocomputenext", "abstract", "iter", "tri", "comput", "next", "abstractiter", "java:143", "abstract", "iter", "noformat"], "B_title": "- IndexPlanner returning plan for queries involving jcr:score", "B_clean_title": ["indexplann", "index", "planner", "return", "plan", "queri", "involv", "jcr", "score"]},
{"A_title": "ConstraintViolationException seen with multiple Oak/Mongo with ConcurrentCreateNodesTestWhile running ConcurrentCreateNodesTest with 5 instances writing to same Mongo instance following exception is seen  noformat Exception in thread Background job org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest Writer@3f56e5ed java.lang.RuntimeException: javax.jcr.nodetype.ConstraintViolationException: OakConstraint0001: /: The primary type rep:root does not exist     at org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest Writer.run(ConcurrentCreateNodesTest.java:111)     at org.apache.jackrabbit.oak.benchmark.AbstractTest 1.run(AbstractTest.java:481) Caused by: javax.jcr.nodetype.ConstraintViolationException: OakConstraint0001: /: The primary type rep:root does not exist     at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:225)     at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:212)     at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.newRepositoryException(SessionDelegate.java:679)     at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:553)     at org.apache.jackrabbit.oak.jcr.session.SessionImpl 8.perform(SessionImpl.java:417)     at org.apache.jackrabbit.oak.jcr.session.SessionImpl 8.perform(SessionImpl.java:414)     at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:308)     at org.apache.jackrabbit.oak.jcr.session.SessionImpl.perform(SessionImpl.java:127)     at org.apache.jackrabbit.oak.jcr.session.SessionImpl.save(SessionImpl.java:414)     at org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest Writer.run(ConcurrentCreateNodesTest.java:100)     ... 1 more Caused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakConstraint0001: /: The primary type rep:root does not exist     at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.constraintViolation(TypeEditor.java:150)     at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.getEffectiveType(TypeEditor.java:286)     at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.<init>(TypeEditor.java:101)     at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditorProvider.getRootEditor(TypeEditorProvider.java:85)     at org.apache.jackrabbit.oak.spi.commit.CompositeEditorProvider.getRootEditor(CompositeEditorProvider.java:80)     at org.apache.jackrabbit.oak.spi.commit.EditorHook.processCommit(EditorHook.java:53)     at org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:60)     at org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:60)     at org.apache.jackrabbit.oak.spi.state.AbstractNodeStoreBranch InMemory.merge(AbstractNodeStoreBranch.java:498)     at org.apache.jackrabbit.oak.spi.state.AbstractNodeStoreBranch.merge(AbstractNodeStoreBranch.java:300)     at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge(DocumentNodeStoreBranch.java:129)     at org.apache.jackrabbit.oak.plugins.document.DocumentRootBuilder.merge(DocumentRootBuilder.java:159)     at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.merge(DocumentNodeStore.java:1275)     at org.apache.jackrabbit.oak.core.MutableRoot.commit(MutableRoot.java:247)     at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.commit(SessionDelegate.java:405)     at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:551)     ... 7 more noformat  This has been reported by ~rogoz", "A_clean_title": ["constraintviolationexcept", "constraint", "violat", "except", "seen", "multipl", "oak", "mongo", "concurrentcreatenodestestwhil", "concurr", "creat", "node", "test", "while", "run", "concurrentcreatenodestest", "concurr", "creat", "node", "test", "instanc", "write", "same", "mongo", "instanc", "follow", "except", "seen", "noformat", "except", "thread", "background", "job", "org", "apach", "jackrabbit", "oak", "benchmark", "concurrentcreatenodestest", "concurr", "creat", "node", "test", "writer", "3f56e5e", "java", "lang", "runtimeexcept", "runtim", "except", "javax", "jcr", "nodetyp", "constraintviolationexcept", "constraint", "violat", "except", "oakconstraint0001", "oak", "constraint0001", "primari", "type", "rep", "root", "not", "exist", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "concurrentcreatenodestest", "concurr", "creat", "node", "test", "writer", "run", "concurrentcreatenodestest", "java:111", "concurr", "creat", "node", "test", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "abstracttest", "abstract", "test", "run", "abstracttest", "java:481", "abstract", "test", "caus", "by", "javax", "jcr", "nodetyp", "constraintviolationexcept", "constraint", "violat", "except", "oakconstraint0001", "oak", "constraint0001", "primari", "type", "rep", "root", "not", "exist", "at", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "asrepositoryexcept", "commit", "fail", "except", "as", "repositori", "except", "commitfailedexcept", "java:225", "commit", "fail", "except", "at", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "asrepositoryexcept", "commit", "fail", "except", "as", "repositori", "except", "commitfailedexcept", "java:212", "commit", "fail", "except", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "newrepositoryexcept", "session", "deleg", "new", "repositori", "except", "sessiondeleg", "java:679", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:553", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "session", "impl", "perform", "sessionimpl", "java:417", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "session", "impl", "perform", "sessionimpl", "java:414", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "perform", "session", "deleg", "sessiondeleg", "java:308", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "perform", "session", "impl", "sessionimpl", "java:127", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "session", "sessionimpl", "save", "session", "impl", "sessionimpl", "java:414", "session", "impl", "at", "org", "apach", "jackrabbit", "oak", "benchmark", "concurrentcreatenodestest", "concurr", "creat", "node", "test", "writer", "run", "concurrentcreatenodestest", "java:100", "concurr", "creat", "node", "test", "more", "caus", "by", "org", "apach", "jackrabbit", "oak", "api", "commitfailedexcept", "commit", "fail", "except", "oakconstraint0001", "oak", "constraint0001", "primari", "type", "rep", "root", "not", "exist", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typeeditor", "constraintviol", "type", "editor", "constraint", "violat", "typeeditor", "java:150", "type", "editor", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typeeditor", "geteffectivetyp", "type", "editor", "get", "effect", "type", "typeeditor", "java:286", "type", "editor", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typeeditor", "type", "editor", "init", "typeeditor", "java:101", "type", "editor", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "typeeditorprovid", "getrooteditor", "type", "editor", "provid", "get", "root", "editor", "typeeditorprovid", "java:85", "type", "editor", "provid", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositeeditorprovid", "getrooteditor", "composit", "editor", "provid", "get", "root", "editor", "compositeeditorprovid", "java:80", "composit", "editor", "provid", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "editorhook", "processcommit", "editor", "hook", "process", "commit", "editorhook", "java:53", "editor", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositehook", "processcommit", "composit", "hook", "process", "commit", "compositehook", "java:60", "composit", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "commit", "compositehook", "processcommit", "composit", "hook", "process", "commit", "compositehook", "java:60", "composit", "hook", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "abstractnodestorebranch", "abstract", "node", "store", "branch", "inmemori", "merg", "memori", "abstractnodestorebranch", "java:498", "abstract", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "spi", "state", "abstractnodestorebranch", "merg", "abstract", "node", "store", "branch", "abstractnodestorebranch", "java:300", "abstract", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestorebranch", "merg", "document", "node", "store", "branch", "documentnodestorebranch", "java:129", "document", "node", "store", "branch", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentrootbuild", "merg", "document", "root", "builder", "documentrootbuild", "java:159", "document", "root", "builder", "at", "org", "apach", "jackrabbit", "oak", "plugin", "document", "documentnodestor", "merg", "document", "node", "store", "documentnodestor", "java:1275", "document", "node", "store", "at", "org", "apach", "jackrabbit", "oak", "core", "mutableroot", "commit", "mutabl", "root", "mutableroot", "java:247", "mutabl", "root", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "commit", "session", "deleg", "sessiondeleg", "java:405", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "deleg", "sessiondeleg", "save", "session", "deleg", "sessiondeleg", "java:551", "session", "deleg", "more", "noformat", "thi", "ha", "been", "report", "by", "~rogoz"], "B_title": "ConstraintViolationException seen with multiple Oak/Mongo with ConcurrentCreateNodesTest", "B_clean_title": ["constraintviolationexcept", "constraint", "violat", "except", "seen", "multipl", "oak", "mongo", "concurrentcreatenodestest", "concurr", "creat", "node", "test"]},
{"A_title": "Any empty url-parameter will make wicket 1.5 crashAdding an empty parameter to the query string will make wicket crash.  http://www.example.com/?oneParam&   How to reproduce in test:  PageParameters params = new PageParameters(); params.set(); params.getAllNamed();   Cause: Wicket accepts empty parameters but when encoding the url for a rendered page it will call params.getAllNamed().  params.getAllNamed() instantiates new NamedPairs which calls Args.notEmpty() on the key during instantiation causing the application to crash.   The NamedPair constructor should probably allow empty string as a key and call Args.notNull() on the key in stead.", "A_clean_title": ["ani", "empti", "url", "paramet", "will", "make", "wicket", "crashad", "crash", "ad", "empti", "paramet", "queri", "string", "will", "make", "wicket", "crash", "http", "exampl", "www", "com", "oneparam", "one", "param", "how", "reproduc", "test", "pageparamet", "page", "paramet", "param", "new", "pageparamet", "page", "paramet", "param", "set", "param", "getallnam", "get", "all", "name", "caus", "wicket", "accept", "empti", "paramet", "but", "when", "encod", "url", "render", "page", "it", "will", "call", "param", "getallnam", "get", "all", "name", "param", "getallnam", "get", "all", "name", "instanti", "new", "namedpair", "name", "pair", "which", "call", "arg", "notempti", "not", "empti", "key", "dure", "instanti", "caus", "applic", "crash", "namedpair", "name", "pair", "constructor", "probabl", "allow", "empti", "string", "as", "key", "call", "arg", "notnul", "not", "null", "key", "stead"], "B_title": "Any empty url-parameter will make wicket 1.5 crash", "B_clean_title": ["ani", "empti", "url", "paramet", "will", "make", "wicket", "crash"]},
{"A_title": "YamlGenerator closes the target stream when configured not toBug description  YamlGenerator closes the target stream when configured not to.  Versions used  jackson-dataformat-yaml 2.9.2  jackson-databind 2.9.6 Expected result  The target stream not closed when writing a value. No output when running reproduction script/program.  Actual result  The target stream is closed when using the YamlGenerator with the following output when running the reproduction script/program.   Steps to reproduce", "A_clean_title": ["yamlgener", "yaml", "gener", "close", "target", "stream", "when", "configur", "not", "tobug", "bug", "descript", "yamlgener", "yaml", "gener", "close", "target", "stream", "when", "configur", "not", "version", "use", "jackson", "dataformat", "yaml", "jackson", "databind", "expect", "result", "target", "stream", "not", "close", "when", "write", "valu", "no", "output", "when", "run", "reproduct", "script", "program", "actual", "result", "target", "stream", "close", "when", "yamlgener", "yaml", "gener", "follow", "output", "when", "run", "reproduct", "script", "program", "step", "reproduc"], "B_title": "Merge pull request #112 from vboulaye/closed-stream-when-autoclose-disabled  fix #99 do not close stream when autoclose is disabled in yaml generator/parser", "B_clean_title": ["merg", "pull", "request", "112", "stream", "when", "autoclos", "disabl", "vboulay", "close", "fix", "99", "not", "close", "stream", "when", "autoclos", "disabl", "yaml", "gener", "parser"]},
{"A_title": "Wicket doesnt encrypt links and Ajax URLs for mounted pages when CryptoMapper is usedURL encryption does not work in Wicket links and Ajax URLs.  For links the URL appears unencrypted in the href attribute value and is only later forwarded to the encrypted URL using a 302 response.  I am uploading a quickstart.", "A_clean_title": ["wicket", "doesnt", "encrypt", "link", "ajax", "url", "ur", "ls", "mount", "page", "when", "cryptomapp", "crypto", "mapper", "usedurl", "use", "url", "encrypt", "not", "work", "wicket", "link", "ajax", "url", "ur", "ls", "link", "url", "appear", "unencrypt", "href", "attribut", "valu", "onli", "later", "forward", "encrypt", "url", "302", "respons", "am", "upload", "quickstart"], "B_title": "Wicket doesnt encrypt links and Ajax URLs when CryptoMapper is used", "B_clean_title": ["wicket", "doesnt", "encrypt", "link", "ajax", "url", "ur", "ls", "when", "cryptomapp", "crypto", "mapper", "use"]},
{"A_title": "NodeDocument _modified may go back in timeIn a cluster with multiple DocumentMK instances the _modified field of a NodeDocument may go back in time. This will result in incorrect diff calculations when the DocumentNodeStore uses the _modified field to find changed nodes for a given revision range.", "A_clean_title": ["nodedocu", "node", "document", "modifi", "may", "go", "back", "timein", "time", "cluster", "multipl", "documentmk", "document", "mk", "instanc", "modifi", "field", "nodedocu", "node", "document", "may", "go", "back", "time", "thi", "will", "result", "incorrect", "diff", "calcul", "when", "documentnodestor", "document", "node", "store", "use", "modifi", "field", "find", "chang", "node", "given", "revis", "rang"], "B_title": "NodeDocument _modified may go back in time", "B_clean_title": ["nodedocu", "node", "document", "modifi", "may", "go", "back", "time"]},
{"A_title": "Watermark triggered operators cannot progress with cyclic flowsThe problem is that we can easily create a cyclic watermark (time) dependency in the stream graph which will result in a deadlock for watermark triggered operators such as  the `WindowOperator`.  A solution to this could be to emit a Long.MAX_VALUE watermark from the iteration sources.", "A_clean_title": ["watermark", "trigger", "oper", "not", "progress", "cyclic", "flowsth", "flow", "problem", "that", "we", "easili", "creat", "cyclic", "watermark", "time", "depend", "stream", "graph", "which", "will", "result", "deadlock", "watermark", "trigger", "oper", "such", "as", "windowoper", "window", "oper", "solut", "thi", "could", "emit", "long", "max", "valu", "watermark", "iter", "sourc"], "B_title": "streaming Remove cyclic watermark dependencies for iterations", "B_clean_title": ["stream", "remov", "cyclic", "watermark", "depend", "iter"]},
{"A_title": "RegulaFalsiSolver failureThe following unit test: code @Test public void testBug()      final UnivariateRealFunction f = new UnivariateRealFunction()              @Override             public double value(double x)                  return Math.exp(x) - Math.pow(Math.PI 3.0);                      ;      UnivariateRealSolver solver = new RegulaFalsiSolver();     double root = solver.solve(100 f 1 10);  code fails with noformat illegal state: maximal count (100) exceeded: evaluations noformat  Using PegasusSolver the answer is found after 17 evaluations.", "A_clean_title": ["regulafalsisolv", "regula", "falsi", "solver", "failureth", "failur", "follow", "unit", "test", "code", "test", "public", "void", "testbug", "test", "bug", "final", "univariaterealfunct", "univari", "real", "function", "new", "univariaterealfunct", "univari", "real", "function", "overrid", "public", "doubl", "valu", "doubl", "return", "math", "exp", "math", "pow", "math", "pi", "univariaterealsolv", "univari", "real", "solver", "solver", "new", "regulafalsisolv", "regula", "falsi", "solver", "doubl", "root", "solver", "solv", "100", "10", "code", "fail", "noformat", "illeg", "state", "maxim", "count", "100", "exceed", "evalu", "noformat", "pegasussolv", "pegasu", "solver", "answer", "found", "after", "17", "evalu"], "B_title": "Early detection of Regula Falsi algorithm being stuck due to finite precision. Javadoc makes it clear that either the Pegasus or the Illinois solver should be preferred over the Regula Falsi one (due to D. Hendriks).", "B_clean_title": ["earli", "detect", "regula", "falsi", "algorithm", "be", "stuck", "due", "finit", "precis", "javadoc", "make", "it", "clear", "that", "either", "pegasu", "or", "illinoi", "solver", "prefer", "over", "regula", "falsi", "one", "due", "hendrik"]},
{"A_title": "Property value converion ignores reisdual property definitionAssume following node type which a property defined with type and a residual unnamed property also defined  noformat oak:foo  - stringProp (String)  - * (undefined) noformat  For such node type if a property stringProp is being set with a binary value then Oak converts it into a String property thereby causing binary stream to change. In JR2 conversion would not happen as conversion logic treats setting (stringPropBINARY) as a residual property", "A_clean_title": ["properti", "valu", "converion", "ignor", "reisdual", "properti", "definitionassum", "definit", "assum", "follow", "node", "type", "which", "properti", "defin", "type", "residu", "unnam", "properti", "also", "defin", "noformat", "oak", "foo", "stringprop", "string", "prop", "string", "undefin", "noformat", "such", "node", "type", "properti", "stringprop", "string", "prop", "be", "set", "binari", "valu", "then", "oak", "convert", "it", "into", "string", "properti", "therebi", "caus", "binari", "stream", "chang", "jr2", "convers", "would", "not", "happen", "as", "convers", "logic", "treat", "set", "stringpropbinari", "string", "prop", "binari", "as", "residu", "properti"], "B_title": "Property value converion ignores reisdual property definition", "B_clean_title": ["properti", "valu", "converion", "ignor", "reisdual", "properti", "definit"]},
{"A_title": "nextExponential parameter check bug - patch suppliedIndex: src/main/java/org/apache/commons/math/random/RandomDataImpl.java =================================================================== --- src/main/java/org/apache/commons/math/random/RandomDataImpl.java(revision 830102) +++ src/main/java/org/apache/commons/math/random/RandomDataImpl.java(working copy) @@ -4627 +4627 @@       * @return the random Exponential value       */      public double nextExponential(double mean)  -        if (mean < 0.0)  +        if (mean <= 0.0)               throw MathRuntimeException.createIllegalArgumentException(                    mean must be positive (0) mean);", "A_clean_title": ["nextexponenti", "next", "exponenti", "paramet", "check", "bug", "patch", "suppliedindex", "suppli", "index", "java", "src", "main", "java", "org", "apach", "common", "math", "random", "randomdataimpl", "random", "data", "impl", "java", "src", "main", "java", "org", "apach", "common", "math", "random", "randomdataimpl", "random", "data", "impl", "revis", "830102", "java", "src", "main", "java", "org", "apach", "common", "math", "random", "randomdataimpl", "random", "data", "impl", "work", "copi", "4627", "+4627", "return", "random", "exponenti", "valu", "public", "doubl", "nextexponenti", "next", "exponenti", "doubl", "mean", "mean", "mean", "throw", "mathruntimeexcept", "createillegalargumentexcept", "math", "runtim", "except", "creat", "illeg", "argument", "except", "mean", "must", "posit", "mean"], "B_title": "Fixed parameter test in RandomDataImpl#nextExponential. JIRA: MATH-309.", "B_clean_title": ["fix", "paramet", "test", "randomdataimpl", "random", "data", "impl", "nextexponenti", "next", "exponenti", "jira", "math", "309"]},
{"A_title": "Crash on the web closure compilerNone", "A_clean_title": ["crash", "web", "closur", "compilernon", "compil", "none"], "B_title": "SmartNamePass shouldnt record assignment dependencies if the rhs is a call. The rhs is used by the context so we dont want it removed if the lhs isnt used.", "B_clean_title": ["smartnamepass", "smart", "name", "pass", "shouldnt", "record", "assign", "depend", "rh", "call", "rh", "use", "by", "context", "so", "we", "dont", "want", "it", "remov", "lh", "isnt", "use"]},
{"A_title": "NodeDocument.getNodeAtRevision() may read too many revisionsThis is a regression introduced by OAK-1972.  The revision returned with the value may be different from the revision of the change when the change was first committed to a branch and later merged. In this case the value will return the merge revision. The check in getNodeAtRevision() introduced with OAK-1972 then assumes there may be more recent changes in a previous document and starts to scan the revision history. This scan depends on the number of changes that have been applied on the document since the most recent change on the property in question.", "A_clean_title": ["nodedocu", "getnodeatrevis", "node", "document", "get", "node", "at", "revis", "may", "read", "too", "mani", "revisionsthi", "revis", "thi", "regress", "introduc", "by", "oak", "1972", "revis", "return", "valu", "may", "differ", "revis", "chang", "when", "chang", "wa", "first", "commit", "branch", "later", "merg", "thi", "case", "valu", "will", "return", "merg", "revis", "check", "getnodeatrevis", "get", "node", "at", "revis", "introduc", "oak", "1972", "then", "assum", "there", "may", "more", "recent", "chang", "previou", "document", "start", "scan", "revis", "histori", "thi", "scan", "depend", "number", "chang", "that", "have", "been", "appli", "document", "sinc", "most", "recent", "chang", "properti", "question"], "B_title": "NodeDocument.getNodeAtRevision() may read too many revisions", "B_clean_title": ["nodedocu", "getnodeatrevis", "node", "document", "get", "node", "at", "revis", "may", "read", "too", "mani", "revis"]},
{"A_title": "SystemUtils.getJavaVersionAsFloat throws StringIndexOutOfBoundsException on Android runtime/Dalvik VMCan be replicated in the Android emulator quite easily. Stack trace:   at org.apache.commons.lang.builder.ToStringBuilder.<clinit>(ToStringBuilder.java:98) E/AndroidRuntime( 1681): ... 17 more E/AndroidRuntime( 1681): Caused by: java.lang.ExceptionInInitializerError E/AndroidRuntime( 1681): at org.apache.commons.lang.builder.ToStringStyle MultiLineToStringStyle.<init>(ToStringStyle.java:2276) E/AndroidRuntime( 1681): at org.apache.commons.lang.builder.ToStringStyle.<clinit>(ToStringStyle.java:94) E/AndroidRuntime( 1681): ... 18 more E/AndroidRuntime( 1681): Caused by: java.lang.StringIndexOutOfBoundsException E/AndroidRuntime( 1681): at java.lang.String.substring(String.java:1571) E/AndroidRuntime( 1681): at org.apache.commons.lang.SystemUtils.getJavaVersionAsFloat(SystemUtils.java:1153) E/AndroidRuntime( 1681): at org.apache.commons.lang.SystemUtils.<clinit>(SystemUtils.java:818)", "A_clean_title": ["systemutil", "getjavaversionasfloat", "system", "util", "get", "java", "version", "as", "float", "throw", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "android", "runtim", "dalvik", "vmcan", "vm", "replic", "android", "emul", "quit", "easili", "stack", "trace", "at", "org", "apach", "common", "lang", "builder", "tostringbuild", "string", "builder", "clinit", "tostringbuild", "java:98", "string", "builder", "androidruntim", "android", "runtim", "1681", "17", "more", "androidruntim", "android", "runtim", "1681", "caus", "by", "java", "lang", "exceptionininitializererror", "except", "initi", "error", "androidruntim", "android", "runtim", "1681", "at", "org", "apach", "common", "lang", "builder", "tostringstyl", "string", "style", "multilinetostringstyl", "multi", "line", "string", "style", "init", "tostringstyl", "java:2276", "string", "style", "androidruntim", "android", "runtim", "1681", "at", "org", "apach", "common", "lang", "builder", "tostringstyl", "string", "style", "clinit", "tostringstyl", "java:94", "string", "style", "androidruntim", "android", "runtim", "1681", "18", "more", "androidruntim", "android", "runtim", "1681", "caus", "by", "java", "lang", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "androidruntim", "android", "runtim", "1681", "at", "java", "lang", "string", "substr", "string", "java:1571", "androidruntim", "android", "runtim", "1681", "at", "org", "apach", "common", "lang", "systemutil", "getjavaversionasfloat", "system", "util", "get", "java", "version", "as", "float", "systemutil", "java:1153", "system", "util", "androidruntim", "android", "runtim", "1681", "at", "org", "apach", "common", "lang", "systemutil", "system", "util", "clinit", "systemutil", "java:818", "system", "util"], "B_title": "SystemUtils.getJavaVersionAsFloat throws StringIndexOutOfBoundsException on Android runtime/Dalvik VM. Oops fix return type.", "B_clean_title": ["systemutil", "getjavaversionasfloat", "system", "util", "get", "java", "version", "as", "float", "throw", "stringindexoutofboundsexcept", "string", "index", "out", "bound", "except", "android", "runtim", "dalvik", "vm", "oop", "fix", "return", "type"]},
{"A_title": "CMAESOptimizer does not enforce boundsThe CMAESOptimizer can exceed the bounds passed to optimize.  Looking at the generationLoop in doOptimize() it does a bounds check by calling isFeasible() but if checkFeasableCount is zero (the default) then isFeasible() is never even called.  Also even with non-zero checkFeasableCount it may give up before finding an in-bounds offspring and go forward with an out-of-bounds offspring.  This is against svn revision 1387637.  I can provide an example program where the optimizer ends up with a fit outside the prescribed bounds if that would help.", "A_clean_title": ["cmaesoptim", "cmae", "optim", "not", "enforc", "boundsth", "bound", "cmaesoptim", "cmae", "optim", "exceed", "bound", "pass", "optim", "look", "at", "generationloop", "gener", "loop", "dooptim", "optim", "it", "bound", "check", "by", "call", "isfeas", "feasibl", "but", "checkfeasablecount", "check", "feasabl", "count", "zero", "default", "then", "isfeas", "feasibl", "never", "even", "call", "also", "even", "non", "zero", "checkfeasablecount", "check", "feasabl", "count", "it", "may", "give", "up", "befor", "find", "bound", "offspr", "go", "forward", "out", "bound", "offspr", "thi", "against", "svn", "revis", "1387637", "provid", "exampl", "program", "where", "optim", "end", "up", "fit", "outsid", "prescrib", "bound", "that", "would", "help"], "B_title": "Fixed missing repair of a point that lies outside the boundaries. Thanks to Frank Hessen for the report and for pinpointing the cause of the problem.", "B_clean_title": ["fix", "miss", "repair", "point", "that", "lie", "outsid", "boundari", "thank", "frank", "hessen", "report", "pinpoint", "caus", "problem"]},
{"A_title": "LucenePropertyIndex full-text search on first level relative node returns no resultFollowing query does not return any result even with a proper index defined 1. noformat//element(* test:Page)  +             jcr:contains(jcr:content summer)  noformat  1 code    jcr:primaryType: oak:QueryIndexDefinition   compatVersion: 2   name: pageIndex   type: lucene   async: async   reindex: true   aggregates:      jcr:primaryType: nt:unstructured     test:Page:        jcr:primaryType: nt:unstructured       include0:          jcr:primaryType: nt:unstructured         relativeNode: true         path: jcr:content                  indexRules:      jcr:primaryType: nt:unstructured     test:Page:        jcr:primaryType: nt:unstructured       properties:          jcr:primaryType: nt:unstructured         jcr:lastModified:            jcr:primaryType: nt:unstructured           ordered: true           propertyIndex: true           name: jcr:content/jcr:lastModified           type: Date                          code", "A_clean_title": ["lucenepropertyindex", "lucen", "properti", "index", "full", "text", "search", "first", "level", "rel", "node", "return", "no", "resultfollow", "result", "follow", "queri", "not", "return", "ani", "result", "even", "proper", "index", "defin", "noformat", "element", "test", "page", "jcr", "contain", "jcr", "content", "summer", "noformat", "code", "jcr", "primarytyp", "primari", "type", "oak", "queryindexdefinit", "queri", "index", "definit", "compatvers", "compat", "version", "name", "pageindex", "page", "index", "type", "lucen", "async", "async", "reindex", "true", "aggreg", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "test", "page", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "include0", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "relativenod", "rel", "node", "true", "path", "jcr", "content", "indexrul", "index", "rule", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "test", "page", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "properti", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "jcr", "lastmodifi", "last", "modifi", "jcr", "primarytyp", "primari", "type", "nt", "unstructur", "order", "true", "propertyindex", "properti", "index", "true", "name", "jcr", "content", "jcr", "lastmodifi", "last", "modifi", "type", "date", "code"], "B_title": "- LucenePropertyIndex full-text search on first level relative node returns no result", "B_clean_title": ["lucenepropertyindex", "lucen", "properti", "index", "full", "text", "search", "first", "level", "rel", "node", "return", "no", "result"]},
{"A_title": "Exception when stubbing more than once with when...thenThrowIf I create a mock and stub a method so it throws an exception and do that twice the first exception will be thrown upon invoking the second stub instruction.", "A_clean_title": ["except", "when", "stub", "more", "than", "onc", "when", "thenthrowif", "then", "throw", "creat", "mock", "stub", "method", "so", "it", "throw", "except", "that", "twice", "first", "except", "will", "thrown", "upon", "invok", "second", "stub", "instruct"], "B_title": "issue 282 : mock invocation listeners were removed on reset(mock)", "B_clean_title": ["issu", "282", "mock", "invoc", "listen", "were", "remov", "reset", "mock"]},
{"A_title": "Wide bounds to CMAESOptimizer result in NaN parameters passed to fitness functionIf you give large values as lower/upper bounds (for example -Double.MAX_VALUE as a lower bound) the optimizer can call the fitness function with parameters set to NaN.  My guess is this is due to FitnessFunction.encode/decode generating NaN when normalizing/denormalizing parameters.  For example if the difference between the lower and upper bound is greater than Double.MAX_VALUE encode could divide infinity by infinity.", "A_clean_title": ["wide", "bound", "cmaesoptim", "cmae", "optim", "result", "nan", "na", "paramet", "pass", "fit", "functionif", "function", "you", "give", "larg", "valu", "as", "lower", "upper", "bound", "exampl", "doubl", "max", "valu", "as", "lower", "bound", "optim", "call", "fit", "function", "paramet", "set", "nan", "na", "my", "guess", "thi", "due", "fitnessfunct", "fit", "function", "encod", "decod", "gener", "nan", "na", "when", "normal", "denorm", "paramet", "exampl", "differ", "between", "lower", "upper", "bound", "greater", "than", "doubl", "max", "valu", "encod", "could", "divid", "infin", "by", "infin"], "B_title": "Early detection that overflow will occur in the variables normalization procedure (encode method). Warning mentioned in the documentation.", "B_clean_title": ["earli", "detect", "that", "overflow", "will", "occur", "variabl", "normal", "procedur", "encod", "method", "warn", "mention", "document"]},
{"A_title": "Incomplete reinitialization with some events handlingI get a bug with event handling: I track 2 events that occur in the same step when the first one is accepted it resets the state but the reinitialization is not complete and the second one becomes unable to find its way. I cant give my context which is rather large but I tried a patch that works for me unfortunately it breaks the unit tests.", "A_clean_title": ["incomplet", "reiniti", "some", "event", "handlingi", "handl", "get", "bug", "event", "handl", "track", "event", "that", "occur", "same", "step", "when", "first", "one", "accept", "it", "reset", "state", "but", "reiniti", "not", "complet", "second", "one", "becom", "unabl", "find", "it", "way", "cant", "give", "my", "context", "which", "rather", "larg", "but", "tri", "patch", "that", "work", "me", "unfortun", "it", "break", "unit", "test"], "B_title": "Fixed an event resetting issue in ODE.", "B_clean_title": ["fix", "event", "reset", "issu", "ode"]},
{"A_title": "InputTableConfig missing isOfflineScan field in SerializerInputTableConfig write(DataOutput dataOutput) forgets to write out the isOfflineScan field which makes it always false when it gets unserialized.", "A_clean_title": ["inputtableconfig", "input", "tabl", "config", "miss", "isofflinescan", "offlin", "scan", "field", "serializerinputtableconfig", "serial", "input", "tabl", "config", "write", "dataoutput", "data", "output", "dataoutput", "data", "output", "forget", "write", "out", "isofflinescan", "offlin", "scan", "field", "which", "make", "it", "alway", "fals", "when", "it", "get", "unseri"], "B_title": "Offline scan property is now being properly serialized. Added verification that all other booleans are being serialized.", "B_clean_title": ["offlin", "scan", "properti", "now", "be", "properli", "serial", "ad", "verif", "that", "all", "other", "boolean", "are", "be", "serial"]},
{"A_title": "Typos in externs/html5.jsNone", "A_clean_title": ["typo", "jsnone", "extern", "html5", "js", "none"], "B_title": "Fixes a bug in getGreatestSubtype (Andrew)", "B_clean_title": ["fix", "bug", "getgreatestsubtyp", "get", "greatest", "subtyp", "andrew"]},
{"A_title": "Branch reset does not revert all changesThis is caused by recent changes done for OAK-3646.", "A_clean_title": ["branch", "reset", "not", "revert", "all", "changesthi", "chang", "thi", "caus", "by", "recent", "chang", "done", "oak", "3646"], "B_title": "Branch reset does not revert all changes", "B_clean_title": ["branch", "reset", "not", "revert", "all", "chang"]},
{"A_title": "In RealVector dotProduct and outerProduct return wrong results due to misuse of sparse iteratorsIn class RealVector the default implementation of RealMatrix outerProduct(RealVector) uses sparse iterators on the entries of the two vectors. The rationale behind this is that 0d * x == 0d is true for all double x. This assumption is in fact false since 0d * NaN == NaN.  Proposed fix is to loop through *all* entries of both vectors. This can have a significant impact on the CPU cost but robustness should probably be preferred over speed in default implementations.  Same issue occurs with double dotProduct(RealVector) which uses sparse iterators for this only.  Another option would be to through an exception if isNaN() is true in which case caching could be used for both isNaN() and isInfinite().", "A_clean_title": ["realvector", "real", "vector", "dotproduct", "dot", "product", "outerproduct", "outer", "product", "return", "wrong", "result", "due", "misus", "spars", "iteratorsin", "iter", "class", "realvector", "real", "vector", "default", "implement", "realmatrix", "real", "matrix", "outerproduct", "outer", "product", "realvector", "real", "vector", "use", "spars", "iter", "entri", "two", "vector", "rational", "behind", "thi", "that", "0d", "0d", "true", "all", "doubl", "thi", "assumpt", "fact", "fals", "sinc", "0d", "nan", "na", "nan", "na", "propos", "fix", "loop", "through", "all", "entri", "both", "vector", "thi", "have", "signific", "impact", "cpu", "cost", "but", "robust", "probabl", "prefer", "over", "speed", "default", "implement", "same", "issu", "occur", "doubl", "dotproduct", "dot", "product", "realvector", "real", "vector", "which", "use", "spars", "iter", "thi", "onli", "anoth", "option", "would", "through", "except", "isnan", "na", "true", "which", "case", "cach", "could", "use", "both", "isnan", "na", "isinfinit", "infinit"], "B_title": "fixed a bug in RealVector.outerProduct(RealVector). Now loops through *all* entries of the vectors.", "B_clean_title": ["fix", "bug", "realvector", "outerproduct", "real", "vector", "outer", "product", "realvector", "real", "vector", "now", "loop", "through", "all", "entri", "vector"]},
{"A_title": "SerializationUtils throws ClassNotFoundException when cloning primitive classesIf a serializable object contains a reference to a primitive class e.g. int.class or int.class the SerializationUtils throw a ClassNotFoundException when trying to clone that object.  import org.apache.commons.lang3.SerializationUtils; import org.junit.Test;   public class SerializationUtilsTest    @Test public void primitiveTypeClassSerialization() Class<?> primitiveType = int.class;  Class<?> clone = SerializationUtils.clone(primitiveType); assertEquals(primitiveType clone);     The problem was already reported as a java bug http://bugs.sun.com/view_bug.do?bug_id=4171142 and ObjectInputStream is fixed since java version 1.4. The SerializationUtils problem arises because the SerializationUtils internally use the ClassLoaderAwareObjectInputStream that overrides the ObjectInputStreams resoleClass method without delegating to the super method in case of a ClassNotFoundException. I understand the intention of the ClassLoaderAwareObjectInputStream but this implementation should also implement a fallback to the original implementation. For example:          protected Class<?> resolveClass(ObjectStreamClass desc) throws IOException ClassNotFoundException              String name = desc.getName();             try                  return Class.forName(name false classLoader);              catch (ClassNotFoundException ex)              try                   return Class.forName(name false Thread.currentThread().getContextClassLoader());              catch (Exception e)       return super.resolveClass(desc);                          Here is the code in ObjectInputStream that fixed the java bug.      protected Class<?> resolveClass(ObjectStreamClass desc) throws IOException ClassNotFoundException      String name = desc.getName(); try      return Class.forName(name false latestUserDefinedLoader());  catch (ClassNotFoundException ex)      Class cl = (Class) primClasses.get(name);     if (cl != null)  return cl;      else  throw ex;", "A_clean_title": ["serializationutil", "serial", "util", "throw", "classnotfoundexcept", "class", "not", "found", "except", "when", "clone", "primit", "classesif", "class", "serializ", "object", "contain", "refer", "primit", "class", "int", "class", "or", "int", "class", "serializationutil", "serial", "util", "throw", "classnotfoundexcept", "class", "not", "found", "except", "when", "tri", "clone", "that", "object", "import", "org", "apach", "common", "lang3", "serializationutil", "serial", "util", "import", "org", "junit", "test", "public", "class", "serializationutilstest", "serial", "util", "test", "test", "public", "void", "primitivetypeclassseri", "primit", "type", "class", "serial", "class", "primitivetyp", "primit", "type", "int", "class", "class", "clone", "serializationutil", "clone", "serial", "util", "primitivetyp", "primit", "type", "assertequ", "assert", "equal", "primitivetyp", "primit", "type", "clone", "problem", "wa", "alreadi", "report", "as", "java", "bug", "http", "sun", "bug", "bug", "com", "view", "bug", "id=4171142", "objectinputstream", "object", "input", "stream", "fix", "sinc", "java", "version", "serializationutil", "serial", "util", "problem", "aris", "becaus", "serializationutil", "serial", "util", "intern", "use", "classloaderawareobjectinputstream", "class", "loader", "awar", "object", "input", "stream", "that", "overrid", "objectinputstream", "object", "input", "stream", "resoleclass", "resol", "class", "method", "without", "deleg", "super", "method", "case", "classnotfoundexcept", "class", "not", "found", "except", "understand", "intent", "classloaderawareobjectinputstream", "class", "loader", "awar", "object", "input", "stream", "but", "thi", "implement", "also", "implement", "fallback", "origin", "implement", "exampl", "protect", "class", "resolveclass", "resolv", "class", "objectstreamclass", "object", "stream", "class", "desc", "throw", "ioexcept", "io", "except", "classnotfoundexcept", "class", "not", "found", "except", "string", "name", "desc", "getnam", "get", "name", "tri", "return", "class", "fornam", "name", "name", "fals", "classload", "class", "loader", "catch", "classnotfoundexcept", "class", "not", "found", "except", "ex", "tri", "return", "class", "fornam", "name", "name", "fals", "thread", "currentthread", "current", "thread", "getcontextclassload", "get", "context", "class", "loader", "catch", "except", "return", "super", "resolveclass", "resolv", "class", "desc", "here", "code", "objectinputstream", "object", "input", "stream", "that", "fix", "java", "bug", "protect", "class", "resolveclass", "resolv", "class", "objectstreamclass", "object", "stream", "class", "desc", "throw", "ioexcept", "io", "except", "classnotfoundexcept", "class", "not", "found", "except", "string", "name", "desc", "getnam", "get", "name", "tri", "return", "class", "fornam", "name", "name", "fals", "latestuserdefinedload", "latest", "user", "defin", "loader", "catch", "classnotfoundexcept", "class", "not", "found", "except", "ex", "class", "cl", "class", "primclass", "get", "prim", "class", "name", "cl", "null", "return", "cl", "throw", "ex"], "B_title": "SerializationUtils throws ClassNotFoundException when cloning primitive classes", "B_clean_title": ["serializationutil", "serial", "util", "throw", "classnotfoundexcept", "class", "not", "found", "except", "when", "clone", "primit", "class"]},
{"A_title": "MU-201 v3.xx doesnt work?Hi  ive tried to install my tracker in Traccar but it doesnt work. The Logfile was generated and everything is running but not the tracker...  HEX is translatet to:   Port 5051  How can i add the device?  Kind regards  Daniel", "A_clean_title": ["mu", "201", "v3", "xx", "doesnt", "work", "hi", "ive", "tri", "instal", "my", "tracker", "traccar", "but", "it", "doesnt", "work", "logfil", "wa", "gener", "everyth", "run", "but", "not", "tracker", "hex", "translatet", "port", "5051", "how", "add", "devic", "kind", "regard", "daniel"], "B_title": "Fix MU-201 message decoding (fix #3220)", "B_clean_title": ["fix", "mu", "201", "messag", "decod", "fix", "3220"]},
{"A_title": "IResponseFilter cannot change buffer contentsChanges to the responseBuffer passed to an IResponseFilter are not picked up nor are newly created AppendingStringBuffer (return value of the method). Both callers of the method invoke it with a copy of the buffer and ignore return values (BufferedWebResponse line 145 and AjaxRequestTarget line 687).", "A_clean_title": ["iresponsefilt", "respons", "filter", "not", "chang", "buffer", "contentschang", "content", "chang", "responsebuff", "respons", "buffer", "pass", "iresponsefilt", "respons", "filter", "are", "not", "pick", "up", "nor", "are", "newli", "creat", "appendingstringbuff", "append", "string", "buffer", "return", "valu", "method", "both", "caller", "method", "invok", "it", "copi", "buffer", "ignor", "return", "valu", "bufferedwebrespons", "buffer", "web", "respons", "line", "145", "ajaxrequesttarget", "ajax", "request", "target", "line", "687"], "B_title": "Changing AjaxRequestTarget and BufferedWebResponse to dont discard the filtered AppendingStringBuffer response if the filter returns a new instance. Issue: WICKET-3620", "B_clean_title": ["chang", "ajaxrequesttarget", "ajax", "request", "target", "bufferedwebrespons", "buffer", "web", "respons", "dont", "discard", "filter", "appendingstringbuff", "append", "string", "buffer", "respons", "filter", "return", "new", "instanc", "issu", "wicket", "3620"]},
{"A_title": "support @lends annotationNone", "A_clean_title": ["support", "lend", "annotationnon", "annot", "none"], "B_title": "dont emit unsafe global this warnings when the @lends annotation is used correctly. fixes issue 248", "B_clean_title": ["dont", "emit", "unsaf", "global", "thi", "warn", "when", "lend", "annot", "use", "correctli", "fix", "issu", "248"]},
{"A_title": "Failure in one of the batch in VersionGC might lead to orphaned nodesVersionGC logic currently performs deletion of nodes in batches. For GC to work properly NodeDocument should always be removed in bottom-up mode i.e. parent node should be removed *after* child has been removed  Currently the GC logic deletes the NodeDocument in undefined order. In such mode if one of the batch fails then its possible that parent might have got deleted but the child was not deleted.   Now in next run the child node would not be recognized as a deleted node because the commit root would not be found.", "A_clean_title": ["failur", "one", "batch", "versiongc", "version", "gc", "might", "lead", "orphan", "nodesversiongc", "node", "version", "gc", "logic", "current", "perform", "delet", "node", "batch", "gc", "work", "properli", "nodedocu", "node", "document", "alway", "remov", "bottom", "up", "mode", "parent", "node", "remov", "after", "child", "ha", "been", "remov", "current", "gc", "logic", "delet", "nodedocu", "node", "document", "undefin", "order", "such", "mode", "one", "batch", "fail", "then", "it", "possibl", "that", "parent", "might", "have", "got", "delet", "but", "child", "wa", "not", "delet", "now", "next", "run", "child", "node", "would", "not", "recogn", "as", "delet", "node", "becaus", "commit", "root", "would", "not", "found"], "B_title": "- Failure in one of the batch in VersionGC might lead to orphaned nodes", "B_clean_title": ["failur", "one", "batch", "versiongc", "version", "gc", "might", "lead", "orphan", "node"]},
{"A_title": "AccessDenied when modifying transiently moved item with too many ACEsIf at least the following preconditions are fulfilled saving a moved item fails with access denied:  1. there are more PermissionEntries in the PermissionEntryCache than the configured EagerCacheSize 2. an node is moved to a location where the user has write access through a group membership 3. a property is added to the transiently moved item  For example: 1. set the *eagerCacheSize* to 0 2. create new group *testgroup* and user *testuser* 3. make *testuser* member of *testgroup* 4. create nodes /testroot/a and /testroot/a/b and /testroot/a/c 5. allow *testgroup* rep:write on /testroot/a 6. as *testuser* create /testroot/a/b/item (to verify that the user has write access) 7. as *testuser* move /testroot/a/b/item to /testroot/a/c/item 8. save() -> works 9. as *testuser* move /testroot/a/c/item back to /testroot/a/b/item AND add new property to the transient /testroot/a/b/item 10. save() -> access denied", "A_clean_title": ["accessdeni", "access", "deni", "when", "modifi", "transient", "move", "item", "too", "mani", "acesif", "ac", "es", "at", "least", "follow", "precondit", "are", "fulfil", "save", "move", "item", "fail", "access", "deni", "there", "are", "more", "permissionentri", "permiss", "entri", "permissionentrycach", "permiss", "entri", "cach", "than", "configur", "eagercaches", "eager", "cach", "size", "node", "move", "locat", "where", "user", "ha", "write", "access", "through", "group", "membership", "properti", "ad", "transient", "move", "item", "exampl", "set", "eagercaches", "eager", "cach", "size", "creat", "new", "group", "testgroup", "user", "testus", "make", "testus", "member", "testgroup", "creat", "node", "testroot", "testroot", "testroot", "allow", "testgroup", "rep", "write", "testroot", "as", "testus", "creat", "testroot", "item", "verifi", "that", "user", "ha", "write", "access", "as", "testus", "move", "testroot", "item", "testroot", "item", "save", "work", "as", "testus", "move", "testroot", "item", "back", "testroot", "item", "add", "new", "properti", "transient", "testroot", "item", "10", "save", "access", "deni"], "B_title": "AccessDenied when modifying transiently moved item with too many ACEs", "B_clean_title": ["accessdeni", "access", "deni", "when", "modifi", "transient", "move", "item", "too", "mani", "ace", "ac", "es"]},
{"A_title": "XYSeries.addOrUpdate() should add if duplicates are allowedIve found a bug in jfreechart-1.0.9 code for org.jfree.data.xy.XYSeries. There was a change some time ago which introduced the notion of allowing duplicate X values in XYSeries data. The method addOrUpdate(Number x Number y) was never modified to support this and therefore duplicate data were overwriting existing data.", "A_clean_title": ["xyseri", "addorupd", "xy", "seri", "add", "or", "updat", "add", "duplic", "are", "allowed", "allow", "ive", "found", "bug", "jfreechart", "code", "org", "jfree", "data", "xy", "xyseri", "xy", "seri", "there", "wa", "chang", "some", "time", "ago", "which", "introduc", "notion", "allow", "duplic", "valu", "xyseri", "xy", "seri", "data", "method", "addorupd", "add", "or", "updat", "number", "number", "wa", "never", "modifi", "support", "thi", "therefor", "duplic", "data", "were", "overwrit", "exist", "data"], "B_title": "Fix for bug 1955483.", "B_clean_title": ["fix", "bug", "1955483"]},
{"A_title": "URL with a previous page version ignores requested page based on mount pathSee discussion on http://mail-archives.apache.org/mod_mbox/wicket-users/201203.mbox/browser  With 2 mounts /page1 and /page2 to stateful pages and the following sequence: 1-With a new session user visits /page1. Displayed URL is /page1?0 2-Whatever without expiring session 3-User requests URL /page2?0 because it was bookmarked received via email etc. 4-Rendered page is /page1?0 which was stored in the page map. The actual URL displayed is /wicket/bookmarkable/com.mycompany.Page1?0  If a requested page id exists but does not match the page class mounted on the actual requested url Wicket should not use the old page version. This is very counter-intuitive for users having bookmarks to stateful pages or exchanging links.", "A_clean_title": ["url", "previou", "page", "version", "ignor", "request", "page", "base", "mount", "pathse", "path", "see", "discuss", "http", "mail", "archiv", "apach", "user", "201203", "mbox", "browser", "org", "mod", "mbox", "wicket", "mount", "page1", "page2", "state", "page", "follow", "sequenc", "new", "session", "user", "visit", "page1", "display", "url", "page1", "whatev", "without", "expir", "session", "user", "request", "url", "page2", "becaus", "it", "wa", "bookmark", "receiv", "via", "email", "etc", "render", "page", "page1", "which", "wa", "store", "page", "map", "actual", "url", "display", "mycompani", "page1", "wicket", "bookmark", "com", "request", "page", "id", "exist", "but", "not", "match", "page", "class", "mount", "actual", "request", "url", "wicket", "not", "use", "old", "page", "version", "thi", "veri", "counter", "intuit", "user", "have", "bookmark", "state", "page", "or", "exchang", "link"], "B_title": "URL with a previous page version ignores requested page based on mount path", "B_clean_title": ["url", "previou", "page", "version", "ignor", "request", "page", "base", "mount", "path"]},
{"A_title": "testing for symmetric positive definite matrix in CholeskyDecompositionI used this matrix:         double cv =   0.40434286 0.09376327 0.30328980 0.04909388   0.09376327 0.10400408 0.07137959 0.04762857   0.30328980 0.07137959 0.30458776 0.04882449             0.04909388 0.04762857 0.04882449 0.07543265         ;  And it works fine because it is symmetric positive definite  I tried this matrix:          double cv =              0.40434286 -0.09376327 0.30328980 0.04909388             -0.09376327 0.10400408 0.07137959 0.04762857             0.30328980 0.07137959 0.30458776 0.04882449              0.04909388 0.04762857 0.04882449 0.07543265         ; And it should throw an exception but it does not.  I tested the matrix in R and Rs cholesky decomposition method returns that the matrix is not symmetric positive definite. Obviously your code is not catching this appropriately. By the way (in my opinion) the use of exceptions to check these conditions is not the best design or use for exceptions.  If you are going to force the use to try and catch these exceptions at least provide methods  to test the conditions prior to the possibility of the exception.", "A_clean_title": ["test", "symmetr", "posit", "definit", "matrix", "choleskydecompositioni", "choleski", "decomposit", "use", "thi", "matrix", "doubl", "cv", "40434286", "09376327", "30328980", "04909388", "09376327", "10400408", "07137959", "04762857", "30328980", "07137959", "30458776", "04882449", "04909388", "04762857", "04882449", "07543265", "it", "work", "fine", "becaus", "it", "symmetr", "posit", "definit", "tri", "thi", "matrix", "doubl", "cv", "40434286", "09376327", "30328980", "04909388", "09376327", "10400408", "07137959", "04762857", "30328980", "07137959", "30458776", "04882449", "04909388", "04762857", "04882449", "07543265", "it", "throw", "except", "but", "it", "not", "test", "matrix", "rs", "choleski", "decomposit", "method", "return", "that", "matrix", "not", "symmetr", "posit", "definit", "obvious", "your", "code", "not", "catch", "thi", "appropri", "by", "way", "my", "opinion", "use", "except", "check", "these", "condit", "not", "best", "design", "or", "use", "except", "you", "are", "go", "forc", "use", "tri", "catch", "these", "except", "at", "least", "provid", "method", "test", "condit", "prior", "possibl", "except"], "B_title": "fixed detection of not positive definite matrices JIRA: MATH-274", "B_clean_title": ["fix", "detect", "not", "posit", "definit", "matric", "jira", "math", "274"]},
{"A_title": "InstanceConnectionInfo returns wrong hostname when no DNS entry existsIf there is no DNS entry for an address (like 10.4.122.43) then the InstanceConnectionInfo returns the first octet (10) as the hostame.", "A_clean_title": ["instanceconnectioninfo", "instanc", "connect", "info", "return", "wrong", "hostnam", "when", "no", "dn", "entri", "existsif", "exist", "there", "no", "dn", "entri", "address", "like", "10", "122", "43", "then", "instanceconnectioninfo", "instanc", "connect", "info", "return", "first", "octet", "10", "as", "hostam"], "B_title": "taskmanager Fix hostname lookup.", "B_clean_title": ["taskmanag", "fix", "hostnam", "lookup"]},
{"A_title": "EnumChoiceRenderer misbehaves with anonymous enum classesPlease find attached testcase reproducing the problem.  Proper fix is to do return object.getDeclaringClass().getSimpleName() + . + object.name()  instead of return object.getClass().getSimpleName() + . + object.name()  in EnumChoiceRenderer.resourceKey", "A_clean_title": ["enumchoicerender", "enum", "choic", "render", "misbehav", "anonym", "enum", "classespleas", "class", "pleas", "find", "attach", "testcas", "reproduc", "problem", "proper", "fix", "return", "object", "getdeclaringclass", "get", "declar", "class", "getsimplenam", "get", "simpl", "name", "object", "name", "instead", "return", "object", "getclass", "get", "class", "getsimplenam", "get", "simpl", "name", "object", "name", "enumchoicerender", "resourcekey", "enum", "choic", "render", "resourc", "key"], "B_title": "EnumChoiceRenderer fix Issue: WICKET-2609", "B_clean_title": ["enumchoicerender", "enum", "choic", "render", "fix", "issu", "wicket", "2609"]},
{"A_title": "Complex.ZERO.reciprocal() returns NaN but should return INF.Complex.ZERO.reciprocal() returns NaN but should return INF. Class: org.apache.commons.math3.complex.Complex; Method: reciprocal() @version  Id: Complex.java 1416643 2012-12-03 19:37:14Z tn", "A_clean_title": ["complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "complex", "zero", "reciproc", "return", "nan", "na", "but", "return", "inf", "class", "org", "apach", "common", "math3", "complex", "complex", "method", "reciproc", "version", "id", "complex", "java", "1416643", "2012", "12", "03", "19:37:14z", "tn"], "B_title": "Fixed Complex.reciprocal() for zero argument.", "B_clean_title": ["fix", "complex", "reciproc", "zero", "argument"]},
{"A_title": "Mapping ResourceReferences to Urls is slowPackageResourceReference is often used for stylesheets and JavaScript resources many of which can appear on a typical page (WicketAjaxReference is one common example). Every time the page is rendered these resources are mapped to urls in order to build the appropriate <link href=...> or <script src=...> tags.  The trouble is that this mapping process is extremely inefficient. To map a ResourceReference to a url ResourceReference#getLastModified() must be consulted for FilenameWithTimestampResourceCachingStrategy and ResourceReference#getUrlAttributes() is called to append appropriate query parameters.  In PackageResourceReference both of these methods delegate to the very expensive PackageResourceReference#lookupStream() which makes several attempts to locate the underlying file or classpath item using various permutations of locale style and variation. Each of these attempts involves I/O. The default ResourceStreamLocator which does the actual file and classpath queries does no caching whatsoever.  On a trivial Wicket page containing 7 total PackageResourceReferences for images stylesheets and JavaScript files the average response time in my tests was 211 ms. The vast majority of that time was spent in ResourceStreamLocator due to the expensive steps described above.  It seems that putting caching at the ResourceStreamLocator would be extremely beneficial. I am attaching a simple implementation. With caching enabled in ResourceStreamLocator the response time of my test page dropped from 211 ms to 49 ms.", "A_clean_title": ["map", "resourcerefer", "resourc", "refer", "url", "slowpackageresourcerefer", "slow", "packag", "resourc", "refer", "often", "use", "stylesheet", "javascript", "java", "script", "resourc", "mani", "which", "appear", "typic", "page", "wicketajaxrefer", "wicket", "ajax", "refer", "one", "common", "exampl", "everi", "time", "page", "render", "these", "resourc", "are", "map", "url", "order", "build", "appropri", "link", "href=", "or", "script", "src=", "tag", "troubl", "that", "thi", "map", "process", "extrem", "ineffici", "map", "resourcerefer", "resourc", "refer", "url", "resourcerefer", "resourc", "refer", "getlastmodifi", "get", "last", "modifi", "must", "consult", "filenamewithtimestampresourcecachingstrategi", "filenam", "timestamp", "resourc", "cach", "strategi", "resourcerefer", "resourc", "refer", "geturlattribut", "get", "url", "attribut", "call", "append", "appropri", "queri", "paramet", "packageresourcerefer", "packag", "resourc", "refer", "both", "these", "method", "deleg", "veri", "expens", "packageresourcerefer", "packag", "resourc", "refer", "lookupstream", "lookup", "stream", "which", "make", "sever", "attempt", "locat", "underli", "file", "or", "classpath", "item", "variou", "permut", "local", "style", "variat", "each", "these", "attempt", "involv", "default", "resourcestreamloc", "resourc", "stream", "locat", "which", "actual", "file", "classpath", "queri", "no", "cach", "whatsoev", "trivial", "wicket", "page", "contain", "total", "packageresourcerefer", "packag", "resourc", "refer", "imag", "stylesheet", "javascript", "java", "script", "file", "averag", "respons", "time", "my", "test", "wa", "211", "ms", "vast", "major", "that", "time", "wa", "spent", "resourcestreamloc", "resourc", "stream", "locat", "due", "expens", "step", "describ", "abov", "it", "seem", "that", "put", "cach", "at", "resourcestreamloc", "resourc", "stream", "locat", "would", "extrem", "benefici", "am", "attach", "simpl", "implement", "cach", "enabl", "resourcestreamloc", "resourc", "stream", "locat", "respons", "time", "my", "test", "page", "drop", "211", "ms", "49", "ms"], "B_title": "Mapping ResourceReferences to Urls is slow", "B_clean_title": ["map", "resourcerefer", "resourc", "refer", "url", "slow"]},
{"A_title": "NullPointerException in DeltaIteration when no ForwardedFiledsThe following exception is thrown by the Connected Components example if the @ForwardedFieldsFirst(*) annotation from the ComponentIdFilter join is removed:  Caused by: java.lang.NullPointerException at org.apache.flink.examples.java.graph.ConnectedComponents ComponentIdFilter.join(ConnectedComponents.java:186) at org.apache.flink.examples.java.graph.ConnectedComponents ComponentIdFilter.join(ConnectedComponents.java:1) at org.apache.flink.runtime.operators.JoinWithSolutionSetSecondDriver.run(JoinWithSolutionSetSecondDriver.java:198) at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:496) at org.apache.flink.runtime.iterative.task.AbstractIterativePactTask.run(AbstractIterativePactTask.java:139) at org.apache.flink.runtime.iterative.task.IterationIntermediatePactTask.run(IterationIntermediatePactTask.java:92) at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:362) at org.apache.flink.runtime.execution.RuntimeEnvironment.run(RuntimeEnvironment.java:217) at java.lang.Thread.run(Thread.java:745)  Code | https://github.com/vasia/flink/tree/cc-test and dataset | http://snap.stanford.edu/data/com-DBLP.html to reproduce.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "deltaiter", "delta", "iter", "when", "no", "forwardedfiledsth", "forward", "file", "follow", "except", "thrown", "by", "connect", "compon", "exampl", "forwardedfieldsfirst", "forward", "field", "first", "annot", "componentidfilt", "compon", "id", "filter", "join", "remov", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "flink", "exampl", "java", "graph", "connectedcompon", "connect", "compon", "componentidfilt", "join", "compon", "id", "filter", "connectedcompon", "java:186", "connect", "compon", "at", "org", "apach", "flink", "exampl", "java", "graph", "connectedcompon", "connect", "compon", "componentidfilt", "join", "compon", "id", "filter", "connectedcompon", "java:1", "connect", "compon", "at", "org", "apach", "flink", "runtim", "oper", "joinwithsolutionsetseconddriv", "run", "join", "solut", "set", "second", "driver", "joinwithsolutionsetseconddriv", "java:198", "join", "solut", "set", "second", "driver", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "run", "regular", "pact", "task", "regularpacttask", "java:496", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "iter", "task", "abstractiterativepacttask", "run", "abstract", "iter", "pact", "task", "abstractiterativepacttask", "java:139", "abstract", "iter", "pact", "task", "at", "org", "apach", "flink", "runtim", "iter", "task", "iterationintermediatepacttask", "run", "iter", "intermedi", "pact", "task", "iterationintermediatepacttask", "java:92", "iter", "intermedi", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "invok", "regular", "pact", "task", "regularpacttask", "java:362", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "run", "runtim", "environ", "runtimeenviron", "java:217", "runtim", "environ", "at", "java", "lang", "thread", "run", "thread", "java:745", "code", "http", "test", "github", "com", "vasia", "flink", "tree", "cc", "dataset", "http", "stanford", "dblp", "html", "snap", "edu", "data", "com", "reproduc"], "B_title": "Fix NullPointerException in delta iteration due to missing temp", "B_clean_title": ["fix", "nullpointerexcept", "null", "pointer", "except", "delta", "iter", "due", "miss", "temp"]},
{"A_title": "XmlPullParser fails to properly parse from String with encoding declarationWhen parsing from a string XmlPullParser fails if the encoding from the XML declaration is different than the systems file encoding.  Examples:    -Dfile.encoding=ISO-8859-1    parser.parse(<?xml encoding=UTF-8 ?><span id=umlaut-äöü></span>);     -Dfile.encoding=UTF-8    parser.parse(<?xml encoding=ISO-8859-1 ?><span id=umlaut-äöü></span>);  Both fail because the string is read with the systems file encoding while the parser expects the stream to be encoded in the declarated encoding.", "A_clean_title": ["xmlpullpars", "xml", "pull", "parser", "fail", "properli", "pars", "string", "encod", "declarationwhen", "declar", "when", "pars", "string", "xmlpullpars", "xml", "pull", "parser", "fail", "encod", "xml", "declar", "differ", "than", "system", "file", "encod", "exampl", "8859", "dfile", "encoding=iso", "parser", "pars", "xml", "encoding=utf", "span", "id=umlaut", "span", "dfile", "encoding=utf", "parser", "pars", "xml", "encoding=iso", "8859", "span", "id=umlaut", "span", "both", "fail", "becaus", "string", "read", "system", "file", "encod", "while", "parser", "expect", "stream", "encod", "declar", "encod"], "B_title": "dont use possibly conflicting encoding from XML declaration when parsing a String", "B_clean_title": ["dont", "use", "possibl", "conflict", "encod", "xml", "declar", "when", "pars", "string"]},
{"A_title": "Rescheduling the same ajax timer behavior causes memory leak in the browserAbstractAjaxTimerBehavior uses JavaScript setTimeout() function to do its job. It has a #stop() method that clears the timeout but if the timeout is re-scheduled without being cleared a memory leak is observed in the browser.", "A_clean_title": ["reschedul", "same", "ajax", "timer", "behavior", "caus", "memori", "leak", "browserabstractajaxtimerbehavior", "browser", "abstract", "ajax", "timer", "behavior", "use", "javascript", "java", "script", "settimeout", "set", "timeout", "function", "it", "job", "it", "ha", "stop", "method", "that", "clear", "timeout", "but", "timeout", "re", "schedul", "without", "be", "clear", "memori", "leak", "observ", "browser"], "B_title": "Rescheduling the same ajax timer behavior causes memory leak in the browser", "B_clean_title": ["reschedul", "same", "ajax", "timer", "behavior", "caus", "memori", "leak", "browser"]},
{"A_title": "Exception thrown in ode for a pair of close eventsWhen two discrete events occur closer to each other than the convergence threshold used for locating them this sometimes triggers a NumberIsTooLargeException.  The exception happens because the EventState class think the second event is simply a numerical artifact (a repetition of the already triggerred first event) and tries to skip past it. If there are no other event in the same step later on one interval boundary finally reach step end and the interval bounds are reversed.", "A_clean_title": ["except", "thrown", "ode", "pair", "close", "eventswhen", "event", "when", "two", "discret", "event", "occur", "closer", "each", "other", "than", "converg", "threshold", "use", "locat", "them", "thi", "sometim", "trigger", "numberistoolargeexcept", "number", "too", "larg", "except", "except", "happen", "becaus", "eventst", "event", "state", "class", "think", "second", "event", "simpli", "numer", "artifact", "repetit", "alreadi", "trigger", "first", "event", "tri", "skip", "past", "it", "there", "are", "no", "other", "event", "same", "step", "later", "one", "interv", "boundari", "final", "reach", "step", "end", "interv", "bound", "are", "revers"], "B_title": "Fixed wrong event detection in case of close events pairs.", "B_clean_title": ["fix", "wrong", "event", "detect", "case", "close", "event", "pair"]},
{"A_title": "constant functions not inlined aggressively enoughNone", "A_clean_title": ["constant", "function", "not", "inlin", "aggress", "enoughnon", "enough", "none"], "B_title": "Lower the cost of true/false/null. Fixes issue 728", "B_clean_title": ["lower", "cost", "true", "fals", "null", "fix", "issu", "728"]},
{"A_title": "Upgraded version history has UUIDs as jcr:frozenUuid of non-referenceable nodesIn Jackrabbit Classic each node even non-referenceable ones has a UUID as its identifier and thus the jcr:frozenUuid properties of frozen nodes are always UUIDs. In contrast Oak uses path identifiers for non-referenceable frozen nodes (see OAK-1009) which presents a problem when dealing with version histories migrated from Jackrabbit Classic.  To avoid this mismatch the upgrade code should check each frozen node for referenceability and replace the frozen UUID with a path identifier if needed.", "A_clean_title": ["upgrad", "version", "histori", "ha", "uuid", "uui", "ds", "as", "jcr", "frozenuuid", "frozen", "uuid", "non", "referenc", "nodesin", "node", "jackrabbit", "classic", "each", "node", "even", "non", "referenc", "one", "ha", "uuid", "as", "it", "identifi", "thu", "jcr", "frozenuuid", "frozen", "uuid", "properti", "frozen", "node", "are", "alway", "uuid", "uui", "ds", "contrast", "oak", "use", "path", "identifi", "non", "referenc", "frozen", "node", "see", "oak", "1009", "which", "present", "problem", "when", "deal", "version", "histori", "migrat", "jackrabbit", "classic", "avoid", "thi", "mismatch", "upgrad", "code", "check", "each", "frozen", "node", "referenc", "replac", "frozen", "uuid", "path", "identifi", "need"], "B_title": "Upgraded version history has UUIDs as jcr:frozenUuid of non-referenceable nodes", "B_clean_title": ["upgrad", "version", "histori", "ha", "uuid", "uui", "ds", "as", "jcr", "frozenuuid", "frozen", "uuid", "non", "referenc", "node"]},
{"A_title": "Wrong compareTo in micro-kernel Id classCompareTo method in Id class fails in some cases.  code  // this works final Id id1 = Id.fromString( 0000000000000007 ); final Id id2 = Id.fromString( 000000000000000c );  assertTrue( id1 +  should be less than  + id2 id1.compareTo( id2 ) < 0 );  // but this doesnt final Id id1 = Id.fromString( 0000000000000070 ); final Id id2 = Id.fromString( 00000000000000c0 );  assertTrue( id1 +  should be less than  + id2 id1.compareTo( id2 ) < 0 ); code", "A_clean_title": ["wrong", "compareto", "compar", "micro", "kernel", "id", "classcompareto", "class", "compar", "method", "id", "class", "fail", "some", "case", "code", "thi", "work", "final", "id", "id1", "id", "fromstr", "string", "0000000000000007", "final", "id", "id2", "id", "fromstr", "string", "000000000000000c", "asserttru", "assert", "true", "id1", "less", "than", "id2", "id1", "compareto", "compar", "id2", "but", "thi", "doesnt", "final", "id", "id1", "id", "fromstr", "string", "0000000000000070", "final", "id", "id2", "id", "fromstr", "string", "00000000000000c0", "asserttru", "assert", "true", "id1", "less", "than", "id2", "id1", "compareto", "compar", "id2", "code"], "B_title": "Wrong compareTo in micro-kernel Id class", "B_clean_title": ["wrong", "compareto", "compar", "micro", "kernel", "id", "class"]},
{"A_title": "UserValidator and AccessControlValidator must not process hidden nodesThis is similar to OAK-3019 but for UserValidator and AccessControlValidator.", "A_clean_title": ["uservalid", "user", "valid", "accesscontrolvalid", "access", "control", "valid", "must", "not", "process", "hidden", "nodesthi", "node", "thi", "similar", "oak", "3019", "but", "uservalid", "user", "valid", "accesscontrolvalid", "access", "control", "valid"], "B_title": "UserValidator and AccessControlValidator must not process hidden nodes", "B_clean_title": ["uservalid", "user", "valid", "accesscontrolvalid", "access", "control", "valid", "must", "not", "process", "hidden", "node"]},
{"A_title": "Bug in require calls processingNone", "A_clean_title": ["bug", "requir", "call", "processingnon", "process", "none"], "B_title": "This change had to be rolled-back since it breaks some users of the Java API. See the updated comment and new test case for reasoning.", "B_clean_title": ["thi", "chang", "had", "roll", "back", "sinc", "it", "break", "some", "user", "java", "api", "see", "updat", "comment", "new", "test", "case", "reason"]},
{"A_title": "Mockito.after() method accepts negative timeperiods and subsequent verifications always passNone", "A_clean_title": ["mockito", "after", "method", "accept", "neg", "timeperiod", "subsequ", "verif", "alway", "passnon", "pass", "none"], "B_title": "Fixes #197 : Blocks ability to use negative value for timeout() and after() method.", "B_clean_title": ["fix", "197", "block", "abil", "use", "neg", "valu", "timeout", "after", "method"]},
{"A_title": "Error while parsing job arguments passed by CLIFlink CLI treats job arguments provided in format -<char> as its own parameters which results in errors in execution.  Example 1: call: >bin/flink info myJarFile.jar -f flink -i <filepath> -m 1 error: Unrecognized option: -f  Example 2: Job myJarFile.jar is uploaded to web submission client flink parameter box is empty program arguments box: -f flink -i <filepath> -m 1 error:  An unexpected error occurred: Unrecognized option: -f org.apache.flink.client.cli.CliArgsException: Unrecognized option: -f at org.apache.flink.client.cli.CliFrontendParser.parseInfoCommand(CliFrontendParser.java:296) at org.apache.flink.client.CliFrontend.info(CliFrontend.java:376) at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:983) at org.apache.flink.client.web.JobSubmissionServlet.doGet(JobSubmissionServlet.java:171) at javax.servlet.http.HttpServlet.service(HttpServlet.java:734) at javax.servlet.http.HttpServlet.service(HttpServlet.java:847) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:532) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:453) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:227) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:965) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:388) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:187) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:901) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:117) at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:47) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:113) at org.eclipse.jetty.server.Server.handle(Server.java:348) at org.eclipse.jetty.server.HttpConnection.handleRequest(HttpConnection.java:596) at org.eclipse.jetty.server.HttpConnection RequestHandler.headerComplete(HttpConnection.java:1048) at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:549) at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:211) at org.eclipse.jetty.server.HttpConnection.handle(HttpConnection.java:425) at org.eclipse.jetty.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:489) at org.eclipse.jetty.util.thread.QueuedThreadPool 2.run(QueuedThreadPool.java:436) at java.lang.Thread.run(Thread.java:745)  Execution of  >bin/flink run myJarFile.jar -f flink -i <filepath> -m 1   works perfectly fine", "A_clean_title": ["error", "while", "pars", "job", "argument", "pass", "by", "cliflink", "cli", "flink", "cli", "treat", "job", "argument", "provid", "format", "char", "as", "it", "own", "paramet", "which", "result", "error", "execut", "exampl", "call", "bin", "flink", "info", "myjarfil", "jar", "my", "jar", "file", "flink", "filepath", "error", "unrecogn", "option", "exampl", "job", "myjarfil", "jar", "my", "jar", "file", "upload", "web", "submiss", "client", "flink", "paramet", "box", "empti", "program", "argument", "box", "flink", "filepath", "error", "unexpect", "error", "occur", "unrecogn", "option", "org", "apach", "flink", "client", "cli", "cliargsexcept", "cli", "arg", "except", "unrecogn", "option", "at", "org", "apach", "flink", "client", "cli", "clifrontendpars", "parseinfocommand", "cli", "frontend", "parser", "pars", "info", "command", "clifrontendpars", "java:296", "cli", "frontend", "parser", "at", "org", "apach", "flink", "client", "clifrontend", "info", "cli", "frontend", "clifrontend", "java:376", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "parseparamet", "cli", "frontend", "pars", "paramet", "clifrontend", "java:983", "cli", "frontend", "at", "org", "apach", "flink", "client", "web", "jobsubmissionservlet", "doget", "job", "submiss", "servlet", "get", "jobsubmissionservlet", "java:171", "job", "submiss", "servlet", "at", "javax", "servlet", "http", "httpservlet", "servic", "http", "servlet", "httpservlet", "java:734", "http", "servlet", "at", "javax", "servlet", "http", "httpservlet", "servic", "http", "servlet", "httpservlet", "java:847", "http", "servlet", "at", "org", "eclips", "jetti", "servlet", "servlethold", "handl", "servlet", "holder", "servlethold", "java:532", "servlet", "holder", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "dohandl", "servlet", "handler", "handl", "servlethandl", "java:453", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "dohandl", "session", "handler", "handl", "sessionhandl", "java:227", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "dohandl", "context", "handler", "handl", "contexthandl", "java:965", "context", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "doscop", "servlet", "handler", "scope", "servlethandl", "java:388", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "doscop", "session", "handler", "scope", "sessionhandl", "java:187", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "doscop", "context", "handler", "scope", "contexthandl", "java:901", "context", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:117", "scope", "handler", "at", "org", "eclips", "jetti", "server", "handler", "handlerlist", "handl", "handler", "list", "handlerlist", "java:47", "handler", "list", "at", "org", "eclips", "jetti", "server", "handler", "handlerwrapp", "handl", "handler", "wrapper", "handlerwrapp", "java:113", "handler", "wrapper", "at", "org", "eclips", "jetti", "server", "server", "handl", "server", "java:348", "at", "org", "eclips", "jetti", "server", "httpconnect", "handlerequest", "http", "connect", "handl", "request", "httpconnect", "java:596", "http", "connect", "at", "org", "eclips", "jetti", "server", "httpconnect", "http", "connect", "requesthandl", "headercomplet", "request", "handler", "header", "complet", "httpconnect", "java:1048", "http", "connect", "at", "org", "eclips", "jetti", "http", "httpparser", "parsenext", "http", "parser", "pars", "next", "httpparser", "java:549", "http", "parser", "at", "org", "eclips", "jetti", "http", "httpparser", "parseavail", "http", "parser", "pars", "avail", "httpparser", "java:211", "http", "parser", "at", "org", "eclips", "jetti", "server", "httpconnect", "handl", "http", "connect", "httpconnect", "java:425", "http", "connect", "at", "org", "eclips", "jetti", "io", "nio", "selectchannelendpoint", "run", "select", "channel", "end", "point", "selectchannelendpoint", "java:489", "select", "channel", "end", "point", "at", "org", "eclips", "jetti", "util", "thread", "queuedthreadpool", "queu", "thread", "pool", "run", "queuedthreadpool", "java:436", "queu", "thread", "pool", "at", "java", "lang", "thread", "run", "thread", "java:745", "execut", "bin", "flink", "run", "myjarfil", "jar", "my", "jar", "file", "flink", "filepath", "work", "perfectli", "fine"], "B_title": "Fix argument parsing of CLI client INFO action", "B_clean_title": ["fix", "argument", "pars", "cli", "client", "info", "action"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Automated g4 rollback of changelist 53511956.", "B_clean_title": ["autom", "g4", "rollback", "changelist", "53511956"]},
{"A_title": "Statistics.setVarianceImpl makes getStandardDeviation produce NaNInvoking SummaryStatistics.setVarianceImpl(new Variance(true/false) makes getStandardDeviation produce NaN. The code to reproduce it:  int scores = 1 2 3 4; SummaryStatistics stats = new SummaryStatistics(); stats.setVarianceImpl(new Variance(false)); //use population variance for(int i : scores)    stats.addValue(i);  double sd = stats.getStandardDeviation(); System.out.println(sd);   A workaround suggested by Mikkel is:    double sd = FastMath.sqrt(stats.getSecondMoment() / stats.getN());", "A_clean_title": ["statist", "setvarianceimpl", "set", "varianc", "impl", "make", "getstandarddevi", "get", "standard", "deviat", "produc", "naninvok", "na", "invok", "summarystatist", "setvarianceimpl", "summari", "statist", "set", "varianc", "impl", "new", "varianc", "true", "fals", "make", "getstandarddevi", "get", "standard", "deviat", "produc", "nan", "na", "code", "reproduc", "it", "int", "score", "summarystatist", "summari", "statist", "stat", "new", "summarystatist", "summari", "statist", "stat", "setvarianceimpl", "set", "varianc", "impl", "new", "varianc", "fals", "use", "popul", "varianc", "int", "score", "stat", "addvalu", "add", "valu", "doubl", "sd", "stat", "getstandarddevi", "get", "standard", "deviat", "system", "out", "println", "sd", "workaround", "suggest", "by", "mikkel", "doubl", "sd", "fastmath", "sqrt", "fast", "math", "stat", "getsecondmo", "get", "second", "moment", "stat", "getn", "get"], "B_title": "Fixed errors in SummaryStatistics causing overriden statistics not to be updated if the supplied impls are commons-math classes.  JIRA: MATH-691.", "B_clean_title": ["fix", "error", "summarystatist", "summari", "statist", "caus", "overriden", "statist", "not", "updat", "suppli", "impl", "are", "common", "math", "class", "jira", "math", "691"]},
{"A_title": "NumberUtils does not handle Long Hex numbersNumberUtils.createLong() does not handle hex numbers but createInteger() handles hex and octal. This seems odd. NumberUtils.createNumber() assumes that hex numbers can only be Integer. Again why not handle bigger Hex numbers? == It is trivial to fix createLong() - just use Long.decode() instead of valueOf(). Its not clear why this was not done originally - the decode() method was added to both Integer and Long in Java 1.2. Fixing createNumber() is also fairly easy - if the hex string has more than 8 digits use Long. Should we allow for leading zeros in an Integer?  If not the length check is trivial.", "A_clean_title": ["numberutil", "number", "util", "not", "handl", "long", "hex", "numbersnumberutil", "createlong", "number", "number", "util", "creat", "long", "not", "handl", "hex", "number", "but", "createinteg", "creat", "integ", "handl", "hex", "octal", "thi", "seem", "odd", "numberutil", "createnumb", "number", "util", "creat", "number", "assum", "that", "hex", "number", "onli", "integ", "again", "whi", "not", "handl", "bigger", "hex", "number", "it", "trivial", "fix", "createlong", "creat", "long", "just", "use", "long", "decod", "instead", "valueof", "valu", "it", "not", "clear", "whi", "thi", "wa", "not", "done", "origin", "decod", "method", "wa", "ad", "both", "integ", "long", "java", "fix", "createnumb", "creat", "number", "also", "fairli", "easi", "hex", "string", "ha", "more", "than", "digit", "use", "long", "we", "allow", "lead", "zero", "integ", "not", "length", "check", "trivial"], "B_title": "NumberUtils does not handle Long Hex numbers", "B_clean_title": ["numberutil", "number", "util", "not", "handl", "long", "hex", "number"]},
{"A_title": "StrBuilder contains usages of thisBuf.length when they should use sizeWhile fixing LANG-294 I noticed that there are two other places in StrBuilder that reference thisBuf.length and unless Im mistaken they shouldnt.", "A_clean_title": ["strbuilder", "str", "builder", "contain", "usag", "thisbuf", "length", "thi", "buf", "when", "they", "use", "sizewhil", "size", "while", "fix", "lang", "294", "notic", "that", "there", "are", "two", "other", "place", "strbuilder", "str", "builder", "that", "refer", "thisbuf", "length", "thi", "buf", "unless", "im", "mistaken", "they", "shouldnt"], "B_title": "Fixng LANG-295 - thisBuf.length calls. There were two of the calls so Ive committed a unit test showing things are broken and a fix in both cases.", "B_clean_title": ["fixng", "lang", "295", "thisbuf", "length", "thi", "buf", "call", "there", "were", "two", "call", "so", "ive", "commit", "unit", "test", "show", "thing", "are", "broken", "fix", "both", "case"]},
{"A_title": "GammaDistribution cloning brokenSerializing a GammaDistribution and deserializing it does not result in a cloned distribution that produces the same samples. Cause: GammaDistribution inherits from AbstractRealDistribution which implements Serializable. AbstractRealDistribution has random in which we have a Well19937c instance which inherits from AbstractWell. AbstractWell implements Serializable. AbstractWell inherits from BitsStreamGenerator which is not Serializable but does have a private field nextGaussian. Solution: Make BitStreamGenerator implement Serializable as well. This probably affects other distributions as well.", "A_clean_title": ["gammadistribut", "gamma", "distribut", "clone", "brokenseri", "broken", "serial", "gammadistribut", "gamma", "distribut", "deseri", "it", "not", "result", "clone", "distribut", "that", "produc", "same", "sampl", "caus", "gammadistribut", "gamma", "distribut", "inherit", "abstractrealdistribut", "abstract", "real", "distribut", "which", "implement", "serializ", "abstractrealdistribut", "abstract", "real", "distribut", "ha", "random", "which", "we", "have", "well19937c", "instanc", "which", "inherit", "abstractwel", "abstract", "well", "abstractwel", "abstract", "well", "implement", "serializ", "abstractwel", "abstract", "well", "inherit", "bitsstreamgener", "bit", "stream", "gener", "which", "not", "serializ", "but", "have", "privat", "field", "nextgaussian", "next", "gaussian", "solut", "make", "bitstreamgener", "bit", "stream", "gener", "implement", "serializ", "as", "well", "thi", "probabl", "affect", "other", "distribut", "as", "well"], "B_title": "Made BitsStreamGenerator class Serializable to allow cloning of subclasses. Added cloning test for all RealDistribution classes. Thanks to Dennis Hendriks.", "B_clean_title": ["made", "bitsstreamgener", "bit", "stream", "gener", "class", "serializ", "allow", "clone", "subclass", "ad", "clone", "test", "all", "realdistribut", "real", "distribut", "class", "thank", "denni", "hendrik"]},
{"A_title": "CryptoMapper does not work for applications having a home page that needs query parametersCryptoMapper.decryptUrl() should not return null for requests like http://myhost/MyApplication/app/?param=xx   As a possible fix one can replace  if (encryptedUrl.getSegments().isEmpty() && encryptedUrl.getQueryParameters().isEmpty())             return encryptedUrl;   with   if (encryptedUrl.getSegments().isEmpty())             return encryptedUrl;   but I suspect that the original test is intended to answer to another use case...", "A_clean_title": ["cryptomapp", "crypto", "mapper", "not", "work", "applic", "have", "home", "page", "that", "need", "queri", "parameterscryptomapp", "decrypturl", "paramet", "crypto", "mapper", "decrypt", "url", "not", "return", "null", "request", "like", "http", "myhost", "myapplic", "app", "my", "applic", "param=xx", "as", "possibl", "fix", "one", "replac", "encryptedurl", "getseg", "encrypt", "url", "get", "segment", "isempti", "empti", "encryptedurl", "getqueryparamet", "encrypt", "url", "get", "queri", "paramet", "isempti", "empti", "return", "encryptedurl", "encrypt", "url", "encryptedurl", "getseg", "encrypt", "url", "get", "segment", "isempti", "empti", "return", "encryptedurl", "encrypt", "url", "but", "suspect", "that", "origin", "test", "intend", "answer", "anoth", "use", "case"], "B_title": "CryptoMapper does not work for applications having a home page that needs query parameters", "B_clean_title": ["cryptomapp", "crypto", "mapper", "not", "work", "applic", "have", "home", "page", "that", "need", "queri", "paramet"]},
{"A_title": "PropertyIndex only considers the cost of a single indexed propertyThe existing PropertyIndex loops through the PropertyRestriction objects in the Filter and essentially only calculates the cost of the first indexed property. This isnt actually the first property in the query and Filter.propertyRestrictions is a HashMap.  More confusingly the plan for a query with multiple indexed properties outputs *all* indexed properties even though only the first one is used.  For queries with multiple indexed properties the cheapest property index should be used in all three relevant places: when calculating the cost when executing the query and when producing the plan.", "A_clean_title": ["propertyindex", "properti", "index", "onli", "consid", "cost", "singl", "index", "propertyth", "properti", "exist", "propertyindex", "properti", "index", "loop", "through", "propertyrestrict", "properti", "restrict", "object", "filter", "essenti", "onli", "calcul", "cost", "first", "index", "properti", "thi", "isnt", "actual", "first", "properti", "queri", "filter", "propertyrestrict", "properti", "restrict", "hashmap", "hash", "map", "more", "confusingli", "plan", "queri", "multipl", "index", "properti", "output", "all", "index", "properti", "even", "though", "onli", "first", "one", "use", "queri", "multipl", "index", "properti", "cheapest", "properti", "index", "use", "all", "three", "relev", "place", "when", "calcul", "cost", "when", "execut", "queri", "when", "produc", "plan"], "B_title": "PropertyIndex only considers the cost of a single indexed property", "B_clean_title": ["propertyindex", "properti", "index", "onli", "consid", "cost", "singl", "index", "properti"]},
{"A_title": "XPath failures for typed propertiesIt looks like there are some failures in xpath queries that expect a match only on properties of a certain type (which is to be inferred from the query)", "A_clean_title": ["xpath", "path", "failur", "type", "propertiesit", "properti", "it", "look", "like", "there", "are", "some", "failur", "xpath", "queri", "that", "expect", "match", "onli", "properti", "certain", "type", "which", "infer", "queri"], "B_title": "XPath failures for typed properties", "B_clean_title": ["xpath", "path", "failur", "type", "properti"]},
{"A_title": "PageParameters construced with keyValuePairs does not handle array valuesThe PageParameters constructor that takes a keyValuePairs argument does not convert repeated keys into an array of values.  For example:  code // specify three comma delimited values for the a parameters PageParameters parameters = new PageParameters(a=1a=2a=3); String a = parameters.getStringArray(a); assertEquals(3 a.length); // fails because a.length == 1 code  Issue first described on the users list: http://www.nabble.com/PageParameters-with-String-array-question-to22540294.html", "A_clean_title": ["pageparamet", "page", "paramet", "construc", "keyvaluepair", "key", "valu", "pair", "not", "handl", "array", "valuesth", "valu", "pageparamet", "page", "paramet", "constructor", "that", "take", "keyvaluepair", "key", "valu", "pair", "argument", "not", "convert", "repeat", "key", "into", "array", "valu", "exampl", "code", "specifi", "three", "comma", "delimit", "valu", "paramet", "pageparamet", "page", "paramet", "paramet", "new", "pageparamet", "page", "paramet", "a=1a=2a=3", "string", "paramet", "getstringarray", "get", "string", "array", "assertequ", "assert", "equal", "length", "fail", "becaus", "length", "code", "issu", "first", "describ", "user", "list", "http", "string", "array", "question", "nabbl", "to22540294", "html", "www", "com", "pageparamet", "page", "paramet"], "B_title": "fixed WICKET-2172 PageParameters construced with keyValuePairs does not handle array values Issue: WICKET-2172", "B_clean_title": ["fix", "wicket", "2172", "pageparamet", "page", "paramet", "construc", "keyvaluepair", "key", "valu", "pair", "not", "handl", "array", "valu", "issu", "wicket", "2172"]},
{"A_title": "Only assignment to this issues a dangerous use of the global this object warning.None", "A_clean_title": ["onli", "assign", "thi", "issu", "danger", "use", "global", "thi", "object", "warn", "none"], "B_title": "Change on 2010/05/27 by johnlenz", "B_clean_title": ["chang", "2010", "05", "27", "by", "johnlenz"]},
{"A_title": "Full-text search on the traversing index fails if the condition contains a slashA full-text search on the traversing index falls back to a sort of manual evaluation of results.  This is handled by the _FullTextTerm_ class and it appears that it passes the constraint text through a cleanup process where it strips most of the characters that are neither _Character.isLetterOrDigit(c)_ not in the list _+-:&_  Im not exactly sure where this list comes from but I see the / character is missing which causes a certain type of query to fail.  Example: code //*jcr:contains(. text/plain) code", "A_clean_title": ["full", "text", "search", "travers", "index", "fail", "condit", "contain", "slasha", "slash", "full", "text", "search", "travers", "index", "fall", "back", "sort", "manual", "evalu", "result", "thi", "handl", "by", "fulltextterm", "full", "text", "term", "class", "it", "appear", "that", "it", "pass", "constraint", "text", "through", "cleanup", "process", "where", "it", "strip", "most", "charact", "that", "are", "neither", "isletterordigit", "charact", "letter", "or", "digit", "not", "list", "im", "not", "exactli", "sure", "where", "thi", "list", "come", "but", "see", "charact", "miss", "which", "caus", "certain", "type", "queri", "fail", "exampl", "code", "jcr", "contain", "text", "plain", "code"], "B_title": "Full-text search on the traversing index fails if the condition contains a slash", "B_clean_title": ["full", "text", "search", "travers", "index", "fail", "condit", "contain", "slash"]},
{"A_title": "Correlated random vector generator fails (silently) when faced with zero rows in covariance matrixThe following three matrices (which are basically permutations of each other) produce different results when sampling a multi-variate Gaussian with the help of CorrelatedRandomVectorGenerator (sample covariances calculated in R based on 10000 samples): Array2DRowRealMatrix  0.00.00.00.00.0  0.00.0134455320.010394690.0098811560.010499559  0.00.010394690.0230066160.0081968560.010732709  0.00.0098811560.0081968560.0190238660.009210099  0.00.0104995590.0107327090.0092100990.019107243 > cov(data1)    V1 V2 V3 V4 V5 V1 0 0.000000000 0.00000000 0.000000000 0.000000000 V2 0 0.013383931 0.01034401 0.009913271 0.010506733 V3 0 0.010344006 0.02309479 0.008374730 0.010759306 V4 0 0.009913271 0.00837473 0.019005488 0.009187287 V5 0 0.010506733 0.01075931 0.009187287 0.019021483 Array2DRowRealMatrix  0.0134455320.010394690.00.0098811560.010499559  0.010394690.0230066160.00.0081968560.010732709  0.00.00.00.00.0 0.0098811560.0081968560.00.0190238660.009210099 0.0104995590.0107327090.00.0092100990.019107243  > cov(data2)             V1 V2 V3 V4 V5 V1 0.006922905 0.010507692 0 0.005817399 0.010330529 V2 0.010507692 0.023428918 0 0.008273152 0.010735568 V3 0.000000000 0.000000000 0 0.000000000 0.000000000 V4 0.005817399 0.008273152 0 0.004929843 0.009048759 V5 0.010330529 0.010735568 0 0.009048759 0.018683544   Array2DRowRealMatrix 0.0134455320.010394690.0098811560.010499559 0.010394690.0230066160.0081968560.010732709 0.0098811560.0081968560.0190238660.009210099 0.0104995590.0107327090.0092100990.019107243  > cov(data3)             V1          V2          V3          V4 V1 0.013445047 0.010478862 0.009955904 0.010529542 V2 0.010478862 0.022910522 0.008610113 0.011046353 V3 0.009955904 0.008610113 0.019250975 0.009464442 V4 0.010529542 0.011046353 0.009464442 0.019260317   Ive traced this back to the RectangularCholeskyDecomposition which does not seem to handle the second matrix very well (decompositions in the same order as the matrices above):  CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.00.00.00.00.0  0.07595774181220630.08761251884742390.00.00.0  0.077644436225135050.051328212214607520.119763818217912350.00.0  0.066629305279094040.055016617441145850.00166625065193079970.107493242076536320.0 0.138228951381394770.00.00.00.0 CorrelatedRandomVectorGenerator.getRank() = 5 CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.07595774181220630.0345127513794487240.0 0.077644436225135050.130299491646287460.0  0.00.00.0  0.066629305279094040.0232039366948556740.0 0.138228951381394770.00.0 CorrelatedRandomVectorGenerator.getRank() = 3 CorrelatedRandomVectorGenerator.getRootMatrix() =  Array2DRowRealMatrix0.07595774181220630.0345127513794487240.0339137482263482250.07303890149947785 0.077644436225135050.130299491646287460.00.0  0.066629305279094040.0232039366948556740.118515733132299450.0 0.138228951381394770.00.00.0 CorrelatedRandomVectorGenerator.getRank() = 4 Clearly the rank of each of these matrices should be 4. The first matrix does not lead to incorrect results but the second one does. Unfortunately I dont know enough about the Cholesky decomposition to find the flaw in the implementation and I could not find documentation for the rectangular variant (also not at the links provided in the javadoc).", "A_clean_title": ["correl", "random", "vector", "gener", "fail", "silent", "when", "face", "zero", "row", "covari", "matrixth", "matrix", "follow", "three", "matric", "which", "are", "basic", "permut", "each", "other", "produc", "differ", "result", "when", "sampl", "multi", "variat", "gaussian", "help", "correlatedrandomvectorgener", "correl", "random", "vector", "gener", "sampl", "covari", "calcul", "base", "10000", "sampl", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "00", "00", "00", "00", "00", "0134455320", "010394690", "0098811560", "010499559", "00", "010394690", "0230066160", "0081968560", "010732709", "00", "0098811560", "0081968560", "0190238660", "009210099", "00", "0104995590", "0107327090", "0092100990", "019107243", "cov", "data1", "v1", "v2", "v3", "v4", "v5", "v1", "000000000", "00000000", "000000000", "000000000", "v2", "013383931", "01034401", "009913271", "010506733", "v3", "010344006", "02309479", "008374730", "010759306", "v4", "009913271", "00837473", "019005488", "009187287", "v5", "010506733", "01075931", "009187287", "019021483", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "0134455320", "010394690", "00", "0098811560", "010499559", "010394690", "0230066160", "00", "0081968560", "010732709", "00", "00", "00", "00", "0098811560", "0081968560", "00", "0190238660", "009210099", "0104995590", "0107327090", "00", "0092100990", "019107243", "cov", "data2", "v1", "v2", "v3", "v4", "v5", "v1", "006922905", "010507692", "005817399", "010330529", "v2", "010507692", "023428918", "008273152", "010735568", "v3", "000000000", "000000000", "000000000", "000000000", "v4", "005817399", "008273152", "004929843", "009048759", "v5", "010330529", "010735568", "009048759", "018683544", "array2drowrealmatrix", "array2d", "row", "real", "matrix", "0134455320", "010394690", "0098811560", "010499559", "010394690", "0230066160", "0081968560", "010732709", "0098811560", "0081968560", "0190238660", "009210099", "0104995590", "0107327090", "0092100990", "019107243", "cov", "data3", "v1", "v2", "v3", "v4", "v1", "013445047", "010478862", "009955904", "010529542", "v2", "010478862", "022910522", "008610113", "011046353", "v3", "009955904", "008610113", "019250975", "009464442", "v4", "010529542", "011046353", "009464442", "019260317", "ive", "trace", "thi", "back", "rectangularcholeskydecomposit", "rectangular", "choleski", "decomposit", "which", "not", "seem", "handl", "second", "matrix", "veri", "well", "decomposit", "same", "order", "as", "matric", "abov", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "00", "00", "00", "00", "array2d", "row", "real", "matrix0", "07595774181220630", "08761251884742390", "00", "00", "077644436225135050", "051328212214607520", "119763818217912350", "00", "066629305279094040", "055016617441145850", "00166625065193079970", "107493242076536320", "138228951381394770", "00", "00", "00", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "07595774181220630", "0345127513794487240", "array2d", "row", "real", "matrix0", "077644436225135050", "130299491646287460", "00", "00", "066629305279094040", "0232039366948556740", "138228951381394770", "00", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "correlatedrandomvectorgener", "getrootmatrix", "correl", "random", "vector", "gener", "get", "root", "matrix", "array2drowrealmatrix0", "07595774181220630", "0345127513794487240", "0339137482263482250", "07303890149947785", "array2d", "row", "real", "matrix0", "077644436225135050", "130299491646287460", "00", "066629305279094040", "0232039366948556740", "118515733132299450", "138228951381394770", "00", "00", "correlatedrandomvectorgener", "getrank", "correl", "random", "vector", "gener", "get", "rank", "clearli", "rank", "each", "these", "matric", "first", "matrix", "not", "lead", "incorrect", "result", "but", "second", "one", "unfortun", "dont", "know", "enough", "about", "choleski", "decomposit", "find", "flaw", "implement", "could", "not", "find", "document", "rectangular", "variant", "also", "not", "at", "link", "provid", "javadoc"], "B_title": "Fixed an error in rectangular Cholesky decomposition.", "B_clean_title": ["fix", "error", "rectangular", "choleski", "decomposit"]},
{"A_title": "POJO Type extractor bug with type variablesThe following program incorrectly states that there are duplicate getters/setters.  code public static class Vertex<K V>   private K key1; private K key2; private V value;  public Vertex()   public Vertex(K key V value)  this.key1 = key; this.key2 = key; this.value = value;   public Vertex(K key1 K key2 V value)  this.key1 = key1; this.key2 = key2; this.value = value;   public void setKey1(K key1)  this.key1 = key1;   public void setKey2(K key2)  this.key2 = key2;   public K getKey1()  return key1;   public K getKey2()  return key2;   public void setValue(V value)  this.value = value;   public V getValue()  return value;    public static void main(String args) throws Exception  ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();  DataSet<Vertex<Long Double>> set = env.fromElements(new Vertex<Long Double>(0L 3.0) new Vertex<Long Double>(1L 1.0));  set.print();  env.execute();  code  The exception is code Exception in thread main java.lang.IllegalStateException: Detected more than one getters at org.apache.flink.api.java.typeutils.TypeExtractor.isValidPojoField(TypeExtractor.java:981) at org.apache.flink.api.java.typeutils.TypeExtractor.analyzePojo(TypeExtractor.java:1025) at org.apache.flink.api.java.typeutils.TypeExtractor.privateGetForClass(TypeExtractor.java:937) at org.apache.flink.api.java.typeutils.TypeExtractor.privateGetForClass(TypeExtractor.java:863) at org.apache.flink.api.java.typeutils.TypeExtractor.privateGetForObject(TypeExtractor.java:1146) at org.apache.flink.api.java.typeutils.TypeExtractor.getForObject(TypeExtractor.java:1116) at org.apache.flink.api.java.ExecutionEnvironment.fromElements(ExecutionEnvironment.java:466) at test.Test.main(Test.java:74)  code", "A_clean_title": ["pojo", "type", "extractor", "bug", "type", "variablesth", "variabl", "follow", "program", "incorrectli", "state", "that", "there", "are", "duplic", "getter", "setter", "code", "public", "static", "class", "vertex", "privat", "key1", "privat", "key2", "privat", "valu", "public", "vertex", "public", "vertex", "key", "valu", "thi", "key1", "key", "thi", "key2", "key", "thi", "valu", "valu", "public", "vertex", "key1", "key2", "valu", "thi", "key1", "key1", "thi", "key2", "key2", "thi", "valu", "valu", "public", "void", "setkey1", "set", "key1", "key1", "thi", "key1", "key1", "public", "void", "setkey2", "set", "key2", "key2", "thi", "key2", "key2", "public", "getkey1", "get", "key1", "return", "key1", "public", "getkey2", "get", "key2", "return", "key2", "public", "void", "setvalu", "set", "valu", "valu", "thi", "valu", "valu", "public", "getvalu", "get", "valu", "return", "valu", "public", "static", "void", "main", "string", "arg", "throw", "except", "executionenviron", "execut", "environ", "env", "executionenviron", "getexecutionenviron", "execut", "environ", "get", "execut", "environ", "dataset", "data", "set", "vertex", "long", "doubl", "set", "env", "fromel", "element", "new", "vertex", "long", "doubl", "0l", "new", "vertex", "long", "doubl", "1l", "set", "print", "env", "execut", "code", "except", "code", "except", "thread", "main", "java", "lang", "illegalstateexcept", "illeg", "state", "except", "detect", "more", "than", "one", "getter", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "isvalidpojofield", "type", "extractor", "valid", "pojo", "field", "typeextractor", "java:981", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "analyzepojo", "type", "extractor", "analyz", "pojo", "typeextractor", "java:1025", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "privategetforclass", "type", "extractor", "privat", "get", "class", "typeextractor", "java:937", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "privategetforclass", "type", "extractor", "privat", "get", "class", "typeextractor", "java:863", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "privategetforobject", "type", "extractor", "privat", "get", "object", "typeextractor", "java:1146", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "typeutil", "typeextractor", "getforobject", "type", "extractor", "get", "object", "typeextractor", "java:1116", "type", "extractor", "at", "org", "apach", "flink", "api", "java", "executionenviron", "fromel", "execut", "environ", "element", "executionenviron", "java:466", "execut", "environ", "at", "test", "test", "main", "test", "java:74", "code"], "B_title": "Fix incorrect getter / setter detection", "B_clean_title": ["fix", "incorrect", "getter", "setter", "detect"]},
{"A_title": "HomePageMapper ignores request to / with query string parametersIssue a request to http://host:port/contextpath/?something Wicket will log an error message like: ERROR - RequestCycle               - Unable to execute request. No suitable RequestHandler found. URL=?something  I think the reason is in HomePageMapper which maps to the configured home page only if there are no query parameters.  HomePageMapper.java: code public IRequestHandler mapRequest(Request request)  if (request.getUrl().getSegments().size() == 0 && request.getUrl().getQueryParameters().size() == 0)  return new RenderPageRequestHandler(new PageProvider(getContext().getHomePageClass()));  else  return null;   code", "A_clean_title": ["homepagemapp", "home", "page", "mapper", "ignor", "request", "queri", "string", "parametersissu", "paramet", "issu", "request", "http", "host", "port", "contextpath", "someth", "wicket", "will", "log", "error", "messag", "like", "error", "requestcycl", "request", "cycl", "unabl", "execut", "request", "no", "suitabl", "requesthandl", "request", "handler", "found", "url=", "someth", "think", "reason", "homepagemapp", "home", "page", "mapper", "which", "map", "configur", "home", "page", "onli", "there", "are", "no", "queri", "paramet", "homepagemapp", "java", "home", "page", "mapper", "code", "public", "irequesthandl", "request", "handler", "maprequest", "map", "request", "request", "request", "request", "geturl", "get", "url", "getseg", "get", "segment", "size", "request", "geturl", "get", "url", "getqueryparamet", "get", "queri", "paramet", "size", "return", "new", "renderpagerequesthandl", "render", "page", "request", "handler", "new", "pageprovid", "page", "provid", "getcontext", "get", "context", "gethomepageclass", "get", "home", "page", "class", "return", "null", "code"], "B_title": "HomePageMapper ignores request to / with query string parameters", "B_clean_title": ["homepagemapp", "home", "page", "mapper", "ignor", "request", "queri", "string", "paramet"]},
{"A_title": "Switched order of delete key and key in statements changes semanticNone", "A_clean_title": ["switch", "order", "delet", "key", "key", "statement", "chang", "semanticnon", "semant", "none"], "B_title": "Dont inline values over a delete. Fixes issue 773", "B_clean_title": ["dont", "inlin", "valu", "over", "delet", "fix", "issu", "773"]},
{"A_title": "Repository.findOne method fails to return row for row level secured entity type if first row isnt readableCode inspection  FindOne shouldnt check if first row of delegate is readable but find first readable row.", "A_clean_title": ["repositori", "findon", "find", "one", "method", "fail", "return", "row", "row", "level", "secur", "entiti", "type", "first", "row", "isnt", "readablecod", "readabl", "code", "inspect", "findon", "find", "one", "shouldnt", "check", "first", "row", "deleg", "readabl", "but", "find", "first", "readabl", "row"], "B_title": "Fix #7263 Row-level secured findOne: return first readable entity", "B_clean_title": ["fix", "7263", "row", "level", "secur", "findon", "find", "one", "return", "first", "readabl", "entiti"]},
{"A_title": "unexpected typed coverage of less than 100%None", "A_clean_title": ["unexpect", "type", "coverag", "less", "than", "100", "none"], "B_title": "Parameter types should be declared rather than inferred. This means that if the programmer re-assignes the argument to a different type they will get a type warning. Fixes issue 433.", "B_clean_title": ["paramet", "type", "declar", "rather", "than", "infer", "thi", "mean", "that", "programm", "re", "assign", "argument", "differ", "type", "they", "will", "get", "type", "warn", "fix", "issu", "433"]},
{"A_title": "Bugs in BrentOptimizerI apologize for having provided a buggy implementation of Brents optimization algorithm (class BrentOptimizer in package optimization.univariate). The unit tests didnt show that there was something wrong although (from the changes.xml file) I discovered that at the time Luc had noticed something weird in the implementations behaviour. Comparing with an implementation in Python I could figure out the fixes. Ill modify BrentOptimizer and add a test. I also propose to change the name of the unit test class from BrentMinimizerTest to BrentOptimizerTest.", "A_clean_title": ["bug", "brentoptimizeri", "brent", "optim", "apolog", "have", "provid", "buggi", "implement", "brent", "optim", "algorithm", "class", "brentoptim", "brent", "optim", "packag", "optim", "univari", "unit", "test", "didnt", "show", "that", "there", "wa", "someth", "wrong", "although", "chang", "xml", "file", "discov", "that", "at", "time", "luc", "had", "notic", "someth", "weird", "implement", "behaviour", "compar", "implement", "python", "could", "figur", "out", "fix", "ill", "modifi", "brentoptim", "brent", "optim", "add", "test", "also", "propos", "chang", "name", "unit", "test", "class", "brentminimizertest", "brent", "minim", "test", "brentoptimizertest", "brent", "optim", "test"], "B_title": "Another bug uncovered; all things being equal the code now behaves like the Puthon implementation. MATH-397: Modified BrentOptimizer following the changes in AbstractUnivariateRealOptimizer.", "B_clean_title": ["anoth", "bug", "uncov", "all", "thing", "be", "equal", "code", "now", "behav", "like", "puthon", "implement", "math", "397", "modifi", "brentoptim", "brent", "optim", "follow", "chang", "abstractunivariaterealoptim", "abstract", "univari", "real", "optim"]},
{"A_title": "Variable names prefixed with MSG_ cause error with advanced optimizationsNone", "A_clean_title": ["variabl", "name", "prefix", "msg", "caus", "error", "advanc", "optimizationsnon", "optim", "none"], "B_title": "Shut off i18n warnings if the user didnt ask for i18n. Fixes issue 1135 R=blickly", "B_clean_title": ["shut", "off", "i18n", "warn", "user", "didnt", "ask", "i18n", "fix", "issu", "1135", "r=blickli"]},
{"A_title": "feat: add support for $java.version in pom.xmlHi !  I have an issue creating a MavenLauncher for projects that have $java.version in their POM.xml .  Replacing it with  1.8 for example seems to work around. Thank you for your help !", "A_clean_title": ["feat", "add", "support", "java", "version", "pom", "xmlhi", "xml", "hi", "have", "issu", "creat", "mavenlaunch", "maven", "launcher", "project", "that", "have", "java", "version", "their", "pom", "xml", "replac", "it", "exampl", "seem", "work", "around", "thank", "you", "your", "help"], "B_title": "fix: parsing of java version not starting with 1. in pom.xml (#2729)  * Check if java.version contains a dot in pom.xml    * cover all cases and added an Assert in MavenLauncherTest    * (style) added a missing whitespace    fix #2714", "B_clean_title": ["fix", "pars", "java", "version", "not", "start", "pom", "xml", "2729", "check", "java", "version", "contain", "dot", "pom", "xml", "cover", "all", "case", "ad", "assert", "mavenlaunchertest", "maven", "launcher", "test", "style", "ad", "miss", "whitespac", "fix", "2714"]},
{"A_title": "RepositorySidegrade: oak-segment to oak-segment-tar should migrate checkpoint infoThe sidegrade from oak-segment to oak-segment-tar should also take care of moving the checkpoint data and meta. This will save a very expensive full-reindex.", "A_clean_title": ["repositorysidegrad", "repositori", "sidegrad", "oak", "segment", "oak", "segment", "tar", "migrat", "checkpoint", "infoth", "info", "sidegrad", "oak", "segment", "oak", "segment", "tar", "also", "take", "care", "move", "checkpoint", "data", "meta", "thi", "will", "save", "veri", "expens", "full", "reindex"], "B_title": "segment to segment-tar should migrate checkpoint info", "B_clean_title": ["segment", "segment", "tar", "migrat", "checkpoint", "info"]},
{"A_title": "AnnotationRevisionMetadata throws ClassCastException DATACMNS-1173opened and commented  AnnotationRevisionMetadata throws ClassCastException at line 90 :  Most likely leftovers during migration to  java.util.Optional   Affects: 2.0 RC3 (Kay)", "A_clean_title": ["annotationrevisionmetadata", "annot", "revis", "metadata", "throw", "classcastexcept", "class", "cast", "except", "datacmn", "1173open", "comment", "annotationrevisionmetadata", "annot", "revis", "metadata", "throw", "classcastexcept", "class", "cast", "except", "at", "line", "90", "most", "like", "leftov", "dure", "migrat", "java", "util", "option", "affect", "rc3", "kay"], "B_title": "DATACMNS-1173 - Fixed value lookup of AnnotationRevisionMetadata.  Fixed handling of absent values. Minor refactorings. More unit tests.", "B_clean_title": ["datacmn", "1173", "fix", "valu", "lookup", "annotationrevisionmetadata", "annot", "revis", "metadata", "fix", "handl", "absent", "valu", "minor", "refactor", "more", "unit", "test"]},
{"A_title": "Error on TimeSeries createCopy() methodThe test case at the end fails with :  java.lang.IllegalArgumentException: Requires start <= end.  The problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned not an exception. This is with jfreechart 1.0.7", "A_clean_title": ["error", "timeseri", "time", "seri", "createcopi", "creat", "copi", "methodth", "method", "test", "case", "at", "end", "fail", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "requir", "start", "end", "problem", "that", "int", "start", "end", "index", "correspond", "given", "timeperiod", "time", "period", "are", "comput", "incorectli", "here", "would", "expect", "empti", "seri", "return", "not", "except", "thi", "jfreechart"], "B_title": "source/org/jfree/data/time/TimeSeries.java (createCopy(RegularTimePeriod RegularTimePeriod)): Handle empty range.", "B_clean_title": ["java", "sourc", "org", "jfree", "data", "time", "timeseri", "time", "seri", "createcopi", "creat", "copi", "regulartimeperiod", "regular", "time", "period", "regulartimeperiod", "regular", "time", "period", "handl", "empti", "rang"]},
{"A_title": "GaussianFitter Unexpectedly Throws NotStrictlyPositiveExceptionRunning the following:      double observations =            1.1143831578403364E-29       4.95281403484594E-28       1.1171347211930288E-26       1.7044813962636277E-25       1.9784716574832164E-24       1.8630236407866774E-23       1.4820532905097742E-22       1.0241963854632831E-21       6.275077366673128E-21       3.461808994532493E-20       1.7407124684715706E-19       8.056687953553974E-19       3.460193945992071E-18       1.3883326374011525E-17       5.233894983671116E-17       1.8630791465263745E-16       6.288759227922111E-16       2.0204433920597856E-15       6.198768938576155E-15       1.821419346860626E-14       5.139176445538471E-14       1.3956427429045787E-13       3.655705706448139E-13       9.253753324779779E-13       2.267636001476696E-12       5.3880460095836855E-12       1.2431632654852931E-11      ;        GaussianFitter g =      new GaussianFitter(new LevenbergMarquardtOptimizer());          for (int index = 0; index < 27; index++)          g.addObservedPoint(index observationsindex);             g.fit();  Results in:  org.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than or equal to the minimum (0) at org.apache.commons.math.analysis.function.Gaussian Parametric.validateParameters(Gaussian.java:184) at org.apache.commons.math.analysis.function.Gaussian Parametric.value(Gaussian.java:129)   Im guessing the initial guess for sigma is off.", "A_clean_title": ["gaussianfitt", "gaussian", "fitter", "unexpectedli", "throw", "notstrictlypositiveexceptionrun", "not", "strictli", "posit", "except", "run", "follow", "doubl", "observ", "29", "1143831578403364e", "28", "95281403484594e", "26", "1171347211930288e", "25", "7044813962636277e", "24", "9784716574832164e", "23", "8630236407866774e", "22", "4820532905097742e", "21", "0241963854632831e", "21", "275077366673128e", "20", "461808994532493e", "19", "7407124684715706e", "19", "056687953553974e", "18", "460193945992071e", "17", "3883326374011525e", "17", "233894983671116e", "16", "8630791465263745e", "16", "288759227922111e", "15", "0204433920597856e", "15", "198768938576155e", "14", "821419346860626e", "14", "139176445538471e", "13", "3956427429045787e", "13", "655705706448139e", "13", "253753324779779e", "12", "267636001476696e", "12", "3880460095836855e", "11", "2431632654852931e", "gaussianfitt", "gaussian", "fitter", "new", "gaussianfitt", "gaussian", "fitter", "new", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "int", "index", "index", "27", "index++", "addobservedpoint", "add", "observ", "point", "index", "observationsindex", "fit", "result", "org", "apach", "common", "math", "except", "notstrictlypositiveexcept", "not", "strictli", "posit", "except", "277", "smaller", "than", "or", "equal", "minimum", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "validateparamet", "valid", "paramet", "gaussian", "java:184", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "valu", "gaussian", "java:129", "im", "guess", "initi", "guess", "sigma", "off"], "B_title": "Workaround exception generated when the optimizer tries invalid values for the sigma parameter. Added a method to allow the user to pass his own initial guess.", "B_clean_title": ["workaround", "except", "gener", "when", "optim", "tri", "invalid", "valu", "sigma", "paramet", "ad", "method", "allow", "user", "pass", "hi", "own", "initi", "guess"]},
{"A_title": "Return empty value for Iterables.I expect an Iterable to be mocked by default with an empty Iterable. I understand from the initial issue this behavior would be introduced in Mockito 2 but beta-8 still returns null. Could we return null for Iterables ?", "A_clean_title": ["return", "empti", "valu", "iter", "expect", "iter", "mock", "by", "default", "empti", "iter", "understand", "initi", "issu", "thi", "behavior", "would", "introduc", "mockito", "but", "beta", "still", "return", "null", "could", "we", "return", "null", "iter"], "B_title": "Adds empty iterable as a new empty value #210", "B_clean_title": ["add", "empti", "iter", "as", "new", "empti", "valu", "210"]},
{"A_title": "PageParameters#mergeWith may loose values of the other PPThe code at org.apache.wicket.request.mapper.parameter.PageParameters#mergeWith() looks like:  for (NamedPair curNamed : other.getAllNamed()) set(curNamed.getKey() curNamed.getValue());  may loose some values if other has a named parameter with several values.With the current code only the last name/value pair is preserved.", "A_clean_title": ["pageparamet", "page", "paramet", "mergewith", "merg", "may", "loos", "valu", "other", "ppthe", "pp", "code", "at", "org", "apach", "wicket", "request", "mapper", "paramet", "pageparamet", "page", "paramet", "mergewith", "merg", "look", "like", "namedpair", "name", "pair", "curnam", "cur", "name", "other", "getallnam", "get", "all", "name", "set", "curnam", "getkey", "cur", "name", "get", "key", "curnam", "getvalu", "cur", "name", "get", "valu", "may", "loos", "some", "valu", "other", "ha", "name", "paramet", "sever", "valu", "current", "code", "onli", "last", "name", "valu", "pair", "preserv"], "B_title": "keep multiple named values and absent indexed values", "B_clean_title": ["keep", "multipl", "name", "valu", "absent", "index", "valu"]},
{"A_title": "One of Variance.evaluate() methods does not work correctlyThe method org.apache.commons.math.stat.descriptive.moment.Variance.evaluate(double values double weights double mean int begin int length) does not work properly. Looks loke it ignores the length parameter and grabs the whole dataset. Similar method in Mean class seems to work. I did not check other methods taking the part of the array; they may have the same problem. Workaround: I had to shrink my arrays and use the method without the length.", "A_clean_title": ["one", "varianc", "evalu", "method", "not", "work", "correctlyth", "correctli", "method", "org", "apach", "common", "math", "stat", "descript", "moment", "varianc", "evalu", "doubl", "valu", "doubl", "weight", "doubl", "mean", "int", "begin", "int", "length", "not", "work", "properli", "look", "loke", "it", "ignor", "length", "paramet", "grab", "whole", "dataset", "similar", "method", "mean", "class", "seem", "work", "did", "not", "check", "other", "method", "take", "part", "array", "they", "may", "have", "same", "problem", "workaround", "had", "shrink", "my", "array", "use", "method", "without", "length"], "B_title": "Fixed array indexing error in Variance evaluate method for computing the weighted variance of an array segment.", "B_clean_title": ["fix", "array", "index", "error", "varianc", "evalu", "method", "comput", "weight", "varianc", "array", "segment"]},
{"A_title": "StringUtils replaceEach - Bug or Missing DocumentationThe following Test Case for replaceEach fails with a null pointer exception. I have expected that all StringUtils methods are null-friendly The use case is that i will stuff Values into the replacementList of which I do not want to check whether they are null. I admit the use case is not perfect because it is unclear what happens on the replace. I outlined three expectations in the test case of course only one should be met. If it is decided that none of them should be possible I propose to update the documentation with what happens when null is passed as replacement string  import static org.junit.Assert.assertEquals;  import org.apache.commons.lang.StringUtils; import org.junit.Test;   public class StringUtilsTest   @Test public void replaceEach() String original = Hello World!; String searchList = Hello World; String replacementList = Greetings null; String result = StringUtils.replaceEach(original searchList replacementList); assertEquals(Greetings ! result); //perhaps this is ok as well                 //assertEquals(Greetings World! result);                 //or even //assertEquals(Greetings null! result);", "A_clean_title": ["stringutil", "string", "util", "replaceeach", "replac", "each", "bug", "or", "miss", "documentationth", "document", "follow", "test", "case", "replaceeach", "replac", "each", "fail", "null", "pointer", "except", "have", "expect", "that", "all", "stringutil", "string", "util", "method", "are", "null", "friendli", "use", "case", "that", "will", "stuff", "valu", "into", "replacementlist", "replac", "list", "which", "not", "want", "check", "whether", "they", "are", "null", "admit", "use", "case", "not", "perfect", "becaus", "it", "unclear", "what", "happen", "replac", "outlin", "three", "expect", "test", "case", "cours", "onli", "one", "met", "it", "decid", "that", "none", "them", "possibl", "propos", "updat", "document", "what", "happen", "when", "null", "pass", "as", "replac", "string", "import", "static", "org", "junit", "assert", "assertequ", "assert", "equal", "import", "org", "apach", "common", "lang", "stringutil", "string", "util", "import", "org", "junit", "test", "public", "class", "stringutilstest", "string", "util", "test", "test", "public", "void", "replaceeach", "replac", "each", "string", "origin", "hello", "world", "string", "searchlist", "search", "list", "hello", "world", "string", "replacementlist", "replac", "list", "greet", "null", "string", "result", "stringutil", "replaceeach", "string", "util", "replac", "each", "origin", "searchlist", "search", "list", "replacementlist", "replac", "list", "assertequ", "assert", "equal", "greet", "result", "perhap", "thi", "ok", "as", "well", "assertequ", "assert", "equal", "greet", "world", "result", "or", "even", "assertequ", "assert", "equal", "greet", "null", "result"], "B_title": "Applying fix for LANG-552. StringUtils.replaceEach(String String String) no longer NPEs when null appears in the last String", "B_clean_title": ["appli", "fix", "lang", "552", "stringutil", "replaceeach", "string", "util", "replac", "each", "string", "string", "string", "no", "longer", "npe", "np", "es", "when", "null", "appear", "last", "string"]},
{"A_title": "DocumentNodeStore.dispatch() may pass null to NodeStateDiffThis is a regression introduced by OAK-2562. The dispatch method passes a null state if the node does not exist at a given revision.", "A_clean_title": ["documentnodestor", "dispatch", "document", "node", "store", "may", "pass", "null", "nodestatediffthi", "node", "state", "diff", "thi", "regress", "introduc", "by", "oak", "2562", "dispatch", "method", "pass", "null", "state", "node", "not", "exist", "at", "given", "revis"], "B_title": "DocumentNodeStore.dispatch() may pass null to NodeStateDiff", "B_clean_title": ["documentnodestor", "dispatch", "document", "node", "store", "may", "pass", "null", "nodestatediff", "node", "state", "diff"]},
{"A_title": "twod.PolygonsSet.getSize produces NullPointerException if BSPTree has no nodesorg.apache.commons.math3.geometry.euclidean.twod.PolygonsSet.getSize() uses a tree internally:  final BSPTree<Euclidean2D> tree = getTree(false);  However if that tree contains no data it seems that the reference returned is null which causes a subsequent NullPointerException.  Probably an exception with a message (tree has no data) would clarify that this is an API usage error.", "A_clean_title": ["twod", "polygonsset", "getsiz", "polygon", "set", "get", "size", "produc", "nullpointerexcept", "null", "pointer", "except", "bsptree", "bsp", "tree", "ha", "no", "nodesorg", "apach", "common", "math3", "geometri", "euclidean", "twod", "polygonsset", "getsiz", "polygon", "set", "get", "size", "use", "tree", "intern", "final", "bsptree", "bsp", "tree", "euclidean2d", "tree", "gettre", "get", "tree", "fals", "howev", "that", "tree", "contain", "no", "data", "it", "seem", "that", "refer", "return", "null", "which", "caus", "subsequ", "nullpointerexcept", "null", "pointer", "except", "probabl", "except", "messag", "tree", "ha", "no", "data", "would", "clarifi", "that", "thi", "api", "usag", "error"], "B_title": "Build properly empty polygons for equal min/max box.", "B_clean_title": ["build", "properli", "empti", "polygon", "equal", "min", "max", "box"]},
{"A_title": "Range check fails with IllegalArgumentExceptionRange.includes() fails with IllegalArgumentException when provided revision is from another cluster node:  noformat java.lang.IllegalArgumentException: Trying to compare revisions of different cluster ids: r142f43d2f0f-0-2 and r142f43d46fb-0-1 at org.apache.jackrabbit.oak.plugins.mongomk.Revision.compareRevisionTime(Revision.java:84) at org.apache.jackrabbit.oak.plugins.mongomk.Range.includes(Range.java:55) noformat  The IllegalArgumentException was introduced with OAK-1274.", "A_clean_title": ["rang", "check", "fail", "illegalargumentexceptionrang", "includ", "illeg", "argument", "except", "rang", "fail", "illegalargumentexcept", "illeg", "argument", "except", "when", "provid", "revis", "anoth", "cluster", "node", "noformat", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "tri", "compar", "revis", "differ", "cluster", "id", "r142f43d2f0f", "r142f43d46fb", "at", "org", "apach", "jackrabbit", "oak", "plugin", "mongomk", "revis", "comparerevisiontim", "compar", "revis", "time", "revis", "java:84", "at", "org", "apach", "jackrabbit", "oak", "plugin", "mongomk", "rang", "includ", "rang", "java:55", "noformat", "illegalargumentexcept", "illeg", "argument", "except", "wa", "introduc", "oak", "1274"], "B_title": "Range check fails with IllegalArgumentException", "B_clean_title": ["rang", "check", "fail", "illegalargumentexcept", "illeg", "argument", "except"]},
{"A_title": "Fix incorrect usage of ByteBufferWhile working on ACCUMULO-4098 I found one place where ByteBuffer was being used incorrectly.   Looking around the code I have found other places that are using ByteBuffer incorrectly.  Some of the problems I found are as follows :   * Calling ByteBuffer.array() without calling ByteBuffer.hasArray().  * Using ByteBuffer.position() or ByteBuffer.limit() without adding ByteBuffer.arrayOffset() when dealing with an array returned by ByteBuffer.array().  * Using ByteBuffer.arrayOffset() without adding ByteBuffer.position() when dealing with an array returned by ByteBuffer.array().", "A_clean_title": ["fix", "incorrect", "usag", "bytebufferwhil", "byte", "buffer", "while", "work", "accumulo", "4098", "found", "one", "place", "where", "bytebuff", "byte", "buffer", "wa", "be", "use", "incorrectli", "look", "around", "code", "have", "found", "other", "place", "that", "are", "bytebuff", "byte", "buffer", "incorrectli", "some", "problem", "found", "are", "as", "follow", "call", "bytebuff", "array", "byte", "buffer", "without", "call", "bytebuff", "hasarray", "byte", "buffer", "ha", "array", "bytebuff", "posit", "byte", "buffer", "or", "bytebuff", "limit", "byte", "buffer", "without", "ad", "bytebuff", "arrayoffset", "byte", "buffer", "array", "offset", "when", "deal", "array", "return", "by", "bytebuff", "array", "byte", "buffer", "bytebuff", "arrayoffset", "byte", "buffer", "array", "offset", "without", "ad", "bytebuff", "posit", "byte", "buffer", "when", "deal", "array", "return", "by", "bytebuff", "array", "byte", "buffer"], "B_title": "Fix incorrect usage of ByteBuffer", "B_clean_title": ["fix", "incorrect", "usag", "bytebuff", "byte", "buffer"]},
{"A_title": "fix some rawtype warnings in tests.None", "A_clean_title": ["fix", "some", "rawtyp", "warn", "test", "none"], "B_title": "Merge pull request #32 from alberskib/master", "B_clean_title": ["merg", "pull", "request", "32", "alberskib", "master"]},
{"A_title": "2.0 equal to -2.0The following test fails:  code     @Test     public void testMath1127()          Assert.assertFalse(Precision.equals(2.0 -2.0 1));      code", "A_clean_title": ["equal", "0the", "follow", "test", "fail", "code", "test", "public", "void", "testmath1127", "test", "math1127", "assert", "assertfals", "assert", "fals", "precis", "equal", "code"], "B_title": "Fixed overflow in Precision.equals with ulps.", "B_clean_title": ["fix", "overflow", "precis", "equal", "ulp"]},
{"A_title": "Incorrect rounding of floatpackage org.apache.commons.math3.util  example of usage of round functions of Precision class:  Precision.round(0.0f 2 BigDecimal.ROUND_UP) = 0.01 Precision.round((float)0.0 2 BigDecimal.ROUND_UP) = 0.01 Precision.round((float) 0.0 2) = 0.0 Precision.round(0.0 2 BigDecimal.ROUND_UP) = 0.0  Seems the reason is usage of extending float to double inside round functions and getting influence of memory trash as value.  I think same problem will be found at usage of other round modes.", "A_clean_title": ["incorrect", "round", "floatpackag", "org", "apach", "common", "math3", "util", "exampl", "usag", "round", "function", "precis", "class", "precis", "round", "0f", "bigdecim", "big", "decim", "round", "up", "01", "precis", "round", "float", "bigdecim", "big", "decim", "round", "up", "01", "precis", "round", "float", "precis", "round", "bigdecim", "big", "decim", "round", "up", "seem", "reason", "usag", "extend", "float", "doubl", "insid", "round", "function", "get", "influenc", "memori", "trash", "as", "valu", "think", "same", "problem", "will", "found", "at", "usag", "other", "round", "mode"], "B_title": "Fix Precision.round(float int int) for RoundingMode ROUND_UP. Thanks to  Oleksandr Muliarevych.", "B_clean_title": ["fix", "precis", "round", "float", "int", "int", "roundingmod", "round", "mode", "round", "up", "thank", "oleksandr", "muliarevych"]},
{"A_title": "ArgumentCaptor no longer working for varargsWhen upgrading 1.10.8 the verify passes but the getValue() fails with this error. One other piece of info came to light as a result of creating the MCVE - the test works fine if the Date is the only element passed for bindVariables. That is remove var1 from target and test code then the test runs fine under 1.9.5 and 1.10.8. Also it doesnt matter that the captor is for a Date. The same issue occurs if the parameter is of another type such as Integer.", "A_clean_title": ["argumentcaptor", "argument", "captor", "no", "longer", "work", "varargswhen", "vararg", "when", "upgrad", "10", "verifi", "pass", "but", "getvalu", "get", "valu", "fail", "thi", "error", "one", "other", "piec", "info", "came", "light", "as", "result", "creat", "mcve", "test", "work", "fine", "date", "onli", "element", "pass", "bindvari", "bind", "variabl", "that", "remov", "var1", "target", "test", "code", "then", "test", "run", "fine", "under", "10", "also", "it", "doesnt", "matter", "that", "captor", "date", "same", "issu", "occur", "paramet", "anoth", "type", "such", "as", "integ"], "B_title": "Fixes #188 : attempt to implement logic for varargs capture", "B_clean_title": ["fix", "188", "attempt", "implement", "logic", "vararg", "captur"]},
{"A_title": "MockAccumulo doesnt throw informative errorsUsers are unable to tell if an error has occurred and whether it is due to unimplemented features in MockAccumulo.", "A_clean_title": ["mockaccumulo", "mock", "accumulo", "doesnt", "throw", "inform", "errorsus", "error", "user", "are", "unabl", "tell", "error", "ha", "occur", "whether", "it", "due", "unimpl", "featur", "mockaccumulo", "mock", "accumulo"], "B_title": "employed more TableNotFound / TableExists Exceptions in TableOperations", "B_clean_title": ["employ", "more", "tablenotfound", "tabl", "not", "found", "tableexist", "tabl", "exist", "except", "tableoper", "tabl", "oper"]},
{"A_title": "Integer overflow in OpenMapRealMatrixcomputeKey() has an integer overflow. Since it is a sparse matrix this is quite easily encountered long before heap space is exhausted. The attached code demonstrates the problem which could potentially be a security vulnerability (for example if one was to use this matrix to store access control information).  Workaround: never create an OpenMapRealMatrix with more cells than are addressable with an int.", "A_clean_title": ["integ", "overflow", "openmaprealmatrixcomputekey", "open", "map", "real", "matrixcomput", "key", "ha", "integ", "overflow", "sinc", "it", "spars", "matrix", "thi", "quit", "easili", "encount", "long", "befor", "heap", "space", "exhaust", "attach", "code", "demonstr", "problem", "which", "could", "potenti", "secur", "vulner", "exampl", "one", "wa", "use", "thi", "matrix", "store", "access", "control", "inform", "workaround", "never", "creat", "openmaprealmatrix", "open", "map", "real", "matrix", "more", "cell", "than", "are", "address", "int"], "B_title": "Fixed an integer overflow in OpenMapRealMatrix.", "B_clean_title": ["fix", "integ", "overflow", "openmaprealmatrix", "open", "map", "real", "matrix"]},
{"A_title": "Use analytical function for UniformRealDistribution.inverseCumulativeProbabilityThe inverse CDF is currently solved by a root finding function. It would be much simpler (and faster) to use the analytical expression. This would save the user from having to set the inverseCumAccuracy correctly.  Ive attached a patch that implements this.", "A_clean_title": ["use", "analyt", "function", "uniformrealdistribut", "inversecumulativeprobabilityth", "uniform", "real", "distribut", "invers", "cumul", "probabl", "invers", "cdf", "current", "solv", "by", "root", "find", "function", "it", "would", "much", "simpler", "faster", "use", "analyt", "express", "thi", "would", "save", "user", "have", "set", "inversecumaccuraci", "invers", "cum", "accuraci", "correctli", "ive", "attach", "patch", "that", "implement", "thi"], "B_title": "Fixed inverse cumulative probability for uniform distribution.", "B_clean_title": ["fix", "invers", "cumul", "probabl", "uniform", "distribut"]},
{"A_title": "onBeforeRender() is called on components that are not allowed to renderpasted from the list:  Hi  I ran into an odd problem this week. A model fed to a ListView was calling service methods the current user wasnt allowed to use and I was wondering how that could happen. A panel far above this ListView in the hierarchy had been secured (using Shiro annotations but that turns out to not matter at all) and was not supposed to be rendered for this user. From this I had expected the ListView not to be rendered either but here it was trying to assemble itself in onBeforeRender and thus calling the forbidden service methods.  I investigated Component and friends for a bit and have found a potential problem.  internalBeforeRender() checks determineVisibility() before doing anything. So far so good. determineVisibility() then checks isRenderAllowed() so the applications IAuthorizationStrategy can block certain components. This is where it goes wrong though: isRenderAllowed() only looks at FLAG_IS_RENDER_ALLOWED for performance reasons and that flag hasnt been set yet! internalPrepareForRender() only calls setRenderAllowed() *after* beforeRender().  Due to this the supposedly secure panel was going through its own beforeRender and thus calling that ListViews beforeRender.  I think this can be a serious problem such as in my case described above. Id expect that if isActionAuthorized(RENDER) is false the secured component should basically never get to the beforeRender phase. My questions are now:  - Is this intentional? If yes please explain the reasoning behind it  because it isnt obvious to me.  - If not can we fix it? My intuitive suggestion would be to simply  move the call to setRenderAllowed() from the end of  internalBeforeRender() (prepareForRender in 1.4) to the beginning of  that method so beforeRender() can reliably look at that flag.  - If we can fix it when and where do we fix it? This hit me in 1.4  and looking at the code its still there in 1.5. Id *really* like it  fixed in the last 1.4 release and certainly in 1.5 given that this  has the potential to impact security.   Its not an API break but Im not sure whether the implications for  application behavior are tolerable for all existing applications. On  the other hand it seems to be a real security problem so maybe the  change is justified. Id like some core dev opinions please :-)  If this is in fact a bug Im of course willing to provide a ticket and a patch :-)  Thanks!  Carl-Eric www.wicketbuch.de", "A_clean_title": ["onbeforerend", "befor", "render", "call", "compon", "that", "are", "not", "allow", "renderpast", "list", "hi", "ran", "into", "odd", "problem", "thi", "week", "model", "fed", "listview", "list", "view", "wa", "call", "servic", "method", "current", "user", "wasnt", "allow", "use", "wa", "wonder", "how", "that", "could", "happen", "panel", "far", "abov", "thi", "listview", "list", "view", "hierarchi", "had", "been", "secur", "shiro", "annot", "but", "that", "turn", "out", "not", "matter", "at", "all", "wa", "not", "suppos", "render", "thi", "user", "thi", "had", "expect", "listview", "list", "view", "not", "render", "either", "but", "here", "it", "wa", "tri", "assembl", "itself", "onbeforerend", "befor", "render", "thu", "call", "forbidden", "servic", "method", "investig", "compon", "friend", "bit", "have", "found", "potenti", "problem", "internalbeforerend", "intern", "befor", "render", "check", "determinevis", "determin", "visibl", "befor", "do", "anyth", "so", "far", "so", "good", "determinevis", "determin", "visibl", "then", "check", "isrenderallow", "render", "allow", "so", "applic", "iauthorizationstrategi", "author", "strategi", "block", "certain", "compon", "thi", "where", "it", "goe", "wrong", "though", "isrenderallow", "render", "allow", "onli", "look", "at", "flag", "render", "allow", "perform", "reason", "that", "flag", "hasnt", "been", "set", "yet", "internalprepareforrend", "intern", "prepar", "render", "onli", "call", "setrenderallow", "set", "render", "allow", "after", "beforerend", "befor", "render", "due", "thi", "supposedli", "secur", "panel", "wa", "go", "through", "it", "own", "beforerend", "befor", "render", "thu", "call", "that", "listview", "list", "view", "beforerend", "befor", "render", "think", "thi", "seriou", "problem", "such", "as", "my", "case", "describ", "abov", "id", "expect", "that", "isactionauthor", "action", "author", "render", "fals", "secur", "compon", "basic", "never", "get", "beforerend", "befor", "render", "phase", "my", "question", "are", "now", "thi", "intent", "ye", "pleas", "explain", "reason", "behind", "it", "becaus", "it", "isnt", "obviou", "me", "not", "we", "fix", "it", "my", "intuit", "suggest", "would", "simpli", "move", "call", "setrenderallow", "set", "render", "allow", "end", "internalbeforerend", "intern", "befor", "render", "prepareforrend", "prepar", "render", "begin", "that", "method", "so", "beforerend", "befor", "render", "reliabl", "look", "at", "that", "flag", "we", "fix", "it", "when", "where", "we", "fix", "it", "thi", "hit", "me", "look", "at", "code", "it", "still", "there", "id", "realli", "like", "it", "fix", "last", "releas", "certainli", "given", "that", "thi", "ha", "potenti", "impact", "secur", "it", "not", "api", "break", "but", "im", "not", "sure", "whether", "implic", "applic", "behavior", "are", "toler", "all", "exist", "applic", "other", "hand", "it", "seem", "real", "secur", "problem", "so", "mayb", "chang", "justifi", "id", "like", "some", "core", "dev", "opinion", "pleas", "thi", "fact", "bug", "im", "cours", "will", "provid", "ticket", "patch", "thank", "carl", "eric", "www", "wicketbuch", "de"], "B_title": "block onbeforerender() from being called if auth strategy vetoes render action Issue: WICKET-4256", "B_clean_title": ["block", "onbeforerend", "be", "call", "auth", "strategi", "veto", "render", "action", "issu", "wicket", "4256"]},
{"A_title": "MockHttpServletResponse.addCookie(Cookie) adds duplicate cookiesorg.apache.wicket.protocol.http.mock.MockHttpServletResponse.addCookie(Cookie) makes a bad check whether the cookie to be added is already in the list of cookies. Since javax.servlet.http.Cookie doesnt implement #equals() cookies.remove(cookie) wont remove the previous cookie because the identity is different.  According to http://www.ietf.org/rfc/rfc2109.txt p.4.3.3 :   If a user agent receives a Set-Cookie response header whose NAME is    the same as a pre-existing cookie and whose Domain and Path    attribute values exactly (string) match those of a pre-existing    cookie the new cookie supersedes the old.  However if the Set-    Cookie has a value for Max-Age of zero the (old and new) cookie is    discarded.  Otherwise cookies accumulate until they expire (resources    permitting) at which time they are discarded.  I.e. the equality is on the name path and domain.", "A_clean_title": ["mockhttpservletrespons", "addcooki", "mock", "http", "servlet", "respons", "add", "cooki", "cooki", "add", "duplic", "cookiesorg", "apach", "wicket", "protocol", "http", "mock", "mockhttpservletrespons", "addcooki", "mock", "http", "servlet", "respons", "add", "cooki", "cooki", "make", "bad", "check", "whether", "cooki", "ad", "alreadi", "list", "cooki", "sinc", "javax", "servlet", "http", "cooki", "doesnt", "implement", "equal", "cooki", "remov", "cooki", "wont", "remov", "previou", "cooki", "becaus", "ident", "differ", "accord", "http", "ietf", "txt", "www", "org", "rfc", "rfc2109", "user", "agent", "receiv", "set", "cooki", "respons", "header", "whose", "name", "same", "as", "pre", "exist", "cooki", "whose", "domain", "path", "attribut", "valu", "exactli", "string", "match", "those", "pre", "exist", "cooki", "new", "cooki", "supersed", "old", "howev", "set", "cooki", "ha", "valu", "max", "age", "zero", "old", "new", "cooki", "discard", "otherwis", "cooki", "accumul", "until", "they", "expir", "resourc", "permit", "at", "which", "time", "they", "are", "discard", "equal", "name", "path", "domain"], "B_title": "MockHttpServletResponse.addCookie(Cookie) adds duplicate cookies", "B_clean_title": ["mockhttpservletrespons", "addcooki", "mock", "http", "servlet", "respons", "add", "cooki", "cooki", "add", "duplic", "cooki"]},
{"A_title": "SQL-2 query parser doesnt detect some illegal statementsThe SQL-2 query parser doesnt detect some illegal statements for example  code select * from nt:base where name =+ Hello select * from nt:base where name => Hello code  Both are currently interpreted as name = Hello which is wrong.", "A_clean_title": ["sql", "queri", "parser", "doesnt", "detect", "some", "illeg", "statementsth", "statement", "sql", "queri", "parser", "doesnt", "detect", "some", "illeg", "statement", "exampl", "code", "select", "nt", "base", "where", "name", "hello", "select", "nt", "base", "where", "name", "hello", "code", "both", "are", "current", "interpret", "as", "name", "hello", "which", "wrong"], "B_title": "SQL-2 query parser doesnt detect some illegal statements", "B_clean_title": ["sql", "queri", "parser", "doesnt", "detect", "some", "illeg", "statement"]},
{"A_title": "Exception when parsing erroneous jsdoc: /**@return @code foo bar   *    baz. */None", "A_clean_title": ["except", "when", "pars", "erron", "jsdoc", "return", "code", "foo", "bar", "baz", "none"], "B_title": "Fixes issue 919", "B_clean_title": ["fix", "issu", "919"]},
{"A_title": "Compiler should warn/error when instance methods are operated onNone", "A_clean_title": ["compil", "warn", "error", "when", "instanc", "method", "are", "oper", "onnon", "none"], "B_title": "Make sure that functions are called with a this type. Fixes issue 440", "B_clean_title": ["make", "sure", "that", "function", "are", "call", "thi", "type", "fix", "issu", "440"]},
{"A_title": "PutTokenImpl not thread safePutTokenImpl uses prefix increment on a static member to generate presumably unique identifiers. Prefix increment is not atomic though which might result in non unique ids being generated.", "A_clean_title": ["puttokenimpl", "put", "token", "impl", "not", "thread", "safeputtokenimpl", "safe", "put", "token", "impl", "use", "prefix", "increment", "static", "member", "gener", "presum", "uniqu", "identifi", "prefix", "increment", "not", "atom", "though", "which", "might", "result", "non", "uniqu", "id", "be", "gener"], "B_title": "PutTokenImpl not thread safe", "B_clean_title": ["puttokenimpl", "put", "token", "impl", "not", "thread", "safe"]},
{"A_title": "PathUtils#getDepth returns 1 for empty pathPathUtils#getDepths that the root path / has depth 0. however passing in a empty string is accepted and returns 1.  according to the API contract getDepth is counting the number of elements in the path which for  should IMO be zero.", "A_clean_title": ["pathutil", "path", "util", "getdepth", "get", "depth", "return", "empti", "pathpathutil", "path", "path", "util", "getdepth", "get", "depth", "that", "root", "path", "ha", "depth", "howev", "pass", "empti", "string", "accept", "return", "accord", "api", "contract", "getdepth", "get", "depth", "count", "number", "element", "path", "which", "imo", "zero"], "B_title": ": PathUtils#getDepth returns 1 for empty path", "B_clean_title": ["pathutil", "path", "util", "getdepth", "get", "depth", "return", "empti", "path"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Fix tests and code in UCE that do unsound optimizations in finally blocks.", "B_clean_title": ["fix", "test", "code", "uce", "that", "unsound", "optim", "final", "block"]},
{"A_title": "address-controller allows to create multiple addresses with the same spec.address valuereproducible via following steps:    create standard address space (reproducible with brokered as well)  deploy 3 addresses into this address space     all addresses were created successfully console shows only one of those addresses next address appears once previous one is removed.  And only first of multiple addresses has isReady attribute set to true in configMap  standard_anycast.json", "A_clean_title": ["address", "control", "allow", "creat", "multipl", "address", "same", "spec", "address", "valuereproduc", "via", "follow", "step", "creat", "standard", "address", "space", "reproduc", "broker", "as", "well", "deploy", "address", "into", "thi", "address", "space", "all", "address", "were", "creat", "success", "consol", "show", "onli", "one", "those", "address", "next", "address", "appear", "onc", "previou", "one", "remov", "onli", "first", "multipl", "address", "ha", "isreadi", "readi", "attribut", "set", "true", "configmap", "config", "map", "json", "standard", "anycast"], "B_title": "Enhance address validation in REST API  * Ensure no duplicate addresses within new addresses * Ensure no duplicate addresses in new addresses and existing addresses  This fixes #931", "B_clean_title": ["enhanc", "address", "valid", "rest", "api", "ensur", "no", "duplic", "address", "within", "new", "address", "ensur", "no", "duplic", "address", "new", "address", "exist", "address", "thi", "fix", "931"]},
{"A_title": "Inheritance layout excludes XML header from outputWhen using inheritance layout if the superclass (Layout class) has an ?xml header at the top its excluded from the rendering of subclasses if they have an associated html file. If the subclass has no .html file associated with it the ?xml header is preserved in the rendering output.  To reproduce: Create a SuperPage class extending WebPage. At the top of SuperPage.html put <?xml version=1.0 encoding=utf-8?> . Create two subclasses of SuperPage one with an HTML file and one without. View the sub pages. Notice when the one with an HTML file is rendered the xml header is excluded.  Expected: The ?xml header should always be preserved in the rendered output as its vital to the layout.", "A_clean_title": ["inherit", "layout", "exclud", "xml", "header", "outputwhen", "output", "when", "inherit", "layout", "superclass", "layout", "class", "ha", "xml", "header", "at", "top", "it", "exclud", "render", "subclass", "they", "have", "associ", "html", "file", "subclass", "ha", "no", "html", "file", "associ", "it", "xml", "header", "preserv", "render", "output", "reproduc", "creat", "superpag", "super", "page", "class", "extend", "webpag", "web", "page", "at", "top", "superpag", "html", "super", "page", "put", "xml", "version=1", "encoding=utf", "creat", "two", "subclass", "superpag", "super", "page", "one", "html", "file", "one", "without", "view", "sub", "page", "notic", "when", "one", "html", "file", "render", "xml", "header", "exclud", "expect", "xml", "header", "alway", "preserv", "render", "output", "as", "it", "vital", "layout"], "B_title": "fixed: Inheritance layout excludes XML header from output Issue: WICKET-2569", "B_clean_title": ["fix", "inherit", "layout", "exclud", "xml", "header", "output", "issu", "wicket", "2569"]},
{"A_title": "GaussianFitter Unexpectedly Throws NotStrictlyPositiveExceptionRunning the following:     double observations =         1.1143831578403364E-29       4.95281403484594E-28       1.1171347211930288E-26       1.7044813962636277E-25       1.9784716574832164E-24       1.8630236407866774E-23       1.4820532905097742E-22       1.0241963854632831E-21       6.275077366673128E-21       3.461808994532493E-20       1.7407124684715706E-19       8.056687953553974E-19       3.460193945992071E-18       1.3883326374011525E-17       5.233894983671116E-17       1.8630791465263745E-16       6.288759227922111E-16       2.0204433920597856E-15       6.198768938576155E-15       1.821419346860626E-14       5.139176445538471E-14       1.3956427429045787E-13       3.655705706448139E-13       9.253753324779779E-13       2.267636001476696E-12       5.3880460095836855E-12       1.2431632654852931E-11       ;     GaussianFitter g =      new GaussianFitter(new LevenbergMarquardtOptimizer());     for (int index = 0; index < 27; index++)          g.addObservedPoint(index observationsindex);             g.fit(); Results in: org.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than or equal to the minimum (0) at org.apache.commons.math.analysis.function.Gaussian Parametric.validateParameters(Gaussian.java:184) at org.apache.commons.math.analysis.function.Gaussian Parametric.value(Gaussian.java:129) Im guessing the initial guess for sigma is off.", "A_clean_title": ["gaussianfitt", "gaussian", "fitter", "unexpectedli", "throw", "notstrictlypositiveexceptionrun", "not", "strictli", "posit", "except", "run", "follow", "doubl", "observ", "29", "1143831578403364e", "28", "95281403484594e", "26", "1171347211930288e", "25", "7044813962636277e", "24", "9784716574832164e", "23", "8630236407866774e", "22", "4820532905097742e", "21", "0241963854632831e", "21", "275077366673128e", "20", "461808994532493e", "19", "7407124684715706e", "19", "056687953553974e", "18", "460193945992071e", "17", "3883326374011525e", "17", "233894983671116e", "16", "8630791465263745e", "16", "288759227922111e", "15", "0204433920597856e", "15", "198768938576155e", "14", "821419346860626e", "14", "139176445538471e", "13", "3956427429045787e", "13", "655705706448139e", "13", "253753324779779e", "12", "267636001476696e", "12", "3880460095836855e", "11", "2431632654852931e", "gaussianfitt", "gaussian", "fitter", "new", "gaussianfitt", "gaussian", "fitter", "new", "levenbergmarquardtoptim", "levenberg", "marquardt", "optim", "int", "index", "index", "27", "index++", "addobservedpoint", "add", "observ", "point", "index", "observationsindex", "fit", "result", "org", "apach", "common", "math", "except", "notstrictlypositiveexcept", "not", "strictli", "posit", "except", "277", "smaller", "than", "or", "equal", "minimum", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "validateparamet", "valid", "paramet", "gaussian", "java:184", "at", "org", "apach", "common", "math", "analysi", "function", "gaussian", "parametr", "valu", "gaussian", "java:129", "im", "guess", "initi", "guess", "sigma", "off"], "B_title": "Workaround exception generated when the optimizer tries invalid values for the sigma parameter. Added a method to allow the user to pass his own initial guess.", "B_clean_title": ["workaround", "except", "gener", "when", "optim", "tri", "invalid", "valu", "sigma", "paramet", "ad", "method", "allow", "user", "pass", "hi", "own", "initi", "guess"]},
{"A_title": "Creating multiple checkpoint on same head revision overwrites previous entriesCurrently when a checkpoint is created in DocumentNodeStore then it is saved in form of currentHeadRev=>expiryTime. Now if multiple checkpoints are created where head revision has not changed then only the last one would be saved and previous entries would be overridden as revision is used as key  One fix would be to change the expiry time only if the new expiry time is greater than previous entry. However doing that safely in a cluster (check then save) is currently not possible with DocumentStore API as the modCount check if only supported for Nodes.", "A_clean_title": ["creat", "multipl", "checkpoint", "same", "head", "revis", "overwrit", "previou", "entriescurr", "entri", "current", "when", "checkpoint", "creat", "documentnodestor", "document", "node", "store", "then", "it", "save", "form", "currentheadrev=", "current", "head", "rev=", "expirytim", "expiri", "time", "now", "multipl", "checkpoint", "are", "creat", "where", "head", "revis", "ha", "not", "chang", "then", "onli", "last", "one", "would", "save", "previou", "entri", "would", "overridden", "as", "revis", "use", "as", "key", "one", "fix", "would", "chang", "expiri", "time", "onli", "new", "expiri", "time", "greater", "than", "previou", "entri", "howev", "do", "that", "safe", "cluster", "check", "then", "save", "current", "not", "possibl", "documentstor", "document", "store", "api", "as", "modcount", "mod", "count", "check", "onli", "support", "node"], "B_title": "Creating multiple checkpoint on same head revision overwrites previous entries", "B_clean_title": ["creat", "multipl", "checkpoint", "same", "head", "revis", "overwrit", "previou", "entri"]},
{"A_title": "goog.scope doesnt properly check declared functionsNone", "A_clean_title": ["goog", "scope", "doesnt", "properli", "check", "declar", "functionsnon", "function", "none"], "B_title": "Emit an error if there are dangling functions in the goog.scope fixes issue 737", "B_clean_title": ["emit", "error", "there", "are", "dangl", "function", "goog", "scope", "fix", "issu", "737"]},
{"A_title": "Overzealous optimization confuses variablesNone", "A_clean_title": ["overzeal", "optim", "confus", "variablesnon", "variabl", "none"], "B_title": "Fix inlining bug in https://code.google.com/p/closure-compiler/issues/detail?id=1053 Attempt 2 Fixes issue 1053 ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=50800167", "B_clean_title": ["fix", "inlin", "bug", "http", "googl", "compil", "issu", "detail", "code", "com", "closur", "id=1053", "attempt", "fix", "issu", "1053", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=50800167"]},
{"A_title": "Fix and then deprecate isSupportXxxInclusive in RealDistribution interfaceThe conclusion from 1 was never implemented. We should deprecate these properties from the RealDistribution interface but since removal will have to wait until 4.0 we should agree on a precise definition and fix the code to match it in the mean time.  The definition that I propose is that isSupportXxxInclusive means that when the density function is applied to the upper or lower bound of support returned by getSupportXxxBound a finite (i.e. not infinite) not NaN value is returned.  1 http://markmail.org/message/dxuxh7eybl7xejde", "A_clean_title": ["fix", "then", "deprec", "issupportxxxinclus", "support", "xxx", "inclus", "realdistribut", "real", "distribut", "interfaceth", "interfac", "conclus", "wa", "never", "implement", "we", "deprec", "these", "properti", "realdistribut", "real", "distribut", "interfac", "but", "sinc", "remov", "will", "have", "wait", "until", "we", "agre", "precis", "definit", "fix", "code", "match", "it", "mean", "time", "definit", "that", "propos", "that", "issupportxxxinclus", "support", "xxx", "inclus", "mean", "that", "when", "densiti", "function", "appli", "upper", "or", "lower", "bound", "support", "return", "by", "getsupportxxxbound", "get", "support", "xxx", "bound", "finit", "not", "infinit", "not", "nan", "na", "valu", "return", "http", "markmail", "org", "messag", "dxuxh7eybl7xejd"], "B_title": "Clarified definition of isSupportXxxBoundInclusive in RealDistribution interface made code consistent with the definition and deprecated these methods marking for removal in 4.0. JIRA: MATH-859", "B_clean_title": ["clarifi", "definit", "issupportxxxboundinclus", "support", "xxx", "bound", "inclus", "realdistribut", "real", "distribut", "interfac", "made", "code", "consist", "definit", "deprec", "these", "method", "mark", "remov", "jira", "math", "859"]},
{"A_title": "DefaultPropertyResolver does not respect JavaBean conventionsThe property name code should handle the isPropertyName pattern  if(getterName.startsWith(get))  name = getterName.substring(3 4).toLowerCase() + getterName.substring(4);  else  name = getterName.substring(2 3).toLowerCase() + getterName.substring(3);   Workaround: providing my own property resolver.", "A_clean_title": ["defaultpropertyresolv", "default", "properti", "resolv", "not", "respect", "javabean", "java", "bean", "conventionsth", "convent", "properti", "name", "code", "handl", "ispropertynam", "properti", "name", "pattern", "getternam", "startswith", "getter", "name", "start", "get", "name", "getternam", "substr", "getter", "name", "tolowercas", "lower", "case", "getternam", "substr", "getter", "name", "name", "getternam", "substr", "getter", "name", "tolowercas", "lower", "case", "getternam", "substr", "getter", "name", "workaround", "provid", "my", "own", "properti", "resolv"], "B_title": "DefaultPropertyResolver does not respect JavaBean conventions", "B_clean_title": ["defaultpropertyresolv", "default", "properti", "resolv", "not", "respect", "javabean", "java", "bean", "convent"]},
{"A_title": "multistep integrator start failure triggers NPEMultistep ODE integrators like Adams-Bashforth and Adams-Moulton require a starter procedure. If the starter integrator is not configured properly it will not create the necessary number of initial points and the multistep integrator will not be initialized correctly. This results in NullPointErException when the scaling array is referenced later on.  The following test case (with an intentionally wrong starter configuration) shows the problem.  code @Test public void testStartFailure()        TestProblem1 pb = new TestProblem1();       double minStep = 0.0001 * (pb.getFinalTime() - pb.getInitialTime());       double maxStep = pb.getFinalTime() - pb.getInitialTime();       double scalAbsoluteTolerance = 1.0e-6;       double scalRelativeTolerance = 1.0e-7;        MultistepIntegrator integ =           new AdamsBashforthIntegrator(4 minStep maxStep                                                             scalAbsoluteTolerance                                                             scalRelativeTolerance);       integ.setStarterIntegrator(new DormandPrince853Integrator(0.2 * (pb.getFinalTime() - pb.getInitialTime())                                                                 pb.getFinalTime() - pb.getInitialTime()                                                                 0.1 0.1));       TestProblemHandler handler = new TestProblemHandler(pb integ);       integ.addStepHandler(handler);       integ.integrate(pb                              pb.getInitialTime() pb.getInitialState()                              pb.getFinalTime() new doublepb.getDimension());       code  Failure to start the integrator should be detected and an appropriate exception should be triggered.", "A_clean_title": ["multistep", "integr", "start", "failur", "trigger", "npemultistep", "npe", "multistep", "ode", "integr", "like", "adam", "bashforth", "adam", "moulton", "requir", "starter", "procedur", "starter", "integr", "not", "configur", "properli", "it", "will", "not", "creat", "necessari", "number", "initi", "point", "multistep", "integr", "will", "not", "initi", "correctli", "thi", "result", "nullpointerexcept", "null", "point", "er", "except", "when", "scale", "array", "referenc", "later", "follow", "test", "case", "intent", "wrong", "starter", "configur", "show", "problem", "code", "test", "public", "void", "teststartfailur", "test", "start", "failur", "testproblem1", "test", "problem1", "pb", "new", "testproblem1", "test", "problem1", "doubl", "minstep", "min", "step", "0001", "pb", "getfinaltim", "get", "final", "time", "pb", "getinitialtim", "get", "initi", "time", "doubl", "maxstep", "max", "step", "pb", "getfinaltim", "get", "final", "time", "pb", "getinitialtim", "get", "initi", "time", "doubl", "scalabsolutetoler", "scal", "absolut", "toler", "0e", "doubl", "scalrelativetoler", "scal", "rel", "toler", "0e", "multistepintegr", "multistep", "integr", "integ", "new", "adamsbashforthintegr", "adam", "bashforth", "integr", "minstep", "min", "step", "maxstep", "max", "step", "scalabsolutetoler", "scal", "absolut", "toler", "scalrelativetoler", "scal", "rel", "toler", "integ", "setstarterintegr", "set", "starter", "integr", "new", "dormandprince853integr", "dormand", "prince853integr", "pb", "getfinaltim", "get", "final", "time", "pb", "getinitialtim", "get", "initi", "time", "pb", "getfinaltim", "get", "final", "time", "pb", "getinitialtim", "get", "initi", "time", "testproblemhandl", "test", "problem", "handler", "handler", "new", "testproblemhandl", "test", "problem", "handler", "pb", "integ", "integ", "addstephandl", "add", "step", "handler", "handler", "integ", "integr", "pb", "pb", "getinitialtim", "get", "initi", "time", "pb", "getinitialst", "get", "initi", "state", "pb", "getfinaltim", "get", "final", "time", "new", "doublepb", "getdimens", "get", "dimens", "code", "failur", "start", "integr", "detect", "appropri", "except", "trigger"], "B_title": "Detect start failures with multi-step ODE integrators.", "B_clean_title": ["detect", "start", "failur", "multi", "step", "ode", "integr"]},
{"A_title": "FileUpload writeToTempFile() method throws NPE for sessionless requestsI have created stateless page with stateless form containing FileUploadField however when I tried to post file to it NPE was thrown.  The issue is caused by method FileUpload#writeToTempFile() method trying to use session id as temp file prefix.   Workaround: create temp file manually and use method FileUpload#writeToFile( myTempFile)", "A_clean_title": ["fileupload", "file", "upload", "writetotempfil", "write", "temp", "file", "method", "throw", "npe", "sessionless", "requestsi", "request", "have", "creat", "stateless", "page", "stateless", "form", "contain", "fileuploadfield", "file", "upload", "field", "howev", "when", "tri", "post", "file", "it", "npe", "wa", "thrown", "issu", "caus", "by", "method", "fileupload", "file", "upload", "writetotempfil", "write", "temp", "file", "method", "tri", "use", "session", "id", "as", "temp", "file", "prefix", "workaround", "creat", "temp", "file", "manual", "use", "method", "fileupload", "file", "upload", "writetofil", "write", "file", "mytempfil", "my", "temp", "file"], "B_title": "Improving the FileUpload#writeToFile method to not rely on HTTP session existence Issue: WICKET-3715", "B_clean_title": ["improv", "fileupload", "file", "upload", "writetofil", "write", "file", "method", "not", "reli", "http", "session", "exist", "issu", "wicket", "3715"]},
{"A_title": "onremove() in RefreshingView.onPopulatefile a bug with a quickstart. onremove() should be called on all removed components.  -igor  On Fri Feb 18 2011 at 5:38 AM Benedikt Rothe <benedikt.rothe@qleo.de> wrote: > > Hi > > > > Are the existing children of a RepeatingView/RefreshingView being informed > > when > > the View is newly populated (RefreshingView.onPopulate). > > > > Id like to clean some internal references in this case. > > I tried: > > - aChild.onRemove is not called in this situation > > - aChild.setParent(null) is called. I treid to override setParent it. But > > setParent is private. > > > > Any suggestions? > > Benedikt", "A_clean_title": ["onremov", "refreshingview", "onpopulatefil", "refresh", "view", "populatefil", "bug", "quickstart", "onremov", "call", "all", "remov", "compon", "igor", "fri", "feb", "18", "2011", "at", "5:38", "am", "benedikt", "roth", "benedikt", "roth", "qleo", "de", "wrote", "hi", "are", "exist", "children", "repeatingview", "refreshingview", "repeat", "view", "refresh", "view", "be", "inform", "when", "view", "newli", "popul", "refreshingview", "onpopul", "refresh", "view", "popul", "id", "like", "clean", "some", "intern", "refer", "thi", "case", "tri", "achild", "onremov", "child", "remov", "not", "call", "thi", "situat", "achild", "setpar", "child", "set", "parent", "null", "call", "treid", "overrid", "setpar", "set", "parent", "it", "but", "setpar", "set", "parent", "privat", "ani", "suggest", "benedikt"], "B_title": "Issue: WICKET-3455", "B_clean_title": ["issu", "wicket", "3455"]},
{"A_title": "WebPage#onAfterRender erroneously reports missing headerIn WebPage#onAfterRender() theres a check wether a header was missing on a page and header contributions would be lost.  In the following case this check erroneously barks: - page A was requested - in As onBeforeRender() a RestartResponseAtInterceptPageException to page B is thrown - page As onAfterRender() is invoked in a finally block - processing continues with page B  Page As onAfterRender() complains about the missing header althought his page was never completely rendered.  IMHO theres a check missing in WebPage#onAfterRender():      if (getRequestCycle().getResponsePage() == this)  .....   Or is Page A not allowed to throw RestartResponseAtInterceptPageException in onBeforeRender() at all?", "A_clean_title": ["webpag", "web", "page", "onafterrend", "after", "render", "erron", "report", "miss", "headerin", "header", "webpag", "web", "page", "onafterrend", "after", "render", "there", "check", "wether", "header", "wa", "miss", "page", "header", "contribut", "would", "lost", "follow", "case", "thi", "check", "erron", "bark", "page", "wa", "request", "as", "onbeforerend", "befor", "render", "restartresponseatinterceptpageexcept", "restart", "respons", "at", "intercept", "page", "except", "page", "thrown", "page", "as", "onafterrend", "after", "render", "invok", "final", "block", "process", "continu", "page", "page", "as", "onafterrend", "after", "render", "complain", "about", "miss", "header", "althought", "hi", "page", "wa", "never", "complet", "render", "imho", "there", "check", "miss", "webpag", "web", "page", "onafterrend", "after", "render", "getrequestcycl", "get", "request", "cycl", "getresponsepag", "get", "respons", "page", "thi", "or", "page", "not", "allow", "throw", "restartresponseatinterceptpageexcept", "restart", "respons", "at", "intercept", "page", "except", "onbeforerend", "befor", "render", "at", "all"], "B_title": "check successful rendering of page before validating headers", "B_clean_title": ["check", "success", "render", "page", "befor", "valid", "header"]},
{"A_title": "When true setOneIndexedParameters still behaves as false in the links of the json response DATACMNS-563opened and commented When setting this to true the argument 1 accepted from the HTTP request is indeed considered to be the index of the first page but the json response still displays links as if the first page is indexed 0. For example requesting the page 3 gets the page 3 but the links are described ignoring the index start at 1. The prev link should show 2 and the next link should show 4. As it stands now the next page link has the same index as the current page in the request.     Affects: 1.8.2 (Dijkstra SR2)  Referenced from: pull request #267  Backported to:  2.0.3 (Kay SR3)  1.13.10 (Ingalls SR10)", "A_clean_title": ["when", "true", "setoneindexedparamet", "set", "one", "index", "paramet", "still", "behav", "as", "fals", "link", "json", "respons", "datacmn", "563open", "comment", "when", "set", "thi", "true", "argument", "accept", "http", "request", "inde", "consid", "index", "first", "page", "but", "json", "respons", "still", "display", "link", "as", "first", "page", "index", "exampl", "request", "page", "get", "page", "but", "link", "are", "describ", "ignor", "index", "start", "at", "prev", "link", "show", "next", "link", "show", "as", "it", "stand", "now", "next", "page", "link", "ha", "same", "index", "as", "current", "page", "request", "affect", "dijkstra", "sr2", "referenc", "pull", "request", "267", "backport", "kay", "sr3", "13", "10", "ingal", "sr10"], "B_title": "DATACMNS-563 - PagedResourcesAssembler now correctly forwards one-index settings to PageMetadata.  Original pull request: #267.", "B_clean_title": ["datacmn", "563", "pagedresourcesassembl", "page", "resourc", "assembl", "now", "correctli", "forward", "one", "index", "set", "pagemetadata", "page", "metadata", "origin", "pull", "request", "267"]},
{"A_title": "no warnings when @private prop is redeclared on subclassNone", "A_clean_title": ["no", "warn", "when", "privat", "prop", "redeclar", "subclassnon", "subclass", "none"], "B_title": "Emit a warning when a private property overrides another private property with both defined in the ctor. Fixes issue 254", "B_clean_title": ["emit", "warn", "when", "privat", "properti", "overrid", "anoth", "privat", "properti", "both", "defin", "ctor", "fix", "issu", "254"]},
{"A_title": "Missing toString hashCode and equals methods on BatchWriterConfigTried to test equality of two BatchWriterConfig objects found theyre missing all of the methods from Object that they should be implementing.", "A_clean_title": ["miss", "tostr", "string", "hashcod", "hash", "code", "equal", "method", "batchwriterconfigtri", "batch", "writer", "config", "tri", "test", "equal", "two", "batchwriterconfig", "batch", "writer", "config", "object", "found", "theyr", "miss", "all", "method", "object", "that", "they", "implement"], "B_title": "Add equals hashCode and toString to batchwriterconfig.", "B_clean_title": ["add", "equal", "hashcod", "hash", "code", "tostr", "string", "batchwriterconfig"]},
{"A_title": "DocumentNodeStore.dispose() may leave repository in an inconsistent stateThe repository may become inconsistent when a commit happens while the DocumentNodeStore is disposed.   The node store writes back pending _lastRevs and then unset the active flag in the clusterNodes collection. It is possible a commit gets through even after the _lastRevs had been updated and the active flag is cleared. This means the missing _lastRev updates will not be recovered on a restart or by another cluster node.", "A_clean_title": ["documentnodestor", "dispos", "document", "node", "store", "may", "leav", "repositori", "inconsist", "stateth", "state", "repositori", "may", "becom", "inconsist", "when", "commit", "happen", "while", "documentnodestor", "document", "node", "store", "dispos", "node", "store", "write", "back", "pend", "lastrev", "last", "rev", "then", "unset", "activ", "flag", "clusternod", "cluster", "node", "collect", "it", "possibl", "commit", "get", "through", "even", "after", "lastrev", "last", "rev", "had", "been", "updat", "activ", "flag", "clear", "thi", "mean", "miss", "lastrev", "last", "rev", "updat", "will", "not", "recov", "restart", "or", "by", "anoth", "cluster", "node"], "B_title": "DocumentNodeStore.dispose() may leave repository in an inconsistent state", "B_clean_title": ["documentnodestor", "dispos", "document", "node", "store", "may", "leav", "repositori", "inconsist", "state"]},
{"A_title": "Need range checks for elitismRate in ElitisticListPopulation constructors.There is a range check for setting the elitismRate via ElitisticListPopulations setElitismRate method but not via the constructors.", "A_clean_title": ["need", "rang", "check", "elitismr", "elit", "rate", "elitisticlistpopul", "elitist", "list", "popul", "constructor", "there", "rang", "check", "set", "elitismr", "elit", "rate", "via", "elitisticlistpopul", "elitist", "list", "popul", "setelitismr", "set", "elit", "rate", "method", "but", "not", "via", "constructor"], "B_title": "Use same range check in ctor as in setter for ElitisticListPopulation. Thanks to Reid Hochstedler", "B_clean_title": ["use", "same", "rang", "check", "ctor", "as", "setter", "elitisticlistpopul", "elitist", "list", "popul", "thank", "reid", "hochstedl"]},
{"A_title": "Minified css/js gets compressedGiven an application with a resource reference to a minified script i.e. html5.js and html5.min.js.  When the ResourceRequestHandler responds  it will set compress to false if the resource reference was PackageResourceReference but it will not change compression if the resource reference was JavaScriptResourceReference.   PackageResourceReference handles minified resources more or less correctly (if they are minified they should not be further compressed) but this behavior is overwritten in its subclasses.", "A_clean_title": ["minifi", "css", "js", "get", "compressedgiven", "compress", "given", "applic", "resourc", "refer", "minifi", "script", "html5", "js", "html5", "min", "js", "when", "resourcerequesthandl", "resourc", "request", "handler", "respond", "it", "will", "set", "compress", "fals", "resourc", "refer", "wa", "packageresourcerefer", "packag", "resourc", "refer", "but", "it", "will", "not", "chang", "compress", "resourc", "refer", "wa", "javascriptresourcerefer", "java", "script", "resourc", "refer", "packageresourcerefer", "packag", "resourc", "refer", "handl", "minifi", "resourc", "more", "or", "less", "correctli", "they", "are", "minifi", "they", "not", "further", "compress", "but", "thi", "behavior", "overwritten", "it", "subclass"], "B_title": "", "B_clean_title": []},
{"A_title": "Overflow checks in Fraction multiply(int) / divide(int)The member methods multiply(int) / divide(int) in the class org.apache.commons.math3.fraction.Fraction do not have overflow checks.  code:java return new Fraction(numerator * i denominator); code  should be  code:java return new Fraction(ArithmeticUtils.mulAndCheck(numerator i) denominator); code  or considering the case gcd(i denominator) > 1  code:java return multiply(new Fraction(i)); code", "A_clean_title": ["overflow", "check", "fraction", "multipli", "int", "divid", "int", "member", "method", "multipli", "int", "divid", "int", "class", "org", "apach", "common", "math3", "fraction", "fraction", "not", "have", "overflow", "check", "code", "java", "return", "new", "fraction", "numer", "denomin", "code", "code", "java", "return", "new", "fraction", "arithmeticutil", "mulandcheck", "arithmet", "util", "mul", "check", "numer", "denomin", "code", "or", "consid", "case", "gcd", "denomin", "code", "java", "return", "multipli", "new", "fraction", "code"], "B_title": "", "B_clean_title": []},
{"A_title": "Node isNew() is false in case the node is removed and added in same commitWhen you remove a Node /path/a transiently and add one add /path/a again. The transiently added Node isNew() check will be false. code root.getNode(name).remove(); Node newNode = root.addNode(name); nowNode.isNew() => false code  The API says quote Returns true if this is a new item meaning that it exists only in transient storage on the Session and has not yet been saved. Within a transaction isNew on an Item may return false (because the item has been saved) even if that Item is not in persistent storage (because the transaction has not yet been committed).... quote", "A_clean_title": ["node", "isnew", "new", "fals", "case", "node", "remov", "ad", "same", "commitwhen", "commit", "when", "you", "remov", "node", "path", "transient", "add", "one", "add", "path", "again", "transient", "ad", "node", "isnew", "new", "check", "will", "fals", "code", "root", "getnod", "get", "node", "name", "remov", "node", "newnod", "new", "node", "root", "addnod", "add", "node", "name", "nownod", "isnew", "now", "node", "new", "fals", "code", "api", "say", "quot", "return", "true", "thi", "new", "item", "mean", "that", "it", "exist", "onli", "transient", "storag", "session", "ha", "not", "yet", "been", "save", "within", "transact", "isnew", "new", "item", "may", "return", "fals", "becaus", "item", "ha", "been", "save", "even", "that", "item", "not", "persist", "storag", "becaus", "transact", "ha", "not", "yet", "been", "commit", "quot"], "B_title": "Node isNew() is false in case the node is removed and added in same commit Treat a replaced builder as new enable test cases", "B_clean_title": ["node", "isnew", "new", "fals", "case", "node", "remov", "ad", "same", "commit", "treat", "replac", "builder", "as", "new", "enabl", "test", "case"]},
{"A_title": "POJO serialization NPENullPointer on serialization of a Date field:  Caused by: java.lang.RuntimeException: Error obtaining the sorted input: Thread SortMerger Reading Thread terminated due to an exception: null at org.apache.flink.runtime.operators.sort.UnilateralSortMerger.getIterator(UnilateralSortMerger.java:607) at org.apache.flink.runtime.operators.RegularPactTask.getInput(RegularPactTask.java:1132) at org.apache.flink.runtime.operators.CoGroupDriver.prepare(CoGroupDriver.java:98) at org.apache.flink.runtime.operators.RegularPactTask.run(RegularPactTask.java:464) ... 3 more Caused by: java.io.IOException: Thread SortMerger Reading Thread terminated due to an exception: null at org.apache.flink.runtime.operators.sort.UnilateralSortMerger ThreadBase.run(UnilateralSortMerger.java:784) Caused by: java.lang.NullPointerException at org.apache.flink.api.common.typeutils.base.DateSerializer.deserialize(DateSerializer.java:72) at org.apache.flink.api.common.typeutils.base.DateSerializer.deserialize(DateSerializer.java:1) at org.apache.flink.api.java.typeutils.runtime.PojoSerializer.deserialize(PojoSerializer.java:487) at org.apache.flink.api.java.typeutils.runtime.TupleSerializer.deserialize(TupleSerializer.java:136) at org.apache.flink.api.java.typeutils.runtime.TupleSerializer.deserialize(TupleSerializer.java:30) at org.apache.flink.runtime.plugable.ReusingDeserializationDelegate.read(ReusingDeserializationDelegate.java:57) at org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer.getNextRecord(SpillingAdaptiveSpanningRecordDeserializer.java:111) at org.apache.flink.runtime.io.network.api.reader.AbstractRecordReader.getNextRecord(AbstractRecordReader.java:64) at org.apache.flink.runtime.io.network.api.reader.MutableRecordReader.next(MutableRecordReader.java:34) at org.apache.flink.runtime.operators.util.ReaderIterator.next(ReaderIterator.java:59) at org.apache.flink.runtime.operators.sort.UnilateralSortMerger ReadingThread.go(UnilateralSortMerger.java:958) at org.apache.flink.runtime.operators.sort.UnilateralSortMerger ThreadBase.run(UnilateralSortMerger.java:781)", "A_clean_title": ["pojo", "serial", "npenullpoint", "npe", "null", "pointer", "serial", "date", "field", "caus", "by", "java", "lang", "runtimeexcept", "runtim", "except", "error", "obtain", "sort", "input", "thread", "sortmerg", "sort", "merger", "read", "thread", "termin", "due", "except", "null", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "getiter", "unilater", "sort", "merger", "get", "iter", "unilateralsortmerg", "java:607", "unilater", "sort", "merger", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "getinput", "regular", "pact", "task", "get", "input", "regularpacttask", "java:1132", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "cogroupdriv", "prepar", "co", "group", "driver", "cogroupdriv", "java:98", "co", "group", "driver", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "run", "regular", "pact", "task", "regularpacttask", "java:464", "regular", "pact", "task", "more", "caus", "by", "java", "io", "ioexcept", "io", "except", "thread", "sortmerg", "sort", "merger", "read", "thread", "termin", "due", "except", "null", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "unilater", "sort", "merger", "threadbas", "run", "thread", "base", "unilateralsortmerg", "java:784", "unilater", "sort", "merger", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "flink", "api", "common", "typeutil", "base", "dateseri", "deseri", "date", "serial", "dateseri", "java:72", "date", "serial", "at", "org", "apach", "flink", "api", "common", "typeutil", "base", "dateseri", "deseri", "date", "serial", "dateseri", "java:1", "date", "serial", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "pojoseri", "deseri", "pojo", "serial", "pojoseri", "java:487", "pojo", "serial", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "tupleseri", "deseri", "tupl", "serial", "tupleseri", "java:136", "tupl", "serial", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "tupleseri", "deseri", "tupl", "serial", "tupleseri", "java:30", "tupl", "serial", "at", "org", "apach", "flink", "runtim", "plugabl", "reusingdeserializationdeleg", "read", "reus", "deseri", "deleg", "reusingdeserializationdeleg", "java:57", "reus", "deseri", "deleg", "at", "org", "apach", "flink", "runtim", "io", "network", "api", "serial", "spillingadaptivespanningrecorddeseri", "getnextrecord", "spill", "adapt", "span", "record", "deseri", "get", "next", "record", "spillingadaptivespanningrecorddeseri", "java:111", "spill", "adapt", "span", "record", "deseri", "at", "org", "apach", "flink", "runtim", "io", "network", "api", "reader", "abstractrecordread", "getnextrecord", "abstract", "record", "reader", "get", "next", "record", "abstractrecordread", "java:64", "abstract", "record", "reader", "at", "org", "apach", "flink", "runtim", "io", "network", "api", "reader", "mutablerecordread", "next", "mutabl", "record", "reader", "mutablerecordread", "java:34", "mutabl", "record", "reader", "at", "org", "apach", "flink", "runtim", "oper", "util", "readeriter", "next", "reader", "iter", "readeriter", "java:59", "reader", "iter", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "unilater", "sort", "merger", "readingthread", "go", "read", "thread", "unilateralsortmerg", "java:958", "unilater", "sort", "merger", "at", "org", "apach", "flink", "runtim", "oper", "sort", "unilateralsortmerg", "unilater", "sort", "merger", "threadbas", "run", "thread", "base", "unilateralsortmerg", "java:781", "unilater", "sort", "merger"], "B_title": "Fix POJO deserialization for reuse objects with NULL fields", "B_clean_title": ["fix", "pojo", "deseri", "reus", "object", "null", "field"]},
{"A_title": "MathUtils.factorial(n) fails for n >= 17The result of MathUtils.factorial( n ) for n = 17 18 19 is wrong probably because of rounding errors in the double calculations. Replace the first line of MathUtilsTest.testFactorial() by         for (int i = 1; i <= 20; i++)  to check all valid arguments for the long result and see the failure. I suggest implementing a simple loop to multiply the long result - or even using a precomputed long - instead of adding logarithms.", "A_clean_title": ["mathutil", "factori", "math", "util", "fail", "17the", "result", "mathutil", "factori", "math", "util", "17", "18", "19", "wrong", "probabl", "becaus", "round", "error", "doubl", "calcul", "replac", "first", "line", "mathutilstest", "testfactori", "math", "util", "test", "test", "factori", "by", "int", "20", "i++", "check", "all", "valid", "argument", "long", "result", "see", "failur", "suggest", "implement", "simpl", "loop", "multipli", "long", "result", "or", "even", "precomput", "long", "instead", "ad", "logarithm"], "B_title": "Fixed error in factorial accuracy.  JIRA: MATH-240.", "B_clean_title": ["fix", "error", "factori", "accuraci", "jira", "math", "240"]},
{"A_title": "too large first step with embedded Runge-Kutta integrators (Dormand-Prince 8(53) ...)Adaptive step size integrators compute the first step size by themselves if it is not provided. For embedded Runge-Kutta type this step size is not checked against the integration range so if the integration range is extremely short this step size may evaluate the function out of the range (and in fact it tries afterward to go back and fails to stop). Gragg-Bulirsch-Stoer integrators do not have this problem the step size is checked and truncated if needed.", "A_clean_title": ["too", "larg", "first", "step", "embed", "rung", "kutta", "integr", "dormand", "princ", "53", "adapt", "step", "size", "integr", "comput", "first", "step", "size", "by", "themselv", "it", "not", "provid", "embed", "rung", "kutta", "type", "thi", "step", "size", "not", "check", "against", "integr", "rang", "so", "integr", "rang", "extrem", "short", "thi", "step", "size", "may", "evalu", "function", "out", "rang", "fact", "it", "tri", "afterward", "go", "back", "fail", "stop", "gragg", "bulirsch", "stoer", "integr", "not", "have", "thi", "problem", "step", "size", "check", "truncat", "need"], "B_title": "fixed too long first step in fixed Runge-Kutta integrators.", "B_clean_title": ["fix", "too", "long", "first", "step", "fix", "rung", "kutta", "integr"]},
{"A_title": "none standard PeriodType without year throws exceptionI tried to get a Period only for months and weeks with following code:  This throws following exception:  Even removing the year component with .withYearsRemoved() throws the same exception:", "A_clean_title": ["none", "standard", "periodtyp", "period", "type", "without", "year", "throw", "exceptioni", "except", "tri", "get", "period", "onli", "month", "week", "follow", "code", "thi", "throw", "follow", "except", "even", "remov", "year", "compon", "withyearsremov", "year", "remov", "throw", "same", "except"], "B_title": "Fix handling of PeriodType when either years or months missing", "B_clean_title": ["fix", "handl", "periodtyp", "period", "type", "when", "either", "year", "or", "month", "miss"]},
{"A_title": "VisibilityFilter does not catch BadArgumentExceptionIf an invalid column visibility makes it into the system then the VisibilityFilter may not handle it properly.   The accept method handles VisibilityParseException but some of the parse code throws a BadArgumentException which is not handled.", "A_clean_title": ["visibilityfilt", "visibl", "filter", "not", "catch", "badargumentexceptionif", "bad", "argument", "except", "invalid", "column", "visibl", "make", "it", "into", "system", "then", "visibilityfilt", "visibl", "filter", "may", "not", "handl", "it", "properli", "accept", "method", "handl", "visibilityparseexcept", "visibl", "pars", "except", "but", "some", "pars", "code", "throw", "badargumentexcept", "bad", "argument", "except", "which", "not", "handl"], "B_title": "made visibilityfilter catch badargument exception", "B_clean_title": ["made", "visibilityfilt", "catch", "badargu", "except"]},
{"A_title": "Blank map and no pointer when tracker is sending vibration alarmHello  Im very happy with the traccar platform but got a strange issue.  I got about 40 trackers connected but 2 is missing map and pointers. I noticed those 2 trackers is marked with ´vibration´ alarm and ignition OFF. Is it a bug or am I doing something wrong ? trackers is running on h02 protocol.  Thanks", "A_clean_title": ["blank", "map", "no", "pointer", "when", "tracker", "send", "vibrat", "alarmhello", "alarm", "hello", "im", "veri", "happi", "traccar", "platform", "but", "got", "strang", "issu", "got", "about", "40", "tracker", "connect", "but", "miss", "map", "pointer", "notic", "those", "tracker", "mark", "´vibration´", "alarm", "ignit", "off", "it", "bug", "or", "am", "do", "someth", "wrong", "tracker", "run", "h02", "protocol", "thank"], "B_title": "Better handle H02 X mode (fix #2780)", "B_clean_title": ["better", "handl", "h02", "mode", "fix", "2780"]},
{"A_title": "should use provided pullRequestTitle when creating the PRSummary  Related to  societe-generale/ci-droid#6 : new pullRequestTitle field needs to be taken into account when creating the PR Type of Issue  It is a :       Motivation  Current Behavior  the PR is created but takes the commitMessage as title : now that a dedicated field (pullRequestTitle) has been introduced in the model we should use it  Expected Behavior  use pullRequestTitle if provided - otherwise use the branch name as PR title  Steps to Reproduce (for bugs)  Your Environment    Version used: 1.0.5  OS and version:  Version of libs used:", "A_clean_title": ["use", "provid", "pullrequesttitl", "pull", "request", "titl", "when", "creat", "prsummari", "pr", "summari", "relat", "societ", "droid", "general", "ci", "new", "pullrequesttitl", "pull", "request", "titl", "field", "need", "taken", "into", "account", "when", "creat", "pr", "type", "issu", "it", "motiv", "current", "behavior", "pr", "creat", "but", "take", "commitmessag", "commit", "messag", "as", "titl", "now", "that", "dedic", "field", "pullrequesttitl", "pull", "request", "titl", "ha", "been", "introduc", "model", "we", "use", "it", "expect", "behavior", "use", "pullrequesttitl", "pull", "request", "titl", "provid", "otherwis", "use", "branch", "name", "as", "pr", "titl", "step", "reproduc", "bug", "your", "environ", "version", "use", "os", "version", "version", "lib", "use"], "B_title": "Issue15 - handle pull request title (#16)  * upgrading to ci-droid-api.version 1.0.4    * fixes https://github.com/societe-generale/ci-droid-tasks-consumer/issues/15", "B_clean_title": ["issue15", "handl", "pull", "request", "titl", "16", "upgrad", "ci", "droid", "api", "version", "fix", "http", "droid", "task", "general", "ci", "consum", "issu", "15", "github", "com", "societ"]},
{"A_title": "Stop receiving records with error  Last request was dispatched at...but no response as of ...Cancelling subscription and restarting. (KCL 2.0)I have a Kinesis stream of 2 shards with data published to it continuously. I use KCL 2.0.1 java to connect to the stream with polling (by populating retrievalConfig.retrievalSpecificConfig with a PollingConfig object). It works completely fine and keeps receiving messages from both shards for the first 10 minutes. After that it stops receiving any message even there is data continuously published to the stream. I leave the process running for 5 more minutes and issue persists. After that I restart the process and it starts receiving messages again from both shards but stops receiving messages again after running for 10 minutes. Issue happens repeatedly.  No throttling error is seen in logs. Instead following errors are seen in logs:   2018-10-19 14:12:43531 ERROR main shardId-000000000000: Last request was dispatched at 2018-10-19T03:12:07.772Z but no response as of 2018-10-19T03:12:43.531Z (PT35.759S).  Cancelling subscription and restarting. This kind of logs appear once for every 35 seconds for each shard. When it first appeared it happened to shardId-000000000000 and no more messages are received from this shard. Then it appeared for shardId-000000000001 as well and no more message is received from this shard.  To isolate the publishing factor Ive done another test where I first published lots of data to the stream without consuming. Then I stop publishing and start the consumer application. Same behaviours are observed.  Same behaviours are observed with KCL 2.0.3.  Ive extracted and attached the relevant application logs and error logs for reference.   app.log  error.log Any idea?", "A_clean_title": ["stop", "receiv", "record", "error", "last", "request", "wa", "dispatch", "at", "but", "no", "respons", "as", "cancel", "subscript", "restart", "kcl", "have", "kinesi", "stream", "shard", "data", "publish", "it", "continu", "use", "kcl", "java", "connect", "stream", "poll", "by", "popul", "retrievalconfig", "retrievalspecificconfig", "retriev", "config", "retriev", "specif", "config", "pollingconfig", "poll", "config", "object", "it", "work", "complet", "fine", "keep", "receiv", "messag", "both", "shard", "first", "10", "minut", "after", "that", "it", "stop", "receiv", "ani", "messag", "even", "there", "data", "continu", "publish", "stream", "leav", "process", "run", "more", "minut", "issu", "persist", "after", "that", "restart", "process", "it", "start", "receiv", "messag", "again", "both", "shard", "but", "stop", "receiv", "messag", "again", "after", "run", "10", "minut", "issu", "happen", "repeatedli", "no", "throttl", "error", "seen", "log", "instead", "follow", "error", "are", "seen", "log", "2018", "10", "19", "14:12:43531", "error", "main", "shardid", "000000000000", "shard", "id", "last", "request", "wa", "dispatch", "at", "2018", "10", "19t03:12:07", "772z", "but", "no", "respons", "as", "2018", "10", "19t03:12:43", "531z", "pt35", "759", "cancel", "subscript", "restart", "thi", "kind", "log", "appear", "onc", "everi", "35", "second", "each", "shard", "when", "it", "first", "appear", "it", "happen", "shardid", "000000000000", "shard", "id", "no", "more", "messag", "are", "receiv", "thi", "shard", "then", "it", "appear", "shardid", "000000000001", "shard", "id", "as", "well", "no", "more", "messag", "receiv", "thi", "shard", "isol", "publish", "factor", "ive", "done", "anoth", "test", "where", "first", "publish", "lot", "data", "stream", "without", "consum", "then", "stop", "publish", "start", "consum", "applic", "same", "behaviour", "are", "observ", "same", "behaviour", "are", "observ", "kcl", "ive", "extract", "attach", "relev", "applic", "log", "error", "log", "refer", "app", "log", "error", "log", "ani", "idea"], "B_title": "Remove a possible deadlock on polling queue fill (#462)  * Remove a possible deadlock on polling queue fill    Adding new items to the receive queue for the PrefetchRecordsPublisher  when at capacity would deadlock retrievals as it was already holding  a lock on this.    The method addArrivedRecordsInput did not need to be synchronized on  this as it didnt change any of the protected  state (requestedResponses).  There is a call to drainQueueForRequests  immediately after the addArrivedRecordsInput that will ensure newly  arrived data is dispatched.    This fixes #448    * Small fix on the reasoning comment    * Adjust the test to act more like the ShardConsumer    The ShardConsuemr which is the principal user of the  PrefetchRecordsPublisher uses RxJava to consume from publisher. This  test uses RxJava to consume and notifies the test thread once  MAX_ITEMS * 3 have been received. This ensures that we cycle through  the queue at least 3 times.    * Removed the upper limit on the retrievals    The way RxJavas request management makes it possible that more  requests than we might expect can happen.", "B_clean_title": ["remov", "possibl", "deadlock", "poll", "queue", "fill", "462", "remov", "possibl", "deadlock", "poll", "queue", "fill", "ad", "new", "item", "receiv", "queue", "prefetchrecordspublish", "prefetch", "record", "publish", "when", "at", "capac", "would", "deadlock", "retriev", "as", "it", "wa", "alreadi", "hold", "lock", "thi", "method", "addarrivedrecordsinput", "add", "arriv", "record", "input", "did", "not", "need", "synchron", "thi", "as", "it", "didnt", "chang", "ani", "protect", "state", "requestedrespons", "request", "respons", "there", "call", "drainqueueforrequest", "drain", "queue", "request", "immedi", "after", "addarrivedrecordsinput", "add", "arriv", "record", "input", "that", "will", "ensur", "newli", "arriv", "data", "dispatch", "thi", "fix", "448", "small", "fix", "reason", "comment", "adjust", "test", "act", "more", "like", "shardconsum", "shard", "consum", "shardconsuemr", "shard", "consuemr", "which", "princip", "user", "prefetchrecordspublish", "prefetch", "record", "publish", "use", "rxjava", "rx", "java", "consum", "publish", "thi", "test", "use", "rxjava", "rx", "java", "consum", "notifi", "test", "thread", "onc", "max", "item", "have", "been", "receiv", "thi", "ensur", "that", "we", "cycl", "through", "queue", "at", "least", "time", "remov", "upper", "limit", "retriev", "way", "rxjava", "rx", "java", "request", "manag", "make", "it", "possibl", "that", "more", "request", "than", "we", "might", "expect", "happen"]},
{"A_title": "PackageMapper - Could not resolve classIt seems that the PackageMapper try to resolve much more than it is supposed to do for instance if Ive 2 pages test1/TestPage1 and test2/TestPage2 then it tries to resolve test2/TestPage1 when I reach the page1...   WARN  - WicketObjects              - Could not resolve class com.mycompany.test2.TestPage1 java.lang.ClassNotFoundException: com.mycompany.test2.TestPage1     at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1714)     at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1559)     at java.lang.Class.forName0(Native Method)     at java.lang.Class.forName(Class.java:270)     at org.apache.wicket.application.AbstractClassResolver.resolveClass(AbstractClassResolver.java:108)     at org.apache.wicket.core.util.lang.WicketObjects.resolveClass(WicketObjects.java:71)     at org.apache.wicket.core.request.mapper.AbstractComponentMapper.getPageClass(AbstractComponentMapper.java:134)     at org.apache.wicket.core.request.mapper.PackageMapper.parseRequest(PackageMapper.java:152)     at org.apache.wicket.core.request.mapper.AbstractBookmarkableMapper.mapRequest(AbstractBookmarkableMapper.java:322)     at org.apache.wicket.request.mapper.CompoundRequestMapper.mapRequest(CompoundRequestMapper.java:152)     at org.apache.wicket.request.cycle.RequestCycle.resolveRequestHandler(RequestCycle.java:189)     at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:219)     at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:293)     at org.apache.wicket.protocol.http.WicketFilter.processRequestCycle(WicketFilter.java:261)     at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:203)     at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:284)", "A_clean_title": ["packagemapp", "packag", "mapper", "could", "not", "resolv", "classit", "class", "it", "seem", "that", "packagemapp", "packag", "mapper", "tri", "resolv", "much", "more", "than", "it", "suppos", "instanc", "ive", "page", "test1", "testpage1", "test", "page1", "test2", "testpage2", "test", "page2", "then", "it", "tri", "resolv", "test2", "testpage1", "test", "page1", "when", "reach", "page1", "warn", "wicketobject", "wicket", "object", "could", "not", "resolv", "class", "com", "mycompani", "test2", "testpage1", "test", "page1", "java", "lang", "classnotfoundexcept", "class", "not", "found", "except", "com", "mycompani", "test2", "testpage1", "test", "page1", "at", "org", "apach", "catalina", "loader", "webappclassload", "loadclass", "webapp", "class", "loader", "load", "class", "webappclassload", "java:1714", "webapp", "class", "loader", "at", "org", "apach", "catalina", "loader", "webappclassload", "loadclass", "webapp", "class", "loader", "load", "class", "webappclassload", "java:1559", "webapp", "class", "loader", "at", "java", "lang", "class", "forname0", "name0", "nativ", "method", "at", "java", "lang", "class", "fornam", "name", "class", "java:270", "at", "org", "apach", "wicket", "applic", "abstractclassresolv", "resolveclass", "abstract", "class", "resolv", "resolv", "class", "abstractclassresolv", "java:108", "abstract", "class", "resolv", "at", "org", "apach", "wicket", "core", "util", "lang", "wicketobject", "resolveclass", "wicket", "object", "resolv", "class", "wicketobject", "java:71", "wicket", "object", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractcomponentmapp", "getpageclass", "abstract", "compon", "mapper", "get", "page", "class", "abstractcomponentmapp", "java:134", "abstract", "compon", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "packagemapp", "parserequest", "packag", "mapper", "pars", "request", "packagemapp", "java:152", "packag", "mapper", "at", "org", "apach", "wicket", "core", "request", "mapper", "abstractbookmarkablemapp", "maprequest", "abstract", "bookmark", "mapper", "map", "request", "abstractbookmarkablemapp", "java:322", "abstract", "bookmark", "mapper", "at", "org", "apach", "wicket", "request", "mapper", "compoundrequestmapp", "maprequest", "compound", "request", "mapper", "map", "request", "compoundrequestmapp", "java:152", "compound", "request", "mapper", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "resolverequesthandl", "request", "cycl", "resolv", "request", "handler", "requestcycl", "java:189", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:219", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:293", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequestcycl", "wicket", "filter", "process", "request", "cycl", "wicketfilt", "java:261", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:203", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:284", "wicket", "filter"], "B_title": "PackageMapper - Could not resolve class", "B_clean_title": ["packagemapp", "packag", "mapper", "could", "not", "resolv", "class"]},
{"A_title": "NEW VALUE is not a valid Serializable error during ajax form submissionI attached a quickstart with a test in TestHomePage#formSubmitsSuccessfully.  The test throws NEW VALUE is not a valid Serializable error when NEW VALUE string in value textField is submitted as a part of myForm ajax submission.  The problem is that a call to Objects#convertValue(nonNullNonArrayValue Object.class) will always return null if nonNullNonArrayValue is a value that is not null and not an array! Shouldnt it always return the first parameter when the second parameter is Object.class?  Sven on Wicket forum suggested to fix this as by adding another if-statement in Objects#convertValue() if (toType.isInstance(value))    result = toType.cast(value);   See the following forum thread for more information http://apache-wicket.1842946.n4.nabble.com/Issues-with-default-type-conversion-in-1-5-td4651857.html", "A_clean_title": ["new", "valu", "not", "valid", "serializ", "error", "dure", "ajax", "form", "submissioni", "submiss", "attach", "quickstart", "test", "testhomepag", "test", "home", "page", "formsubmitssuccess", "form", "submit", "success", "test", "throw", "new", "valu", "not", "valid", "serializ", "error", "when", "new", "valu", "string", "valu", "textfield", "text", "field", "submit", "as", "part", "myform", "my", "form", "ajax", "submiss", "problem", "that", "call", "object", "convertvalu", "convert", "valu", "nonnullnonarrayvalu", "non", "null", "non", "array", "valu", "object", "class", "will", "alway", "return", "null", "nonnullnonarrayvalu", "non", "null", "non", "array", "valu", "valu", "that", "not", "null", "not", "array", "shouldnt", "it", "alway", "return", "first", "paramet", "when", "second", "paramet", "object", "class", "sven", "wicket", "forum", "suggest", "fix", "thi", "as", "by", "ad", "anoth", "statement", "object", "convertvalu", "convert", "valu", "totyp", "isinst", "type", "instanc", "valu", "result", "totyp", "cast", "type", "valu", "see", "follow", "forum", "thread", "more", "inform", "http", "default", "type", "convers", "apach", "wicket", "1842946", "n4", "nabbl", "td4651857", "html", "com", "issu"], "B_title": "cast if possible", "B_clean_title": ["cast", "possibl"]}]