[{"A_title": "Fix and then deprecate isSupportXxxInclusive in RealDistribution interfaceThe conclusion from 1 was never implemented. We should deprecate these properties from the RealDistribution interface but since removal will have to wait until 4.0 we should agree on a precise definition and fix the code to match it in the mean time. The definition that I propose is that isSupportXxxInclusive means that when the density function is applied to the upper or lower bound of support returned by getSupportXxxBound a finite (i.e. not infinite) not NaN value is returned. 1 http://markmail.org/message/dxuxh7eybl7xejde", "A_clean_title": ["fix", "then", "deprec", "issupportxxxinclus", "support", "xxx", "inclus", "realdistribut", "real", "distribut", "interfaceth", "interfac", "conclus", "wa", "never", "implement", "we", "deprec", "these", "properti", "realdistribut", "real", "distribut", "interfac", "but", "sinc", "remov", "will", "have", "wait", "until", "we", "agre", "precis", "definit", "fix", "code", "match", "it", "mean", "time", "definit", "that", "propos", "that", "issupportxxxinclus", "support", "xxx", "inclus", "mean", "that", "when", "densiti", "function", "appli", "upper", "or", "lower", "bound", "support", "return", "by", "getsupportxxxbound", "get", "support", "xxx", "bound", "finit", "not", "infinit", "not", "nan", "na", "valu", "return", "http", "markmail", "org", "messag", "dxuxh7eybl7xejd"], "B_title": "support lower bound in FDistribution. Fix UniformRealDistribution . isSupportUpperBoundInclusive. ", "B_clean_title": ["support", "lower", "bound", "fdistribut", "distribut", "fix", "uniformrealdistribut", "uniform", "real", "distribut", "issupportupperboundinclus", "support", "upper", "bound", "inclus"]},
{"A_title": "Fix and then deprecate isSupportXxxInclusive in RealDistribution interfaceThe conclusion from 1 was never implemented. We should deprecate these properties from the RealDistribution interface but since removal will have to wait until 4.0 we should agree on a precise definition and fix the code to match it in the mean time. The definition that I propose is that isSupportXxxInclusive means that when the density function is applied to the upper or lower bound of support returned by getSupportXxxBound a finite (i.e. not infinite) not NaN value is returned. 1 http://markmail.org/message/dxuxh7eybl7xejde", "A_clean_title": ["fix", "then", "deprec", "issupportxxxinclus", "support", "xxx", "inclus", "realdistribut", "real", "distribut", "interfaceth", "interfac", "conclus", "wa", "never", "implement", "we", "deprec", "these", "properti", "realdistribut", "real", "distribut", "interfac", "but", "sinc", "remov", "will", "have", "wait", "until", "we", "agre", "precis", "definit", "fix", "code", "match", "it", "mean", "time", "definit", "that", "propos", "that", "issupportxxxinclus", "support", "xxx", "inclus", "mean", "that", "when", "densiti", "function", "appli", "upper", "or", "lower", "bound", "support", "return", "by", "getsupportxxxbound", "get", "support", "xxx", "bound", "finit", "not", "infinit", "not", "nan", "na", "valu", "return", "http", "markmail", "org", "messag", "dxuxh7eybl7xejd"], "B_title": "UniformRealDistribution copy ( ). ", "B_clean_title": ["uniformrealdistribut", "uniform", "real", "distribut", "copi"]},
{"A_title": "NaN in equals methodsIn MathUtils some equals methods will return true if both argument are NaN. Unless Im mistaken this contradicts the IEEE standard. If nobody objects Im going to make the changes.", "A_clean_title": ["nan", "na", "equal", "methodsin", "method", "mathutil", "math", "util", "some", "equal", "method", "will", "return", "true", "both", "argument", "are", "nan", "na", "unless", "im", "mistaken", "thi", "contradict", "ieee", "standard", "nobodi", "object", "im", "go", "make", "chang"], "B_title": "Fix a bug in MathUtils . equals ( double  double  int ). ", "B_clean_title": ["fix", "bug", "mathutil", "math", "util", "equal", "doubl", "doubl", "int"]},
{"A_title": "NaN in equals methodsIn MathUtils some equals methods will return true if both argument are NaN. Unless Im mistaken this contradicts the IEEE standard. If nobody objects Im going to make the changes.", "A_clean_title": ["nan", "na", "equal", "methodsin", "method", "mathutil", "math", "util", "some", "equal", "method", "will", "return", "true", "both", "argument", "are", "nan", "na", "unless", "im", "mistaken", "thi", "contradict", "ieee", "standard", "nobodi", "object", "im", "go", "make", "chang"], "B_title": "Fix MathUtils . equals ( double  double  int ). ", "B_clean_title": ["fix", "mathutil", "math", "util", "equal", "doubl", "doubl", "int"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Fix try / catch in minimizeExitPoints. ", "B_clean_title": ["fix", "tri", "catch", "minimizeexitpoint", "minim", "exit", "point"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Remove  finally  keyword from  try / rescue . ", "B_clean_title": ["remov", "final", "keyword", "tri", "rescu"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Fix tryMinimizeExitPoints. ", "B_clean_title": ["fix", "tryminimizeexitpoint", "tri", "minim", "exit", "point"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Fix tryMinimizeExits. ", "B_clean_title": ["fix", "tryminimizeexit", "tri", "minim", "exit"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Remove tryMinimizeExits from tryMinimizeExits. ", "B_clean_title": ["remov", "tryminimizeexit", "tri", "minim", "exit", "tryminimizeexit", "tri", "minim", "exit"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Improve program minimization. ", "B_clean_title": ["improv", "program", "minim"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "try minimize exits on finally blocks. ", "B_clean_title": ["tri", "minim", "exit", "final", "block"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Remove tryMinimizeExits from tryMinimizeExits. ", "B_clean_title": ["remov", "tryminimizeexit", "tri", "minim", "exit", "tryminimizeexit", "tri", "minim", "exit"]},
{"A_title": "Wrong code generated if mixing types in ternary operatorNone", "A_clean_title": ["wrong", "code", "gener", "mix", "type", "ternari", "operatornon", "oper", "none"], "B_title": "Remove mayBeStringHelper from matchAll. ", "B_clean_title": ["remov", "maybestringhelp", "may", "string", "helper", "matchal", "match", "all"]},
{"A_title": "Inconsistent interpretation of ambiguous time during DSTThe inconsistency appears for timezone Europe/London.  These three DateTime objects should all represent the same moment in time even if they are ambiguous. Now it always returns the earlier instant (summer time) during an overlap.", "A_clean_title": ["inconsist", "interpret", "ambigu", "time", "dure", "dstthe", "dst", "inconsist", "appear", "timezon", "europ", "london", "these", "three", "datetim", "date", "time", "object", "all", "repres", "same", "moment", "time", "even", "they", "are", "ambigu", "now", "it", "alway", "return", "earlier", "instant", "summer", "time", "dure", "overlap"], "B_title": "fixed typo .. ", "B_clean_title": ["fix", "typo"]},
{"A_title": "Inconsistent interpretation of ambiguous time during DSTThe inconsistency appears for timezone Europe/London.  These three DateTime objects should all represent the same moment in time even if they are ambiguous. Now it always returns the earlier instant (summer time) during an overlap.", "A_clean_title": ["inconsist", "interpret", "ambigu", "time", "dure", "dstthe", "dst", "inconsist", "appear", "timezon", "europ", "london", "these", "three", "datetim", "date", "time", "object", "all", "repres", "same", "moment", "time", "even", "they", "are", "ambigu", "now", "it", "alway", "return", "earlier", "instant", "summer", "time", "dure", "overlap"], "B_title": "Added transition marker. ", "B_clean_title": ["ad", "transit", "marker"]},
{"A_title": "Inconsistent interpretation of ambiguous time during DSTThe inconsistency appears for timezone Europe/London.  These three DateTime objects should all represent the same moment in time even if they are ambiguous. Now it always returns the earlier instant (summer time) during an overlap.", "A_clean_title": ["inconsist", "interpret", "ambigu", "time", "dure", "dstthe", "dst", "inconsist", "appear", "timezon", "europ", "london", "these", "three", "datetim", "date", "time", "object", "all", "repres", "same", "moment", "time", "even", "they", "are", "ambigu", "now", "it", "alway", "return", "earlier", "instant", "summer", "time", "dure", "overlap"], "B_title": "fixed typo .. ", "B_clean_title": ["fix", "typo"]},
{"A_title": "smartNameRemoval causing compiler crashNone", "A_clean_title": ["smartnameremov", "smart", "name", "remov", "caus", "compil", "crashnon", "crash", "none"], "B_title": "Fix dead code. ", "B_clean_title": ["fix", "dead", "code"]},
{"A_title": "@const dumps type cast informationNone", "A_clean_title": ["const", "dump", "type", "cast", "informationnon", "inform", "none"], "B_title": "When declaring @const vars initialized to a type-casted value prefer the type-cast as the declared type. fixes issue 688", "B_clean_title": ["when", "declar", "const", "var", "initi", "type", "cast", "valu", "prefer", "type", "cast", "as", "declar", "type", "fix", "issu", "688"]},
{"A_title": "HttpSession getSession() in MockHttpServletRequest is not compliant with the j2ee servlet specThe implementation of httpRequest.getSession(); for MockHttpServletRequest seems not correct since it can return null when the servler api specs (http://docs.oracle.com/javaee/1.4/api/) says:  public HttpSession getSession() Returns the current session associated with this request or if the request does not have a session creates one.  So as far as I understand httpRequest.getSession(); and httpRequest.getSession(true); are equivalent  The MockHttpServletRequest implementation is     public HttpSession getSession()            if (session instanceof MockHttpSession && ((MockHttpSession)session).isTemporary())                    return null;                return session;      I think it should be     public HttpSession getSession()            return getSession(true);", "A_clean_title": ["httpsession", "http", "session", "getsess", "get", "session", "mockhttpservletrequest", "mock", "http", "servlet", "request", "not", "compliant", "j2ee", "servlet", "specth", "spec", "implement", "httprequest", "getsess", "http", "request", "get", "session", "mockhttpservletrequest", "mock", "http", "servlet", "request", "seem", "not", "correct", "sinc", "it", "return", "null", "when", "servler", "api", "spec", "http", "oracl", "doc", "com", "javae", "api", "say", "public", "httpsession", "http", "session", "getsess", "get", "session", "return", "current", "session", "associ", "thi", "request", "or", "request", "not", "have", "session", "creat", "one", "so", "as", "far", "as", "understand", "httprequest", "getsess", "http", "request", "get", "session", "httprequest", "getsess", "http", "request", "get", "session", "true", "are", "equival", "mockhttpservletrequest", "mock", "http", "servlet", "request", "implement", "public", "httpsession", "http", "session", "getsess", "get", "session", "session", "instanceof", "mockhttpsess", "mock", "http", "session", "mockhttpsess", "mock", "http", "session", "session", "istemporari", "temporari", "return", "null", "return", "session", "think", "it", "public", "httpsession", "http", "session", "getsess", "get", "session", "return", "getsess", "get", "session", "true"], "B_title": "HttpSession getSession() in MockHttpServletRequest is not compliant with the j2ee servlet spec", "B_clean_title": ["httpsession", "http", "session", "getsess", "get", "session", "mockhttpservletrequest", "mock", "http", "servlet", "request", "not", "compliant", "j2ee", "servlet", "spec"]},
{"A_title": "RangeInputSplit doesnt serialize table nameFound another missed member in the serialization of RangeInputSplit: the table name.  Not a huge deal because the table information should still be in the Configuration for most users but this does break in advanced uses of mapreduce. Work around is to re-set the table in the RangeInputSplit in your overridden InputFormat.getRecordReader or make sure the Configuration is consistent from getRecordReader and getSplits.", "A_clean_title": ["rangeinputsplit", "rang", "input", "split", "doesnt", "serial", "tabl", "namefound", "name", "found", "anoth", "miss", "member", "serial", "rangeinputsplit", "rang", "input", "split", "tabl", "name", "not", "huge", "deal", "becaus", "tabl", "inform", "still", "configur", "most", "user", "but", "thi", "break", "advanc", "use", "mapreduc", "work", "around", "re", "set", "tabl", "rangeinputsplit", "rang", "input", "split", "your", "overridden", "inputformat", "getrecordread", "input", "format", "get", "record", "reader", "or", "make", "sure", "configur", "consist", "getrecordread", "get", "record", "reader", "getsplit", "get", "split"], "B_title": "Ensure table name is serialized in RangeInputSplit.", "B_clean_title": ["ensur", "tabl", "name", "serial", "rangeinputsplit", "rang", "input", "split"]},
{"A_title": "LevenburgMaquardt switched evaluation and iterationsNone", "A_clean_title": ["levenburgmaquardt", "levenburg", "maquardt", "switch", "evalu", "iterationsnon", "iter", "none"], "B_title": "Fix switched iterations and evaluations", "B_clean_title": ["fix", "switch", "iter", "evalu"]},
{"A_title": "EigenDecomposition.Solver should consider tiny values 0 for purposes of determining singularityEigenDecomposition.Solver tests for singularity by comparing eigenvalues to 0 for exact equality. Elsewhere in the class and in the code of course very small values are considered 0. This causes the solver to consider some singular matrices as non-singular.  The patch here includes a test as well showing the behavior -- the matrix is clearly singular but isnt considered as such since one eigenvalue are ~1e-14 rather than exactly 0.  (What I am not sure of is whether we should really be evaluating the *norm* of the imaginary eigenvalues rather than real/imag components separately. But the javadoc says the solver only supports real eigenvalues anyhow so its kind of moot since imag=0 for all eigenvalues.)", "A_clean_title": ["eigendecomposit", "solver", "eigen", "decomposit", "consid", "tini", "valu", "purpos", "determin", "singularityeigendecomposit", "solver", "singular", "eigen", "decomposit", "test", "singular", "by", "compar", "eigenvalu", "exact", "equal", "elsewher", "class", "code", "cours", "veri", "small", "valu", "are", "consid", "thi", "caus", "solver", "consid", "some", "singular", "matric", "as", "non", "singular", "patch", "here", "includ", "test", "as", "well", "show", "behavior", "matrix", "clearli", "singular", "but", "isnt", "consid", "as", "such", "sinc", "one", "eigenvalu", "are", "~1e", "14", "rather", "than", "exactli", "what", "am", "not", "sure", "whether", "we", "realli", "evalu", "norm", "imaginari", "eigenvalu", "rather", "than", "real", "imag", "compon", "separ", "but", "javadoc", "say", "solver", "onli", "support", "real", "eigenvalu", "anyhow", "so", "it", "kind", "moot", "sinc", "imag=0", "all", "eigenvalu"], "B_title": "Singular matrices were considered non-singular due to strict comparison with zero. Reported and fixed by Sean Owen.", "B_clean_title": ["singular", "matric", "were", "consid", "non", "singular", "due", "strict", "comparison", "zero", "report", "fix", "by", "sean", "owen"]},
{"A_title": "Fix and then deprecate isSupportXxxInclusive in RealDistribution interfaceThe conclusion from 1 was never implemented. We should deprecate these properties from the RealDistribution interface but since removal will have to wait until 4.0 we should agree on a precise definition and fix the code to match it in the mean time. The definition that I propose is that isSupportXxxInclusive means that when the density function is applied to the upper or lower bound of support returned by getSupportXxxBound a finite (i.e. not infinite) not NaN value is returned. 1 http://markmail.org/message/dxuxh7eybl7xejde", "A_clean_title": ["fix", "then", "deprec", "issupportxxxinclus", "support", "xxx", "inclus", "realdistribut", "real", "distribut", "interfaceth", "interfac", "conclus", "wa", "never", "implement", "we", "deprec", "these", "properti", "realdistribut", "real", "distribut", "interfac", "but", "sinc", "remov", "will", "have", "wait", "until", "we", "agre", "precis", "definit", "fix", "code", "match", "it", "mean", "time", "definit", "that", "propos", "that", "issupportxxxinclus", "support", "xxx", "inclus", "mean", "that", "when", "densiti", "function", "appli", "upper", "or", "lower", "bound", "support", "return", "by", "getsupportxxxbound", "get", "support", "xxx", "bound", "finit", "not", "infinit", "not", "nan", "na", "valu", "return", "http", "markmail", "org", "messag", "dxuxh7eybl7xejd"], "B_title": "Clarified definition of isSupportXxxBoundInclusive in RealDistribution interface made code consistent with the definition and deprecated these methods marking for removal in 4.0. JIRA: MATH-859", "B_clean_title": ["clarifi", "definit", "issupportxxxboundinclus", "support", "xxx", "bound", "inclus", "realdistribut", "real", "distribut", "interfac", "made", "code", "consist", "definit", "deprec", "these", "method", "mark", "remov", "jira", "math", "859"]},
{"A_title": "Stat calculation of STDEV may be inaccurateThe math is sound but it is susceptible to rounding errors. We should address that.  See http://www.strchr.com/standard_deviation_in_one_pass and http://www.cs.berkeley.edu/~mhoemmen/cs194/Tutorials/variance.pdf", "A_clean_title": ["stat", "calcul", "stdev", "may", "inaccurateth", "inaccur", "math", "sound", "but", "it", "suscept", "round", "error", "we", "address", "that", "see", "http", "strchr", "www", "deviat", "one", "pass", "com", "standard", "http", "cs", "berkeley", "pdf", "www", "edu", "~mhoemmen", "cs194", "tutori", "varianc"], "B_title": "Delegate math to commons-math", "B_clean_title": ["deleg", "math", "common", "math"]},
{"A_title": "ClassGeneratingPropertyAccessorFactory needs custom ClassLoader for defineClass() DATACMNS-1422opened and commented The  ClassGeneratingPropertyAccessorFactory fails to generate classes in an OSGi environment where the ClassLoader for the model project the store implementation and Spring Data is different. Here is the error we are facing:  The problem seems to be that  PropertyAccessorClassGenerator.generateBytecode() adds the interface PersistentPropertyAccessor which lives in Spring Data. In generateCustomAccessorClass() the ClassLoader of the model entity is used. Therefore the ClassLoader of the custom model project needs access to all classes which are added by the factory (especially the package org.springframework.data.mapping ). To resolve this problem a child ClassLoader of the entity should be used that is able to access both projects: Spring Data and the custom entity model. Else this has to fail because different classes are mixed which cannot be accessed by a single ClassLoader    Affects: 2.1.2 (Lovelace SR2)  Attachments:      Referenced from: pull request #324  Backported to:  2.1.3 (Lovelace SR3)", "A_clean_title": ["classgeneratingpropertyaccessorfactori", "class", "gener", "properti", "accessor", "factori", "need", "custom", "classload", "class", "loader", "defineclass", "defin", "class", "datacmn", "1422open", "comment", "classgeneratingpropertyaccessorfactori", "class", "gener", "properti", "accessor", "factori", "fail", "gener", "class", "osgi", "os", "gi", "environ", "where", "classload", "class", "loader", "model", "project", "store", "implement", "spring", "data", "differ", "here", "error", "we", "are", "face", "problem", "seem", "that", "propertyaccessorclassgener", "generatebytecod", "properti", "accessor", "class", "gener", "gener", "bytecod", "add", "interfac", "persistentpropertyaccessor", "persist", "properti", "accessor", "which", "live", "spring", "data", "generatecustomaccessorclass", "gener", "custom", "accessor", "class", "classload", "class", "loader", "model", "entiti", "use", "therefor", "classload", "class", "loader", "custom", "model", "project", "need", "access", "all", "class", "which", "are", "ad", "by", "factori", "especi", "packag", "org", "springframework", "data", "map", "resolv", "thi", "problem", "child", "classload", "class", "loader", "entiti", "use", "that", "abl", "access", "both", "project", "spring", "data", "custom", "entiti", "model", "thi", "ha", "fail", "becaus", "differ", "class", "are", "mix", "which", "not", "access", "by", "singl", "classload", "class", "loader", "affect", "lovelac", "sr2", "attach", "referenc", "pull", "request", "324", "backport", "lovelac", "sr3"], "B_title": "DATACMNS-1422 - Fall back to reflection-based PropertyAccessor/EntityInstantiator on inaccessible framework types.  We now fall back to reflection-based PropertyAccessor/EntityInstantiator strategies when framework types are not visible by the entitys ClassLoader.  Typically we use class generation to create and load PropertyAccessor and EntityInstantiator classes to bypass reflection. Generated types are injected into the ClassLoader that has loaded the actual entity. Generated classes implement framework types such as ObjectInstantiator and these interfaces must be visible to the ClassLoader that hosts the generated class. Some arrangements such as OSGi isolate class repositories so the OSGi class loader cannot load our own types which prevents loading the generated class.  Original pull request: #324.", "B_clean_title": ["datacmn", "1422", "fall", "back", "reflect", "base", "propertyaccessor", "entityinstanti", "properti", "accessor", "entiti", "instanti", "inaccess", "framework", "type", "we", "now", "fall", "back", "reflect", "base", "propertyaccessor", "entityinstanti", "properti", "accessor", "entiti", "instanti", "strategi", "when", "framework", "type", "are", "not", "visibl", "by", "entiti", "classload", "class", "loader", "typic", "we", "use", "class", "gener", "creat", "load", "propertyaccessor", "properti", "accessor", "entityinstanti", "entiti", "instanti", "class", "bypass", "reflect", "gener", "type", "are", "inject", "into", "classload", "class", "loader", "that", "ha", "load", "actual", "entiti", "gener", "class", "implement", "framework", "type", "such", "as", "objectinstanti", "object", "instanti", "these", "interfac", "must", "visibl", "classload", "class", "loader", "that", "host", "gener", "class", "some", "arrang", "such", "as", "osgi", "os", "gi", "isol", "class", "repositori", "so", "osgi", "os", "gi", "class", "loader", "not", "load", "our", "own", "type", "which", "prevent", "load", "gener", "class", "origin", "pull", "request", "324"]},
{"A_title": "DefaultLoadBalancer takes a long time when tablets are highly unbalancedAfter creating a thousand splits on a large cluster I noticed the master was only moving tablets to one server at a time.", "A_clean_title": ["defaultloadbalanc", "default", "load", "balanc", "take", "long", "time", "when", "tablet", "are", "highli", "unbalancedaft", "unbalanc", "after", "creat", "thousand", "split", "larg", "cluster", "notic", "master", "wa", "onli", "move", "tablet", "one", "server", "at", "time"], "B_title": "keep better info on what tablet counts will be after balancing", "B_clean_title": ["keep", "better", "info", "what", "tablet", "count", "will", "after", "balanc"]},
{"A_title": "WicketSessionFilter and HttpSessionStore use different attribute name for Wicket Sessionfrom this topic  http://apache-wicket.1842946.n4.nabble.com/WicketSessionFilter-and-ignorePaths-in-WicketFilter-td3570291.html Please look at the second post (the ignorePaths param is not linked with this issue as the title suggests).  How to reproduce with the quickstart: 1. open localhost:8080 - a wicket test page is displayed. 2. open localhost:8080/external - this is the external servlet that tries to access the wicket session. An exception is thrown.", "A_clean_title": ["wicketsessionfilt", "wicket", "session", "filter", "httpsessionstor", "http", "session", "store", "use", "differ", "attribut", "name", "wicket", "sessionfrom", "thi", "topic", "http", "ignorepath", "wicketfilt", "apach", "wicket", "1842946", "n4", "nabbl", "ignor", "path", "wicket", "filter", "td3570291", "html", "com", "wicketsessionfilt", "wicket", "session", "filter", "pleas", "look", "at", "second", "post", "ignorepath", "ignor", "path", "param", "not", "link", "thi", "issu", "as", "titl", "suggest", "how", "reproduc", "quickstart", "open", "localhost:8080", "wicket", "test", "page", "display", "open", "localhost:8080", "extern", "thi", "extern", "servlet", "that", "tri", "access", "wicket", "session", "except", "thrown"], "B_title": "WicketSessionFilter and HttpSessionStore use different attribute name for Wicket Session", "B_clean_title": ["wicketsessionfilt", "wicket", "session", "filter", "httpsessionstor", "http", "session", "store", "use", "differ", "attribut", "name", "wicket", "session"]},
{"A_title": "Do not use the parsed PageParameters when re-creating an expired pageWICKET-4014 and WICKET-4290 provided functionality to re-create an expired page if there is a mount path in the current requests url. There is a minor problem with that because the page parameters are passed to the freshly created page. I.e. parameters for a callback behavior are now set as page construction parameters. Since the execution of the behavior is ignored for the recreated page these parameters should be ignored too.", "A_clean_title": ["not", "use", "pars", "pageparamet", "page", "paramet", "when", "re", "creat", "expir", "pagewicket", "4014", "page", "wicket", "wicket", "4290", "provid", "function", "re", "creat", "expir", "page", "there", "mount", "path", "current", "request", "url", "there", "minor", "problem", "that", "becaus", "page", "paramet", "are", "pass", "freshli", "creat", "page", "paramet", "callback", "behavior", "are", "now", "set", "as", "page", "construct", "paramet", "sinc", "execut", "behavior", "ignor", "recreat", "page", "these", "paramet", "ignor", "too"], "B_title": "Do not use the parsed PageParameters when re-creating an expired page", "B_clean_title": ["not", "use", "pars", "pageparamet", "page", "paramet", "when", "re", "creat", "expir", "page"]},
{"A_title": "Session should be bound when adding messages to itWhen using the Sessions info() error() and success() methods and the session is temporary the messages can be dropped silently. This happens when on stateless pages and a redirect happens in the same request during which a session message is added.  The fix for this could be to make sure the session is bound and call Session#bind() automatically when a session message is added.  Email thread: http://wicket-users.markmail.org/thread/zd72s4gwnlp5d7ch", "A_clean_title": ["session", "bound", "when", "ad", "messag", "itwhen", "it", "when", "session", "info", "error", "success", "method", "session", "temporari", "messag", "drop", "silent", "thi", "happen", "when", "stateless", "page", "redirect", "happen", "same", "request", "dure", "which", "session", "messag", "ad", "fix", "thi", "could", "make", "sure", "session", "bound", "call", "session", "bind", "automat", "when", "session", "messag", "ad", "email", "thread", "http", "wicket", "user", "markmail", "org", "thread", "zd72s4gwnlp5d7ch"], "B_title": "Session should be bound when adding messages to it", "B_clean_title": ["session", "bound", "when", "ad", "messag", "it"]},
{"A_title": "MongoMK: split documents when they are too largeCurrently the MongoMK stores all revisions of a node in the same document. Once there are many revisions the document gets very large.  The plan is to split the document when it gets big.  It looks like this isnt just a nice to have but also a problem for some use cases. Example stack trace:  code 21.07.2013 12:35:47.554 *ERROR* ... Caused by: java.lang.IllegalArgumentException: ok should never be null... at com.mongodb.CommandResult.ok(CommandResult.java:48) at com.mongodb.DBCollection.findAndModify(DBCollection.java:375) at org.apache.jackrabbit.oak.plugins.mongomk.MongoDocumentStore.findAndModify(MongoDocumentStore.java:302) ... 32 more code  at the same time in the MongoDB log:  code Sun Jul 21 12:35:47.334 conn7 warning: log line attempted (159k) over max size(10k)  printing beginning and end ...  Assertion: 10334:BSONObj size: 16795219 (0x53460001) is invalid.  Size must be between 0 and 16793600(16MB)  First element: :childOrder:  r1400279f22d-0-1:  ... code", "A_clean_title": ["mongomk", "mongo", "mk", "split", "document", "when", "they", "are", "too", "largecurr", "larg", "current", "mongomk", "mongo", "mk", "store", "all", "revis", "node", "same", "document", "onc", "there", "are", "mani", "revis", "document", "get", "veri", "larg", "plan", "split", "document", "when", "it", "get", "big", "it", "look", "like", "thi", "isnt", "just", "nice", "have", "but", "also", "problem", "some", "use", "case", "exampl", "stack", "trace", "code", "21", "07", "2013", "12:35:47", "554", "error", "caus", "by", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "ok", "never", "null", "at", "com", "mongodb", "commandresult", "ok", "command", "result", "commandresult", "java:48", "command", "result", "at", "com", "mongodb", "dbcollect", "findandmodifi", "db", "collect", "find", "modifi", "dbcollect", "java:375", "db", "collect", "at", "org", "apach", "jackrabbit", "oak", "plugin", "mongomk", "mongodocumentstor", "findandmodifi", "mongo", "document", "store", "find", "modifi", "mongodocumentstor", "java:302", "mongo", "document", "store", "32", "more", "code", "at", "same", "time", "mongodb", "mongo", "db", "log", "code", "sun", "jul", "21", "12:35:47", "334", "conn7", "warn", "log", "line", "attempt", "159k", "over", "max", "size", "10k", "print", "begin", "end", "assert", "10334", "bsonobj", "bson", "obj", "size", "16795219", "0x53460001", "invalid", "size", "must", "between", "16793600", "16mb", "first", "element", "childord", "child", "order", "r1400279f22d", "code"], "B_title": "MongoMK: split documents when they are too large - Parse PREVIOUS into Revision/Range on demand - More tests", "B_clean_title": ["mongomk", "mongo", "mk", "split", "document", "when", "they", "are", "too", "larg", "pars", "previou", "into", "revis", "rang", "demand", "more", "test"]},
{"A_title": "FastMath.exp may return NaN for non-NaN argumentsI have observed that FastMath.exp(709.8125) returns NaN. However the exponential function must never return NaN (if the argument is not NaN). The result must always be non-negative or positive infinity.", "A_clean_title": ["fastmath", "exp", "fast", "math", "may", "return", "nan", "na", "non", "nan", "na", "argumentsi", "argument", "have", "observ", "that", "fastmath", "exp", "fast", "math", "709", "8125", "return", "nan", "na", "howev", "exponenti", "function", "must", "never", "return", "nan", "na", "argument", "not", "nan", "na", "result", "must", "alway", "non", "neg", "or", "posit", "infin"], "B_title": "fixed FastMath.exp returning NaN for non-NaN arguments", "B_clean_title": ["fix", "fastmath", "exp", "fast", "math", "return", "nan", "na", "non", "nan", "na", "argument"]},
{"A_title": "inverseCumulativeDistribution fails with cumulative distribution having a plateauThis bug report follows MATH-692. The attached unit test fails. As required by the definition in MATH-692 the lower-bound of the interval on which the cdf is constant should be returned. This is not so at the moment.", "A_clean_title": ["inversecumulativedistribut", "invers", "cumul", "distribut", "fail", "cumul", "distribut", "have", "plateauthi", "plateau", "thi", "bug", "report", "follow", "math", "692", "attach", "unit", "test", "fail", "as", "requir", "by", "definit", "math", "692", "lower", "bound", "interv", "which", "cdf", "constant", "return", "thi", "not", "so", "at", "moment"], "B_title": "New implementation of AbstractRealDistribution.inverseCumulativeProbability(double). Solves MATH-699 and leads to slightly smaller execution times.", "B_clean_title": ["new", "implement", "abstractrealdistribut", "inversecumulativeprob", "abstract", "real", "distribut", "invers", "cumul", "probabl", "doubl", "solv", "math", "699", "lead", "slightli", "smaller", "execut", "time"]},
{"A_title": "Checkpoint stats show ghost numbers~StephanEwen reported an issue with the display of checkpoint stats. A pipeline with a stateful source and stateless intermediate operator shows stats for the stateless intermediate operator. The numbers are most likely the same as for the source operator.", "A_clean_title": ["checkpoint", "stat", "show", "ghost", "numbers~stephanewen", "numbers~stephan", "ewen", "report", "issu", "display", "checkpoint", "stat", "pipelin", "state", "sourc", "stateless", "intermedi", "oper", "show", "stat", "stateless", "intermedi", "oper", "number", "are", "most", "like", "same", "as", "sourc", "oper"], "B_title": "runtime Return empty stats for unknown operator", "B_clean_title": ["runtim", "return", "empti", "stat", "unknown", "oper"]},
{"A_title": "Ajax behavior on component with setRenderBodyOnly(true) dont get called - improve warningWhen you put AJAX behavior on component with setRenderBodyOnly(true) and try to call it with callback script it wont get called and no error / warning is displayed. See attached quickstart sample. Just unzipp and run with: mvn jetty:run  Navigate browser to http://localhost:8080/ When you try to click on labels AJAX behavior should get called. But it wont. This kind of behavior is correct (i assume). But i think user should be warned that behavior cant be called. I think proper place is somewhere on server side? But I dont know where exactly put the warning.  Now only message is in Wicket Ajax Debug window - Ajax request stopped because of precondition check. I had to debug wicket javascript to find what precondition check failed. Maybe more detailed message in default precondition check would be useful too?", "A_clean_title": ["ajax", "behavior", "compon", "setrenderbodyonli", "set", "render", "bodi", "onli", "true", "dont", "get", "call", "improv", "warningwhen", "warn", "when", "you", "put", "ajax", "behavior", "compon", "setrenderbodyonli", "set", "render", "bodi", "onli", "true", "tri", "call", "it", "callback", "script", "it", "wont", "get", "call", "no", "error", "warn", "display", "see", "attach", "quickstart", "sampl", "just", "unzipp", "run", "mvn", "jetti", "run", "navig", "browser", "http", "localhost:8080", "when", "you", "tri", "click", "label", "ajax", "behavior", "get", "call", "but", "it", "wont", "thi", "kind", "behavior", "correct", "assum", "but", "think", "user", "warn", "that", "behavior", "cant", "call", "think", "proper", "place", "somewher", "server", "side", "but", "dont", "know", "where", "exactli", "put", "warn", "now", "onli", "messag", "wicket", "ajax", "debug", "window", "ajax", "request", "stop", "becaus", "precondit", "check", "had", "debug", "wicket", "javascript", "find", "what", "precondit", "check", "fail", "mayb", "more", "detail", "messag", "default", "precondit", "check", "would", "use", "too"], "B_title": "dont request a groups markup since this will result in a log warning if the group does render its body only (the default) - formerly encoding of the groups markup id in the check/radios CSS class is no longer needed with WICKET-4797 anyway", "B_clean_title": ["dont", "request", "group", "markup", "sinc", "thi", "will", "result", "log", "warn", "group", "render", "it", "bodi", "onli", "default", "formerli", "encod", "group", "markup", "id", "check", "radio", "css", "class", "no", "longer", "need", "wicket", "4797", "anyway"]},
{"A_title": "Invalid left-hand side of assignment not detectedNone", "A_clean_title": ["invalid", "left", "hand", "side", "assign", "not", "detectednon", "detect", "none"], "B_title": "Dont let invalid LHS assignments to slip through. Fixes issue 215. Fixes issue 214.", "B_clean_title": ["dont", "let", "invalid", "lh", "assign", "slip", "through", "fix", "issu", "215", "fix", "issu", "214"]},
{"A_title": "FormTester throws an exception when a Palette component is added to a Form associated with a compound property modelFormTester throws an exception when a Palette component is added to a Form associated with a compound property model: org.apache.wicket.WicketRuntimeException: No get method defined for class ... expression: choices  It worked fine in Wicket 6.5.0 and works fine if the form is not associated with a compound property model.", "A_clean_title": ["formtest", "form", "tester", "throw", "except", "when", "palett", "compon", "ad", "form", "associ", "compound", "properti", "modelformtest", "model", "form", "tester", "throw", "except", "when", "palett", "compon", "ad", "form", "associ", "compound", "properti", "model", "org", "apach", "wicket", "wicketruntimeexcept", "wicket", "runtim", "except", "no", "get", "method", "defin", "class", "express", "choic", "it", "work", "fine", "wicket", "work", "fine", "form", "not", "associ", "compound", "properti", "model"], "B_title": "AbstractOptions does not use its model", "B_clean_title": ["abstractopt", "abstract", "option", "not", "use", "it", "model"]},
{"A_title": "Lucene index / compatVersion 2: search for a=b=c does not workSimilar to OAK-3879 we need to escape = (althoug lucene escape()|https://github.com/apache/lucene-solr/blob/releases/lucene-solr/4.7.1/lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/QueryParserBase.java#L988 apparently doesnt escape it).  Due to this searching for a=b=c throws parse exception from lucene query parser. Also searching for a=b gives incorrect result.", "A_clean_title": ["lucen", "index", "compatvers", "compat", "version", "search", "a=b=c", "not", "worksimilar", "work", "similar", "oak", "3879", "we", "need", "escap", "althoug", "lucen", "escap", "|http", "solr", "blob", "releas", "lucen", "java", "github", "com", "apach", "lucen", "solr", "lucen", "querypars", "src", "java", "org", "apach", "lucen", "querypars", "classic", "queryparserbas", "queri", "parser", "base", "l988", "appar", "doesnt", "escap", "it", "due", "thi", "search", "a=b=c", "throw", "pars", "except", "lucen", "queri", "parser", "also", "search", "a=b", "give", "incorrect", "result"], "B_title": "Lucene query fails if search string contains = symbol", "B_clean_title": ["lucen", "queri", "fail", "search", "string", "contain", "symbol"]},
{"A_title": "NPE when calling SubLine.intersection() with non-intersecting linesWhen calling SubLine.intersection() with two lines that not intersect then a NullPointerException is thrown in Line.toSubSpace(). This bug is in the twod and threed implementations.  The attached patch fixes both implementations and adds the required test cases.", "A_clean_title": ["npe", "when", "call", "sublin", "intersect", "sub", "line", "non", "intersect", "lineswhen", "line", "when", "call", "sublin", "intersect", "sub", "line", "two", "line", "that", "not", "intersect", "then", "nullpointerexcept", "null", "pointer", "except", "thrown", "line", "tosubspac", "sub", "space", "thi", "bug", "twod", "threed", "implement", "attach", "patch", "fix", "both", "implement", "add", "requir", "test", "case"], "B_title": "Fixed NullPointerException in 2D and 3D sub-line intersections.", "B_clean_title": ["fix", "nullpointerexcept", "null", "pointer", "except", "2d", "3d", "sub", "line", "intersect"]},
{"A_title": "CryptoMapper ignores original queryString parametersWhen an AjaxRequest with parameters (e.g.: Autocomplete.getChoices()) arrives and CryptoMapper decrypts it original queryString parameters dissapears.  Debugging CryptoMapper Ive checked that this method: private Url decryptUrl(final Request request final Url encryptedUrl)          ...   receives querystrings parameters (on field url.parameter from request parameter) and the new Url returned by the method never adds them to its own list.", "A_clean_title": ["cryptomapp", "crypto", "mapper", "ignor", "origin", "querystr", "queri", "string", "parameterswhen", "paramet", "when", "ajaxrequest", "ajax", "request", "paramet", "autocomplet", "getchoic", "get", "choic", "arriv", "cryptomapp", "crypto", "mapper", "decrypt", "it", "origin", "querystr", "queri", "string", "paramet", "dissapear", "debug", "cryptomapp", "crypto", "mapper", "ive", "check", "that", "thi", "method", "privat", "url", "decrypturl", "decrypt", "url", "final", "request", "request", "final", "url", "encryptedurl", "encrypt", "url", "receiv", "querystr", "paramet", "field", "url", "paramet", "request", "paramet", "new", "url", "return", "by", "method", "never", "add", "them", "it", "own", "list"], "B_title": "additional query parameters have to be added to the new url", "B_clean_title": ["addit", "queri", "paramet", "have", "ad", "new", "url"]},
{"A_title": "addDays(0) changes value of MutableDateTimeUpon DST transition from summer to winter time zone adding the amount of zero days to a mutable date time object changes the value of the object. The methods addMonths and addYears show the same problem; addSeconds addMinutes and addHours are ok.  I have tested with version 2.3. However if I repeat the test with Joda 1.5.2 the invocation of addDays(0) does not change the dates value.", "A_clean_title": ["addday", "add", "day", "chang", "valu", "mutabledatetimeupon", "mutabl", "date", "time", "upon", "dst", "transit", "summer", "winter", "time", "zone", "ad", "amount", "zero", "day", "mutabl", "date", "time", "object", "chang", "valu", "object", "method", "addmonth", "add", "month", "addyear", "add", "year", "show", "same", "problem", "addsecond", "add", "second", "addminut", "add", "minut", "addhour", "add", "hour", "are", "ok", "have", "test", "version", "howev", "repeat", "test", "joda", "invoc", "addday", "add", "day", "not", "chang", "date", "valu"], "B_title": "Adding zero no longer changes the offset during DST overlap", "B_clean_title": ["ad", "zero", "no", "longer", "chang", "offset", "dure", "dst", "overlap"]},
{"A_title": "discrepancy between JavaDoc and code in MarkupContainer#visitChildren()The JavaDoc for  MarkupContainer#visitChildren() states that  @param clazz The class of child to visit or null to visit all children  The parameter clazz is used to create a new ClassVisitFilter which in its visitObject() does not check for clazz == null leading to a NPE.", "A_clean_title": ["discrep", "between", "javadoc", "java", "doc", "code", "markupcontain", "markup", "contain", "visitchildren", "visit", "children", "javadoc", "java", "doc", "markupcontain", "markup", "contain", "visitchildren", "visit", "children", "state", "that", "param", "clazz", "class", "child", "visit", "or", "null", "visit", "all", "children", "paramet", "clazz", "use", "creat", "new", "classvisitfilt", "class", "visit", "filter", "which", "it", "visitobject", "visit", "object", "not", "check", "clazz", "null", "lead", "npe"], "B_title": "discrepancy between JavaDoc and code in MarkupContainer#visitChildren()", "B_clean_title": ["discrep", "between", "javadoc", "java", "doc", "code", "markupcontain", "markup", "contain", "visitchildren", "visit", "children"]},
{"A_title": "Custom Kryo Serializer fails in itertation scenarioWhen using iterations with a custom serializer for a domain object the iteration will fail.  code:java org.apache.flink.runtime.client.JobExecutionException: com.esotericsoftware.kryo.KryoException: Buffer underflow at org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.require(NoFetchingInput.java:76) at com.esotericsoftware.kryo.io.Input.readVarInt(Input.java:355) at com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:109) at com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:641) at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:752) at org.apache.flink.api.java.typeutils.runtime.KryoSerializer.deserialize(KryoSerializer.java:198) at org.apache.flink.api.java.typeutils.runtime.KryoSerializer.deserialize(KryoSerializer.java:203) at org.apache.flink.runtime.io.disk.InputViewIterator.next(InputViewIterator.java:43) at org.apache.flink.runtime.iterative.task.IterationHeadPactTask.streamOutFinalOutputBulk(IterationHeadPactTask.java:404) at org.apache.flink.runtime.iterative.task.IterationHeadPactTask.run(IterationHeadPactTask.java:377) at org.apache.flink.runtime.operators.RegularPactTask.invoke(RegularPactTask.java:360) at org.apache.flink.runtime.execution.RuntimeEnvironment.run(RuntimeEnvironment.java:204) at java.lang.Thread.run(Thread.java:745) code", "A_clean_title": ["custom", "kryo", "serial", "fail", "itert", "scenariowhen", "scenario", "when", "iter", "custom", "serial", "domain", "object", "iter", "will", "fail", "code", "java", "org", "apach", "flink", "runtim", "client", "jobexecutionexcept", "job", "execut", "except", "com", "esotericsoftwar", "kryo", "kryoexcept", "kryo", "except", "buffer", "underflow", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "nofetchinginput", "requir", "no", "fetch", "input", "nofetchinginput", "java:76", "no", "fetch", "input", "at", "com", "esotericsoftwar", "kryo", "io", "input", "readvarint", "read", "var", "int", "input", "java:355", "at", "com", "esotericsoftwar", "kryo", "util", "defaultclassresolv", "readclass", "default", "class", "resolv", "read", "class", "defaultclassresolv", "java:109", "default", "class", "resolv", "at", "com", "esotericsoftwar", "kryo", "kryo", "readclass", "read", "class", "kryo", "java:641", "at", "com", "esotericsoftwar", "kryo", "kryo", "readclassandobject", "read", "class", "object", "kryo", "java:752", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "kryoseri", "deseri", "kryo", "serial", "kryoseri", "java:198", "kryo", "serial", "at", "org", "apach", "flink", "api", "java", "typeutil", "runtim", "kryoseri", "deseri", "kryo", "serial", "kryoseri", "java:203", "kryo", "serial", "at", "org", "apach", "flink", "runtim", "io", "disk", "inputviewiter", "next", "input", "view", "iter", "inputviewiter", "java:43", "input", "view", "iter", "at", "org", "apach", "flink", "runtim", "iter", "task", "iterationheadpacttask", "streamoutfinaloutputbulk", "iter", "head", "pact", "task", "stream", "out", "final", "output", "bulk", "iterationheadpacttask", "java:404", "iter", "head", "pact", "task", "at", "org", "apach", "flink", "runtim", "iter", "task", "iterationheadpacttask", "run", "iter", "head", "pact", "task", "iterationheadpacttask", "java:377", "iter", "head", "pact", "task", "at", "org", "apach", "flink", "runtim", "oper", "regularpacttask", "invok", "regular", "pact", "task", "regularpacttask", "java:360", "regular", "pact", "task", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "run", "runtim", "environ", "runtimeenviron", "java:204", "runtim", "environ", "at", "java", "lang", "thread", "run", "thread", "java:745", "code"], "B_title": "runtime Adds proper EOFException forwarding to KryoSerializer.", "B_clean_title": ["runtim", "add", "proper", "eofexcept", "eof", "except", "forward", "kryoseri", "kryo", "serial"]},
{"A_title": "if statementNone", "A_clean_title": ["statementnon", "statement", "none"], "B_title": "Dont reorder if condition expressions if they contain side-effects. Fixes issue 925. ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=43060270", "B_clean_title": ["dont", "reorder", "condit", "express", "they", "contain", "side", "effect", "fix", "issu", "925", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=43060270"]},
{"A_title": "Parallel execution of SimpleSearchTest fails with MongoMKAt some point in the benchmark run one MongoMK instance will fail to read a node created by another instance. The exception is very similar to *E1* reported in OAK-1204.", "A_clean_title": ["parallel", "execut", "simplesearchtest", "simpl", "search", "test", "fail", "mongomkat", "mongo", "mk", "at", "some", "point", "benchmark", "run", "one", "mongomk", "mongo", "mk", "instanc", "will", "fail", "read", "node", "creat", "by", "anoth", "instanc", "except", "veri", "similar", "e1", "report", "oak", "1204"], "B_title": "Parallel execution of SimpleSearchTest fails with MongoMK - publish current head revision first to revision comparator - enable tests", "B_clean_title": ["parallel", "execut", "simplesearchtest", "simpl", "search", "test", "fail", "mongomk", "mongo", "mk", "publish", "current", "head", "revis", "first", "revis", "compar", "enabl", "test"]},
{"A_title": "Url.canonical() breaks when there are two consecutive parent segments followed by a normal segmentassertEquals(a/d Url.parse(a/b/c/../../d).canonical().getPath());   breaks with : Expected :a/d Actual   :a/b/../d", "A_clean_title": ["url", "canon", "break", "when", "there", "are", "two", "consecut", "parent", "segment", "follow", "by", "normal", "segmentassertequ", "segmentassert", "equal", "url", "pars", "canon", "getpath", "get", "path", "break", "expect", "actual"], "B_title": "Url.canonical() breaks when there are two consecutive parent segments followed by a normal segment", "B_clean_title": ["url", "canon", "break", "when", "there", "are", "two", "consecut", "parent", "segment", "follow", "by", "normal", "segment"]},
{"A_title": "File never picked up for replicationI was running some tests and noticed that a single file was getting ignored. The logs were warning that the Status message that was written to accumulo.metadata didnt have a createdTime on the Status record.  The odd part is that all other Status messages had a createdTime and were successfully replicated. Looking at the writes from the TabletServer logs the expected record *was* written by the TabletServer and writing a test with the full series of Status records written does net the correct Status (which was different than what was observed in the actual table).  Looking into it the log which was subject to this error was the first WAL that was used when the instance was started. Because the table configurations are lazily configured when they are actually used I believe that the StatusCombiner that is set on accumulo.metadata was not seen by the TabletServer and the VersioningIterator ate the first record.  I need to come up with a way that I can be sure that all tservers will have seen the Combiner set on accumulo.metadata before any data is written to it to avoid losing a record like this.", "A_clean_title": ["file", "never", "pick", "up", "replicationi", "replic", "wa", "run", "some", "test", "notic", "that", "singl", "file", "wa", "get", "ignor", "log", "were", "warn", "that", "statu", "messag", "that", "wa", "written", "accumulo", "metadata", "didnt", "have", "createdtim", "creat", "time", "statu", "record", "odd", "part", "that", "all", "other", "statu", "messag", "had", "createdtim", "creat", "time", "were", "success", "replic", "look", "at", "write", "tabletserv", "tablet", "server", "log", "expect", "record", "wa", "written", "by", "tabletserv", "tablet", "server", "write", "test", "full", "seri", "statu", "record", "written", "net", "correct", "statu", "which", "wa", "differ", "than", "what", "wa", "observ", "actual", "tabl", "look", "into", "it", "log", "which", "wa", "subject", "thi", "error", "wa", "first", "wal", "that", "wa", "use", "when", "instanc", "wa", "start", "becaus", "tabl", "configur", "are", "lazili", "configur", "when", "they", "are", "actual", "use", "believ", "that", "statuscombin", "statu", "combin", "that", "set", "accumulo", "metadata", "wa", "not", "seen", "by", "tabletserv", "tablet", "server", "versioningiter", "version", "iter", "ate", "first", "record", "need", "come", "up", "way", "that", "sure", "that", "all", "tserver", "will", "have", "seen", "combin", "set", "accumulo", "metadata", "befor", "ani", "data", "written", "it", "avoid", "lose", "record", "like", "thi"], "B_title": "Set StatusCombiner on accumulo.metadata during initialize.", "B_clean_title": ["set", "statuscombin", "statu", "combin", "accumulo", "metadata", "dure", "initi"]},
{"A_title": "new multivariate vector optimizers cannot be used with large number of weightsWhen using the Weigth class to pass a large number of weights to multivariate vector optimizers an nxn full matrix is created (and copied) when a n elements vector is used. This exhausts memory when n is large.  This happens for example when using curve fitters (even simple curve fitters like polynomial ones for low degree) with large number of points. I encountered this with curve fitting on 41200 points which created a matrix with 1.7 billion elements.", "A_clean_title": ["new", "multivari", "vector", "optim", "not", "use", "larg", "number", "weightswhen", "weight", "when", "weigth", "class", "pass", "larg", "number", "weight", "multivari", "vector", "optim", "nxn", "full", "matrix", "creat", "copi", "when", "element", "vector", "use", "thi", "exhaust", "memori", "when", "larg", "thi", "happen", "exampl", "when", "curv", "fitter", "even", "simpl", "curv", "fitter", "like", "polynomi", "one", "low", "degre", "larg", "number", "point", "encount", "thi", "curv", "fit", "41200", "point", "which", "creat", "matrix", "billion", "element"], "B_title": "Avoid memory exhaustion for large number of unclorrelated observations.", "B_clean_title": ["avoid", "memori", "exhaust", "larg", "number", "unclorrel", "observ"]},
{"A_title": "Accumulo Shell does not respect exit when executing fileIf there is an exit statement in the file given via accumulo shell -f file the execution seems to skip it and go on to the next command instead of terminating.  To recreate: noformat mike@home ~ cat bug.accumulo exit scan -np -t !METADATA mike@home ~ bin/accumulo shell -f /home/mike/bug.accumulo noformat  Expected output: None Actual output: A full scan of the !METADATA", "A_clean_title": ["accumulo", "shell", "not", "respect", "exit", "when", "execut", "fileif", "file", "there", "exit", "statement", "file", "given", "via", "accumulo", "shell", "file", "execut", "seem", "skip", "it", "go", "next", "command", "instead", "termin", "recreat", "noformat", "mike", "home", "cat", "bug", "accumulo", "exit", "scan", "np", "metadata", "mike", "home", "bin", "accumulo", "shell", "accumulo", "home", "mike", "bug", "noformat", "expect", "output", "none", "actual", "output", "full", "scan", "metadata"], "B_title": "merged patch to trunk", "B_clean_title": ["merg", "patch", "trunk"]},
{"A_title": "MarkupContainer.toString(true) fails with MarkupNotFoundException if the call is made in the component constructororg.apache.wicket.MarkupContainer.toString(boolean) uses if (getMarkup() != null) to decide whether to write something for the markup but since recently Component#getMarkup() throws MarkupNotFoundException when there is no markup and doesnt return null.", "A_clean_title": ["markupcontain", "tostr", "markup", "contain", "string", "true", "fail", "markupnotfoundexcept", "markup", "not", "found", "except", "call", "made", "compon", "constructororg", "apach", "wicket", "markupcontain", "tostr", "markup", "contain", "string", "boolean", "use", "getmarkup", "get", "markup", "null", "decid", "whether", "write", "someth", "markup", "but", "sinc", "recent", "compon", "getmarkup", "get", "markup", "throw", "markupnotfoundexcept", "markup", "not", "found", "except", "when", "there", "no", "markup", "doesnt", "return", "null"], "B_title": "MarkupContainer.toString(true) fails with MarkupNotFoundException if the call is made in the component constructor", "B_clean_title": ["markupcontain", "tostr", "markup", "contain", "string", "true", "fail", "markupnotfoundexcept", "markup", "not", "found", "except", "call", "made", "compon", "constructor"]},
{"A_title": "PageParametersEncoder should not decode parameters with no nameFrom dev@ mailing list: http://markmail.org/message/khuc2v37aakzyfth  PageParametersEncoder should ignore query parameters like &=& and &=value because they make no sene and lead to exceptions later at PageParameters#add() call.", "A_clean_title": ["pageparametersencod", "page", "paramet", "encod", "not", "decod", "paramet", "no", "namefrom", "name", "dev", "mail", "list", "http", "markmail", "org", "messag", "khuc2v37aakzyfth", "pageparametersencod", "page", "paramet", "encod", "ignor", "queri", "paramet", "like", "=valu", "becaus", "they", "make", "no", "sene", "lead", "except", "later", "at", "pageparamet", "page", "paramet", "add", "call"], "B_title": "PageParametersEncoder should not decode parameters with no name", "B_clean_title": ["pageparametersencod", "page", "paramet", "encod", "not", "decod", "paramet", "no", "name"]},
{"A_title": "Hidden properties (one prefixed with :) in lucenes analyzer configuration fail to construct analyzersThis is similar to OAK-2524 in the sense that lucene doesnt like extra arguments sent its way while constructing analyzers. In some cases (like node move adds :source-path) we have hidden properties added to index definition nodes and they get passed along to lucene analyzer factories which complaint and fail.", "A_clean_title": ["hidden", "properti", "one", "prefix", "lucen", "analyz", "configur", "fail", "construct", "analyzersthi", "analyz", "thi", "similar", "oak", "2524", "sens", "that", "lucen", "doesnt", "like", "extra", "argument", "sent", "it", "way", "while", "construct", "analyz", "some", "case", "like", "node", "move", "add", "sourc", "path", "we", "have", "hidden", "properti", "ad", "index", "definit", "node", "they", "get", "pass", "along", "lucen", "analyz", "factori", "which", "complaint", "fail"], "B_title": "Hidden properties in lucene analyzer configuration fail to construct analyzers", "B_clean_title": ["hidden", "properti", "lucen", "analyz", "configur", "fail", "construct", "analyz"]},
{"A_title": "Remove assert from MathUtils.equalsThe assert in methods equals(doubledoubleint) and equals(floatfloatint) is not necessary.", "A_clean_title": ["remov", "assert", "mathutil", "equalsth", "math", "util", "equal", "assert", "method", "equal", "doubledoubleint", "equal", "floatfloatint", "not", "necessari"], "B_title": "Removed assert statements.", "B_clean_title": ["remov", "assert", "statement"]},
{"A_title": "getKernel fails for buckets with only multiple instances of the same value in random.EmpiricalDistributionAfter loading a set of values into an EmpericalDistribution assume that theres a case where a single bin ONLY contains multiple instances of the same value.  In this case the standard deviation will equal zero.  This will fail when getKernel attempts to create a NormalDistribution.  The other case where stddev=0 is when there is only a single value in the bin and this is handled by returning a ConstantRealDistribution rather than a NormalDistrbution.  See: https://issues.apache.org/jira/browse/MATH-984", "A_clean_title": ["getkernel", "get", "kernel", "fail", "bucket", "onli", "multipl", "instanc", "same", "valu", "random", "empiricaldistributionaft", "empir", "distribut", "after", "load", "set", "valu", "into", "empericaldistribut", "emper", "distribut", "assum", "that", "there", "case", "where", "singl", "bin", "onli", "contain", "multipl", "instanc", "same", "valu", "thi", "case", "standard", "deviat", "will", "equal", "zero", "thi", "will", "fail", "when", "getkernel", "get", "kernel", "attempt", "creat", "normaldistribut", "normal", "distribut", "other", "case", "where", "stddev=0", "when", "there", "onli", "singl", "valu", "bin", "thi", "handl", "by", "return", "constantrealdistribut", "constant", "real", "distribut", "rather", "than", "normaldistrbut", "normal", "distrbut", "see", "http", "984", "apach", "issu", "org", "jira", "brows", "math"], "B_title": "Made getKernel return a constant distribution for zero variance bins.  JIRA: MATH-1203.", "B_clean_title": ["made", "getkernel", "get", "kernel", "return", "constant", "distribut", "zero", "varianc", "bin", "jira", "math", "1203"]},
{"A_title": "Trailing slash not removed for simple path in JCR to Oak path conversionWhile converting from JCR path to Oak path the trailing slashes are not removed for simple paths. They are removed for complex path  code assertEquals(/oak-foo:bar/oak-quu:quxnpMapper.getOakPath(/foo:bar/quu:qux/)); assertEquals(/a/b/cnpMapper.getOakPath(/a/b/c/));      code  Of the two cases above the first one passes while the second one fails", "A_clean_title": ["trail", "slash", "not", "remov", "simpl", "path", "jcr", "oak", "path", "conversionwhil", "convers", "while", "convert", "jcr", "path", "oak", "path", "trail", "slash", "are", "not", "remov", "simpl", "path", "they", "are", "remov", "complex", "path", "code", "assertequ", "assert", "equal", "foo", "oak", "quu", "bar", "oak", "quxnpmapp", "getoakpath", "quxnp", "mapper", "get", "oak", "path", "foo", "bar", "quu", "qux", "assertequ", "assert", "equal", "getoakpath", "cnpmapper", "get", "oak", "path", "cnp", "mapper", "code", "two", "case", "abov", "first", "one", "pass", "while", "second", "one", "fail"], "B_title": "Trailing slash not removed for simple path in JCR to Oak path conversion Thanks Chetan for the patch", "B_clean_title": ["trail", "slash", "not", "remov", "simpl", "path", "jcr", "oak", "path", "convers", "thank", "chetan", "patch"]},
{"A_title": "Array Join Munged IncorrectlyNone", "A_clean_title": ["array", "join", "mung", "incorrectlynon", "incorrectli", "none"], "B_title": "Fix an edge case in how Array.prototype.join is collapsed. Fixes issue 106.", "B_clean_title": ["fix", "edg", "case", "how", "array", "prototyp", "join", "collaps", "fix", "issu", "106"]},
{"A_title": "NodeType index doesnt respect the declaringNodeTypes settingFollowing the OAK-1150 discussion Ive noticed that the node type index doesnt respect the declaringNodeTypes setting. Setting a restriction on the node type index definition breaks the index - there are 0 query hits.", "A_clean_title": ["nodetyp", "node", "type", "index", "doesnt", "respect", "declaringnodetyp", "declar", "node", "type", "settingfollow", "set", "follow", "oak", "1150", "discuss", "ive", "notic", "that", "node", "type", "index", "doesnt", "respect", "declaringnodetyp", "declar", "node", "type", "set", "set", "restrict", "node", "type", "index", "definit", "break", "index", "there", "are", "queri", "hit"], "B_title": "NodeType index doesnt respect the declaringNodeTypes setting", "B_clean_title": ["nodetyp", "node", "type", "index", "doesnt", "respect", "declaringnodetyp", "declar", "node", "type", "set"]},
{"A_title": "Stack overflow when render malformed html.Stack overflow when render malformed html.  Please note that </HEAD> element is inserted after </body>.  HTML: <html> <head> <body> Malformed HTML </body> </head> </html>  Java: package com.mycompany;  import org.apache.wicket.markup.html.WebPage; public class Test1 extends WebPage  private static final long serialVersionUID = -4267477971499123852L;     Thanks.", "A_clean_title": ["stack", "overflow", "when", "render", "malform", "html", "stack", "overflow", "when", "render", "malform", "html", "pleas", "note", "that", "head", "element", "insert", "after", "bodi", "html", "html", "head", "bodi", "malform", "html", "bodi", "head", "html", "java", "packag", "com", "mycompani", "import", "org", "apach", "wicket", "markup", "html", "webpag", "web", "page", "public", "class", "test1", "extend", "webpag", "web", "page", "privat", "static", "final", "long", "serialversionuid", "serial", "version", "uid", "4267477971499123852l", "thank"], "B_title": "Stack overflow when render malformed html.", "B_clean_title": ["stack", "overflow", "when", "render", "malform", "html"]},
{"A_title": "Make org.mockito.asm.signature package optional in Import-Packages.None", "A_clean_title": ["make", "org", "mockito", "asm", "signatur", "packag", "option", "import", "packag", "none"], "B_title": "Fixed issue 151. Merged from trunk. Mockito should not be so defensive and clear potential stubbed call on creation of new mock", "B_clean_title": ["fix", "issu", "151", "merg", "trunk", "mockito", "not", "so", "defens", "clear", "potenti", "stub", "call", "creation", "new", "mock"]},
{"A_title": "Mockito 1.10.x timeout verification needs JUnit classes (VerifyError NoClassDefFoundError).If JUnit is not on the classpath and mockito is version 1.10.x (as of now 1.10.1 up to 1.10.19) and the code is using the timeout verification which is not supposed to be related to JUnit then the JVM may fail with a VerifyError or a NoClassDefFoundError.", "A_clean_title": ["mockito", "10", "timeout", "verif", "need", "junit", "unit", "class", "verifyerror", "verifi", "error", "noclassdeffounderror", "no", "class", "def", "found", "error", "junit", "unit", "not", "classpath", "mockito", "version", "10", "as", "now", "10", "up", "10", "19", "code", "timeout", "verif", "which", "not", "suppos", "relat", "junit", "unit", "then", "jvm", "may", "fail", "verifyerror", "verifi", "error", "or", "noclassdeffounderror", "no", "class", "def", "found", "error"], "B_title": "Fixed issue 152 User should be able to configure the mock to be serializable and have extra interfaces", "B_clean_title": ["fix", "issu", "152", "user", "abl", "configur", "mock", "serializ", "have", "extra", "interfac"]},
{"A_title": "TypeExtractor returns wrong type info when a Tuple has two fields of the same POJO typeConsider the following code:  DataSet<FooBarPojo> d1 = env.fromElements(new FooBarPojo()); DataSet<Tuple2<FooBarPojo FooBarPojo>> d2 = d1.map(new MapFunction<FooBarPojo Tuple2<FooBarPojo FooBarPojo>>()  @Override public Tuple2<FooBarPojo FooBarPojo> map(FooBarPojo value) throws Exception  return null;  );  where FooBarPojo is the following type: public class FooBarPojo  public int foo bar; public FooBarPojo()    This should print a tuple type with two identical fields: Java Tuple2<PojoType<FooBarPojo fields = bar: Integer foo: Integer> PojoType<FooBarPojo fields = bar: Integer foo: Integer>>  But it prints the following instead: Java Tuple2<PojoType<FooBarPojo fields = bar: Integer foo: Integer> GenericType<FooBarPojo>>  Note that this problem causes some co-groups in Gelly to crash with org.apache.flink.api.common.InvalidProgramException: The pair of co-group keys are not compatible with each other when the vertex ID type is a POJO because the second field of the Edge type gets to be a generic type but the POJO gets recognized in the Vertex type and getNumberOfKeyFields returns different numbers for the POJO and the generic type.  The source of the problem is the mechanism in TypeExtractor that would detect recursive types (see the alreadySeen field in TypeExtractor) as it mistakes the second appearance of FooBarPojo with a recursive field.  Specifically the following happens: createTypeInfoWithTypeHierarchy starts to process the Tuple2<FooBarPojo FooBarPojo> type and in line 434 it calls itself for the first field which proceeds into the privateGetForClass case which correctly detects that it is a POJO and correctly returns a PojoTypeInfo; but in the meantime in line 1191 privateGetForClass adds PojoTypeInfo to alreadySeen. Then the outer createTypeInfoWithTypeHierarchy approaches the second field goes into privateGetForClass which mistakenly returns a GenericTypeInfo as it thinks in line 1187 that a recursive type is being processed.  (Note that if we comment out the recursive type detection (the lines that do their thing with the alreadySeen field) then the output is correct.)", "A_clean_title": ["typeextractor", "type", "extractor", "return", "wrong", "type", "info", "when", "tupl", "ha", "two", "field", "same", "pojo", "typeconsid", "type", "consid", "follow", "code", "dataset", "data", "set", "foobarpojo", "foo", "bar", "pojo", "d1", "env", "fromel", "element", "new", "foobarpojo", "foo", "bar", "pojo", "dataset", "data", "set", "tuple2", "foobarpojo", "foo", "bar", "pojo", "foobarpojo", "foo", "bar", "pojo", "d2", "d1", "map", "new", "mapfunct", "map", "function", "foobarpojo", "foo", "bar", "pojo", "tuple2", "foobarpojo", "foo", "bar", "pojo", "foobarpojo", "foo", "bar", "pojo", "overrid", "public", "tuple2", "foobarpojo", "foo", "bar", "pojo", "foobarpojo", "foo", "bar", "pojo", "map", "foobarpojo", "foo", "bar", "pojo", "valu", "throw", "except", "return", "null", "where", "foobarpojo", "foo", "bar", "pojo", "follow", "type", "public", "class", "foobarpojo", "foo", "bar", "pojo", "public", "int", "foo", "bar", "public", "foobarpojo", "foo", "bar", "pojo", "thi", "print", "tupl", "type", "two", "ident", "field", "java", "tuple2", "pojotyp", "pojo", "type", "foobarpojo", "foo", "bar", "pojo", "field", "bar", "integ", "foo", "integ", "pojotyp", "pojo", "type", "foobarpojo", "foo", "bar", "pojo", "field", "bar", "integ", "foo", "integ", "but", "it", "print", "follow", "instead", "java", "tuple2", "pojotyp", "pojo", "type", "foobarpojo", "foo", "bar", "pojo", "field", "bar", "integ", "foo", "integ", "generictyp", "gener", "type", "foobarpojo", "foo", "bar", "pojo", "note", "that", "thi", "problem", "caus", "some", "co", "group", "gelli", "crash", "org", "apach", "flink", "api", "common", "invalidprogramexcept", "invalid", "program", "except", "pair", "co", "group", "key", "are", "not", "compat", "each", "other", "when", "vertex", "id", "type", "pojo", "becaus", "second", "field", "edg", "type", "get", "gener", "type", "but", "pojo", "get", "recogn", "vertex", "type", "getnumberofkeyfield", "get", "number", "key", "field", "return", "differ", "number", "pojo", "gener", "type", "sourc", "problem", "mechan", "typeextractor", "type", "extractor", "that", "would", "detect", "recurs", "type", "see", "alreadyseen", "alreadi", "seen", "field", "typeextractor", "type", "extractor", "as", "it", "mistak", "second", "appear", "foobarpojo", "foo", "bar", "pojo", "recurs", "field", "specif", "follow", "happen", "createtypeinfowithtypehierarchi", "creat", "type", "info", "type", "hierarchi", "start", "process", "tuple2", "foobarpojo", "foo", "bar", "pojo", "foobarpojo", "foo", "bar", "pojo", "type", "line", "434", "it", "call", "itself", "first", "field", "which", "proce", "into", "privategetforclass", "privat", "get", "class", "case", "which", "correctli", "detect", "that", "it", "pojo", "correctli", "return", "pojotypeinfo", "pojo", "type", "info", "but", "meantim", "line", "1191", "privategetforclass", "privat", "get", "class", "add", "pojotypeinfo", "pojo", "type", "info", "alreadyseen", "alreadi", "seen", "then", "outer", "createtypeinfowithtypehierarchi", "creat", "type", "info", "type", "hierarchi", "approach", "second", "field", "goe", "into", "privategetforclass", "privat", "get", "class", "which", "mistakenli", "return", "generictypeinfo", "gener", "type", "info", "as", "it", "think", "line", "1187", "that", "recurs", "type", "be", "process", "note", "that", "we", "comment", "out", "recurs", "type", "detect", "line", "that", "their", "thing", "alreadyseen", "alreadi", "seen", "field", "then", "output", "correct"], "B_title": "java api TypeExtractor returns wrong type info when a Tuple has two fields of the same POJO type", "B_clean_title": ["java", "api", "typeextractor", "type", "extractor", "return", "wrong", "type", "info", "when", "tupl", "ha", "two", "field", "same", "pojo", "type"]},
{"A_title": "A random crash of MersenneTwister random generatorThere is a very small probability that MersenneTwister generator gives a following error:  java.lang.ArrayIndexOutOfBoundsException: 624 in MersenneTwister.java line 253 The error is completely random and its probability is about 1e-8.  UPD: The problem most probably arises only in multy-thread mode.", "A_clean_title": ["random", "crash", "mersennetwist", "mersenn", "twister", "random", "generatorther", "gener", "there", "veri", "small", "probabl", "that", "mersennetwist", "mersenn", "twister", "gener", "give", "follow", "error", "java", "lang", "arrayindexoutofboundsexcept", "array", "index", "out", "bound", "except", "624", "mersennetwist", "java", "mersenn", "twister", "line", "253", "error", "complet", "random", "it", "probabl", "about", "1e", "upd", "problem", "most", "probabl", "aris", "onli", "multi", "thread", "mode"], "B_title": "Fixed copy/paste bug.", "B_clean_title": ["fix", "copi", "past", "bug"]},
{"A_title": "Incomplete reinitialization with some events handlingI get a bug with event handling: I track 2 events that occur in the same step when the first one is accepted it resets the state but the reinitialization is not complete and the second one becomes unable to find its way. I cant give my context which is rather large but I tried a patch that works for me unfortunately it breaks the unit tests.", "A_clean_title": ["incomplet", "reiniti", "some", "event", "handlingi", "handl", "get", "bug", "event", "handl", "track", "event", "that", "occur", "same", "step", "when", "first", "one", "accept", "it", "reset", "state", "but", "reiniti", "not", "complet", "second", "one", "becom", "unabl", "find", "it", "way", "cant", "give", "my", "context", "which", "rather", "larg", "but", "tri", "patch", "that", "work", "me", "unfortun", "it", "break", "unit", "test"], "B_title": "Fixed an event resetting issue in ODE.", "B_clean_title": ["fix", "event", "reset", "issu", "ode"]},
{"A_title": "TreeTypeProvider treats optimized node type definition info as Ac-Contentwhile investigating a bug reported by ~teofili and ~mpetria that cause group-import with policy node to fail when run with non-administrative session i found that the TreeTypeProvider wrongly identifies the optimized item definition information stored with the node types (e.g. /jcr:system/jcr:nodeTypes/rep:AccessControllable/rep:namedChildNodeDefinitions/rep:policy ) as access control content and thus doesnt read it properly when using a session that doesnt have jcr:readAccessControl privilege at /jcr:system/jcr:nodeTypes.  the effect of this bug is as follows: the internal calculation of the effective node type and thus item definitions will not work properly for rep:policy nodes (and similar) as the editing session cannot read the full (oak internal) node type definition as stored below /jcr:system/jcr:nodeTypes.", "A_clean_title": ["treetypeprovid", "tree", "type", "provid", "treat", "optim", "node", "type", "definit", "info", "as", "ac", "contentwhil", "investig", "bug", "report", "by", "~teofili", "~mpetria", "that", "caus", "group", "import", "polici", "node", "fail", "when", "run", "non", "administr", "session", "found", "that", "treetypeprovid", "tree", "type", "provid", "wrongli", "identifi", "optim", "item", "definit", "inform", "store", "node", "type", "jcr", "system", "jcr", "nodetyp", "rep", "node", "type", "accesscontrol", "rep", "access", "control", "namedchildnodedefinit", "rep", "name", "child", "node", "definit", "polici", "as", "access", "control", "content", "thu", "doesnt", "read", "it", "properli", "when", "session", "that", "doesnt", "have", "jcr", "readaccesscontrol", "read", "access", "control", "privileg", "at", "jcr", "system", "jcr", "nodetyp", "node", "type", "effect", "thi", "bug", "as", "follow", "intern", "calcul", "effect", "node", "type", "thu", "item", "definit", "will", "not", "work", "properli", "rep", "polici", "node", "similar", "as", "edit", "session", "not", "read", "full", "oak", "intern", "node", "type", "definit", "as", "store", "below", "jcr", "system", "jcr", "nodetyp", "node", "type"], "B_title": ": TreeTypeProvider treates optimized node type definition info as Ac-Content", "B_clean_title": ["treetypeprovid", "tree", "type", "provid", "treat", "optim", "node", "type", "definit", "info", "as", "ac", "content"]},
{"A_title": "bad variable inlining in closureNone", "A_clean_title": ["bad", "variabl", "inlin", "closurenon", "closur", "none"], "B_title": "Change on 2010/06/09 by nicksantos", "B_clean_title": ["chang", "2010", "06", "09", "by", "nicksanto"]},
{"A_title": "DownloadLink doesnt wrap the String model used for file name nor does it detachComponent DownloadLink doesnt call method wrap of class Component on parameter fileNameModel. This causes models like StringResourceModel to not resolve resource bundles correctly. See the discussion here: http://stackoverflow.com/questions/12196533/how-to-use-wicket-stringresourcemodel-in-downloadlink  The patch seems quite trivial.   Detachment is also missing.", "A_clean_title": ["downloadlink", "download", "link", "doesnt", "wrap", "string", "model", "use", "file", "name", "nor", "it", "detachcompon", "detach", "compon", "downloadlink", "download", "link", "doesnt", "call", "method", "wrap", "class", "compon", "paramet", "filenamemodel", "file", "name", "model", "thi", "caus", "model", "like", "stringresourcemodel", "string", "resourc", "model", "not", "resolv", "resourc", "bundl", "correctli", "see", "discuss", "here", "http", "use", "wicket", "stringresourcemodel", "downloadlink", "stackoverflow", "com", "question", "12196533", "how", "patch", "seem", "quit", "trivial", "detach", "also", "miss"], "B_title": "fileNameModel wrapOnAssignment and detach", "B_clean_title": ["filenamemodel", "file", "name", "model", "wraponassign", "wrap", "assign", "detach"]},
{"A_title": "Type refining of this raises IllegalArgumentExceptionNone", "A_clean_title": ["type", "refin", "thi", "rais", "illegalargumentexceptionnon", "illeg", "argument", "except", "none"], "B_title": "Handle this properly in the RAI. fixes issue 769", "B_clean_title": ["handl", "thi", "properli", "rai", "fix", "issu", "769"]},
{"A_title": "setResponsePage in AjaxLink goes always to localhost:8080 instead to the right host and portsetResponsePage in an AjaxLink in Wicket 1.4 redirects with a relative path to the response page. Wicket 1.5 takes the absolute path localhost:8080/path to the response page even when the host and port are different. (e.g. with Apache2 a virtual host is created with server name www.mycompany.com setResponce wil go to localhost:8080/path to page instead of  www.mycompany.com/path to page)", "A_clean_title": ["setresponsepag", "set", "respons", "page", "ajaxlink", "ajax", "link", "goe", "alway", "localhost:8080", "instead", "right", "host", "portsetresponsepag", "portset", "respons", "page", "ajaxlink", "ajax", "link", "wicket", "redirect", "rel", "path", "respons", "page", "wicket", "take", "absolut", "path", "localhost:8080", "path", "respons", "page", "even", "when", "host", "port", "are", "differ", "apache2", "virtual", "host", "creat", "server", "name", "www", "mycompani", "com", "setresponc", "set", "responc", "wil", "go", "localhost:8080", "path", "page", "instead", "www", "mycompani", "com", "path", "page"], "B_title": "setResponsePage in AjaxLink goes always to localhost:8080 instead to the right host and port", "B_clean_title": ["setresponsepag", "set", "respons", "page", "ajaxlink", "ajax", "link", "goe", "alway", "localhost:8080", "instead", "right", "host", "port"]},
{"A_title": "MutableHashTable fails when spilling partitions without overflow segmentsWhen one performs a join operation with many and large records then the join operation fails with the following exception when it tries to spill a HashPartition.  code java.lang.RuntimeException: Bug in Hybrid Hash Join: Request to spill a partition with less than two buffers. at org.apache.flink.runtime.operators.hash.HashPartition.spillPartition(HashPartition.java:302) at org.apache.flink.runtime.operators.hash.MutableHashTable.spillPartition(MutableHashTable.java:1108) at org.apache.flink.runtime.operators.hash.MutableHashTable.nextSegment(MutableHashTable.java:1277) at org.apache.flink.runtime.operators.hash.HashPartition BuildSideBuffer.nextSegment(HashPartition.java:524) at org.apache.flink.runtime.memory.AbstractPagedOutputView.advance(AbstractPagedOutputView.java:140) at org.apache.flink.runtime.memory.AbstractPagedOutputView.write(AbstractPagedOutputView.java:201) at org.apache.flink.runtime.memory.AbstractPagedOutputView.write(AbstractPagedOutputView.java:178) at org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.serialize(BytePrimitiveArraySerializer.java:74) at org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer.serialize(BytePrimitiveArraySerializer.java:30) at org.apache.flink.runtime.operators.hash.HashPartition.insertIntoBuildBuffer(HashPartition.java:257) at org.apache.flink.runtime.operators.hash.MutableHashTable.insertIntoTable(MutableHashTable.java:856) at org.apache.flink.runtime.operators.hash.MutableHashTable.buildInitialTable(MutableHashTable.java:685) at org.apache.flink.runtime.operators.hash.MutableHashTable.open(MutableHashTable.java:443) at org.apache.flink.runtime.operators.hash.HashTableTest.testSpillingWhenBuildingTableWithoutOverflow(HashTableTest.java:234) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at org.junit.runners.model.FrameworkMethod 1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) at org.junit.runners.ParentRunner 3.run(ParentRunner.java:238) at org.junit.runners.ParentRunner 1.schedule(ParentRunner.java:63) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) at org.junit.runners.ParentRunner.access 000(ParentRunner.java:53) at org.junit.runners.ParentRunner 2.evaluate(ParentRunner.java:229) at org.junit.runners.ParentRunner.run(ParentRunner.java:309) at org.junit.runner.JUnitCore.run(JUnitCore.java:160) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:78) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:212) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140) code  The reason is that the HashPartition does not include the number of used memory segments by the BuildSideBuffer when it counts the currently occupied memory segments.", "A_clean_title": ["mutablehasht", "mutabl", "hash", "tabl", "fail", "when", "spill", "partit", "without", "overflow", "segmentswhen", "segment", "when", "one", "perform", "join", "oper", "mani", "larg", "record", "then", "join", "oper", "fail", "follow", "except", "when", "it", "tri", "spill", "hashpartit", "hash", "partit", "code", "java", "lang", "runtimeexcept", "runtim", "except", "bug", "hybrid", "hash", "join", "request", "spill", "partit", "less", "than", "two", "buffer", "at", "org", "apach", "flink", "runtim", "oper", "hash", "hashpartit", "spillpartit", "hash", "partit", "spill", "partit", "hashpartit", "java:302", "hash", "partit", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "spillpartit", "mutabl", "hash", "tabl", "spill", "partit", "mutablehasht", "java:1108", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "nextseg", "mutabl", "hash", "tabl", "next", "segment", "mutablehasht", "java:1277", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "hashpartit", "hash", "partit", "buildsidebuff", "nextseg", "build", "side", "buffer", "next", "segment", "hashpartit", "java:524", "hash", "partit", "at", "org", "apach", "flink", "runtim", "memori", "abstractpagedoutputview", "advanc", "abstract", "page", "output", "view", "abstractpagedoutputview", "java:140", "abstract", "page", "output", "view", "at", "org", "apach", "flink", "runtim", "memori", "abstractpagedoutputview", "write", "abstract", "page", "output", "view", "abstractpagedoutputview", "java:201", "abstract", "page", "output", "view", "at", "org", "apach", "flink", "runtim", "memori", "abstractpagedoutputview", "write", "abstract", "page", "output", "view", "abstractpagedoutputview", "java:178", "abstract", "page", "output", "view", "at", "org", "apach", "flink", "api", "common", "typeutil", "base", "array", "byteprimitivearrayseri", "serial", "byte", "primit", "array", "serial", "byteprimitivearrayseri", "java:74", "byte", "primit", "array", "serial", "at", "org", "apach", "flink", "api", "common", "typeutil", "base", "array", "byteprimitivearrayseri", "serial", "byte", "primit", "array", "serial", "byteprimitivearrayseri", "java:30", "byte", "primit", "array", "serial", "at", "org", "apach", "flink", "runtim", "oper", "hash", "hashpartit", "insertintobuildbuff", "hash", "partit", "insert", "into", "build", "buffer", "hashpartit", "java:257", "hash", "partit", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "insertintot", "mutabl", "hash", "tabl", "insert", "into", "tabl", "mutablehasht", "java:856", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "buildinitialt", "mutabl", "hash", "tabl", "build", "initi", "tabl", "mutablehasht", "java:685", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "mutablehasht", "open", "mutabl", "hash", "tabl", "mutablehasht", "java:443", "mutabl", "hash", "tabl", "at", "org", "apach", "flink", "runtim", "oper", "hash", "hashtabletest", "testspillingwhenbuildingtablewithoutoverflow", "hash", "tabl", "test", "test", "spill", "when", "build", "tabl", "without", "overflow", "hashtabletest", "java:234", "hash", "tabl", "test", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:62", "nativ", "method", "accessor", "impl", "at", "sun", "reflect", "delegatingmethodaccessorimpl", "invok", "deleg", "method", "accessor", "impl", "delegatingmethodaccessorimpl", "java:43", "deleg", "method", "accessor", "impl", "at", "org", "junit", "runner", "model", "frameworkmethod", "framework", "method", "runreflectivecal", "run", "reflect", "call", "frameworkmethod", "java:47", "framework", "method", "at", "org", "junit", "intern", "runner", "model", "reflectivecal", "run", "reflect", "callabl", "reflectivecal", "java:12", "reflect", "callabl", "at", "org", "junit", "runner", "model", "frameworkmethod", "invokeexplos", "framework", "method", "invok", "explos", "frameworkmethod", "java:44", "framework", "method", "at", "org", "junit", "intern", "runner", "statement", "invokemethod", "evalu", "invok", "method", "invokemethod", "java:17", "invok", "method", "at", "org", "junit", "runner", "parentrunn", "runleaf", "parent", "runner", "run", "leaf", "parentrunn", "java:271", "parent", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:70", "block", "unit4class", "runner", "at", "org", "junit", "runner", "blockjunit4classrunn", "runchild", "block", "unit4class", "runner", "run", "child", "blockjunit4classrunn", "java:50", "block", "unit4class", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "run", "parentrunn", "java:238", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "schedul", "parentrunn", "java:63", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "runchildren", "parent", "runner", "run", "children", "parentrunn", "java:236", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "access", "parent", "runner", "000", "parentrunn", "java:53", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "parent", "runner", "evalu", "parentrunn", "java:229", "parent", "runner", "at", "org", "junit", "runner", "parentrunn", "run", "parent", "runner", "parentrunn", "java:309", "parent", "runner", "at", "org", "junit", "runner", "junitcor", "run", "unit", "core", "junitcor", "java:160", "unit", "core", "at", "com", "intellij", "junit4", "junit4ideatestrunn", "startrunnerwitharg", "unit4idea", "test", "runner", "start", "runner", "arg", "junit4ideatestrunn", "java:78", "unit4idea", "test", "runner", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "preparestreamsandstart", "unit", "starter", "prepar", "stream", "start", "junitstart", "java:212", "unit", "starter", "at", "com", "intellij", "rt", "execut", "junit", "junitstart", "main", "unit", "starter", "junitstart", "java:68", "unit", "starter", "at", "sun", "reflect", "nativemethodaccessorimpl", "invoke0", "nativ", "method", "accessor", "impl", "nativ", "method", "at", "sun", "reflect", "nativemethodaccessorimpl", "invok", "nativ", "method", "accessor", "impl", "nativemethodaccessorimpl", "java:62", "nativ", "method", "accessor", "impl", "at", "com", "intellij", "rt", "execut", "applic", "appmain", "main", "app", "main", "appmain", "java:140", "app", "main", "code", "reason", "that", "hashpartit", "hash", "partit", "not", "includ", "number", "use", "memori", "segment", "by", "buildsidebuff", "build", "side", "buffer", "when", "it", "count", "current", "occupi", "memori", "segment"], "B_title": "runtime Fix broken spilling of MutableHashTable", "B_clean_title": ["runtim", "fix", "broken", "spill", "mutablehasht", "mutabl", "hash", "tabl"]},
{"A_title": "Importing an entitytype with several columns with the same name import without errorsHow to Reproduce  Import a datasheet with multiple columns that have the same name.  Expected behavior  An error telling me to only use the name of every attribute once per entitytype  Observed behavior  Everything imports fine and I have issues much later then one would expect.", "A_clean_title": ["import", "entitytyp", "sever", "column", "same", "name", "import", "without", "errorshow", "error", "how", "reproduc", "import", "datasheet", "multipl", "column", "that", "have", "same", "name", "expect", "behavior", "error", "tell", "me", "onli", "use", "name", "everi", "attribut", "onc", "per", "entitytyp", "observ", "behavior", "everyth", "import", "fine", "have", "issu", "much", "later", "then", "one", "would", "expect"], "B_title": "Merge pull request #7277 from dennishendriksen/fix/6906-emxDuplicateColIds  Fix #6906 Duplicate col header exception for CSV and Excel repository", "B_clean_title": ["merg", "pull", "request", "7277", "emxduplicatecolid", "dennishendriksen", "fix", "6906", "emx", "duplic", "col", "id", "fix", "6906", "duplic", "col", "header", "except", "csv", "excel", "repositori"]},
{"A_title": "AppendingStringBuffer.insert  infinite loopWhen trying to insert a StringBuffer into an AppendingStringBuffer the method   public AppendingStringBuffer insert(final int offset final Object obj)  will call itself repeatedly generating an infinite loop.  The fix would be to call toString() method if the object is a StringBuffer   public AppendingStringBuffer insert(final int offset final Object obj)  if (obj instanceof AppendingStringBuffer)  AppendingStringBuffer asb = (AppendingStringBuffer)obj; return insert(offset asb.value 0 asb.count);  else if (obj instanceof StringBuffer)  //return insert(offset obj);                        return insert(offset obj.toString());   return insert(offset String.valueOf(obj));", "A_clean_title": ["appendingstringbuff", "insert", "append", "string", "buffer", "infinit", "loopwhen", "loop", "when", "tri", "insert", "stringbuff", "string", "buffer", "into", "appendingstringbuff", "append", "string", "buffer", "method", "public", "appendingstringbuff", "append", "string", "buffer", "insert", "final", "int", "offset", "final", "object", "obj", "will", "call", "itself", "repeatedli", "gener", "infinit", "loop", "fix", "would", "call", "tostr", "string", "method", "object", "stringbuff", "string", "buffer", "public", "appendingstringbuff", "append", "string", "buffer", "insert", "final", "int", "offset", "final", "object", "obj", "obj", "instanceof", "appendingstringbuff", "append", "string", "buffer", "appendingstringbuff", "append", "string", "buffer", "asb", "appendingstringbuff", "append", "string", "buffer", "obj", "return", "insert", "offset", "asb", "valu", "asb", "count", "obj", "instanceof", "stringbuff", "string", "buffer", "return", "insert", "offset", "obj", "return", "insert", "offset", "obj", "tostr", "string", "return", "insert", "offset", "string", "valueof", "valu", "obj"], "B_title": "", "B_clean_title": []},
{"A_title": "possible NPE exception when class cannot be mocked via PowerMockitoIn version 1.10.5 the catch block needs to guard against a null proxyInstance.", "A_clean_title": ["possibl", "npe", "except", "when", "class", "not", "mock", "via", "powermockitoin", "power", "mockito", "version", "10", "catch", "block", "need", "guard", "against", "null", "proxyinst", "proxi", "instanc"], "B_title": "Fixed issue 98 In order to avoid NPE in some very rare cases.", "B_clean_title": ["fix", "issu", "98", "order", "avoid", "npe", "some", "veri", "rare", "case"]},
{"A_title": "NaN in equals methodsIn MathUtils some equals methods will return true if both argument are NaN. Unless Im mistaken this contradicts the IEEE standard. If nobody objects Im going to make the changes.", "A_clean_title": ["nan", "na", "equal", "methodsin", "method", "mathutil", "math", "util", "some", "equal", "method", "will", "return", "true", "both", "argument", "are", "nan", "na", "unless", "im", "mistaken", "thi", "contradict", "ieee", "standard", "nobodi", "object", "im", "go", "make", "chang"], "B_title": "Removed deprecated methods.", "B_clean_title": ["remov", "deprec", "method"]},
{"A_title": "AjaxFormChoiceComponentUpdatingBehavior affects checkboxes even if component uses radios and vice-versaI have a form with two radio buttons.  Depending which radio the user selects I show one form or another form.  Im using an AjaxFormChoiceComponentUpdatingBehavior attached to the RadioGroup.  One of the forms has a checkbox.  The checkbox triggers an ajax update--even though the AjaxFormChoiceComponentUpdatingBehavior is attached to a RadioGroup.  AjaxFormChoiceComponentUpdatingBehavior should only affect the appropriate controls based on whether it is attached to a choice component that uses radios or checkboxes.  If a developer really wants both then he can use two AjaxFormChoiceComponentUpdatingBehavior instances.  Ive attached a patch.", "A_clean_title": ["ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "affect", "checkbox", "even", "compon", "use", "radio", "vice", "versai", "versa", "have", "form", "two", "radio", "button", "depend", "which", "radio", "user", "select", "show", "one", "form", "or", "anoth", "form", "im", "ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "attach", "radiogroup", "radio", "group", "one", "form", "ha", "checkbox", "checkbox", "trigger", "ajax", "updat", "even", "though", "ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "attach", "radiogroup", "radio", "group", "ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "onli", "affect", "appropri", "control", "base", "whether", "it", "attach", "choic", "compon", "that", "use", "radio", "or", "checkbox", "develop", "realli", "want", "both", "then", "he", "use", "two", "ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "instanc", "ive", "attach", "patch"], "B_title": "", "B_clean_title": []},
{"A_title": "AutoLabelTextResolver fails to pick up locale changes in the sessionWhen using <wicket:label key=...> AutoLabelTextResolver correctly picks up the localized message identified by the key. However if the Session locale is changed neither the printed label nor the FormComponents label model get updated - both will still contain the initial message. This is inconsistent with the behavior of <wicket:message> and StringResourceModel. The principle of least surprise (and in my opinion also that of highest usefulness ;-) ) suggests that AutoLabelTextResolver should dynamically get the localized string whenever it deals with something that can be localized. That includes the <wicket:label key=...> case mentioned above as well as when using FormComponent#getDefaultLabel.  I have only tested this in trunk 1.5 (since it recently came up during a training I gave on Wicket 1.5). I suspect it also affects 1.4.x.", "A_clean_title": ["autolabeltextresolv", "auto", "label", "text", "resolv", "fail", "pick", "up", "local", "chang", "sessionwhen", "session", "when", "wicket", "label", "key=", "autolabeltextresolv", "auto", "label", "text", "resolv", "correctli", "pick", "up", "local", "messag", "identifi", "by", "key", "howev", "session", "local", "chang", "neither", "print", "label", "nor", "formcompon", "form", "compon", "label", "model", "get", "updat", "both", "will", "still", "contain", "initi", "messag", "thi", "inconsist", "behavior", "wicket", "messag", "stringresourcemodel", "string", "resourc", "model", "principl", "least", "surpris", "my", "opinion", "also", "that", "highest", "use", "suggest", "that", "autolabeltextresolv", "auto", "label", "text", "resolv", "dynam", "get", "local", "string", "whenev", "it", "deal", "someth", "that", "local", "that", "includ", "wicket", "label", "key=", "case", "mention", "abov", "as", "well", "as", "when", "formcompon", "form", "compon", "getdefaultlabel", "get", "default", "label", "have", "onli", "test", "thi", "trunk", "sinc", "it", "recent", "came", "up", "dure", "train", "gave", "wicket", "suspect", "it", "also", "affect"], "B_title": "Issue: WICKET-4102", "B_clean_title": ["issu", "wicket", "4102"]},
{"A_title": "FastMath.cosh sinh do not support the same range of values as the Math counterpartsAs reported by Jeff Hain: cosh(double) and sinh(double): Math.cosh(709.783) = 8.991046692770538E307 FastMath.cosh(709.783) = Infinity Math.sinh(709.783) = 8.991046692770538E307 FastMath.sinh(709.783) = Infinity ===> This is due to using exp( x )/2 for values of |x| above 20: the result sometimes should not overflow but exp( x ) does so we end up with some infinity. ===> for values of |x| >= StrictMath.log(Double.MAX_VALUE) exp will overflow so you need to use that instead: for x positive: double t = exp(x*0.5); return (0.5*t)*t; for x negative: double t = exp(-x*0.5); return (-0.5*t)*t;", "A_clean_title": ["fastmath", "cosh", "fast", "math", "sinh", "not", "support", "same", "rang", "valu", "as", "math", "counterpartsa", "counterpart", "as", "report", "by", "jeff", "hain", "cosh", "doubl", "sinh", "doubl", "math", "cosh", "709", "783", "991046692770538e307", "fastmath", "cosh", "fast", "math", "709", "783", "infin", "math", "sinh", "709", "783", "991046692770538e307", "fastmath", "sinh", "fast", "math", "709", "783", "infin", "thi", "due", "exp", "valu", "|x|", "abov", "20", "result", "sometim", "not", "overflow", "but", "exp", "so", "we", "end", "up", "some", "infin", "valu", "|x|", "strictmath", "log", "strict", "math", "doubl", "max", "valu", "exp", "will", "overflow", "so", "you", "need", "use", "that", "instead", "posit", "doubl", "exp", "return", "neg", "doubl", "exp", "return"], "B_title": "Avoid overflow on the whole range covered by the equivalent functions in the standard Math class.", "B_clean_title": ["avoid", "overflow", "whole", "rang", "cover", "by", "equival", "function", "standard", "math", "class"]},
{"A_title": "FixedLengthRecordSorter can not write to output cross MemorySegments.FixedLengthRecordSorter can not write to output cross MemorySegments it works well as its only called to write a single record before. Should fix it and add more unit test.", "A_clean_title": ["fixedlengthrecordsort", "fix", "length", "record", "sorter", "not", "write", "output", "cross", "memoryseg", "fixedlengthrecordsort", "memori", "segment", "fix", "length", "record", "sorter", "not", "write", "output", "cross", "memoryseg", "memori", "segment", "it", "work", "well", "as", "it", "onli", "call", "write", "singl", "record", "befor", "fix", "it", "add", "more", "unit", "test"], "B_title": "Fixed FixedLengthRecordSorter write to multi memory pages issue and add more unit tests.", "B_clean_title": ["fix", "fixedlengthrecordsort", "fix", "length", "record", "sorter", "write", "multi", "memori", "page", "issu", "add", "more", "unit", "test"]},
{"A_title": "EigenDecomposition.Solver should consider tiny values 0 for purposes of determining singularityEigenDecomposition.Solver tests for singularity by comparing eigenvalues to 0 for exact equality. Elsewhere in the class and in the code of course very small values are considered 0. This causes the solver to consider some singular matrices as non-singular.  The patch here includes a test as well showing the behavior -- the matrix is clearly singular but isnt considered as such since one eigenvalue are ~1e-14 rather than exactly 0.  (What I am not sure of is whether we should really be evaluating the *norm* of the imaginary eigenvalues rather than real/imag components separately. But the javadoc says the solver only supports real eigenvalues anyhow so its kind of moot since imag=0 for all eigenvalues.)", "A_clean_title": ["eigendecomposit", "solver", "eigen", "decomposit", "consid", "tini", "valu", "purpos", "determin", "singularityeigendecomposit", "solver", "singular", "eigen", "decomposit", "test", "singular", "by", "compar", "eigenvalu", "exact", "equal", "elsewher", "class", "code", "cours", "veri", "small", "valu", "are", "consid", "thi", "caus", "solver", "consid", "some", "singular", "matric", "as", "non", "singular", "patch", "here", "includ", "test", "as", "well", "show", "behavior", "matrix", "clearli", "singular", "but", "isnt", "consid", "as", "such", "sinc", "one", "eigenvalu", "are", "~1e", "14", "rather", "than", "exactli", "what", "am", "not", "sure", "whether", "we", "realli", "evalu", "norm", "imaginari", "eigenvalu", "rather", "than", "real", "imag", "compon", "separ", "but", "javadoc", "say", "solver", "onli", "support", "real", "eigenvalu", "anyhow", "so", "it", "kind", "moot", "sinc", "imag=0", "all", "eigenvalu"], "B_title": "Loop added to ensure that the largest norm is used in the singularity check. Patch provided by Sean Owen.", "B_clean_title": ["loop", "ad", "ensur", "that", "largest", "norm", "use", "singular", "check", "patch", "provid", "by", "sean", "owen"]},
{"A_title": "Invalid execution graph cleanup for jobs with colocation groupsCurrently upon restarting an execution graph we clean-up the colocation constraints for each group present in an ExecutionJobVertex respectively.  This can lead to invalid reconfiguration upon a restart or any other activity that relies on state cleanup of the execution graph. For example upon restarting a DataStream job with iterations the following steps are executed:  1) IterationSource colgroup constraints are reset 2) IterationSource execution vertices reset and create new colocation constraints 3) IterationSink colgroup constraints are reset 4) IterationSink execution vertices reset and create different colocation constraints.  This can be trivially fixed by reseting colocation groups independently from ExecutionJobVertices thus updating them once per reconfiguration.", "A_clean_title": ["invalid", "execut", "graph", "cleanup", "job", "coloc", "groupscurr", "group", "current", "upon", "restart", "execut", "graph", "we", "clean", "up", "coloc", "constraint", "each", "group", "present", "executionjobvertex", "execut", "job", "vertex", "respect", "thi", "lead", "invalid", "reconfigur", "upon", "restart", "or", "ani", "other", "activ", "that", "reli", "state", "cleanup", "execut", "graph", "exampl", "upon", "restart", "datastream", "data", "stream", "job", "iter", "follow", "step", "are", "execut", "iterationsourc", "iter", "sourc", "colgroup", "constraint", "are", "reset", "iterationsourc", "iter", "sourc", "execut", "vertic", "reset", "creat", "new", "coloc", "constraint", "iterationsink", "iter", "sink", "colgroup", "constraint", "are", "reset", "iterationsink", "iter", "sink", "execut", "vertic", "reset", "creat", "differ", "coloc", "constraint", "thi", "trivial", "fix", "by", "reset", "coloc", "group", "independ", "executionjobvertic", "execut", "job", "vertic", "thu", "updat", "them", "onc", "per", "reconfigur"], "B_title": "Fix colocation group re-instantiation", "B_clean_title": ["fix", "coloc", "group", "re", "instanti"]},
{"A_title": "Allow convenient spying on abstract classes.Mockito is easy to use when the test needs to provide canned values for a certain method. But it gets harder when a canned value isnt sufficient.", "A_clean_title": ["allow", "conveni", "spi", "abstract", "class", "mockito", "easi", "use", "when", "test", "need", "provid", "can", "valu", "certain", "method", "but", "it", "get", "harder", "when", "can", "valu", "isnt", "suffici"], "B_title": "Fixed problem with type testing of outer classes", "B_clean_title": ["fix", "problem", "type", "test", "outer", "class"]},
{"A_title": "HeaderResponse.renderCSSReference does not render context path relative url but wicket filter url-pattern relative urlIn an application with a wicket filter url-pattern different than /* if you use HeaderResponse.renderCSSReference(String url) where url is a context-path-relative url (css/main.css for example) the generated css link is not context relative but wicket url-pattern relative.", "A_clean_title": ["headerrespons", "rendercssrefer", "header", "respons", "render", "css", "refer", "not", "render", "context", "path", "rel", "url", "but", "wicket", "filter", "url", "pattern", "rel", "urlin", "url", "applic", "wicket", "filter", "url", "pattern", "differ", "than", "you", "use", "headerrespons", "rendercssrefer", "header", "respons", "render", "css", "refer", "string", "url", "where", "url", "context", "path", "rel", "url", "css", "css", "main", "exampl", "gener", "css", "link", "not", "context", "rel", "but", "wicket", "url", "pattern", "rel"], "B_title": "Issue: WICKET-4030", "B_clean_title": ["issu", "wicket", "4030"]},
{"A_title": "StackOverflowError after form submit with a validation errorI was not able to find a cause or make a small quickstart but it has something to do with a form validation my workaround was to setDefaultFormProcessing(false) or not use required TextFields.  It can be reproduced on https://github.com/krasa/DevSupportApp/tree/stackOverflow  1) run StartVojtitkoDummy 2) go to http://localhost:8765/wicket/bookmarkable/krasa.release.frontend.TokenizationPage 3) click on Generate Release json button  - instead of SOE it should give a validation error probably even on fields which I would not want to validate but thats just because Ive made the page badly...     code java.lang.StackOverflowError: null ... at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:81) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:74) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy 1.component(AbstractMarkupSourcingStrategy.java:66) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:144) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:162) at org.apache.wicket.util.visit.Visits.visitChildren(Visits.java:123) at org.apache.wicket.MarkupContainer.visitChildren(MarkupContainer.java:862) at org.apache.wicket.markup.html.panel.AbstractMarkupSourcingStrategy.searchMarkupInTransparentResolvers(AbstractMarkupSourcingStrategy.java:65) at org.apache.wicket.markup.html.panel.DefaultMarkupSourcingStrategy.getMarkup(DefaultMarkupSourcingStrategy.java:99) at org.apache.wicket.MarkupContainer.getMarkup(MarkupContainer.java:453) at org.apache.wicket.Component.getMarkup(Component.java:755) at org.apache.wicket.Component.internalRender(Component.java:2344) at org.apache.wicket.Component.render(Component.java:2307) at org.apache.wicket.ajax.XmlAjaxResponse.writeComponent(XmlAjaxResponse.java:128) at org.apache.wicket.ajax.AbstractAjaxResponse.writeComponents(AbstractAjaxResponse.java:218) at org.apache.wicket.ajax.AbstractAjaxResponse.writeTo(AbstractAjaxResponse.java:150) at org.apache.wicket.ajax.AjaxRequestHandler.respond(AjaxRequestHandler.java:359) at org.apache.wicket.request.cycle.RequestCycle HandlerExecutor.respond(RequestCycle.java:865) at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:64) at org.apache.wicket.request.RequestHandlerStack.execute(RequestHandlerStack.java:97) at org.apache.wicket.request.cycle.RequestCycle.execute(RequestCycle.java:265) at org.apache.wicket.request.cycle.RequestCycle.processRequest(RequestCycle.java:222) at org.apache.wicket.request.cycle.RequestCycle.processRequestAndDetach(RequestCycle.java:293) at org.apache.wicket.protocol.ws.AbstractUpgradeFilter.processRequestCycle(AbstractUpgradeFilter.java:59) at org.apache.wicket.protocol.http.WicketFilter.processRequest(WicketFilter.java:203) at org.apache.wicket.protocol.http.WicketFilter.doFilter(WicketFilter.java:284) at org.eclipse.jetty.servlet.ServletHandler CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1125) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1059) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:497) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:248) at org.eclipse.jetty.io.AbstractConnection 2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:620) at org.eclipse.jetty.util.thread.QueuedThreadPool 3.ru code", "A_clean_title": ["stackoverflowerror", "stack", "overflow", "error", "after", "form", "submit", "valid", "errori", "error", "wa", "not", "abl", "find", "caus", "or", "make", "small", "quickstart", "but", "it", "ha", "someth", "form", "valid", "my", "workaround", "wa", "setdefaultformprocess", "set", "default", "form", "process", "fals", "or", "not", "use", "requir", "textfield", "text", "field", "it", "reproduc", "http", "github", "com", "krasa", "devsupportapp", "tree", "stackoverflow", "dev", "support", "app", "stack", "overflow", "run", "startvojtitkodummi", "start", "vojtitko", "dummi", "go", "http", "releas", "frontend", "tokenizationpag", "localhost:8765", "wicket", "bookmark", "krasa", "token", "page", "click", "gener", "releas", "json", "button", "instead", "soe", "it", "give", "valid", "error", "probabl", "even", "field", "which", "would", "not", "want", "valid", "but", "that", "just", "becaus", "ive", "made", "page", "badli", "code", "java", "lang", "stackoverflowerror", "stack", "overflow", "error", "null", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:81", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:74", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "abstract", "markup", "sourc", "strategi", "compon", "abstractmarkupsourcingstrategi", "java:66", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:144", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:162", "at", "org", "apach", "wicket", "util", "visit", "visit", "visitchildren", "visit", "children", "visit", "java:123", "at", "org", "apach", "wicket", "markupcontain", "visitchildren", "markup", "contain", "visit", "children", "markupcontain", "java:862", "markup", "contain", "at", "org", "apach", "wicket", "markup", "html", "panel", "abstractmarkupsourcingstrategi", "searchmarkupintransparentresolv", "abstract", "markup", "sourc", "strategi", "search", "markup", "transpar", "resolv", "abstractmarkupsourcingstrategi", "java:65", "abstract", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markup", "html", "panel", "defaultmarkupsourcingstrategi", "getmarkup", "default", "markup", "sourc", "strategi", "get", "markup", "defaultmarkupsourcingstrategi", "java:99", "default", "markup", "sourc", "strategi", "at", "org", "apach", "wicket", "markupcontain", "getmarkup", "markup", "contain", "get", "markup", "markupcontain", "java:453", "markup", "contain", "at", "org", "apach", "wicket", "compon", "getmarkup", "get", "markup", "compon", "java:755", "at", "org", "apach", "wicket", "compon", "internalrend", "intern", "render", "compon", "java:2344", "at", "org", "apach", "wicket", "compon", "render", "compon", "java:2307", "at", "org", "apach", "wicket", "ajax", "xmlajaxrespons", "writecompon", "xml", "ajax", "respons", "write", "compon", "xmlajaxrespons", "java:128", "xml", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "abstractajaxrespons", "writecompon", "abstract", "ajax", "respons", "write", "compon", "abstractajaxrespons", "java:218", "abstract", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "abstractajaxrespons", "writeto", "abstract", "ajax", "respons", "write", "abstractajaxrespons", "java:150", "abstract", "ajax", "respons", "at", "org", "apach", "wicket", "ajax", "ajaxrequesthandl", "respond", "ajax", "request", "handler", "ajaxrequesthandl", "java:359", "ajax", "request", "handler", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "request", "cycl", "handlerexecutor", "respond", "handler", "executor", "requestcycl", "java:865", "request", "cycl", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:64", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "requesthandlerstack", "execut", "request", "handler", "stack", "requesthandlerstack", "java:97", "request", "handler", "stack", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "execut", "request", "cycl", "requestcycl", "java:265", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequest", "request", "cycl", "process", "request", "requestcycl", "java:222", "request", "cycl", "at", "org", "apach", "wicket", "request", "cycl", "requestcycl", "processrequestanddetach", "request", "cycl", "process", "request", "detach", "requestcycl", "java:293", "request", "cycl", "at", "org", "apach", "wicket", "protocol", "ws", "abstractupgradefilt", "processrequestcycl", "abstract", "upgrad", "filter", "process", "request", "cycl", "abstractupgradefilt", "java:59", "abstract", "upgrad", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "processrequest", "wicket", "filter", "process", "request", "wicketfilt", "java:203", "wicket", "filter", "at", "org", "apach", "wicket", "protocol", "http", "wicketfilt", "dofilt", "wicket", "filter", "filter", "wicketfilt", "java:284", "wicket", "filter", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "servlet", "handler", "cachedchain", "dofilt", "cach", "chain", "filter", "servlethandl", "java:1652", "servlet", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "dohandl", "servlet", "handler", "handl", "servlethandl", "java:585", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:143", "scope", "handler", "at", "org", "eclips", "jetti", "secur", "securityhandl", "handl", "secur", "handler", "securityhandl", "java:577", "secur", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "dohandl", "session", "handler", "handl", "sessionhandl", "java:223", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "dohandl", "context", "handler", "handl", "contexthandl", "java:1125", "context", "handler", "at", "org", "eclips", "jetti", "servlet", "servlethandl", "doscop", "servlet", "handler", "scope", "servlethandl", "java:515", "servlet", "handler", "at", "org", "eclips", "jetti", "server", "session", "sessionhandl", "doscop", "session", "handler", "scope", "sessionhandl", "java:185", "session", "handler", "at", "org", "eclips", "jetti", "server", "handler", "contexthandl", "doscop", "context", "handler", "scope", "contexthandl", "java:1059", "context", "handler", "at", "org", "eclips", "jetti", "server", "handler", "scopedhandl", "handl", "scope", "handler", "scopedhandl", "java:141", "scope", "handler", "at", "org", "eclips", "jetti", "server", "handler", "handlerwrapp", "handl", "handler", "wrapper", "handlerwrapp", "java:97", "handler", "wrapper", "at", "org", "eclips", "jetti", "server", "server", "handl", "server", "java:497", "at", "org", "eclips", "jetti", "server", "httpchannel", "handl", "http", "channel", "httpchannel", "java:310", "http", "channel", "at", "org", "eclips", "jetti", "server", "httpconnect", "onfil", "http", "connect", "fillabl", "httpconnect", "java:248", "http", "connect", "at", "org", "eclips", "jetti", "io", "abstractconnect", "abstract", "connect", "run", "abstractconnect", "java:540", "abstract", "connect", "at", "org", "eclips", "jetti", "util", "thread", "queuedthreadpool", "runjob", "queu", "thread", "pool", "run", "job", "queuedthreadpool", "java:620", "queu", "thread", "pool", "at", "org", "eclips", "jetti", "util", "thread", "queuedthreadpool", "queu", "thread", "pool", "ru", "code"], "B_title": "method searchMarkupInTransparentResolversrewritten to use container markup fragment", "B_clean_title": ["method", "searchmarkupintransparentresolversrewritten", "search", "markup", "transpar", "resolversrewritten", "use", "contain", "markup", "fragment"]},
{"A_title": "Inconsistent state in Mongo/KernelRootBuilderThe state of Kernel- and MongoRootBuilder may turn inconsistent when a NodeStoreBranch.merge() performs a rebase followed by a failed merge on the underlying storage. The head and base are not properly updated to reflect the successful rebase.", "A_clean_title": ["inconsist", "state", "mongo", "kernelrootbuilderth", "kernel", "root", "builder", "state", "kernel", "mongorootbuild", "mongo", "root", "builder", "may", "turn", "inconsist", "when", "nodestorebranch", "merg", "node", "store", "branch", "perform", "rebas", "follow", "by", "fail", "merg", "underli", "storag", "head", "base", "are", "not", "properli", "updat", "reflect", "success", "rebas"], "B_title": "Inconsistent state in Mongo/KernelRootBuilder", "B_clean_title": ["inconsist", "state", "mongo", "kernelrootbuild", "kernel", "root", "builder"]},
{"A_title": "Date converters should use a new instance of DateFormat to be thread safePlease consider the linked issue WICKET-4833.  I had to open a new issue because I cannot attach the quickstart project Ive prepared to a closed issue.", "A_clean_title": ["date", "convert", "use", "new", "instanc", "dateformat", "date", "format", "thread", "safepleas", "safe", "pleas", "consid", "link", "issu", "wicket", "4833", "had", "open", "new", "issu", "becaus", "not", "attach", "quickstart", "project", "ive", "prepar", "close", "issu"], "B_title": "ConverterLocator should create a new instance for all date based converters", "B_clean_title": ["converterloc", "convert", "locat", "creat", "new", "instanc", "all", "date", "base", "convert"]},
{"A_title": "Break in finally block isnt optimized properlyNone", "A_clean_title": ["break", "final", "block", "isnt", "optim", "properlynon", "properli", "none"], "B_title": "Fix bug in MinimizeExitPoints with removing breaks inside finally blocks.", "B_clean_title": ["fix", "bug", "minimizeexitpoint", "minim", "exit", "point", "remov", "break", "insid", "final", "block"]},
{"A_title": "Dfp Dfp.multiply(int x) does not comply with the general contract FieldElement.multiply(int n)In class org.apache.commons.math3.Dfp  the method multiply(int n) is limited to 0 <= n <= 9999. This is not consistent with the general contract of FieldElement.multiply(int n) where there should be no limitation on the values of n.", "A_clean_title": ["dfp", "dfp", "multipli", "int", "not", "compli", "gener", "contract", "fieldel", "multipli", "field", "element", "int", "class", "org", "apach", "common", "math3", "dfp", "method", "multipli", "int", "limit", "9999", "thi", "not", "consist", "gener", "contract", "fieldel", "multipli", "field", "element", "int", "where", "there", "no", "limit", "valu"], "B_title": "Allow unlimited input values for Dfp#multiply.", "B_clean_title": ["allow", "unlimit", "input", "valu", "dfp", "multipli"]},
{"A_title": "Paths containing a Windows drive letter cannot be used in FileOutputFormatsPaths that contain a Windows drive letter such as file:///c:/my/directory cannot be used as output path for FileOutputFormat.  If done the following exception is thrown:  code Caused by: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: file:c:         at org.apache.flink.core.fs.Path.initialize(Path.java:242)         at org.apache.flink.core.fs.Path.<init>(Path.java:225)         at org.apache.flink.core.fs.Path.<init>(Path.java:138)         at org.apache.flink.core.fs.local.LocalFileSystem.pathToFile(LocalFileSystem.java:147)         at org.apache.flink.core.fs.local.LocalFileSystem.mkdirs(LocalFileSystem.java:232)         at org.apache.flink.core.fs.local.LocalFileSystem.mkdirs(LocalFileSystem.java:233)         at org.apache.flink.core.fs.local.LocalFileSystem.mkdirs(LocalFileSystem.java:233)         at org.apache.flink.core.fs.local.LocalFileSystem.mkdirs(LocalFileSystem.java:233)         at org.apache.flink.core.fs.local.LocalFileSystem.mkdirs(LocalFileSystem.java:233)         at org.apache.flink.core.fs.FileSystem.initOutPathLocalFS(FileSystem.java:603)         at org.apache.flink.api.common.io.FileOutputFormat.open(FileOutputFormat.java:233)         at org.apache.flink.api.java.io.CsvOutputFormat.open(CsvOutputFormat.java:158)         at org.apache.flink.runtime.operators.DataSinkTask.invoke(DataSinkTask.java:183)         at org.apache.flink.runtime.execution.RuntimeEnvironment.run(RuntimeEnvironment.java:217)         at java.lang.Thread.run(Unknown Source) Caused by: java.net.URISyntaxException: Relative path in absolute URI: file:c:         at java.net.URI.checkPath(Unknown Source)         at java.net.URI.<init>(Unknown Source)         at org.apache.flink.core.fs.Path.initialize(Path.java:240)         ... 14 more code", "A_clean_title": ["path", "contain", "window", "drive", "letter", "not", "use", "fileoutputformatspath", "file", "output", "format", "path", "that", "contain", "window", "drive", "letter", "such", "as", "file", "my", "directori", "not", "use", "as", "output", "path", "fileoutputformat", "file", "output", "format", "done", "follow", "except", "thrown", "code", "caus", "by", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "java", "net", "urisyntaxexcept", "uri", "syntax", "except", "rel", "path", "absolut", "uri", "file", "at", "org", "apach", "flink", "core", "fs", "path", "initi", "path", "java:242", "at", "org", "apach", "flink", "core", "fs", "path", "init", "path", "java:225", "at", "org", "apach", "flink", "core", "fs", "path", "init", "path", "java:138", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "pathtofil", "local", "file", "system", "path", "file", "localfilesystem", "java:147", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "mkdir", "local", "file", "system", "localfilesystem", "java:232", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "mkdir", "local", "file", "system", "localfilesystem", "java:233", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "mkdir", "local", "file", "system", "localfilesystem", "java:233", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "mkdir", "local", "file", "system", "localfilesystem", "java:233", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "local", "localfilesystem", "mkdir", "local", "file", "system", "localfilesystem", "java:233", "local", "file", "system", "at", "org", "apach", "flink", "core", "fs", "filesystem", "initoutpathlocalf", "file", "system", "init", "out", "path", "local", "fs", "filesystem", "java:603", "file", "system", "at", "org", "apach", "flink", "api", "common", "io", "fileoutputformat", "open", "file", "output", "format", "fileoutputformat", "java:233", "file", "output", "format", "at", "org", "apach", "flink", "api", "java", "io", "csvoutputformat", "open", "csv", "output", "format", "csvoutputformat", "java:158", "csv", "output", "format", "at", "org", "apach", "flink", "runtim", "oper", "datasinktask", "invok", "data", "sink", "task", "datasinktask", "java:183", "data", "sink", "task", "at", "org", "apach", "flink", "runtim", "execut", "runtimeenviron", "run", "runtim", "environ", "runtimeenviron", "java:217", "runtim", "environ", "at", "java", "lang", "thread", "run", "unknown", "sourc", "caus", "by", "java", "net", "urisyntaxexcept", "uri", "syntax", "except", "rel", "path", "absolut", "uri", "file", "at", "java", "net", "uri", "checkpath", "check", "path", "unknown", "sourc", "at", "java", "net", "uri", "init", "unknown", "sourc", "at", "org", "apach", "flink", "core", "fs", "path", "initi", "path", "java:240", "14", "more", "code"], "B_title": "Fix for file paths with Windows drive letters", "B_clean_title": ["fix", "file", "path", "window", "drive", "letter"]},
{"A_title": "NullPointerException in org.apache.wicket.markup.html.form.ValidationErrorFeedbackorg.apache.wicket.markup.html.form.ValidationErrorFeedback throws a NPE in the following situation:  - Form with a TextField<Integer> that has a RangeValidator - value outside range is entered - form is submitted  See attached quickstart.", "A_clean_title": ["nullpointerexcept", "null", "pointer", "except", "org", "apach", "wicket", "markup", "html", "form", "validationerrorfeedbackorg", "apach", "wicket", "markup", "html", "form", "validationerrorfeedback", "valid", "error", "feedbackorg", "valid", "error", "feedback", "throw", "npe", "follow", "situat", "form", "textfield", "text", "field", "integ", "that", "ha", "rangevalid", "rang", "valid", "valu", "outsid", "rang", "enter", "form", "submit", "see", "attach", "quickstart"], "B_title": "NullPointerException in org.apache.wicket.markup.html.form.ValidationErrorFeedback", "B_clean_title": ["nullpointerexcept", "null", "pointer", "except", "org", "apach", "wicket", "markup", "html", "form", "validationerrorfeedback", "valid", "error", "feedback"]},
{"A_title": "bug in Duration.toString(Locale locale)Duration.toString(Locale locale) misses milliseconds in line 529", "A_clean_title": ["bug", "durat", "tostr", "string", "local", "local", "durat", "tostr", "string", "local", "local", "miss", "millisecond", "line", "529"], "B_title": "bug in Duration.toString(Locale locale)", "B_clean_title": ["bug", "durat", "tostr", "string", "local", "local"]},
{"A_title": "ListPopulation Iterator allows you to remove chromosomes from the population.Calling the iterator method of ListPopulation returns an iterator of the protected modifiable list. Before returning the iterator we should wrap it in an unmodifiable list.", "A_clean_title": ["listpopul", "list", "popul", "iter", "allow", "you", "remov", "chromosom", "popul", "call", "iter", "method", "listpopul", "list", "popul", "return", "iter", "protect", "modifi", "list", "befor", "return", "iter", "we", "wrap", "it", "unmodifi", "list"], "B_title": "Fixed iterator() method in ListPopulation to return an iterator of the unmodifiable list thanks to Reid Hochstedler.", "B_clean_title": ["fix", "iter", "method", "listpopul", "list", "popul", "return", "iter", "unmodifi", "list", "thank", "reid", "hochstedl"]},
{"A_title": "o.a.j.o.spi.query.Filter exposes unexported class o.a.j.o.query.ast.SelectorImplThe interface o.a.j.o.spi.query.Filter uses in its public API the class o.a.j.o.query.ast.SelectorImpl but while the former is contained in an exported package the latter is not.", "A_clean_title": ["spi", "queri", "filter", "expos", "unexport", "class", "queri", "ast", "selectorimplth", "selector", "impl", "interfac", "spi", "queri", "filter", "use", "it", "public", "api", "class", "queri", "ast", "selectorimpl", "selector", "impl", "but", "while", "former", "contain", "export", "packag", "latter", "not"], "B_title": "o.a.j.o.spi.query.Filter exposes unexported class o.a.j.o.query.ast.SelectorImpl", "B_clean_title": ["spi", "queri", "filter", "expos", "unexport", "class", "queri", "ast", "selectorimpl", "selector", "impl"]},
{"A_title": "LIRS cache: zero size cache causes IllegalArgumentExceptionThe LIRS cache does not support a zero size cache currently. Such a configuration causes an IllegalArgumentException.  Instead no exception should be thrown and no or a minimum size cache should be used.", "A_clean_title": ["lir", "cach", "zero", "size", "cach", "caus", "illegalargumentexceptionth", "illeg", "argument", "except", "lir", "cach", "not", "support", "zero", "size", "cach", "current", "such", "configur", "caus", "illegalargumentexcept", "illeg", "argument", "except", "instead", "no", "except", "thrown", "no", "or", "minimum", "size", "cach", "use"], "B_title": "LIRS cache: zero size cache causes IllegalArgumentException", "B_clean_title": ["lir", "cach", "zero", "size", "cach", "caus", "illegalargumentexcept", "illeg", "argument", "except"]},
{"A_title": "Document split suppressed with steady load on many cluster nodesDocument split is suppressed when there is a steady write load on many cluster nodes. The document grows bigger over time and leads to poor performance.", "A_clean_title": ["document", "split", "suppress", "steadi", "load", "mani", "cluster", "nodesdocu", "node", "document", "split", "suppress", "when", "there", "steadi", "write", "load", "mani", "cluster", "node", "document", "grow", "bigger", "over", "time", "lead", "poor", "perform"], "B_title": "Document split suppressed with steady load on many cluster nodes", "B_clean_title": ["document", "split", "suppress", "steadi", "load", "mani", "cluster", "node"]},
{"A_title": "Ajax behaviors are failing in stateless pagesStateless ajax behaviors are not working in stateless pages in 1.5-RC4.2. I verified it with the stateless demo project of Martin Grigorov (https://github.com/martin-g/wicket-stateless) when changing the dropdown on the start page an exception is thrown (clicking the increment link causes a similar exception):   org.apache.wicket.behavior.InvalidBehaviorIdException: Cannot find behavior with id: 0 on component: DropDownChoice Component id = c  At first glance the reason may be located in org.apache.wicket.Behaviors.getBehaviorById() which does not create the ID list if missing (getBehaviorsIdList(false) in line 286 instead of getBehaviorsIdList(true)) because this error does not occur when getBehaviorId() was manually called in the page constructor to force creation of the list.", "A_clean_title": ["ajax", "behavior", "are", "fail", "stateless", "pagesstateless", "page", "stateless", "ajax", "behavior", "are", "not", "work", "stateless", "page", "rc4", "verifi", "it", "stateless", "demo", "project", "martin", "grigorov", "http", "stateless", "wicket", "github", "com", "martin", "when", "chang", "dropdown", "start", "page", "except", "thrown", "click", "increment", "link", "caus", "similar", "except", "org", "apach", "wicket", "behavior", "invalidbehavioridexcept", "invalid", "behavior", "id", "except", "not", "find", "behavior", "id", "compon", "dropdownchoic", "drop", "down", "choic", "compon", "id", "at", "first", "glanc", "reason", "may", "locat", "org", "apach", "wicket", "behavior", "getbehaviorbyid", "get", "behavior", "by", "id", "which", "not", "creat", "id", "list", "miss", "getbehaviorsidlist", "get", "behavior", "id", "list", "fals", "line", "286", "instead", "getbehaviorsidlist", "get", "behavior", "id", "list", "true", "becaus", "thi", "error", "not", "occur", "when", "getbehaviorid", "get", "behavior", "id", "wa", "manual", "call", "page", "constructor", "forc", "creation", "list"], "B_title": "Ajax behaviors are failing in stateless pages", "B_clean_title": ["ajax", "behavior", "are", "fail", "stateless", "page"]},
{"A_title": "cGuard protocol decoding issueIve got a pair of cGuard Atom devices  one of the them is 2015 and another one - 2016. Im trying to install and configure the Traccar server (inside Docker) to acquire data from the devices.  Traccar version: 3.10  cGuard Atom fw: 3.2.3 (the latest available) The server successfully detects a new device (2017-04-09 03:06:43  WARN: Unknown device - 35338606530**** (***)) and after a couple of minutes begins to decode gps-data. However the navi data seem to be being decoded incorrectly. All the testing time coordinates are zeroes the datetime mark correspond to Unix epoch time etc.. (see below).   The hex-decoder on the Trackar site correctly decodes HEX-parts of the data:", "A_clean_title": ["cguard", "guard", "protocol", "decod", "issueiv", "issu", "ive", "got", "pair", "cguard", "guard", "atom", "devic", "one", "them", "2015", "anoth", "one", "2016", "im", "tri", "instal", "configur", "traccar", "server", "insid", "docker", "acquir", "data", "devic", "traccar", "version", "10", "cguard", "guard", "atom", "fw", "latest", "avail", "server", "success", "detect", "new", "devic", "2017", "04", "09", "03:06:43", "warn", "unknown", "devic", "35338606530", "after", "coupl", "minut", "begin", "decod", "gp", "data", "howev", "navi", "data", "seem", "be", "decod", "incorrectli", "all", "test", "time", "coordin", "are", "zero", "datetim", "mark", "correspond", "unix", "epoch", "time", "etc", "see", "below", "hex", "decod", "trackar", "site", "correctli", "decod", "hex", "part", "data"], "B_title": "Import cGuard protocol decoder (fix #3080)", "B_clean_title": ["import", "cguard", "guard", "protocol", "decod", "fix", "3080"]},
{"A_title": "OnChangeAjaxBehavior should listen for both inputchange and change events for TextField and TextAreaWICKET-5603 introduced a regression that a TextField using OnChangeAjaxBehavior doesnt work anymore when used as date picker or Select2. The problem is that usually extensions like DatePicker and Select2 will fire change event when they update the text input.  OnChangeAjaxBehavior should use both inputchange and change events for TextField and TextArea components.", "A_clean_title": ["onchangeajaxbehavior", "chang", "ajax", "behavior", "listen", "both", "inputchang", "chang", "event", "textfield", "text", "field", "textareawicket", "5603", "text", "area", "wicket", "introduc", "regress", "that", "textfield", "text", "field", "onchangeajaxbehavior", "chang", "ajax", "behavior", "doesnt", "work", "anymor", "when", "use", "as", "date", "picker", "or", "select2", "problem", "that", "usual", "extens", "like", "datepick", "date", "picker", "select2", "will", "fire", "chang", "event", "when", "they", "updat", "text", "input", "onchangeajaxbehavior", "chang", "ajax", "behavior", "use", "both", "inputchang", "chang", "event", "textfield", "text", "field", "textarea", "text", "area", "compon"], "B_title": "OnChangeAjaxBehavior should listen for both inputchange and change events for TextField and TextArea", "B_clean_title": ["onchangeajaxbehavior", "chang", "ajax", "behavior", "listen", "both", "inputchang", "chang", "event", "textfield", "text", "field", "textarea", "text", "area"]},
{"A_title": "Off-by-one error in FamilyIntersectingIteratorIn the buildDocKey() function within the FamilyIntersectingIterator there is a bug that shortens the docID by 1.  This causes the wrong docs data to be returned in the results of a query using this Iterator.", "A_clean_title": ["off", "by", "one", "error", "familyintersectingiteratorin", "famili", "intersect", "iter", "builddockey", "build", "doc", "key", "function", "within", "familyintersectingiter", "famili", "intersect", "iter", "there", "bug", "that", "shorten", "docid", "doc", "id", "by", "thi", "caus", "wrong", "doc", "data", "return", "result", "queri", "thi", "iter"], "B_title": "merge to trunk", "B_clean_title": ["merg", "trunk"]},
{"A_title": "Errors creating/parsing dates with specific time zones.The results are out of 572 time zones 130 fail and 30 throw exceptions.  The failures are the most interesting. When I query DateTimeZone to get its time zone ids I will get a time zone like America/Atka. When I take that id and create a date time with it its time zone id is America/Adak. It is like there are multiple list of time zones in Joda time and they are out of sync.", "A_clean_title": ["error", "creat", "pars", "date", "specif", "time", "zone", "result", "are", "out", "572", "time", "zone", "130", "fail", "30", "throw", "except", "failur", "are", "most", "interest", "when", "queri", "datetimezon", "date", "time", "zone", "get", "it", "time", "zone", "id", "will", "get", "time", "zone", "like", "america", "atka", "when", "take", "that", "id", "creat", "date", "time", "it", "it", "time", "zone", "id", "america", "adak", "it", "like", "there", "are", "multipl", "list", "time", "zone", "joda", "time", "they", "are", "out", "sync"], "B_title": "Fix zone id parsing for ids like America/Dawson_Creek 3427389", "B_clean_title": ["fix", "zone", "id", "pars", "id", "like", "creek", "america", "dawson", "3427389"]},
{"A_title": "Missing commit hooks in upgradeTheres a TODO in the RepositoryUpgrade class about missing commit hooks. For example the PermissionHook isnt currently run as a part of the upgrade which breaks permission evaluation even though the actual ACL nodes are present after the upgrade.", "A_clean_title": ["miss", "commit", "hook", "upgradether", "upgrad", "there", "todo", "repositoryupgrad", "repositori", "upgrad", "class", "about", "miss", "commit", "hook", "exampl", "permissionhook", "permiss", "hook", "isnt", "current", "run", "as", "part", "upgrad", "which", "break", "permiss", "evalu", "even", "though", "actual", "acl", "node", "are", "present", "after", "upgrad"], "B_title": "Missing commit hooks in upgrade", "B_clean_title": ["miss", "commit", "hook", "upgrad"]},
{"A_title": "SegmentWriter saves references to external blobsThe new SegmentWriteOperation#internalWriteStream method checks whether the input stream to write is a SegmentStream. If its writer will reuse existing block ids rather than storing the whole stream.  It should also check whether the blocks in SegmentStream comes from the same tracker / segment store. Otherwise this will create invalid references if someone invokes the internalWriteStream() method with a SegmentStream created externally.", "A_clean_title": ["segmentwrit", "segment", "writer", "save", "refer", "extern", "blobsth", "blob", "new", "segmentwriteoper", "segment", "write", "oper", "internalwritestream", "intern", "write", "stream", "method", "check", "whether", "input", "stream", "write", "segmentstream", "segment", "stream", "it", "writer", "will", "reus", "exist", "block", "id", "rather", "than", "store", "whole", "stream", "it", "also", "check", "whether", "block", "segmentstream", "segment", "stream", "come", "same", "tracker", "segment", "store", "otherwis", "thi", "will", "creat", "invalid", "refer", "someon", "invok", "internalwritestream", "intern", "write", "stream", "method", "segmentstream", "segment", "stream", "creat", "extern"], "B_title": "SegmentWriter saves references to external blobs", "B_clean_title": ["segmentwrit", "segment", "writer", "save", "refer", "extern", "blob"]},
{"A_title": "Fraction.comparTo returns 0 for some differente fractionsIf two different fractions evaluate to the same double due to limited precision the compareTo methode returns 0 as if they were identical.  // value is roughly PI - 3.07e-18 Fraction pi1 = new Fraction(1068966896 340262731);  // value is roughly PI + 1.936e-17 Fraction pi2 = new Fraction( 411557987 131002976);  System.out.println(pi1.doubleValue() - pi2.doubleValue()); // exactly 0.0 due to limited IEEE754 precision System.out.println(pi1.compareTo(pi2)); // display 0 instead of a negative value", "A_clean_title": ["fraction", "comparto", "compar", "return", "some", "different", "fractionsif", "fraction", "two", "differ", "fraction", "evalu", "same", "doubl", "due", "limit", "precis", "compareto", "compar", "method", "return", "as", "they", "were", "ident", "valu", "roughli", "pi", "18", "07e", "fraction", "pi1", "new", "fraction", "1068966896", "340262731", "valu", "roughli", "pi", "17", "936e", "fraction", "pi2", "new", "fraction", "411557987", "131002976", "system", "out", "println", "pi1", "doublevalu", "doubl", "valu", "pi2", "doublevalu", "doubl", "valu", "exactli", "due", "limit", "ieee754", "precis", "system", "out", "println", "pi1", "compareto", "compar", "pi2", "display", "instead", "neg", "valu"], "B_title": "Fixed a comparison error when two different fractions evaluate to the same double due to limited precision. Jira: MATH-252", "B_clean_title": ["fix", "comparison", "error", "when", "two", "differ", "fraction", "evalu", "same", "doubl", "due", "limit", "precis", "jira", "math", "252"]},
{"A_title": "Incorrect Kendall Tau calc due to data type mistmatchThe Kendall Tau calculation returns a number from -1.0 to 1.0  due to a mixing of ints and longs a mistake occurs on large size columns (arrays) passed to the function. an array size of > 50350 triggers the condition in my case - although it may be data dependent  the ver 3.5 library returns 2.6 as a result (outside of the defined range of Kendall Tau)  with the cast to long below - the result reutns to its expected value   commons.math3.stat.correlation.KendallsCorrelation.correlation   heres the sample code I used: I added the cast to long of swaps in the   int swaps = 1077126315;  final long numPairs = sum(50350 - 1);     long tiedXPairs = 0;         long tiedXYPairs = 0;         long tiedYPairs = 0;            final long concordantMinusDiscordant = numPairs - tiedXPairs - tiedYPairs + tiedXYPairs - 2 * (long) swaps;         final double nonTiedPairsMultiplied = 1.6e18;         double myTest = concordantMinusDiscordant / FastMath.sqrt(nonTiedPairsMultiplied);", "A_clean_title": ["incorrect", "kendal", "tau", "calc", "due", "data", "type", "mistmatchth", "mistmatch", "kendal", "tau", "calcul", "return", "number", "due", "mix", "int", "long", "mistak", "occur", "larg", "size", "column", "array", "pass", "function", "array", "size", "50350", "trigger", "condit", "my", "case", "although", "it", "may", "data", "depend", "ver", "librari", "return", "as", "result", "outsid", "defin", "rang", "kendal", "tau", "cast", "long", "below", "result", "reutn", "it", "expect", "valu", "common", "math3", "stat", "correl", "kendallscorrel", "correl", "kendal", "correl", "here", "sampl", "code", "use", "ad", "cast", "long", "swap", "int", "swap", "1077126315", "final", "long", "numpair", "num", "pair", "sum", "50350", "long", "tiedxpair", "tie", "pair", "long", "tiedxypair", "tie", "xy", "pair", "long", "tiedypair", "tie", "pair", "final", "long", "concordantminusdiscord", "concord", "minu", "discord", "numpair", "num", "pair", "tiedxpair", "tie", "pair", "tiedypair", "tie", "pair", "tiedxypair", "tie", "xy", "pair", "long", "swap", "final", "doubl", "nontiedpairsmultipli", "non", "tie", "pair", "multipli", "6e18", "doubl", "mytest", "my", "test", "concordantminusdiscord", "concord", "minu", "discord", "fastmath", "sqrt", "fast", "math", "nontiedpairsmultipli", "non", "tie", "pair", "multipli"], "B_title": "Fixed incorrect Kendalls tau coefficient calculation due to internal integer overflow. Thanks to Marc Rosen.", "B_clean_title": ["fix", "incorrect", "kendal", "tau", "coeffici", "calcul", "due", "intern", "integ", "overflow", "thank", "marc", "rosen"]},
{"A_title": "XmlPullParser doesnt parse correctly attributes with complex namespaceHaving a markup like: <a class=addthis_button_google_plusone_badge g:plusone:size=smallbadge  g:plusone:href=https://plus.google.com/25252/></a> causes XmlPullParser to throw the following exception:  java.text.ParseException: Same attribute found twice: g:plusone (line 19 column 100)      at org.apache.wicket.markup.parser.XmlPullParser.parseTagText(XmlPullParser.java:673)      at org.apache.wicket.markup.parser.XmlPullParser.next(XmlPullParser.java:294)      at org.apache.wicket.markup.parser.filter.RootMarkupFilter.nextElement(RootMarkupFilter.java:58) .....", "A_clean_title": ["xmlpullpars", "xml", "pull", "parser", "doesnt", "pars", "correctli", "attribut", "complex", "namespacehav", "namespac", "have", "markup", "like", "class=addthi", "button", "googl", "pluson", "badg", "pluson", "size=smallbadg", "pluson", "href=http", "googl", "plu", "com", "25252", "caus", "xmlpullpars", "xml", "pull", "parser", "throw", "follow", "except", "java", "text", "parseexcept", "pars", "except", "same", "attribut", "found", "twice", "pluson", "line", "19", "column", "100", "at", "org", "apach", "wicket", "markup", "parser", "xmlpullpars", "parsetagtext", "xml", "pull", "parser", "pars", "tag", "text", "xmlpullpars", "java:673", "xml", "pull", "parser", "at", "org", "apach", "wicket", "markup", "parser", "xmlpullpars", "next", "xml", "pull", "parser", "xmlpullpars", "java:294", "xml", "pull", "parser", "at", "org", "apach", "wicket", "markup", "parser", "filter", "rootmarkupfilt", "nextel", "root", "markup", "filter", "next", "element", "rootmarkupfilt", "java:58", "root", "markup", "filter"], "B_title": "XmlPullParser doesnt parse correctly attributes with complex namespace", "B_clean_title": ["xmlpullpars", "xml", "pull", "parser", "doesnt", "pars", "correctli", "attribut", "complex", "namespac"]},
{"A_title": "Compiler removes function properties that it should notNone", "A_clean_title": ["compil", "remov", "function", "properti", "that", "it", "notnon", "not", "none"], "B_title": "Turn off collapsing for non-constructor function properties. Fixes issue 289.", "B_clean_title": ["turn", "off", "collaps", "non", "constructor", "function", "properti", "fix", "issu", "289"]},
{"A_title": "Test failure: CompactionMapTest.removeSomeSaid test fails sporadically:  noformat at org.junit.Assert.assertNull(Assert.java:562) at org.apache.jackrabbit.oak.plugins.segment.CompactionMapTest.removeSome(CompactionMapTest.java:156) noformat  This is a regression introduced with OAK-3501: the recent map gets not cleared when segmentIdMap is empty. This can happen when a recent key is removed again while there are no other changes.", "A_clean_title": ["test", "failur", "compactionmaptest", "removesomesaid", "compact", "map", "test", "remov", "some", "said", "test", "fail", "sporad", "noformat", "at", "org", "junit", "assert", "assertnul", "assert", "null", "assert", "java:562", "at", "org", "apach", "jackrabbit", "oak", "plugin", "segment", "compactionmaptest", "removesom", "compact", "map", "test", "remov", "some", "compactionmaptest", "java:156", "compact", "map", "test", "noformat", "thi", "regress", "introduc", "oak", "3501", "recent", "map", "get", "not", "clear", "when", "segmentidmap", "segment", "id", "map", "empti", "thi", "happen", "when", "recent", "key", "remov", "again", "while", "there", "are", "no", "other", "chang"], "B_title": "Test failure: CompactionMapTest.removeSome Unconditionally clear recent keys on compress", "B_clean_title": ["test", "failur", "compactionmaptest", "removesom", "compact", "map", "test", "remov", "some", "uncondit", "clear", "recent", "key", "compress"]},
{"A_title": "SmartLinkLabel failing to process email with +Using SmartLinkLabel with an email address that includes a + generates a link only on the right-most part of the address.  Example: - my+test@example.com Will generate a link like: - my+<a href=mailto:test@example.com>test@example.com@pappin.ca</a>  THe addition of the + char is a valid email address format.", "A_clean_title": ["smartlinklabel", "smart", "link", "label", "fail", "process", "email", "+use", "smartlinklabel", "smart", "link", "label", "email", "address", "that", "includ", "gener", "link", "onli", "right", "most", "part", "address", "exampl", "my+test", "exampl", "com", "will", "gener", "link", "like", "my+", "href=mailto", "test", "exampl", "com", "test", "exampl", "com", "pappin", "ca", "he", "addit", "char", "valid", "email", "address", "format"], "B_title": "Issue: WICKET-3174", "B_clean_title": ["issu", "wicket", "3174"]},
{"A_title": "FileStore.flush prone to races leading to corruptionThere is a small window in FileStore.flush that could lead to data corruption: if we crash right after setting the persisted head but before any delay-flushed SegmentBufferWriter instance flushes (see SegmentBufferWriterPool.returnWriter()) then that data is lost although it might already be referenced from the persisted head.  We need to come up with a test case for this.   A possible fix would be to return a future from SegmentWriter.flush and rely on a completion callback. Such a change would most likely also be useful for OAK-3690.", "A_clean_title": ["filestor", "flush", "file", "store", "prone", "race", "lead", "corruptionther", "corrupt", "there", "small", "window", "filestor", "flush", "file", "store", "that", "could", "lead", "data", "corrupt", "we", "crash", "right", "after", "set", "persist", "head", "but", "befor", "ani", "delay", "flush", "segmentbufferwrit", "segment", "buffer", "writer", "instanc", "flush", "see", "segmentbufferwriterpool", "returnwrit", "segment", "buffer", "writer", "pool", "return", "writer", "then", "that", "data", "lost", "although", "it", "might", "alreadi", "referenc", "persist", "head", "we", "need", "come", "up", "test", "case", "thi", "possibl", "fix", "would", "return", "futur", "segmentwrit", "flush", "segment", "writer", "reli", "complet", "callback", "such", "chang", "would", "most", "like", "also", "use", "oak", "3690"], "B_title": "FileStore.flush prone to races leading to corruption Make SegmentBufferWriterPool.flush synchrnous again but avoid flusing segments while holding locks", "B_clean_title": ["filestor", "flush", "file", "store", "prone", "race", "lead", "corrupt", "make", "segmentbufferwriterpool", "flush", "segment", "buffer", "writer", "pool", "synchrnou", "again", "but", "avoid", "fluse", "segment", "while", "hold", "lock"]},
{"A_title": "NPE trying to add a node to an nt:folder nodeThe following code throws a NPE:  code Session s = getAdminSession(); s.getRootNode().addNode(a nt:folder).addNode(b); s.save();         code  Stack trace: code java.lang.NullPointerException at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:191) at org.apache.jackrabbit.oak.namepath.LocalNameMapper.getOakNameOrNull(LocalNameMapper.java:82) at org.apache.jackrabbit.oak.namepath.GlobalNameMapper.getOakName(GlobalNameMapper.java:64) at org.apache.jackrabbit.oak.namepath.NamePathMapperImpl.getOakName(NamePathMapperImpl.java:62) at org.apache.jackrabbit.oak.plugins.nodetype.ReadOnlyNodeTypeManager.getOakName(ReadOnlyNodeTypeManager.java:92) at org.apache.jackrabbit.oak.plugins.nodetype.ReadOnlyNodeTypeManager.getNodeType(ReadOnlyNodeTypeManager.java:186) at org.apache.jackrabbit.oak.jcr.NodeImpl 5.perform(NodeImpl.java:265) at org.apache.jackrabbit.oak.jcr.NodeImpl 5.perform(NodeImpl.java:1) at org.apache.jackrabbit.oak.jcr.SessionDelegate.perform(SessionDelegate.java:136) at org.apache.jackrabbit.oak.jcr.NodeImpl.addNode(NodeImpl.java:219) at org.apache.jackrabbit.oak.jcr.NodeImpl.addNode(NodeImpl.java:210) at org.apache.jackrabbit.oak.jcr.CRUDTest.nodeType(CRUDTest.java:122) code", "A_clean_title": ["npe", "tri", "add", "node", "nt", "folder", "nodeth", "node", "follow", "code", "throw", "npe", "code", "session", "getadminsess", "get", "admin", "session", "getrootnod", "get", "root", "node", "addnod", "add", "node", "nt", "folder", "addnod", "add", "node", "save", "code", "stack", "trace", "code", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "com", "googl", "common", "base", "precondit", "checknotnul", "check", "not", "null", "precondit", "java:191", "at", "org", "apach", "jackrabbit", "oak", "namepath", "localnamemapp", "getoaknameornul", "local", "name", "mapper", "get", "oak", "name", "or", "null", "localnamemapp", "java:82", "local", "name", "mapper", "at", "org", "apach", "jackrabbit", "oak", "namepath", "globalnamemapp", "getoaknam", "global", "name", "mapper", "get", "oak", "name", "globalnamemapp", "java:64", "global", "name", "mapper", "at", "org", "apach", "jackrabbit", "oak", "namepath", "namepathmapperimpl", "getoaknam", "name", "path", "mapper", "impl", "get", "oak", "name", "namepathmapperimpl", "java:62", "name", "path", "mapper", "impl", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "readonlynodetypemanag", "getoaknam", "read", "onli", "node", "type", "manag", "get", "oak", "name", "readonlynodetypemanag", "java:92", "read", "onli", "node", "type", "manag", "at", "org", "apach", "jackrabbit", "oak", "plugin", "nodetyp", "readonlynodetypemanag", "getnodetyp", "read", "onli", "node", "type", "manag", "get", "node", "type", "readonlynodetypemanag", "java:186", "read", "onli", "node", "type", "manag", "at", "org", "apach", "jackrabbit", "oak", "jcr", "nodeimpl", "node", "impl", "perform", "nodeimpl", "java:265", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "nodeimpl", "node", "impl", "perform", "nodeimpl", "java:1", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "sessiondeleg", "perform", "session", "deleg", "sessiondeleg", "java:136", "session", "deleg", "at", "org", "apach", "jackrabbit", "oak", "jcr", "nodeimpl", "addnod", "node", "impl", "add", "node", "nodeimpl", "java:219", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "nodeimpl", "addnod", "node", "impl", "add", "node", "nodeimpl", "java:210", "node", "impl", "at", "org", "apach", "jackrabbit", "oak", "jcr", "crudtest", "nodetyp", "crud", "test", "node", "type", "crudtest", "java:122", "crud", "test", "code"], "B_title": "NPE trying to add a node to an nt:folder node", "B_clean_title": ["npe", "tri", "add", "node", "nt", "folder", "node"]},
{"A_title": "Verify all methods in the ProxyService that take table names actually throw TableNotFoundException when the table is missing.None", "A_clean_title": ["verifi", "all", "method", "proxyservic", "proxi", "servic", "that", "take", "tabl", "name", "actual", "throw", "tablenotfoundexcept", "tabl", "not", "found", "except", "when", "tabl", "miss", "none"], "B_title": "mode some more methods in proxy throw table not found exception.  cleaned up proxy formatting.  made proxy throw more specific exceptions.", "B_clean_title": ["mode", "some", "more", "method", "proxi", "throw", "tabl", "not", "found", "except", "clean", "up", "proxi", "format", "made", "proxi", "throw", "more", "specif", "except"]},
{"A_title": "DefaultSyncContext.syncMembership may sync group of a foreign IDPWith the following scenario the DefaultSyncContext.syncMembership may end up synchronizing (i.e. updating) a group defined by an foreign IDP and even add the user to be synchronized as a new member:  - configuration with different IDPs - foreign IDP synchronizes a given external group groupA => rep:externalID points to foreign-IDP (e.g. rep:externalId = groupA;foreignIDP) - my-IDP contains a group with the same ID (but obviously with a different rep:externalID) and user that has declared group membership pointing to groupA from my IDP  if synchronizing my user first the groupA will be created with a rep:externalId = groupA;myIDP. however if the group has been synced before by the foreignIDP the code fails to verify that an existing group groupA really belongs to the same IDP and thus may end up synchronizing the group and updating its members.  IMHO thats a critical issue as it violates the IDP boundaries. the fix is pretty trivial as it only requires testing for the IDP of the existing group as we do it in other places (even in the same method).", "A_clean_title": ["defaultsynccontext", "syncmembership", "default", "sync", "context", "sync", "membership", "may", "sync", "group", "foreign", "idpwith", "idp", "follow", "scenario", "defaultsynccontext", "syncmembership", "default", "sync", "context", "sync", "membership", "may", "end", "up", "synchron", "updat", "group", "defin", "by", "foreign", "idp", "even", "add", "user", "synchron", "as", "new", "member", "configur", "differ", "idp", "id", "ps", "foreign", "idp", "synchron", "given", "extern", "group", "groupa", "group", "rep", "externalid", "extern", "id", "point", "foreign", "idp", "rep", "externalid", "extern", "id", "groupa", "group", "foreignidp", "foreign", "idp", "my", "idp", "contain", "group", "same", "id", "but", "obvious", "differ", "rep", "externalid", "extern", "id", "user", "that", "ha", "declar", "group", "membership", "point", "groupa", "group", "my", "idp", "synchron", "my", "user", "first", "groupa", "group", "will", "creat", "rep", "externalid", "extern", "id", "groupa", "group", "myidp", "my", "idp", "howev", "group", "ha", "been", "sync", "befor", "by", "foreignidp", "foreign", "idp", "code", "fail", "verifi", "that", "exist", "group", "groupa", "group", "realli", "belong", "same", "idp", "thu", "may", "end", "up", "synchron", "group", "updat", "it", "member", "imho", "that", "critic", "issu", "as", "it", "violat", "idp", "boundari", "fix", "pretti", "trivial", "as", "it", "onli", "requir", "test", "idp", "exist", "group", "as", "we", "it", "other", "place", "even", "same", "method"], "B_title": ": DefaultSyncContext.syncMembership may sync group of a foreign IDP", "B_clean_title": ["defaultsynccontext", "syncmembership", "default", "sync", "context", "sync", "membership", "may", "sync", "group", "foreign", "idp"]},
{"A_title": "Division by zeroIn class Complex division by zero always returns NaN. I think that it should return NaN only when the numerator is also ZERO otherwise the result should be INF. See here|http://en.wikipedia.org/wiki/Riemann_sphere#Arithmetic_operations.", "A_clean_title": ["divis", "by", "zeroin", "zero", "class", "complex", "divis", "by", "zero", "alway", "return", "nan", "na", "think", "that", "it", "return", "nan", "na", "onli", "when", "numer", "also", "zero", "otherwis", "result", "inf", "see", "here|http", "wikipedia", "en", "sphere", "org", "wiki", "riemann", "arithmet", "oper"], "B_title": "Reverting to previous behaviour as requested by P. Steitz.", "B_clean_title": ["revert", "previou", "behaviour", "as", "request", "by", "steitz"]},
{"A_title": "SimpleTree example not working with CryptoMapperAdding the following lines to WicketExampleApplication.java causes the SimpleTree example to break. There are no expand icons anymore and there is no way to expand the tree. Even the expand link will not work.  Add to WicketExampleApplication.java   IRequestMapper cryptoMapper = new CryptoMapper(getRootRequestMapper() this); setRootRequestMapper(cryptoMapper);   Comment out in WicketExampleApplication.java   //getSecuritySettings().setCryptFactory(new ClassCryptFactory(NoCrypt.class ISecuritySettings.DEFAULT_ENCRYPTION_KEY));  Without the CryptoMapper everythings works fine.", "A_clean_title": ["simpletre", "simpl", "tree", "exampl", "not", "work", "cryptomapperad", "crypto", "mapper", "ad", "follow", "line", "wicketexampleappl", "java", "wicket", "exampl", "applic", "caus", "simpletre", "simpl", "tree", "exampl", "break", "there", "are", "no", "expand", "icon", "anymor", "there", "no", "way", "expand", "tree", "even", "expand", "link", "will", "not", "work", "add", "wicketexampleappl", "java", "wicket", "exampl", "applic", "irequestmapp", "request", "mapper", "cryptomapp", "crypto", "mapper", "new", "cryptomapp", "crypto", "mapper", "getrootrequestmapp", "get", "root", "request", "mapper", "thi", "setrootrequestmapp", "set", "root", "request", "mapper", "cryptomapp", "crypto", "mapper", "comment", "out", "wicketexampleappl", "java", "wicket", "exampl", "applic", "getsecurityset", "get", "secur", "set", "setcryptfactori", "set", "crypt", "factori", "new", "classcryptfactori", "class", "crypt", "factori", "nocrypt", "class", "no", "crypt", "isecurityset", "secur", "set", "default", "encrypt", "key", "without", "cryptomapp", "crypto", "mapper", "everyth", "work", "fine"], "B_title": "SimpleTree example not working with CryptoMapper", "B_clean_title": ["simpletre", "simpl", "tree", "exampl", "not", "work", "cryptomapp", "crypto", "mapper"]},
{"A_title": "Select component loses its valueSelect component loses selected option and shows the first option in some situations (one example is when you try to submit a form but there are validation errors).  It was working fine in 1.4.18 but its broken in 1.4.19.This must be caused by the solution from this issue https://issues.apache.org/jira/browse/WICKET-3962 I think the problem is likely in Select.isSelected method where String paths = getInputAsArray() is actually an array of uuid-s so uuid-s are compared to paths.  I havent tested wicket 1.5 but this problem may also affect 1.5 versions.", "A_clean_title": ["select", "compon", "lose", "it", "valueselect", "valu", "select", "compon", "lose", "select", "option", "show", "first", "option", "some", "situat", "one", "exampl", "when", "you", "tri", "submit", "form", "but", "there", "are", "valid", "error", "it", "wa", "work", "fine", "18", "but", "it", "broken", "19", "thi", "must", "caus", "by", "solut", "thi", "issu", "http", "3962", "apach", "issu", "org", "jira", "brows", "wicket", "think", "problem", "like", "select", "isselect", "select", "method", "where", "string", "path", "getinputasarray", "get", "input", "as", "array", "actual", "array", "uuid", "so", "uuid", "are", "compar", "path", "havent", "test", "wicket", "but", "thi", "problem", "may", "also", "affect", "version"], "B_title": "Select keep selection on form error", "B_clean_title": ["select", "keep", "select", "form", "error"]},
{"A_title": "XPath query failures for mvpsAdding some cases related to mvps that are not currently covered by the existing (jackrabbit) tests.", "A_clean_title": ["xpath", "path", "queri", "failur", "mvpsad", "mvp", "ad", "some", "case", "relat", "mvp", "that", "are", "not", "current", "cover", "by", "exist", "jackrabbit", "test"], "B_title": "XPath query failures for mvps", "B_clean_title": ["xpath", "path", "queri", "failur", "mvp"]},
{"A_title": "AjaxFormChoiceComponentUpdatingBehavior fails for choices containing other invalid FormComponentsIf a TextField inside a RadioGroup has a ValidationError processing of AjaxFormChoiceComponentUpdatingBehavior will erroneously update the groups model:  - RadioGroup#validate() does not convert the input because #isValid() returns false (since the nested textfield has an error message) - the behavior tests #hasErrorMessage() on the group which returns false (since the group itself doesnt have an error message) - the behavior continues processing with a null value", "A_clean_title": ["ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "fail", "choic", "contain", "other", "invalid", "formcomponentsif", "form", "compon", "textfield", "text", "field", "insid", "radiogroup", "radio", "group", "ha", "validationerror", "valid", "error", "process", "ajaxformchoicecomponentupdatingbehavior", "ajax", "form", "choic", "compon", "updat", "behavior", "will", "erron", "updat", "group", "model", "radiogroup", "radio", "group", "valid", "not", "convert", "input", "becaus", "isvalid", "valid", "return", "fals", "sinc", "nest", "textfield", "ha", "error", "messag", "behavior", "test", "haserrormessag", "ha", "error", "messag", "group", "which", "return", "fals", "sinc", "group", "itself", "doesnt", "have", "error", "messag", "behavior", "continu", "process", "null", "valu"], "B_title": "use #isValid() instead of #hasErrorMessage() as the FormComponent does too", "B_clean_title": ["use", "isvalid", "valid", "instead", "haserrormessag", "ha", "error", "messag", "as", "formcompon", "form", "compon", "too"]},
{"A_title": "Wrong code generated if mixing types in ternary operatorNone", "A_clean_title": ["wrong", "code", "gener", "mix", "type", "ternari", "operatornon", "oper", "none"], "B_title": "Properly determine if any possible results may be a string. Fixes issue 821", "B_clean_title": ["properli", "determin", "ani", "possibl", "result", "may", "string", "fix", "issu", "821"]},
{"A_title": "Problem with setting of IComponentInheritedModel and FLAG_INHERITABLE_MODELDescribed in the mailing list: http://mail-archives.apache.org/mod_mbox/wicket-users/201407.mbox/%3CCAF2_608c8TOZjprV8Md15KJpRET6YQdXHe%3DwRzF-y5G_zAXcDg%40mail.gmail.com%3E  Im aware of the another issue (https://issues.apache.org/jira/browse/WICKET-3413) which dealt with the exact same code - and I believe there was a mistake in the solution that leads to this issue.  Please see the attached quickstart (including a JUnit test) to reproduce the error.", "A_clean_title": ["problem", "set", "icomponentinheritedmodel", "compon", "inherit", "model", "flag", "inherit", "modeldescrib", "model", "describ", "mail", "list", "http", "mail", "archiv", "apach", "user", "201407", "mbox", "org", "mod", "mbox", "wicket", "3ccaf2", "608c8tozjprv8md15kjpret6yqdxh", "608c8to", "zjpr", "v8md15k", "jp", "ret6i", "qd", "he", "3dwrzf", "3dw", "rz", "y5g", "zaxcdg", "xc", "dg", "40mail", "gmail", "com", "3e", "im", "awar", "anoth", "issu", "http", "3413", "apach", "issu", "org", "jira", "brows", "wicket", "which", "dealt", "exact", "same", "code", "believ", "there", "wa", "mistak", "solut", "that", "lead", "thi", "issu", "pleas", "see", "attach", "quickstart", "includ", "junit", "unit", "test", "reproduc", "error"], "B_title": "clear FLAG_INHERITABLE_MODEL reliably", "B_clean_title": ["clear", "flag", "inherit", "model", "reliabl"]},
{"A_title": "MutableTree#isNew: replace implementation by NodeBuilder#isNewSimilar to the issue described in OAK-1177 we may consider replacing the implementation of MutableTree#isNew by the corresponding call on the NodeBuilder.  See also OAK-947.", "A_clean_title": ["mutabletre", "mutabl", "tree", "isnew", "new", "replac", "implement", "by", "nodebuild", "node", "builder", "isnewsimilar", "new", "similar", "issu", "describ", "oak", "1177", "we", "may", "consid", "replac", "implement", "mutabletre", "mutabl", "tree", "isnew", "new", "by", "correspond", "call", "nodebuild", "node", "builder", "see", "also", "oak", "947"], "B_title": "MutableTree#isNew: replace implementation by NodeBuilder#isNew - Rebasing should correctly set the base state of the KernelNodeBuilder and the MongoNodeBuilder - MongoNodeBuilder needs to calculate its base state instead of relying on that of the MemoryNodeBuilder backing it", "B_clean_title": ["mutabletre", "mutabl", "tree", "isnew", "new", "replac", "implement", "by", "nodebuild", "node", "builder", "isnew", "new", "rebas", "correctli", "set", "base", "state", "kernelnodebuild", "kernel", "node", "builder", "mongonodebuild", "mongo", "node", "builder", "mongonodebuild", "mongo", "node", "builder", "need", "calcul", "it", "base", "state", "instead", "reli", "that", "memorynodebuild", "memori", "node", "builder", "back", "it"]},
{"A_title": "CompilerException caused by NullPointerExceptionRun into it during working on my code. Seems not caused by my plan or anyway the compiler should have a NullPointer isssue:  org.apache.flink.compiler.CompilerException: An error occurred while translating the optimized plan to a nephele JobGraph: Error translating node Union Union : UNION  GlobalProperties partitioning=HASH_PARTITIONED on fields 0   LocalProperties ordering=null grouped=null unique=null : null at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.postVisit(NepheleJobGraphGenerator.java:543) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.postVisit(NepheleJobGraphGenerator.java:95) at org.apache.flink.compiler.plan.DualInputPlanNode.accept(DualInputPlanNode.java:170) at org.apache.flink.compiler.plan.SingleInputPlanNode.accept(SingleInputPlanNode.java:196) at org.apache.flink.compiler.plan.SingleInputPlanNode.accept(SingleInputPlanNode.java:196) at org.apache.flink.compiler.plan.OptimizedPlan.accept(OptimizedPlan.java:165) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.compileJobGraph(NepheleJobGraphGenerator.java:163) at org.apache.flink.client.program.Client.getJobGraph(Client.java:218) at org.apache.flink.client.program.Client.run(Client.java:290) at org.apache.flink.client.program.Client.run(Client.java:285) at org.apache.flink.client.program.Client.run(Client.java:230) at org.apache.flink.client.CliFrontend.executeProgram(CliFrontend.java:347) at org.apache.flink.client.CliFrontend.run(CliFrontend.java:334) at org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:1001) at org.apache.flink.client.CliFrontend.main(CliFrontend.java:1025) Caused by: org.apache.flink.compiler.CompilerException: Error translating node Union Union : UNION  GlobalProperties partitioning=HASH_PARTITIONED on fields 0   LocalProperties ordering=null grouped=null unique=null : null at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.preVisit(NepheleJobGraphGenerator.java:338) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.preVisit(NepheleJobGraphGenerator.java:95) at org.apache.flink.compiler.plan.DualInputPlanNode.accept(DualInputPlanNode.java:162) at org.apache.flink.compiler.plan.WorksetIterationPlanNode.acceptForStepFunction(WorksetIterationPlanNode.java:196) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.postVisit(NepheleJobGraphGenerator.java:398) ... 14 more Caused by: java.lang.NullPointerException at org.apache.flink.runtime.operators.util.TaskConfig.setDriver(TaskConfig.java:307) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.createDualInputVertex(NepheleJobGraphGenerator.java:793) at org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator.preVisit(NepheleJobGraphGenerator.java:286) ... 18 more", "A_clean_title": ["compilerexcept", "compil", "except", "caus", "by", "nullpointerexceptionrun", "null", "pointer", "except", "run", "into", "it", "dure", "work", "my", "code", "seem", "not", "caus", "by", "my", "plan", "or", "anyway", "compil", "have", "nullpoint", "null", "pointer", "isssu", "org", "apach", "flink", "compil", "compilerexcept", "compil", "except", "error", "occur", "while", "translat", "optim", "plan", "nephel", "jobgraph", "job", "graph", "error", "translat", "node", "union", "union", "union", "globalproperti", "global", "properti", "partitioning=hash", "partit", "field", "localproperti", "local", "properti", "ordering=nul", "grouped=nul", "unique=nul", "null", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "postvisit", "nephel", "job", "graph", "gener", "post", "visit", "nephelejobgraphgener", "java:543", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "postvisit", "nephel", "job", "graph", "gener", "post", "visit", "nephelejobgraphgener", "java:95", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "compil", "plan", "dualinputplannod", "accept", "dual", "input", "plan", "node", "dualinputplannod", "java:170", "dual", "input", "plan", "node", "at", "org", "apach", "flink", "compil", "plan", "singleinputplannod", "accept", "singl", "input", "plan", "node", "singleinputplannod", "java:196", "singl", "input", "plan", "node", "at", "org", "apach", "flink", "compil", "plan", "singleinputplannod", "accept", "singl", "input", "plan", "node", "singleinputplannod", "java:196", "singl", "input", "plan", "node", "at", "org", "apach", "flink", "compil", "plan", "optimizedplan", "accept", "optim", "plan", "optimizedplan", "java:165", "optim", "plan", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "compilejobgraph", "nephel", "job", "graph", "gener", "compil", "job", "graph", "nephelejobgraphgener", "java:163", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "client", "program", "client", "getjobgraph", "get", "job", "graph", "client", "java:218", "at", "org", "apach", "flink", "client", "program", "client", "run", "client", "java:290", "at", "org", "apach", "flink", "client", "program", "client", "run", "client", "java:285", "at", "org", "apach", "flink", "client", "program", "client", "run", "client", "java:230", "at", "org", "apach", "flink", "client", "clifrontend", "executeprogram", "cli", "frontend", "execut", "program", "clifrontend", "java:347", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "run", "cli", "frontend", "clifrontend", "java:334", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "parseparamet", "cli", "frontend", "pars", "paramet", "clifrontend", "java:1001", "cli", "frontend", "at", "org", "apach", "flink", "client", "clifrontend", "main", "cli", "frontend", "clifrontend", "java:1025", "cli", "frontend", "caus", "by", "org", "apach", "flink", "compil", "compilerexcept", "compil", "except", "error", "translat", "node", "union", "union", "union", "globalproperti", "global", "properti", "partitioning=hash", "partit", "field", "localproperti", "local", "properti", "ordering=nul", "grouped=nul", "unique=nul", "null", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "previsit", "nephel", "job", "graph", "gener", "pre", "visit", "nephelejobgraphgener", "java:338", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "previsit", "nephel", "job", "graph", "gener", "pre", "visit", "nephelejobgraphgener", "java:95", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "compil", "plan", "dualinputplannod", "accept", "dual", "input", "plan", "node", "dualinputplannod", "java:162", "dual", "input", "plan", "node", "at", "org", "apach", "flink", "compil", "plan", "worksetiterationplannod", "acceptforstepfunct", "workset", "iter", "plan", "node", "accept", "step", "function", "worksetiterationplannod", "java:196", "workset", "iter", "plan", "node", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "postvisit", "nephel", "job", "graph", "gener", "post", "visit", "nephelejobgraphgener", "java:398", "nephel", "job", "graph", "gener", "14", "more", "caus", "by", "java", "lang", "nullpointerexcept", "null", "pointer", "except", "at", "org", "apach", "flink", "runtim", "oper", "util", "taskconfig", "setdriv", "task", "config", "set", "driver", "taskconfig", "java:307", "task", "config", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "createdualinputvertex", "nephel", "job", "graph", "gener", "creat", "dual", "input", "vertex", "nephelejobgraphgener", "java:793", "nephel", "job", "graph", "gener", "at", "org", "apach", "flink", "compil", "plantransl", "nephelejobgraphgener", "previsit", "nephel", "job", "graph", "gener", "pre", "visit", "nephelejobgraphgener", "java:286", "nephel", "job", "graph", "gener", "18", "more"], "B_title": "Handle unions at the root of the iteration", "B_clean_title": ["handl", "union", "at", "root", "iter"]},
{"A_title": "Compiler gives false error with respect to unreachable codeNone", "A_clean_title": ["compil", "give", "fals", "error", "respect", "unreach", "codenon", "code", "none"], "B_title": "Make the CFA recognize possible ON_EX edges for instanceof operations. Fixes issue 113. (Alan)", "B_clean_title": ["make", "cfa", "recogn", "possibl", "ex", "edg", "instanceof", "oper", "fix", "issu", "113", "alan"]},
{"A_title": "EigenDecomposition fails for certain matricesThe Schurtransformation of the following matrix fails which is a preliminary step for the Eigendecomposition:  RealMatrix m = MatrixUtils.DEFAULT_FORMAT.parse(0.184944928-0.06469710460.0774755812-0.0969651755-0.06926488060.3282344352-0.01774230740.206313634-0.0742700134-0.028906303-0.001726946-0.0375550146-0.0487737922-0.2616837868-0.0821201295-0.25300001670.25499101270.0995733692-0.00097183880.01492828080.1791878897-0.08231828160.05826292560.3219545182-0.0694747557-0.1880649148-0.27406309110.0720096468-0.1800836914-0.35189964250.24867478330.62579381670.0536360918-0.13392977780.2241579764-0.0195327484-0.00541038080.03475645180.5120802482-0.0329902864-0.5933332356-0.24887210820.23571736290.01772854730.0856630593-0.35671263-0.1600668126-0.1010899621-0.0514349819-0.08543194350.11250500610.006345356-0.2250000688-0.2209343090.1964623477-0.15123299240.0197395947-0.1997170581-0.1425959019-0.274947791-0.09694670730.060368852-0.28269051920.1794315473);", "A_clean_title": ["eigendecomposit", "eigen", "decomposit", "fail", "certain", "matricesth", "matric", "schurtransform", "follow", "matrix", "fail", "which", "preliminari", "step", "eigendecomposit", "realmatrix", "real", "matrix", "matrixutil", "pars", "matrix", "util", "default", "format", "184944928", "06469710460", "0774755812", "0969651755", "06926488060", "3282344352", "01774230740", "206313634", "0742700134", "028906303", "001726946", "0375550146", "0487737922", "2616837868", "0821201295", "25300001670", "25499101270", "0995733692", "00097183880", "01492828080", "1791878897", "08231828160", "05826292560", "3219545182", "0694747557", "1880649148", "27406309110", "0720096468", "1800836914", "35189964250", "24867478330", "62579381670", "0536360918", "13392977780", "2241579764", "0195327484", "00541038080", "03475645180", "5120802482", "0329902864", "5933332356", "24887210820", "23571736290", "01772854730", "0856630593", "35671263", "1600668126", "1010899621", "0514349819", "08543194350", "11250500610", "006345356", "2250000688", "2209343090", "1964623477", "15123299240", "0197395947", "1997170581", "1425959019", "274947791", "09694670730", "060368852", "28269051920", "1794315473"], "B_title": "Fixed Schur transformation for certain input matrices changed index parameter names to indicate their purpose.", "B_clean_title": ["fix", "schur", "transform", "certain", "input", "matric", "chang", "index", "paramet", "name", "indic", "their", "purpos"]},
{"A_title": "Unexpected expression nodeDELPROP 1None", "A_clean_title": ["unexpect", "express", "nodedelprop", "node", "delprop", "1none"], "B_title": "delete operator with a boolean result. Fixes issue 364", "B_clean_title": ["delet", "oper", "boolean", "result", "fix", "issu", "364"]},
{"A_title": "Erroneous optimization in ADVANCED_OPTIMIZATIONS modeNone", "A_clean_title": ["erron", "optim", "advanc", "optim", "modenon", "mode", "none"], "B_title": "Nerf direct function inlining when the function be inlined has side-effects and the call arguments can be effected. Fixes issue 1101 ------------- Created by MOE: http://code.google.com/p/moe-java MOE_MIGRATED_REVID=53511956", "B_clean_title": ["nerf", "direct", "function", "inlin", "when", "function", "inlin", "ha", "side", "effect", "call", "argument", "effect", "fix", "issu", "1101", "creat", "by", "moe", "http", "java", "googl", "code", "com", "moe", "moe", "migrat", "revid=53511956"]},
{"A_title": "Obfuscated code triggers TypeError in FirefoxNone", "A_clean_title": ["obfusc", "code", "trigger", "typeerror", "type", "error", "firefoxnon", "firefox", "none"], "B_title": "Dont collapse assignments into var declarations if it would cause a redeclarion of a named parameter.", "B_clean_title": ["dont", "collaps", "assign", "into", "var", "declar", "it", "would", "caus", "redeclarion", "name", "paramet"]},
{"A_title": "Condition check broken in MemoryDocumentStoreThe Operation.CONTAINS_MAP_ENTRY condition check does not work correctly in the MemoryDocumentStore and may return false even when the condition is not met.", "A_clean_title": ["condit", "check", "broken", "memorydocumentstoreth", "memori", "document", "store", "oper", "contain", "map", "entri", "condit", "check", "not", "work", "correctli", "memorydocumentstor", "memori", "document", "store", "may", "return", "fals", "even", "when", "condit", "not", "met"], "B_title": "Condition check broken in MemoryDocumentStore", "B_clean_title": ["condit", "check", "broken", "memorydocumentstor", "memori", "document", "store"]},
{"A_title": "class Dfp toDouble method return -inf whan Dfp value is 0 zeroI found a bug in the toDouble() method of the Dfp class. If the Dfps value is 0 zero the toDouble() method returns a  negative infini. This is because the double value returned has an exposant equal to 0xFFF  and a significand is equal to 0. In the IEEE754 this is a -inf. To be equal to zero the exposant and the significand must be equal to zero. A simple test case is : ---------------------------------------------- import org.apache.commons.math.dfp.DfpField; public class test  /**  @param args  */ public static void main(String args)   DfpField field = new DfpField(100); System.out.println(toDouble value of getZero() =+field.getZero().toDouble()+ ntoDouble value of newDfp(0.0) =+ field.newDfp(0.0).toDouble());    May be the simplest way to fix it is to test the zero equality at the begin of the toDouble() method to be able to return the correctly signed zero ?", "A_clean_title": ["class", "dfp", "todoubl", "doubl", "method", "return", "inf", "whan", "dfp", "valu", "zeroi", "zero", "found", "bug", "todoubl", "doubl", "method", "dfp", "class", "dfp", "valu", "zero", "todoubl", "doubl", "method", "return", "neg", "infini", "thi", "becaus", "doubl", "valu", "return", "ha", "expos", "equal", "0xfff", "0x", "fff", "significand", "equal", "ieee754", "thi", "inf", "equal", "zero", "expos", "significand", "must", "equal", "zero", "simpl", "test", "case", "import", "org", "apach", "common", "math", "dfp", "dfpfield", "dfp", "field", "public", "class", "test", "param", "arg", "public", "static", "void", "main", "string", "arg", "dfpfield", "dfp", "field", "field", "new", "dfpfield", "dfp", "field", "100", "system", "out", "println", "todoubl", "doubl", "valu", "getzero", "get", "zero", "=+field", "getzero", "get", "zero", "todoubl", "doubl", "ntodoubl", "nto", "doubl", "valu", "newdfp", "new", "dfp", "field", "newdfp", "new", "dfp", "todoubl", "doubl", "may", "simplest", "way", "fix", "it", "test", "zero", "equal", "at", "begin", "todoubl", "doubl", "method", "abl", "return", "correctli", "sign", "zero"], "B_title": "Fixed conversion problems to/from 0 in Decimal Floating Point (Dfp) class.", "B_clean_title": ["fix", "convers", "problem", "decim", "float", "point", "dfp", "class"]},
{"A_title": "PolyhedronsSet.firstIntersection(Vector3D point Line line) sometimes reports intersections on wrong end of lineI constructed a PolyhedronsSet from a list of triangular faces representing an icosphere (using the instructions found at https://mail-archives.apache.org/mod_mbox/commons-user/201208.mbox/<5039FE35.2090307@free.fr>).  This seems to produce correct INSIDE/OUTSIDE results for randomly chosen points.  I think my mesh triangles are defined appropriately.  However using PolyhedronsSet.firstIntersection(Vector3D point Line line) to shoot randomly oriented rays from the origin sometimes gives a wrong mesh intersection point behind the origin.  The intersection algorithm is sometimes picking up faces of the sphere-shaped mesh on the wrong semi-infinite portion of the line i.e. meshIntersectionPoint.subtract(point).dotProduct(line.getDirection())<0 where point is the Vector3D at center of the sphere and line extends outward through the mesh.  I think the dot product above should always be positive. If multiple intersections exist along a whole line then the first one in front of the lines origin should be returned. This makes ray tracing with a PolyhedronsSet possible.", "A_clean_title": ["polyhedronsset", "firstintersect", "polyhedron", "set", "first", "intersect", "vector3d", "point", "line", "line", "sometim", "report", "intersect", "wrong", "end", "linei", "line", "construct", "polyhedronsset", "polyhedron", "set", "list", "triangular", "face", "repres", "icospher", "instruct", "found", "at", "http", "mail", "archiv", "apach", "user", "201208", "mbox", "org", "mod", "mbox", "common", "5039fe35", "2090307", "free", "fr", "thi", "seem", "produc", "correct", "insid", "outsid", "result", "randomli", "chosen", "point", "think", "my", "mesh", "triangl", "are", "defin", "appropri", "howev", "polyhedronsset", "firstintersect", "polyhedron", "set", "first", "intersect", "vector3d", "point", "line", "line", "shoot", "randomli", "orient", "ray", "origin", "sometim", "give", "wrong", "mesh", "intersect", "point", "behind", "origin", "intersect", "algorithm", "sometim", "pick", "up", "face", "sphere", "shape", "mesh", "wrong", "semi", "infinit", "portion", "line", "meshintersectionpoint", "subtract", "mesh", "intersect", "point", "point", "dotproduct", "dot", "product", "line", "getdirect", "get", "direct", "where", "point", "vector3d", "at", "center", "sphere", "line", "extend", "outward", "through", "mesh", "think", "dot", "product", "abov", "alway", "posit", "multipl", "intersect", "exist", "along", "whole", "line", "then", "first", "one", "front", "line", "origin", "return", "thi", "make", "ray", "trace", "polyhedronsset", "polyhedron", "set", "possibl"], "B_title": "Fixed wrong intersection selection in polyhedrons sets.", "B_clean_title": ["fix", "wrong", "intersect", "select", "polyhedron", "set"]},
{"A_title": "Inconsistent read on DocumentNodeStore startupThis is a regression introduced with OAK-2929. On DocumentNodeStore startup the RevisionComparator of the local instance is initialized with the current _lastRev entries from the other cluster nodes. The external _lastRev entries are seenAt the same revision which means for those revisions the RevisionComparator will use the clusterId to compare them. This is also described in OAK-3388.  OAK-2929 changed the sequence of revisions to check for conflicts from StableRevisionComparator to RevisionComparator. This makes the conflict check susceptible to the RevisionComparison behaviour described in OAK-3388. Commits may be rejected with a conflict when there isnt really a conflict.", "A_clean_title": ["inconsist", "read", "documentnodestor", "document", "node", "store", "startupthi", "startup", "thi", "regress", "introduc", "oak", "2929", "documentnodestor", "document", "node", "store", "startup", "revisioncompar", "revis", "compar", "local", "instanc", "initi", "current", "lastrev", "last", "rev", "entri", "other", "cluster", "node", "extern", "lastrev", "last", "rev", "entri", "are", "seenat", "seen", "at", "same", "revis", "which", "mean", "those", "revis", "revisioncompar", "revis", "compar", "will", "use", "clusterid", "cluster", "id", "compar", "them", "thi", "also", "describ", "oak", "3388", "oak", "2929", "chang", "sequenc", "revis", "check", "conflict", "stablerevisioncompar", "stabl", "revis", "compar", "revisioncompar", "revis", "compar", "thi", "make", "conflict", "check", "suscept", "revisioncomparison", "revis", "comparison", "behaviour", "describ", "oak", "3388", "commit", "may", "reject", "conflict", "when", "there", "isnt", "realli", "conflict"], "B_title": "Inconsistent read on DocumentNodeStore startup", "B_clean_title": ["inconsist", "read", "documentnodestor", "document", "node", "store", "startup"]},
{"A_title": "Lucene should not serve queries for what it doesnt indexIf a query is asked and Lucene is chosen as index for serving it it will try to serve all the restrictions of the query even the one that are not indexed.", "A_clean_title": ["lucen", "not", "serv", "queri", "what", "it", "doesnt", "indexif", "index", "queri", "ask", "lucen", "chosen", "as", "index", "serv", "it", "it", "will", "tri", "serv", "all", "restrict", "queri", "even", "one", "that", "are", "not", "index"], "B_title": "Lucene should not serve queries for what it doesnt index", "B_clean_title": ["lucen", "not", "serv", "queri", "what", "it", "doesnt", "index"]},
{"A_title": "Inline enclosure doesnt work if wicket:message attribute is used on the same tagMarkup like:          <div wicket:enclosure=child wicket:message=title:something>         <div>Inner div         <span wicket:id=child>Blah</span>         </div>         </div>  doesnt work (Inner div is visible no matter whether child is visible or not) because the auto component created for wicket:message breaks somehow wicket:enclosure.", "A_clean_title": ["inlin", "enclosur", "doesnt", "work", "wicket", "messag", "attribut", "use", "same", "tagmarkup", "tag", "markup", "like", "div", "wicket", "enclosure=child", "wicket", "message=titl", "someth", "div", "inner", "div", "span", "wicket", "id=child", "blah", "span", "div", "div", "doesnt", "work", "inner", "div", "visibl", "no", "matter", "whether", "child", "visibl", "or", "not", "becaus", "auto", "compon", "creat", "wicket", "messag", "break", "somehow", "wicket", "enclosur"], "B_title": "Inline enclosure doesnt work if wicket:message attribute is used on the same tag", "B_clean_title": ["inlin", "enclosur", "doesnt", "work", "wicket", "messag", "attribut", "use", "same", "tag"]},
{"A_title": "One-to-many with integer ids retrieval brokenHow to Reproduce  Upload:   string-id.xlsx Go to dataexplorer select Subjects table  I dont like the order of the samples so I want to change the ID attribute datatype of the samples to int Upload:  int-id.xlsx Go to your table again Expected behavior  My beautiful table nicely int sorted --> happy datamanager  Observed behavior    --> Sad datamanager", "A_clean_title": ["one", "mani", "integ", "id", "retriev", "brokenhow", "broken", "how", "reproduc", "upload", "string", "id", "xlsx", "go", "dataexplor", "select", "subject", "tabl", "dont", "like", "order", "sampl", "so", "want", "chang", "id", "attribut", "datatyp", "sampl", "int", "upload", "int", "id", "xlsx", "go", "your", "tabl", "again", "expect", "behavior", "my", "beauti", "tabl", "nice", "int", "sort", "happi", "datamanag", "observ", "behavior", "sad", "datamanag"], "B_title": "Merge pull request #7303 from dennishendriksen/fix/7297-oneToManyIntIds  Fix #7297 One-to-many with integer ids retrieval", "B_clean_title": ["merg", "pull", "request", "7303", "onetomanyintid", "dennishendriksen", "fix", "7297", "one", "mani", "int", "id", "fix", "7297", "one", "mani", "integ", "id", "retriev"]},
{"A_title": "IRequestCycleListener: RequestCycle.get() is null inside onBeginRequestI expect the request cycle that is supplied as an argument to onBeginRequest to be the same as RequestCycle.get.  == == == CODE == == ==      @Override     public void onBeginRequest(RequestCycle cycle)          Session session = Session.get(); // throws IllegalArgumentException         if (session.getMetaData(REDIRECTED_JSESSIONID) == null)              logger.debug(first application request - redirecting to loading page);             session.setMetaData(REDIRECTED_JSESSIONID Boolean.TRUE);             String url = getServletRequestContextPath() + / + cycle.getRequest().getUrl();             throw new RestartResponseException(newLoadingPage(url));               == == == == == == == ==   == == == STACK TRACE == == ==  java.lang.IllegalArgumentException: Argument requestCycle may not be null.     at org.apache.wicket.util.lang.Args.notNull(Args.java:37)     at org.apache.wicket.Application.fetchCreateAndSetSession(Application.java:1436)     at org.apache.wicket.Session.get(Session.java:154)     at com.joynit.tuv.common.view.request.SessionIdRemoveListener.onBeginRequest(SessionIdRemoveListener.java:30)  ... snipped -other part is not relevant  == == == == == == == == == == ==", "A_clean_title": ["irequestcyclelisten", "request", "cycl", "listen", "requestcycl", "get", "request", "cycl", "null", "insid", "onbeginrequesti", "begin", "request", "expect", "request", "cycl", "that", "suppli", "as", "argument", "onbeginrequest", "begin", "request", "same", "as", "requestcycl", "get", "request", "cycl", "code", "overrid", "public", "void", "onbeginrequest", "begin", "request", "requestcycl", "request", "cycl", "cycl", "session", "session", "session", "get", "throw", "illegalargumentexcept", "illeg", "argument", "except", "session", "getmetadata", "get", "meta", "data", "redirect", "jsessionid", "null", "logger", "debug", "first", "applic", "request", "redirect", "load", "page", "session", "setmetadata", "set", "meta", "data", "redirect", "jsessionid", "boolean", "true", "string", "url", "getservletrequestcontextpath", "get", "servlet", "request", "context", "path", "cycl", "getrequest", "get", "request", "geturl", "get", "url", "throw", "new", "restartresponseexcept", "restart", "respons", "except", "newloadingpag", "new", "load", "page", "url", "stack", "trace", "java", "lang", "illegalargumentexcept", "illeg", "argument", "except", "argument", "requestcycl", "request", "cycl", "may", "not", "null", "at", "org", "apach", "wicket", "util", "lang", "arg", "notnul", "not", "null", "arg", "java:37", "at", "org", "apach", "wicket", "applic", "fetchcreateandsetsess", "fetch", "creat", "set", "session", "applic", "java:1436", "at", "org", "apach", "wicket", "session", "get", "session", "java:154", "at", "com", "joynit", "tuv", "common", "view", "request", "sessionidremovelisten", "onbeginrequest", "session", "id", "remov", "listen", "begin", "request", "sessionidremovelisten", "java:30", "session", "id", "remov", "listen", "snip", "other", "part", "not", "relev"], "B_title": "Issue: WICKET-3428", "B_clean_title": ["issu", "wicket", "3428"]},
{"A_title": "Fix interplay of automatic Operator UID and Changing name of WindowOperatorWindowOperator can have a changing name because it has the TypeSerializer .toString() output in its name. For some type serializers that dont implement toString() this means that the name changes.  This means that savepoint restore does not work for the automatically generated UID.", "A_clean_title": ["fix", "interplay", "automat", "oper", "uid", "chang", "name", "windowoperatorwindowoper", "window", "oper", "window", "oper", "have", "chang", "name", "becaus", "it", "ha", "typeseri", "type", "serial", "tostr", "string", "output", "it", "name", "some", "type", "serial", "that", "dont", "implement", "tostr", "string", "thi", "mean", "that", "name", "chang", "thi", "mean", "that", "savepoint", "restor", "not", "work", "automat", "gener", "uid"], "B_title": "runtime Fix interplay of automatic Operator UID and Changing name of WindowOperator", "B_clean_title": ["runtim", "fix", "interplay", "automat", "oper", "uid", "chang", "name", "windowoper", "window", "oper"]},
{"A_title": "function arguments should not be optimized awayNone", "A_clean_title": ["function", "argument", "not", "optim", "awaynon", "away", "none"], "B_title": "In simple mode do not remove unreferenced function arguments. Fixes issue 253", "B_clean_title": ["simpl", "mode", "not", "remov", "unreferenc", "function", "argument", "fix", "issu", "253"]},
{"A_title": "TextField ingnores convertEmptyInputStringToNull = true property when the String type is setI posted this patch on WICKET-3269 but the discussion on this ticket is about an improvement request not a bug. I opened this one for the bug.", "A_clean_title": ["textfield", "text", "field", "ingnor", "convertemptyinputstringtonul", "convert", "empti", "input", "string", "null", "true", "properti", "when", "string", "type", "seti", "set", "post", "thi", "patch", "wicket", "3269", "but", "discuss", "thi", "ticket", "about", "improv", "request", "not", "bug", "open", "thi", "one", "bug"], "B_title": "Issue: WICKET-3304", "B_clean_title": ["issu", "wicket", "3304"]},
{"A_title": "DiscreteDistribution.sample(int) may throw an exception if first element of singletons of sub-class typeCreating an array with Array.newInstance(singletons.get(0).getClass() sampleSize) in DiscreteDistribution.sample(int) is risky. An exception will be thrown if:  singleons.get(0) is of type T1 an sub-class of T and DiscreteDistribution.sample() returns an object which is of type T but not of type T1.  To reproduce:  List<Pair<ObjectDouble>> list = new ArrayList<Pair<Object Double>>(); list.add(new Pair<Object Double>(new Object()  new Double(0))); list.add(new Pair<Object Double>(new Object()  new Double(1))); new DiscreteDistribution<Object>(list).sample(1);   Attaching a patch.", "A_clean_title": ["discretedistribut", "sampl", "discret", "distribut", "int", "may", "throw", "except", "first", "element", "singleton", "sub", "class", "typecr", "type", "creat", "array", "array", "newinst", "new", "instanc", "singleton", "get", "getclass", "get", "class", "samples", "sampl", "size", "discretedistribut", "sampl", "discret", "distribut", "int", "riski", "except", "will", "thrown", "singleon", "get", "type", "t1", "sub", "class", "discretedistribut", "sampl", "discret", "distribut", "return", "object", "which", "type", "but", "not", "type", "t1", "reproduc", "list", "pair", "objectdoubl", "object", "doubl", "list", "new", "arraylist", "array", "list", "pair", "object", "doubl", "list", "add", "new", "pair", "object", "doubl", "new", "object", "new", "doubl", "list", "add", "new", "pair", "object", "doubl", "new", "object", "new", "doubl", "new", "discretedistribut", "discret", "distribut", "object", "list", "sampl", "attach", "patch"], "B_title": "Fixed creation of generic array.", "B_clean_title": ["fix", "creation", "gener", "array"]},
{"A_title": "XPath queries with certain combinations of or conditions dont use an indexXPath queries with the following conditions are not converted to union SQL-2 queries and therefore dont use an index:  noformat /jcr:root/content//*((@i = 1 or @i = 2) or (@s = x)) and (@t = a or @t = b) noformat", "A_clean_title": ["xpath", "path", "queri", "certain", "combin", "or", "condit", "dont", "use", "indexxpath", "index", "path", "queri", "follow", "condit", "are", "not", "convert", "union", "sql", "queri", "therefor", "dont", "use", "index", "noformat", "jcr", "root", "content", "or", "or", "or", "noformat"], "B_title": "XPath queries with certain combinations of or conditions dont use an index OAK-2022 XPath queries with order by are never converted to union", "B_clean_title": ["xpath", "path", "queri", "certain", "combin", "or", "condit", "dont", "use", "index", "oak", "2022", "xpath", "path", "queri", "order", "by", "are", "never", "convert", "union"]},
{"A_title": "Windowed fold operation fails because the initial value was not serializedThe windowed fold operation currently fails because the initial value was not serialized. The reason for this is that the fold operation is realized as a WindowFunction within an AbstractUdfStreamOperator and does not get the output type information forwarded (which is necessary for the serialization).   The solution is to let the AbstractUdfStreamOperator forward the output type information to the WindowFunction if it implements the OutputTypeConfigurable interface.", "A_clean_title": ["window", "fold", "oper", "fail", "becaus", "initi", "valu", "wa", "not", "serializedth", "serial", "window", "fold", "oper", "current", "fail", "becaus", "initi", "valu", "wa", "not", "serial", "reason", "thi", "that", "fold", "oper", "realiz", "as", "windowfunct", "window", "function", "within", "abstractudfstreamoper", "abstract", "udf", "stream", "oper", "not", "get", "output", "type", "inform", "forward", "which", "necessari", "serial", "solut", "let", "abstractudfstreamoper", "abstract", "udf", "stream", "oper", "forward", "output", "type", "inform", "windowfunct", "window", "function", "it", "implement", "outputtypeconfigur", "output", "type", "configur", "interfac"], "B_title": "streaming Let AbstractUdfStreamOperator forward output type information to WindowFunction", "B_clean_title": ["stream", "let", "abstractudfstreamoper", "abstract", "udf", "stream", "oper", "forward", "output", "type", "inform", "windowfunct", "window", "function"]},
{"A_title": "Cookies#isEqual(Cookie Cookie) may fail with NullPointerExceptionIf c1.getPath == null but c2.getPath != null then a NPE will occur. Same is valid for the domain property.", "A_clean_title": ["cooki", "isequ", "equal", "cooki", "cooki", "may", "fail", "nullpointerexceptionif", "null", "pointer", "except", "c1", "getpath", "get", "path", "null", "but", "c2", "getpath", "get", "path", "null", "then", "npe", "will", "occur", "same", "valid", "domain", "properti"], "B_title": "Cookies#isEqual(Cookie Cookie) may fail with NullPointerException", "B_clean_title": ["cooki", "isequ", "equal", "cooki", "cooki", "may", "fail", "nullpointerexcept", "null", "pointer", "except"]},
{"A_title": "Header contributions order is not stableIn the last RCs I started to experience problems with the contributions order. For example I add jQuery and until 1.5RC5 it worked well but now the call to the jQuery script has been moved to the bottom of the page head and this disables all my other scripts that are expecting jQuerys   to be defined.  I attach a quickstart to demonstrate the problem. Maybe the order in the quickstart is not the expected one but what it shows is that the order does not make real sense (at least to me) : In the quickstart the wicket:head tag contributions are in the order 3 - 8 - 9 - 5 and the renderHead methods contributions are in the order 4 - 1 - 2 - 6 - 7.", "A_clean_title": ["header", "contribut", "order", "not", "stablein", "stabl", "last", "rc", "cs", "start", "experi", "problem", "contribut", "order", "exampl", "add", "jqueri", "queri", "until", "5rc5", "it", "work", "well", "but", "now", "call", "jqueri", "queri", "script", "ha", "been", "move", "bottom", "page", "head", "thi", "disabl", "all", "my", "other", "script", "that", "are", "expect", "jqueri", "queri", "defin", "attach", "quickstart", "demonstr", "problem", "mayb", "order", "quickstart", "not", "expect", "one", "but", "what", "it", "show", "that", "order", "not", "make", "real", "sens", "at", "least", "me", "quickstart", "wicket", "head", "tag", "contribut", "are", "order", "renderhead", "render", "head", "method", "contribut", "are", "order"], "B_title": "Header contributions order is not stable", "B_clean_title": ["header", "contribut", "order", "not", "stabl"]},
{"A_title": "AjaxPreprocessingCallDecorator calls the delegate decorator before itself (same behavior as AjaxPostprocessingCallDecorator)AjaxPreprocessingCallDecorator calls the delegate decorator before itself (same behavior as AjaxPostprocessingCallDecorator) when it should call itself before the delegate.", "A_clean_title": ["ajaxpreprocessingcalldecor", "ajax", "preprocess", "call", "decor", "call", "deleg", "decor", "befor", "itself", "same", "behavior", "as", "ajaxpostprocessingcalldecor", "ajax", "postprocess", "call", "decor", "ajaxpreprocessingcalldecor", "ajax", "preprocess", "call", "decor", "call", "deleg", "decor", "befor", "itself", "same", "behavior", "as", "ajaxpostprocessingcalldecor", "ajax", "postprocess", "call", "decor", "when", "it", "call", "itself", "befor", "deleg"], "B_title": "", "B_clean_title": []},
{"A_title": "Division by zeroIn class Complex division by zero always returns NaN. I think that it should return NaN only when the numerator is also ZERO otherwise the result should be INF. See here.", "A_clean_title": ["divis", "by", "zeroin", "zero", "class", "complex", "divis", "by", "zero", "alway", "return", "nan", "na", "think", "that", "it", "return", "nan", "na", "onli", "when", "numer", "also", "zero", "otherwis", "result", "inf", "see", "here"], "B_title": "Complex division by zero:  z / 0 = INF if z is not ZERO  0 / 0 = NaN", "B_clean_title": ["complex", "divis", "by", "zero", "inf", "not", "zero", "nan", "na"]},
{"A_title": "TarMK compaction can create mixed segmentsAs described in http://markmail.org/message/ujkqdlthudaortxf commits that occur while the compaction operation is running can make the compacted segments contain references to older data segments which prevents old data from being reclaimed during cleanup.", "A_clean_title": ["tarmk", "tar", "mk", "compact", "creat", "mix", "segmentsa", "segment", "as", "describ", "http", "markmail", "org", "messag", "ujkqdlthudaortxf", "commit", "that", "occur", "while", "compact", "oper", "run", "make", "compact", "segment", "contain", "refer", "older", "data", "segment", "which", "prevent", "old", "data", "be", "reclaim", "dure", "cleanup"], "B_title": "TarMK compaction can create mixed segments", "B_clean_title": ["tarmk", "tar", "mk", "compact", "creat", "mix", "segment"]},
{"A_title": "smartNameRemoval causing compiler crashNone", "A_clean_title": ["smartnameremov", "smart", "name", "remov", "caus", "compil", "crashnon", "crash", "none"], "B_title": "fix smartNameRemoval crash Fixes issue 284", "B_clean_title": ["fix", "smartnameremov", "smart", "name", "remov", "crash", "fix", "issu", "284"]},
{"A_title": "Gamma function computationIn the gamma method when handling the case absX > 20 the computation of gammaAbs should replace x (see code below with x in bold) by absX. For large negative values of x the function returns with the wrong sign.  final double gammaAbs = SQRT_TWO_PI / *x* *                                      FastMath.pow(y absX + 0.5) *                                      FastMath.exp(-y) * lanczos(absX);", "A_clean_title": ["gamma", "function", "computationin", "comput", "gamma", "method", "when", "handl", "case", "absx", "ab", "20", "comput", "gammaab", "gamma", "ab", "replac", "see", "code", "below", "bold", "by", "absx", "ab", "larg", "neg", "valu", "function", "return", "wrong", "sign", "final", "doubl", "gammaab", "gamma", "ab", "sqrt", "two", "pi", "fastmath", "pow", "fast", "math", "absx", "ab", "fastmath", "exp", "fast", "math", "lanczo", "absx", "ab"], "B_title": "Fixed Gamma#gamma function for values smaller than -20. Thanks to Jean Noel Delavalade", "B_clean_title": ["fix", "gamma", "gamma", "function", "valu", "smaller", "than", "20", "thank", "jean", "noel", "delavalad"]},
{"A_title": "Use of ThreadLocals in ToStringStyle and HashCodeBuilder trigger memory leaks in container environmentsThe thread local in org.apache.commons.lang3.builder.ToStringStyle is created but never removed and no API is provided to remove it. If a webapps use of LANG triggers the loading of this class a reference chain will be created that will cause a memory leak on web application reload. See http://markmail.org/thread/uetw2fdrsqgbh2cv for more info.", "A_clean_title": ["use", "threadloc", "thread", "local", "tostringstyl", "string", "style", "hashcodebuild", "hash", "code", "builder", "trigger", "memori", "leak", "contain", "environmentsth", "environ", "thread", "local", "org", "apach", "common", "lang3", "builder", "tostringstyl", "string", "style", "creat", "but", "never", "remov", "no", "api", "provid", "remov", "it", "webapp", "use", "lang", "trigger", "load", "thi", "class", "refer", "chain", "will", "creat", "that", "will", "caus", "memori", "leak", "web", "applic", "reload", "see", "http", "markmail", "org", "thread", "uetw2fdrsqgbh2cv", "more", "info"], "B_title": "Clear ThreadLocal for HashCodeBuilder as well", "B_clean_title": ["clear", "threadloc", "thread", "local", "hashcodebuild", "hash", "code", "builder", "as", "well"]}]